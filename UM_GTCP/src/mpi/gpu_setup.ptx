//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-21313570
// Cuda compilation tools, release 8.0, V8.0.53
// Based on LLVM 3.4svn
//

.version 5.0
.target sm_60
.address_size 64

.extern .func  (.param .b32 func_retval0) vprintf
(
	.param .b64 vprintf_param_0,
	.param .b64 vprintf_param_1
)
;
.func  (.param .b64 func_retval0) __internal_trig_reduction_slowpathd
(
	.param .b64 __internal_trig_reduction_slowpathd_param_0,
	.param .b64 __internal_trig_reduction_slowpathd_param_1
)
;
.global .align 16 .b8 params[504];
.const .align 16 .b8 temp[5768];
.const .align 16 .b8 dtemp[5768];
.const .align 16 .b8 rtemi[5768];
.const .align 16 .b8 qtinv[5768];
.const .align 16 .b8 delt[5768];
.const .align 16 .b8 igrid[2884];
.const .align 16 .b8 mtheta[2884];
.const .align 16 .u32 max_shift_mi;
.global .align 16 .b8 radial_decomp[256];
.global .texref evectorTexRef;
.global .align 4 .b8 d_start_shift[12];
.global .align 1 .b8 _ZN6thrust6system6detail10sequential3seqE[1];
.shared .align 8 .b8 _ZN6thrust6system4cuda6detail5bulk_6detail41_GLOBAL__N__17_gpu_setup_cpp1_ii_524b47c119s_on_chip_allocatorE[24];
.global .align 1 .b8 _ZN6thrust6system4cuda6detail5bulk_4rootE[1];
.global .align 1 .b8 _ZN6thrust12placeholders2_1E[1];
.global .align 1 .b8 _ZN6thrust12placeholders2_2E[1];
.global .align 1 .b8 _ZN6thrust12placeholders2_3E[1];
.global .align 1 .b8 _ZN6thrust12placeholders2_4E[1];
.global .align 1 .b8 _ZN6thrust12placeholders2_5E[1];
.global .align 1 .b8 _ZN6thrust12placeholders2_6E[1];
.global .align 1 .b8 _ZN6thrust12placeholders2_7E[1];
.global .align 1 .b8 _ZN6thrust12placeholders2_8E[1];
.global .align 1 .b8 _ZN6thrust12placeholders2_9E[1];
.global .align 1 .b8 _ZN6thrust12placeholders3_10E[1];
.global .align 1 .b8 _ZN6thrust3seqE[1];
.global .align 1 .b8 $str[38] = {119, 97, 114, 110, 105, 110, 103, 58, 32, 114, 101, 100, 117, 99, 105, 110, 103, 32, 114, 104, 111, 105, 32, 116, 111, 32, 37, 101, 32, 102, 114, 111, 109, 32, 37, 101, 10, 0};
.extern .shared .align 4 .b8 shared_buffer[];
.extern .shared .align 8 .b8 shared_buffer_gyro[];
.global .align 1 .b8 $str1[61] = {69, 114, 114, 111, 114, 33, 32, 100, 101, 99, 111, 117, 112, 108, 105, 110, 103, 32, 109, 111, 100, 101, 115, 32, 102, 111, 114, 32, 110, 111, 110, 108, 105, 110, 101, 97, 114, 32, 61, 32, 48, 46, 48, 32, 110, 111, 116, 32, 105, 109, 112, 108, 101, 109, 101, 110, 116, 101, 100, 10, 0};
.global .align 1 .b8 $str2[39] = {114, 104, 111, 116, 109, 112, 61, 37, 101, 32, 114, 104, 111, 105, 61, 37, 101, 32, 114, 104, 111, 95, 109, 97, 120, 61, 37, 101, 32, 112, 103, 121, 114, 111, 61, 37, 101, 10, 0};
.global .align 1 .b8 $str3[47] = {119, 97, 114, 110, 105, 110, 103, 58, 32, 112, 117, 115, 104, 32, 115, 117, 98, 32, 114, 101, 100, 117, 99, 105, 110, 103, 32, 114, 104, 111, 105, 32, 116, 111, 32, 37, 101, 32, 102, 114, 111, 109, 32, 37, 101, 10, 0};
// _ZN6thrust6system4cuda6detail4cub_28DeviceRadixSortUpsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE16PtxUpsweepPolicyELb0EiiEEvPT1_PT2_SA_iibNS3_13GridEvenShareISA_EE$__cuda_local_var_106522_74_non_const_temp_storage has been demoted
// _ZN6thrust6system4cuda6detail4cub_28DeviceRadixSortUpsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE19PtxAltUpsweepPolicyELb0EiiEEvPT1_PT2_SA_iibNS3_13GridEvenShareISA_EE$__cuda_local_var_106522_74_non_const_temp_storage has been demoted
// _ZN6thrust6system4cuda6detail4cub_23RadixSortScanBinsKernelINS3_23DeviceRadixSortDispatchILb0EiiiE13PtxScanPolicyEiEEvPT0_i$__cuda_local_var_106560_67_non_const_temp_storage has been demoted
// _ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE18PtxDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE$__cuda_local_var_106605_76_non_const_temp_storage has been demoted
// _ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE21PtxAltDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE$__cuda_local_var_106605_76_non_const_temp_storage has been demoted
.extern .shared .align 4 .b8 _ZN6thrust6system4cuda6detail5bulk_6detail20s_data_segment_beginE[];
.const .align 8 .b8 __cudart_i2opi_d[144] = {8, 93, 141, 31, 177, 95, 251, 107, 234, 146, 82, 138, 247, 57, 7, 61, 123, 241, 229, 235, 199, 186, 39, 117, 45, 234, 95, 158, 102, 63, 70, 79, 183, 9, 203, 39, 207, 126, 54, 109, 31, 109, 10, 90, 139, 17, 47, 239, 15, 152, 5, 222, 255, 151, 248, 31, 59, 40, 249, 189, 139, 95, 132, 156, 244, 57, 83, 131, 57, 214, 145, 57, 65, 126, 95, 180, 38, 112, 156, 233, 132, 68, 187, 46, 245, 53, 130, 232, 62, 167, 41, 177, 28, 235, 29, 254, 28, 146, 209, 9, 234, 46, 73, 6, 224, 210, 77, 66, 58, 110, 36, 183, 97, 197, 187, 222, 171, 99, 81, 254, 65, 144, 67, 60, 153, 149, 98, 219, 192, 221, 52, 245, 209, 87, 39, 252, 41, 21, 68, 78, 110, 131, 249, 162};
.const .align 8 .b8 __cudart_sin_cos_coeffs[128] = {186, 94, 120, 249, 101, 219, 229, 61, 70, 210, 176, 44, 241, 229, 90, 190, 146, 227, 172, 105, 227, 29, 199, 62, 161, 98, 219, 25, 160, 1, 42, 191, 24, 8, 17, 17, 17, 17, 129, 63, 84, 85, 85, 85, 85, 85, 197, 191, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 100, 129, 253, 32, 131, 255, 168, 189, 40, 133, 239, 193, 167, 238, 33, 62, 217, 230, 6, 142, 79, 126, 146, 190, 233, 188, 221, 25, 160, 1, 250, 62, 71, 93, 193, 22, 108, 193, 86, 191, 81, 85, 85, 85, 85, 85, 165, 63, 0, 0, 0, 0, 0, 0, 224, 191, 0, 0, 0, 0, 0, 0, 240, 63};

.func _Z14atomicDPupdatePdd(
	.param .b64 _Z14atomicDPupdatePdd_param_0,
	.param .b64 _Z14atomicDPupdatePdd_param_1
)
{
	.reg .pred 	%p<2>;
	.reg .f64 	%fd<7>;
	.reg .b64 	%rd<5>;


	ld.param.u64 	%rd1, [_Z14atomicDPupdatePdd_param_0];
	ld.param.f64 	%fd4, [_Z14atomicDPupdatePdd_param_1];
	ld.f64 	%fd6, [%rd1];

BB0_1:
	mov.f64 	%fd2, %fd6;
	add.f64 	%fd5, %fd2, %fd4;
	mov.b64 	 %rd2, %fd5;
	mov.b64 	 %rd3, %fd2;
	atom.cas.b64 	%rd4, [%rd1], %rd3, %rd2;
	mov.b64 	 %fd6, %rd4;
	setp.neu.f64	%p1, %fd2, %fd6;
	@%p1 bra 	BB0_1;

	ret;
}

.entry _Z16gpu_charge_multiP16gtc_field_data_tP19gtc_particle_data_tP23gtc_aux_particle_data_ti(
	.param .u64 _Z16gpu_charge_multiP16gtc_field_data_tP19gtc_particle_data_tP23gtc_aux_particle_data_ti_param_0,
	.param .u64 _Z16gpu_charge_multiP16gtc_field_data_tP19gtc_particle_data_tP23gtc_aux_particle_data_ti_param_1,
	.param .u64 _Z16gpu_charge_multiP16gtc_field_data_tP19gtc_particle_data_tP23gtc_aux_particle_data_ti_param_2,
	.param .u32 _Z16gpu_charge_multiP16gtc_field_data_tP19gtc_particle_data_tP23gtc_aux_particle_data_ti_param_3
)
.maxntid 64, 1, 1
.minnctapersm 1
{
	.local .align 8 .b8 	__local_depot1[16];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<12>;
	.reg .b32 	%r<67>;
	.reg .f64 	%fd<82>;
	.reg .b64 	%rd<75>;


	mov.u64 	%rd74, __local_depot1;
	cvta.local.u64 	%SP, %rd74;
	ld.param.u64 	%rd14, [_Z16gpu_charge_multiP16gtc_field_data_tP19gtc_particle_data_tP23gtc_aux_particle_data_ti_param_0];
	ld.param.u64 	%rd15, [_Z16gpu_charge_multiP16gtc_field_data_tP19gtc_particle_data_tP23gtc_aux_particle_data_ti_param_1];
	mov.u32 	%r12, %ntid.x;
	mov.u32 	%r13, %ctaid.x;
	mov.u32 	%r14, %tid.x;
	mad.lo.s32 	%r65, %r12, %r13, %r14;
	ld.global.v4.u32 	{%r15, %r16, %r17, %r18}, [params];
	ld.global.f64 	%fd1, [params+480];
	ld.global.u32 	%r3, [params+20];
	cvt.s64.s32	%rd1, %r3;
	ld.global.f64 	%fd2, [params+496];
	ld.global.u32 	%r4, [radial_decomp+24];
	ld.global.f64 	%fd3, [radial_decomp+96];
	ld.global.f64 	%fd4, [params+200];
	setp.ge.s32	%p1, %r65, %r15;
	@%p1 bra 	BB1_7;

	cvta.to.global.u64 	%rd16, %rd15;
	ld.global.f64 	%fd5, [params+488];
	ld.global.f64 	%fd6, [params+472];
	ld.global.f64 	%fd7, [params+360];
	cvta.to.global.u64 	%rd17, %rd14;
	ld.global.nc.u64 	%rd2, [%rd17+136];
	ld.global.f64 	%fd23, [params+208];
	sub.f64 	%fd8, %fd23, %fd4;
	ld.global.nc.u64 	%rd3, [%rd17+208];
	ld.global.nc.u64 	%rd4, [%rd17+216];
	ld.global.nc.u64 	%rd5, [%rd16];
	ld.global.nc.u64 	%rd6, [%rd16+8];
	ld.global.nc.u64 	%rd7, [%rd16+16];
	ld.global.nc.u64 	%rd8, [%rd16+32];
	ld.global.nc.u64 	%rd9, [%rd16+40];
	add.s32 	%r6, %r3, -1;

BB1_2:
	mul.wide.s32 	%rd18, %r65, 8;
	add.s64 	%rd19, %rd5, %rd18;
	add.s64 	%rd20, %rd6, %rd18;
	add.s64 	%rd21, %rd7, %rd18;
	add.s64 	%rd22, %rd8, %rd18;
	add.s64 	%rd23, %rd9, %rd18;
	ld.f64 	%fd24, [%rd23];
	mul.f64 	%fd80, %fd6, %fd24;
	ld.f64 	%fd25, [%rd19];
	sub.f64 	%fd10, %fd25, %fd4;
	fma.rn.f64 	%fd26, %fd1, %fd10, 0d3FE0000000000000;
	cvt.rzi.s32.f64	%r20, %fd26;
	min.s32 	%r21, %r18, %r20;
	setp.gt.s32	%p2, %r21, 0;
	ld.f64 	%fd11, [%rd20];
	mul.f64 	%fd27, %fd2, %fd11;
	cvt.s64.s32	%rd24, %r21;
	selp.b64	%rd25, %rd24, 0, %p2;
	shl.b64 	%rd26, %rd25, 3;
	mov.u64 	%rd27, delt;
	add.s64 	%rd28, %rd27, %rd26;
	ld.const.f64 	%fd28, [%rd28];
	fma.rn.f64 	%fd29, %fd27, %fd28, 0d3FE0000000000000;
	cvt.rzi.s32.f64	%r22, %fd29;
	shl.b64 	%rd29, %rd25, 2;
	mov.u64 	%rd30, mtheta;
	add.s64 	%rd31, %rd30, %rd29;
	ld.const.u32 	%r23, [%rd31];
	min.s32 	%r24, %r23, %r22;
	mov.u32 	%r25, 0;
	max.s32 	%r26, %r24, %r25;
	ld.f64 	%fd12, [%rd21];
	sub.f64 	%fd30, %fd12, %fd7;
	mul.f64 	%fd31, %fd5, %fd30;
	cvt.rzi.s32.f64	%r27, %fd31;
	cvt.u32.u64	%r28, %rd1;
	setp.gt.s32	%p3, %r28, %r27;
	selp.b32	%r29, %r27, %r6, %p3;
	max.s32 	%r8, %r29, %r25;
	cvt.rn.f64.s32	%fd32, %r8;
	sub.f64 	%fd33, %fd31, %fd32;
	ld.f64 	%fd34, [%rd22];
	mul.f64 	%fd13, %fd34, %fd33;
	sub.f64 	%fd14, %fd34, %fd13;
	mov.u64 	%rd32, igrid;
	add.s64 	%rd33, %rd32, %rd29;
	sub.s32 	%r30, %r26, %r4;
	ld.const.u32 	%r31, [%rd33];
	add.s32 	%r32, %r30, %r31;
	shl.b32 	%r33, %r32, 2;
	cvt.s64.s32	%rd34, %r33;
	neg.s64 	%rd73, %rd34;
	mov.u32 	%r66, -4;

BB1_3:
	shl.b64 	%rd35, %rd73, 3;
	sub.s64 	%rd12, %rd3, %rd35;
	ld.f64 	%fd16, [%rd12];
	mul.f64 	%fd17, %fd80, %fd16;
	abs.f64 	%fd18, %fd17;
	setp.leu.f64	%p4, %fd18, %fd3;
	mov.f64 	%fd81, %fd17;
	@%p4 bra 	BB1_5;

	div.rn.f64 	%fd35, %fd17, %fd18;
	mul.f64 	%fd19, %fd3, %fd35;
	div.rn.f64 	%fd36, %fd19, %fd16;
	add.u64 	%rd36, %SP, 0;
	cvta.to.local.u64 	%rd37, %rd36;
	st.local.f64 	[%rd37], %fd36;
	st.local.f64 	[%rd37+8], %fd17;
	mov.u64 	%rd38, $str;
	cvta.global.u64 	%rd39, %rd38;
	// Callseq Start 0
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd39;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd36;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r34, [retval0+0];
	
	//{
	}// Callseq End 0
	ld.f64 	%fd37, [%rd12];
	div.rn.f64 	%fd80, %fd19, %fd37;
	mov.f64 	%fd81, %fd19;

BB1_5:
	mov.u64 	%rd72, igrid;
	mov.u64 	%rd71, mtheta;
	mov.u64 	%rd70, delt;
	mov.u32 	%r63, 0;
	add.f64 	%fd38, %fd10, %fd81;
	setp.lt.f64	%p5, %fd8, %fd38;
	selp.f64	%fd39, %fd8, %fd38, %p5;
	setp.gt.f64	%p6, %fd39, 0d0000000000000000;
	selp.f64	%fd40, %fd39, 0d0000000000000000, %p6;
	mul.f64 	%fd41, %fd1, %fd40;
	sub.s64 	%rd41, %rd4, %rd35;
	ld.f64 	%fd42, [%rd41];
	fma.rn.f64 	%fd43, %fd80, %fd42, %fd11;
	cvt.rzi.s32.f64	%r35, %fd41;
	setp.gt.s32	%p7, %r18, %r35;
	add.s32 	%r36, %r18, -1;
	selp.b32	%r37, %r35, %r36, %p7;
	max.s32 	%r39, %r37, %r63;
	cvt.rn.f64.s32	%fd44, %r39;
	sub.f64 	%fd45, %fd41, %fd44;
	mov.f64 	%fd46, 0d3FF0000000000000;
	sub.f64 	%fd47, %fd46, %fd45;
	mul.wide.s32 	%rd42, %r39, 8;
	mov.u64 	%rd43, qtinv;
	add.s64 	%rd44, %rd43, %rd42;
	ld.const.f64 	%fd48, [%rd44];
	mul.f64 	%fd49, %fd12, %fd48;
	sub.f64 	%fd50, %fd43, %fd49;
	fma.rn.f64 	%fd51, %fd2, %fd50, 0d4024000000000000;
	cvt.rzi.s32.f64	%r40, %fd51;
	cvt.rn.f64.s32	%fd52, %r40;
	sub.f64 	%fd53, %fd51, %fd52;
	add.s64 	%rd46, %rd70, %rd42;
	ld.const.f64 	%fd54, [%rd46];
	mul.f64 	%fd55, %fd54, %fd53;
	mul.wide.s32 	%rd47, %r39, 4;
	add.s64 	%rd49, %rd71, %rd47;
	ld.const.u32 	%r41, [%rd49];
	add.s32 	%r42, %r41, -1;
	cvt.rzi.s32.f64	%r43, %fd55;
	setp.gt.s32	%p8, %r41, %r43;
	selp.b32	%r44, %r43, %r42, %p8;
	max.s32 	%r45, %r44, %r63;
	add.s64 	%rd51, %rd72, %rd47;
	cvt.rn.f64.s32	%fd56, %r45;
	sub.f64 	%fd57, %fd55, %fd56;
	ld.const.f64 	%fd58, [%rd44+8];
	mul.f64 	%fd59, %fd12, %fd58;
	sub.f64 	%fd60, %fd43, %fd59;
	fma.rn.f64 	%fd61, %fd2, %fd60, 0d4024000000000000;
	cvt.rzi.s32.f64	%r46, %fd61;
	cvt.rn.f64.s32	%fd62, %r46;
	sub.f64 	%fd63, %fd61, %fd62;
	ld.const.f64 	%fd64, [%rd46+8];
	mul.f64 	%fd65, %fd64, %fd63;
	ld.const.u32 	%r47, [%rd49+4];
	add.s32 	%r48, %r47, -1;
	cvt.rzi.s32.f64	%r49, %fd65;
	setp.gt.s32	%p9, %r47, %r49;
	selp.b32	%r50, %r49, %r48, %p9;
	max.s32 	%r51, %r50, %r63;
	ld.const.u32 	%r52, [%rd51+4];
	cvt.rn.f64.s32	%fd66, %r51;
	sub.f64 	%fd67, %fd65, %fd66;
	mul.f64 	%fd68, %fd47, %fd57;
	sub.f64 	%fd69, %fd47, %fd68;
	mul.f64 	%fd70, %fd45, %fd67;
	sub.f64 	%fd71, %fd45, %fd70;
	ld.const.u32 	%r53, [%rd51];
	sub.s32 	%r54, %r53, %r4;
	add.s32 	%r55, %r54, %r45;
	add.s32 	%r56, %r6, 2;
	mad.lo.s32 	%r57, %r55, %r56, %r8;
	cvt.s64.s32	%rd52, %r57;
	mul.wide.s32 	%rd53, %r57, 8;
	mul.f64 	%fd72, %fd14, %fd69;
	add.s64 	%rd54, %rd2, %rd53;
	// Callseq Start 1
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd54;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd72;
	call.uni 
	_Z14atomicDPupdatePdd, 
	(
	param0, 
	param1
	);
	
	//{
	}// Callseq End 1
	add.s64 	%rd55, %rd54, 8;
	mul.f64 	%fd73, %fd13, %fd69;
	// Callseq Start 2
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd55;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd73;
	call.uni 
	_Z14atomicDPupdatePdd, 
	(
	param0, 
	param1
	);
	
	//{
	}// Callseq End 2
	add.s64 	%rd56, %rd1, %rd52;
	shl.b64 	%rd57, %rd56, 3;
	add.s64 	%rd58, %rd57, %rd2;
	add.s64 	%rd59, %rd58, 8;
	mul.f64 	%fd74, %fd14, %fd68;
	// Callseq Start 3
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd59;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd74;
	call.uni 
	_Z14atomicDPupdatePdd, 
	(
	param0, 
	param1
	);
	
	//{
	}// Callseq End 3
	add.s64 	%rd60, %rd58, 16;
	mul.f64 	%fd75, %fd13, %fd68;
	// Callseq Start 4
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd60;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd75;
	call.uni 
	_Z14atomicDPupdatePdd, 
	(
	param0, 
	param1
	);
	
	//{
	}// Callseq End 4
	sub.s32 	%r58, %r52, %r4;
	add.s32 	%r59, %r58, %r51;
	mad.lo.s32 	%r60, %r59, %r56, %r8;
	cvt.s64.s32	%rd61, %r60;
	mul.wide.s32 	%rd62, %r60, 8;
	mul.f64 	%fd76, %fd14, %fd71;
	add.s64 	%rd63, %rd2, %rd62;
	// Callseq Start 5
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd63;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd76;
	call.uni 
	_Z14atomicDPupdatePdd, 
	(
	param0, 
	param1
	);
	
	//{
	}// Callseq End 5
	add.s64 	%rd64, %rd63, 8;
	mul.f64 	%fd77, %fd13, %fd71;
	// Callseq Start 6
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd64;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd77;
	call.uni 
	_Z14atomicDPupdatePdd, 
	(
	param0, 
	param1
	);
	
	//{
	}// Callseq End 6
	add.s64 	%rd65, %rd1, %rd61;
	shl.b64 	%rd66, %rd65, 3;
	add.s64 	%rd67, %rd66, %rd2;
	add.s64 	%rd68, %rd67, 8;
	mul.f64 	%fd78, %fd14, %fd70;
	// Callseq Start 7
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd68;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd78;
	call.uni 
	_Z14atomicDPupdatePdd, 
	(
	param0, 
	param1
	);
	
	//{
	}// Callseq End 7
	add.s64 	%rd69, %rd67, 16;
	mul.f64 	%fd79, %fd13, %fd70;
	// Callseq Start 8
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd69;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd79;
	call.uni 
	_Z14atomicDPupdatePdd, 
	(
	param0, 
	param1
	);
	
	//{
	}// Callseq End 8
	add.s64 	%rd73, %rd73, -1;
	add.s32 	%r66, %r66, 1;
	setp.ne.s32	%p10, %r66, 0;
	@%p10 bra 	BB1_3;

	mov.u32 	%r64, %ntid.x;
	mov.u32 	%r61, %nctaid.x;
	mad.lo.s32 	%r65, %r64, %r61, %r65;
	setp.lt.s32	%p11, %r65, %r15;
	@%p11 bra 	BB1_2;

BB1_7:
	ret;
}

.entry _Z22gpu_charge_cooperativeP16gtc_field_data_tP19gtc_particle_data_tP23gtc_aux_particle_data_ti(
	.param .u64 _Z22gpu_charge_cooperativeP16gtc_field_data_tP19gtc_particle_data_tP23gtc_aux_particle_data_ti_param_0,
	.param .u64 _Z22gpu_charge_cooperativeP16gtc_field_data_tP19gtc_particle_data_tP23gtc_aux_particle_data_ti_param_1,
	.param .u64 _Z22gpu_charge_cooperativeP16gtc_field_data_tP19gtc_particle_data_tP23gtc_aux_particle_data_ti_param_2,
	.param .u32 _Z22gpu_charge_cooperativeP16gtc_field_data_tP19gtc_particle_data_tP23gtc_aux_particle_data_ti_param_3
)
.maxntid 64, 1, 1
.minnctapersm 1
{
	.local .align 8 .b8 	__local_depot2[16];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<19>;
	.reg .b32 	%r<108>;
	.reg .f64 	%fd<92>;
	.reg .b64 	%rd<115>;


	mov.u64 	%rd114, __local_depot2;
	cvta.local.u64 	%SP, %rd114;
	ld.param.u64 	%rd25, [_Z22gpu_charge_cooperativeP16gtc_field_data_tP19gtc_particle_data_tP23gtc_aux_particle_data_ti_param_0];
	ld.param.u64 	%rd26, [_Z22gpu_charge_cooperativeP16gtc_field_data_tP19gtc_particle_data_tP23gtc_aux_particle_data_ti_param_1];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r23, %ctaid.x;
	mov.u32 	%r24, %tid.x;
	mad.lo.s32 	%r105, %r1, %r23, %r24;
	mov.u32 	%r25, %nctaid.x;
	mul.lo.s32 	%r3, %r1, %r25;
	bar.sync 	0;
	ld.global.v4.u32 	{%r26, %r27, %r28, %r29}, [params];
	ld.global.f64 	%fd1, [params+480];
	ld.global.u32 	%r5, [params+20];
	ld.global.f64 	%fd2, [params+496];
	ld.global.u32 	%r6, [radial_decomp+24];
	ld.global.f64 	%fd3, [radial_decomp+96];
	cvta.to.global.u64 	%rd27, %rd25;
	add.s64 	%rd1, %rd27, 136;
	ld.global.nc.u64 	%rd2, [%rd27+136];
	ld.global.f64 	%fd4, [params+200];
	rem.s32 	%r30, %r26, %r3;
	rem.s32 	%r8, %r30, %r1;
	div.s32 	%r31, %r30, %r1;
	setp.eq.s32	%p1, %r8, 0;
	selp.b32	%r32, -1, 0, %p1;
	add.s32 	%r9, %r32, %r31;
	setp.ge.s32	%p2, %r105, %r26;
	@%p2 bra 	BB2_10;

	cvta.to.global.u64 	%rd28, %rd26;
	ld.global.f64 	%fd5, [params+488];
	ld.global.f64 	%fd6, [params+472];
	ld.global.f64 	%fd7, [params+360];
	ld.global.f64 	%fd31, [params+208];
	sub.f64 	%fd8, %fd31, %fd4;
	ld.global.nc.u64 	%rd3, [%rd1+72];
	ld.global.nc.u64 	%rd4, [%rd1+80];
	ld.global.nc.u64 	%rd5, [%rd28];
	ld.global.nc.u64 	%rd6, [%rd28+8];
	ld.global.nc.u64 	%rd7, [%rd28+16];
	ld.global.nc.u64 	%rd8, [%rd28+32];
	ld.global.nc.u64 	%rd9, [%rd28+40];
	mov.u32 	%r106, 0;

BB2_2:
	mov.u32 	%r104, 0;
	mul.wide.s32 	%rd34, %r105, 8;
	add.s64 	%rd29, %rd5, %rd34;
	// inline asm
	ld.global.cs.f64 %fd32, [%rd29];
	// inline asm
	add.s64 	%rd30, %rd6, %rd34;
	// inline asm
	ld.global.cs.f64 %fd33, [%rd30];
	// inline asm
	add.s64 	%rd31, %rd7, %rd34;
	// inline asm
	ld.global.cs.f64 %fd34, [%rd31];
	// inline asm
	add.s64 	%rd32, %rd8, %rd34;
	// inline asm
	ld.global.cs.f64 %fd35, [%rd32];
	// inline asm
	add.s64 	%rd33, %rd9, %rd34;
	// inline asm
	ld.global.cs.f64 %fd36, [%rd33];
	// inline asm
	mul.f64 	%fd90, %fd6, %fd36;
	sub.f64 	%fd12, %fd32, %fd4;
	fma.rn.f64 	%fd37, %fd1, %fd12, 0d3FE0000000000000;
	cvt.rzi.s32.f64	%r35, %fd37;
	min.s32 	%r36, %r29, %r35;
	setp.gt.s32	%p3, %r36, 0;
	mul.f64 	%fd38, %fd2, %fd33;
	cvt.s64.s32	%rd35, %r36;
	selp.b64	%rd36, %rd35, 0, %p3;
	shl.b64 	%rd37, %rd36, 3;
	mov.u64 	%rd38, delt;
	add.s64 	%rd39, %rd38, %rd37;
	ld.const.f64 	%fd39, [%rd39];
	fma.rn.f64 	%fd40, %fd38, %fd39, 0d3FE0000000000000;
	cvt.rzi.s32.f64	%r37, %fd40;
	shl.b64 	%rd40, %rd36, 2;
	mov.u64 	%rd41, mtheta;
	add.s64 	%rd42, %rd41, %rd40;
	ld.const.u32 	%r38, [%rd42];
	min.s32 	%r39, %r38, %r37;
	max.s32 	%r41, %r39, %r104;
	sub.f64 	%fd41, %fd34, %fd7;
	mul.f64 	%fd42, %fd5, %fd41;
	cvt.rzi.s32.f64	%r42, %fd42;
	setp.gt.s32	%p4, %r5, %r42;
	add.s32 	%r43, %r5, -1;
	selp.b32	%r44, %r42, %r43, %p4;
	max.s32 	%r12, %r44, %r104;
	cvt.rn.f64.s32	%fd43, %r12;
	sub.f64 	%fd44, %fd42, %fd43;
	mul.f64 	%fd13, %fd35, %fd44;
	sub.f64 	%fd14, %fd35, %fd13;
	mov.u64 	%rd43, igrid;
	add.s64 	%rd44, %rd43, %rd40;
	sub.s32 	%r45, %r41, %r6;
	ld.const.u32 	%r46, [%rd44];
	add.s32 	%r47, %r45, %r46;
	shl.b32 	%r48, %r47, 2;
	cvt.s64.s32	%rd45, %r48;
	neg.s64 	%rd113, %rd45;
	mov.u32 	%r107, -4;

BB2_3:
	shl.b64 	%rd46, %rd113, 3;
	sub.s64 	%rd12, %rd3, %rd46;
	ld.f64 	%fd16, [%rd12];
	mul.f64 	%fd91, %fd90, %fd16;
	abs.f64 	%fd18, %fd91;
	setp.leu.f64	%p5, %fd18, %fd3;
	@%p5 bra 	BB2_5;

	div.rn.f64 	%fd45, %fd91, %fd18;
	mul.f64 	%fd91, %fd3, %fd45;
	div.rn.f64 	%fd46, %fd91, %fd16;
	add.u64 	%rd47, %SP, 0;
	cvta.to.local.u64 	%rd48, %rd47;
	st.local.f64 	[%rd48], %fd46;
	st.local.f64 	[%rd48+8], %fd90;
	mov.u64 	%rd49, $str;
	cvta.global.u64 	%rd50, %rd49;
	// Callseq Start 9
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd50;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd47;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r49, [retval0+0];
	
	//{
	}// Callseq End 9
	ld.f64 	%fd47, [%rd12];
	div.rn.f64 	%fd90, %fd91, %fd47;

BB2_5:
	ld.param.u32 	%r103, [_Z22gpu_charge_cooperativeP16gtc_field_data_tP19gtc_particle_data_tP23gtc_aux_particle_data_ti_param_3];
	mov.u32 	%r102, %ctaid.x;
	mov.u64 	%rd112, igrid;
	mov.u64 	%rd111, mtheta;
	mov.u64 	%rd110, delt;
	add.f64 	%fd48, %fd12, %fd91;
	setp.lt.f64	%p6, %fd8, %fd48;
	selp.f64	%fd49, %fd8, %fd48, %p6;
	setp.gt.f64	%p7, %fd49, 0d0000000000000000;
	selp.f64	%fd50, %fd49, 0d0000000000000000, %p7;
	mul.f64 	%fd51, %fd1, %fd50;
	sub.s64 	%rd52, %rd4, %rd46;
	ld.f64 	%fd52, [%rd52];
	fma.rn.f64 	%fd53, %fd90, %fd52, %fd33;
	cvt.rzi.s32.f64	%r50, %fd51;
	setp.gt.s32	%p8, %r29, %r50;
	add.s32 	%r51, %r29, -1;
	selp.b32	%r52, %r50, %r51, %p8;
	mov.u32 	%r53, 0;
	max.s32 	%r54, %r52, %r53;
	cvt.rn.f64.s32	%fd54, %r54;
	sub.f64 	%fd55, %fd51, %fd54;
	mov.f64 	%fd56, 0d3FF0000000000000;
	sub.f64 	%fd57, %fd56, %fd55;
	mul.wide.s32 	%rd53, %r54, 8;
	mov.u64 	%rd54, qtinv;
	add.s64 	%rd55, %rd54, %rd53;
	ld.const.f64 	%fd58, [%rd55];
	mul.f64 	%fd59, %fd34, %fd58;
	sub.f64 	%fd60, %fd53, %fd59;
	fma.rn.f64 	%fd61, %fd2, %fd60, 0d4024000000000000;
	cvt.rzi.s32.f64	%r55, %fd61;
	cvt.rn.f64.s32	%fd62, %r55;
	sub.f64 	%fd63, %fd61, %fd62;
	add.s64 	%rd57, %rd110, %rd53;
	ld.const.f64 	%fd64, [%rd57];
	mul.f64 	%fd65, %fd64, %fd63;
	mul.wide.s32 	%rd58, %r54, 4;
	add.s64 	%rd60, %rd111, %rd58;
	ld.const.u32 	%r56, [%rd60];
	add.s32 	%r57, %r56, -1;
	cvt.rzi.s32.f64	%r58, %fd65;
	setp.gt.s32	%p9, %r56, %r58;
	selp.b32	%r59, %r58, %r57, %p9;
	max.s32 	%r60, %r59, %r53;
	add.s64 	%rd62, %rd112, %rd58;
	cvt.rn.f64.s32	%fd66, %r60;
	sub.f64 	%fd67, %fd65, %fd66;
	ld.const.f64 	%fd68, [%rd55+8];
	mul.f64 	%fd69, %fd34, %fd68;
	sub.f64 	%fd70, %fd53, %fd69;
	fma.rn.f64 	%fd71, %fd2, %fd70, 0d4024000000000000;
	cvt.rzi.s32.f64	%r61, %fd71;
	cvt.rn.f64.s32	%fd72, %r61;
	sub.f64 	%fd73, %fd71, %fd72;
	ld.const.f64 	%fd74, [%rd57+8];
	mul.f64 	%fd75, %fd74, %fd73;
	ld.const.u32 	%r62, [%rd60+4];
	add.s32 	%r63, %r62, -1;
	cvt.rzi.s32.f64	%r64, %fd75;
	setp.gt.s32	%p10, %r62, %r64;
	selp.b32	%r65, %r64, %r63, %p10;
	max.s32 	%r66, %r65, %r53;
	cvt.rn.f64.s32	%fd76, %r66;
	sub.f64 	%fd77, %fd75, %fd76;
	mul.f64 	%fd78, %fd57, %fd67;
	sub.f64 	%fd79, %fd57, %fd78;
	mul.f64 	%fd80, %fd55, %fd77;
	sub.f64 	%fd81, %fd55, %fd80;
	ld.const.u32 	%r67, [%rd62];
	sub.s32 	%r68, %r67, %r6;
	add.s32 	%r69, %r68, %r60;
	add.s32 	%r70, %r5, 1;
	mad.lo.s32 	%r14, %r69, %r70, %r12;
	mul.f64 	%fd23, %fd14, %fd79;
	mul.f64 	%fd24, %fd13, %fd79;
	mul.f64 	%fd25, %fd14, %fd78;
	mul.f64 	%fd26, %fd13, %fd78;
	ld.const.u32 	%r71, [%rd62+4];
	sub.s32 	%r72, %r71, %r6;
	add.s32 	%r73, %r72, %r66;
	mad.lo.s32 	%r15, %r73, %r70, %r12;
	mul.f64 	%fd27, %fd14, %fd81;
	mul.f64 	%fd28, %fd13, %fd81;
	mul.f64 	%fd29, %fd14, %fd80;
	mul.f64 	%fd30, %fd13, %fd80;
	setp.gt.s32	%p11, %r102, %r9;
	selp.b32	%r75, -1, 0, %p11;
	add.s32 	%r76, %r103, %r75;
	add.s32 	%r77, %r76, -1;
	setp.eq.s32	%p12, %r106, %r77;
	setp.eq.s32	%p13, %r102, %r9;
	and.pred  	%p14, %p12, %p13;
	setp.ne.s32	%p15, %r8, 0;
	and.pred  	%p16, %p14, %p15;
	@%p16 bra 	BB2_7;
	bra.uni 	BB2_6;

BB2_7:
	cvt.s64.s32	%rd91, %r14;
	mul.wide.s32 	%rd92, %r14, 8;
	add.s64 	%rd93, %rd2, %rd92;
	// Callseq Start 18
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd93;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd23;
	call.uni 
	_Z14atomicDPupdatePdd, 
	(
	param0, 
	param1
	);
	
	//{
	}// Callseq End 18
	add.s64 	%rd94, %rd93, 8;
	// Callseq Start 19
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd94;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd24;
	call.uni 
	_Z14atomicDPupdatePdd, 
	(
	param0, 
	param1
	);
	
	//{
	}// Callseq End 19
	cvt.s64.s32	%rd95, %r5;
	add.s64 	%rd96, %rd95, %rd91;
	shl.b64 	%rd97, %rd96, 3;
	add.s64 	%rd98, %rd97, %rd2;
	add.s64 	%rd99, %rd98, 8;
	// Callseq Start 20
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd99;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd25;
	call.uni 
	_Z14atomicDPupdatePdd, 
	(
	param0, 
	param1
	);
	
	//{
	}// Callseq End 20
	add.s64 	%rd100, %rd98, 16;
	// Callseq Start 21
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd100;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd26;
	call.uni 
	_Z14atomicDPupdatePdd, 
	(
	param0, 
	param1
	);
	
	//{
	}// Callseq End 21
	cvt.s64.s32	%rd101, %r15;
	mul.wide.s32 	%rd102, %r15, 8;
	add.s64 	%rd103, %rd2, %rd102;
	// Callseq Start 22
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd103;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd27;
	call.uni 
	_Z14atomicDPupdatePdd, 
	(
	param0, 
	param1
	);
	
	//{
	}// Callseq End 22
	add.s64 	%rd104, %rd103, 8;
	// Callseq Start 23
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd104;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd28;
	call.uni 
	_Z14atomicDPupdatePdd, 
	(
	param0, 
	param1
	);
	
	//{
	}// Callseq End 23
	add.s64 	%rd105, %rd95, %rd101;
	shl.b64 	%rd106, %rd105, 3;
	add.s64 	%rd107, %rd106, %rd2;
	add.s64 	%rd108, %rd107, 8;
	// Callseq Start 24
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd108;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd29;
	call.uni 
	_Z14atomicDPupdatePdd, 
	(
	param0, 
	param1
	);
	
	//{
	}// Callseq End 24
	add.s64 	%rd109, %rd107, 16;
	// Callseq Start 25
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd109;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd30;
	call.uni 
	_Z14atomicDPupdatePdd, 
	(
	param0, 
	param1
	);
	
	//{
	}// Callseq End 25
	bra.uni 	BB2_8;

BB2_6:
	shl.b32 	%r78, %r24, 2;
	mul.wide.s32 	%rd63, %r78, 4;
	mov.u64 	%rd64, shared_buffer;
	add.s64 	%rd13, %rd64, %rd63;
	st.shared.u32 	[%rd13], %r14;
	add.s32 	%r79, %r14, 1;
	st.shared.u32 	[%rd13+4], %r79;
	add.s32 	%r80, %r14, %r5;
	add.s32 	%r81, %r80, 1;
	st.shared.u32 	[%rd13+8], %r81;
	add.s32 	%r82, %r80, 2;
	st.shared.u32 	[%rd13+12], %r82;
	shl.b32 	%r83, %r1, 2;
	mul.wide.s32 	%rd65, %r83, 4;
	add.s64 	%rd14, %rd64, %rd65;
	mul.wide.s32 	%rd66, %r78, 8;
	add.s64 	%rd15, %rd14, %rd66;
	st.shared.f64 	[%rd15], %fd23;
	st.shared.f64 	[%rd15+8], %fd24;
	st.shared.f64 	[%rd15+16], %fd25;
	st.shared.f64 	[%rd15+24], %fd26;
	bar.sync 	0;
	mul.wide.s32 	%rd67, %r24, 4;
	add.s64 	%rd16, %rd64, %rd67;
	ld.shared.u32 	%r84, [%rd16];
	mul.wide.s32 	%rd69, %r84, 8;
	add.s64 	%rd70, %rd2, %rd69;
	mul.wide.s32 	%rd71, %r24, 8;
	add.s64 	%rd17, %rd14, %rd71;
	ld.shared.f64 	%fd82, [%rd17];
	// Callseq Start 10
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd70;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd82;
	call.uni 
	_Z14atomicDPupdatePdd, 
	(
	param0, 
	param1
	);
	
	//{
	}// Callseq End 10
	mul.wide.s32 	%rd72, %r1, 4;
	add.s64 	%rd18, %rd16, %rd72;
	ld.shared.u32 	%r85, [%rd18];
	mul.wide.s32 	%rd73, %r85, 8;
	add.s64 	%rd74, %rd2, %rd73;
	add.s32 	%r86, %r1, %r24;
	mul.wide.s32 	%rd75, %r86, 8;
	add.s64 	%rd19, %rd14, %rd75;
	ld.shared.f64 	%fd83, [%rd19];
	// Callseq Start 11
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd74;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd83;
	call.uni 
	_Z14atomicDPupdatePdd, 
	(
	param0, 
	param1
	);
	
	//{
	}// Callseq End 11
	shl.b32 	%r87, %r1, 1;
	add.s32 	%r88, %r87, %r24;
	mul.wide.s32 	%rd76, %r88, 4;
	add.s64 	%rd20, %rd64, %rd76;
	ld.shared.u32 	%r89, [%rd20];
	mul.wide.s32 	%rd77, %r89, 8;
	add.s64 	%rd78, %rd2, %rd77;
	mul.wide.s32 	%rd79, %r88, 8;
	add.s64 	%rd21, %rd14, %rd79;
	ld.shared.f64 	%fd84, [%rd21];
	// Callseq Start 12
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd78;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd84;
	call.uni 
	_Z14atomicDPupdatePdd, 
	(
	param0, 
	param1
	);
	
	//{
	}// Callseq End 12
	add.s64 	%rd22, %rd20, %rd72;
	ld.shared.u32 	%r90, [%rd22];
	mul.wide.s32 	%rd80, %r90, 8;
	add.s64 	%rd81, %rd2, %rd80;
	mad.lo.s32 	%r91, %r1, 3, %r24;
	mul.wide.s32 	%rd82, %r91, 8;
	add.s64 	%rd23, %rd14, %rd82;
	ld.shared.f64 	%fd85, [%rd23];
	// Callseq Start 13
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd81;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd85;
	call.uni 
	_Z14atomicDPupdatePdd, 
	(
	param0, 
	param1
	);
	
	//{
	}// Callseq End 13
	st.shared.u32 	[%rd13], %r15;
	add.s32 	%r92, %r15, 1;
	st.shared.u32 	[%rd13+4], %r92;
	add.s32 	%r93, %r15, %r5;
	add.s32 	%r94, %r93, 1;
	st.shared.u32 	[%rd13+8], %r94;
	add.s32 	%r95, %r93, 2;
	st.shared.u32 	[%rd13+12], %r95;
	st.shared.f64 	[%rd15], %fd27;
	st.shared.f64 	[%rd15+8], %fd28;
	st.shared.f64 	[%rd15+16], %fd29;
	st.shared.f64 	[%rd15+24], %fd30;
	bar.sync 	0;
	ld.shared.u32 	%r96, [%rd16];
	mul.wide.s32 	%rd83, %r96, 8;
	add.s64 	%rd84, %rd2, %rd83;
	ld.shared.f64 	%fd86, [%rd17];
	// Callseq Start 14
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd84;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd86;
	call.uni 
	_Z14atomicDPupdatePdd, 
	(
	param0, 
	param1
	);
	
	//{
	}// Callseq End 14
	ld.shared.u32 	%r97, [%rd18];
	mul.wide.s32 	%rd85, %r97, 8;
	add.s64 	%rd86, %rd2, %rd85;
	ld.shared.f64 	%fd87, [%rd19];
	// Callseq Start 15
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd86;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd87;
	call.uni 
	_Z14atomicDPupdatePdd, 
	(
	param0, 
	param1
	);
	
	//{
	}// Callseq End 15
	ld.shared.u32 	%r98, [%rd20];
	mul.wide.s32 	%rd87, %r98, 8;
	add.s64 	%rd88, %rd2, %rd87;
	ld.shared.f64 	%fd88, [%rd21];
	// Callseq Start 16
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd88;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd88;
	call.uni 
	_Z14atomicDPupdatePdd, 
	(
	param0, 
	param1
	);
	
	//{
	}// Callseq End 16
	ld.shared.u32 	%r99, [%rd22];
	mul.wide.s32 	%rd89, %r99, 8;
	add.s64 	%rd90, %rd2, %rd89;
	ld.shared.f64 	%fd89, [%rd23];
	// Callseq Start 17
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd90;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd89;
	call.uni 
	_Z14atomicDPupdatePdd, 
	(
	param0, 
	param1
	);
	
	//{
	}// Callseq End 17

BB2_8:
	add.s64 	%rd113, %rd113, -1;
	add.s32 	%r107, %r107, 1;
	setp.ne.s32	%p17, %r107, 0;
	@%p17 bra 	BB2_3;

	bar.sync 	0;
	add.s32 	%r106, %r106, 1;
	add.s32 	%r105, %r105, %r3;
	setp.lt.s32	%p18, %r105, %r26;
	@%p18 bra 	BB2_2;

BB2_10:
	ret;
}

.entry _Z8memresetPdi(
	.param .u64 _Z8memresetPdi_param_0,
	.param .u32 _Z8memresetPdi_param_1
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<20>;
	.reg .b64 	%rd<6>;


	ld.param.u64 	%rd2, [_Z8memresetPdi_param_0];
	ld.param.u32 	%r6, [_Z8memresetPdi_param_1];
	cvta.to.global.u64 	%rd1, %rd2;
	mov.u32 	%r7, %ntid.x;
	mov.u32 	%r8, %tid.y;
	mov.u32 	%r9, %tid.x;
	mad.lo.s32 	%r1, %r7, %r8, %r9;
	mov.u32 	%r10, %ctaid.y;
	mov.u32 	%r11, %nctaid.x;
	mov.u32 	%r12, %ctaid.x;
	mad.lo.s32 	%r13, %r10, %r11, %r12;
	mov.u32 	%r14, %ntid.y;
	mul.lo.s32 	%r15, %r14, %r7;
	mov.u32 	%r16, %nctaid.y;
	mul.lo.s32 	%r17, %r16, %r11;
	mul.lo.s32 	%r2, %r17, %r15;
	mul.lo.s32 	%r19, %r13, %r15;
	setp.ge.s32	%p1, %r19, %r6;
	@%p1 bra 	BB3_2;

BB3_1:
	add.s32 	%r18, %r1, %r19;
	mul.wide.s32 	%rd3, %r18, 8;
	add.s64 	%rd4, %rd1, %rd3;
	mov.u64 	%rd5, 0;
	st.global.u64 	[%rd4], %rd5;
	add.s32 	%r19, %r19, %r2;
	setp.lt.s32	%p2, %r19, %r6;
	@%p2 bra 	BB3_1;

BB3_2:
	ret;
}

.entry _Z22calculate_sort_keypairP19gtc_particle_data_tPiS1_(
	.param .u64 _Z22calculate_sort_keypairP19gtc_particle_data_tPiS1__param_0,
	.param .u64 _Z22calculate_sort_keypairP19gtc_particle_data_tPiS1__param_1,
	.param .u64 _Z22calculate_sort_keypairP19gtc_particle_data_tPiS1__param_2
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<14>;
	.reg .f64 	%fd<21>;
	.reg .b64 	%rd<17>;


	ld.param.u64 	%rd5, [_Z22calculate_sort_keypairP19gtc_particle_data_tPiS1__param_0];
	ld.param.u64 	%rd3, [_Z22calculate_sort_keypairP19gtc_particle_data_tPiS1__param_1];
	ld.param.u64 	%rd4, [_Z22calculate_sort_keypairP19gtc_particle_data_tPiS1__param_2];
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r4, %ctaid.x;
	mov.u32 	%r5, %tid.x;
	mad.lo.s32 	%r1, %r3, %r4, %r5;
	cvta.to.global.u64 	%rd1, %rd5;
	ld.global.u32 	%r2, [params];
	setp.ge.s32	%p1, %r1, %r2;
	@%p1 bra 	BB4_4;

	ld.global.u64 	%rd2, [%rd1];
	ld.global.f64 	%fd1, [params+200];
	ld.global.f64 	%fd2, [params+480];
	setp.ne.s32	%p2, %r1, 0;
	@%p2 bra 	BB4_3;

	st.global.u32 	[d_start_shift], %r2;
	st.global.u32 	[d_start_shift+4], %r2;
	st.global.u32 	[d_start_shift+8], %r2;

BB4_3:
	cvta.to.global.u64 	%rd6, %rd4;
	cvta.to.global.u64 	%rd7, %rd3;
	cvta.to.global.u64 	%rd8, %rd2;
	ld.global.u32 	%r6, [params+12];
	mul.wide.s32 	%rd9, %r1, 4;
	add.s64 	%rd10, %rd7, %rd9;
	st.global.u32 	[%rd10], %r1;
	mul.wide.s32 	%rd11, %r1, 8;
	add.s64 	%rd12, %rd8, %rd11;
	ld.global.f64 	%fd3, [params+248];
	add.f64 	%fd4, %fd3, %fd3;
	ld.global.u64 	%rd13, [%rd1+16];
	cvta.to.global.u64 	%rd14, %rd13;
	add.s64 	%rd15, %rd14, %rd11;
	ld.global.f64 	%fd5, [%rd15];
	min.f64 	%fd6, %fd4, %fd5;
	ld.global.v2.f64 	{%fd7, %fd8}, [params+352];
	sub.f64 	%fd10, %fd6, %fd7;
	sub.f64 	%fd12, %fd5, %fd8;
	mul.f64 	%fd13, %fd12, %fd10;
	setp.gt.f64	%p3, %fd13, 0d0000000000000000;
	ld.global.f64 	%fd14, [params+496];
	mul.f64 	%fd15, %fd14, %fd10;
	cvt.rmi.f64.f64	%fd16, %fd15;
	sub.f64 	%fd17, %fd15, %fd16;
	setp.lt.f64	%p4, %fd17, 0d3FE0000000000000;
	ld.global.f64 	%fd18, [%rd12];
	sub.f64 	%fd19, %fd18, %fd1;
	fma.rn.f64 	%fd20, %fd2, %fd19, 0d3FE0000000000000;
	cvt.rzi.s32.f64	%r7, %fd20;
	min.s32 	%r8, %r6, %r7;
	mov.u32 	%r9, 0;
	max.s32 	%r10, %r8, %r9;
	selp.b32	%r11, 536870912, 268435456, %p4;
	selp.b32	%r12, %r11, 0, %p3;
	add.s32 	%r13, %r10, %r12;
	add.s64 	%rd16, %rd6, %rd9;
	st.global.u32 	[%rd16], %r13;

BB4_4:
	ret;
}

.entry _Z29calculate_sort_keypair_radialP19gtc_particle_data_tPiS1_(
	.param .u64 _Z29calculate_sort_keypair_radialP19gtc_particle_data_tPiS1__param_0,
	.param .u64 _Z29calculate_sort_keypair_radialP19gtc_particle_data_tPiS1__param_1,
	.param .u64 _Z29calculate_sort_keypair_radialP19gtc_particle_data_tPiS1__param_2
)
{
	.reg .pred 	%p<15>;
	.reg .b32 	%r<18>;
	.reg .f64 	%fd<8>;
	.reg .b64 	%rd<16>;


	ld.param.u64 	%rd3, [_Z29calculate_sort_keypair_radialP19gtc_particle_data_tPiS1__param_0];
	ld.param.u64 	%rd4, [_Z29calculate_sort_keypair_radialP19gtc_particle_data_tPiS1__param_1];
	ld.param.u64 	%rd5, [_Z29calculate_sort_keypair_radialP19gtc_particle_data_tPiS1__param_2];
	mov.u32 	%r6, %ntid.x;
	mov.u32 	%r7, %ctaid.x;
	mov.u32 	%r8, %tid.x;
	mad.lo.s32 	%r1, %r6, %r7, %r8;
	ld.global.f64 	%fd1, [radial_decomp+72];
	ld.global.u32 	%r2, [radial_decomp+132];
	ld.global.u32 	%r3, [radial_decomp+124];
	ld.global.u32 	%r4, [params];
	setp.ge.s32	%p3, %r1, %r4;
	@%p3 bra 	BB5_6;

	cvta.to.global.u64 	%rd6, %rd3;
	ld.global.u64 	%rd1, [%rd6];
	ld.global.f64 	%fd2, [params+200];
	ld.global.f64 	%fd3, [params+480];
	setp.ne.s32	%p4, %r1, 0;
	@%p4 bra 	BB5_3;

	st.global.u32 	[d_start_shift], %r4;
	st.global.u32 	[d_start_shift+4], %r4;
	st.global.u32 	[d_start_shift+8], %r4;

BB5_3:
	cvta.to.global.u64 	%rd7, %rd1;
	ld.global.f64 	%fd5, [radial_decomp+64];
	ld.global.u32 	%r5, [params+12];
	cvt.s64.s32	%rd2, %r1;
	cvta.to.global.u64 	%rd8, %rd4;
	mul.wide.s32 	%rd9, %r1, 4;
	add.s64 	%rd10, %rd8, %rd9;
	st.global.u32 	[%rd10], %r1;
	mul.wide.s32 	%rd11, %r1, 8;
	add.s64 	%rd12, %rd7, %rd11;
	ld.global.f64 	%fd4, [%rd12];
	setp.lt.f64	%p6, %fd4, %fd5;
	setp.gt.s32	%p7, %r2, 0;
	and.pred  	%p8, %p6, %p7;
	mov.pred 	%p14, -1;
	@%p8 bra 	BB5_5;

	add.s32 	%r9, %r3, -1;
	setp.lt.s32	%p9, %r2, %r9;
	setp.gt.f64	%p10, %fd4, %fd1;
	and.pred  	%p14, %p10, %p9;

BB5_5:
	add.s32 	%r10, %r3, -1;
	setp.lt.s32	%p11, %r2, %r10;
	setp.gt.f64	%p12, %fd4, %fd1;
	and.pred  	%p13, %p11, %p12;
	selp.b32	%r11, 536870912, 268435456, %p13;
	sub.f64 	%fd6, %fd4, %fd2;
	fma.rn.f64 	%fd7, %fd3, %fd6, 0d3FE0000000000000;
	cvt.rzi.s32.f64	%r12, %fd7;
	min.s32 	%r13, %r5, %r12;
	mov.u32 	%r14, 0;
	max.s32 	%r15, %r13, %r14;
	selp.b32	%r16, %r11, 0, %p14;
	add.s32 	%r17, %r15, %r16;
	cvta.to.global.u64 	%rd13, %rd5;
	shl.b64 	%rd14, %rd2, 2;
	add.s64 	%rd15, %rd13, %rd14;
	st.global.u32 	[%rd15], %r17;

BB5_6:
	ret;
}

.entry _Z28calculate_sort_keypair_shiftP19gtc_particle_data_tPiS1_(
	.param .u64 _Z28calculate_sort_keypair_shiftP19gtc_particle_data_tPiS1__param_0,
	.param .u64 _Z28calculate_sort_keypair_shiftP19gtc_particle_data_tPiS1__param_1,
	.param .u64 _Z28calculate_sort_keypair_shiftP19gtc_particle_data_tPiS1__param_2
)
{
	.reg .pred 	%p<5>;
	.reg .b32 	%r<10>;
	.reg .f64 	%fd<16>;
	.reg .b64 	%rd<18>;


	ld.param.u64 	%rd3, [_Z28calculate_sort_keypair_shiftP19gtc_particle_data_tPiS1__param_0];
	ld.param.u64 	%rd4, [_Z28calculate_sort_keypair_shiftP19gtc_particle_data_tPiS1__param_1];
	ld.param.u64 	%rd5, [_Z28calculate_sort_keypair_shiftP19gtc_particle_data_tPiS1__param_2];
	mov.u32 	%r5, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r1, %r5, %r6, %r7;
	ld.global.u32 	%r2, [params];
	setp.ge.s32	%p1, %r1, %r2;
	@%p1 bra 	BB6_6;

	setp.ne.s32	%p2, %r1, 0;
	@%p2 bra 	BB6_3;

	st.global.u32 	[d_start_shift], %r2;
	st.global.u32 	[d_start_shift+4], %r2;
	st.global.u32 	[d_start_shift+8], %r2;

BB6_3:
	cvta.to.global.u64 	%rd6, %rd3;
	cvta.to.global.u64 	%rd7, %rd4;
	cvt.s64.s32	%rd1, %r1;
	mul.wide.s32 	%rd8, %r1, 4;
	add.s64 	%rd9, %rd7, %rd8;
	st.global.u32 	[%rd9], %r1;
	mov.u64 	%rd10, params;
	add.s64 	%rd2, %rd10, 496;
	ld.global.f64 	%fd2, [params+248];
	add.f64 	%fd3, %fd2, %fd2;
	ld.global.u64 	%rd11, [%rd6+16];
	cvta.to.global.u64 	%rd12, %rd11;
	mul.wide.s32 	%rd13, %r1, 8;
	add.s64 	%rd14, %rd12, %rd13;
	ld.global.f64 	%fd4, [%rd14];
	min.f64 	%fd5, %fd3, %fd4;
	ld.global.v2.f64 	{%fd6, %fd7}, [params+352];
	sub.f64 	%fd1, %fd5, %fd6;
	sub.f64 	%fd10, %fd4, %fd7;
	mul.f64 	%fd11, %fd10, %fd1;
	mov.u32 	%r9, 0;
	setp.leu.f64	%p3, %fd11, 0d0000000000000000;
	@%p3 bra 	BB6_5;

	ld.global.f64 	%fd12, [%rd2];
	mul.f64 	%fd13, %fd12, %fd1;
	cvt.rmi.f64.f64	%fd14, %fd13;
	sub.f64 	%fd15, %fd13, %fd14;
	setp.lt.f64	%p4, %fd15, 0d3FE0000000000000;
	selp.b32	%r9, 2, 1, %p4;

BB6_5:
	cvta.to.global.u64 	%rd15, %rd5;
	shl.b64 	%rd16, %rd1, 2;
	add.s64 	%rd17, %rd15, %rd16;
	st.global.u32 	[%rd17], %r9;

BB6_6:
	ret;
}

.entry _Z35calculate_sort_keypair_radial_shiftP19gtc_particle_data_tPiS1_(
	.param .u64 _Z35calculate_sort_keypair_radial_shiftP19gtc_particle_data_tPiS1__param_0,
	.param .u64 _Z35calculate_sort_keypair_radial_shiftP19gtc_particle_data_tPiS1__param_1,
	.param .u64 _Z35calculate_sort_keypair_radial_shiftP19gtc_particle_data_tPiS1__param_2
)
{
	.reg .pred 	%p<15>;
	.reg .b32 	%r<12>;
	.reg .f64 	%fd<4>;
	.reg .b64 	%rd<16>;


	ld.param.u64 	%rd2, [_Z35calculate_sort_keypair_radial_shiftP19gtc_particle_data_tPiS1__param_0];
	ld.param.u64 	%rd3, [_Z35calculate_sort_keypair_radial_shiftP19gtc_particle_data_tPiS1__param_1];
	ld.param.u64 	%rd4, [_Z35calculate_sort_keypair_radial_shiftP19gtc_particle_data_tPiS1__param_2];
	mov.u32 	%r5, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r1, %r5, %r6, %r7;
	ld.global.f64 	%fd1, [radial_decomp+72];
	ld.global.u32 	%r2, [radial_decomp+132];
	ld.global.u32 	%r3, [radial_decomp+124];
	ld.global.u32 	%r4, [params];
	setp.ge.s32	%p3, %r1, %r4;
	@%p3 bra 	BB7_6;

	setp.ne.s32	%p4, %r1, 0;
	@%p4 bra 	BB7_3;

	st.global.u32 	[d_start_shift], %r4;
	st.global.u32 	[d_start_shift+4], %r4;
	st.global.u32 	[d_start_shift+8], %r4;

BB7_3:
	cvta.to.global.u64 	%rd5, %rd2;
	cvta.to.global.u64 	%rd6, %rd3;
	ld.global.f64 	%fd3, [radial_decomp+64];
	cvt.s64.s32	%rd1, %r1;
	mul.wide.s32 	%rd7, %r1, 4;
	add.s64 	%rd8, %rd6, %rd7;
	st.global.u32 	[%rd8], %r1;
	ld.global.u64 	%rd9, [%rd5];
	cvta.to.global.u64 	%rd10, %rd9;
	mul.wide.s32 	%rd11, %r1, 8;
	add.s64 	%rd12, %rd10, %rd11;
	ld.global.f64 	%fd2, [%rd12];
	setp.lt.f64	%p6, %fd2, %fd3;
	setp.gt.s32	%p7, %r2, 0;
	and.pred  	%p8, %p6, %p7;
	mov.pred 	%p14, -1;
	@%p8 bra 	BB7_5;

	add.s32 	%r8, %r3, -1;
	setp.lt.s32	%p9, %r2, %r8;
	setp.gt.f64	%p10, %fd2, %fd1;
	and.pred  	%p14, %p10, %p9;

BB7_5:
	cvta.to.global.u64 	%rd13, %rd4;
	add.s32 	%r9, %r3, -1;
	setp.lt.s32	%p11, %r2, %r9;
	setp.gt.f64	%p12, %fd2, %fd1;
	and.pred  	%p13, %p12, %p11;
	selp.b32	%r10, 2, 1, %p13;
	selp.b32	%r11, %r10, 0, %p14;
	shl.b64 	%rd14, %rd1, 2;
	add.s64 	%rd15, %rd13, %rd14;
	st.global.u32 	[%rd15], %r11;

BB7_6:
	ret;
}

.entry _Z26permute_particles_zion_ph1P19gtc_particle_data_tS0_Pii(
	.param .u64 _Z26permute_particles_zion_ph1P19gtc_particle_data_tS0_Pii_param_0,
	.param .u64 _Z26permute_particles_zion_ph1P19gtc_particle_data_tS0_Pii_param_1,
	.param .u64 _Z26permute_particles_zion_ph1P19gtc_particle_data_tS0_Pii_param_2,
	.param .u32 _Z26permute_particles_zion_ph1P19gtc_particle_data_tS0_Pii_param_3
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<8>;
	.reg .f64 	%fd<21>;
	.reg .b64 	%rd<55>;


	ld.param.u64 	%rd5, [_Z26permute_particles_zion_ph1P19gtc_particle_data_tS0_Pii_param_0];
	ld.param.u64 	%rd6, [_Z26permute_particles_zion_ph1P19gtc_particle_data_tS0_Pii_param_1];
	ld.param.u64 	%rd7, [_Z26permute_particles_zion_ph1P19gtc_particle_data_tS0_Pii_param_2];
	ld.param.u32 	%r2, [_Z26permute_particles_zion_ph1P19gtc_particle_data_tS0_Pii_param_3];
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r4, %ctaid.x;
	mov.u32 	%r5, %tid.x;
	mad.lo.s32 	%r1, %r3, %r4, %r5;
	ld.global.u32 	%r6, [params];
	setp.ge.s32	%p1, %r1, %r6;
	@%p1 bra 	BB8_3;

	cvta.to.global.u64 	%rd4, %rd6;
	cvta.to.global.u64 	%rd3, %rd5;
	cvta.to.global.u64 	%rd18, %rd7;
	cvt.s64.s32	%rd1, %r1;
	mul.wide.s32 	%rd19, %r1, 4;
	add.s64 	%rd20, %rd18, %rd19;
	ld.global.u32 	%r7, [%rd20];
	cvt.s64.s32	%rd2, %r7;
	ld.global.u64 	%rd21, [%rd3];
	mul.wide.s32 	%rd22, %r7, 8;
	add.s64 	%rd8, %rd21, %rd22;
	// inline asm
	ld.global.ca.nc.f64 %fd1, [%rd8];
	// inline asm
	ld.global.u64 	%rd23, [%rd3+8];
	add.s64 	%rd9, %rd23, %rd22;
	// inline asm
	ld.global.ca.nc.f64 %fd2, [%rd9];
	// inline asm
	ld.global.u64 	%rd24, [%rd3+16];
	add.s64 	%rd10, %rd24, %rd22;
	// inline asm
	ld.global.ca.nc.f64 %fd3, [%rd10];
	// inline asm
	ld.global.u64 	%rd25, [%rd3+24];
	add.s64 	%rd11, %rd25, %rd22;
	// inline asm
	ld.global.ca.nc.f64 %fd4, [%rd11];
	// inline asm
	ld.global.u64 	%rd26, [%rd3+32];
	add.s64 	%rd12, %rd26, %rd22;
	// inline asm
	ld.global.ca.nc.f64 %fd5, [%rd12];
	// inline asm
	ld.global.u64 	%rd27, [%rd4];
	mul.wide.s32 	%rd28, %r1, 8;
	add.s64 	%rd13, %rd27, %rd28;
	// inline asm
	st.global.cs.f64 [%rd13], %fd1;
	// inline asm
	ld.global.u64 	%rd29, [%rd4+8];
	add.s64 	%rd14, %rd29, %rd28;
	// inline asm
	st.global.cs.f64 [%rd14], %fd2;
	// inline asm
	ld.global.u64 	%rd30, [%rd4+16];
	add.s64 	%rd15, %rd30, %rd28;
	// inline asm
	st.global.cs.f64 [%rd15], %fd3;
	// inline asm
	ld.global.u64 	%rd31, [%rd4+24];
	add.s64 	%rd16, %rd31, %rd28;
	// inline asm
	st.global.cs.f64 [%rd16], %fd4;
	// inline asm
	ld.global.u64 	%rd32, [%rd4+32];
	add.s64 	%rd17, %rd32, %rd28;
	// inline asm
	st.global.cs.f64 [%rd17], %fd5;
	// inline asm
	setp.ne.s32	%p2, %r2, 1;
	@%p2 bra 	BB8_3;

	ld.global.u64 	%rd43, [%rd3+48];
	shl.b64 	%rd44, %rd2, 3;
	add.s64 	%rd33, %rd43, %rd44;
	// inline asm
	ld.global.ca.nc.f64 %fd11, [%rd33];
	// inline asm
	ld.global.u64 	%rd45, [%rd3+56];
	add.s64 	%rd34, %rd45, %rd44;
	// inline asm
	ld.global.ca.nc.f64 %fd12, [%rd34];
	// inline asm
	ld.global.u64 	%rd46, [%rd3+64];
	add.s64 	%rd35, %rd46, %rd44;
	// inline asm
	ld.global.ca.nc.f64 %fd13, [%rd35];
	// inline asm
	ld.global.u64 	%rd47, [%rd3+72];
	add.s64 	%rd36, %rd47, %rd44;
	// inline asm
	ld.global.ca.nc.f64 %fd14, [%rd36];
	// inline asm
	ld.global.u64 	%rd48, [%rd3+80];
	add.s64 	%rd37, %rd48, %rd44;
	// inline asm
	ld.global.ca.nc.f64 %fd15, [%rd37];
	// inline asm
	ld.global.u64 	%rd49, [%rd4+48];
	shl.b64 	%rd50, %rd1, 3;
	add.s64 	%rd38, %rd49, %rd50;
	// inline asm
	st.global.cs.f64 [%rd38], %fd11;
	// inline asm
	ld.global.u64 	%rd51, [%rd4+56];
	add.s64 	%rd39, %rd51, %rd50;
	// inline asm
	st.global.cs.f64 [%rd39], %fd12;
	// inline asm
	ld.global.u64 	%rd52, [%rd4+64];
	add.s64 	%rd40, %rd52, %rd50;
	// inline asm
	st.global.cs.f64 [%rd40], %fd13;
	// inline asm
	ld.global.u64 	%rd53, [%rd4+72];
	add.s64 	%rd41, %rd53, %rd50;
	// inline asm
	st.global.cs.f64 [%rd41], %fd14;
	// inline asm
	ld.global.u64 	%rd54, [%rd4+80];
	add.s64 	%rd42, %rd54, %rd50;
	// inline asm
	st.global.cs.f64 [%rd42], %fd15;
	// inline asm

BB8_3:
	ret;
}

.entry _Z26permute_particles_zion_ph2P19gtc_particle_data_tS0_PiS1_(
	.param .u64 _Z26permute_particles_zion_ph2P19gtc_particle_data_tS0_PiS1__param_0,
	.param .u64 _Z26permute_particles_zion_ph2P19gtc_particle_data_tS0_PiS1__param_1,
	.param .u64 _Z26permute_particles_zion_ph2P19gtc_particle_data_tS0_PiS1__param_2,
	.param .u64 _Z26permute_particles_zion_ph2P19gtc_particle_data_tS0_PiS1__param_3
)
{
	.reg .pred 	%p<9>;
	.reg .b32 	%r<11>;
	.reg .f64 	%fd<5>;
	.reg .b64 	%rd<27>;


	ld.param.u64 	%rd5, [_Z26permute_particles_zion_ph2P19gtc_particle_data_tS0_PiS1__param_0];
	ld.param.u64 	%rd6, [_Z26permute_particles_zion_ph2P19gtc_particle_data_tS0_PiS1__param_1];
	ld.param.u64 	%rd7, [_Z26permute_particles_zion_ph2P19gtc_particle_data_tS0_PiS1__param_2];
	ld.param.u64 	%rd8, [_Z26permute_particles_zion_ph2P19gtc_particle_data_tS0_PiS1__param_3];
	cvta.to.global.u64 	%rd26, %rd8;
	mov.u32 	%r5, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r1, %r5, %r6, %r7;
	ld.global.u32 	%r8, [params];
	setp.ge.s32	%p1, %r1, %r8;
	@%p1 bra 	BB9_8;

	cvta.to.global.u64 	%rd9, %rd7;
	cvt.s64.s32	%rd2, %r1;
	mul.wide.s32 	%rd10, %r1, 4;
	add.s64 	%rd11, %rd9, %rd10;
	ld.global.u32 	%r2, [%rd11];
	add.s64 	%rd12, %rd26, %rd10;
	ld.global.u32 	%r3, [%rd12];
	setp.lt.s32	%p2, %r1, 1;
	@%p2 bra 	BB9_3;

	add.s32 	%r9, %r1, -1;
	mul.wide.s32 	%rd13, %r9, 4;
	add.s64 	%rd26, %rd26, %rd13;

BB9_3:
	and.b32  	%r10, %r3, -268435456;
	setp.eq.s32	%p3, %r10, 268435456;
	ld.global.u32 	%r4, [%rd26];
	setp.lt.s32	%p4, %r4, 268435456;
	and.pred  	%p5, %p3, %p4;
	@!%p5 bra 	BB9_5;
	bra.uni 	BB9_4;

BB9_4:
	st.global.u32 	[d_start_shift+4], %r1;

BB9_5:
	setp.gt.s32	%p6, %r3, 536870911;
	setp.lt.s32	%p7, %r4, 536870912;
	and.pred  	%p8, %p6, %p7;
	@!%p8 bra 	BB9_7;
	bra.uni 	BB9_6;

BB9_6:
	st.global.u32 	[d_start_shift+8], %r1;

BB9_7:
	cvta.to.global.u64 	%rd18, %rd6;
	cvta.to.global.u64 	%rd19, %rd5;
	ld.global.u64 	%rd20, [%rd19+40];
	mul.wide.s32 	%rd21, %r2, 8;
	add.s64 	%rd14, %rd20, %rd21;
	// inline asm
	ld.global.ca.nc.f64 %fd1, [%rd14];
	// inline asm
	ld.global.u64 	%rd22, [%rd19+88];
	add.s64 	%rd15, %rd22, %rd21;
	// inline asm
	ld.global.ca.nc.f64 %fd2, [%rd15];
	// inline asm
	ld.global.u64 	%rd23, [%rd18+40];
	shl.b64 	%rd24, %rd2, 3;
	add.s64 	%rd16, %rd23, %rd24;
	// inline asm
	st.global.cs.f64 [%rd16], %fd1;
	// inline asm
	ld.global.u64 	%rd25, [%rd18+88];
	add.s64 	%rd17, %rd25, %rd24;
	// inline asm
	st.global.cs.f64 [%rd17], %fd2;
	// inline asm

BB9_8:
	ret;
}

.entry _Z32permute_particles_zion_shift_ph2P19gtc_particle_data_tS0_PiS1_(
	.param .u64 _Z32permute_particles_zion_shift_ph2P19gtc_particle_data_tS0_PiS1__param_0,
	.param .u64 _Z32permute_particles_zion_shift_ph2P19gtc_particle_data_tS0_PiS1__param_1,
	.param .u64 _Z32permute_particles_zion_shift_ph2P19gtc_particle_data_tS0_PiS1__param_2,
	.param .u64 _Z32permute_particles_zion_shift_ph2P19gtc_particle_data_tS0_PiS1__param_3
)
{
	.reg .pred 	%p<9>;
	.reg .b32 	%r<10>;
	.reg .f64 	%fd<5>;
	.reg .b64 	%rd<27>;


	ld.param.u64 	%rd5, [_Z32permute_particles_zion_shift_ph2P19gtc_particle_data_tS0_PiS1__param_0];
	ld.param.u64 	%rd6, [_Z32permute_particles_zion_shift_ph2P19gtc_particle_data_tS0_PiS1__param_1];
	ld.param.u64 	%rd7, [_Z32permute_particles_zion_shift_ph2P19gtc_particle_data_tS0_PiS1__param_2];
	ld.param.u64 	%rd8, [_Z32permute_particles_zion_shift_ph2P19gtc_particle_data_tS0_PiS1__param_3];
	cvta.to.global.u64 	%rd26, %rd8;
	mov.u32 	%r5, %ntid.x;
	mov.u32 	%r6, %ctaid.x;
	mov.u32 	%r7, %tid.x;
	mad.lo.s32 	%r1, %r5, %r6, %r7;
	ld.global.u32 	%r8, [params];
	setp.ge.s32	%p1, %r1, %r8;
	@%p1 bra 	BB10_8;

	cvta.to.global.u64 	%rd9, %rd7;
	cvt.s64.s32	%rd2, %r1;
	mul.wide.s32 	%rd10, %r1, 4;
	add.s64 	%rd11, %rd9, %rd10;
	ld.global.u32 	%r2, [%rd11];
	add.s64 	%rd12, %rd26, %rd10;
	ld.global.u32 	%r3, [%rd12];
	setp.lt.s32	%p2, %r1, 1;
	@%p2 bra 	BB10_3;

	add.s32 	%r9, %r1, -1;
	mul.wide.s32 	%rd13, %r9, 4;
	add.s64 	%rd26, %rd26, %rd13;

BB10_3:
	ld.global.u32 	%r4, [%rd26];
	setp.eq.s32	%p3, %r4, 0;
	setp.eq.s32	%p4, %r3, 1;
	and.pred  	%p5, %p4, %p3;
	@!%p5 bra 	BB10_5;
	bra.uni 	BB10_4;

BB10_4:
	st.global.u32 	[d_start_shift+4], %r1;

BB10_5:
	setp.eq.s32	%p6, %r3, 2;
	setp.lt.u32	%p7, %r4, 2;
	and.pred  	%p8, %p6, %p7;
	@!%p8 bra 	BB10_7;
	bra.uni 	BB10_6;

BB10_6:
	st.global.u32 	[d_start_shift+8], %r1;

BB10_7:
	cvta.to.global.u64 	%rd18, %rd6;
	cvta.to.global.u64 	%rd19, %rd5;
	ld.global.u64 	%rd20, [%rd19+40];
	mul.wide.s32 	%rd21, %r2, 8;
	add.s64 	%rd14, %rd20, %rd21;
	// inline asm
	ld.global.ca.nc.f64 %fd1, [%rd14];
	// inline asm
	ld.global.u64 	%rd22, [%rd19+88];
	add.s64 	%rd15, %rd22, %rd21;
	// inline asm
	ld.global.ca.nc.f64 %fd2, [%rd15];
	// inline asm
	ld.global.u64 	%rd23, [%rd18+40];
	shl.b64 	%rd24, %rd2, 3;
	add.s64 	%rd16, %rd23, %rd24;
	// inline asm
	st.global.cs.f64 [%rd16], %fd1;
	// inline asm
	ld.global.u64 	%rd25, [%rd18+88];
	add.s64 	%rd17, %rd25, %rd24;
	// inline asm
	st.global.cs.f64 [%rd17], %fd2;
	// inline asm

BB10_8:
	ret;
}

.entry _Z24update_particle_zion_ph1P19gtc_particle_data_tS0_i(
	.param .u64 _Z24update_particle_zion_ph1P19gtc_particle_data_tS0_i_param_0,
	.param .u64 _Z24update_particle_zion_ph1P19gtc_particle_data_tS0_i_param_1,
	.param .u32 _Z24update_particle_zion_ph1P19gtc_particle_data_tS0_i_param_2
)
{
	.reg .pred 	%p<3>;
	.reg .b32 	%r<7>;
	.reg .f64 	%fd<11>;
	.reg .b64 	%rd<68>;


	ld.param.u64 	%rd4, [_Z24update_particle_zion_ph1P19gtc_particle_data_tS0_i_param_0];
	ld.param.u64 	%rd5, [_Z24update_particle_zion_ph1P19gtc_particle_data_tS0_i_param_1];
	ld.param.u32 	%r2, [_Z24update_particle_zion_ph1P19gtc_particle_data_tS0_i_param_2];
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r4, %ctaid.x;
	mov.u32 	%r5, %tid.x;
	mad.lo.s32 	%r1, %r3, %r4, %r5;
	ld.global.u32 	%r6, [params];
	setp.ge.s32	%p1, %r1, %r6;
	@%p1 bra 	BB11_3;

	cvta.to.global.u64 	%rd3, %rd4;
	cvta.to.global.u64 	%rd1, %rd5;
	ld.global.u64 	%rd6, [%rd1];
	cvta.to.global.u64 	%rd7, %rd6;
	cvt.s64.s32	%rd2, %r1;
	mul.wide.s32 	%rd8, %r1, 8;
	add.s64 	%rd9, %rd7, %rd8;
	ld.global.f64 	%fd1, [%rd9];
	ld.global.u64 	%rd10, [%rd3];
	cvta.to.global.u64 	%rd11, %rd10;
	add.s64 	%rd12, %rd11, %rd8;
	st.global.f64 	[%rd12], %fd1;
	ld.global.u64 	%rd13, [%rd1+8];
	cvta.to.global.u64 	%rd14, %rd13;
	add.s64 	%rd15, %rd14, %rd8;
	ld.global.f64 	%fd2, [%rd15];
	ld.global.u64 	%rd16, [%rd3+8];
	cvta.to.global.u64 	%rd17, %rd16;
	add.s64 	%rd18, %rd17, %rd8;
	st.global.f64 	[%rd18], %fd2;
	ld.global.u64 	%rd19, [%rd1+16];
	cvta.to.global.u64 	%rd20, %rd19;
	add.s64 	%rd21, %rd20, %rd8;
	ld.global.f64 	%fd3, [%rd21];
	ld.global.u64 	%rd22, [%rd3+16];
	cvta.to.global.u64 	%rd23, %rd22;
	add.s64 	%rd24, %rd23, %rd8;
	st.global.f64 	[%rd24], %fd3;
	ld.global.u64 	%rd25, [%rd1+24];
	cvta.to.global.u64 	%rd26, %rd25;
	add.s64 	%rd27, %rd26, %rd8;
	ld.global.f64 	%fd4, [%rd27];
	ld.global.u64 	%rd28, [%rd3+24];
	cvta.to.global.u64 	%rd29, %rd28;
	add.s64 	%rd30, %rd29, %rd8;
	st.global.f64 	[%rd30], %fd4;
	ld.global.u64 	%rd31, [%rd1+32];
	cvta.to.global.u64 	%rd32, %rd31;
	add.s64 	%rd33, %rd32, %rd8;
	ld.global.f64 	%fd5, [%rd33];
	ld.global.u64 	%rd34, [%rd3+32];
	cvta.to.global.u64 	%rd35, %rd34;
	add.s64 	%rd36, %rd35, %rd8;
	st.global.f64 	[%rd36], %fd5;
	setp.ne.s32	%p2, %r2, 1;
	@%p2 bra 	BB11_3;

	ld.global.u64 	%rd37, [%rd1+48];
	cvta.to.global.u64 	%rd38, %rd37;
	shl.b64 	%rd39, %rd2, 3;
	add.s64 	%rd40, %rd38, %rd39;
	ld.global.f64 	%fd6, [%rd40];
	ld.global.u64 	%rd41, [%rd3+48];
	cvta.to.global.u64 	%rd42, %rd41;
	add.s64 	%rd43, %rd42, %rd39;
	st.global.f64 	[%rd43], %fd6;
	ld.global.u64 	%rd44, [%rd1+56];
	cvta.to.global.u64 	%rd45, %rd44;
	add.s64 	%rd46, %rd45, %rd39;
	ld.global.f64 	%fd7, [%rd46];
	ld.global.u64 	%rd47, [%rd3+56];
	cvta.to.global.u64 	%rd48, %rd47;
	add.s64 	%rd49, %rd48, %rd39;
	st.global.f64 	[%rd49], %fd7;
	ld.global.u64 	%rd50, [%rd1+64];
	cvta.to.global.u64 	%rd51, %rd50;
	add.s64 	%rd52, %rd51, %rd39;
	ld.global.f64 	%fd8, [%rd52];
	ld.global.u64 	%rd53, [%rd3+64];
	cvta.to.global.u64 	%rd54, %rd53;
	add.s64 	%rd55, %rd54, %rd39;
	st.global.f64 	[%rd55], %fd8;
	ld.global.u64 	%rd56, [%rd1+72];
	cvta.to.global.u64 	%rd57, %rd56;
	add.s64 	%rd58, %rd57, %rd39;
	ld.global.f64 	%fd9, [%rd58];
	ld.global.u64 	%rd59, [%rd3+72];
	cvta.to.global.u64 	%rd60, %rd59;
	add.s64 	%rd61, %rd60, %rd39;
	st.global.f64 	[%rd61], %fd9;
	ld.global.u64 	%rd62, [%rd1+80];
	cvta.to.global.u64 	%rd63, %rd62;
	add.s64 	%rd64, %rd63, %rd39;
	ld.global.f64 	%fd10, [%rd64];
	ld.global.u64 	%rd65, [%rd3+80];
	cvta.to.global.u64 	%rd66, %rd65;
	add.s64 	%rd67, %rd66, %rd39;
	st.global.f64 	[%rd67], %fd10;

BB11_3:
	ret;
}

.entry _Z24update_particle_zion_ph2P19gtc_particle_data_tS0_(
	.param .u64 _Z24update_particle_zion_ph2P19gtc_particle_data_tS0__param_0,
	.param .u64 _Z24update_particle_zion_ph2P19gtc_particle_data_tS0__param_1
)
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<6>;
	.reg .f64 	%fd<3>;
	.reg .b64 	%rd<18>;


	ld.param.u64 	%rd1, [_Z24update_particle_zion_ph2P19gtc_particle_data_tS0__param_0];
	ld.param.u64 	%rd2, [_Z24update_particle_zion_ph2P19gtc_particle_data_tS0__param_1];
	mov.u32 	%r2, %ntid.x;
	mov.u32 	%r3, %ctaid.x;
	mov.u32 	%r4, %tid.x;
	mad.lo.s32 	%r1, %r2, %r3, %r4;
	ld.global.u32 	%r5, [params];
	setp.ge.s32	%p1, %r1, %r5;
	@%p1 bra 	BB12_2;

	cvta.to.global.u64 	%rd3, %rd1;
	cvta.to.global.u64 	%rd4, %rd2;
	ld.global.u64 	%rd5, [%rd4+40];
	cvta.to.global.u64 	%rd6, %rd5;
	mul.wide.s32 	%rd7, %r1, 8;
	add.s64 	%rd8, %rd6, %rd7;
	ld.global.f64 	%fd1, [%rd8];
	ld.global.u64 	%rd9, [%rd3+40];
	cvta.to.global.u64 	%rd10, %rd9;
	add.s64 	%rd11, %rd10, %rd7;
	st.global.f64 	[%rd11], %fd1;
	ld.global.u64 	%rd12, [%rd4+88];
	cvta.to.global.u64 	%rd13, %rd12;
	add.s64 	%rd14, %rd13, %rd7;
	ld.global.f64 	%fd2, [%rd14];
	ld.global.u64 	%rd15, [%rd3+88];
	cvta.to.global.u64 	%rd16, %rd15;
	add.s64 	%rd17, %rd16, %rd7;
	st.global.f64 	[%rd17], %fd2;

BB12_2:
	ret;
}

.entry _Z16gpu_pushi_kernelP19gtc_particle_data_tP23gtc_aux_particle_data_tP16gtc_field_data_tP20gtc_diagnosis_data_tiii(
	.param .u64 _Z16gpu_pushi_kernelP19gtc_particle_data_tP23gtc_aux_particle_data_tP16gtc_field_data_tP20gtc_diagnosis_data_tiii_param_0,
	.param .u64 _Z16gpu_pushi_kernelP19gtc_particle_data_tP23gtc_aux_particle_data_tP16gtc_field_data_tP20gtc_diagnosis_data_tiii_param_1,
	.param .u64 _Z16gpu_pushi_kernelP19gtc_particle_data_tP23gtc_aux_particle_data_tP16gtc_field_data_tP20gtc_diagnosis_data_tiii_param_2,
	.param .u64 _Z16gpu_pushi_kernelP19gtc_particle_data_tP23gtc_aux_particle_data_tP16gtc_field_data_tP20gtc_diagnosis_data_tiii_param_3,
	.param .u32 _Z16gpu_pushi_kernelP19gtc_particle_data_tP23gtc_aux_particle_data_tP16gtc_field_data_tP20gtc_diagnosis_data_tiii_param_4,
	.param .u32 _Z16gpu_pushi_kernelP19gtc_particle_data_tP23gtc_aux_particle_data_tP16gtc_field_data_tP20gtc_diagnosis_data_tiii_param_5,
	.param .u32 _Z16gpu_pushi_kernelP19gtc_particle_data_tP23gtc_aux_particle_data_tP16gtc_field_data_tP20gtc_diagnosis_data_tiii_param_6
)
.maxntid 64, 1, 1
.minnctapersm 1
{
	.local .align 8 .b8 	__local_depot13[40];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<54>;
	.reg .f32 	%f<3>;
	.reg .b32 	%r<271>;
	.reg .f64 	%fd<695>;
	.reg .b64 	%rd<324>;


	mov.u64 	%rd323, __local_depot13;
	cvta.local.u64 	%SP, %rd323;
	ld.param.u64 	%rd53, [_Z16gpu_pushi_kernelP19gtc_particle_data_tP23gtc_aux_particle_data_tP16gtc_field_data_tP20gtc_diagnosis_data_tiii_param_0];
	ld.param.u64 	%rd54, [_Z16gpu_pushi_kernelP19gtc_particle_data_tP23gtc_aux_particle_data_tP16gtc_field_data_tP20gtc_diagnosis_data_tiii_param_2];
	ld.param.u64 	%rd55, [_Z16gpu_pushi_kernelP19gtc_particle_data_tP23gtc_aux_particle_data_tP16gtc_field_data_tP20gtc_diagnosis_data_tiii_param_3];
	ld.param.u32 	%r35, [_Z16gpu_pushi_kernelP19gtc_particle_data_tP23gtc_aux_particle_data_tP16gtc_field_data_tP20gtc_diagnosis_data_tiii_param_4];
	ld.param.u32 	%r36, [_Z16gpu_pushi_kernelP19gtc_particle_data_tP23gtc_aux_particle_data_tP16gtc_field_data_tP20gtc_diagnosis_data_tiii_param_6];
	mov.u32 	%r1, %ntid.x;
	mov.u32 	%r37, %ctaid.x;
	mov.u32 	%r2, %tid.x;
	mad.lo.s32 	%r266, %r1, %r37, %r2;
	mul.lo.s32 	%r4, %r1, 7;
	setp.ne.s32	%p2, %r36, 0;
	@%p2 bra 	BB13_8;

	setp.ge.s32	%p3, %r2, %r4;
	@%p3 bra 	BB13_4;

	mov.u32 	%r265, %r2;

BB13_3:
	mov.u32 	%r5, %r265;
	mul.wide.s32 	%rd56, %r5, 8;
	mov.u64 	%rd57, shared_buffer_gyro;
	add.s64 	%rd58, %rd56, %rd57;
	mov.u64 	%rd59, 0;
	st.shared.u64 	[%rd58+40], %rd59;
	add.s32 	%r6, %r5, %r1;
	setp.lt.s32	%p4, %r6, %r4;
	mov.u32 	%r265, %r6;
	@%p4 bra 	BB13_3;

BB13_4:
	cvt.s64.s32	%rd1, %r4;
	mul.lo.s32 	%r7, %r1, 20;
	setp.ge.s32	%p5, %r2, %r7;
	@%p5 bra 	BB13_7;

	mov.u32 	%r264, %r2;

BB13_6:
	cvt.s64.s32	%rd60, %r264;
	add.s64 	%rd61, %rd1, %rd60;
	shl.b64 	%rd62, %rd61, 3;
	mov.u64 	%rd63, shared_buffer_gyro;
	add.s64 	%rd64, %rd62, %rd63;
	mov.u64 	%rd65, 0;
	st.shared.u64 	[%rd64+40], %rd65;
	add.s32 	%r264, %r264, %r1;
	setp.lt.s32	%p6, %r264, %r7;
	@%p6 bra 	BB13_6;

BB13_7:
	bar.sync 	0;

BB13_8:
	cvta.to.global.u64 	%rd4, %rd53;
	cvta.to.global.u64 	%rd66, %rd55;
	ld.global.v4.u32 	{%r38, %r39, %r40, %r41}, [params];
	ld.global.f64 	%fd1, [params+480];
	ld.global.f64 	%fd123, [params+248];
	add.f64 	%fd2, %fd123, %fd123;
	ld.global.f64 	%fd3, [params+496];
	ld.global.f64 	%fd4, [params+256];
	ld.global.f64 	%fd5, [params+184];
	ld.global.nc.u64 	%rd3, [%rd66+72];
	ld.global.u32 	%r12, [radial_decomp+24];
	ld.global.f64 	%fd6, [radial_decomp+96];
	ld.global.nc.u64 	%rd5, [%rd4];
	ld.global.nc.u64 	%rd6, [%rd4+8];
	ld.global.nc.u64 	%rd7, [%rd4+16];
	ld.global.nc.u64 	%rd8, [%rd4+24];
	ld.global.nc.u64 	%rd9, [%rd4+32];
	ld.global.nc.u64 	%rd10, [%rd4+48];
	ld.global.nc.u64 	%rd11, [%rd4+56];
	ld.global.nc.u64 	%rd12, [%rd4+64];
	ld.global.nc.u64 	%rd13, [%rd4+72];
	ld.global.nc.u64 	%rd14, [%rd4+80];
	ld.global.f64 	%fd7, [params+208];
	ld.global.f64 	%fd8, [params+408];
	ld.global.f64 	%fd9, [params+328];
	ld.global.f64 	%fd10, [params+200];
	cvt.s64.s32	%rd15, %r2;
	setp.ge.s32	%p7, %r266, %r38;
	@%p7 bra 	BB13_55;

	cvta.to.global.u64 	%rd67, %rd54;
	ld.global.f64 	%fd11, [params+192];
	ld.global.nc.u64 	%rd16, [%rd4+40];
	ld.global.nc.u64 	%rd17, [%rd4+88];
	ld.global.u32 	%r42, [params+100];
	setp.eq.s32	%p8, %r42, 0;
	selp.f64	%fd12, 0d0000000000000000, 0d3FF0000000000000, %p8;
	mul.f64 	%fd125, %fd7, 0d3FE0000000000000;
	mul.f64 	%fd126, %fd7, %fd125;
	ld.global.f64 	%fd127, [params+424];
	div.rn.f64 	%fd13, %fd8, %fd127;
	rcp.rn.f64 	%fd14, %fd8;
	abs.f64 	%fd128, %fd8;
	mul.f64 	%fd129, %fd9, %fd128;
	div.rn.f64 	%fd130, %fd129, %fd127;
	sub.f64 	%fd131, %fd7, %fd10;
	mov.f64 	%fd132, 0d4014000000000000;
	div.rn.f64 	%fd15, %fd132, %fd131;
	mul.f64 	%fd16, %fd4, 0d3FE0000000000000;
	ld.global.f64 	%fd133, [params+216];
	rcp.rn.f64 	%fd17, %fd133;
	mul.f64 	%fd18, %fd127, 0d3FE0000000000000;
	mul.f64 	%fd19, %fd126, 0d3E45798EE2308C3A;
	mul.f64 	%fd134, %fd127, 0d3FF8000000000000;
	mul.f64 	%fd135, %fd134, %fd130;
	mul.f64 	%fd20, %fd130, %fd135;
	ld.global.nc.u64 	%rd68, [%rd67+184];
	shl.b64 	%rd69, %rd15, 3;
	add.s64 	%rd18, %rd68, %rd69;

BB13_10:
	mov.f64 	%fd22, %fd691;
	mov.f64 	%fd25, %fd673;
	mov.f64 	%fd24, %fd663;
	mov.f64 	%fd23, %fd653;
	mov.f64 	%fd21, %fd643;
	setp.eq.s32	%p9, %r35, 1;
	@%p9 bra 	BB13_17;
	bra.uni 	BB13_11;

BB13_17:
	setp.gt.s32	%p13, %r2, 4;
	@%p13 bra 	BB13_19;

	mul.wide.s32 	%rd80, %r2, 8;
	mov.u64 	%rd81, shared_buffer_gyro;
	add.s64 	%rd82, %rd81, %rd80;
	mov.u64 	%rd83, 0;
	st.shared.u64 	[%rd82], %rd83;

BB13_19:
	mul.wide.s32 	%rd94, %r266, 8;
	add.s64 	%rd84, %rd5, %rd94;
	// inline asm
	ld.global.cs.f64 %fd642, [%rd84];
	// inline asm
	add.s64 	%rd85, %rd6, %rd94;
	// inline asm
	ld.global.cs.f64 %fd690, [%rd85];
	// inline asm
	add.s64 	%rd86, %rd7, %rd94;
	// inline asm
	ld.global.cs.f64 %fd652, [%rd86];
	// inline asm
	add.s64 	%rd87, %rd8, %rd94;
	// inline asm
	ld.global.cs.f64 %fd662, [%rd87];
	// inline asm
	add.s64 	%rd88, %rd9, %rd94;
	// inline asm
	ld.global.cs.f64 %fd672, [%rd88];
	// inline asm
	add.s64 	%rd89, %rd10, %rd94;
	// inline asm
	st.global.cs.f64 [%rd89], %fd642;
	// inline asm
	add.s64 	%rd90, %rd11, %rd94;
	// inline asm
	st.global.cs.f64 [%rd90], %fd690;
	// inline asm
	add.s64 	%rd91, %rd12, %rd94;
	// inline asm
	st.global.cs.f64 [%rd91], %fd652;
	// inline asm
	add.s64 	%rd92, %rd13, %rd94;
	// inline asm
	st.global.cs.f64 [%rd92], %fd662;
	// inline asm
	add.s64 	%rd93, %rd14, %rd94;
	// inline asm
	st.global.cs.f64 [%rd93], %fd672;
	// inline asm
	mov.f64 	%fd628, %fd16;
	bra.uni 	BB13_20;

BB13_11:
	setp.lt.f64	%p10, %fd5, 0d3FE0000000000000;
	@%p10 bra 	BB13_14;
	bra.uni 	BB13_12;

BB13_14:
	mov.u64 	%rd73, $str1;
	cvta.global.u64 	%rd74, %rd73;
	mov.u64 	%rd75, 0;
	// Callseq Start 26
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd74;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd75;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r43, [retval0+0];
	
	//{
	}// Callseq End 26
	setp.gt.s32	%p12, %r2, 4;
	mov.f64 	%fd626, %fd4;
	mov.f64 	%fd628, %fd626;
	mov.f64 	%fd636, %fd21;
	mov.f64 	%fd642, %fd636;
	mov.f64 	%fd646, %fd23;
	mov.f64 	%fd652, %fd646;
	mov.f64 	%fd656, %fd24;
	mov.f64 	%fd662, %fd656;
	mov.f64 	%fd666, %fd25;
	mov.f64 	%fd672, %fd666;
	mov.f64 	%fd678, %fd22;
	mov.f64 	%fd690, %fd678;
	@%p12 bra 	BB13_20;

	mul.wide.s32 	%rd76, %r2, 8;
	mov.u64 	%rd77, shared_buffer_gyro;
	add.s64 	%rd78, %rd77, %rd76;
	st.shared.u64 	[%rd78], %rd75;
	mov.f64 	%fd627, %fd4;
	mov.f64 	%fd628, %fd627;
	bra.uni 	BB13_16;

BB13_12:
	setp.gt.s32	%p11, %r2, 4;
	mov.f64 	%fd628, %fd4;
	mov.f64 	%fd642, %fd21;
	mov.f64 	%fd652, %fd23;
	mov.f64 	%fd662, %fd24;
	mov.f64 	%fd672, %fd25;
	mov.f64 	%fd690, %fd22;
	@%p11 bra 	BB13_20;

	ld.f64 	%fd136, [%rd18];
	mul.wide.s32 	%rd70, %r2, 8;
	mov.u64 	%rd71, shared_buffer_gyro;
	add.s64 	%rd72, %rd71, %rd70;
	st.shared.f64 	[%rd72], %fd136;
	mov.f64 	%fd625, %fd4;
	mov.f64 	%fd628, %fd625;

BB13_16:
	mov.f64 	%fd642, %fd21;
	mov.f64 	%fd652, %fd23;
	mov.f64 	%fd662, %fd24;
	mov.f64 	%fd672, %fd25;
	mov.f64 	%fd690, %fd22;

BB13_20:
	mov.f64 	%fd689, %fd690;
	mov.f64 	%fd671, %fd672;
	mov.f64 	%fd661, %fd662;
	mov.f64 	%fd651, %fd652;
	mov.f64 	%fd641, %fd642;
	mov.f64 	%fd36, %fd628;
	bar.sync 	0;
	@%p9 bra 	BB13_22;

	mul.wide.s32 	%rd100, %r266, 8;
	add.s64 	%rd95, %rd5, %rd100;
	// inline asm
	ld.global.cs.f64 %fd641, [%rd95];
	// inline asm
	add.s64 	%rd96, %rd6, %rd100;
	// inline asm
	ld.global.cs.f64 %fd689, [%rd96];
	// inline asm
	add.s64 	%rd97, %rd7, %rd100;
	// inline asm
	ld.global.cs.f64 %fd651, [%rd97];
	// inline asm
	add.s64 	%rd98, %rd8, %rd100;
	// inline asm
	ld.global.cs.f64 %fd661, [%rd98];
	// inline asm
	add.s64 	%rd99, %rd9, %rd100;
	// inline asm
	ld.global.cs.f64 %fd671, [%rd99];
	// inline asm

BB13_22:
	mov.f64 	%fd45, %fd689;
	mov.f64 	%fd42, %fd671;
	mov.f64 	%fd43, %fd661;
	mov.f64 	%fd650, %fd651;
	mov.f64 	%fd46, %fd641;
	mul.wide.s32 	%rd102, %r266, 8;
	add.s64 	%rd101, %rd16, %rd102;
	// inline asm
	ld.global.cs.f64 %fd152, [%rd101];
	// inline asm
	ld.global.f64 	%fd156, [params+472];
	mul.f64 	%fd629, %fd152, %fd156;
	sub.f64 	%fd49, %fd46, %fd10;
	mul.f64 	%fd50, %fd1, %fd49;
	add.f64 	%fd157, %fd50, 0d3FE0000000000000;
	cvt.rzi.s32.f64	%r45, %fd157;
	min.s32 	%r46, %r41, %r45;
	setp.gt.s32	%p15, %r46, 0;
	cvt.s64.s32	%rd104, %r46;
	selp.b64	%rd105, %rd104, 0, %p15;
	shl.b64 	%rd106, %rd105, 3;
	mov.u64 	%rd107, delt;
	add.s64 	%rd108, %rd107, %rd106;
	ld.const.f64 	%fd158, [%rd108];
	mul.f64 	%fd159, %fd3, %fd45;
	fma.rn.f64 	%fd160, %fd159, %fd158, 0d3FE0000000000000;
	cvt.rzi.s32.f64	%r47, %fd160;
	shl.b64 	%rd109, %rd105, 2;
	mov.u64 	%rd110, mtheta;
	add.s64 	%rd111, %rd110, %rd109;
	ld.const.u32 	%r48, [%rd111];
	min.s32 	%r49, %r48, %r47;
	mov.u32 	%r50, 0;
	max.s32 	%r51, %r49, %r50;
	ld.global.f64 	%fd161, [params+360];
	sub.f64 	%fd162, %fd650, %fd161;
	ld.global.f64 	%fd163, [params+488];
	mul.f64 	%fd51, %fd162, %fd163;
	mov.f64 	%fd164, 0d3FF0000000000000;
	mov.u64 	%rd112, igrid;
	add.s64 	%rd113, %rd112, %rd109;
	sub.s32 	%r52, %r51, %r12;
	ld.const.u32 	%r53, [%rd113];
	add.s32 	%r54, %r52, %r53;
	shl.b32 	%r55, %r54, 2;
	cvt.s64.s32	%rd114, %r55;
	neg.s64 	%rd322, %rd114;
	mov.f64 	%fd632, 0d0000000000000000;
	mov.f64 	%fd631, %fd632;
	mov.f64 	%fd630, %fd632;
	mov.u32 	%r267, -4;

BB13_23:
	ld.global.nc.u64 	%rd317, [%rd67+208];
	shl.b64 	%rd115, %rd322, 3;
	sub.s64 	%rd23, %rd317, %rd115;
	ld.f64 	%fd57, [%rd23];
	mul.f64 	%fd633, %fd629, %fd57;
	abs.f64 	%fd59, %fd633;
	setp.leu.f64	%p16, %fd59, %fd6;
	@%p16 bra 	BB13_25;

	add.u64 	%rd116, %SP, 8;
	cvta.to.local.u64 	%rd117, %rd116;
	st.local.f64 	[%rd117], %fd633;
	st.local.f64 	[%rd117+8], %fd629;
	st.local.f64 	[%rd117+16], %fd6;
	st.local.f64 	[%rd117+24], %fd57;
	mov.u64 	%rd118, $str2;
	cvta.global.u64 	%rd119, %rd118;
	// Callseq Start 27
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd119;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd116;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r56, [retval0+0];
	
	//{
	}// Callseq End 27
	div.rn.f64 	%fd165, %fd633, %fd59;
	mul.f64 	%fd633, %fd6, %fd165;
	ld.f64 	%fd166, [%rd23];
	div.rn.f64 	%fd167, %fd633, %fd166;
	st.local.f64 	[%rd117], %fd167;
	st.local.f64 	[%rd117+8], %fd629;
	mov.u64 	%rd120, $str3;
	cvta.global.u64 	%rd121, %rd120;
	// Callseq Start 28
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd121;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd116;
	.param .b32 retval0;
	call.uni (retval0), 
	vprintf, 
	(
	param0, 
	param1
	);
	ld.param.b32	%r57, [retval0+0];
	
	//{
	}// Callseq End 28
	ld.f64 	%fd168, [%rd23];
	div.rn.f64 	%fd629, %fd633, %fd168;

BB13_25:
	sub.f64 	%fd624, %fd164, %fd51;
	mov.u64 	%rd321, igrid;
	mov.u64 	%rd320, mtheta;
	mov.u64 	%rd319, delt;
	ld.global.nc.u64 	%rd318, [%rd67+216];
	add.f64 	%fd170, %fd49, %fd633;
	setp.lt.f64	%p17, %fd131, %fd170;
	selp.f64	%fd171, %fd131, %fd170, %p17;
	setp.gt.f64	%p18, %fd171, 0d0000000000000000;
	selp.f64	%fd172, %fd171, 0d0000000000000000, %p18;
	mul.f64 	%fd173, %fd1, %fd172;
	sub.s64 	%rd123, %rd318, %rd115;
	ld.f64 	%fd174, [%rd123];
	fma.rn.f64 	%fd175, %fd629, %fd174, %fd45;
	cvt.rzi.s32.f64	%r58, %fd173;
	setp.gt.s32	%p19, %r41, %r58;
	add.s32 	%r59, %r41, -1;
	selp.b32	%r60, %r58, %r59, %p19;
	max.s32 	%r62, %r60, %r50;
	mul.wide.s32 	%rd124, %r62, 8;
	mov.u64 	%rd125, qtinv;
	add.s64 	%rd126, %rd125, %rd124;
	ld.const.f64 	%fd176, [%rd126];
	mul.f64 	%fd177, %fd650, %fd176;
	sub.f64 	%fd178, %fd175, %fd177;
	fma.rn.f64 	%fd179, %fd3, %fd178, 0d4024000000000000;
	ld.const.f64 	%fd180, [%rd126+8];
	mul.f64 	%fd181, %fd650, %fd180;
	sub.f64 	%fd182, %fd175, %fd181;
	fma.rn.f64 	%fd183, %fd3, %fd182, 0d4024000000000000;
	cvt.rzi.s32.f64	%r63, %fd179;
	cvt.rn.f64.s32	%fd184, %r63;
	sub.f64 	%fd185, %fd179, %fd184;
	add.s64 	%rd128, %rd319, %rd124;
	ld.const.f64 	%fd186, [%rd128];
	mul.f64 	%fd187, %fd186, %fd185;
	cvt.rzi.s32.f64	%r64, %fd183;
	cvt.rn.f64.s32	%fd188, %r64;
	sub.f64 	%fd189, %fd183, %fd188;
	ld.const.f64 	%fd190, [%rd128+8];
	mul.f64 	%fd191, %fd190, %fd189;
	mul.wide.s32 	%rd129, %r62, 4;
	add.s64 	%rd131, %rd320, %rd129;
	ld.const.u32 	%r65, [%rd131];
	add.s32 	%r66, %r65, -1;
	cvt.rzi.s32.f64	%r67, %fd187;
	setp.gt.s32	%p20, %r65, %r67;
	selp.b32	%r68, %r67, %r66, %p20;
	max.s32 	%r69, %r68, %r50;
	ld.const.u32 	%r70, [%rd131+4];
	add.s32 	%r71, %r70, -1;
	cvt.rzi.s32.f64	%r72, %fd191;
	setp.gt.s32	%p21, %r70, %r72;
	selp.b32	%r73, %r72, %r71, %p21;
	max.s32 	%r74, %r73, %r50;
	add.s64 	%rd133, %rd321, %rd129;
	ld.const.u32 	%r75, [%rd133];
	sub.s32 	%r76, %r75, %r12;
	add.s32 	%r77, %r76, %r69;
	ld.const.u32 	%r78, [%rd133+4];
	sub.s32 	%r79, %r78, %r12;
	add.s32 	%r80, %r79, %r74;
	mul.lo.s32 	%r81, %r77, 6;
	mul.lo.s32 	%r82, %r80, 6;
	tex.1d.v4.s32.s32	{%r83, %r84, %r85, %r86}, [evectorTexRef, {%r81}];
	mov.b64 	%fd192, {%r83, %r84};
	add.s32 	%r87, %r81, 3;
	tex.1d.v4.s32.s32	{%r88, %r89, %r90, %r91}, [evectorTexRef, {%r87}];
	cvt.rn.f64.s32	%fd193, %r69;
	cvt.rn.f64.s32	%fd194, %r62;
	sub.f64 	%fd195, %fd187, %fd193;
	sub.f64 	%fd196, %fd173, %fd194;
	sub.f64 	%fd198, %fd164, %fd195;
	sub.f64 	%fd199, %fd164, %fd196;
	mul.f64 	%fd200, %fd199, %fd198;
	mov.b64 	%fd201, {%r88, %r89};
	mul.f64 	%fd202, %fd51, %fd201;
	fma.rn.f64 	%fd203, %fd624, %fd192, %fd202;
	fma.rn.f64 	%fd204, %fd200, %fd203, %fd632;
	add.s32 	%r92, %r81, 1;
	tex.1d.v4.s32.s32	{%r93, %r94, %r95, %r96}, [evectorTexRef, {%r92}];
	mov.b64 	%fd205, {%r93, %r94};
	add.s32 	%r97, %r81, 4;
	tex.1d.v4.s32.s32	{%r98, %r99, %r100, %r101}, [evectorTexRef, {%r97}];
	mov.b64 	%fd206, {%r98, %r99};
	mul.f64 	%fd207, %fd51, %fd206;
	fma.rn.f64 	%fd208, %fd624, %fd205, %fd207;
	fma.rn.f64 	%fd209, %fd200, %fd208, %fd631;
	add.s32 	%r102, %r81, 2;
	tex.1d.v4.s32.s32	{%r103, %r104, %r105, %r106}, [evectorTexRef, {%r102}];
	mov.b64 	%fd210, {%r103, %r104};
	add.s32 	%r107, %r81, 5;
	tex.1d.v4.s32.s32	{%r108, %r109, %r110, %r111}, [evectorTexRef, {%r107}];
	mov.b64 	%fd211, {%r108, %r109};
	mul.f64 	%fd212, %fd51, %fd211;
	fma.rn.f64 	%fd213, %fd624, %fd210, %fd212;
	fma.rn.f64 	%fd214, %fd200, %fd213, %fd630;
	mul.f64 	%fd215, %fd199, %fd195;
	add.s32 	%r112, %r81, 6;
	tex.1d.v4.s32.s32	{%r113, %r114, %r115, %r116}, [evectorTexRef, {%r112}];
	mov.b64 	%fd216, {%r113, %r114};
	add.s32 	%r117, %r81, 9;
	tex.1d.v4.s32.s32	{%r118, %r119, %r120, %r121}, [evectorTexRef, {%r117}];
	mov.b64 	%fd217, {%r118, %r119};
	mul.f64 	%fd218, %fd51, %fd217;
	fma.rn.f64 	%fd219, %fd624, %fd216, %fd218;
	fma.rn.f64 	%fd220, %fd215, %fd219, %fd204;
	add.s32 	%r122, %r81, 7;
	tex.1d.v4.s32.s32	{%r123, %r124, %r125, %r126}, [evectorTexRef, {%r122}];
	mov.b64 	%fd221, {%r123, %r124};
	add.s32 	%r127, %r81, 10;
	tex.1d.v4.s32.s32	{%r128, %r129, %r130, %r131}, [evectorTexRef, {%r127}];
	mov.b64 	%fd222, {%r128, %r129};
	mul.f64 	%fd223, %fd51, %fd222;
	fma.rn.f64 	%fd224, %fd624, %fd221, %fd223;
	fma.rn.f64 	%fd225, %fd215, %fd224, %fd209;
	add.s32 	%r132, %r81, 8;
	tex.1d.v4.s32.s32	{%r133, %r134, %r135, %r136}, [evectorTexRef, {%r132}];
	mov.b64 	%fd226, {%r133, %r134};
	add.s32 	%r137, %r81, 11;
	tex.1d.v4.s32.s32	{%r138, %r139, %r140, %r141}, [evectorTexRef, {%r137}];
	cvt.rn.f64.s32	%fd227, %r74;
	sub.f64 	%fd228, %fd191, %fd227;
	sub.f64 	%fd229, %fd164, %fd228;
	mov.b64 	%fd230, {%r138, %r139};
	mul.f64 	%fd231, %fd51, %fd230;
	fma.rn.f64 	%fd232, %fd624, %fd226, %fd231;
	fma.rn.f64 	%fd233, %fd215, %fd232, %fd214;
	mul.f64 	%fd234, %fd196, %fd229;
	tex.1d.v4.s32.s32	{%r142, %r143, %r144, %r145}, [evectorTexRef, {%r82}];
	mov.b64 	%fd235, {%r142, %r143};
	add.s32 	%r146, %r82, 3;
	tex.1d.v4.s32.s32	{%r147, %r148, %r149, %r150}, [evectorTexRef, {%r146}];
	mov.b64 	%fd236, {%r147, %r148};
	mul.f64 	%fd237, %fd51, %fd236;
	fma.rn.f64 	%fd238, %fd624, %fd235, %fd237;
	fma.rn.f64 	%fd239, %fd234, %fd238, %fd220;
	add.s32 	%r151, %r82, 1;
	tex.1d.v4.s32.s32	{%r152, %r153, %r154, %r155}, [evectorTexRef, {%r151}];
	mov.b64 	%fd240, {%r152, %r153};
	add.s32 	%r156, %r82, 4;
	tex.1d.v4.s32.s32	{%r157, %r158, %r159, %r160}, [evectorTexRef, {%r156}];
	mov.b64 	%fd241, {%r157, %r158};
	mul.f64 	%fd242, %fd51, %fd241;
	fma.rn.f64 	%fd243, %fd624, %fd240, %fd242;
	fma.rn.f64 	%fd244, %fd234, %fd243, %fd225;
	add.s32 	%r161, %r82, 2;
	tex.1d.v4.s32.s32	{%r162, %r163, %r164, %r165}, [evectorTexRef, {%r161}];
	mov.b64 	%fd245, {%r162, %r163};
	add.s32 	%r166, %r82, 5;
	tex.1d.v4.s32.s32	{%r167, %r168, %r169, %r170}, [evectorTexRef, {%r166}];
	mov.b64 	%fd246, {%r167, %r168};
	mul.f64 	%fd247, %fd51, %fd246;
	fma.rn.f64 	%fd248, %fd624, %fd245, %fd247;
	fma.rn.f64 	%fd249, %fd234, %fd248, %fd233;
	mul.f64 	%fd250, %fd196, %fd228;
	add.s32 	%r171, %r82, 6;
	tex.1d.v4.s32.s32	{%r172, %r173, %r174, %r175}, [evectorTexRef, {%r171}];
	mov.b64 	%fd251, {%r172, %r173};
	add.s32 	%r176, %r82, 9;
	tex.1d.v4.s32.s32	{%r177, %r178, %r179, %r180}, [evectorTexRef, {%r176}];
	mov.b64 	%fd252, {%r177, %r178};
	mul.f64 	%fd253, %fd51, %fd252;
	fma.rn.f64 	%fd254, %fd624, %fd251, %fd253;
	fma.rn.f64 	%fd632, %fd250, %fd254, %fd239;
	add.s32 	%r181, %r82, 7;
	tex.1d.v4.s32.s32	{%r182, %r183, %r184, %r185}, [evectorTexRef, {%r181}];
	mov.b64 	%fd255, {%r182, %r183};
	add.s32 	%r186, %r82, 10;
	tex.1d.v4.s32.s32	{%r187, %r188, %r189, %r190}, [evectorTexRef, {%r186}];
	mov.b64 	%fd256, {%r187, %r188};
	mul.f64 	%fd257, %fd51, %fd256;
	fma.rn.f64 	%fd258, %fd624, %fd255, %fd257;
	fma.rn.f64 	%fd631, %fd250, %fd258, %fd244;
	add.s32 	%r191, %r82, 8;
	tex.1d.v4.s32.s32	{%r192, %r193, %r194, %r195}, [evectorTexRef, {%r191}];
	mov.b64 	%fd259, {%r192, %r193};
	add.s32 	%r196, %r82, 11;
	tex.1d.v4.s32.s32	{%r197, %r198, %r199, %r200}, [evectorTexRef, {%r196}];
	mov.b64 	%fd260, {%r197, %r198};
	mul.f64 	%fd261, %fd51, %fd260;
	fma.rn.f64 	%fd262, %fd624, %fd259, %fd261;
	fma.rn.f64 	%fd630, %fd250, %fd262, %fd249;
	add.s64 	%rd322, %rd322, -1;
	add.s32 	%r267, %r267, 1;
	setp.ne.s32	%p22, %r267, 0;
	@%p22 bra 	BB13_23;

	mov.f64 	%fd640, %fd46;
	mov.f64 	%fd660, %fd43;
	mov.f64 	%fd670, %fd42;
	mov.f64 	%fd688, %fd45;
	@%p9 bra 	BB13_28;

	mul.wide.s32 	%rd315, %r266, 8;
	add.s64 	%rd135, %rd10, %rd315;
	// inline asm
	ld.global.cs.f64 %fd263, [%rd135];
	// inline asm
	add.s64 	%rd136, %rd11, %rd315;
	// inline asm
	ld.global.cs.f64 %fd264, [%rd136];
	// inline asm
	add.s64 	%rd137, %rd12, %rd315;
	// inline asm
	ld.global.cs.f64 %fd650, [%rd137];
	// inline asm
	add.s64 	%rd138, %rd13, %rd315;
	// inline asm
	ld.global.cs.f64 %fd266, [%rd138];
	// inline asm
	add.s64 	%rd139, %rd14, %rd315;
	// inline asm
	ld.global.cs.f64 %fd267, [%rd139];
	// inline asm
	mov.f64 	%fd640, %fd263;
	mov.f64 	%fd660, %fd266;
	mov.f64 	%fd670, %fd267;
	mov.f64 	%fd688, %fd264;

BB13_28:
	mov.f64 	%fd73, %fd688;
	mov.f64 	%fd76, %fd670;
	mov.f64 	%fd75, %fd660;
	mov.f64 	%fd72, %fd640;
	add.s32 	%r262, %r41, -1;
	rcp.rn.f64 	%fd77, %fd46;
	ld.global.v2.f64 	{%fd268, %fd269}, [params+384];
	cvt.rzi.s32.f64	%r201, %fd50;
	setp.gt.s32	%p24, %r41, %r201;
	selp.b32	%r203, %r201, %r262, %p24;
	max.s32 	%r205, %r203, %r50;
	mul.f64 	%fd270, %fd15, %fd49;
	cvt.rzi.s32.f64	%r16, %fd270;
	add.s32 	%r206, %r205, 1;
	cvt.rn.f64.s32	%fd271, %r206;
	sub.f64 	%fd272, %fd271, %fd50;
	sub.f64 	%fd274, %fd164, %fd272;
	cvt.s64.s32	%rd25, %r205;
	mul.wide.s32 	%rd141, %r205, 8;
	mov.u64 	%rd142, temp;
	add.s64 	%rd143, %rd142, %rd141;
	ld.const.f64 	%fd275, [%rd143];
	ld.const.f64 	%fd276, [%rd143+8];
	mul.f64 	%fd277, %fd276, %fd274;
	fma.rn.f64 	%fd80, %fd275, %fd272, %fd277;
	ld.global.v2.f64 	{%fd278, %fd279}, [params+224];
	mul.f64 	%fd282, %fd46, %fd279;
	fma.rn.f64 	%fd283, %fd17, %fd282, %fd278;
	ld.global.f64 	%fd284, [params+240];
	mul.f64 	%fd285, %fd46, %fd284;
	mul.f64 	%fd286, %fd46, %fd285;
	mul.f64 	%fd287, %fd17, %fd286;
	fma.rn.f64 	%fd81, %fd17, %fd287, %fd283;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r207}, %fd45;
	}
	and.b32  	%r17, %r207, 2147483647;
	setp.ne.s32	%p25, %r17, 2146435072;
	mov.f64 	%fd687, %fd45;
	@%p25 bra 	BB13_31;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r208, %temp}, %fd45;
	}
	setp.ne.s32	%p26, %r208, 0;
	mov.f64 	%fd687, %fd45;
	@%p26 bra 	BB13_31;

	mov.f64 	%fd288, 0d0000000000000000;
	mul.rn.f64 	%fd687, %fd45, %fd288;

BB13_31:
	mul.f64 	%fd289, %fd687, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r268, %fd289;
	add.u64 	%rd144, %SP, 0;
	cvta.to.local.u64 	%rd145, %rd144;
	st.local.u32 	[%rd145], %r268;
	cvt.rn.f64.s32	%fd290, %r268;
	neg.f64 	%fd291, %fd290;
	mov.f64 	%fd292, 0d3FF921FB54442D18;
	fma.rn.f64 	%fd293, %fd291, %fd292, %fd687;
	mov.f64 	%fd294, 0d3C91A62633145C00;
	fma.rn.f64 	%fd295, %fd291, %fd294, %fd293;
	mov.f64 	%fd296, 0d397B839A252049C0;
	fma.rn.f64 	%fd674, %fd291, %fd296, %fd295;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r209}, %fd687;
	}
	and.b32  	%r210, %r209, 2145386496;
	setp.lt.u32	%p27, %r210, 1105199104;
	@%p27 bra 	BB13_33;

	// Callseq Start 29
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd687;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd144;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd674, [retval0+0];
	
	//{
	}// Callseq End 29
	ld.local.u32 	%r268, [%rd145];

BB13_33:
	add.s32 	%r21, %r268, 1;
	and.b32  	%r211, %r21, 1;
	shl.b32 	%r212, %r211, 3;
	setp.eq.s32	%p28, %r211, 0;
	selp.f64	%fd297, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p28;
	mul.wide.u32 	%rd148, %r212, 8;
	mov.u64 	%rd149, __cudart_sin_cos_coeffs;
	add.s64 	%rd150, %rd148, %rd149;
	ld.const.f64 	%fd298, [%rd150+8];
	mul.rn.f64 	%fd87, %fd674, %fd674;
	fma.rn.f64 	%fd299, %fd297, %fd87, %fd298;
	ld.const.f64 	%fd300, [%rd150+16];
	fma.rn.f64 	%fd301, %fd299, %fd87, %fd300;
	ld.const.f64 	%fd302, [%rd150+24];
	fma.rn.f64 	%fd303, %fd301, %fd87, %fd302;
	ld.const.f64 	%fd304, [%rd150+32];
	fma.rn.f64 	%fd305, %fd303, %fd87, %fd304;
	ld.const.f64 	%fd306, [%rd150+40];
	fma.rn.f64 	%fd307, %fd305, %fd87, %fd306;
	ld.const.f64 	%fd308, [%rd150+48];
	fma.rn.f64 	%fd88, %fd307, %fd87, %fd308;
	fma.rn.f64 	%fd675, %fd88, %fd674, %fd674;
	@%p28 bra 	BB13_35;

	fma.rn.f64 	%fd675, %fd88, %fd87, %fd164;

BB13_35:
	and.b32  	%r213, %r21, 2;
	setp.eq.s32	%p29, %r213, 0;
	@%p29 bra 	BB13_37;

	mov.f64 	%fd310, 0d0000000000000000;
	mov.f64 	%fd311, 0dBFF0000000000000;
	fma.rn.f64 	%fd675, %fd675, %fd311, %fd310;

BB13_37:
	mov.f64 	%fd686, %fd45;
	@%p25 bra 	BB13_40;

	{
	.reg .b32 %temp; 
	mov.b64 	{%r214, %temp}, %fd45;
	}
	setp.ne.s32	%p31, %r214, 0;
	mov.f64 	%fd686, %fd45;
	@%p31 bra 	BB13_40;

	mov.f64 	%fd312, 0d0000000000000000;
	mul.rn.f64 	%fd686, %fd45, %fd312;

BB13_40:
	mul.f64 	%fd313, %fd686, 0d3FE45F306DC9C883;
	cvt.rni.s32.f64	%r269, %fd313;
	st.local.u32 	[%rd145], %r269;
	cvt.rn.f64.s32	%fd314, %r269;
	neg.f64 	%fd315, %fd314;
	fma.rn.f64 	%fd317, %fd315, %fd292, %fd686;
	fma.rn.f64 	%fd319, %fd315, %fd294, %fd317;
	fma.rn.f64 	%fd692, %fd315, %fd296, %fd319;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r215}, %fd686;
	}
	and.b32  	%r216, %r215, 2145386496;
	setp.lt.u32	%p32, %r216, 1105199104;
	@%p32 bra 	BB13_42;

	// Callseq Start 30
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.f64	[param0+0], %fd686;
	.param .b64 param1;
	st.param.b64	[param1+0], %rd144;
	.param .b64 retval0;
	call.uni (retval0), 
	__internal_trig_reduction_slowpathd, 
	(
	param0, 
	param1
	);
	ld.param.f64	%fd692, [retval0+0];
	
	//{
	}// Callseq End 30
	ld.local.u32 	%r269, [%rd145];

BB13_42:
	and.b32  	%r217, %r269, 1;
	shl.b32 	%r218, %r217, 3;
	setp.eq.s32	%p33, %r217, 0;
	selp.f64	%fd321, 0d3DE5DB65F9785EBA, 0dBDA8FF8320FD8164, %p33;
	mul.wide.u32 	%rd155, %r218, 8;
	add.s64 	%rd157, %rd155, %rd149;
	ld.const.f64 	%fd322, [%rd157+8];
	mul.rn.f64 	%fd99, %fd692, %fd692;
	fma.rn.f64 	%fd323, %fd321, %fd99, %fd322;
	ld.const.f64 	%fd324, [%rd157+16];
	fma.rn.f64 	%fd325, %fd323, %fd99, %fd324;
	ld.const.f64 	%fd326, [%rd157+24];
	fma.rn.f64 	%fd327, %fd325, %fd99, %fd326;
	ld.const.f64 	%fd328, [%rd157+32];
	fma.rn.f64 	%fd329, %fd327, %fd99, %fd328;
	ld.const.f64 	%fd330, [%rd157+40];
	fma.rn.f64 	%fd331, %fd329, %fd99, %fd330;
	ld.const.f64 	%fd332, [%rd157+48];
	fma.rn.f64 	%fd100, %fd331, %fd99, %fd332;
	fma.rn.f64 	%fd693, %fd100, %fd692, %fd692;
	@%p33 bra 	BB13_44;

	fma.rn.f64 	%fd693, %fd100, %fd99, %fd164;

BB13_44:
	and.b32  	%r219, %r269, 2;
	setp.eq.s32	%p34, %r219, 0;
	@%p34 bra 	BB13_46;

	mov.f64 	%fd334, 0d0000000000000000;
	mov.f64 	%fd335, 0dBFF0000000000000;
	fma.rn.f64 	%fd693, %fd693, %fd335, %fd334;

BB13_46:
	fma.rn.f64 	%fd336, %fd46, %fd675, 0d3FF0000000000000;
	rcp.rn.f64 	%fd106, %fd336;
	mul.f64 	%fd337, %fd43, %fd43;
	mul.f64 	%fd338, %fd8, %fd337;
	mul.f64 	%fd339, %fd338, %fd106;
	mul.f64 	%fd340, %fd152, %fd152;
	fma.rn.f64 	%fd107, %fd13, %fd339, %fd340;
	mul.f64 	%fd108, %fd43, 0d0000000000000000;
	add.f64 	%fd341, %fd81, 0d0000000000000000;
	add.f64 	%fd109, %fd108, %fd341;
	mul.f64 	%fd342, %fd43, %fd106;
	mul.f64 	%fd110, %fd13, %fd342;
	mul.f64 	%fd343, %fd18, %fd110;
	mul.f64 	%fd344, %fd110, %fd343;
	fma.rn.f64 	%fd111, %fd340, %fd106, %fd344;
	sub.f64 	%fd345, %fd46, %fd268;
	mul.f64 	%fd346, %fd269, %fd345;
	mul.f64 	%fd347, %fd346, %fd346;
	mul.f64 	%fd348, %fd347, %fd347;
	mul.f64 	%fd349, %fd347, %fd348;
	neg.f64 	%fd112, %fd349;
	mov.f64 	%fd350, 0d4338000000000000;
	mov.f64 	%fd351, 0d3FF71547652B82FE;
	fma.rn.f64 	%fd352, %fd112, %fd351, %fd350;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r25, %temp}, %fd352;
	}
	mov.f64 	%fd353, 0dC338000000000000;
	add.rn.f64 	%fd354, %fd352, %fd353;
	mov.f64 	%fd355, 0dBFE62E42FEFA39EF;
	fma.rn.f64 	%fd356, %fd354, %fd355, %fd112;
	mov.f64 	%fd357, 0dBC7ABC9E3B39803F;
	fma.rn.f64 	%fd358, %fd354, %fd357, %fd356;
	mov.f64 	%fd359, 0d3E928AF3FCA213EA;
	mov.f64 	%fd360, 0d3E5ADE1569CE2BDF;
	fma.rn.f64 	%fd361, %fd360, %fd358, %fd359;
	mov.f64 	%fd362, 0d3EC71DEE62401315;
	fma.rn.f64 	%fd363, %fd361, %fd358, %fd362;
	mov.f64 	%fd364, 0d3EFA01997C89EB71;
	fma.rn.f64 	%fd365, %fd363, %fd358, %fd364;
	mov.f64 	%fd366, 0d3F2A01A014761F65;
	fma.rn.f64 	%fd367, %fd365, %fd358, %fd366;
	mov.f64 	%fd368, 0d3F56C16C1852B7AF;
	fma.rn.f64 	%fd369, %fd367, %fd358, %fd368;
	mov.f64 	%fd370, 0d3F81111111122322;
	fma.rn.f64 	%fd371, %fd369, %fd358, %fd370;
	mov.f64 	%fd372, 0d3FA55555555502A1;
	fma.rn.f64 	%fd373, %fd371, %fd358, %fd372;
	mov.f64 	%fd374, 0d3FC5555555555511;
	fma.rn.f64 	%fd375, %fd373, %fd358, %fd374;
	mov.f64 	%fd376, 0d3FE000000000000B;
	fma.rn.f64 	%fd377, %fd375, %fd358, %fd376;
	fma.rn.f64 	%fd379, %fd377, %fd358, %fd164;
	fma.rn.f64 	%fd380, %fd379, %fd358, %fd164;
	{
	.reg .b32 %temp; 
	mov.b64 	{%r26, %temp}, %fd380;
	}
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r27}, %fd380;
	}
	shl.b32 	%r220, %r25, 20;
	add.s32 	%r221, %r27, %r220;
	mov.b64 	%fd694, {%r26, %r221};
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r222}, %fd112;
	}
	mov.b32 	 %f2, %r222;
	abs.f32 	%f1, %f2;
	setp.lt.f32	%p35, %f1, 0f4086232B;
	@%p35 bra 	BB13_49;

	setp.lt.f64	%p36, %fd112, 0d0000000000000000;
	add.f64 	%fd381, %fd112, 0d7FF0000000000000;
	selp.f64	%fd694, 0d0000000000000000, %fd381, %p36;
	setp.geu.f32	%p37, %f1, 0f40874800;
	@%p37 bra 	BB13_49;

	shr.u32 	%r223, %r25, 31;
	add.s32 	%r224, %r25, %r223;
	shr.s32 	%r225, %r224, 1;
	shl.b32 	%r226, %r225, 20;
	add.s32 	%r227, %r226, %r27;
	mov.b64 	%fd382, {%r26, %r227};
	sub.s32 	%r228, %r25, %r225;
	shl.b32 	%r229, %r228, 20;
	add.s32 	%r230, %r229, 1072693248;
	mov.b64 	%fd383, {%r50, %r230};
	mul.f64 	%fd694, %fd382, %fd383;

BB13_49:
	mul.wide.s32 	%rd311, %r266, 8;
	mul.f64 	%fd389, %fd632, 0d3FD0000000000000;
	mul.f64 	%fd390, %fd631, 0d3FD0000000000000;
	mul.f64 	%fd391, %fd630, 0d3FD0000000000000;
	rcp.rn.f64 	%fd392, %fd81;
	neg.f64 	%fd393, %fd106;
	mul.f64 	%fd394, %fd106, %fd393;
	mul.f64 	%fd395, %fd675, %fd394;
	mul.f64 	%fd396, %fd77, %fd395;
	mul.f64 	%fd397, %fd106, %fd106;
	mul.f64 	%fd398, %fd46, %fd397;
	mul.f64 	%fd399, %fd693, %fd398;
	mul.f64 	%fd400, %fd14, %fd107;
	rcp.rn.f64 	%fd401, %fd109;
	add.s32 	%r232, %r16, 1;
	setp.gt.s32	%p38, %r16, 3;
	selp.b32	%r233, 4, %r232, %p38;
	setp.gt.s32	%p39, %r233, 0;
	sub.f64 	%fd403, %fd164, %fd12;
	fma.rn.f64 	%fd404, %fd12, %fd694, %fd403;
	fma.rn.f64 	%fd405, %fd80, %fd111, 0dBFF8000000000000;
	ld.global.f64 	%fd406, [params+264];
	ld.global.f64 	%fd407, [params+280];
	fma.rn.f64 	%fd408, %fd405, %fd406, %fd407;
	mul.f64 	%fd409, %fd404, %fd408;
	mul.f64 	%fd410, %fd77, %fd409;
	mul.f64 	%fd411, %fd390, %fd392;
	sub.f64 	%fd412, %fd391, %fd411;
	mul.f64 	%fd413, %fd630, 0dBFD0000000000000;
	mul.f64 	%fd414, %fd413, %fd106;
	mul.f64 	%fd415, %fd81, %fd414;
	mul.f64 	%fd416, %fd401, %fd415;
	cvt.s64.s32	%rd163, %r233;
	selp.b64	%rd164, %rd163, 0, %p39;
	shl.b64 	%rd165, %rd164, 3;
	mov.u64 	%rd166, shared_buffer_gyro;
	add.s64 	%rd167, %rd166, %rd165;
	ld.shared.f64 	%fd417, [%rd167];
	add.f64 	%fd418, %fd390, %fd417;
	mul.f64 	%fd419, %fd412, 0d0000000000000000;
	sub.f64 	%fd420, %fd419, %fd418;
	mul.f64 	%fd421, %fd81, %fd420;
	mul.f64 	%fd117, %fd401, %fd421;
	shl.b64 	%rd168, %rd25, 3;
	mov.u64 	%rd169, dtemp;
	add.s64 	%rd170, %rd169, %rd168;
	ld.const.f64 	%fd422, [%rd170];
	sub.f64 	%fd423, %fd110, %fd422;
	mul.f64 	%fd424, %fd416, %fd423;
	mul.f64 	%fd425, %fd8, %fd424;
	mul.f64 	%fd426, %fd80, %fd425;
	mul.f64 	%fd427, %fd396, %fd418;
	mul.f64 	%fd428, %fd389, %fd399;
	sub.f64 	%fd429, %fd428, %fd427;
	mul.f64 	%fd430, %fd396, 0d0000000000000000;
	fma.rn.f64 	%fd431, %fd412, %fd430, %fd429;
	mul.f64 	%fd432, %fd81, %fd431;
	mul.f64 	%fd433, %fd401, %fd432;
	mul.f64 	%fd434, %fd400, %fd433;
	mul.f64 	%fd435, %fd8, %fd434;
	add.s64 	%rd172, %rd17, %rd311;
	ld.f64 	%fd436, [%rd172];
	sub.f64 	%fd437, %fd436, %fd42;
	fma.rn.f64 	%fd438, %fd410, %fd117, %fd426;
	fma.rn.f64 	%fd439, %fd80, %fd435, %fd438;
	mul.f64 	%fd440, %fd437, %fd439;
	ld.global.v2.f64 	{%fd441, %fd442}, [params+288];
	mul.f64 	%fd445, %fd46, %fd442;
	fma.rn.f64 	%fd446, %fd17, %fd445, %fd441;
	ld.global.f64 	%fd447, [params+304];
	mul.f64 	%fd448, %fd46, %fd447;
	mul.f64 	%fd449, %fd46, %fd448;
	mul.f64 	%fd450, %fd17, %fd449;
	fma.rn.f64 	%fd451, %fd17, %fd450, %fd446;
	mul.f64 	%fd452, %fd9, %fd451;
	fma.rn.f64 	%fd453, %fd5, %fd389, %fd452;
	mul.f64 	%fd454, %fd5, %fd418;
	mul.f64 	%fd455, %fd5, %fd412;
	neg.f64 	%fd456, %fd400;
	mul.f64 	%fd457, %fd399, %fd456;
	sub.f64 	%fd458, %fd457, %fd454;
	fma.rn.f64 	%fd459, %fd455, 0d0000000000000000, %fd458;
	mul.f64 	%fd460, %fd81, %fd459;
	mul.f64 	%fd461, %fd401, %fd460;
	mul.f64 	%fd462, %fd81, 0d0000000000000000;
	mul.f64 	%fd463, %fd43, %fd462;
	sub.f64 	%fd464, %fd164, %fd463;
	mul.f64 	%fd465, %fd106, %fd110;
	fma.rn.f64 	%fd466, %fd400, %fd396, %fd453;
	mul.f64 	%fd467, %fd81, %fd466;
	fma.rn.f64 	%fd468, %fd464, %fd465, %fd467;
	mul.f64 	%fd469, %fd401, %fd468;
	mul.f64 	%fd470, %fd81, %fd465;
	add.f64 	%fd471, %fd108, 0d3FF0000000000000;
	mul.f64 	%fd472, %fd471, %fd470;
	mul.f64 	%fd473, %fd462, %fd466;
	sub.f64 	%fd474, %fd472, %fd473;
	mul.f64 	%fd475, %fd401, %fd474;
	mul.f64 	%fd476, %fd11, %fd454;
	fma.rn.f64 	%fd477, %fd399, %fd400, %fd476;
	add.f64 	%fd478, %fd108, 0dBFF0000000000000;
	mul.f64 	%fd479, %fd478, %fd477;
	mul.f64 	%fd480, %fd11, %fd81;
	mul.f64 	%fd481, %fd471, %fd480;
	mul.f64 	%fd482, %fd481, %fd455;
	sub.f64 	%fd483, %fd479, %fd482;
	mul.f64 	%fd484, %fd401, %fd483;
	mul.f64 	%fd485, %fd72, 0d3FE0000000000000;
	mul.f64 	%fd486, %fd36, %fd461;
	fma.rn.f64 	%fd487, %fd72, %fd485, %fd486;
	max.f64 	%fd488, %fd19, %fd487;
	add.f64 	%fd489, %fd488, %fd488;
	sqrt.rn.f64 	%fd384, %fd489;
	mov.f64 	%fd643, %fd384;
	add.s64 	%rd158, %rd5, %rd311;
	// inline asm
	st.global.cs.f64 [%rd158], %fd384;
	// inline asm
	fma.rn.f64 	%fd490, %fd36, %fd469, %fd73;
	fma.rn.f64 	%fd491, %fd36, %fd475, %fd650;
	fma.rn.f64 	%fd663, %fd36, %fd484, %fd75;
	add.s64 	%rd159, %rd8, %rd311;
	// inline asm
	st.global.cs.f64 [%rd159], %fd663;
	// inline asm
	fma.rn.f64 	%fd673, %fd36, %fd440, %fd76;
	add.s64 	%rd160, %rd9, %rd311;
	// inline asm
	st.global.cs.f64 [%rd160], %fd673;
	// inline asm
	fma.rn.f64 	%fd492, %fd3, %fd490, 0d4024000000000000;
	cvt.rzi.s32.f64	%r234, %fd492;
	cvt.rn.f64.s32	%fd493, %r234;
	sub.f64 	%fd494, %fd492, %fd493;
	mul.f64 	%fd387, %fd2, %fd494;
	mov.f64 	%fd691, %fd387;
	add.s64 	%rd161, %rd6, %rd311;
	// inline asm
	st.global.cs.f64 [%rd161], %fd387;
	// inline asm
	fma.rn.f64 	%fd495, %fd3, %fd491, 0d4024000000000000;
	cvt.rzi.s32.f64	%r235, %fd495;
	cvt.rn.f64.s32	%fd496, %r235;
	sub.f64 	%fd497, %fd495, %fd496;
	mul.f64 	%fd388, %fd2, %fd497;
	mov.f64 	%fd653, %fd388;
	add.s64 	%rd162, %rd7, %rd311;
	// inline asm
	st.global.cs.f64 [%rd162], %fd388;
	// inline asm
	setp.ne.s32	%p40, %r35, 2;
	@%p40 bra 	BB13_52;

	setp.gt.f64	%p41, %fd384, %fd7;
	setp.lt.f64	%p42, %fd384, %fd10;
	or.pred  	%p43, %p41, %p42;
	@!%p43 bra 	BB13_52;
	bra.uni 	BB13_51;

BB13_51:
	mul.wide.s32 	%rd316, %r266, 8;
	// inline asm
	st.global.cs.f64 [%rd158], %fd72;
	// inline asm
	sub.f64 	%fd503, %fd2, %fd73;
	// inline asm
	st.global.cs.f64 [%rd161], %fd503;
	// inline asm
	// inline asm
	st.global.cs.f64 [%rd162], %fd650;
	// inline asm
	// inline asm
	st.global.cs.f64 [%rd159], %fd75;
	// inline asm
	// inline asm
	st.global.cs.f64 [%rd160], %fd76;
	// inline asm
	add.s64 	%rd178, %rd11, %rd316;
	// inline asm
	st.global.cs.f64 [%rd178], %fd503;
	// inline asm

BB13_52:
	@%p2 bra 	BB13_54;

	mov.u32 	%r236, 4;
	min.s32 	%r237, %r236, %r16;
	max.s32 	%r239, %r237, %r50;
	mov.u64 	%rd181, rtemi;
	add.s64 	%rd182, %rd181, %rd168;
	ld.const.f64 	%fd504, [%rd182];
	mul.f64 	%fd505, %fd20, %fd504;
	sub.f64 	%fd506, %fd111, %fd505;
	mul.f64 	%fd507, %fd77, %fd117;
	mul.f64 	%fd508, %fd507, %fd506;
	mov.u32 	%r240, %ntid.x;
	mad.lo.s32 	%r241, %r239, %r240, %r2;
	cvt.s64.s32	%rd183, %r241;
	mul.lo.s32 	%r242, %r240, 7;
	cvt.s64.s32	%rd184, %r242;
	add.s64 	%rd185, %rd184, %rd183;
	shl.b64 	%rd186, %rd185, 3;
	add.s64 	%rd188, %rd186, %rd166;
	add.s64 	%rd189, %rd188, 40;
	ld.shared.f64 	%fd509, [%rd188+40];
	fma.rn.f64 	%fd510, %fd76, %fd508, %fd509;
	st.shared.f64 	[%rd188+40], %fd510;
	mul.lo.s32 	%r243, %r240, 5;
	mul.wide.s32 	%rd190, %r243, 8;
	add.s64 	%rd191, %rd189, %rd190;
	ld.shared.f64 	%fd511, [%rd191];
	add.f64 	%fd512, %fd511, 0d3FF0000000000000;
	st.shared.f64 	[%rd191], %fd512;
	add.s64 	%rd192, %rd191, %rd190;
	ld.shared.f64 	%fd513, [%rd192];
	fma.rn.f64 	%fd514, %fd46, %fd507, %fd513;
	st.shared.f64 	[%rd192], %fd514;
	add.s64 	%rd193, %rd192, %rd190;
	ld.shared.f64 	%fd515, [%rd193];
	add.f64 	%fd516, %fd515, 0d3FF0000000000000;
	st.shared.f64 	[%rd193], %fd516;
	mul.wide.s32 	%rd194, %r2, 8;
	add.s64 	%rd195, %rd166, %rd194;
	ld.shared.f64 	%fd517, [%rd195+40];
	fma.rn.f64 	%fd518, %fd76, %fd508, %fd517;
	st.shared.f64 	[%rd195+40], %fd518;
	mul.wide.s32 	%rd196, %r240, 8;
	add.s64 	%rd197, %rd195, %rd196;
	ld.shared.f64 	%fd519, [%rd197+40];
	fma.rn.f64 	%fd520, %fd76, %fd507, %fd519;
	st.shared.f64 	[%rd197+40], %fd520;
	mul.f64 	%fd521, %fd75, %fd106;
	add.s64 	%rd198, %rd195, 40;
	add.s64 	%rd199, %rd198, %rd196;
	add.s64 	%rd200, %rd199, %rd196;
	ld.shared.f64 	%fd522, [%rd200];
	fma.rn.f64 	%fd523, %fd76, %fd521, %fd522;
	st.shared.f64 	[%rd200], %fd523;
	add.s64 	%rd201, %rd200, %rd196;
	add.s64 	%rd202, %rd201, -40;
	ld.shared.f64 	%fd524, [%rd201];
	fma.rn.f64 	%fd525, %fd76, %fd76, %fd524;
	st.shared.f64 	[%rd201], %fd525;
	add.s64 	%rd203, %rd202, %rd196;
	ld.shared.f64 	%fd526, [%rd203+40];
	fma.rn.f64 	%fd527, %fd76, %fd111, %fd526;
	st.shared.f64 	[%rd203+40], %fd527;
	add.s64 	%rd204, %rd203, %rd196;
	ld.shared.f64 	%fd528, [%rd204+40];
	add.f64 	%fd529, %fd111, %fd528;
	st.shared.f64 	[%rd204+40], %fd529;
	mul.wide.s32 	%rd205, %r240, 16;
	add.s64 	%rd206, %rd203, %rd205;
	ld.shared.f64 	%fd530, [%rd206+40];
	add.f64 	%fd531, %fd76, %fd530;
	st.shared.f64 	[%rd206+40], %fd531;

BB13_54:
	mov.u32 	%r244, %ntid.x;
	mov.u32 	%r245, %nctaid.x;
	mad.lo.s32 	%r266, %r244, %r245, %r266;
	setp.lt.s32	%p45, %r266, %r38;
	@%p45 bra 	BB13_10;

BB13_55:
	ld.param.u32 	%r261, [_Z16gpu_pushi_kernelP19gtc_particle_data_tP23gtc_aux_particle_data_tP16gtc_field_data_tP20gtc_diagnosis_data_tiii_param_6];
	setp.eq.s32	%p1, %r261, 0;
	bar.sync 	0;
	@!%p1 bra 	BB13_71;
	bra.uni 	BB13_56;

BB13_56:
	setp.lt.s32	%p46, %r1, 2;
	@%p46 bra 	BB13_61;

	mad.lo.s32 	%r30, %r1, 5, %r2;
	cvt.s64.s32	%rd208, %r30;
	cvt.s64.s32	%rd209, %r4;
	mov.u64 	%rd210, shared_buffer_gyro;
	add.s64 	%rd211, %rd15, %rd209;
	shl.b64 	%rd212, %rd211, 3;
	add.s64 	%rd31, %rd212, %rd210;
	add.s64 	%rd213, %rd208, %rd209;
	shl.b64 	%rd214, %rd213, 3;
	add.s64 	%rd32, %rd214, %rd210;
	mad.lo.s32 	%r31, %r1, 10, %r2;
	cvt.s64.s32	%rd215, %r31;
	add.s64 	%rd216, %rd215, %rd209;
	shl.b64 	%rd217, %rd216, 3;
	add.s64 	%rd33, %rd217, %rd210;
	mad.lo.s32 	%r32, %r1, 15, %r2;
	cvt.s64.s32	%rd218, %r32;
	add.s64 	%rd219, %rd218, %rd209;
	shl.b64 	%rd220, %rd219, 3;
	add.s64 	%rd34, %rd220, %rd210;
	mul.wide.s32 	%rd35, %r1, 8;
	add.s64 	%rd36, %rd31, %rd35;
	add.s64 	%rd37, %rd36, %rd35;
	add.s64 	%rd38, %rd37, %rd35;
	shl.b64 	%rd221, %rd35, 1;
	add.s64 	%rd39, %rd37, %rd221;
	add.s64 	%rd40, %rd32, %rd35;
	add.s64 	%rd41, %rd40, %rd35;
	add.s64 	%rd42, %rd41, %rd35;
	add.s64 	%rd43, %rd41, %rd221;
	add.s64 	%rd44, %rd33, %rd35;
	add.s64 	%rd45, %rd44, %rd35;
	add.s64 	%rd46, %rd45, %rd35;
	add.s64 	%rd47, %rd45, %rd221;
	add.s64 	%rd48, %rd34, %rd35;
	add.s64 	%rd49, %rd48, %rd35;
	add.s64 	%rd50, %rd49, %rd35;
	add.s64 	%rd51, %rd49, %rd221;
	mov.u32 	%r270, %r1;

BB13_58:
	mov.u32 	%r33, %r270;
	shr.s32 	%r34, %r33, 1;
	setp.ge.s32	%p47, %r2, %r34;
	@%p47 bra 	BB13_60;

	add.s32 	%r248, %r2, %r34;
	cvt.s64.s32	%rd222, %r248;
	mul.wide.s32 	%rd223, %r248, 8;
	add.s64 	%rd225, %rd223, %rd210;
	add.s64 	%rd226, %rd225, 40;
	mul.wide.s32 	%rd227, %r2, 8;
	add.s64 	%rd228, %rd210, %rd227;
	ld.shared.f64 	%fd532, [%rd228+40];
	ld.shared.f64 	%fd533, [%rd225+40];
	add.f64 	%fd534, %fd533, %fd532;
	st.shared.f64 	[%rd228+40], %fd534;
	add.s64 	%rd229, %rd226, %rd35;
	mov.u32 	%r249, %ntid.x;
	mul.wide.s32 	%rd230, %r249, 8;
	add.s64 	%rd231, %rd228, %rd230;
	ld.shared.f64 	%fd535, [%rd231+40];
	ld.shared.f64 	%fd536, [%rd229];
	add.f64 	%fd537, %fd536, %fd535;
	st.shared.f64 	[%rd231+40], %fd537;
	add.s64 	%rd232, %rd229, %rd35;
	add.s64 	%rd233, %rd228, 40;
	add.s64 	%rd234, %rd233, %rd230;
	add.s64 	%rd235, %rd234, %rd230;
	ld.shared.f64 	%fd538, [%rd235];
	ld.shared.f64 	%fd539, [%rd232];
	add.f64 	%fd540, %fd539, %fd538;
	st.shared.f64 	[%rd235], %fd540;
	add.s64 	%rd236, %rd232, %rd35;
	add.s64 	%rd237, %rd235, %rd230;
	add.s64 	%rd238, %rd237, -40;
	ld.shared.f64 	%fd541, [%rd237];
	ld.shared.f64 	%fd542, [%rd236];
	add.f64 	%fd543, %fd542, %fd541;
	st.shared.f64 	[%rd237], %fd543;
	add.s64 	%rd239, %rd236, %rd35;
	add.s64 	%rd240, %rd238, %rd230;
	ld.shared.f64 	%fd544, [%rd240+40];
	ld.shared.f64 	%fd545, [%rd239];
	add.f64 	%fd546, %fd545, %fd544;
	st.shared.f64 	[%rd240+40], %fd546;
	add.s32 	%r250, %r30, %r34;
	cvt.s64.s32	%rd241, %r250;
	add.s64 	%rd242, %rd239, %rd35;
	add.s64 	%rd243, %rd240, %rd230;
	ld.shared.f64 	%fd547, [%rd243+40];
	ld.shared.f64 	%fd548, [%rd242];
	add.f64 	%fd549, %fd548, %fd547;
	st.shared.f64 	[%rd243+40], %fd549;
	add.s64 	%rd244, %rd242, %rd35;
	mul.wide.s32 	%rd245, %r249, 16;
	add.s64 	%rd246, %rd240, %rd245;
	ld.shared.f64 	%fd550, [%rd246+40];
	ld.shared.f64 	%fd551, [%rd244];
	add.f64 	%fd552, %fd551, %fd550;
	st.shared.f64 	[%rd246+40], %fd552;
	mul.lo.s32 	%r251, %r249, 7;
	cvt.s64.s32	%rd247, %r251;
	add.s64 	%rd248, %rd247, %rd222;
	shl.b64 	%rd249, %rd248, 3;
	add.s64 	%rd250, %rd249, %rd210;
	add.s64 	%rd251, %rd250, 40;
	ld.shared.f64 	%fd553, [%rd31+40];
	ld.shared.f64 	%fd554, [%rd250+40];
	add.f64 	%fd555, %fd554, %fd553;
	st.shared.f64 	[%rd31+40], %fd555;
	add.s64 	%rd252, %rd247, %rd241;
	shl.b64 	%rd253, %rd252, 3;
	add.s64 	%rd254, %rd253, %rd210;
	add.s64 	%rd255, %rd254, 40;
	ld.shared.f64 	%fd556, [%rd32+40];
	ld.shared.f64 	%fd557, [%rd254+40];
	add.f64 	%fd558, %fd557, %fd556;
	st.shared.f64 	[%rd32+40], %fd558;
	add.s32 	%r252, %r31, %r34;
	cvt.s64.s32	%rd256, %r252;
	add.s64 	%rd257, %rd247, %rd256;
	shl.b64 	%rd258, %rd257, 3;
	add.s64 	%rd259, %rd258, %rd210;
	add.s64 	%rd260, %rd259, 40;
	ld.shared.f64 	%fd559, [%rd33+40];
	ld.shared.f64 	%fd560, [%rd259+40];
	add.f64 	%fd561, %fd560, %fd559;
	st.shared.f64 	[%rd33+40], %fd561;
	add.s32 	%r253, %r32, %r34;
	cvt.s64.s32	%rd261, %r253;
	add.s64 	%rd262, %rd247, %rd261;
	shl.b64 	%rd263, %rd262, 3;
	add.s64 	%rd264, %rd263, %rd210;
	add.s64 	%rd265, %rd264, 40;
	ld.shared.f64 	%fd562, [%rd34+40];
	ld.shared.f64 	%fd563, [%rd264+40];
	add.f64 	%fd564, %fd563, %fd562;
	st.shared.f64 	[%rd34+40], %fd564;
	add.s64 	%rd266, %rd251, %rd35;
	ld.shared.f64 	%fd565, [%rd36+40];
	ld.shared.f64 	%fd566, [%rd266];
	add.f64 	%fd567, %fd566, %fd565;
	st.shared.f64 	[%rd36+40], %fd567;
	add.s64 	%rd267, %rd255, %rd35;
	ld.shared.f64 	%fd568, [%rd40+40];
	ld.shared.f64 	%fd569, [%rd267];
	add.f64 	%fd570, %fd569, %fd568;
	st.shared.f64 	[%rd40+40], %fd570;
	add.s64 	%rd268, %rd260, %rd35;
	ld.shared.f64 	%fd571, [%rd44+40];
	ld.shared.f64 	%fd572, [%rd268];
	add.f64 	%fd573, %fd572, %fd571;
	st.shared.f64 	[%rd44+40], %fd573;
	add.s64 	%rd269, %rd265, %rd35;
	ld.shared.f64 	%fd574, [%rd48+40];
	ld.shared.f64 	%fd575, [%rd269];
	add.f64 	%fd576, %fd575, %fd574;
	st.shared.f64 	[%rd48+40], %fd576;
	add.s64 	%rd270, %rd266, %rd35;
	ld.shared.f64 	%fd577, [%rd37+40];
	ld.shared.f64 	%fd578, [%rd270];
	add.f64 	%fd579, %fd578, %fd577;
	st.shared.f64 	[%rd37+40], %fd579;
	add.s64 	%rd271, %rd267, %rd35;
	ld.shared.f64 	%fd580, [%rd41+40];
	ld.shared.f64 	%fd581, [%rd271];
	add.f64 	%fd582, %fd581, %fd580;
	st.shared.f64 	[%rd41+40], %fd582;
	add.s64 	%rd272, %rd268, %rd35;
	ld.shared.f64 	%fd583, [%rd45+40];
	ld.shared.f64 	%fd584, [%rd272];
	add.f64 	%fd585, %fd584, %fd583;
	st.shared.f64 	[%rd45+40], %fd585;
	add.s64 	%rd273, %rd269, %rd35;
	ld.shared.f64 	%fd586, [%rd49+40];
	ld.shared.f64 	%fd587, [%rd273];
	add.f64 	%fd588, %fd587, %fd586;
	st.shared.f64 	[%rd49+40], %fd588;
	add.s64 	%rd274, %rd270, %rd35;
	ld.shared.f64 	%fd589, [%rd38+40];
	ld.shared.f64 	%fd590, [%rd274];
	add.f64 	%fd591, %fd590, %fd589;
	st.shared.f64 	[%rd38+40], %fd591;
	add.s64 	%rd275, %rd271, %rd35;
	ld.shared.f64 	%fd592, [%rd42+40];
	ld.shared.f64 	%fd593, [%rd275];
	add.f64 	%fd594, %fd593, %fd592;
	st.shared.f64 	[%rd42+40], %fd594;
	add.s64 	%rd276, %rd272, %rd35;
	ld.shared.f64 	%fd595, [%rd46+40];
	ld.shared.f64 	%fd596, [%rd276];
	add.f64 	%fd597, %fd596, %fd595;
	st.shared.f64 	[%rd46+40], %fd597;
	add.s64 	%rd277, %rd273, %rd35;
	ld.shared.f64 	%fd598, [%rd50+40];
	ld.shared.f64 	%fd599, [%rd277];
	add.f64 	%fd600, %fd599, %fd598;
	st.shared.f64 	[%rd50+40], %fd600;
	add.s64 	%rd278, %rd274, %rd35;
	ld.shared.f64 	%fd601, [%rd39+40];
	ld.shared.f64 	%fd602, [%rd278];
	add.f64 	%fd603, %fd602, %fd601;
	st.shared.f64 	[%rd39+40], %fd603;
	add.s64 	%rd279, %rd275, %rd35;
	ld.shared.f64 	%fd604, [%rd43+40];
	ld.shared.f64 	%fd605, [%rd279];
	add.f64 	%fd606, %fd605, %fd604;
	st.shared.f64 	[%rd43+40], %fd606;
	add.s64 	%rd280, %rd276, %rd35;
	ld.shared.f64 	%fd607, [%rd47+40];
	ld.shared.f64 	%fd608, [%rd280];
	add.f64 	%fd609, %fd608, %fd607;
	st.shared.f64 	[%rd47+40], %fd609;
	add.s64 	%rd281, %rd277, %rd35;
	ld.shared.f64 	%fd610, [%rd51+40];
	ld.shared.f64 	%fd611, [%rd281];
	add.f64 	%fd612, %fd611, %fd610;
	st.shared.f64 	[%rd51+40], %fd612;

BB13_60:
	bar.sync 	0;
	setp.gt.s32	%p48, %r34, 1;
	mov.u32 	%r270, %r34;
	@%p48 bra 	BB13_58;

BB13_61:
	setp.ne.s32	%p49, %r2, 0;
	@%p49 bra 	BB13_63;

	ld.param.u64 	%rd314, [_Z16gpu_pushi_kernelP19gtc_particle_data_tP23gtc_aux_particle_data_tP16gtc_field_data_tP20gtc_diagnosis_data_tiii_param_3];
	cvta.to.global.u64 	%rd313, %rd314;
	ld.global.nc.u64 	%rd312, [%rd313+16];
	mov.u64 	%rd282, shared_buffer_gyro;
	ld.shared.f64 	%fd613, [shared_buffer_gyro+40];
	// Callseq Start 31
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd312;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd613;
	call.uni 
	_Z14atomicDPupdatePdd, 
	(
	param0, 
	param1
	);
	
	//{
	}// Callseq End 31
	mul.wide.s32 	%rd283, %r1, 8;
	add.s64 	%rd284, %rd282, %rd283;
	add.s64 	%rd285, %rd284, %rd283;
	ld.shared.f64 	%fd614, [%rd284+40];
	add.s64 	%rd286, %rd312, 16;
	// Callseq Start 32
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd286;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd614;
	call.uni 
	_Z14atomicDPupdatePdd, 
	(
	param0, 
	param1
	);
	
	//{
	}// Callseq End 32
	add.s64 	%rd287, %rd285, 40;
	ld.shared.f64 	%fd615, [%rd285+40];
	add.s64 	%rd288, %rd312, 48;
	// Callseq Start 33
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd288;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd615;
	call.uni 
	_Z14atomicDPupdatePdd, 
	(
	param0, 
	param1
	);
	
	//{
	}// Callseq End 33
	add.s64 	%rd289, %rd287, %rd283;
	ld.shared.f64 	%fd616, [%rd289];
	add.s64 	%rd290, %rd312, 64;
	// Callseq Start 34
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd290;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd616;
	call.uni 
	_Z14atomicDPupdatePdd, 
	(
	param0, 
	param1
	);
	
	//{
	}// Callseq End 34
	add.s64 	%rd291, %rd289, %rd283;
	add.s64 	%rd292, %rd291, -40;
	ld.shared.f64 	%fd617, [%rd291];
	add.s64 	%rd293, %rd312, 96;
	// Callseq Start 35
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd293;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd617;
	call.uni 
	_Z14atomicDPupdatePdd, 
	(
	param0, 
	param1
	);
	
	//{
	}// Callseq End 35
	add.s64 	%rd294, %rd292, %rd283;
	ld.shared.f64 	%fd618, [%rd294+40];
	add.s64 	%rd295, %rd312, 104;
	// Callseq Start 36
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd295;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd618;
	call.uni 
	_Z14atomicDPupdatePdd, 
	(
	param0, 
	param1
	);
	
	//{
	}// Callseq End 36
	add.s64 	%rd296, %rd294, %rd283;
	ld.shared.f64 	%fd619, [%rd296+40];
	add.s64 	%rd297, %rd312, 120;
	// Callseq Start 37
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd297;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd619;
	call.uni 
	_Z14atomicDPupdatePdd, 
	(
	param0, 
	param1
	);
	
	//{
	}// Callseq End 37

BB13_63:
	mul.lo.s32 	%r256, %r1, %r2;
	cvt.s64.s32	%rd298, %r256;
	cvt.s64.s32	%rd299, %r4;
	add.s64 	%rd300, %rd299, %rd298;
	shl.b64 	%rd301, %rd300, 3;
	mov.u64 	%rd302, shared_buffer_gyro;
	add.s64 	%rd52, %rd302, %rd301;
	setp.gt.s32	%p50, %r2, 4;
	@%p50 bra 	BB13_65;

	mul.wide.s32 	%rd303, %r2, 8;
	add.s64 	%rd304, %rd3, %rd303;
	ld.shared.f64 	%fd620, [%rd52+40];
	// Callseq Start 38
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd304;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd620;
	call.uni 
	_Z14atomicDPupdatePdd, 
	(
	param0, 
	param1
	);
	
	//{
	}// Callseq End 38

BB13_65:
	add.s32 	%r258, %r2, -5;
	setp.gt.u32	%p51, %r258, 4;
	@%p51 bra 	BB13_67;

	mul.wide.s32 	%rd305, %r2, 8;
	add.s64 	%rd306, %rd3, %rd305;
	ld.shared.f64 	%fd621, [%rd52+40];
	// Callseq Start 39
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd306;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd621;
	call.uni 
	_Z14atomicDPupdatePdd, 
	(
	param0, 
	param1
	);
	
	//{
	}// Callseq End 39

BB13_67:
	add.s32 	%r259, %r2, -10;
	setp.gt.u32	%p52, %r259, 4;
	@%p52 bra 	BB13_69;

	mul.wide.s32 	%rd307, %r2, 8;
	add.s64 	%rd308, %rd3, %rd307;
	ld.shared.f64 	%fd622, [%rd52+40];
	// Callseq Start 40
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd308;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd622;
	call.uni 
	_Z14atomicDPupdatePdd, 
	(
	param0, 
	param1
	);
	
	//{
	}// Callseq End 40

BB13_69:
	add.s32 	%r260, %r2, -15;
	setp.gt.u32	%p53, %r260, 4;
	@%p53 bra 	BB13_71;

	mul.wide.s32 	%rd309, %r2, 8;
	add.s64 	%rd310, %rd3, %rd309;
	ld.shared.f64 	%fd623, [%rd52+40];
	// Callseq Start 41
	{
	.reg .b32 temp_param_reg;
	// <end>}
	.param .b64 param0;
	st.param.b64	[param0+0], %rd310;
	.param .b64 param1;
	st.param.f64	[param1+0], %fd623;
	call.uni 
	_Z14atomicDPupdatePdd, 
	(
	param0, 
	param1
	);
	
	//{
	}// Callseq End 41

BB13_71:
	ret;
}

	// .globl	_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_IPiSK_NS_9null_typeESL_SL_SL_SL_SL_SL_SL_EEEENS_6detail16wrapped_functionINSO_23unary_transform_functorINS_8identityIiEEEEvEEjSL_SL_SL_SL_SL_SL_EEEEEEEEvT0_
.visible .entry _ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_IPiSK_NS_9null_typeESL_SL_SL_SL_SL_SL_SL_EEEENS_6detail16wrapped_functionINSO_23unary_transform_functorINS_8identityIiEEEEvEEjSL_SL_SL_SL_SL_SL_EEEEEEEEvT0_(
	.param .align 8 .b8 _ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_IPiSK_NS_9null_typeESL_SL_SL_SL_SL_SL_SL_EEEENS_6detail16wrapped_functionINSO_23unary_transform_functorINS_8identityIiEEEEvEEjSL_SL_SL_SL_SL_SL_EEEEEEEEvT0__param_0[72]
)
{
	.reg .pred 	%p<6>;
	.reg .b16 	%rs<12>;
	.reg .b32 	%r<28>;
	.reg .b64 	%rd<21>;


	ld.param.v2.u32 	{%r18, %r19}, [_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_IPiSK_NS_9null_typeESL_SL_SL_SL_SL_SL_SL_EEEENS_6detail16wrapped_functionINSO_23unary_transform_functorINS_8identityIiEEEEvEEjSL_SL_SL_SL_SL_SL_EEEEEEEEvT0__param_0+56];
	ld.param.v2.u32 	{%r20, %r21}, [_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_IPiSK_NS_9null_typeESL_SL_SL_SL_SL_SL_SL_EEEENS_6detail16wrapped_functionINSO_23unary_transform_functorINS_8identityIiEEEEvEEjSL_SL_SL_SL_SL_SL_EEEEEEEEvT0__param_0+48];
	ld.param.u32 	%r17, [_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_IPiSK_NS_9null_typeESL_SL_SL_SL_SL_SL_SL_EEEENS_6detail16wrapped_functionINSO_23unary_transform_functorINS_8identityIiEEEEvEEjSL_SL_SL_SL_SL_SL_EEEEEEEEvT0__param_0+64];
	ld.param.u32 	%r10, [_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_IPiSK_NS_9null_typeESL_SL_SL_SL_SL_SL_SL_EEEENS_6detail16wrapped_functionINSO_23unary_transform_functorINS_8identityIiEEEEvEEjSL_SL_SL_SL_SL_SL_EEEEEEEEvT0__param_0+36];
	ld.param.u64 	%rd9, [_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_IPiSK_NS_9null_typeESL_SL_SL_SL_SL_SL_SL_EEEENS_6detail16wrapped_functionINSO_23unary_transform_functorINS_8identityIiEEEEvEEjSL_SL_SL_SL_SL_SL_EEEEEEEEvT0__param_0+24];
	ld.param.u64 	%rd8, [_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_IPiSK_NS_9null_typeESL_SL_SL_SL_SL_SL_SL_EEEENS_6detail16wrapped_functionINSO_23unary_transform_functorINS_8identityIiEEEEvEEjSL_SL_SL_SL_SL_SL_EEEEEEEEvT0__param_0+16];
	mov.u32 	%r1, %tid.x;
	setp.ne.s32	%p1, %r1, 0;
	mov.u64 	%rd10, _ZN6thrust6system4cuda6detail5bulk_6detail41_GLOBAL__N__17_gpu_setup_cpp1_ii_524b47c119s_on_chip_allocatorE;
	cvta.shared.u64 	%rd11, %rd10;
	setp.eq.s64	%p2, %rd11, 0;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	BB14_2;

	cvt.s64.s32	%rd12, %r21;
	mov.u32 	%r24, 0;
	st.shared.u32 	[_ZN6thrust6system4cuda6detail5bulk_6detail41_GLOBAL__N__17_gpu_setup_cpp1_ii_524b47c119s_on_chip_allocatorE], %r24;
	mov.u64 	%rd13, _ZN6thrust6system4cuda6detail5bulk_6detail20s_data_segment_beginE;
	cvta.shared.u64 	%rd14, %rd13;
	st.shared.u64 	[_ZN6thrust6system4cuda6detail5bulk_6detail41_GLOBAL__N__17_gpu_setup_cpp1_ii_524b47c119s_on_chip_allocatorE+8], %rd14;
	st.shared.u64 	[_ZN6thrust6system4cuda6detail5bulk_6detail41_GLOBAL__N__17_gpu_setup_cpp1_ii_524b47c119s_on_chip_allocatorE+16], %rd12;

BB14_2:
	mov.u32 	%r4, %ntid.x;
	mov.u32 	%r25, %ctaid.x;
	add.s32 	%r5, %r25, %r17;
	bar.sync 	0;
	mul.lo.s32 	%r6, %r4, %r18;
	mad.lo.s32 	%r27, %r5, %r4, %r1;
	setp.ge.u32	%p4, %r27, %r10;
	@%p4 bra 	BB14_5;

	cvta.to.global.u64 	%rd15, %rd8;
	cvta.to.global.u64 	%rd16, %rd9;
	mul.wide.u32 	%rd17, %r27, 4;
	add.s64 	%rd20, %rd15, %rd17;
	add.s64 	%rd19, %rd16, %rd17;
	cvt.u64.u32	%rd3, %r6;
	shl.b64 	%rd18, %rd3, 2;

BB14_4:
	ld.global.u32 	%r26, [%rd20];
	st.global.u32 	[%rd19], %r26;
	add.s64 	%rd20, %rd20, %rd18;
	add.s64 	%rd19, %rd19, %rd18;
	add.s32 	%r27, %r27, %r6;
	setp.lt.u32	%p5, %r27, %r10;
	@%p5 bra 	BB14_4;

BB14_5:
	ret;
}

	// .globl	_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_IPiSK_NS_9null_typeESL_SL_SL_SL_SL_SL_SL_EEEENS_6detail16wrapped_functionINSO_23unary_transform_functorINS_8identityIiEEEEvEElSL_SL_SL_SL_SL_SL_EEEEEEEEvT0_
.visible .entry _ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_IPiSK_NS_9null_typeESL_SL_SL_SL_SL_SL_SL_EEEENS_6detail16wrapped_functionINSO_23unary_transform_functorINS_8identityIiEEEEvEElSL_SL_SL_SL_SL_SL_EEEEEEEEvT0_(
	.param .align 8 .b8 _ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_IPiSK_NS_9null_typeESL_SL_SL_SL_SL_SL_SL_EEEENS_6detail16wrapped_functionINSO_23unary_transform_functorINS_8identityIiEEEEvEElSL_SL_SL_SL_SL_SL_EEEEEEEEvT0__param_0[80]
)
{
	.reg .pred 	%p<6>;
	.reg .b16 	%rs<12>;
	.reg .b32 	%r<23>;
	.reg .b64 	%rd<27>;


	ld.param.v2.u32 	{%r12, %r13}, [_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_IPiSK_NS_9null_typeESL_SL_SL_SL_SL_SL_SL_EEEENS_6detail16wrapped_functionINSO_23unary_transform_functorINS_8identityIiEEEEvEElSL_SL_SL_SL_SL_SL_EEEEEEEEvT0__param_0+64];
	ld.param.v2.u32 	{%r14, %r15}, [_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_IPiSK_NS_9null_typeESL_SL_SL_SL_SL_SL_SL_EEEENS_6detail16wrapped_functionINSO_23unary_transform_functorINS_8identityIiEEEEvEElSL_SL_SL_SL_SL_SL_EEEEEEEEvT0__param_0+56];
	ld.param.u32 	%r11, [_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_IPiSK_NS_9null_typeESL_SL_SL_SL_SL_SL_SL_EEEENS_6detail16wrapped_functionINSO_23unary_transform_functorINS_8identityIiEEEEvEElSL_SL_SL_SL_SL_SL_EEEEEEEEvT0__param_0+72];
	ld.param.u64 	%rd16, [_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_IPiSK_NS_9null_typeESL_SL_SL_SL_SL_SL_SL_EEEENS_6detail16wrapped_functionINSO_23unary_transform_functorINS_8identityIiEEEEvEElSL_SL_SL_SL_SL_SL_EEEEEEEEvT0__param_0+40];
	ld.param.u64 	%rd15, [_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_IPiSK_NS_9null_typeESL_SL_SL_SL_SL_SL_SL_EEEENS_6detail16wrapped_functionINSO_23unary_transform_functorINS_8identityIiEEEEvEElSL_SL_SL_SL_SL_SL_EEEEEEEEvT0__param_0+24];
	ld.param.u64 	%rd14, [_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_IPiSK_NS_9null_typeESL_SL_SL_SL_SL_SL_SL_EEEENS_6detail16wrapped_functionINSO_23unary_transform_functorINS_8identityIiEEEEvEElSL_SL_SL_SL_SL_SL_EEEEEEEEvT0__param_0+16];
	mov.u32 	%r1, %tid.x;
	setp.ne.s32	%p1, %r1, 0;
	mov.u64 	%rd17, _ZN6thrust6system4cuda6detail5bulk_6detail41_GLOBAL__N__17_gpu_setup_cpp1_ii_524b47c119s_on_chip_allocatorE;
	cvta.shared.u64 	%rd18, %rd17;
	setp.eq.s64	%p2, %rd18, 0;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	BB15_2;

	cvt.s64.s32	%rd19, %r15;
	mov.u32 	%r18, 0;
	st.shared.u32 	[_ZN6thrust6system4cuda6detail5bulk_6detail41_GLOBAL__N__17_gpu_setup_cpp1_ii_524b47c119s_on_chip_allocatorE], %r18;
	mov.u64 	%rd20, _ZN6thrust6system4cuda6detail5bulk_6detail20s_data_segment_beginE;
	cvta.shared.u64 	%rd21, %rd20;
	st.shared.u64 	[_ZN6thrust6system4cuda6detail5bulk_6detail41_GLOBAL__N__17_gpu_setup_cpp1_ii_524b47c119s_on_chip_allocatorE+8], %rd21;
	st.shared.u64 	[_ZN6thrust6system4cuda6detail5bulk_6detail41_GLOBAL__N__17_gpu_setup_cpp1_ii_524b47c119s_on_chip_allocatorE+16], %rd19;

BB15_2:
	cvta.to.global.u64 	%rd1, %rd14;
	cvta.to.global.u64 	%rd2, %rd15;
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r19, %ctaid.x;
	add.s32 	%r4, %r19, %r11;
	bar.sync 	0;
	mul.lo.s32 	%r20, %r3, %r12;
	cvt.s64.s32	%rd4, %r20;
	mad.lo.s32 	%r21, %r4, %r3, %r1;
	cvt.s64.s32	%rd24, %r21;
	mul.wide.s32 	%rd22, %r21, 4;
	add.s64 	%rd26, %rd1, %rd22;
	add.s64 	%rd25, %rd2, %rd22;
	setp.ge.s64	%p4, %rd24, %rd16;
	@%p4 bra 	BB15_4;

BB15_3:
	ld.global.u32 	%r22, [%rd26];
	st.global.u32 	[%rd25], %r22;
	shl.b64 	%rd23, %rd4, 2;
	add.s64 	%rd26, %rd26, %rd23;
	add.s64 	%rd25, %rd25, %rd23;
	add.s64 	%rd24, %rd24, %rd4;
	setp.lt.s64	%p5, %rd24, %rd16;
	@%p5 bra 	BB15_3;

BB15_4:
	ret;
}

	// .globl	_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_INS_10device_ptrIiEESL_NS_9null_typeESM_SM_SM_SM_SM_SM_SM_EEEENS_6detail16wrapped_functionINSP_23unary_transform_functorINS_8identityIiEEEEvEEjSM_SM_SM_SM_SM_SM_EEEEEEEEvT0_
.visible .entry _ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_INS_10device_ptrIiEESL_NS_9null_typeESM_SM_SM_SM_SM_SM_SM_EEEENS_6detail16wrapped_functionINSP_23unary_transform_functorINS_8identityIiEEEEvEEjSM_SM_SM_SM_SM_SM_EEEEEEEEvT0_(
	.param .align 8 .b8 _ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_INS_10device_ptrIiEESL_NS_9null_typeESM_SM_SM_SM_SM_SM_SM_EEEENS_6detail16wrapped_functionINSP_23unary_transform_functorINS_8identityIiEEEEvEEjSM_SM_SM_SM_SM_SM_EEEEEEEEvT0__param_0[72]
)
{
	.reg .pred 	%p<6>;
	.reg .b16 	%rs<12>;
	.reg .b32 	%r<28>;
	.reg .b64 	%rd<21>;


	ld.param.v2.u32 	{%r18, %r19}, [_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_INS_10device_ptrIiEESL_NS_9null_typeESM_SM_SM_SM_SM_SM_SM_EEEENS_6detail16wrapped_functionINSP_23unary_transform_functorINS_8identityIiEEEEvEEjSM_SM_SM_SM_SM_SM_EEEEEEEEvT0__param_0+56];
	ld.param.v2.u32 	{%r20, %r21}, [_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_INS_10device_ptrIiEESL_NS_9null_typeESM_SM_SM_SM_SM_SM_SM_EEEENS_6detail16wrapped_functionINSP_23unary_transform_functorINS_8identityIiEEEEvEEjSM_SM_SM_SM_SM_SM_EEEEEEEEvT0__param_0+48];
	ld.param.u32 	%r17, [_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_INS_10device_ptrIiEESL_NS_9null_typeESM_SM_SM_SM_SM_SM_SM_EEEENS_6detail16wrapped_functionINSP_23unary_transform_functorINS_8identityIiEEEEvEEjSM_SM_SM_SM_SM_SM_EEEEEEEEvT0__param_0+64];
	ld.param.u32 	%r10, [_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_INS_10device_ptrIiEESL_NS_9null_typeESM_SM_SM_SM_SM_SM_SM_EEEENS_6detail16wrapped_functionINSP_23unary_transform_functorINS_8identityIiEEEEvEEjSM_SM_SM_SM_SM_SM_EEEEEEEEvT0__param_0+36];
	ld.param.u64 	%rd9, [_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_INS_10device_ptrIiEESL_NS_9null_typeESM_SM_SM_SM_SM_SM_SM_EEEENS_6detail16wrapped_functionINSP_23unary_transform_functorINS_8identityIiEEEEvEEjSM_SM_SM_SM_SM_SM_EEEEEEEEvT0__param_0+24];
	ld.param.u64 	%rd8, [_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_INS_10device_ptrIiEESL_NS_9null_typeESM_SM_SM_SM_SM_SM_SM_EEEENS_6detail16wrapped_functionINSP_23unary_transform_functorINS_8identityIiEEEEvEEjSM_SM_SM_SM_SM_SM_EEEEEEEEvT0__param_0+16];
	mov.u32 	%r1, %tid.x;
	setp.ne.s32	%p1, %r1, 0;
	mov.u64 	%rd10, _ZN6thrust6system4cuda6detail5bulk_6detail41_GLOBAL__N__17_gpu_setup_cpp1_ii_524b47c119s_on_chip_allocatorE;
	cvta.shared.u64 	%rd11, %rd10;
	setp.eq.s64	%p2, %rd11, 0;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	BB16_2;

	cvt.s64.s32	%rd12, %r21;
	mov.u32 	%r24, 0;
	st.shared.u32 	[_ZN6thrust6system4cuda6detail5bulk_6detail41_GLOBAL__N__17_gpu_setup_cpp1_ii_524b47c119s_on_chip_allocatorE], %r24;
	mov.u64 	%rd13, _ZN6thrust6system4cuda6detail5bulk_6detail20s_data_segment_beginE;
	cvta.shared.u64 	%rd14, %rd13;
	st.shared.u64 	[_ZN6thrust6system4cuda6detail5bulk_6detail41_GLOBAL__N__17_gpu_setup_cpp1_ii_524b47c119s_on_chip_allocatorE+8], %rd14;
	st.shared.u64 	[_ZN6thrust6system4cuda6detail5bulk_6detail41_GLOBAL__N__17_gpu_setup_cpp1_ii_524b47c119s_on_chip_allocatorE+16], %rd12;

BB16_2:
	mov.u32 	%r4, %ntid.x;
	mov.u32 	%r25, %ctaid.x;
	add.s32 	%r5, %r25, %r17;
	bar.sync 	0;
	mul.lo.s32 	%r6, %r4, %r18;
	mad.lo.s32 	%r27, %r5, %r4, %r1;
	setp.ge.u32	%p4, %r27, %r10;
	@%p4 bra 	BB16_5;

	cvta.to.global.u64 	%rd15, %rd8;
	cvta.to.global.u64 	%rd16, %rd9;
	mul.wide.u32 	%rd17, %r27, 4;
	add.s64 	%rd20, %rd15, %rd17;
	add.s64 	%rd19, %rd16, %rd17;
	cvt.u64.u32	%rd3, %r6;
	shl.b64 	%rd18, %rd3, 2;

BB16_4:
	ld.global.u32 	%r26, [%rd20];
	st.global.u32 	[%rd19], %r26;
	add.s64 	%rd20, %rd20, %rd18;
	add.s64 	%rd19, %rd19, %rd18;
	add.s32 	%r27, %r27, %r6;
	setp.lt.u32	%p5, %r27, %r10;
	@%p5 bra 	BB16_4;

BB16_5:
	ret;
}

	// .globl	_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_INS_10device_ptrIiEESL_NS_9null_typeESM_SM_SM_SM_SM_SM_SM_EEEENS_6detail16wrapped_functionINSP_23unary_transform_functorINS_8identityIiEEEEvEElSM_SM_SM_SM_SM_SM_EEEEEEEEvT0_
.visible .entry _ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_INS_10device_ptrIiEESL_NS_9null_typeESM_SM_SM_SM_SM_SM_SM_EEEENS_6detail16wrapped_functionINSP_23unary_transform_functorINS_8identityIiEEEEvEElSM_SM_SM_SM_SM_SM_EEEEEEEEvT0_(
	.param .align 8 .b8 _ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_INS_10device_ptrIiEESL_NS_9null_typeESM_SM_SM_SM_SM_SM_SM_EEEENS_6detail16wrapped_functionINSP_23unary_transform_functorINS_8identityIiEEEEvEElSM_SM_SM_SM_SM_SM_EEEEEEEEvT0__param_0[80]
)
{
	.reg .pred 	%p<6>;
	.reg .b16 	%rs<12>;
	.reg .b32 	%r<23>;
	.reg .b64 	%rd<27>;


	ld.param.v2.u32 	{%r12, %r13}, [_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_INS_10device_ptrIiEESL_NS_9null_typeESM_SM_SM_SM_SM_SM_SM_EEEENS_6detail16wrapped_functionINSP_23unary_transform_functorINS_8identityIiEEEEvEElSM_SM_SM_SM_SM_SM_EEEEEEEEvT0__param_0+64];
	ld.param.v2.u32 	{%r14, %r15}, [_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_INS_10device_ptrIiEESL_NS_9null_typeESM_SM_SM_SM_SM_SM_SM_EEEENS_6detail16wrapped_functionINSP_23unary_transform_functorINS_8identityIiEEEEvEElSM_SM_SM_SM_SM_SM_EEEEEEEEvT0__param_0+56];
	ld.param.u32 	%r11, [_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_INS_10device_ptrIiEESL_NS_9null_typeESM_SM_SM_SM_SM_SM_SM_EEEENS_6detail16wrapped_functionINSP_23unary_transform_functorINS_8identityIiEEEEvEElSM_SM_SM_SM_SM_SM_EEEEEEEEvT0__param_0+72];
	ld.param.u64 	%rd16, [_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_INS_10device_ptrIiEESL_NS_9null_typeESM_SM_SM_SM_SM_SM_SM_EEEENS_6detail16wrapped_functionINSP_23unary_transform_functorINS_8identityIiEEEEvEElSM_SM_SM_SM_SM_SM_EEEEEEEEvT0__param_0+40];
	ld.param.u64 	%rd15, [_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_INS_10device_ptrIiEESL_NS_9null_typeESM_SM_SM_SM_SM_SM_SM_EEEENS_6detail16wrapped_functionINSP_23unary_transform_functorINS_8identityIiEEEEvEElSM_SM_SM_SM_SM_SM_EEEEEEEEvT0__param_0+24];
	ld.param.u64 	%rd14, [_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_INS_10device_ptrIiEESL_NS_9null_typeESM_SM_SM_SM_SM_SM_SM_EEEENS_6detail16wrapped_functionINSP_23unary_transform_functorINS_8identityIiEEEEvEElSM_SM_SM_SM_SM_SM_EEEEEEEEvT0__param_0+16];
	mov.u32 	%r1, %tid.x;
	setp.ne.s32	%p1, %r1, 0;
	mov.u64 	%rd17, _ZN6thrust6system4cuda6detail5bulk_6detail41_GLOBAL__N__17_gpu_setup_cpp1_ii_524b47c119s_on_chip_allocatorE;
	cvta.shared.u64 	%rd18, %rd17;
	setp.eq.s64	%p2, %rd18, 0;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	BB17_2;

	cvt.s64.s32	%rd19, %r15;
	mov.u32 	%r18, 0;
	st.shared.u32 	[_ZN6thrust6system4cuda6detail5bulk_6detail41_GLOBAL__N__17_gpu_setup_cpp1_ii_524b47c119s_on_chip_allocatorE], %r18;
	mov.u64 	%rd20, _ZN6thrust6system4cuda6detail5bulk_6detail20s_data_segment_beginE;
	cvta.shared.u64 	%rd21, %rd20;
	st.shared.u64 	[_ZN6thrust6system4cuda6detail5bulk_6detail41_GLOBAL__N__17_gpu_setup_cpp1_ii_524b47c119s_on_chip_allocatorE+8], %rd21;
	st.shared.u64 	[_ZN6thrust6system4cuda6detail5bulk_6detail41_GLOBAL__N__17_gpu_setup_cpp1_ii_524b47c119s_on_chip_allocatorE+16], %rd19;

BB17_2:
	cvta.to.global.u64 	%rd1, %rd14;
	cvta.to.global.u64 	%rd2, %rd15;
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r19, %ctaid.x;
	add.s32 	%r4, %r19, %r11;
	bar.sync 	0;
	mul.lo.s32 	%r20, %r3, %r12;
	cvt.s64.s32	%rd4, %r20;
	mad.lo.s32 	%r21, %r4, %r3, %r1;
	cvt.s64.s32	%rd24, %r21;
	mul.wide.s32 	%rd22, %r21, 4;
	add.s64 	%rd26, %rd1, %rd22;
	add.s64 	%rd25, %rd2, %rd22;
	setp.ge.s64	%p4, %rd24, %rd16;
	@%p4 bra 	BB17_4;

BB17_3:
	ld.global.u32 	%r22, [%rd26];
	st.global.u32 	[%rd25], %r22;
	shl.b64 	%rd23, %rd4, 2;
	add.s64 	%rd26, %rd26, %rd23;
	add.s64 	%rd25, %rd25, %rd23;
	add.s64 	%rd24, %rd24, %rd4;
	setp.lt.s64	%p5, %rd24, %rd16;
	@%p5 bra 	BB17_3;

BB17_4:
	ret;
}

	// .globl	_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_INS_10device_ptrIiEEPiNS_9null_typeESN_SN_SN_SN_SN_SN_SN_EEEENS_6detail16wrapped_functionINSQ_23unary_transform_functorINS_8identityIiEEEEvEEjSN_SN_SN_SN_SN_SN_EEEEEEEEvT0_
.visible .entry _ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_INS_10device_ptrIiEEPiNS_9null_typeESN_SN_SN_SN_SN_SN_SN_EEEENS_6detail16wrapped_functionINSQ_23unary_transform_functorINS_8identityIiEEEEvEEjSN_SN_SN_SN_SN_SN_EEEEEEEEvT0_(
	.param .align 8 .b8 _ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_INS_10device_ptrIiEEPiNS_9null_typeESN_SN_SN_SN_SN_SN_SN_EEEENS_6detail16wrapped_functionINSQ_23unary_transform_functorINS_8identityIiEEEEvEEjSN_SN_SN_SN_SN_SN_EEEEEEEEvT0__param_0[72]
)
{
	.reg .pred 	%p<6>;
	.reg .b16 	%rs<12>;
	.reg .b32 	%r<28>;
	.reg .b64 	%rd<21>;


	ld.param.v2.u32 	{%r18, %r19}, [_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_INS_10device_ptrIiEEPiNS_9null_typeESN_SN_SN_SN_SN_SN_SN_EEEENS_6detail16wrapped_functionINSQ_23unary_transform_functorINS_8identityIiEEEEvEEjSN_SN_SN_SN_SN_SN_EEEEEEEEvT0__param_0+56];
	ld.param.v2.u32 	{%r20, %r21}, [_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_INS_10device_ptrIiEEPiNS_9null_typeESN_SN_SN_SN_SN_SN_SN_EEEENS_6detail16wrapped_functionINSQ_23unary_transform_functorINS_8identityIiEEEEvEEjSN_SN_SN_SN_SN_SN_EEEEEEEEvT0__param_0+48];
	ld.param.u32 	%r17, [_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_INS_10device_ptrIiEEPiNS_9null_typeESN_SN_SN_SN_SN_SN_SN_EEEENS_6detail16wrapped_functionINSQ_23unary_transform_functorINS_8identityIiEEEEvEEjSN_SN_SN_SN_SN_SN_EEEEEEEEvT0__param_0+64];
	ld.param.u32 	%r10, [_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_INS_10device_ptrIiEEPiNS_9null_typeESN_SN_SN_SN_SN_SN_SN_EEEENS_6detail16wrapped_functionINSQ_23unary_transform_functorINS_8identityIiEEEEvEEjSN_SN_SN_SN_SN_SN_EEEEEEEEvT0__param_0+36];
	ld.param.u64 	%rd9, [_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_INS_10device_ptrIiEEPiNS_9null_typeESN_SN_SN_SN_SN_SN_SN_EEEENS_6detail16wrapped_functionINSQ_23unary_transform_functorINS_8identityIiEEEEvEEjSN_SN_SN_SN_SN_SN_EEEEEEEEvT0__param_0+24];
	ld.param.u64 	%rd8, [_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_INS_10device_ptrIiEEPiNS_9null_typeESN_SN_SN_SN_SN_SN_SN_EEEENS_6detail16wrapped_functionINSQ_23unary_transform_functorINS_8identityIiEEEEvEEjSN_SN_SN_SN_SN_SN_EEEEEEEEvT0__param_0+16];
	mov.u32 	%r1, %tid.x;
	setp.ne.s32	%p1, %r1, 0;
	mov.u64 	%rd10, _ZN6thrust6system4cuda6detail5bulk_6detail41_GLOBAL__N__17_gpu_setup_cpp1_ii_524b47c119s_on_chip_allocatorE;
	cvta.shared.u64 	%rd11, %rd10;
	setp.eq.s64	%p2, %rd11, 0;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	BB18_2;

	cvt.s64.s32	%rd12, %r21;
	mov.u32 	%r24, 0;
	st.shared.u32 	[_ZN6thrust6system4cuda6detail5bulk_6detail41_GLOBAL__N__17_gpu_setup_cpp1_ii_524b47c119s_on_chip_allocatorE], %r24;
	mov.u64 	%rd13, _ZN6thrust6system4cuda6detail5bulk_6detail20s_data_segment_beginE;
	cvta.shared.u64 	%rd14, %rd13;
	st.shared.u64 	[_ZN6thrust6system4cuda6detail5bulk_6detail41_GLOBAL__N__17_gpu_setup_cpp1_ii_524b47c119s_on_chip_allocatorE+8], %rd14;
	st.shared.u64 	[_ZN6thrust6system4cuda6detail5bulk_6detail41_GLOBAL__N__17_gpu_setup_cpp1_ii_524b47c119s_on_chip_allocatorE+16], %rd12;

BB18_2:
	mov.u32 	%r4, %ntid.x;
	mov.u32 	%r25, %ctaid.x;
	add.s32 	%r5, %r25, %r17;
	bar.sync 	0;
	mul.lo.s32 	%r6, %r4, %r18;
	mad.lo.s32 	%r27, %r5, %r4, %r1;
	setp.ge.u32	%p4, %r27, %r10;
	@%p4 bra 	BB18_5;

	cvta.to.global.u64 	%rd15, %rd8;
	cvta.to.global.u64 	%rd16, %rd9;
	mul.wide.u32 	%rd17, %r27, 4;
	add.s64 	%rd20, %rd15, %rd17;
	add.s64 	%rd19, %rd16, %rd17;
	cvt.u64.u32	%rd3, %r6;
	shl.b64 	%rd18, %rd3, 2;

BB18_4:
	ld.global.u32 	%r26, [%rd20];
	st.global.u32 	[%rd19], %r26;
	add.s64 	%rd20, %rd20, %rd18;
	add.s64 	%rd19, %rd19, %rd18;
	add.s32 	%r27, %r27, %r6;
	setp.lt.u32	%p5, %r27, %r10;
	@%p5 bra 	BB18_4;

BB18_5:
	ret;
}

	// .globl	_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_INS_10device_ptrIiEEPiNS_9null_typeESN_SN_SN_SN_SN_SN_SN_EEEENS_6detail16wrapped_functionINSQ_23unary_transform_functorINS_8identityIiEEEEvEElSN_SN_SN_SN_SN_SN_EEEEEEEEvT0_
.visible .entry _ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_INS_10device_ptrIiEEPiNS_9null_typeESN_SN_SN_SN_SN_SN_SN_EEEENS_6detail16wrapped_functionINSQ_23unary_transform_functorINS_8identityIiEEEEvEElSN_SN_SN_SN_SN_SN_EEEEEEEEvT0_(
	.param .align 8 .b8 _ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_INS_10device_ptrIiEEPiNS_9null_typeESN_SN_SN_SN_SN_SN_SN_EEEENS_6detail16wrapped_functionINSQ_23unary_transform_functorINS_8identityIiEEEEvEElSN_SN_SN_SN_SN_SN_EEEEEEEEvT0__param_0[80]
)
{
	.reg .pred 	%p<6>;
	.reg .b16 	%rs<12>;
	.reg .b32 	%r<23>;
	.reg .b64 	%rd<27>;


	ld.param.v2.u32 	{%r12, %r13}, [_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_INS_10device_ptrIiEEPiNS_9null_typeESN_SN_SN_SN_SN_SN_SN_EEEENS_6detail16wrapped_functionINSQ_23unary_transform_functorINS_8identityIiEEEEvEElSN_SN_SN_SN_SN_SN_EEEEEEEEvT0__param_0+64];
	ld.param.v2.u32 	{%r14, %r15}, [_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_INS_10device_ptrIiEEPiNS_9null_typeESN_SN_SN_SN_SN_SN_SN_EEEENS_6detail16wrapped_functionINSQ_23unary_transform_functorINS_8identityIiEEEEvEElSN_SN_SN_SN_SN_SN_EEEEEEEEvT0__param_0+56];
	ld.param.u32 	%r11, [_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_INS_10device_ptrIiEEPiNS_9null_typeESN_SN_SN_SN_SN_SN_SN_EEEENS_6detail16wrapped_functionINSQ_23unary_transform_functorINS_8identityIiEEEEvEElSN_SN_SN_SN_SN_SN_EEEEEEEEvT0__param_0+72];
	ld.param.u64 	%rd16, [_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_INS_10device_ptrIiEEPiNS_9null_typeESN_SN_SN_SN_SN_SN_SN_EEEENS_6detail16wrapped_functionINSQ_23unary_transform_functorINS_8identityIiEEEEvEElSN_SN_SN_SN_SN_SN_EEEEEEEEvT0__param_0+40];
	ld.param.u64 	%rd15, [_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_INS_10device_ptrIiEEPiNS_9null_typeESN_SN_SN_SN_SN_SN_SN_EEEENS_6detail16wrapped_functionINSQ_23unary_transform_functorINS_8identityIiEEEEvEElSN_SN_SN_SN_SN_SN_EEEEEEEEvT0__param_0+24];
	ld.param.u64 	%rd14, [_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_INS_10device_ptrIiEEPiNS_9null_typeESN_SN_SN_SN_SN_SN_SN_EEEENS_6detail16wrapped_functionINSQ_23unary_transform_functorINS_8identityIiEEEEvEElSN_SN_SN_SN_SN_SN_EEEEEEEEvT0__param_0+16];
	mov.u32 	%r1, %tid.x;
	setp.ne.s32	%p1, %r1, 0;
	mov.u64 	%rd17, _ZN6thrust6system4cuda6detail5bulk_6detail41_GLOBAL__N__17_gpu_setup_cpp1_ii_524b47c119s_on_chip_allocatorE;
	cvta.shared.u64 	%rd18, %rd17;
	setp.eq.s64	%p2, %rd18, 0;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	BB19_2;

	cvt.s64.s32	%rd19, %r15;
	mov.u32 	%r18, 0;
	st.shared.u32 	[_ZN6thrust6system4cuda6detail5bulk_6detail41_GLOBAL__N__17_gpu_setup_cpp1_ii_524b47c119s_on_chip_allocatorE], %r18;
	mov.u64 	%rd20, _ZN6thrust6system4cuda6detail5bulk_6detail20s_data_segment_beginE;
	cvta.shared.u64 	%rd21, %rd20;
	st.shared.u64 	[_ZN6thrust6system4cuda6detail5bulk_6detail41_GLOBAL__N__17_gpu_setup_cpp1_ii_524b47c119s_on_chip_allocatorE+8], %rd21;
	st.shared.u64 	[_ZN6thrust6system4cuda6detail5bulk_6detail41_GLOBAL__N__17_gpu_setup_cpp1_ii_524b47c119s_on_chip_allocatorE+16], %rd19;

BB19_2:
	cvta.to.global.u64 	%rd1, %rd14;
	cvta.to.global.u64 	%rd2, %rd15;
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r19, %ctaid.x;
	add.s32 	%r4, %r19, %r11;
	bar.sync 	0;
	mul.lo.s32 	%r20, %r3, %r12;
	cvt.s64.s32	%rd4, %r20;
	mad.lo.s32 	%r21, %r4, %r3, %r1;
	cvt.s64.s32	%rd24, %r21;
	mul.wide.s32 	%rd22, %r21, 4;
	add.s64 	%rd26, %rd1, %rd22;
	add.s64 	%rd25, %rd2, %rd22;
	setp.ge.s64	%p4, %rd24, %rd16;
	@%p4 bra 	BB19_4;

BB19_3:
	ld.global.u32 	%r22, [%rd26];
	st.global.u32 	[%rd25], %r22;
	shl.b64 	%rd23, %rd4, 2;
	add.s64 	%rd26, %rd26, %rd23;
	add.s64 	%rd25, %rd25, %rd23;
	add.s64 	%rd24, %rd24, %rd4;
	setp.lt.s64	%p5, %rd24, %rd16;
	@%p5 bra 	BB19_3;

BB19_4:
	ret;
}

	// .globl	_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_IPKiNS_10device_ptrIiEENS_9null_typeESO_SO_SO_SO_SO_SO_SO_EEEENS_6detail16wrapped_functionINSR_23unary_transform_functorINS_8identityIiEEEEvEEjSO_SO_SO_SO_SO_SO_EEEEEEEEvT0_
.visible .entry _ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_IPKiNS_10device_ptrIiEENS_9null_typeESO_SO_SO_SO_SO_SO_SO_EEEENS_6detail16wrapped_functionINSR_23unary_transform_functorINS_8identityIiEEEEvEEjSO_SO_SO_SO_SO_SO_EEEEEEEEvT0_(
	.param .align 8 .b8 _ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_IPKiNS_10device_ptrIiEENS_9null_typeESO_SO_SO_SO_SO_SO_SO_EEEENS_6detail16wrapped_functionINSR_23unary_transform_functorINS_8identityIiEEEEvEEjSO_SO_SO_SO_SO_SO_EEEEEEEEvT0__param_0[72]
)
{
	.reg .pred 	%p<6>;
	.reg .b16 	%rs<12>;
	.reg .b32 	%r<28>;
	.reg .b64 	%rd<21>;


	ld.param.v2.u32 	{%r18, %r19}, [_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_IPKiNS_10device_ptrIiEENS_9null_typeESO_SO_SO_SO_SO_SO_SO_EEEENS_6detail16wrapped_functionINSR_23unary_transform_functorINS_8identityIiEEEEvEEjSO_SO_SO_SO_SO_SO_EEEEEEEEvT0__param_0+56];
	ld.param.v2.u32 	{%r20, %r21}, [_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_IPKiNS_10device_ptrIiEENS_9null_typeESO_SO_SO_SO_SO_SO_SO_EEEENS_6detail16wrapped_functionINSR_23unary_transform_functorINS_8identityIiEEEEvEEjSO_SO_SO_SO_SO_SO_EEEEEEEEvT0__param_0+48];
	ld.param.u32 	%r17, [_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_IPKiNS_10device_ptrIiEENS_9null_typeESO_SO_SO_SO_SO_SO_SO_EEEENS_6detail16wrapped_functionINSR_23unary_transform_functorINS_8identityIiEEEEvEEjSO_SO_SO_SO_SO_SO_EEEEEEEEvT0__param_0+64];
	ld.param.u32 	%r10, [_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_IPKiNS_10device_ptrIiEENS_9null_typeESO_SO_SO_SO_SO_SO_SO_EEEENS_6detail16wrapped_functionINSR_23unary_transform_functorINS_8identityIiEEEEvEEjSO_SO_SO_SO_SO_SO_EEEEEEEEvT0__param_0+36];
	ld.param.u64 	%rd9, [_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_IPKiNS_10device_ptrIiEENS_9null_typeESO_SO_SO_SO_SO_SO_SO_EEEENS_6detail16wrapped_functionINSR_23unary_transform_functorINS_8identityIiEEEEvEEjSO_SO_SO_SO_SO_SO_EEEEEEEEvT0__param_0+24];
	ld.param.u64 	%rd8, [_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_IPKiNS_10device_ptrIiEENS_9null_typeESO_SO_SO_SO_SO_SO_SO_EEEENS_6detail16wrapped_functionINSR_23unary_transform_functorINS_8identityIiEEEEvEEjSO_SO_SO_SO_SO_SO_EEEEEEEEvT0__param_0+16];
	mov.u32 	%r1, %tid.x;
	setp.ne.s32	%p1, %r1, 0;
	mov.u64 	%rd10, _ZN6thrust6system4cuda6detail5bulk_6detail41_GLOBAL__N__17_gpu_setup_cpp1_ii_524b47c119s_on_chip_allocatorE;
	cvta.shared.u64 	%rd11, %rd10;
	setp.eq.s64	%p2, %rd11, 0;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	BB20_2;

	cvt.s64.s32	%rd12, %r21;
	mov.u32 	%r24, 0;
	st.shared.u32 	[_ZN6thrust6system4cuda6detail5bulk_6detail41_GLOBAL__N__17_gpu_setup_cpp1_ii_524b47c119s_on_chip_allocatorE], %r24;
	mov.u64 	%rd13, _ZN6thrust6system4cuda6detail5bulk_6detail20s_data_segment_beginE;
	cvta.shared.u64 	%rd14, %rd13;
	st.shared.u64 	[_ZN6thrust6system4cuda6detail5bulk_6detail41_GLOBAL__N__17_gpu_setup_cpp1_ii_524b47c119s_on_chip_allocatorE+8], %rd14;
	st.shared.u64 	[_ZN6thrust6system4cuda6detail5bulk_6detail41_GLOBAL__N__17_gpu_setup_cpp1_ii_524b47c119s_on_chip_allocatorE+16], %rd12;

BB20_2:
	mov.u32 	%r4, %ntid.x;
	mov.u32 	%r25, %ctaid.x;
	add.s32 	%r5, %r25, %r17;
	bar.sync 	0;
	mul.lo.s32 	%r6, %r4, %r18;
	mad.lo.s32 	%r27, %r5, %r4, %r1;
	setp.ge.u32	%p4, %r27, %r10;
	@%p4 bra 	BB20_5;

	cvta.to.global.u64 	%rd15, %rd8;
	cvta.to.global.u64 	%rd16, %rd9;
	mul.wide.u32 	%rd17, %r27, 4;
	add.s64 	%rd20, %rd15, %rd17;
	add.s64 	%rd19, %rd16, %rd17;
	cvt.u64.u32	%rd3, %r6;
	shl.b64 	%rd18, %rd3, 2;

BB20_4:
	ld.global.u32 	%r26, [%rd20];
	st.global.u32 	[%rd19], %r26;
	add.s64 	%rd20, %rd20, %rd18;
	add.s64 	%rd19, %rd19, %rd18;
	add.s32 	%r27, %r27, %r6;
	setp.lt.u32	%p5, %r27, %r10;
	@%p5 bra 	BB20_4;

BB20_5:
	ret;
}

	// .globl	_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_IPKiNS_10device_ptrIiEENS_9null_typeESO_SO_SO_SO_SO_SO_SO_EEEENS_6detail16wrapped_functionINSR_23unary_transform_functorINS_8identityIiEEEEvEElSO_SO_SO_SO_SO_SO_EEEEEEEEvT0_
.visible .entry _ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_IPKiNS_10device_ptrIiEENS_9null_typeESO_SO_SO_SO_SO_SO_SO_EEEENS_6detail16wrapped_functionINSR_23unary_transform_functorINS_8identityIiEEEEvEElSO_SO_SO_SO_SO_SO_EEEEEEEEvT0_(
	.param .align 8 .b8 _ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_IPKiNS_10device_ptrIiEENS_9null_typeESO_SO_SO_SO_SO_SO_SO_EEEENS_6detail16wrapped_functionINSR_23unary_transform_functorINS_8identityIiEEEEvEElSO_SO_SO_SO_SO_SO_EEEEEEEEvT0__param_0[80]
)
{
	.reg .pred 	%p<6>;
	.reg .b16 	%rs<12>;
	.reg .b32 	%r<23>;
	.reg .b64 	%rd<27>;


	ld.param.v2.u32 	{%r12, %r13}, [_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_IPKiNS_10device_ptrIiEENS_9null_typeESO_SO_SO_SO_SO_SO_SO_EEEENS_6detail16wrapped_functionINSR_23unary_transform_functorINS_8identityIiEEEEvEElSO_SO_SO_SO_SO_SO_EEEEEEEEvT0__param_0+64];
	ld.param.v2.u32 	{%r14, %r15}, [_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_IPKiNS_10device_ptrIiEENS_9null_typeESO_SO_SO_SO_SO_SO_SO_EEEENS_6detail16wrapped_functionINSR_23unary_transform_functorINS_8identityIiEEEEvEElSO_SO_SO_SO_SO_SO_EEEEEEEEvT0__param_0+56];
	ld.param.u32 	%r11, [_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_IPKiNS_10device_ptrIiEENS_9null_typeESO_SO_SO_SO_SO_SO_SO_EEEENS_6detail16wrapped_functionINSR_23unary_transform_functorINS_8identityIiEEEEvEElSO_SO_SO_SO_SO_SO_EEEEEEEEvT0__param_0+72];
	ld.param.u64 	%rd16, [_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_IPKiNS_10device_ptrIiEENS_9null_typeESO_SO_SO_SO_SO_SO_SO_EEEENS_6detail16wrapped_functionINSR_23unary_transform_functorINS_8identityIiEEEEvEElSO_SO_SO_SO_SO_SO_EEEEEEEEvT0__param_0+40];
	ld.param.u64 	%rd15, [_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_IPKiNS_10device_ptrIiEENS_9null_typeESO_SO_SO_SO_SO_SO_SO_EEEENS_6detail16wrapped_functionINSR_23unary_transform_functorINS_8identityIiEEEEvEElSO_SO_SO_SO_SO_SO_EEEEEEEEvT0__param_0+24];
	ld.param.u64 	%rd14, [_ZN6thrust6system4cuda6detail5bulk_6detail15launch_by_valueILj0ENS4_9cuda_taskINS3_14parallel_groupINS3_16concurrent_groupINS3_5agentILm1EEELm0EEELm0EEENS4_7closureINS2_17for_each_n_detail15for_each_kernelENS_5tupleINS4_6cursorILj0EEENS_12zip_iteratorINSG_IPKiNS_10device_ptrIiEENS_9null_typeESO_SO_SO_SO_SO_SO_SO_EEEENS_6detail16wrapped_functionINSR_23unary_transform_functorINS_8identityIiEEEEvEElSO_SO_SO_SO_SO_SO_EEEEEEEEvT0__param_0+16];
	mov.u32 	%r1, %tid.x;
	setp.ne.s32	%p1, %r1, 0;
	mov.u64 	%rd17, _ZN6thrust6system4cuda6detail5bulk_6detail41_GLOBAL__N__17_gpu_setup_cpp1_ii_524b47c119s_on_chip_allocatorE;
	cvta.shared.u64 	%rd18, %rd17;
	setp.eq.s64	%p2, %rd18, 0;
	or.pred  	%p3, %p1, %p2;
	@%p3 bra 	BB21_2;

	cvt.s64.s32	%rd19, %r15;
	mov.u32 	%r18, 0;
	st.shared.u32 	[_ZN6thrust6system4cuda6detail5bulk_6detail41_GLOBAL__N__17_gpu_setup_cpp1_ii_524b47c119s_on_chip_allocatorE], %r18;
	mov.u64 	%rd20, _ZN6thrust6system4cuda6detail5bulk_6detail20s_data_segment_beginE;
	cvta.shared.u64 	%rd21, %rd20;
	st.shared.u64 	[_ZN6thrust6system4cuda6detail5bulk_6detail41_GLOBAL__N__17_gpu_setup_cpp1_ii_524b47c119s_on_chip_allocatorE+8], %rd21;
	st.shared.u64 	[_ZN6thrust6system4cuda6detail5bulk_6detail41_GLOBAL__N__17_gpu_setup_cpp1_ii_524b47c119s_on_chip_allocatorE+16], %rd19;

BB21_2:
	cvta.to.global.u64 	%rd1, %rd14;
	cvta.to.global.u64 	%rd2, %rd15;
	mov.u32 	%r3, %ntid.x;
	mov.u32 	%r19, %ctaid.x;
	add.s32 	%r4, %r19, %r11;
	bar.sync 	0;
	mul.lo.s32 	%r20, %r3, %r12;
	cvt.s64.s32	%rd4, %r20;
	mad.lo.s32 	%r21, %r4, %r3, %r1;
	cvt.s64.s32	%rd24, %r21;
	mul.wide.s32 	%rd22, %r21, 4;
	add.s64 	%rd26, %rd1, %rd22;
	add.s64 	%rd25, %rd2, %rd22;
	setp.ge.s64	%p4, %rd24, %rd16;
	@%p4 bra 	BB21_4;

BB21_3:
	ld.global.u32 	%r22, [%rd26];
	st.global.u32 	[%rd25], %r22;
	shl.b64 	%rd23, %rd4, 2;
	add.s64 	%rd26, %rd26, %rd23;
	add.s64 	%rd25, %rd25, %rd23;
	add.s64 	%rd24, %rd24, %rd4;
	setp.lt.s64	%p5, %rd24, %rd16;
	@%p5 bra 	BB21_3;

BB21_4:
	ret;
}

	// .globl	_ZN6thrust6system4cuda6detail4cub_11EmptyKernelIvEEvv
.visible .entry _ZN6thrust6system4cuda6detail4cub_11EmptyKernelIvEEvv(

)
{



	ret;
}

	// .globl	_ZN6thrust6system4cuda6detail4cub_28DeviceRadixSortUpsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE16PtxUpsweepPolicyELb0EiiEEvPT1_PT2_SA_iibNS3_13GridEvenShareISA_EE
.visible .entry _ZN6thrust6system4cuda6detail4cub_28DeviceRadixSortUpsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE16PtxUpsweepPolicyELb0EiiEEvPT1_PT2_SA_iibNS3_13GridEvenShareISA_EE(
	.param .u64 _ZN6thrust6system4cuda6detail4cub_28DeviceRadixSortUpsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE16PtxUpsweepPolicyELb0EiiEEvPT1_PT2_SA_iibNS3_13GridEvenShareISA_EE_param_0,
	.param .u64 _ZN6thrust6system4cuda6detail4cub_28DeviceRadixSortUpsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE16PtxUpsweepPolicyELb0EiiEEvPT1_PT2_SA_iibNS3_13GridEvenShareISA_EE_param_1,
	.param .u32 _ZN6thrust6system4cuda6detail4cub_28DeviceRadixSortUpsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE16PtxUpsweepPolicyELb0EiiEEvPT1_PT2_SA_iibNS3_13GridEvenShareISA_EE_param_2,
	.param .u32 _ZN6thrust6system4cuda6detail4cub_28DeviceRadixSortUpsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE16PtxUpsweepPolicyELb0EiiEEvPT1_PT2_SA_iibNS3_13GridEvenShareISA_EE_param_3,
	.param .u32 _ZN6thrust6system4cuda6detail4cub_28DeviceRadixSortUpsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE16PtxUpsweepPolicyELb0EiiEEvPT1_PT2_SA_iibNS3_13GridEvenShareISA_EE_param_4,
	.param .u8 _ZN6thrust6system4cuda6detail4cub_28DeviceRadixSortUpsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE16PtxUpsweepPolicyELb0EiiEEvPT1_PT2_SA_iibNS3_13GridEvenShareISA_EE_param_5,
	.param .align 4 .b8 _ZN6thrust6system4cuda6detail4cub_28DeviceRadixSortUpsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE16PtxUpsweepPolicyELb0EiiEEvPT1_PT2_SA_iibNS3_13GridEvenShareISA_EE_param_6[36]
)
.maxntid 128, 1, 1
{
	.reg .pred 	%p<18>;
	.reg .b16 	%rs<127>;
	.reg .b32 	%r<610>;
	.reg .b64 	%rd<292>;
	// demoted variable
	.shared .align 4 .b8 _ZN6thrust6system4cuda6detail4cub_28DeviceRadixSortUpsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE16PtxUpsweepPolicyELb0EiiEEvPT1_PT2_SA_iibNS3_13GridEvenShareISA_EE$__cuda_local_var_106522_74_non_const_temp_storage[4224];

	ld.param.u64 	%rd10, [_ZN6thrust6system4cuda6detail4cub_28DeviceRadixSortUpsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE16PtxUpsweepPolicyELb0EiiEEvPT1_PT2_SA_iibNS3_13GridEvenShareISA_EE_param_0];
	ld.param.u64 	%rd11, [_ZN6thrust6system4cuda6detail4cub_28DeviceRadixSortUpsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE16PtxUpsweepPolicyELb0EiiEEvPT1_PT2_SA_iibNS3_13GridEvenShareISA_EE_param_1];
	ld.param.u32 	%r110, [_ZN6thrust6system4cuda6detail4cub_28DeviceRadixSortUpsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE16PtxUpsweepPolicyELb0EiiEEvPT1_PT2_SA_iibNS3_13GridEvenShareISA_EE_param_3];
	ld.param.u32 	%r111, [_ZN6thrust6system4cuda6detail4cub_28DeviceRadixSortUpsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE16PtxUpsweepPolicyELb0EiiEEvPT1_PT2_SA_iibNS3_13GridEvenShareISA_EE_param_4];
	ld.param.u32 	%r120, [_ZN6thrust6system4cuda6detail4cub_28DeviceRadixSortUpsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE16PtxUpsweepPolicyELb0EiiEEvPT1_PT2_SA_iibNS3_13GridEvenShareISA_EE_param_6+32];
	ld.param.u32 	%r119, [_ZN6thrust6system4cuda6detail4cub_28DeviceRadixSortUpsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE16PtxUpsweepPolicyELb0EiiEEvPT1_PT2_SA_iibNS3_13GridEvenShareISA_EE_param_6+28];
	ld.param.u32 	%r117, [_ZN6thrust6system4cuda6detail4cub_28DeviceRadixSortUpsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE16PtxUpsweepPolicyELb0EiiEEvPT1_PT2_SA_iibNS3_13GridEvenShareISA_EE_param_6+20];
	ld.param.u32 	%r116, [_ZN6thrust6system4cuda6detail4cub_28DeviceRadixSortUpsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE16PtxUpsweepPolicyELb0EiiEEvPT1_PT2_SA_iibNS3_13GridEvenShareISA_EE_param_6+16];
	ld.param.u32 	%r115, [_ZN6thrust6system4cuda6detail4cub_28DeviceRadixSortUpsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE16PtxUpsweepPolicyELb0EiiEEvPT1_PT2_SA_iibNS3_13GridEvenShareISA_EE_param_6+12];
	ld.param.u32 	%r114, [_ZN6thrust6system4cuda6detail4cub_28DeviceRadixSortUpsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE16PtxUpsweepPolicyELb0EiiEEvPT1_PT2_SA_iibNS3_13GridEvenShareISA_EE_param_6+8];
	ld.param.u32 	%r112, [_ZN6thrust6system4cuda6detail4cub_28DeviceRadixSortUpsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE16PtxUpsweepPolicyELb0EiiEEvPT1_PT2_SA_iibNS3_13GridEvenShareISA_EE_param_6];
	ld.param.u32 	%r113, [_ZN6thrust6system4cuda6detail4cub_28DeviceRadixSortUpsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE16PtxUpsweepPolicyELb0EiiEEvPT1_PT2_SA_iibNS3_13GridEvenShareISA_EE_param_6+4];
	mov.u32 	%r1, %ctaid.x;
	setp.lt.s32	%p3, %r1, %r113;
	@%p3 bra 	BB23_3;
	bra.uni 	BB23_1;

BB23_3:
	mul.lo.s32 	%r599, %r1, %r114;
	add.s32 	%r586, %r599, %r114;
	bra.uni 	BB23_4;

BB23_1:
	mov.u32 	%r586, %r120;
	mov.u32 	%r599, %r119;
	setp.ge.s32	%p4, %r1, %r112;
	@%p4 bra 	BB23_4;

	mad.lo.s32 	%r599, %r1, %r115, %r116;
	add.s32 	%r121, %r599, %r115;
	min.s32 	%r586, %r121, %r117;

BB23_4:
	mov.u32 	%r8, %r599;
	mov.u32 	%r130, %tid.x;
	mul.wide.u32 	%rd12, %r130, 4;
	mov.u64 	%rd13, _ZN6thrust6system4cuda6detail4cub_28DeviceRadixSortUpsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE16PtxUpsweepPolicyELb0EiiEEvPT1_PT2_SA_iibNS3_13GridEvenShareISA_EE$__cuda_local_var_106522_74_non_const_temp_storage;
	add.s64 	%rd14, %rd13, %rd12;
	mov.u32 	%r608, 0;
	st.shared.u32 	[%rd14], %r608;
	st.shared.u32 	[%rd14+512], %r608;
	st.shared.u32 	[%rd14+1024], %r608;
	st.shared.u32 	[%rd14+1536], %r608;
	st.shared.u32 	[%rd14+2048], %r608;
	st.shared.u32 	[%rd14+2560], %r608;
	st.shared.u32 	[%rd14+3072], %r608;
	st.shared.u32 	[%rd14+3584], %r608;
	add.s32 	%r131, %r8, 32640;
	setp.gt.s32	%p5, %r131, %r586;
	mov.u32 	%r604, %r608;
	mov.u32 	%r603, %r608;
	mov.u32 	%r602, %r608;
	mov.u32 	%r601, %r608;
	mov.u32 	%r607, %r608;
	mov.u32 	%r606, %r608;
	mov.u32 	%r605, %r608;
	mov.u32 	%r598, %r8;
	@%p5 bra 	BB23_13;

	add.s32 	%r588, %r8, 30720;
	mov.u32 	%r608, 0;
	mov.u32 	%r604, %r608;
	mov.u32 	%r603, %r608;
	mov.u32 	%r602, %r608;
	mov.u32 	%r601, %r608;
	mov.u32 	%r607, %r608;
	mov.u32 	%r606, %r608;
	mov.u32 	%r605, %r608;
	mov.u32 	%r587, %r608;

BB23_6:
	mov.u32 	%r20, %r588;
	add.s32 	%r142, %r8, %r587;
	mul.wide.s32 	%rd15, %r130, 4;
	add.s64 	%rd16, %rd10, %rd15;
	mul.wide.s32 	%rd17, %r142, 4;
	add.s64 	%rd290, %rd16, %rd17;
	mov.u32 	%r589, -17;

BB23_7:
	// inline asm
	ld.global.nc.u32 %r144, [%rd290];
	// inline asm
	add.s64 	%rd19, %rd290, 512;
	// inline asm
	ld.global.nc.u32 %r145, [%rd19];
	// inline asm
	add.s64 	%rd20, %rd290, 1024;
	// inline asm
	ld.global.nc.u32 %r146, [%rd20];
	// inline asm
	add.s64 	%rd21, %rd290, 1536;
	// inline asm
	ld.global.nc.u32 %r147, [%rd21];
	// inline asm
	add.s64 	%rd22, %rd290, 2048;
	// inline asm
	ld.global.nc.u32 %r148, [%rd22];
	// inline asm
	add.s64 	%rd23, %rd290, 2560;
	// inline asm
	ld.global.nc.u32 %r149, [%rd23];
	// inline asm
	add.s64 	%rd24, %rd290, 3072;
	// inline asm
	ld.global.nc.u32 %r150, [%rd24];
	// inline asm
	add.s64 	%rd25, %rd290, 3584;
	// inline asm
	ld.global.nc.u32 %r151, [%rd25];
	// inline asm
	add.s64 	%rd26, %rd290, 4096;
	// inline asm
	ld.global.nc.u32 %r152, [%rd26];
	// inline asm
	add.s64 	%rd27, %rd290, 4608;
	// inline asm
	ld.global.nc.u32 %r153, [%rd27];
	// inline asm
	add.s64 	%rd28, %rd290, 5120;
	// inline asm
	ld.global.nc.u32 %r154, [%rd28];
	// inline asm
	add.s64 	%rd29, %rd290, 5632;
	// inline asm
	ld.global.nc.u32 %r155, [%rd29];
	// inline asm
	add.s64 	%rd30, %rd290, 6144;
	// inline asm
	ld.global.nc.u32 %r156, [%rd30];
	// inline asm
	add.s64 	%rd31, %rd290, 6656;
	// inline asm
	ld.global.nc.u32 %r157, [%rd31];
	// inline asm
	add.s64 	%rd32, %rd290, 7168;
	// inline asm
	ld.global.nc.u32 %r158, [%rd32];
	// inline asm
	bar.sync 	0;
	xor.b32  	%r160, %r144, -2147483648;
	// inline asm
	bfe.u32 %r159, %r160, %r110, %r111;
	// inline asm
	and.b32  	%r219, %r159, 3;
	shr.u32 	%r220, %r159, 2;
	cvt.u64.u32	%rd33, %r219;
	mul.wide.u32 	%rd34, %r220, 512;
	add.s64 	%rd36, %rd13, %rd34;
	add.s64 	%rd38, %rd36, %rd12;
	add.s64 	%rd39, %rd38, %rd33;
	ld.shared.u8 	%rs1, [%rd39];
	add.s16 	%rs2, %rs1, 1;
	st.shared.u8 	[%rd39], %rs2;
	xor.b32  	%r164, %r145, -2147483648;
	// inline asm
	bfe.u32 %r163, %r164, %r110, %r111;
	// inline asm
	and.b32  	%r222, %r163, 3;
	shr.u32 	%r223, %r163, 2;
	cvt.u64.u32	%rd40, %r222;
	mul.wide.u32 	%rd41, %r223, 512;
	add.s64 	%rd42, %rd13, %rd41;
	add.s64 	%rd43, %rd42, %rd12;
	add.s64 	%rd44, %rd43, %rd40;
	ld.shared.u8 	%rs3, [%rd44];
	add.s16 	%rs4, %rs3, 1;
	st.shared.u8 	[%rd44], %rs4;
	xor.b32  	%r168, %r146, -2147483648;
	// inline asm
	bfe.u32 %r167, %r168, %r110, %r111;
	// inline asm
	and.b32  	%r224, %r167, 3;
	shr.u32 	%r225, %r167, 2;
	cvt.u64.u32	%rd45, %r224;
	mul.wide.u32 	%rd46, %r225, 512;
	add.s64 	%rd47, %rd13, %rd46;
	add.s64 	%rd48, %rd47, %rd12;
	add.s64 	%rd49, %rd48, %rd45;
	ld.shared.u8 	%rs5, [%rd49];
	add.s16 	%rs6, %rs5, 1;
	st.shared.u8 	[%rd49], %rs6;
	xor.b32  	%r172, %r147, -2147483648;
	// inline asm
	bfe.u32 %r171, %r172, %r110, %r111;
	// inline asm
	and.b32  	%r226, %r171, 3;
	shr.u32 	%r227, %r171, 2;
	cvt.u64.u32	%rd50, %r226;
	mul.wide.u32 	%rd51, %r227, 512;
	add.s64 	%rd52, %rd13, %rd51;
	add.s64 	%rd53, %rd52, %rd12;
	add.s64 	%rd54, %rd53, %rd50;
	ld.shared.u8 	%rs7, [%rd54];
	add.s16 	%rs8, %rs7, 1;
	st.shared.u8 	[%rd54], %rs8;
	xor.b32  	%r176, %r148, -2147483648;
	// inline asm
	bfe.u32 %r175, %r176, %r110, %r111;
	// inline asm
	and.b32  	%r228, %r175, 3;
	shr.u32 	%r229, %r175, 2;
	cvt.u64.u32	%rd55, %r228;
	mul.wide.u32 	%rd56, %r229, 512;
	add.s64 	%rd57, %rd13, %rd56;
	add.s64 	%rd58, %rd57, %rd12;
	add.s64 	%rd59, %rd58, %rd55;
	ld.shared.u8 	%rs9, [%rd59];
	add.s16 	%rs10, %rs9, 1;
	st.shared.u8 	[%rd59], %rs10;
	xor.b32  	%r180, %r149, -2147483648;
	// inline asm
	bfe.u32 %r179, %r180, %r110, %r111;
	// inline asm
	and.b32  	%r230, %r179, 3;
	shr.u32 	%r231, %r179, 2;
	cvt.u64.u32	%rd60, %r230;
	mul.wide.u32 	%rd61, %r231, 512;
	add.s64 	%rd62, %rd13, %rd61;
	add.s64 	%rd63, %rd62, %rd12;
	add.s64 	%rd64, %rd63, %rd60;
	ld.shared.u8 	%rs11, [%rd64];
	add.s16 	%rs12, %rs11, 1;
	st.shared.u8 	[%rd64], %rs12;
	xor.b32  	%r184, %r150, -2147483648;
	// inline asm
	bfe.u32 %r183, %r184, %r110, %r111;
	// inline asm
	and.b32  	%r232, %r183, 3;
	shr.u32 	%r233, %r183, 2;
	cvt.u64.u32	%rd65, %r232;
	mul.wide.u32 	%rd66, %r233, 512;
	add.s64 	%rd67, %rd13, %rd66;
	add.s64 	%rd68, %rd67, %rd12;
	add.s64 	%rd69, %rd68, %rd65;
	ld.shared.u8 	%rs13, [%rd69];
	add.s16 	%rs14, %rs13, 1;
	st.shared.u8 	[%rd69], %rs14;
	xor.b32  	%r188, %r151, -2147483648;
	// inline asm
	bfe.u32 %r187, %r188, %r110, %r111;
	// inline asm
	and.b32  	%r234, %r187, 3;
	shr.u32 	%r235, %r187, 2;
	cvt.u64.u32	%rd70, %r234;
	mul.wide.u32 	%rd71, %r235, 512;
	add.s64 	%rd72, %rd13, %rd71;
	add.s64 	%rd73, %rd72, %rd12;
	add.s64 	%rd74, %rd73, %rd70;
	ld.shared.u8 	%rs15, [%rd74];
	add.s16 	%rs16, %rs15, 1;
	st.shared.u8 	[%rd74], %rs16;
	xor.b32  	%r192, %r152, -2147483648;
	// inline asm
	bfe.u32 %r191, %r192, %r110, %r111;
	// inline asm
	and.b32  	%r236, %r191, 3;
	shr.u32 	%r237, %r191, 2;
	cvt.u64.u32	%rd75, %r236;
	mul.wide.u32 	%rd76, %r237, 512;
	add.s64 	%rd77, %rd13, %rd76;
	add.s64 	%rd78, %rd77, %rd12;
	add.s64 	%rd79, %rd78, %rd75;
	ld.shared.u8 	%rs17, [%rd79];
	add.s16 	%rs18, %rs17, 1;
	st.shared.u8 	[%rd79], %rs18;
	xor.b32  	%r196, %r153, -2147483648;
	// inline asm
	bfe.u32 %r195, %r196, %r110, %r111;
	// inline asm
	and.b32  	%r238, %r195, 3;
	shr.u32 	%r239, %r195, 2;
	cvt.u64.u32	%rd80, %r238;
	mul.wide.u32 	%rd81, %r239, 512;
	add.s64 	%rd82, %rd13, %rd81;
	add.s64 	%rd83, %rd82, %rd12;
	add.s64 	%rd84, %rd83, %rd80;
	ld.shared.u8 	%rs19, [%rd84];
	add.s16 	%rs20, %rs19, 1;
	st.shared.u8 	[%rd84], %rs20;
	xor.b32  	%r200, %r154, -2147483648;
	// inline asm
	bfe.u32 %r199, %r200, %r110, %r111;
	// inline asm
	and.b32  	%r240, %r199, 3;
	shr.u32 	%r241, %r199, 2;
	cvt.u64.u32	%rd85, %r240;
	mul.wide.u32 	%rd86, %r241, 512;
	add.s64 	%rd87, %rd13, %rd86;
	add.s64 	%rd88, %rd87, %rd12;
	add.s64 	%rd89, %rd88, %rd85;
	ld.shared.u8 	%rs21, [%rd89];
	add.s16 	%rs22, %rs21, 1;
	st.shared.u8 	[%rd89], %rs22;
	xor.b32  	%r204, %r155, -2147483648;
	// inline asm
	bfe.u32 %r203, %r204, %r110, %r111;
	// inline asm
	and.b32  	%r242, %r203, 3;
	shr.u32 	%r243, %r203, 2;
	cvt.u64.u32	%rd90, %r242;
	mul.wide.u32 	%rd91, %r243, 512;
	add.s64 	%rd92, %rd13, %rd91;
	add.s64 	%rd93, %rd92, %rd12;
	add.s64 	%rd94, %rd93, %rd90;
	ld.shared.u8 	%rs23, [%rd94];
	add.s16 	%rs24, %rs23, 1;
	st.shared.u8 	[%rd94], %rs24;
	xor.b32  	%r208, %r156, -2147483648;
	// inline asm
	bfe.u32 %r207, %r208, %r110, %r111;
	// inline asm
	and.b32  	%r244, %r207, 3;
	shr.u32 	%r245, %r207, 2;
	cvt.u64.u32	%rd95, %r244;
	mul.wide.u32 	%rd96, %r245, 512;
	add.s64 	%rd97, %rd13, %rd96;
	add.s64 	%rd98, %rd97, %rd12;
	add.s64 	%rd99, %rd98, %rd95;
	ld.shared.u8 	%rs25, [%rd99];
	add.s16 	%rs26, %rs25, 1;
	st.shared.u8 	[%rd99], %rs26;
	xor.b32  	%r212, %r157, -2147483648;
	// inline asm
	bfe.u32 %r211, %r212, %r110, %r111;
	// inline asm
	and.b32  	%r246, %r211, 3;
	shr.u32 	%r247, %r211, 2;
	cvt.u64.u32	%rd100, %r246;
	mul.wide.u32 	%rd101, %r247, 512;
	add.s64 	%rd102, %rd13, %rd101;
	add.s64 	%rd103, %rd102, %rd12;
	add.s64 	%rd104, %rd103, %rd100;
	ld.shared.u8 	%rs27, [%rd104];
	add.s16 	%rs28, %rs27, 1;
	st.shared.u8 	[%rd104], %rs28;
	xor.b32  	%r216, %r158, -2147483648;
	// inline asm
	bfe.u32 %r215, %r216, %r110, %r111;
	// inline asm
	and.b32  	%r248, %r215, 3;
	shr.u32 	%r249, %r215, 2;
	cvt.u64.u32	%rd105, %r248;
	mul.wide.u32 	%rd106, %r249, 512;
	add.s64 	%rd107, %rd13, %rd106;
	add.s64 	%rd108, %rd107, %rd12;
	add.s64 	%rd109, %rd108, %rd105;
	ld.shared.u8 	%rs29, [%rd109];
	add.s16 	%rs30, %rs29, 1;
	st.shared.u8 	[%rd109], %rs30;
	add.s64 	%rd290, %rd290, 7680;
	add.s32 	%r589, %r589, 1;
	setp.ne.s32	%p6, %r589, 0;
	@%p6 bra 	BB23_7;

	setp.lt.u32	%p1, %r130, 256;
	bar.sync 	0;
	@!%p1 bra 	BB23_10;
	bra.uni 	BB23_9;

BB23_9:
	shr.u32 	%r252, %r130, 5;
	and.b32  	%r253, %r130, 31;
	mul.wide.u32 	%rd110, %r252, 512;
	add.s64 	%rd112, %rd13, %rd110;
	mul.wide.u32 	%rd113, %r253, 4;
	add.s64 	%rd114, %rd112, %rd113;
	ld.shared.v4.u8 	{%rs31, %rs32, %rs33, %rs34}, [%rd114];
	cvt.u32.u16	%r254, %rs34;
	cvt.u32.u16	%r255, %rs33;
	cvt.u32.u16	%r256, %rs32;
	cvt.u32.u16	%r257, %rs31;
	add.s32 	%r258, %r604, %r257;
	add.s32 	%r259, %r603, %r256;
	add.s32 	%r260, %r602, %r255;
	add.s32 	%r261, %r601, %r254;
	ld.shared.v4.u8 	{%rs35, %rs36, %rs37, %rs38}, [%rd114+128];
	cvt.u32.u16	%r262, %rs38;
	cvt.u32.u16	%r263, %rs37;
	cvt.u32.u16	%r264, %rs36;
	cvt.u32.u16	%r265, %rs35;
	add.s32 	%r266, %r258, %r265;
	add.s32 	%r267, %r259, %r264;
	add.s32 	%r268, %r260, %r263;
	add.s32 	%r269, %r261, %r262;
	ld.shared.v4.u8 	{%rs39, %rs40, %rs41, %rs42}, [%rd114+256];
	cvt.u32.u16	%r270, %rs42;
	cvt.u32.u16	%r271, %rs41;
	cvt.u32.u16	%r272, %rs40;
	cvt.u32.u16	%r273, %rs39;
	add.s32 	%r274, %r266, %r273;
	add.s32 	%r275, %r267, %r272;
	add.s32 	%r276, %r268, %r271;
	add.s32 	%r277, %r269, %r270;
	ld.shared.v4.u8 	{%rs43, %rs44, %rs45, %rs46}, [%rd114+384];
	cvt.u32.u16	%r278, %rs46;
	cvt.u32.u16	%r279, %rs45;
	cvt.u32.u16	%r280, %rs44;
	cvt.u32.u16	%r281, %rs43;
	add.s32 	%r604, %r274, %r281;
	add.s32 	%r603, %r275, %r280;
	add.s32 	%r602, %r276, %r279;
	add.s32 	%r601, %r277, %r278;

BB23_10:
	shr.u32 	%r283, %r130, 5;
	add.s32 	%r284, %r283, 4;
	setp.gt.u32	%p7, %r284, 7;
	@%p7 bra 	BB23_12;

	and.b32  	%r287, %r130, 31;
	mul.wide.u32 	%rd115, %r283, 512;
	add.s64 	%rd117, %rd13, %rd115;
	mul.wide.u32 	%rd118, %r287, 4;
	add.s64 	%rd119, %rd117, %rd118;
	ld.shared.v4.u8 	{%rs47, %rs48, %rs49, %rs50}, [%rd119+2048];
	cvt.u32.u16	%r288, %rs50;
	cvt.u32.u16	%r289, %rs49;
	cvt.u32.u16	%r290, %rs48;
	cvt.u32.u16	%r291, %rs47;
	add.s32 	%r292, %r607, %r291;
	add.s32 	%r293, %r606, %r290;
	add.s32 	%r294, %r605, %r289;
	add.s32 	%r295, %r608, %r288;
	ld.shared.v4.u8 	{%rs51, %rs52, %rs53, %rs54}, [%rd119+2176];
	cvt.u32.u16	%r296, %rs54;
	cvt.u32.u16	%r297, %rs53;
	cvt.u32.u16	%r298, %rs52;
	cvt.u32.u16	%r299, %rs51;
	add.s32 	%r300, %r292, %r299;
	add.s32 	%r301, %r293, %r298;
	add.s32 	%r302, %r294, %r297;
	add.s32 	%r303, %r295, %r296;
	ld.shared.v4.u8 	{%rs55, %rs56, %rs57, %rs58}, [%rd119+2304];
	cvt.u32.u16	%r304, %rs58;
	cvt.u32.u16	%r305, %rs57;
	cvt.u32.u16	%r306, %rs56;
	cvt.u32.u16	%r307, %rs55;
	add.s32 	%r308, %r300, %r307;
	add.s32 	%r309, %r301, %r306;
	add.s32 	%r310, %r302, %r305;
	add.s32 	%r311, %r303, %r304;
	ld.shared.v4.u8 	{%rs59, %rs60, %rs61, %rs62}, [%rd119+2432];
	cvt.u32.u16	%r312, %rs62;
	cvt.u32.u16	%r313, %rs61;
	cvt.u32.u16	%r314, %rs60;
	cvt.u32.u16	%r315, %rs59;
	add.s32 	%r607, %r308, %r315;
	add.s32 	%r606, %r309, %r314;
	add.s32 	%r605, %r310, %r313;
	add.s32 	%r608, %r311, %r312;

BB23_12:
	bar.sync 	0;
	mov.u32 	%r317, 0;
	st.shared.u32 	[%rd14], %r317;
	st.shared.u32 	[%rd14+512], %r317;
	st.shared.u32 	[%rd14+1024], %r317;
	st.shared.u32 	[%rd14+1536], %r317;
	st.shared.u32 	[%rd14+2048], %r317;
	st.shared.u32 	[%rd14+2560], %r317;
	st.shared.u32 	[%rd14+3072], %r317;
	st.shared.u32 	[%rd14+3584], %r317;
	add.s32 	%r318, %r20, 34560;
	add.s32 	%r588, %r20, 32640;
	add.s32 	%r587, %r587, 32640;
	add.s32 	%r56, %r20, 1920;
	setp.le.s32	%p8, %r318, %r586;
	mov.u32 	%r598, %r56;
	@%p8 bra 	BB23_6;

BB23_13:
	mov.u32 	%r595, %r598;
	add.s32 	%r597, %r595, 1920;
	setp.gt.s32	%p9, %r597, %r586;
	@%p9 bra 	BB23_16;

	mov.u32 	%r596, %r595;

BB23_15:
	mov.u32 	%r593, %r597;
	mov.u32 	%r68, %r596;
	mov.u32 	%r596, %r593;
	cvt.s64.s32	%rd138, %r130;
	cvt.s64.s32	%rd139, %r68;
	add.s64 	%rd140, %rd138, %rd139;
	shl.b64 	%rd141, %rd140, 2;
	add.s64 	%rd123, %rd10, %rd141;
	// inline asm
	ld.global.nc.u32 %r319, [%rd123];
	// inline asm
	add.s32 	%r334, %r130, 128;
	cvt.s64.s32	%rd142, %r334;
	add.s64 	%rd143, %rd142, %rd139;
	shl.b64 	%rd144, %rd143, 2;
	add.s64 	%rd124, %rd10, %rd144;
	// inline asm
	ld.global.nc.u32 %r320, [%rd124];
	// inline asm
	add.s32 	%r335, %r130, 256;
	cvt.s64.s32	%rd145, %r335;
	add.s64 	%rd146, %rd145, %rd139;
	shl.b64 	%rd147, %rd146, 2;
	add.s64 	%rd125, %rd10, %rd147;
	// inline asm
	ld.global.nc.u32 %r321, [%rd125];
	// inline asm
	add.s32 	%r336, %r130, 384;
	cvt.s64.s32	%rd148, %r336;
	add.s64 	%rd149, %rd148, %rd139;
	shl.b64 	%rd150, %rd149, 2;
	add.s64 	%rd126, %rd10, %rd150;
	// inline asm
	ld.global.nc.u32 %r322, [%rd126];
	// inline asm
	add.s32 	%r337, %r130, 512;
	cvt.s64.s32	%rd151, %r337;
	add.s64 	%rd152, %rd151, %rd139;
	shl.b64 	%rd153, %rd152, 2;
	add.s64 	%rd127, %rd10, %rd153;
	// inline asm
	ld.global.nc.u32 %r323, [%rd127];
	// inline asm
	add.s32 	%r338, %r130, 640;
	cvt.s64.s32	%rd154, %r338;
	add.s64 	%rd155, %rd154, %rd139;
	shl.b64 	%rd156, %rd155, 2;
	add.s64 	%rd128, %rd10, %rd156;
	// inline asm
	ld.global.nc.u32 %r324, [%rd128];
	// inline asm
	add.s32 	%r339, %r130, 768;
	cvt.s64.s32	%rd157, %r339;
	add.s64 	%rd158, %rd157, %rd139;
	shl.b64 	%rd159, %rd158, 2;
	add.s64 	%rd129, %rd10, %rd159;
	// inline asm
	ld.global.nc.u32 %r325, [%rd129];
	// inline asm
	add.s32 	%r340, %r130, 896;
	cvt.s64.s32	%rd160, %r340;
	add.s64 	%rd161, %rd160, %rd139;
	shl.b64 	%rd162, %rd161, 2;
	add.s64 	%rd130, %rd10, %rd162;
	// inline asm
	ld.global.nc.u32 %r326, [%rd130];
	// inline asm
	add.s32 	%r341, %r130, 1024;
	cvt.s64.s32	%rd163, %r341;
	add.s64 	%rd164, %rd163, %rd139;
	shl.b64 	%rd165, %rd164, 2;
	add.s64 	%rd131, %rd10, %rd165;
	// inline asm
	ld.global.nc.u32 %r327, [%rd131];
	// inline asm
	add.s32 	%r342, %r130, 1152;
	cvt.s64.s32	%rd166, %r342;
	add.s64 	%rd167, %rd166, %rd139;
	shl.b64 	%rd168, %rd167, 2;
	add.s64 	%rd132, %rd10, %rd168;
	// inline asm
	ld.global.nc.u32 %r328, [%rd132];
	// inline asm
	add.s32 	%r343, %r130, 1280;
	cvt.s64.s32	%rd169, %r343;
	add.s64 	%rd170, %rd169, %rd139;
	shl.b64 	%rd171, %rd170, 2;
	add.s64 	%rd133, %rd10, %rd171;
	// inline asm
	ld.global.nc.u32 %r329, [%rd133];
	// inline asm
	add.s32 	%r344, %r130, 1408;
	cvt.s64.s32	%rd172, %r344;
	add.s64 	%rd173, %rd172, %rd139;
	shl.b64 	%rd174, %rd173, 2;
	add.s64 	%rd134, %rd10, %rd174;
	// inline asm
	ld.global.nc.u32 %r330, [%rd134];
	// inline asm
	add.s32 	%r345, %r130, 1536;
	cvt.s64.s32	%rd175, %r345;
	add.s64 	%rd176, %rd175, %rd139;
	shl.b64 	%rd177, %rd176, 2;
	add.s64 	%rd135, %rd10, %rd177;
	// inline asm
	ld.global.nc.u32 %r331, [%rd135];
	// inline asm
	add.s32 	%r346, %r130, 1664;
	cvt.s64.s32	%rd178, %r346;
	add.s64 	%rd179, %rd178, %rd139;
	shl.b64 	%rd180, %rd179, 2;
	add.s64 	%rd136, %rd10, %rd180;
	// inline asm
	ld.global.nc.u32 %r332, [%rd136];
	// inline asm
	add.s32 	%r347, %r130, 1792;
	cvt.s64.s32	%rd181, %r347;
	add.s64 	%rd182, %rd181, %rd139;
	shl.b64 	%rd183, %rd182, 2;
	add.s64 	%rd137, %rd10, %rd183;
	// inline asm
	ld.global.nc.u32 %r333, [%rd137];
	// inline asm
	bar.sync 	0;
	xor.b32  	%r349, %r319, -2147483648;
	// inline asm
	bfe.u32 %r348, %r349, %r110, %r111;
	// inline asm
	and.b32  	%r408, %r348, 3;
	shr.u32 	%r409, %r348, 2;
	cvt.u64.u32	%rd184, %r408;
	mul.wide.u32 	%rd185, %r409, 512;
	add.s64 	%rd187, %rd13, %rd185;
	add.s64 	%rd189, %rd187, %rd12;
	add.s64 	%rd190, %rd189, %rd184;
	ld.shared.u8 	%rs63, [%rd190];
	add.s16 	%rs64, %rs63, 1;
	st.shared.u8 	[%rd190], %rs64;
	xor.b32  	%r353, %r320, -2147483648;
	// inline asm
	bfe.u32 %r352, %r353, %r110, %r111;
	// inline asm
	and.b32  	%r410, %r352, 3;
	shr.u32 	%r411, %r352, 2;
	cvt.u64.u32	%rd191, %r410;
	mul.wide.u32 	%rd192, %r411, 512;
	add.s64 	%rd193, %rd13, %rd192;
	add.s64 	%rd194, %rd193, %rd12;
	add.s64 	%rd195, %rd194, %rd191;
	ld.shared.u8 	%rs65, [%rd195];
	add.s16 	%rs66, %rs65, 1;
	st.shared.u8 	[%rd195], %rs66;
	xor.b32  	%r357, %r321, -2147483648;
	// inline asm
	bfe.u32 %r356, %r357, %r110, %r111;
	// inline asm
	and.b32  	%r412, %r356, 3;
	shr.u32 	%r413, %r356, 2;
	cvt.u64.u32	%rd196, %r412;
	mul.wide.u32 	%rd197, %r413, 512;
	add.s64 	%rd198, %rd13, %rd197;
	add.s64 	%rd199, %rd198, %rd12;
	add.s64 	%rd200, %rd199, %rd196;
	ld.shared.u8 	%rs67, [%rd200];
	add.s16 	%rs68, %rs67, 1;
	st.shared.u8 	[%rd200], %rs68;
	xor.b32  	%r361, %r322, -2147483648;
	// inline asm
	bfe.u32 %r360, %r361, %r110, %r111;
	// inline asm
	and.b32  	%r414, %r360, 3;
	shr.u32 	%r415, %r360, 2;
	cvt.u64.u32	%rd201, %r414;
	mul.wide.u32 	%rd202, %r415, 512;
	add.s64 	%rd203, %rd13, %rd202;
	add.s64 	%rd204, %rd203, %rd12;
	add.s64 	%rd205, %rd204, %rd201;
	ld.shared.u8 	%rs69, [%rd205];
	add.s16 	%rs70, %rs69, 1;
	st.shared.u8 	[%rd205], %rs70;
	xor.b32  	%r365, %r323, -2147483648;
	// inline asm
	bfe.u32 %r364, %r365, %r110, %r111;
	// inline asm
	and.b32  	%r416, %r364, 3;
	shr.u32 	%r417, %r364, 2;
	cvt.u64.u32	%rd206, %r416;
	mul.wide.u32 	%rd207, %r417, 512;
	add.s64 	%rd208, %rd13, %rd207;
	add.s64 	%rd209, %rd208, %rd12;
	add.s64 	%rd210, %rd209, %rd206;
	ld.shared.u8 	%rs71, [%rd210];
	add.s16 	%rs72, %rs71, 1;
	st.shared.u8 	[%rd210], %rs72;
	xor.b32  	%r369, %r324, -2147483648;
	// inline asm
	bfe.u32 %r368, %r369, %r110, %r111;
	// inline asm
	and.b32  	%r418, %r368, 3;
	shr.u32 	%r419, %r368, 2;
	cvt.u64.u32	%rd211, %r418;
	mul.wide.u32 	%rd212, %r419, 512;
	add.s64 	%rd213, %rd13, %rd212;
	add.s64 	%rd214, %rd213, %rd12;
	add.s64 	%rd215, %rd214, %rd211;
	ld.shared.u8 	%rs73, [%rd215];
	add.s16 	%rs74, %rs73, 1;
	st.shared.u8 	[%rd215], %rs74;
	xor.b32  	%r373, %r325, -2147483648;
	// inline asm
	bfe.u32 %r372, %r373, %r110, %r111;
	// inline asm
	and.b32  	%r420, %r372, 3;
	shr.u32 	%r421, %r372, 2;
	cvt.u64.u32	%rd216, %r420;
	mul.wide.u32 	%rd217, %r421, 512;
	add.s64 	%rd218, %rd13, %rd217;
	add.s64 	%rd219, %rd218, %rd12;
	add.s64 	%rd220, %rd219, %rd216;
	ld.shared.u8 	%rs75, [%rd220];
	add.s16 	%rs76, %rs75, 1;
	st.shared.u8 	[%rd220], %rs76;
	xor.b32  	%r377, %r326, -2147483648;
	// inline asm
	bfe.u32 %r376, %r377, %r110, %r111;
	// inline asm
	and.b32  	%r422, %r376, 3;
	shr.u32 	%r423, %r376, 2;
	cvt.u64.u32	%rd221, %r422;
	mul.wide.u32 	%rd222, %r423, 512;
	add.s64 	%rd223, %rd13, %rd222;
	add.s64 	%rd224, %rd223, %rd12;
	add.s64 	%rd225, %rd224, %rd221;
	ld.shared.u8 	%rs77, [%rd225];
	add.s16 	%rs78, %rs77, 1;
	st.shared.u8 	[%rd225], %rs78;
	xor.b32  	%r381, %r327, -2147483648;
	// inline asm
	bfe.u32 %r380, %r381, %r110, %r111;
	// inline asm
	and.b32  	%r424, %r380, 3;
	shr.u32 	%r425, %r380, 2;
	cvt.u64.u32	%rd226, %r424;
	mul.wide.u32 	%rd227, %r425, 512;
	add.s64 	%rd228, %rd13, %rd227;
	add.s64 	%rd229, %rd228, %rd12;
	add.s64 	%rd230, %rd229, %rd226;
	ld.shared.u8 	%rs79, [%rd230];
	add.s16 	%rs80, %rs79, 1;
	st.shared.u8 	[%rd230], %rs80;
	xor.b32  	%r385, %r328, -2147483648;
	// inline asm
	bfe.u32 %r384, %r385, %r110, %r111;
	// inline asm
	and.b32  	%r426, %r384, 3;
	shr.u32 	%r427, %r384, 2;
	cvt.u64.u32	%rd231, %r426;
	mul.wide.u32 	%rd232, %r427, 512;
	add.s64 	%rd233, %rd13, %rd232;
	add.s64 	%rd234, %rd233, %rd12;
	add.s64 	%rd235, %rd234, %rd231;
	ld.shared.u8 	%rs81, [%rd235];
	add.s16 	%rs82, %rs81, 1;
	st.shared.u8 	[%rd235], %rs82;
	xor.b32  	%r389, %r329, -2147483648;
	// inline asm
	bfe.u32 %r388, %r389, %r110, %r111;
	// inline asm
	and.b32  	%r428, %r388, 3;
	shr.u32 	%r429, %r388, 2;
	cvt.u64.u32	%rd236, %r428;
	mul.wide.u32 	%rd237, %r429, 512;
	add.s64 	%rd238, %rd13, %rd237;
	add.s64 	%rd239, %rd238, %rd12;
	add.s64 	%rd240, %rd239, %rd236;
	ld.shared.u8 	%rs83, [%rd240];
	add.s16 	%rs84, %rs83, 1;
	st.shared.u8 	[%rd240], %rs84;
	xor.b32  	%r393, %r330, -2147483648;
	// inline asm
	bfe.u32 %r392, %r393, %r110, %r111;
	// inline asm
	and.b32  	%r430, %r392, 3;
	shr.u32 	%r431, %r392, 2;
	cvt.u64.u32	%rd241, %r430;
	mul.wide.u32 	%rd242, %r431, 512;
	add.s64 	%rd243, %rd13, %rd242;
	add.s64 	%rd244, %rd243, %rd12;
	add.s64 	%rd245, %rd244, %rd241;
	ld.shared.u8 	%rs85, [%rd245];
	add.s16 	%rs86, %rs85, 1;
	st.shared.u8 	[%rd245], %rs86;
	xor.b32  	%r397, %r331, -2147483648;
	// inline asm
	bfe.u32 %r396, %r397, %r110, %r111;
	// inline asm
	and.b32  	%r432, %r396, 3;
	shr.u32 	%r433, %r396, 2;
	cvt.u64.u32	%rd246, %r432;
	mul.wide.u32 	%rd247, %r433, 512;
	add.s64 	%rd248, %rd13, %rd247;
	add.s64 	%rd249, %rd248, %rd12;
	add.s64 	%rd250, %rd249, %rd246;
	ld.shared.u8 	%rs87, [%rd250];
	add.s16 	%rs88, %rs87, 1;
	st.shared.u8 	[%rd250], %rs88;
	xor.b32  	%r401, %r332, -2147483648;
	// inline asm
	bfe.u32 %r400, %r401, %r110, %r111;
	// inline asm
	and.b32  	%r434, %r400, 3;
	shr.u32 	%r435, %r400, 2;
	cvt.u64.u32	%rd251, %r434;
	mul.wide.u32 	%rd252, %r435, 512;
	add.s64 	%rd253, %rd13, %rd252;
	add.s64 	%rd254, %rd253, %rd12;
	add.s64 	%rd255, %rd254, %rd251;
	ld.shared.u8 	%rs89, [%rd255];
	add.s16 	%rs90, %rs89, 1;
	st.shared.u8 	[%rd255], %rs90;
	xor.b32  	%r405, %r333, -2147483648;
	// inline asm
	bfe.u32 %r404, %r405, %r110, %r111;
	// inline asm
	and.b32  	%r436, %r404, 3;
	shr.u32 	%r437, %r404, 2;
	cvt.u64.u32	%rd256, %r436;
	mul.wide.u32 	%rd257, %r437, 512;
	add.s64 	%rd258, %rd13, %rd257;
	add.s64 	%rd259, %rd258, %rd12;
	add.s64 	%rd260, %rd259, %rd256;
	ld.shared.u8 	%rs91, [%rd260];
	add.s16 	%rs92, %rs91, 1;
	st.shared.u8 	[%rd260], %rs92;
	add.s32 	%r597, %r596, 1920;
	setp.le.s32	%p10, %r597, %r586;
	mov.u32 	%r595, %r596;
	@%p10 bra 	BB23_15;

BB23_16:
	add.s32 	%r600, %r130, %r595;
	setp.ge.s32	%p11, %r600, %r586;
	@%p11 bra 	BB23_19;

	add.s32 	%r440, %r130, %r595;
	mul.wide.s32 	%rd261, %r440, 4;
	add.s64 	%rd291, %rd10, %rd261;
	cvt.u64.u32	%rd5, %r130;
	shl.b64 	%rd267, %rd5, 2;

BB23_18:
	// inline asm
	ld.global.nc.u32 %r441, [%rd291];
	// inline asm
	xor.b32  	%r443, %r441, -2147483648;
	// inline asm
	bfe.u32 %r442, %r443, %r110, %r111;
	// inline asm
	and.b32  	%r446, %r442, 3;
	shr.u32 	%r447, %r442, 2;
	cvt.u64.u32	%rd263, %r446;
	mul.wide.u32 	%rd264, %r447, 512;
	add.s64 	%rd266, %rd13, %rd264;
	add.s64 	%rd268, %rd266, %rd267;
	add.s64 	%rd269, %rd268, %rd263;
	ld.shared.u8 	%rs93, [%rd269];
	add.s16 	%rs94, %rs93, 1;
	st.shared.u8 	[%rd269], %rs94;
	add.s64 	%rd291, %rd291, 512;
	add.s32 	%r600, %r600, 128;
	setp.lt.s32	%p12, %r600, %r586;
	@%p12 bra 	BB23_18;

BB23_19:
	bar.sync 	0;
	setp.gt.u32	%p13, %r130, 255;
	@%p13 bra 	BB23_21;

	shr.u32 	%r450, %r130, 5;
	and.b32  	%r451, %r130, 31;
	mul.wide.u32 	%rd270, %r450, 512;
	add.s64 	%rd272, %rd13, %rd270;
	mul.wide.u32 	%rd273, %r451, 4;
	add.s64 	%rd274, %rd272, %rd273;
	ld.shared.v4.u8 	{%rs95, %rs96, %rs97, %rs98}, [%rd274];
	cvt.u32.u16	%r452, %rs98;
	cvt.u32.u16	%r453, %rs97;
	cvt.u32.u16	%r454, %rs96;
	cvt.u32.u16	%r455, %rs95;
	add.s32 	%r456, %r604, %r455;
	add.s32 	%r457, %r603, %r454;
	add.s32 	%r458, %r602, %r453;
	add.s32 	%r459, %r601, %r452;
	ld.shared.v4.u8 	{%rs99, %rs100, %rs101, %rs102}, [%rd274+128];
	cvt.u32.u16	%r460, %rs102;
	cvt.u32.u16	%r461, %rs101;
	cvt.u32.u16	%r462, %rs100;
	cvt.u32.u16	%r463, %rs99;
	add.s32 	%r464, %r456, %r463;
	add.s32 	%r465, %r457, %r462;
	add.s32 	%r466, %r458, %r461;
	add.s32 	%r467, %r459, %r460;
	ld.shared.v4.u8 	{%rs103, %rs104, %rs105, %rs106}, [%rd274+256];
	cvt.u32.u16	%r468, %rs106;
	cvt.u32.u16	%r469, %rs105;
	cvt.u32.u16	%r470, %rs104;
	cvt.u32.u16	%r471, %rs103;
	add.s32 	%r472, %r464, %r471;
	add.s32 	%r473, %r465, %r470;
	add.s32 	%r474, %r466, %r469;
	add.s32 	%r475, %r467, %r468;
	ld.shared.v4.u8 	{%rs107, %rs108, %rs109, %rs110}, [%rd274+384];
	cvt.u32.u16	%r476, %rs110;
	cvt.u32.u16	%r477, %rs109;
	cvt.u32.u16	%r478, %rs108;
	cvt.u32.u16	%r479, %rs107;
	add.s32 	%r604, %r472, %r479;
	add.s32 	%r603, %r473, %r478;
	add.s32 	%r602, %r474, %r477;
	add.s32 	%r601, %r475, %r476;

BB23_21:
	shr.u32 	%r481, %r130, 5;
	add.s32 	%r98, %r481, 4;
	setp.gt.u32	%p14, %r98, 7;
	@%p14 bra 	BB23_23;

	and.b32  	%r484, %r130, 31;
	mul.wide.u32 	%rd275, %r481, 512;
	add.s64 	%rd277, %rd13, %rd275;
	mul.wide.u32 	%rd278, %r484, 4;
	add.s64 	%rd279, %rd277, %rd278;
	ld.shared.v4.u8 	{%rs111, %rs112, %rs113, %rs114}, [%rd279+2048];
	cvt.u32.u16	%r485, %rs114;
	cvt.u32.u16	%r486, %rs113;
	cvt.u32.u16	%r487, %rs112;
	cvt.u32.u16	%r488, %rs111;
	add.s32 	%r489, %r607, %r488;
	add.s32 	%r490, %r606, %r487;
	add.s32 	%r491, %r605, %r486;
	add.s32 	%r492, %r608, %r485;
	ld.shared.v4.u8 	{%rs115, %rs116, %rs117, %rs118}, [%rd279+2176];
	cvt.u32.u16	%r493, %rs118;
	cvt.u32.u16	%r494, %rs117;
	cvt.u32.u16	%r495, %rs116;
	cvt.u32.u16	%r496, %rs115;
	add.s32 	%r497, %r489, %r496;
	add.s32 	%r498, %r490, %r495;
	add.s32 	%r499, %r491, %r494;
	add.s32 	%r500, %r492, %r493;
	ld.shared.v4.u8 	{%rs119, %rs120, %rs121, %rs122}, [%rd279+2304];
	cvt.u32.u16	%r501, %rs122;
	cvt.u32.u16	%r502, %rs121;
	cvt.u32.u16	%r503, %rs120;
	cvt.u32.u16	%r504, %rs119;
	add.s32 	%r505, %r497, %r504;
	add.s32 	%r506, %r498, %r503;
	add.s32 	%r507, %r499, %r502;
	add.s32 	%r508, %r500, %r501;
	ld.shared.v4.u8 	{%rs123, %rs124, %rs125, %rs126}, [%rd279+2432];
	cvt.u32.u16	%r509, %rs126;
	cvt.u32.u16	%r510, %rs125;
	cvt.u32.u16	%r511, %rs124;
	cvt.u32.u16	%r512, %rs123;
	add.s32 	%r607, %r505, %r512;
	add.s32 	%r606, %r506, %r511;
	add.s32 	%r605, %r507, %r510;
	add.s32 	%r608, %r508, %r509;

BB23_23:
	setp.lt.u32	%p2, %r130, 256;
	and.b32  	%r513, %r130, 31;
	cvt.u64.u32	%rd8, %r513;
	bar.sync 	0;
	shr.u32 	%r514, %r130, 3;
	and.b32  	%r515, %r514, 536870908;
	mul.wide.u32 	%rd280, %r515, 132;
	add.s64 	%rd282, %rd13, %rd280;
	shl.b64 	%rd283, %rd8, 2;
	add.s64 	%rd9, %rd282, %rd283;
	@!%p2 bra 	BB23_25;
	bra.uni 	BB23_24;

BB23_24:
	st.shared.u32 	[%rd9], %r604;
	st.shared.u32 	[%rd9+132], %r603;
	st.shared.u32 	[%rd9+264], %r602;
	st.shared.u32 	[%rd9+396], %r601;

BB23_25:
	@%p14 bra 	BB23_27;

	st.shared.u32 	[%rd9+2112], %r607;
	st.shared.u32 	[%rd9+2244], %r606;
	st.shared.u32 	[%rd9+2376], %r605;
	st.shared.u32 	[%rd9+2508], %r608;

BB23_27:
	bar.sync 	0;
	setp.gt.u32	%p16, %r130, 31;
	@%p16 bra 	BB23_29;

	mul.wide.u32 	%rd284, %r130, 132;
	add.s64 	%rd286, %rd13, %rd284;
	ld.shared.u32 	%r519, [%rd286+4];
	ld.shared.u32 	%r520, [%rd286];
	add.s32 	%r521, %r519, %r520;
	ld.shared.u32 	%r522, [%rd286+8];
	add.s32 	%r523, %r521, %r522;
	ld.shared.u32 	%r524, [%rd286+12];
	add.s32 	%r525, %r523, %r524;
	ld.shared.u32 	%r526, [%rd286+16];
	add.s32 	%r527, %r525, %r526;
	ld.shared.u32 	%r528, [%rd286+20];
	add.s32 	%r529, %r527, %r528;
	ld.shared.u32 	%r530, [%rd286+24];
	add.s32 	%r531, %r529, %r530;
	ld.shared.u32 	%r532, [%rd286+28];
	add.s32 	%r533, %r531, %r532;
	ld.shared.u32 	%r534, [%rd286+32];
	add.s32 	%r535, %r533, %r534;
	ld.shared.u32 	%r536, [%rd286+36];
	add.s32 	%r537, %r535, %r536;
	ld.shared.u32 	%r538, [%rd286+40];
	add.s32 	%r539, %r537, %r538;
	ld.shared.u32 	%r540, [%rd286+44];
	add.s32 	%r541, %r539, %r540;
	ld.shared.u32 	%r542, [%rd286+48];
	add.s32 	%r543, %r541, %r542;
	ld.shared.u32 	%r544, [%rd286+52];
	add.s32 	%r545, %r543, %r544;
	ld.shared.u32 	%r546, [%rd286+56];
	add.s32 	%r547, %r545, %r546;
	ld.shared.u32 	%r548, [%rd286+60];
	add.s32 	%r549, %r547, %r548;
	ld.shared.u32 	%r550, [%rd286+64];
	add.s32 	%r551, %r549, %r550;
	ld.shared.u32 	%r552, [%rd286+68];
	add.s32 	%r553, %r551, %r552;
	ld.shared.u32 	%r554, [%rd286+72];
	add.s32 	%r555, %r553, %r554;
	ld.shared.u32 	%r556, [%rd286+76];
	add.s32 	%r557, %r555, %r556;
	ld.shared.u32 	%r558, [%rd286+80];
	add.s32 	%r559, %r557, %r558;
	ld.shared.u32 	%r560, [%rd286+84];
	add.s32 	%r561, %r559, %r560;
	ld.shared.u32 	%r562, [%rd286+88];
	add.s32 	%r563, %r561, %r562;
	ld.shared.u32 	%r564, [%rd286+92];
	add.s32 	%r565, %r563, %r564;
	ld.shared.u32 	%r566, [%rd286+96];
	add.s32 	%r567, %r565, %r566;
	ld.shared.u32 	%r568, [%rd286+100];
	add.s32 	%r569, %r567, %r568;
	ld.shared.u32 	%r570, [%rd286+104];
	add.s32 	%r571, %r569, %r570;
	ld.shared.u32 	%r572, [%rd286+108];
	add.s32 	%r573, %r571, %r572;
	ld.shared.u32 	%r574, [%rd286+112];
	add.s32 	%r575, %r573, %r574;
	ld.shared.u32 	%r576, [%rd286+116];
	add.s32 	%r577, %r575, %r576;
	ld.shared.u32 	%r578, [%rd286+120];
	add.s32 	%r579, %r577, %r578;
	ld.shared.u32 	%r580, [%rd286+124];
	add.s32 	%r609, %r579, %r580;

BB23_29:
	@%p16 bra 	BB23_31;

	mov.u32 	%r582, %nctaid.x;
	mad.lo.s32 	%r585, %r582, %r130, %r1;
	cvta.to.global.u64 	%rd287, %rd11;
	mul.wide.u32 	%rd288, %r585, 4;
	add.s64 	%rd289, %rd287, %rd288;
	st.global.u32 	[%rd289], %r609;

BB23_31:
	ret;
}

	// .globl	_ZN6thrust6system4cuda6detail4cub_28DeviceRadixSortUpsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE19PtxAltUpsweepPolicyELb0EiiEEvPT1_PT2_SA_iibNS3_13GridEvenShareISA_EE
.visible .entry _ZN6thrust6system4cuda6detail4cub_28DeviceRadixSortUpsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE19PtxAltUpsweepPolicyELb0EiiEEvPT1_PT2_SA_iibNS3_13GridEvenShareISA_EE(
	.param .u64 _ZN6thrust6system4cuda6detail4cub_28DeviceRadixSortUpsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE19PtxAltUpsweepPolicyELb0EiiEEvPT1_PT2_SA_iibNS3_13GridEvenShareISA_EE_param_0,
	.param .u64 _ZN6thrust6system4cuda6detail4cub_28DeviceRadixSortUpsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE19PtxAltUpsweepPolicyELb0EiiEEvPT1_PT2_SA_iibNS3_13GridEvenShareISA_EE_param_1,
	.param .u32 _ZN6thrust6system4cuda6detail4cub_28DeviceRadixSortUpsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE19PtxAltUpsweepPolicyELb0EiiEEvPT1_PT2_SA_iibNS3_13GridEvenShareISA_EE_param_2,
	.param .u32 _ZN6thrust6system4cuda6detail4cub_28DeviceRadixSortUpsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE19PtxAltUpsweepPolicyELb0EiiEEvPT1_PT2_SA_iibNS3_13GridEvenShareISA_EE_param_3,
	.param .u32 _ZN6thrust6system4cuda6detail4cub_28DeviceRadixSortUpsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE19PtxAltUpsweepPolicyELb0EiiEEvPT1_PT2_SA_iibNS3_13GridEvenShareISA_EE_param_4,
	.param .u8 _ZN6thrust6system4cuda6detail4cub_28DeviceRadixSortUpsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE19PtxAltUpsweepPolicyELb0EiiEEvPT1_PT2_SA_iibNS3_13GridEvenShareISA_EE_param_5,
	.param .align 4 .b8 _ZN6thrust6system4cuda6detail4cub_28DeviceRadixSortUpsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE19PtxAltUpsweepPolicyELb0EiiEEvPT1_PT2_SA_iibNS3_13GridEvenShareISA_EE_param_6[36]
)
.maxntid 128, 1, 1
{
	.reg .pred 	%p<15>;
	.reg .b16 	%rs<95>;
	.reg .b32 	%r<508>;
	.reg .b64 	%rd<282>;
	// demoted variable
	.shared .align 4 .b8 _ZN6thrust6system4cuda6detail4cub_28DeviceRadixSortUpsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE19PtxAltUpsweepPolicyELb0EiiEEvPT1_PT2_SA_iibNS3_13GridEvenShareISA_EE$__cuda_local_var_106522_74_non_const_temp_storage[2112];

	ld.param.u64 	%rd12, [_ZN6thrust6system4cuda6detail4cub_28DeviceRadixSortUpsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE19PtxAltUpsweepPolicyELb0EiiEEvPT1_PT2_SA_iibNS3_13GridEvenShareISA_EE_param_0];
	ld.param.u64 	%rd13, [_ZN6thrust6system4cuda6detail4cub_28DeviceRadixSortUpsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE19PtxAltUpsweepPolicyELb0EiiEEvPT1_PT2_SA_iibNS3_13GridEvenShareISA_EE_param_1];
	ld.param.u32 	%r84, [_ZN6thrust6system4cuda6detail4cub_28DeviceRadixSortUpsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE19PtxAltUpsweepPolicyELb0EiiEEvPT1_PT2_SA_iibNS3_13GridEvenShareISA_EE_param_3];
	ld.param.u32 	%r85, [_ZN6thrust6system4cuda6detail4cub_28DeviceRadixSortUpsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE19PtxAltUpsweepPolicyELb0EiiEEvPT1_PT2_SA_iibNS3_13GridEvenShareISA_EE_param_4];
	ld.param.u32 	%r94, [_ZN6thrust6system4cuda6detail4cub_28DeviceRadixSortUpsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE19PtxAltUpsweepPolicyELb0EiiEEvPT1_PT2_SA_iibNS3_13GridEvenShareISA_EE_param_6+32];
	ld.param.u32 	%r93, [_ZN6thrust6system4cuda6detail4cub_28DeviceRadixSortUpsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE19PtxAltUpsweepPolicyELb0EiiEEvPT1_PT2_SA_iibNS3_13GridEvenShareISA_EE_param_6+28];
	ld.param.u32 	%r91, [_ZN6thrust6system4cuda6detail4cub_28DeviceRadixSortUpsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE19PtxAltUpsweepPolicyELb0EiiEEvPT1_PT2_SA_iibNS3_13GridEvenShareISA_EE_param_6+20];
	ld.param.u32 	%r90, [_ZN6thrust6system4cuda6detail4cub_28DeviceRadixSortUpsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE19PtxAltUpsweepPolicyELb0EiiEEvPT1_PT2_SA_iibNS3_13GridEvenShareISA_EE_param_6+16];
	ld.param.u32 	%r89, [_ZN6thrust6system4cuda6detail4cub_28DeviceRadixSortUpsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE19PtxAltUpsweepPolicyELb0EiiEEvPT1_PT2_SA_iibNS3_13GridEvenShareISA_EE_param_6+12];
	ld.param.u32 	%r88, [_ZN6thrust6system4cuda6detail4cub_28DeviceRadixSortUpsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE19PtxAltUpsweepPolicyELb0EiiEEvPT1_PT2_SA_iibNS3_13GridEvenShareISA_EE_param_6+8];
	ld.param.u32 	%r86, [_ZN6thrust6system4cuda6detail4cub_28DeviceRadixSortUpsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE19PtxAltUpsweepPolicyELb0EiiEEvPT1_PT2_SA_iibNS3_13GridEvenShareISA_EE_param_6];
	ld.param.u32 	%r87, [_ZN6thrust6system4cuda6detail4cub_28DeviceRadixSortUpsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE19PtxAltUpsweepPolicyELb0EiiEEvPT1_PT2_SA_iibNS3_13GridEvenShareISA_EE_param_6+4];
	mov.u32 	%r1, %ctaid.x;
	setp.lt.s32	%p3, %r1, %r87;
	@%p3 bra 	BB24_3;
	bra.uni 	BB24_1;

BB24_3:
	mul.lo.s32 	%r501, %r1, %r88;
	add.s32 	%r488, %r501, %r88;
	bra.uni 	BB24_4;

BB24_1:
	mov.u32 	%r488, %r94;
	mov.u32 	%r501, %r93;
	setp.ge.s32	%p4, %r1, %r86;
	@%p4 bra 	BB24_4;

	mad.lo.s32 	%r501, %r1, %r89, %r90;
	add.s32 	%r95, %r501, %r89;
	min.s32 	%r488, %r95, %r91;

BB24_4:
	mov.u32 	%r8, %r501;
	mov.u32 	%r100, %tid.x;
	mul.wide.u32 	%rd14, %r100, 4;
	mov.u64 	%rd15, _ZN6thrust6system4cuda6detail4cub_28DeviceRadixSortUpsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE19PtxAltUpsweepPolicyELb0EiiEEvPT1_PT2_SA_iibNS3_13GridEvenShareISA_EE$__cuda_local_var_106522_74_non_const_temp_storage;
	add.s64 	%rd16, %rd15, %rd14;
	mov.u32 	%r506, 0;
	st.shared.u32 	[%rd16], %r506;
	st.shared.u32 	[%rd16+512], %r506;
	st.shared.u32 	[%rd16+1024], %r506;
	st.shared.u32 	[%rd16+1536], %r506;
	add.s32 	%r101, %r8, 32640;
	setp.gt.s32	%p5, %r101, %r488;
	mov.u32 	%r505, %r506;
	mov.u32 	%r504, %r506;
	mov.u32 	%r503, %r506;
	mov.u32 	%r500, %r8;
	@%p5 bra 	BB24_11;

	add.s32 	%r490, %r8, 30720;
	mov.u32 	%r506, 0;
	mov.u32 	%r505, %r506;
	mov.u32 	%r504, %r506;
	mov.u32 	%r503, %r506;
	mov.u32 	%r489, %r506;

BB24_6:
	add.s32 	%r108, %r8, %r489;
	mul.wide.s32 	%rd17, %r100, 4;
	add.s64 	%rd18, %rd12, %rd17;
	mul.wide.s32 	%rd19, %r108, 4;
	add.s64 	%rd280, %rd18, %rd19;
	mov.u32 	%r491, -17;

BB24_7:
	// inline asm
	ld.global.nc.u32 %r110, [%rd280];
	// inline asm
	add.s64 	%rd21, %rd280, 512;
	// inline asm
	ld.global.nc.u32 %r111, [%rd21];
	// inline asm
	add.s64 	%rd22, %rd280, 1024;
	// inline asm
	ld.global.nc.u32 %r112, [%rd22];
	// inline asm
	add.s64 	%rd23, %rd280, 1536;
	// inline asm
	ld.global.nc.u32 %r113, [%rd23];
	// inline asm
	add.s64 	%rd24, %rd280, 2048;
	// inline asm
	ld.global.nc.u32 %r114, [%rd24];
	// inline asm
	add.s64 	%rd25, %rd280, 2560;
	// inline asm
	ld.global.nc.u32 %r115, [%rd25];
	// inline asm
	add.s64 	%rd26, %rd280, 3072;
	// inline asm
	ld.global.nc.u32 %r116, [%rd26];
	// inline asm
	add.s64 	%rd27, %rd280, 3584;
	// inline asm
	ld.global.nc.u32 %r117, [%rd27];
	// inline asm
	add.s64 	%rd28, %rd280, 4096;
	// inline asm
	ld.global.nc.u32 %r118, [%rd28];
	// inline asm
	add.s64 	%rd29, %rd280, 4608;
	// inline asm
	ld.global.nc.u32 %r119, [%rd29];
	// inline asm
	add.s64 	%rd30, %rd280, 5120;
	// inline asm
	ld.global.nc.u32 %r120, [%rd30];
	// inline asm
	add.s64 	%rd31, %rd280, 5632;
	// inline asm
	ld.global.nc.u32 %r121, [%rd31];
	// inline asm
	add.s64 	%rd32, %rd280, 6144;
	// inline asm
	ld.global.nc.u32 %r122, [%rd32];
	// inline asm
	add.s64 	%rd33, %rd280, 6656;
	// inline asm
	ld.global.nc.u32 %r123, [%rd33];
	// inline asm
	add.s64 	%rd34, %rd280, 7168;
	// inline asm
	ld.global.nc.u32 %r124, [%rd34];
	// inline asm
	bar.sync 	0;
	xor.b32  	%r126, %r110, -2147483648;
	// inline asm
	bfe.u32 %r125, %r126, %r84, %r85;
	// inline asm
	and.b32  	%r185, %r125, 3;
	shr.u32 	%r186, %r125, 2;
	cvt.u64.u32	%rd35, %r185;
	mul.wide.u32 	%rd36, %r186, 512;
	add.s64 	%rd38, %rd15, %rd36;
	add.s64 	%rd40, %rd38, %rd14;
	add.s64 	%rd41, %rd40, %rd35;
	ld.shared.u8 	%rs1, [%rd41];
	add.s16 	%rs2, %rs1, 1;
	st.shared.u8 	[%rd41], %rs2;
	xor.b32  	%r130, %r111, -2147483648;
	// inline asm
	bfe.u32 %r129, %r130, %r84, %r85;
	// inline asm
	and.b32  	%r188, %r129, 3;
	shr.u32 	%r189, %r129, 2;
	cvt.u64.u32	%rd42, %r188;
	mul.wide.u32 	%rd43, %r189, 512;
	add.s64 	%rd44, %rd15, %rd43;
	add.s64 	%rd45, %rd44, %rd14;
	add.s64 	%rd46, %rd45, %rd42;
	ld.shared.u8 	%rs3, [%rd46];
	add.s16 	%rs4, %rs3, 1;
	st.shared.u8 	[%rd46], %rs4;
	xor.b32  	%r134, %r112, -2147483648;
	// inline asm
	bfe.u32 %r133, %r134, %r84, %r85;
	// inline asm
	and.b32  	%r190, %r133, 3;
	shr.u32 	%r191, %r133, 2;
	cvt.u64.u32	%rd47, %r190;
	mul.wide.u32 	%rd48, %r191, 512;
	add.s64 	%rd49, %rd15, %rd48;
	add.s64 	%rd50, %rd49, %rd14;
	add.s64 	%rd51, %rd50, %rd47;
	ld.shared.u8 	%rs5, [%rd51];
	add.s16 	%rs6, %rs5, 1;
	st.shared.u8 	[%rd51], %rs6;
	xor.b32  	%r138, %r113, -2147483648;
	// inline asm
	bfe.u32 %r137, %r138, %r84, %r85;
	// inline asm
	and.b32  	%r192, %r137, 3;
	shr.u32 	%r193, %r137, 2;
	cvt.u64.u32	%rd52, %r192;
	mul.wide.u32 	%rd53, %r193, 512;
	add.s64 	%rd54, %rd15, %rd53;
	add.s64 	%rd55, %rd54, %rd14;
	add.s64 	%rd56, %rd55, %rd52;
	ld.shared.u8 	%rs7, [%rd56];
	add.s16 	%rs8, %rs7, 1;
	st.shared.u8 	[%rd56], %rs8;
	xor.b32  	%r142, %r114, -2147483648;
	// inline asm
	bfe.u32 %r141, %r142, %r84, %r85;
	// inline asm
	and.b32  	%r194, %r141, 3;
	shr.u32 	%r195, %r141, 2;
	cvt.u64.u32	%rd57, %r194;
	mul.wide.u32 	%rd58, %r195, 512;
	add.s64 	%rd59, %rd15, %rd58;
	add.s64 	%rd60, %rd59, %rd14;
	add.s64 	%rd61, %rd60, %rd57;
	ld.shared.u8 	%rs9, [%rd61];
	add.s16 	%rs10, %rs9, 1;
	st.shared.u8 	[%rd61], %rs10;
	xor.b32  	%r146, %r115, -2147483648;
	// inline asm
	bfe.u32 %r145, %r146, %r84, %r85;
	// inline asm
	and.b32  	%r196, %r145, 3;
	shr.u32 	%r197, %r145, 2;
	cvt.u64.u32	%rd62, %r196;
	mul.wide.u32 	%rd63, %r197, 512;
	add.s64 	%rd64, %rd15, %rd63;
	add.s64 	%rd65, %rd64, %rd14;
	add.s64 	%rd66, %rd65, %rd62;
	ld.shared.u8 	%rs11, [%rd66];
	add.s16 	%rs12, %rs11, 1;
	st.shared.u8 	[%rd66], %rs12;
	xor.b32  	%r150, %r116, -2147483648;
	// inline asm
	bfe.u32 %r149, %r150, %r84, %r85;
	// inline asm
	and.b32  	%r198, %r149, 3;
	shr.u32 	%r199, %r149, 2;
	cvt.u64.u32	%rd67, %r198;
	mul.wide.u32 	%rd68, %r199, 512;
	add.s64 	%rd69, %rd15, %rd68;
	add.s64 	%rd70, %rd69, %rd14;
	add.s64 	%rd71, %rd70, %rd67;
	ld.shared.u8 	%rs13, [%rd71];
	add.s16 	%rs14, %rs13, 1;
	st.shared.u8 	[%rd71], %rs14;
	xor.b32  	%r154, %r117, -2147483648;
	// inline asm
	bfe.u32 %r153, %r154, %r84, %r85;
	// inline asm
	and.b32  	%r200, %r153, 3;
	shr.u32 	%r201, %r153, 2;
	cvt.u64.u32	%rd72, %r200;
	mul.wide.u32 	%rd73, %r201, 512;
	add.s64 	%rd74, %rd15, %rd73;
	add.s64 	%rd75, %rd74, %rd14;
	add.s64 	%rd76, %rd75, %rd72;
	ld.shared.u8 	%rs15, [%rd76];
	add.s16 	%rs16, %rs15, 1;
	st.shared.u8 	[%rd76], %rs16;
	xor.b32  	%r158, %r118, -2147483648;
	// inline asm
	bfe.u32 %r157, %r158, %r84, %r85;
	// inline asm
	and.b32  	%r202, %r157, 3;
	shr.u32 	%r203, %r157, 2;
	cvt.u64.u32	%rd77, %r202;
	mul.wide.u32 	%rd78, %r203, 512;
	add.s64 	%rd79, %rd15, %rd78;
	add.s64 	%rd80, %rd79, %rd14;
	add.s64 	%rd81, %rd80, %rd77;
	ld.shared.u8 	%rs17, [%rd81];
	add.s16 	%rs18, %rs17, 1;
	st.shared.u8 	[%rd81], %rs18;
	xor.b32  	%r162, %r119, -2147483648;
	// inline asm
	bfe.u32 %r161, %r162, %r84, %r85;
	// inline asm
	and.b32  	%r204, %r161, 3;
	shr.u32 	%r205, %r161, 2;
	cvt.u64.u32	%rd82, %r204;
	mul.wide.u32 	%rd83, %r205, 512;
	add.s64 	%rd84, %rd15, %rd83;
	add.s64 	%rd85, %rd84, %rd14;
	add.s64 	%rd86, %rd85, %rd82;
	ld.shared.u8 	%rs19, [%rd86];
	add.s16 	%rs20, %rs19, 1;
	st.shared.u8 	[%rd86], %rs20;
	xor.b32  	%r166, %r120, -2147483648;
	// inline asm
	bfe.u32 %r165, %r166, %r84, %r85;
	// inline asm
	and.b32  	%r206, %r165, 3;
	shr.u32 	%r207, %r165, 2;
	cvt.u64.u32	%rd87, %r206;
	mul.wide.u32 	%rd88, %r207, 512;
	add.s64 	%rd89, %rd15, %rd88;
	add.s64 	%rd90, %rd89, %rd14;
	add.s64 	%rd91, %rd90, %rd87;
	ld.shared.u8 	%rs21, [%rd91];
	add.s16 	%rs22, %rs21, 1;
	st.shared.u8 	[%rd91], %rs22;
	xor.b32  	%r170, %r121, -2147483648;
	// inline asm
	bfe.u32 %r169, %r170, %r84, %r85;
	// inline asm
	and.b32  	%r208, %r169, 3;
	shr.u32 	%r209, %r169, 2;
	cvt.u64.u32	%rd92, %r208;
	mul.wide.u32 	%rd93, %r209, 512;
	add.s64 	%rd94, %rd15, %rd93;
	add.s64 	%rd95, %rd94, %rd14;
	add.s64 	%rd96, %rd95, %rd92;
	ld.shared.u8 	%rs23, [%rd96];
	add.s16 	%rs24, %rs23, 1;
	st.shared.u8 	[%rd96], %rs24;
	xor.b32  	%r174, %r122, -2147483648;
	// inline asm
	bfe.u32 %r173, %r174, %r84, %r85;
	// inline asm
	and.b32  	%r210, %r173, 3;
	shr.u32 	%r211, %r173, 2;
	cvt.u64.u32	%rd97, %r210;
	mul.wide.u32 	%rd98, %r211, 512;
	add.s64 	%rd99, %rd15, %rd98;
	add.s64 	%rd100, %rd99, %rd14;
	add.s64 	%rd101, %rd100, %rd97;
	ld.shared.u8 	%rs25, [%rd101];
	add.s16 	%rs26, %rs25, 1;
	st.shared.u8 	[%rd101], %rs26;
	xor.b32  	%r178, %r123, -2147483648;
	// inline asm
	bfe.u32 %r177, %r178, %r84, %r85;
	// inline asm
	and.b32  	%r212, %r177, 3;
	shr.u32 	%r213, %r177, 2;
	cvt.u64.u32	%rd102, %r212;
	mul.wide.u32 	%rd103, %r213, 512;
	add.s64 	%rd104, %rd15, %rd103;
	add.s64 	%rd105, %rd104, %rd14;
	add.s64 	%rd106, %rd105, %rd102;
	ld.shared.u8 	%rs27, [%rd106];
	add.s16 	%rs28, %rs27, 1;
	st.shared.u8 	[%rd106], %rs28;
	xor.b32  	%r182, %r124, -2147483648;
	// inline asm
	bfe.u32 %r181, %r182, %r84, %r85;
	// inline asm
	and.b32  	%r214, %r181, 3;
	shr.u32 	%r215, %r181, 2;
	cvt.u64.u32	%rd107, %r214;
	mul.wide.u32 	%rd108, %r215, 512;
	add.s64 	%rd109, %rd15, %rd108;
	add.s64 	%rd110, %rd109, %rd14;
	add.s64 	%rd111, %rd110, %rd107;
	ld.shared.u8 	%rs29, [%rd111];
	add.s16 	%rs30, %rs29, 1;
	st.shared.u8 	[%rd111], %rs30;
	add.s64 	%rd280, %rd280, 7680;
	add.s32 	%r491, %r491, 1;
	setp.ne.s32	%p6, %r491, 0;
	@%p6 bra 	BB24_7;

	setp.lt.u32	%p1, %r100, 128;
	bar.sync 	0;
	@!%p1 bra 	BB24_10;
	bra.uni 	BB24_9;

BB24_9:
	shr.u32 	%r218, %r100, 5;
	and.b32  	%r219, %r100, 31;
	mul.wide.u32 	%rd112, %r218, 512;
	add.s64 	%rd114, %rd15, %rd112;
	mul.wide.u32 	%rd115, %r219, 4;
	add.s64 	%rd116, %rd114, %rd115;
	ld.shared.v4.u8 	{%rs31, %rs32, %rs33, %rs34}, [%rd116];
	cvt.u32.u16	%r220, %rs34;
	cvt.u32.u16	%r221, %rs33;
	cvt.u32.u16	%r222, %rs32;
	cvt.u32.u16	%r223, %rs31;
	add.s32 	%r224, %r505, %r223;
	add.s32 	%r225, %r504, %r222;
	add.s32 	%r226, %r503, %r221;
	add.s32 	%r227, %r506, %r220;
	ld.shared.v4.u8 	{%rs35, %rs36, %rs37, %rs38}, [%rd116+128];
	cvt.u32.u16	%r228, %rs38;
	cvt.u32.u16	%r229, %rs37;
	cvt.u32.u16	%r230, %rs36;
	cvt.u32.u16	%r231, %rs35;
	add.s32 	%r232, %r224, %r231;
	add.s32 	%r233, %r225, %r230;
	add.s32 	%r234, %r226, %r229;
	add.s32 	%r235, %r227, %r228;
	ld.shared.v4.u8 	{%rs39, %rs40, %rs41, %rs42}, [%rd116+256];
	cvt.u32.u16	%r236, %rs42;
	cvt.u32.u16	%r237, %rs41;
	cvt.u32.u16	%r238, %rs40;
	cvt.u32.u16	%r239, %rs39;
	add.s32 	%r240, %r232, %r239;
	add.s32 	%r241, %r233, %r238;
	add.s32 	%r242, %r234, %r237;
	add.s32 	%r243, %r235, %r236;
	ld.shared.v4.u8 	{%rs43, %rs44, %rs45, %rs46}, [%rd116+384];
	cvt.u32.u16	%r244, %rs46;
	cvt.u32.u16	%r245, %rs45;
	cvt.u32.u16	%r246, %rs44;
	cvt.u32.u16	%r247, %rs43;
	add.s32 	%r505, %r240, %r247;
	add.s32 	%r504, %r241, %r246;
	add.s32 	%r503, %r242, %r245;
	add.s32 	%r506, %r243, %r244;

BB24_10:
	bar.sync 	0;
	mov.u32 	%r249, 0;
	st.shared.u32 	[%rd16], %r249;
	st.shared.u32 	[%rd16+512], %r249;
	st.shared.u32 	[%rd16+1024], %r249;
	st.shared.u32 	[%rd16+1536], %r249;
	add.s32 	%r42, %r490, 1920;
	add.s32 	%r250, %r490, 34560;
	add.s32 	%r490, %r490, 32640;
	add.s32 	%r489, %r489, 32640;
	setp.le.s32	%p7, %r250, %r488;
	mov.u32 	%r500, %r42;
	@%p7 bra 	BB24_6;

BB24_11:
	mov.u32 	%r497, %r500;
	add.s32 	%r499, %r497, 1920;
	setp.gt.s32	%p8, %r499, %r488;
	@%p8 bra 	BB24_14;

	add.s32 	%r252, %r100, 128;
	cvt.s64.s32	%rd4, %r252;
	add.s32 	%r253, %r100, 256;
	cvt.s64.s32	%rd5, %r253;
	add.s32 	%r254, %r100, 384;
	cvt.s64.s32	%rd6, %r254;
	cvt.u64.u32	%rd7, %r100;
	shl.b64 	%rd182, %rd7, 2;
	mov.u32 	%r498, %r497;

BB24_13:
	mov.u32 	%r495, %r499;
	mov.u32 	%r52, %r498;
	mov.u32 	%r498, %r495;
	cvt.s64.s32	%rd135, %r100;
	cvt.s64.s32	%rd136, %r52;
	add.s64 	%rd137, %rd135, %rd136;
	shl.b64 	%rd138, %rd137, 2;
	add.s64 	%rd120, %rd12, %rd138;
	// inline asm
	ld.global.nc.u32 %r255, [%rd120];
	// inline asm
	add.s64 	%rd139, %rd4, %rd136;
	shl.b64 	%rd140, %rd139, 2;
	add.s64 	%rd121, %rd12, %rd140;
	// inline asm
	ld.global.nc.u32 %r256, [%rd121];
	// inline asm
	add.s64 	%rd141, %rd5, %rd136;
	shl.b64 	%rd142, %rd141, 2;
	add.s64 	%rd122, %rd12, %rd142;
	// inline asm
	ld.global.nc.u32 %r257, [%rd122];
	// inline asm
	add.s64 	%rd143, %rd6, %rd136;
	shl.b64 	%rd144, %rd143, 2;
	add.s64 	%rd123, %rd12, %rd144;
	// inline asm
	ld.global.nc.u32 %r258, [%rd123];
	// inline asm
	add.s32 	%r271, %r100, 512;
	cvt.s64.s32	%rd145, %r271;
	add.s64 	%rd146, %rd145, %rd136;
	shl.b64 	%rd147, %rd146, 2;
	add.s64 	%rd124, %rd12, %rd147;
	// inline asm
	ld.global.nc.u32 %r259, [%rd124];
	// inline asm
	add.s32 	%r272, %r100, 640;
	cvt.s64.s32	%rd148, %r272;
	add.s64 	%rd149, %rd148, %rd136;
	shl.b64 	%rd150, %rd149, 2;
	add.s64 	%rd125, %rd12, %rd150;
	// inline asm
	ld.global.nc.u32 %r260, [%rd125];
	// inline asm
	add.s32 	%r273, %r100, 768;
	cvt.s64.s32	%rd151, %r273;
	add.s64 	%rd152, %rd151, %rd136;
	shl.b64 	%rd153, %rd152, 2;
	add.s64 	%rd126, %rd12, %rd153;
	// inline asm
	ld.global.nc.u32 %r261, [%rd126];
	// inline asm
	add.s32 	%r274, %r100, 896;
	cvt.s64.s32	%rd154, %r274;
	add.s64 	%rd155, %rd154, %rd136;
	shl.b64 	%rd156, %rd155, 2;
	add.s64 	%rd127, %rd12, %rd156;
	// inline asm
	ld.global.nc.u32 %r262, [%rd127];
	// inline asm
	add.s32 	%r275, %r100, 1024;
	cvt.s64.s32	%rd157, %r275;
	add.s64 	%rd158, %rd157, %rd136;
	shl.b64 	%rd159, %rd158, 2;
	add.s64 	%rd128, %rd12, %rd159;
	// inline asm
	ld.global.nc.u32 %r263, [%rd128];
	// inline asm
	add.s32 	%r276, %r100, 1152;
	cvt.s64.s32	%rd160, %r276;
	add.s64 	%rd161, %rd160, %rd136;
	shl.b64 	%rd162, %rd161, 2;
	add.s64 	%rd129, %rd12, %rd162;
	// inline asm
	ld.global.nc.u32 %r264, [%rd129];
	// inline asm
	add.s32 	%r277, %r100, 1280;
	cvt.s64.s32	%rd163, %r277;
	add.s64 	%rd164, %rd163, %rd136;
	shl.b64 	%rd165, %rd164, 2;
	add.s64 	%rd130, %rd12, %rd165;
	// inline asm
	ld.global.nc.u32 %r265, [%rd130];
	// inline asm
	add.s32 	%r278, %r100, 1408;
	cvt.s64.s32	%rd166, %r278;
	add.s64 	%rd167, %rd166, %rd136;
	shl.b64 	%rd168, %rd167, 2;
	add.s64 	%rd131, %rd12, %rd168;
	// inline asm
	ld.global.nc.u32 %r266, [%rd131];
	// inline asm
	add.s32 	%r279, %r100, 1536;
	cvt.s64.s32	%rd169, %r279;
	add.s64 	%rd170, %rd169, %rd136;
	shl.b64 	%rd171, %rd170, 2;
	add.s64 	%rd132, %rd12, %rd171;
	// inline asm
	ld.global.nc.u32 %r267, [%rd132];
	// inline asm
	add.s32 	%r280, %r100, 1664;
	cvt.s64.s32	%rd172, %r280;
	add.s64 	%rd173, %rd172, %rd136;
	shl.b64 	%rd174, %rd173, 2;
	add.s64 	%rd133, %rd12, %rd174;
	// inline asm
	ld.global.nc.u32 %r268, [%rd133];
	// inline asm
	add.s32 	%r281, %r100, 1792;
	cvt.s64.s32	%rd175, %r281;
	add.s64 	%rd176, %rd175, %rd136;
	shl.b64 	%rd177, %rd176, 2;
	add.s64 	%rd134, %rd12, %rd177;
	// inline asm
	ld.global.nc.u32 %r269, [%rd134];
	// inline asm
	bar.sync 	0;
	xor.b32  	%r283, %r255, -2147483648;
	// inline asm
	bfe.u32 %r282, %r283, %r84, %r85;
	// inline asm
	and.b32  	%r342, %r282, 3;
	shr.u32 	%r343, %r282, 2;
	cvt.u64.u32	%rd178, %r342;
	mul.wide.u32 	%rd179, %r343, 512;
	add.s64 	%rd181, %rd15, %rd179;
	add.s64 	%rd183, %rd181, %rd182;
	add.s64 	%rd184, %rd183, %rd178;
	ld.shared.u8 	%rs47, [%rd184];
	add.s16 	%rs48, %rs47, 1;
	st.shared.u8 	[%rd184], %rs48;
	xor.b32  	%r287, %r256, -2147483648;
	// inline asm
	bfe.u32 %r286, %r287, %r84, %r85;
	// inline asm
	and.b32  	%r344, %r286, 3;
	shr.u32 	%r345, %r286, 2;
	cvt.u64.u32	%rd185, %r344;
	mul.wide.u32 	%rd186, %r345, 512;
	add.s64 	%rd187, %rd15, %rd186;
	add.s64 	%rd188, %rd187, %rd182;
	add.s64 	%rd189, %rd188, %rd185;
	ld.shared.u8 	%rs49, [%rd189];
	add.s16 	%rs50, %rs49, 1;
	st.shared.u8 	[%rd189], %rs50;
	xor.b32  	%r291, %r257, -2147483648;
	// inline asm
	bfe.u32 %r290, %r291, %r84, %r85;
	// inline asm
	and.b32  	%r346, %r290, 3;
	shr.u32 	%r347, %r290, 2;
	cvt.u64.u32	%rd190, %r346;
	mul.wide.u32 	%rd191, %r347, 512;
	add.s64 	%rd192, %rd15, %rd191;
	add.s64 	%rd193, %rd192, %rd182;
	add.s64 	%rd194, %rd193, %rd190;
	ld.shared.u8 	%rs51, [%rd194];
	add.s16 	%rs52, %rs51, 1;
	st.shared.u8 	[%rd194], %rs52;
	xor.b32  	%r295, %r258, -2147483648;
	// inline asm
	bfe.u32 %r294, %r295, %r84, %r85;
	// inline asm
	and.b32  	%r348, %r294, 3;
	shr.u32 	%r349, %r294, 2;
	cvt.u64.u32	%rd195, %r348;
	mul.wide.u32 	%rd196, %r349, 512;
	add.s64 	%rd197, %rd15, %rd196;
	add.s64 	%rd198, %rd197, %rd182;
	add.s64 	%rd199, %rd198, %rd195;
	ld.shared.u8 	%rs53, [%rd199];
	add.s16 	%rs54, %rs53, 1;
	st.shared.u8 	[%rd199], %rs54;
	xor.b32  	%r299, %r259, -2147483648;
	// inline asm
	bfe.u32 %r298, %r299, %r84, %r85;
	// inline asm
	and.b32  	%r350, %r298, 3;
	shr.u32 	%r351, %r298, 2;
	cvt.u64.u32	%rd200, %r350;
	mul.wide.u32 	%rd201, %r351, 512;
	add.s64 	%rd202, %rd15, %rd201;
	add.s64 	%rd203, %rd202, %rd182;
	add.s64 	%rd204, %rd203, %rd200;
	ld.shared.u8 	%rs55, [%rd204];
	add.s16 	%rs56, %rs55, 1;
	st.shared.u8 	[%rd204], %rs56;
	xor.b32  	%r303, %r260, -2147483648;
	// inline asm
	bfe.u32 %r302, %r303, %r84, %r85;
	// inline asm
	and.b32  	%r352, %r302, 3;
	shr.u32 	%r353, %r302, 2;
	cvt.u64.u32	%rd205, %r352;
	mul.wide.u32 	%rd206, %r353, 512;
	add.s64 	%rd207, %rd15, %rd206;
	add.s64 	%rd208, %rd207, %rd182;
	add.s64 	%rd209, %rd208, %rd205;
	ld.shared.u8 	%rs57, [%rd209];
	add.s16 	%rs58, %rs57, 1;
	st.shared.u8 	[%rd209], %rs58;
	xor.b32  	%r307, %r261, -2147483648;
	// inline asm
	bfe.u32 %r306, %r307, %r84, %r85;
	// inline asm
	and.b32  	%r354, %r306, 3;
	shr.u32 	%r355, %r306, 2;
	cvt.u64.u32	%rd210, %r354;
	mul.wide.u32 	%rd211, %r355, 512;
	add.s64 	%rd212, %rd15, %rd211;
	add.s64 	%rd213, %rd212, %rd182;
	add.s64 	%rd214, %rd213, %rd210;
	ld.shared.u8 	%rs59, [%rd214];
	add.s16 	%rs60, %rs59, 1;
	st.shared.u8 	[%rd214], %rs60;
	xor.b32  	%r311, %r262, -2147483648;
	// inline asm
	bfe.u32 %r310, %r311, %r84, %r85;
	// inline asm
	and.b32  	%r356, %r310, 3;
	shr.u32 	%r357, %r310, 2;
	cvt.u64.u32	%rd215, %r356;
	mul.wide.u32 	%rd216, %r357, 512;
	add.s64 	%rd217, %rd15, %rd216;
	add.s64 	%rd218, %rd217, %rd182;
	add.s64 	%rd219, %rd218, %rd215;
	ld.shared.u8 	%rs61, [%rd219];
	add.s16 	%rs62, %rs61, 1;
	st.shared.u8 	[%rd219], %rs62;
	xor.b32  	%r315, %r263, -2147483648;
	// inline asm
	bfe.u32 %r314, %r315, %r84, %r85;
	// inline asm
	and.b32  	%r358, %r314, 3;
	shr.u32 	%r359, %r314, 2;
	cvt.u64.u32	%rd220, %r358;
	mul.wide.u32 	%rd221, %r359, 512;
	add.s64 	%rd222, %rd15, %rd221;
	add.s64 	%rd223, %rd222, %rd182;
	add.s64 	%rd224, %rd223, %rd220;
	ld.shared.u8 	%rs63, [%rd224];
	add.s16 	%rs64, %rs63, 1;
	st.shared.u8 	[%rd224], %rs64;
	xor.b32  	%r319, %r264, -2147483648;
	// inline asm
	bfe.u32 %r318, %r319, %r84, %r85;
	// inline asm
	and.b32  	%r360, %r318, 3;
	shr.u32 	%r361, %r318, 2;
	cvt.u64.u32	%rd225, %r360;
	mul.wide.u32 	%rd226, %r361, 512;
	add.s64 	%rd227, %rd15, %rd226;
	add.s64 	%rd228, %rd227, %rd182;
	add.s64 	%rd229, %rd228, %rd225;
	ld.shared.u8 	%rs65, [%rd229];
	add.s16 	%rs66, %rs65, 1;
	st.shared.u8 	[%rd229], %rs66;
	xor.b32  	%r323, %r265, -2147483648;
	// inline asm
	bfe.u32 %r322, %r323, %r84, %r85;
	// inline asm
	and.b32  	%r362, %r322, 3;
	shr.u32 	%r363, %r322, 2;
	cvt.u64.u32	%rd230, %r362;
	mul.wide.u32 	%rd231, %r363, 512;
	add.s64 	%rd232, %rd15, %rd231;
	add.s64 	%rd233, %rd232, %rd182;
	add.s64 	%rd234, %rd233, %rd230;
	ld.shared.u8 	%rs67, [%rd234];
	add.s16 	%rs68, %rs67, 1;
	st.shared.u8 	[%rd234], %rs68;
	xor.b32  	%r327, %r266, -2147483648;
	// inline asm
	bfe.u32 %r326, %r327, %r84, %r85;
	// inline asm
	and.b32  	%r364, %r326, 3;
	shr.u32 	%r365, %r326, 2;
	cvt.u64.u32	%rd235, %r364;
	mul.wide.u32 	%rd236, %r365, 512;
	add.s64 	%rd237, %rd15, %rd236;
	add.s64 	%rd238, %rd237, %rd182;
	add.s64 	%rd239, %rd238, %rd235;
	ld.shared.u8 	%rs69, [%rd239];
	add.s16 	%rs70, %rs69, 1;
	st.shared.u8 	[%rd239], %rs70;
	xor.b32  	%r331, %r267, -2147483648;
	// inline asm
	bfe.u32 %r330, %r331, %r84, %r85;
	// inline asm
	and.b32  	%r366, %r330, 3;
	shr.u32 	%r367, %r330, 2;
	cvt.u64.u32	%rd240, %r366;
	mul.wide.u32 	%rd241, %r367, 512;
	add.s64 	%rd242, %rd15, %rd241;
	add.s64 	%rd243, %rd242, %rd182;
	add.s64 	%rd244, %rd243, %rd240;
	ld.shared.u8 	%rs71, [%rd244];
	add.s16 	%rs72, %rs71, 1;
	st.shared.u8 	[%rd244], %rs72;
	xor.b32  	%r335, %r268, -2147483648;
	// inline asm
	bfe.u32 %r334, %r335, %r84, %r85;
	// inline asm
	and.b32  	%r368, %r334, 3;
	shr.u32 	%r369, %r334, 2;
	cvt.u64.u32	%rd245, %r368;
	mul.wide.u32 	%rd246, %r369, 512;
	add.s64 	%rd247, %rd15, %rd246;
	add.s64 	%rd248, %rd247, %rd182;
	add.s64 	%rd249, %rd248, %rd245;
	ld.shared.u8 	%rs73, [%rd249];
	add.s16 	%rs74, %rs73, 1;
	st.shared.u8 	[%rd249], %rs74;
	xor.b32  	%r339, %r269, -2147483648;
	// inline asm
	bfe.u32 %r338, %r339, %r84, %r85;
	// inline asm
	and.b32  	%r370, %r338, 3;
	shr.u32 	%r371, %r338, 2;
	cvt.u64.u32	%rd250, %r370;
	mul.wide.u32 	%rd251, %r371, 512;
	add.s64 	%rd252, %rd15, %rd251;
	add.s64 	%rd253, %rd252, %rd182;
	add.s64 	%rd254, %rd253, %rd250;
	ld.shared.u8 	%rs75, [%rd254];
	add.s16 	%rs76, %rs75, 1;
	st.shared.u8 	[%rd254], %rs76;
	add.s32 	%r499, %r498, 1920;
	setp.le.s32	%p9, %r499, %r488;
	mov.u32 	%r497, %r498;
	@%p9 bra 	BB24_13;

BB24_14:
	add.s32 	%r502, %r100, %r497;
	setp.ge.s32	%p10, %r502, %r488;
	@%p10 bra 	BB24_17;

	add.s32 	%r374, %r100, %r497;
	mul.wide.s32 	%rd255, %r374, 4;
	add.s64 	%rd281, %rd12, %rd255;
	cvt.u64.u32	%rd9, %r100;
	shl.b64 	%rd261, %rd9, 2;

BB24_16:
	// inline asm
	ld.global.nc.u32 %r375, [%rd281];
	// inline asm
	xor.b32  	%r377, %r375, -2147483648;
	// inline asm
	bfe.u32 %r376, %r377, %r84, %r85;
	// inline asm
	and.b32  	%r380, %r376, 3;
	shr.u32 	%r381, %r376, 2;
	cvt.u64.u32	%rd257, %r380;
	mul.wide.u32 	%rd258, %r381, 512;
	add.s64 	%rd260, %rd15, %rd258;
	add.s64 	%rd262, %rd260, %rd261;
	add.s64 	%rd263, %rd262, %rd257;
	ld.shared.u8 	%rs77, [%rd263];
	add.s16 	%rs78, %rs77, 1;
	st.shared.u8 	[%rd263], %rs78;
	add.s64 	%rd281, %rd281, 512;
	add.s32 	%r502, %r502, 128;
	setp.lt.s32	%p11, %r502, %r488;
	@%p11 bra 	BB24_16;

BB24_17:
	bar.sync 	0;
	setp.gt.u32	%p12, %r100, 127;
	@%p12 bra 	BB24_19;

	shr.u32 	%r384, %r100, 5;
	and.b32  	%r385, %r100, 31;
	mul.wide.u32 	%rd264, %r384, 512;
	add.s64 	%rd266, %rd15, %rd264;
	mul.wide.u32 	%rd267, %r385, 4;
	add.s64 	%rd268, %rd266, %rd267;
	ld.shared.v4.u8 	{%rs79, %rs80, %rs81, %rs82}, [%rd268];
	cvt.u32.u16	%r386, %rs82;
	cvt.u32.u16	%r387, %rs81;
	cvt.u32.u16	%r388, %rs80;
	cvt.u32.u16	%r389, %rs79;
	add.s32 	%r390, %r505, %r389;
	add.s32 	%r391, %r504, %r388;
	add.s32 	%r392, %r503, %r387;
	add.s32 	%r393, %r506, %r386;
	ld.shared.v4.u8 	{%rs83, %rs84, %rs85, %rs86}, [%rd268+128];
	cvt.u32.u16	%r394, %rs86;
	cvt.u32.u16	%r395, %rs85;
	cvt.u32.u16	%r396, %rs84;
	cvt.u32.u16	%r397, %rs83;
	add.s32 	%r398, %r390, %r397;
	add.s32 	%r399, %r391, %r396;
	add.s32 	%r400, %r392, %r395;
	add.s32 	%r401, %r393, %r394;
	ld.shared.v4.u8 	{%rs87, %rs88, %rs89, %rs90}, [%rd268+256];
	cvt.u32.u16	%r402, %rs90;
	cvt.u32.u16	%r403, %rs89;
	cvt.u32.u16	%r404, %rs88;
	cvt.u32.u16	%r405, %rs87;
	add.s32 	%r406, %r398, %r405;
	add.s32 	%r407, %r399, %r404;
	add.s32 	%r408, %r400, %r403;
	add.s32 	%r409, %r401, %r402;
	ld.shared.v4.u8 	{%rs91, %rs92, %rs93, %rs94}, [%rd268+384];
	cvt.u32.u16	%r410, %rs94;
	cvt.u32.u16	%r411, %rs93;
	cvt.u32.u16	%r412, %rs92;
	cvt.u32.u16	%r413, %rs91;
	add.s32 	%r505, %r406, %r413;
	add.s32 	%r504, %r407, %r412;
	add.s32 	%r503, %r408, %r411;
	add.s32 	%r506, %r409, %r410;

BB24_19:
	setp.lt.u32	%p2, %r100, 128;
	bar.sync 	0;
	@!%p2 bra 	BB24_21;
	bra.uni 	BB24_20;

BB24_20:
	and.b32  	%r414, %r100, 31;
	shr.u32 	%r416, %r100, 3;
	and.b32  	%r417, %r416, 536870908;
	mul.wide.u32 	%rd269, %r417, 132;
	add.s64 	%rd271, %rd15, %rd269;
	mul.wide.u32 	%rd272, %r414, 4;
	add.s64 	%rd273, %rd271, %rd272;
	st.shared.u32 	[%rd273], %r505;
	st.shared.u32 	[%rd273+132], %r504;
	st.shared.u32 	[%rd273+264], %r503;
	st.shared.u32 	[%rd273+396], %r506;

BB24_21:
	bar.sync 	0;
	setp.gt.u32	%p13, %r100, 15;
	@%p13 bra 	BB24_23;

	mul.wide.u32 	%rd274, %r100, 132;
	add.s64 	%rd276, %rd15, %rd274;
	ld.shared.u32 	%r421, [%rd276+4];
	ld.shared.u32 	%r422, [%rd276];
	add.s32 	%r423, %r421, %r422;
	ld.shared.u32 	%r424, [%rd276+8];
	add.s32 	%r425, %r423, %r424;
	ld.shared.u32 	%r426, [%rd276+12];
	add.s32 	%r427, %r425, %r426;
	ld.shared.u32 	%r428, [%rd276+16];
	add.s32 	%r429, %r427, %r428;
	ld.shared.u32 	%r430, [%rd276+20];
	add.s32 	%r431, %r429, %r430;
	ld.shared.u32 	%r432, [%rd276+24];
	add.s32 	%r433, %r431, %r432;
	ld.shared.u32 	%r434, [%rd276+28];
	add.s32 	%r435, %r433, %r434;
	ld.shared.u32 	%r436, [%rd276+32];
	add.s32 	%r437, %r435, %r436;
	ld.shared.u32 	%r438, [%rd276+36];
	add.s32 	%r439, %r437, %r438;
	ld.shared.u32 	%r440, [%rd276+40];
	add.s32 	%r441, %r439, %r440;
	ld.shared.u32 	%r442, [%rd276+44];
	add.s32 	%r443, %r441, %r442;
	ld.shared.u32 	%r444, [%rd276+48];
	add.s32 	%r445, %r443, %r444;
	ld.shared.u32 	%r446, [%rd276+52];
	add.s32 	%r447, %r445, %r446;
	ld.shared.u32 	%r448, [%rd276+56];
	add.s32 	%r449, %r447, %r448;
	ld.shared.u32 	%r450, [%rd276+60];
	add.s32 	%r451, %r449, %r450;
	ld.shared.u32 	%r452, [%rd276+64];
	add.s32 	%r453, %r451, %r452;
	ld.shared.u32 	%r454, [%rd276+68];
	add.s32 	%r455, %r453, %r454;
	ld.shared.u32 	%r456, [%rd276+72];
	add.s32 	%r457, %r455, %r456;
	ld.shared.u32 	%r458, [%rd276+76];
	add.s32 	%r459, %r457, %r458;
	ld.shared.u32 	%r460, [%rd276+80];
	add.s32 	%r461, %r459, %r460;
	ld.shared.u32 	%r462, [%rd276+84];
	add.s32 	%r463, %r461, %r462;
	ld.shared.u32 	%r464, [%rd276+88];
	add.s32 	%r465, %r463, %r464;
	ld.shared.u32 	%r466, [%rd276+92];
	add.s32 	%r467, %r465, %r466;
	ld.shared.u32 	%r468, [%rd276+96];
	add.s32 	%r469, %r467, %r468;
	ld.shared.u32 	%r470, [%rd276+100];
	add.s32 	%r471, %r469, %r470;
	ld.shared.u32 	%r472, [%rd276+104];
	add.s32 	%r473, %r471, %r472;
	ld.shared.u32 	%r474, [%rd276+108];
	add.s32 	%r475, %r473, %r474;
	ld.shared.u32 	%r476, [%rd276+112];
	add.s32 	%r477, %r475, %r476;
	ld.shared.u32 	%r478, [%rd276+116];
	add.s32 	%r479, %r477, %r478;
	ld.shared.u32 	%r480, [%rd276+120];
	add.s32 	%r481, %r479, %r480;
	ld.shared.u32 	%r482, [%rd276+124];
	add.s32 	%r507, %r481, %r482;

BB24_23:
	@%p13 bra 	BB24_25;

	mov.u32 	%r484, %nctaid.x;
	mad.lo.s32 	%r487, %r484, %r100, %r1;
	cvta.to.global.u64 	%rd277, %rd13;
	mul.wide.u32 	%rd278, %r487, 4;
	add.s64 	%rd279, %rd277, %rd278;
	st.global.u32 	[%rd279], %r507;

BB24_25:
	ret;
}

	// .globl	_ZN6thrust6system4cuda6detail4cub_23RadixSortScanBinsKernelINS3_23DeviceRadixSortDispatchILb0EiiiE13PtxScanPolicyEiEEvPT0_i
.visible .entry _ZN6thrust6system4cuda6detail4cub_23RadixSortScanBinsKernelINS3_23DeviceRadixSortDispatchILb0EiiiE13PtxScanPolicyEiEEvPT0_i(
	.param .u64 _ZN6thrust6system4cuda6detail4cub_23RadixSortScanBinsKernelINS3_23DeviceRadixSortDispatchILb0EiiiE13PtxScanPolicyEiEEvPT0_i_param_0,
	.param .u32 _ZN6thrust6system4cuda6detail4cub_23RadixSortScanBinsKernelINS3_23DeviceRadixSortDispatchILb0EiiiE13PtxScanPolicyEiEEvPT0_i_param_1
)
.maxntid 1024, 1, 1
.minnctapersm 1
{
	.reg .pred 	%p<39>;
	.reg .b32 	%r<193>;
	.reg .b64 	%rd<14>;
	// demoted variable
	.shared .align 4 .b8 _ZN6thrust6system4cuda6detail4cub_23RadixSortScanBinsKernelINS3_23DeviceRadixSortDispatchILb0EiiiE13PtxScanPolicyEiEEvPT0_i$__cuda_local_var_106560_67_non_const_temp_storage[172];

	ld.param.u64 	%rd5, [_ZN6thrust6system4cuda6detail4cub_23RadixSortScanBinsKernelINS3_23DeviceRadixSortDispatchILb0EiiiE13PtxScanPolicyEiEEvPT0_i_param_0];
	ld.param.u32 	%r20, [_ZN6thrust6system4cuda6detail4cub_23RadixSortScanBinsKernelINS3_23DeviceRadixSortDispatchILb0EiiiE13PtxScanPolicyEiEEvPT0_i_param_1];
	mov.u32 	%r21, %ctaid.x;
	setp.ne.s32	%p33, %r21, 0;
	setp.lt.s32	%p34, %r20, 4096;
	or.pred  	%p35, %p33, %p34;
	@%p35 bra 	BB25_8;

	cvta.to.global.u64 	%rd13, %rd5;
	mov.u32 	%r24, %tid.x;
	shr.s32 	%r25, %r24, 31;
	shr.u32 	%r26, %r25, 27;
	add.s32 	%r27, %r24, %r26;
	shr.s32 	%r28, %r27, 5;
	mul.wide.s32 	%rd6, %r28, 4;
	mov.u64 	%rd7, _ZN6thrust6system4cuda6detail4cub_23RadixSortScanBinsKernelINS3_23DeviceRadixSortDispatchILb0EiiiE13PtxScanPolicyEiEEvPT0_i$__cuda_local_var_106560_67_non_const_temp_storage;
	add.s64 	%rd8, %rd7, %rd6;
	add.s64 	%rd2, %rd8, 36;
	mov.u32 	%r191, 0;
	mov.u32 	%r187, 4096;
	// inline asm
	mov.u32 %r31, %laneid;
	// inline asm

BB25_2:
	mov.u32 	%r2, %r191;
	shl.b32 	%r30, %r24, 2;
	mul.wide.s32 	%rd9, %r30, 4;
	add.s64 	%rd10, %rd13, %rd9;
	ld.global.u32 	%r3, [%rd10];
	ld.global.u32 	%r4, [%rd10+4];
	ld.global.u32 	%r5, [%rd10+8];
	ld.global.u32 	%r6, [%rd10+12];
	bar.sync 	0;
	add.s32 	%r57, %r4, %r3;
	add.s32 	%r58, %r57, %r5;
	add.s32 	%r36, %r58, %r6;
	mov.u32 	%r34, 1;
	mov.u32 	%r55, 0;
	// inline asm
	{  .reg .u32 r0;  .reg .pred p;  shfl.up.b32 r0|p, %r36, %r34, %r55;  @p add.u32 r0, r0, %r36;  mov.u32 %r32, r0;}
	// inline asm
	mov.u32 	%r39, 2;
	// inline asm
	{  .reg .u32 r0;  .reg .pred p;  shfl.up.b32 r0|p, %r32, %r39, %r55;  @p add.u32 r0, r0, %r32;  mov.u32 %r37, r0;}
	// inline asm
	mov.u32 	%r44, 4;
	// inline asm
	{  .reg .u32 r0;  .reg .pred p;  shfl.up.b32 r0|p, %r37, %r44, %r55;  @p add.u32 r0, r0, %r37;  mov.u32 %r42, r0;}
	// inline asm
	mov.u32 	%r49, 8;
	// inline asm
	{  .reg .u32 r0;  .reg .pred p;  shfl.up.b32 r0|p, %r42, %r49, %r55;  @p add.u32 r0, r0, %r42;  mov.u32 %r47, r0;}
	// inline asm
	mov.u32 	%r54, 16;
	// inline asm
	{  .reg .u32 r0;  .reg .pred p;  shfl.up.b32 r0|p, %r47, %r54, %r55;  @p add.u32 r0, r0, %r47;  mov.u32 %r52, r0;}
	// inline asm
	setp.ne.s32	%p36, %r31, 31;
	@%p36 bra 	BB25_4;

	st.shared.u32 	[%rd2], %r52;

BB25_4:
	sub.s32 	%r10, %r52, %r36;
	add.s32 	%r60, %r24, 31;
	setp.lt.u32	%p1, %r60, 63;
	and.b32  	%r61, %r24, -32;
	setp.eq.s32	%p2, %r61, 992;
	setp.eq.s32	%p3, %r61, 960;
	setp.eq.s32	%p4, %r61, 928;
	setp.eq.s32	%p5, %r61, 896;
	setp.eq.s32	%p6, %r61, 864;
	setp.eq.s32	%p7, %r61, 832;
	setp.eq.s32	%p8, %r61, 800;
	setp.eq.s32	%p9, %r61, 768;
	setp.eq.s32	%p10, %r61, 736;
	setp.eq.s32	%p11, %r61, 704;
	setp.eq.s32	%p12, %r61, 672;
	setp.eq.s32	%p13, %r61, 640;
	setp.eq.s32	%p14, %r61, 608;
	setp.eq.s32	%p15, %r61, 576;
	setp.eq.s32	%p16, %r61, 544;
	setp.eq.s32	%p17, %r61, 512;
	setp.eq.s32	%p18, %r61, 480;
	setp.eq.s32	%p19, %r61, 448;
	setp.eq.s32	%p20, %r61, 416;
	setp.eq.s32	%p21, %r61, 384;
	setp.eq.s32	%p22, %r61, 352;
	setp.eq.s32	%p23, %r61, 320;
	setp.eq.s32	%p24, %r61, 288;
	setp.eq.s32	%p25, %r61, 256;
	setp.eq.s32	%p26, %r61, 224;
	setp.eq.s32	%p27, %r61, 192;
	setp.eq.s32	%p28, %r61, 160;
	setp.eq.s32	%p29, %r61, 128;
	setp.eq.s32	%p30, %r61, 96;
	setp.eq.s32	%p31, %r61, 64;
	setp.eq.s32	%p32, %r61, 32;
	bar.sync 	0;
	ld.shared.u32 	%r62, [_ZN6thrust6system4cuda6detail4cub_23RadixSortScanBinsKernelINS3_23DeviceRadixSortDispatchILb0EiiiE13PtxScanPolicyEiEEvPT0_i$__cuda_local_var_106560_67_non_const_temp_storage+36];
	selp.b32	%r63, %r62, 0, %p32;
	add.s32 	%r64, %r10, %r63;
	ld.shared.u32 	%r65, [_ZN6thrust6system4cuda6detail4cub_23RadixSortScanBinsKernelINS3_23DeviceRadixSortDispatchILb0EiiiE13PtxScanPolicyEiEEvPT0_i$__cuda_local_var_106560_67_non_const_temp_storage+40];
	add.s32 	%r66, %r65, %r62;
	selp.b32	%r67, %r66, 0, %p31;
	add.s32 	%r68, %r64, %r67;
	ld.shared.u32 	%r69, [_ZN6thrust6system4cuda6detail4cub_23RadixSortScanBinsKernelINS3_23DeviceRadixSortDispatchILb0EiiiE13PtxScanPolicyEiEEvPT0_i$__cuda_local_var_106560_67_non_const_temp_storage+44];
	add.s32 	%r70, %r66, %r69;
	selp.b32	%r71, %r70, 0, %p30;
	add.s32 	%r72, %r68, %r71;
	ld.shared.u32 	%r73, [_ZN6thrust6system4cuda6detail4cub_23RadixSortScanBinsKernelINS3_23DeviceRadixSortDispatchILb0EiiiE13PtxScanPolicyEiEEvPT0_i$__cuda_local_var_106560_67_non_const_temp_storage+48];
	add.s32 	%r74, %r70, %r73;
	selp.b32	%r75, %r74, 0, %p29;
	add.s32 	%r76, %r72, %r75;
	ld.shared.u32 	%r77, [_ZN6thrust6system4cuda6detail4cub_23RadixSortScanBinsKernelINS3_23DeviceRadixSortDispatchILb0EiiiE13PtxScanPolicyEiEEvPT0_i$__cuda_local_var_106560_67_non_const_temp_storage+52];
	add.s32 	%r78, %r74, %r77;
	selp.b32	%r79, %r78, 0, %p28;
	add.s32 	%r80, %r76, %r79;
	ld.shared.u32 	%r81, [_ZN6thrust6system4cuda6detail4cub_23RadixSortScanBinsKernelINS3_23DeviceRadixSortDispatchILb0EiiiE13PtxScanPolicyEiEEvPT0_i$__cuda_local_var_106560_67_non_const_temp_storage+56];
	add.s32 	%r82, %r78, %r81;
	selp.b32	%r83, %r82, 0, %p27;
	add.s32 	%r84, %r80, %r83;
	ld.shared.u32 	%r85, [_ZN6thrust6system4cuda6detail4cub_23RadixSortScanBinsKernelINS3_23DeviceRadixSortDispatchILb0EiiiE13PtxScanPolicyEiEEvPT0_i$__cuda_local_var_106560_67_non_const_temp_storage+60];
	add.s32 	%r86, %r82, %r85;
	selp.b32	%r87, %r86, 0, %p26;
	add.s32 	%r88, %r84, %r87;
	ld.shared.u32 	%r89, [_ZN6thrust6system4cuda6detail4cub_23RadixSortScanBinsKernelINS3_23DeviceRadixSortDispatchILb0EiiiE13PtxScanPolicyEiEEvPT0_i$__cuda_local_var_106560_67_non_const_temp_storage+64];
	add.s32 	%r90, %r86, %r89;
	selp.b32	%r91, %r90, 0, %p25;
	add.s32 	%r92, %r88, %r91;
	ld.shared.u32 	%r93, [_ZN6thrust6system4cuda6detail4cub_23RadixSortScanBinsKernelINS3_23DeviceRadixSortDispatchILb0EiiiE13PtxScanPolicyEiEEvPT0_i$__cuda_local_var_106560_67_non_const_temp_storage+68];
	add.s32 	%r94, %r90, %r93;
	selp.b32	%r95, %r94, 0, %p24;
	add.s32 	%r96, %r92, %r95;
	ld.shared.u32 	%r97, [_ZN6thrust6system4cuda6detail4cub_23RadixSortScanBinsKernelINS3_23DeviceRadixSortDispatchILb0EiiiE13PtxScanPolicyEiEEvPT0_i$__cuda_local_var_106560_67_non_const_temp_storage+72];
	add.s32 	%r98, %r94, %r97;
	selp.b32	%r99, %r98, 0, %p23;
	add.s32 	%r100, %r96, %r99;
	ld.shared.u32 	%r101, [_ZN6thrust6system4cuda6detail4cub_23RadixSortScanBinsKernelINS3_23DeviceRadixSortDispatchILb0EiiiE13PtxScanPolicyEiEEvPT0_i$__cuda_local_var_106560_67_non_const_temp_storage+76];
	add.s32 	%r102, %r98, %r101;
	selp.b32	%r103, %r102, 0, %p22;
	add.s32 	%r104, %r100, %r103;
	ld.shared.u32 	%r105, [_ZN6thrust6system4cuda6detail4cub_23RadixSortScanBinsKernelINS3_23DeviceRadixSortDispatchILb0EiiiE13PtxScanPolicyEiEEvPT0_i$__cuda_local_var_106560_67_non_const_temp_storage+80];
	add.s32 	%r106, %r102, %r105;
	selp.b32	%r107, %r106, 0, %p21;
	add.s32 	%r108, %r104, %r107;
	ld.shared.u32 	%r109, [_ZN6thrust6system4cuda6detail4cub_23RadixSortScanBinsKernelINS3_23DeviceRadixSortDispatchILb0EiiiE13PtxScanPolicyEiEEvPT0_i$__cuda_local_var_106560_67_non_const_temp_storage+84];
	add.s32 	%r110, %r106, %r109;
	selp.b32	%r111, %r110, 0, %p20;
	add.s32 	%r112, %r108, %r111;
	ld.shared.u32 	%r113, [_ZN6thrust6system4cuda6detail4cub_23RadixSortScanBinsKernelINS3_23DeviceRadixSortDispatchILb0EiiiE13PtxScanPolicyEiEEvPT0_i$__cuda_local_var_106560_67_non_const_temp_storage+88];
	add.s32 	%r114, %r110, %r113;
	selp.b32	%r115, %r114, 0, %p19;
	add.s32 	%r116, %r112, %r115;
	ld.shared.u32 	%r117, [_ZN6thrust6system4cuda6detail4cub_23RadixSortScanBinsKernelINS3_23DeviceRadixSortDispatchILb0EiiiE13PtxScanPolicyEiEEvPT0_i$__cuda_local_var_106560_67_non_const_temp_storage+92];
	add.s32 	%r118, %r114, %r117;
	selp.b32	%r119, %r118, 0, %p18;
	add.s32 	%r120, %r116, %r119;
	ld.shared.u32 	%r121, [_ZN6thrust6system4cuda6detail4cub_23RadixSortScanBinsKernelINS3_23DeviceRadixSortDispatchILb0EiiiE13PtxScanPolicyEiEEvPT0_i$__cuda_local_var_106560_67_non_const_temp_storage+96];
	add.s32 	%r122, %r118, %r121;
	selp.b32	%r123, %r122, 0, %p17;
	add.s32 	%r124, %r120, %r123;
	ld.shared.u32 	%r125, [_ZN6thrust6system4cuda6detail4cub_23RadixSortScanBinsKernelINS3_23DeviceRadixSortDispatchILb0EiiiE13PtxScanPolicyEiEEvPT0_i$__cuda_local_var_106560_67_non_const_temp_storage+100];
	add.s32 	%r126, %r122, %r125;
	selp.b32	%r127, %r126, 0, %p16;
	add.s32 	%r128, %r124, %r127;
	ld.shared.u32 	%r129, [_ZN6thrust6system4cuda6detail4cub_23RadixSortScanBinsKernelINS3_23DeviceRadixSortDispatchILb0EiiiE13PtxScanPolicyEiEEvPT0_i$__cuda_local_var_106560_67_non_const_temp_storage+104];
	add.s32 	%r130, %r126, %r129;
	selp.b32	%r131, %r130, 0, %p15;
	add.s32 	%r132, %r128, %r131;
	ld.shared.u32 	%r133, [_ZN6thrust6system4cuda6detail4cub_23RadixSortScanBinsKernelINS3_23DeviceRadixSortDispatchILb0EiiiE13PtxScanPolicyEiEEvPT0_i$__cuda_local_var_106560_67_non_const_temp_storage+108];
	add.s32 	%r134, %r130, %r133;
	selp.b32	%r135, %r134, 0, %p14;
	add.s32 	%r136, %r132, %r135;
	ld.shared.u32 	%r137, [_ZN6thrust6system4cuda6detail4cub_23RadixSortScanBinsKernelINS3_23DeviceRadixSortDispatchILb0EiiiE13PtxScanPolicyEiEEvPT0_i$__cuda_local_var_106560_67_non_const_temp_storage+112];
	add.s32 	%r138, %r134, %r137;
	selp.b32	%r139, %r138, 0, %p13;
	add.s32 	%r140, %r136, %r139;
	ld.shared.u32 	%r141, [_ZN6thrust6system4cuda6detail4cub_23RadixSortScanBinsKernelINS3_23DeviceRadixSortDispatchILb0EiiiE13PtxScanPolicyEiEEvPT0_i$__cuda_local_var_106560_67_non_const_temp_storage+116];
	add.s32 	%r142, %r138, %r141;
	selp.b32	%r143, %r142, 0, %p12;
	add.s32 	%r144, %r140, %r143;
	ld.shared.u32 	%r145, [_ZN6thrust6system4cuda6detail4cub_23RadixSortScanBinsKernelINS3_23DeviceRadixSortDispatchILb0EiiiE13PtxScanPolicyEiEEvPT0_i$__cuda_local_var_106560_67_non_const_temp_storage+120];
	add.s32 	%r146, %r142, %r145;
	selp.b32	%r147, %r146, 0, %p11;
	add.s32 	%r148, %r144, %r147;
	ld.shared.u32 	%r149, [_ZN6thrust6system4cuda6detail4cub_23RadixSortScanBinsKernelINS3_23DeviceRadixSortDispatchILb0EiiiE13PtxScanPolicyEiEEvPT0_i$__cuda_local_var_106560_67_non_const_temp_storage+124];
	add.s32 	%r150, %r146, %r149;
	selp.b32	%r151, %r150, 0, %p10;
	add.s32 	%r152, %r148, %r151;
	ld.shared.u32 	%r153, [_ZN6thrust6system4cuda6detail4cub_23RadixSortScanBinsKernelINS3_23DeviceRadixSortDispatchILb0EiiiE13PtxScanPolicyEiEEvPT0_i$__cuda_local_var_106560_67_non_const_temp_storage+128];
	add.s32 	%r154, %r150, %r153;
	selp.b32	%r155, %r154, 0, %p9;
	add.s32 	%r156, %r152, %r155;
	ld.shared.u32 	%r157, [_ZN6thrust6system4cuda6detail4cub_23RadixSortScanBinsKernelINS3_23DeviceRadixSortDispatchILb0EiiiE13PtxScanPolicyEiEEvPT0_i$__cuda_local_var_106560_67_non_const_temp_storage+132];
	add.s32 	%r158, %r154, %r157;
	selp.b32	%r159, %r158, 0, %p8;
	add.s32 	%r160, %r156, %r159;
	ld.shared.u32 	%r161, [_ZN6thrust6system4cuda6detail4cub_23RadixSortScanBinsKernelINS3_23DeviceRadixSortDispatchILb0EiiiE13PtxScanPolicyEiEEvPT0_i$__cuda_local_var_106560_67_non_const_temp_storage+136];
	add.s32 	%r162, %r158, %r161;
	selp.b32	%r163, %r162, 0, %p7;
	add.s32 	%r164, %r160, %r163;
	ld.shared.u32 	%r165, [_ZN6thrust6system4cuda6detail4cub_23RadixSortScanBinsKernelINS3_23DeviceRadixSortDispatchILb0EiiiE13PtxScanPolicyEiEEvPT0_i$__cuda_local_var_106560_67_non_const_temp_storage+140];
	add.s32 	%r166, %r162, %r165;
	selp.b32	%r167, %r166, 0, %p6;
	add.s32 	%r168, %r164, %r167;
	ld.shared.u32 	%r169, [_ZN6thrust6system4cuda6detail4cub_23RadixSortScanBinsKernelINS3_23DeviceRadixSortDispatchILb0EiiiE13PtxScanPolicyEiEEvPT0_i$__cuda_local_var_106560_67_non_const_temp_storage+144];
	add.s32 	%r170, %r166, %r169;
	selp.b32	%r171, %r170, 0, %p5;
	add.s32 	%r172, %r168, %r171;
	ld.shared.u32 	%r173, [_ZN6thrust6system4cuda6detail4cub_23RadixSortScanBinsKernelINS3_23DeviceRadixSortDispatchILb0EiiiE13PtxScanPolicyEiEEvPT0_i$__cuda_local_var_106560_67_non_const_temp_storage+148];
	add.s32 	%r174, %r170, %r173;
	selp.b32	%r175, %r174, 0, %p4;
	add.s32 	%r176, %r172, %r175;
	ld.shared.u32 	%r177, [_ZN6thrust6system4cuda6detail4cub_23RadixSortScanBinsKernelINS3_23DeviceRadixSortDispatchILb0EiiiE13PtxScanPolicyEiEEvPT0_i$__cuda_local_var_106560_67_non_const_temp_storage+152];
	add.s32 	%r178, %r174, %r177;
	selp.b32	%r179, %r178, 0, %p3;
	add.s32 	%r180, %r176, %r179;
	ld.shared.u32 	%r181, [_ZN6thrust6system4cuda6detail4cub_23RadixSortScanBinsKernelINS3_23DeviceRadixSortDispatchILb0EiiiE13PtxScanPolicyEiEEvPT0_i$__cuda_local_var_106560_67_non_const_temp_storage+156];
	add.s32 	%r11, %r178, %r181;
	selp.b32	%r182, %r11, 0, %p2;
	add.s32 	%r12, %r180, %r182;
	mov.u32 	%r192, %r2;
	@!%p1 bra 	BB25_7;
	bra.uni 	BB25_5;

BB25_5:
	ld.shared.u32 	%r183, [_ZN6thrust6system4cuda6detail4cub_23RadixSortScanBinsKernelINS3_23DeviceRadixSortDispatchILb0EiiiE13PtxScanPolicyEiEEvPT0_i$__cuda_local_var_106560_67_non_const_temp_storage+160];
	add.s32 	%r184, %r183, %r2;
	add.s32 	%r13, %r184, %r11;
	setp.ne.s32	%p37, %r31, 0;
	mov.u32 	%r192, %r13;
	@%p37 bra 	BB25_7;

	st.shared.u32 	[_ZN6thrust6system4cuda6detail4cub_23RadixSortScanBinsKernelINS3_23DeviceRadixSortDispatchILb0EiiiE13PtxScanPolicyEiEEvPT0_i$__cuda_local_var_106560_67_non_const_temp_storage+164], %r2;
	mov.u32 	%r192, %r13;

BB25_7:
	mov.u32 	%r191, %r192;
	bar.sync 	0;
	ld.shared.u32 	%r185, [_ZN6thrust6system4cuda6detail4cub_23RadixSortScanBinsKernelINS3_23DeviceRadixSortDispatchILb0EiiiE13PtxScanPolicyEiEEvPT0_i$__cuda_local_var_106560_67_non_const_temp_storage+164];
	add.s32 	%r15, %r12, %r185;
	add.s32 	%r16, %r3, %r15;
	add.s32 	%r17, %r16, %r4;
	add.s32 	%r18, %r17, %r5;
	bar.sync 	0;
	mul.wide.s32 	%rd11, %r24, 16;
	add.s64 	%rd12, %rd13, %rd11;
	st.global.v4.u32 	[%rd12], {%r15, %r16, %r17, %r18};
	add.s64 	%rd13, %rd13, 16384;
	add.s32 	%r187, %r187, 4096;
	setp.le.s32	%p38, %r187, %r20;
	@%p38 bra 	BB25_2;

BB25_8:
	ret;
}

	// .globl	_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE18PtxDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE
.visible .entry _ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE18PtxDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE(
	.param .u64 _ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE18PtxDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_0,
	.param .u64 _ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE18PtxDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_1,
	.param .u64 _ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE18PtxDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_2,
	.param .u64 _ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE18PtxDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_3,
	.param .u64 _ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE18PtxDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_4,
	.param .u32 _ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE18PtxDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_5,
	.param .u32 _ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE18PtxDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_6,
	.param .u32 _ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE18PtxDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_7,
	.param .u8 _ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE18PtxDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_8,
	.param .u8 _ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE18PtxDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_9,
	.param .align 4 .b8 _ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE18PtxDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_10[36]
)
.maxntid 128, 1, 1
{
	.reg .pred 	%p<152>;
	.reg .b16 	%rs<3>;
	.reg .b32 	%r<1389>;
	.reg .b64 	%rd<1125>;
	// demoted variable
	.shared .align 8 .b8 _ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE18PtxDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE$__cuda_local_var_106605_76_non_const_temp_storage[9400];

	ld.param.u64 	%rd142, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE18PtxDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_0];
	ld.param.u64 	%rd143, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE18PtxDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_1];
	ld.param.u64 	%rd144, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE18PtxDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_2];
	ld.param.u64 	%rd145, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE18PtxDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_3];
	ld.param.u64 	%rd146, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE18PtxDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_4];
	ld.param.u32 	%r389, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE18PtxDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_5];
	ld.param.u32 	%r390, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE18PtxDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_6];
	ld.param.u32 	%r391, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE18PtxDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_7];
	ld.param.u32 	%r400, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE18PtxDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_10+32];
	ld.param.u32 	%r399, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE18PtxDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_10+28];
	ld.param.u32 	%r397, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE18PtxDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_10+20];
	ld.param.u32 	%r396, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE18PtxDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_10+16];
	ld.param.u32 	%r395, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE18PtxDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_10+12];
	ld.param.u32 	%r394, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE18PtxDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_10+8];
	ld.param.u32 	%r392, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE18PtxDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_10];
	ld.param.u32 	%r393, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE18PtxDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_10+4];
	cvta.to.global.u64 	%rd1, %rd145;
	cvta.to.global.u64 	%rd2, %rd143;
	mov.u32 	%r1, %ctaid.x;
	setp.lt.s32	%p7, %r1, %r393;
	@%p7 bra 	BB26_3;
	bra.uni 	BB26_1;

BB26_3:
	mul.lo.s32 	%r1342, %r1, %r394;
	add.s32 	%r1302, %r1342, %r394;
	bra.uni 	BB26_4;

BB26_1:
	mov.u32 	%r1302, %r400;
	mov.u32 	%r1342, %r399;
	setp.ge.s32	%p8, %r1, %r392;
	@%p8 bra 	BB26_4;

	mad.lo.s32 	%r1342, %r1, %r395, %r396;
	add.s32 	%r401, %r1342, %r395;
	min.s32 	%r1302, %r401, %r397;

BB26_4:
	mov.u32 	%r9, %r1342;
	mov.u32 	%r10, %tid.x;
	setp.gt.u32	%p9, %r10, 31;
	@%p9 bra 	BB26_6;

	cvta.to.global.u64 	%rd147, %rd146;
	mov.u32 	%r405, %nctaid.x;
	mul.lo.s32 	%r406, %r405, %r10;
	mul.wide.u32 	%rd148, %r406, 4;
	add.s64 	%rd149, %rd147, %rd148;
	ld.global.u32 	%r407, [%rd149];
	setp.eq.s32	%p10, %r407, 0;
	setp.eq.s32	%p11, %r407, %r389;
	or.pred  	%p12, %p10, %p11;
	selp.u32	%r404, 1, 0, %p12;
	// inline asm
	{ 
	.reg .pred 	%p1; 
	.reg .pred 	%p2; 
	setp.ne.u32 	%p1, %r404, 0; 
	vote.all.pred 	%p2, %p1; 
	selp.s32 	%r403, 1, 0, %p2; 
	}
	// inline asm
	setp.ne.s32	%p13, %r403, 0;
	selp.u16	%rs1, 1, 0, %p13;
	st.shared.u8 	[_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE18PtxDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE$__cuda_local_var_106605_76_non_const_temp_storage+132], %rs1;
	add.s32 	%r408, %r406, %r1;
	mul.wide.u32 	%rd150, %r408, 4;
	add.s64 	%rd151, %rd147, %rd150;
	ld.global.u32 	%r1343, [%rd151];

BB26_6:
	bar.sync 	0;
	ld.shared.u8 	%rs2, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE18PtxDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE$__cuda_local_var_106605_76_non_const_temp_storage+132];
	setp.eq.s16	%p14, %rs2, 0;
	add.s32 	%r13, %r9, 1920;
	@%p14 bra 	BB26_135;

	setp.gt.s32	%p15, %r13, %r1302;
	mov.u32 	%r1339, %r9;
	@%p15 bra 	BB26_10;

	cvt.s64.s32	%rd3, %r10;
	add.s32 	%r409, %r10, 128;
	cvt.s64.s32	%rd4, %r409;
	add.s32 	%r410, %r10, 256;
	cvt.s64.s32	%rd5, %r410;
	add.s32 	%r411, %r10, 384;
	cvt.s64.s32	%rd6, %r411;
	add.s32 	%r412, %r10, 512;
	cvt.s64.s32	%rd7, %r412;
	add.s32 	%r413, %r10, 640;
	cvt.s64.s32	%rd8, %r413;
	add.s32 	%r414, %r10, 768;
	cvt.s64.s32	%rd9, %r414;
	add.s32 	%r415, %r10, 896;
	cvt.s64.s32	%rd10, %r415;
	add.s32 	%r416, %r10, 1024;
	cvt.s64.s32	%rd11, %r416;
	add.s32 	%r417, %r10, 1152;
	cvt.s64.s32	%rd12, %r417;
	add.s32 	%r418, %r10, 1280;
	cvt.s64.s32	%rd13, %r418;
	add.s32 	%r419, %r10, 1408;
	cvt.s64.s32	%rd14, %r419;
	add.s32 	%r420, %r10, 1536;
	cvt.s64.s32	%rd15, %r420;
	add.s32 	%r421, %r10, 1664;
	cvt.s64.s32	%rd16, %r421;
	add.s32 	%r422, %r10, 1792;
	cvt.s64.s32	%rd17, %r422;
	mov.u32 	%r1340, %r9;
	mov.u32 	%r1341, %r13;

BB26_9:
	mov.u32 	%r1327, %r1341;
	mov.u32 	%r15, %r1340;
	mov.u32 	%r1340, %r1327;
	cvt.s64.s32	%rd167, %r15;
	add.s64 	%rd18, %rd3, %rd167;
	shl.b64 	%rd168, %rd18, 2;
	add.s64 	%rd152, %rd142, %rd168;
	// inline asm
	ld.global.nc.u32 %r423, [%rd152];
	// inline asm
	add.s64 	%rd169, %rd4, %rd167;
	shl.b64 	%rd170, %rd169, 2;
	add.s64 	%rd153, %rd142, %rd170;
	// inline asm
	ld.global.nc.u32 %r424, [%rd153];
	// inline asm
	add.s64 	%rd171, %rd5, %rd167;
	shl.b64 	%rd172, %rd171, 2;
	add.s64 	%rd154, %rd142, %rd172;
	// inline asm
	ld.global.nc.u32 %r425, [%rd154];
	// inline asm
	add.s64 	%rd173, %rd6, %rd167;
	shl.b64 	%rd174, %rd173, 2;
	add.s64 	%rd155, %rd142, %rd174;
	// inline asm
	ld.global.nc.u32 %r426, [%rd155];
	// inline asm
	add.s64 	%rd175, %rd7, %rd167;
	shl.b64 	%rd176, %rd175, 2;
	add.s64 	%rd156, %rd142, %rd176;
	// inline asm
	ld.global.nc.u32 %r427, [%rd156];
	// inline asm
	add.s64 	%rd177, %rd8, %rd167;
	shl.b64 	%rd178, %rd177, 2;
	add.s64 	%rd157, %rd142, %rd178;
	// inline asm
	ld.global.nc.u32 %r428, [%rd157];
	// inline asm
	add.s64 	%rd179, %rd9, %rd167;
	shl.b64 	%rd180, %rd179, 2;
	add.s64 	%rd158, %rd142, %rd180;
	// inline asm
	ld.global.nc.u32 %r429, [%rd158];
	// inline asm
	add.s64 	%rd181, %rd10, %rd167;
	shl.b64 	%rd182, %rd181, 2;
	add.s64 	%rd159, %rd142, %rd182;
	// inline asm
	ld.global.nc.u32 %r430, [%rd159];
	// inline asm
	add.s64 	%rd183, %rd11, %rd167;
	shl.b64 	%rd184, %rd183, 2;
	add.s64 	%rd160, %rd142, %rd184;
	// inline asm
	ld.global.nc.u32 %r431, [%rd160];
	// inline asm
	add.s64 	%rd185, %rd12, %rd167;
	shl.b64 	%rd186, %rd185, 2;
	add.s64 	%rd161, %rd142, %rd186;
	// inline asm
	ld.global.nc.u32 %r432, [%rd161];
	// inline asm
	add.s64 	%rd187, %rd13, %rd167;
	shl.b64 	%rd188, %rd187, 2;
	add.s64 	%rd162, %rd142, %rd188;
	// inline asm
	ld.global.nc.u32 %r433, [%rd162];
	// inline asm
	add.s64 	%rd189, %rd14, %rd167;
	shl.b64 	%rd190, %rd189, 2;
	add.s64 	%rd163, %rd142, %rd190;
	// inline asm
	ld.global.nc.u32 %r434, [%rd163];
	// inline asm
	add.s64 	%rd191, %rd15, %rd167;
	shl.b64 	%rd192, %rd191, 2;
	add.s64 	%rd164, %rd142, %rd192;
	// inline asm
	ld.global.nc.u32 %r435, [%rd164];
	// inline asm
	add.s64 	%rd193, %rd16, %rd167;
	shl.b64 	%rd194, %rd193, 2;
	add.s64 	%rd165, %rd142, %rd194;
	// inline asm
	ld.global.nc.u32 %r436, [%rd165];
	// inline asm
	add.s64 	%rd195, %rd17, %rd167;
	shl.b64 	%rd196, %rd195, 2;
	add.s64 	%rd166, %rd142, %rd196;
	// inline asm
	ld.global.nc.u32 %r437, [%rd166];
	// inline asm
	bar.sync 	0;
	add.s64 	%rd198, %rd2, %rd168;
	st.global.u32 	[%rd198], %r423;
	st.global.u32 	[%rd198+512], %r424;
	st.global.u32 	[%rd198+1024], %r425;
	st.global.u32 	[%rd198+1536], %r426;
	st.global.u32 	[%rd198+2048], %r427;
	st.global.u32 	[%rd198+2560], %r428;
	st.global.u32 	[%rd198+3072], %r429;
	st.global.u32 	[%rd198+3584], %r430;
	st.global.u32 	[%rd198+4096], %r431;
	st.global.u32 	[%rd198+4608], %r432;
	st.global.u32 	[%rd198+5120], %r433;
	st.global.u32 	[%rd198+5632], %r434;
	st.global.u32 	[%rd198+6144], %r435;
	st.global.u32 	[%rd198+6656], %r436;
	st.global.u32 	[%rd198+7168], %r437;
	add.s32 	%r31, %r1340, 1920;
	setp.le.s32	%p16, %r31, %r1302;
	mov.u32 	%r1328, %r1340;
	mov.u32 	%r1339, %r1328;
	mov.u32 	%r1341, %r31;
	@%p16 bra 	BB26_9;

BB26_10:
	mov.u32 	%r32, %r1339;
	setp.le.s32	%p17, %r1302, %r32;
	@%p17 bra 	BB26_71;

	sub.s32 	%r33, %r1302, %r32;
	cvt.s64.s32	%rd19, %r32;
	sub.s32 	%r34, %r33, %r10;
	setp.lt.s32	%p18, %r34, 1;
	@%p18 bra 	BB26_13;

	cvt.s64.s32	%rd200, %r10;
	add.s64 	%rd201, %rd200, %rd19;
	shl.b64 	%rd202, %rd201, 2;
	add.s64 	%rd199, %rd142, %rd202;
	// inline asm
	ld.global.nc.u32 %r1303, [%rd199];
	// inline asm

BB26_13:
	setp.lt.s32	%p19, %r34, 129;
	@%p19 bra 	BB26_15;

	add.s32 	%r443, %r10, 128;
	cvt.s64.s32	%rd204, %r443;
	add.s64 	%rd205, %rd204, %rd19;
	shl.b64 	%rd206, %rd205, 2;
	add.s64 	%rd203, %rd142, %rd206;
	// inline asm
	ld.global.nc.u32 %r1304, [%rd203];
	// inline asm

BB26_15:
	setp.lt.s32	%p20, %r34, 257;
	@%p20 bra 	BB26_17;

	add.s32 	%r446, %r10, 256;
	cvt.s64.s32	%rd208, %r446;
	add.s64 	%rd209, %rd208, %rd19;
	shl.b64 	%rd210, %rd209, 2;
	add.s64 	%rd207, %rd142, %rd210;
	// inline asm
	ld.global.nc.u32 %r1305, [%rd207];
	// inline asm

BB26_17:
	setp.lt.s32	%p21, %r34, 385;
	@%p21 bra 	BB26_19;

	add.s32 	%r449, %r10, 384;
	cvt.s64.s32	%rd212, %r449;
	add.s64 	%rd213, %rd212, %rd19;
	shl.b64 	%rd214, %rd213, 2;
	add.s64 	%rd211, %rd142, %rd214;
	// inline asm
	ld.global.nc.u32 %r1306, [%rd211];
	// inline asm

BB26_19:
	setp.lt.s32	%p22, %r34, 513;
	@%p22 bra 	BB26_21;

	add.s32 	%r452, %r10, 512;
	cvt.s64.s32	%rd216, %r452;
	add.s64 	%rd217, %rd216, %rd19;
	shl.b64 	%rd218, %rd217, 2;
	add.s64 	%rd215, %rd142, %rd218;
	// inline asm
	ld.global.nc.u32 %r1307, [%rd215];
	// inline asm

BB26_21:
	setp.lt.s32	%p23, %r34, 641;
	@%p23 bra 	BB26_23;

	add.s32 	%r455, %r10, 640;
	cvt.s64.s32	%rd220, %r455;
	add.s64 	%rd221, %rd220, %rd19;
	shl.b64 	%rd222, %rd221, 2;
	add.s64 	%rd219, %rd142, %rd222;
	// inline asm
	ld.global.nc.u32 %r1308, [%rd219];
	// inline asm

BB26_23:
	setp.lt.s32	%p24, %r34, 769;
	@%p24 bra 	BB26_25;

	add.s32 	%r458, %r10, 768;
	cvt.s64.s32	%rd224, %r458;
	add.s64 	%rd225, %rd224, %rd19;
	shl.b64 	%rd226, %rd225, 2;
	add.s64 	%rd223, %rd142, %rd226;
	// inline asm
	ld.global.nc.u32 %r1309, [%rd223];
	// inline asm

BB26_25:
	setp.lt.s32	%p25, %r34, 897;
	@%p25 bra 	BB26_27;

	add.s32 	%r461, %r10, 896;
	cvt.s64.s32	%rd228, %r461;
	add.s64 	%rd229, %rd228, %rd19;
	shl.b64 	%rd230, %rd229, 2;
	add.s64 	%rd227, %rd142, %rd230;
	// inline asm
	ld.global.nc.u32 %r1310, [%rd227];
	// inline asm

BB26_27:
	setp.lt.s32	%p26, %r34, 1025;
	@%p26 bra 	BB26_29;

	add.s32 	%r464, %r10, 1024;
	cvt.s64.s32	%rd232, %r464;
	add.s64 	%rd233, %rd232, %rd19;
	shl.b64 	%rd234, %rd233, 2;
	add.s64 	%rd231, %rd142, %rd234;
	// inline asm
	ld.global.nc.u32 %r1311, [%rd231];
	// inline asm

BB26_29:
	setp.lt.s32	%p27, %r34, 1153;
	@%p27 bra 	BB26_31;

	add.s32 	%r467, %r10, 1152;
	cvt.s64.s32	%rd236, %r467;
	add.s64 	%rd237, %rd236, %rd19;
	shl.b64 	%rd238, %rd237, 2;
	add.s64 	%rd235, %rd142, %rd238;
	// inline asm
	ld.global.nc.u32 %r1312, [%rd235];
	// inline asm

BB26_31:
	setp.lt.s32	%p28, %r34, 1281;
	@%p28 bra 	BB26_33;

	add.s32 	%r470, %r10, 1280;
	cvt.s64.s32	%rd240, %r470;
	add.s64 	%rd241, %rd240, %rd19;
	shl.b64 	%rd242, %rd241, 2;
	add.s64 	%rd239, %rd142, %rd242;
	// inline asm
	ld.global.nc.u32 %r1313, [%rd239];
	// inline asm

BB26_33:
	setp.lt.s32	%p29, %r34, 1409;
	@%p29 bra 	BB26_35;

	add.s32 	%r473, %r10, 1408;
	cvt.s64.s32	%rd244, %r473;
	add.s64 	%rd245, %rd244, %rd19;
	shl.b64 	%rd246, %rd245, 2;
	add.s64 	%rd243, %rd142, %rd246;
	// inline asm
	ld.global.nc.u32 %r1314, [%rd243];
	// inline asm

BB26_35:
	setp.lt.s32	%p30, %r34, 1537;
	@%p30 bra 	BB26_37;

	add.s32 	%r476, %r10, 1536;
	cvt.s64.s32	%rd248, %r476;
	add.s64 	%rd249, %rd248, %rd19;
	shl.b64 	%rd250, %rd249, 2;
	add.s64 	%rd247, %rd142, %rd250;
	// inline asm
	ld.global.nc.u32 %r1315, [%rd247];
	// inline asm

BB26_37:
	setp.lt.s32	%p31, %r34, 1665;
	@%p31 bra 	BB26_39;

	add.s32 	%r479, %r10, 1664;
	cvt.s64.s32	%rd252, %r479;
	add.s64 	%rd253, %rd252, %rd19;
	shl.b64 	%rd254, %rd253, 2;
	add.s64 	%rd251, %rd142, %rd254;
	// inline asm
	ld.global.nc.u32 %r1316, [%rd251];
	// inline asm

BB26_39:
	setp.lt.s32	%p32, %r34, 1793;
	@%p32 bra 	BB26_41;

	add.s32 	%r482, %r10, 1792;
	cvt.s64.s32	%rd256, %r482;
	add.s64 	%rd257, %rd256, %rd19;
	shl.b64 	%rd258, %rd257, 2;
	add.s64 	%rd255, %rd142, %rd258;
	// inline asm
	ld.global.nc.u32 %r1317, [%rd255];
	// inline asm

BB26_41:
	bar.sync 	0;
	cvt.s64.s32	%rd259, %r10;
	add.s64 	%rd260, %rd259, %rd19;
	shl.b64 	%rd261, %rd260, 2;
	add.s64 	%rd20, %rd2, %rd261;
	setp.le.s32	%p33, %r33, %r10;
	@%p33 bra 	BB26_43;

	st.global.u32 	[%rd20], %r1303;

BB26_43:
	add.s32 	%r483, %r10, 128;
	setp.ge.s32	%p34, %r483, %r33;
	@%p34 bra 	BB26_45;

	st.global.u32 	[%rd20+512], %r1304;

BB26_45:
	add.s32 	%r484, %r10, 256;
	setp.ge.s32	%p35, %r484, %r33;
	@%p35 bra 	BB26_47;

	st.global.u32 	[%rd20+1024], %r1305;

BB26_47:
	add.s32 	%r485, %r10, 384;
	setp.ge.s32	%p36, %r485, %r33;
	@%p36 bra 	BB26_49;

	st.global.u32 	[%rd20+1536], %r1306;

BB26_49:
	add.s32 	%r486, %r10, 512;
	setp.ge.s32	%p37, %r486, %r33;
	@%p37 bra 	BB26_51;

	st.global.u32 	[%rd20+2048], %r1307;

BB26_51:
	add.s32 	%r487, %r10, 640;
	setp.ge.s32	%p38, %r487, %r33;
	@%p38 bra 	BB26_53;

	st.global.u32 	[%rd20+2560], %r1308;

BB26_53:
	add.s32 	%r488, %r10, 768;
	setp.ge.s32	%p39, %r488, %r33;
	@%p39 bra 	BB26_55;

	st.global.u32 	[%rd20+3072], %r1309;

BB26_55:
	add.s32 	%r489, %r10, 896;
	setp.ge.s32	%p40, %r489, %r33;
	@%p40 bra 	BB26_57;

	st.global.u32 	[%rd20+3584], %r1310;

BB26_57:
	add.s32 	%r490, %r10, 1024;
	setp.ge.s32	%p41, %r490, %r33;
	@%p41 bra 	BB26_59;

	st.global.u32 	[%rd20+4096], %r1311;

BB26_59:
	add.s32 	%r491, %r10, 1152;
	setp.ge.s32	%p42, %r491, %r33;
	@%p42 bra 	BB26_61;

	st.global.u32 	[%rd20+4608], %r1312;

BB26_61:
	add.s32 	%r492, %r10, 1280;
	setp.ge.s32	%p43, %r492, %r33;
	@%p43 bra 	BB26_63;

	st.global.u32 	[%rd20+5120], %r1313;

BB26_63:
	add.s32 	%r493, %r10, 1408;
	setp.ge.s32	%p44, %r493, %r33;
	@%p44 bra 	BB26_65;

	st.global.u32 	[%rd20+5632], %r1314;

BB26_65:
	add.s32 	%r494, %r10, 1536;
	setp.ge.s32	%p45, %r494, %r33;
	@%p45 bra 	BB26_67;

	st.global.u32 	[%rd20+6144], %r1315;

BB26_67:
	add.s32 	%r495, %r10, 1664;
	setp.ge.s32	%p46, %r495, %r33;
	@%p46 bra 	BB26_69;

	st.global.u32 	[%rd20+6656], %r1316;

BB26_69:
	add.s32 	%r496, %r10, 1792;
	setp.ge.s32	%p47, %r496, %r33;
	@%p47 bra 	BB26_71;

	st.global.u32 	[%rd20+7168], %r1317;

BB26_71:
	mov.u32 	%r1336, %r9;
	@%p15 bra 	BB26_74;

	cvt.s64.s32	%rd21, %r10;
	add.s32 	%r497, %r10, 128;
	cvt.s64.s32	%rd22, %r497;
	add.s32 	%r498, %r10, 256;
	cvt.s64.s32	%rd23, %r498;
	add.s32 	%r499, %r10, 384;
	cvt.s64.s32	%rd24, %r499;
	add.s32 	%r500, %r10, 512;
	cvt.s64.s32	%rd25, %r500;
	add.s32 	%r501, %r10, 640;
	cvt.s64.s32	%rd26, %r501;
	add.s32 	%r502, %r10, 768;
	cvt.s64.s32	%rd27, %r502;
	add.s32 	%r503, %r10, 896;
	cvt.s64.s32	%rd28, %r503;
	add.s32 	%r504, %r10, 1024;
	cvt.s64.s32	%rd29, %r504;
	add.s32 	%r505, %r10, 1152;
	cvt.s64.s32	%rd30, %r505;
	add.s32 	%r506, %r10, 1280;
	cvt.s64.s32	%rd31, %r506;
	add.s32 	%r507, %r10, 1408;
	cvt.s64.s32	%rd32, %r507;
	add.s32 	%r508, %r10, 1536;
	cvt.s64.s32	%rd33, %r508;
	add.s32 	%r509, %r10, 1664;
	cvt.s64.s32	%rd34, %r509;
	add.s32 	%r510, %r10, 1792;
	cvt.s64.s32	%rd35, %r510;
	mov.u32 	%r1337, %r9;
	mov.u32 	%r1338, %r13;

BB26_73:
	mov.u32 	%r1329, %r1338;
	mov.u32 	%r81, %r1337;
	mov.u32 	%r1337, %r1329;
	cvt.s64.s32	%rd277, %r81;
	add.s64 	%rd36, %rd21, %rd277;
	shl.b64 	%rd278, %rd36, 2;
	add.s64 	%rd262, %rd144, %rd278;
	// inline asm
	ld.global.nc.u32 %r511, [%rd262];
	// inline asm
	add.s64 	%rd279, %rd22, %rd277;
	shl.b64 	%rd280, %rd279, 2;
	add.s64 	%rd263, %rd144, %rd280;
	// inline asm
	ld.global.nc.u32 %r512, [%rd263];
	// inline asm
	add.s64 	%rd281, %rd23, %rd277;
	shl.b64 	%rd282, %rd281, 2;
	add.s64 	%rd264, %rd144, %rd282;
	// inline asm
	ld.global.nc.u32 %r513, [%rd264];
	// inline asm
	add.s64 	%rd283, %rd24, %rd277;
	shl.b64 	%rd284, %rd283, 2;
	add.s64 	%rd265, %rd144, %rd284;
	// inline asm
	ld.global.nc.u32 %r514, [%rd265];
	// inline asm
	add.s64 	%rd285, %rd25, %rd277;
	shl.b64 	%rd286, %rd285, 2;
	add.s64 	%rd266, %rd144, %rd286;
	// inline asm
	ld.global.nc.u32 %r515, [%rd266];
	// inline asm
	add.s64 	%rd287, %rd26, %rd277;
	shl.b64 	%rd288, %rd287, 2;
	add.s64 	%rd267, %rd144, %rd288;
	// inline asm
	ld.global.nc.u32 %r516, [%rd267];
	// inline asm
	add.s64 	%rd289, %rd27, %rd277;
	shl.b64 	%rd290, %rd289, 2;
	add.s64 	%rd268, %rd144, %rd290;
	// inline asm
	ld.global.nc.u32 %r517, [%rd268];
	// inline asm
	add.s64 	%rd291, %rd28, %rd277;
	shl.b64 	%rd292, %rd291, 2;
	add.s64 	%rd269, %rd144, %rd292;
	// inline asm
	ld.global.nc.u32 %r518, [%rd269];
	// inline asm
	add.s64 	%rd293, %rd29, %rd277;
	shl.b64 	%rd294, %rd293, 2;
	add.s64 	%rd270, %rd144, %rd294;
	// inline asm
	ld.global.nc.u32 %r519, [%rd270];
	// inline asm
	add.s64 	%rd295, %rd30, %rd277;
	shl.b64 	%rd296, %rd295, 2;
	add.s64 	%rd271, %rd144, %rd296;
	// inline asm
	ld.global.nc.u32 %r520, [%rd271];
	// inline asm
	add.s64 	%rd297, %rd31, %rd277;
	shl.b64 	%rd298, %rd297, 2;
	add.s64 	%rd272, %rd144, %rd298;
	// inline asm
	ld.global.nc.u32 %r521, [%rd272];
	// inline asm
	add.s64 	%rd299, %rd32, %rd277;
	shl.b64 	%rd300, %rd299, 2;
	add.s64 	%rd273, %rd144, %rd300;
	// inline asm
	ld.global.nc.u32 %r522, [%rd273];
	// inline asm
	add.s64 	%rd301, %rd33, %rd277;
	shl.b64 	%rd302, %rd301, 2;
	add.s64 	%rd274, %rd144, %rd302;
	// inline asm
	ld.global.nc.u32 %r523, [%rd274];
	// inline asm
	add.s64 	%rd303, %rd34, %rd277;
	shl.b64 	%rd304, %rd303, 2;
	add.s64 	%rd275, %rd144, %rd304;
	// inline asm
	ld.global.nc.u32 %r524, [%rd275];
	// inline asm
	add.s64 	%rd305, %rd35, %rd277;
	shl.b64 	%rd306, %rd305, 2;
	add.s64 	%rd276, %rd144, %rd306;
	// inline asm
	ld.global.nc.u32 %r525, [%rd276];
	// inline asm
	bar.sync 	0;
	add.s64 	%rd308, %rd1, %rd278;
	st.global.u32 	[%rd308], %r511;
	st.global.u32 	[%rd308+512], %r512;
	st.global.u32 	[%rd308+1024], %r513;
	st.global.u32 	[%rd308+1536], %r514;
	st.global.u32 	[%rd308+2048], %r515;
	st.global.u32 	[%rd308+2560], %r516;
	st.global.u32 	[%rd308+3072], %r517;
	st.global.u32 	[%rd308+3584], %r518;
	st.global.u32 	[%rd308+4096], %r519;
	st.global.u32 	[%rd308+4608], %r520;
	st.global.u32 	[%rd308+5120], %r521;
	st.global.u32 	[%rd308+5632], %r522;
	st.global.u32 	[%rd308+6144], %r523;
	st.global.u32 	[%rd308+6656], %r524;
	st.global.u32 	[%rd308+7168], %r525;
	add.s32 	%r1338, %r1337, 1920;
	setp.le.s32	%p49, %r1338, %r1302;
	mov.u32 	%r1336, %r1337;
	@%p49 bra 	BB26_73;

BB26_74:
	setp.le.s32	%p50, %r1302, %r1336;
	@%p50 bra 	BB26_271;

	sub.s32 	%r99, %r1302, %r1336;
	cvt.s64.s32	%rd37, %r1336;
	sub.s32 	%r100, %r99, %r10;
	setp.lt.s32	%p51, %r100, 1;
	@%p51 bra 	BB26_77;

	cvt.s64.s32	%rd310, %r10;
	add.s64 	%rd311, %rd310, %rd37;
	shl.b64 	%rd312, %rd311, 2;
	add.s64 	%rd309, %rd144, %rd312;
	// inline asm
	ld.global.nc.u32 %r1303, [%rd309];
	// inline asm

BB26_77:
	setp.lt.s32	%p52, %r100, 129;
	@%p52 bra 	BB26_79;

	add.s32 	%r528, %r10, 128;
	cvt.s64.s32	%rd314, %r528;
	add.s64 	%rd315, %rd314, %rd37;
	shl.b64 	%rd316, %rd315, 2;
	add.s64 	%rd313, %rd144, %rd316;
	// inline asm
	ld.global.nc.u32 %r1304, [%rd313];
	// inline asm

BB26_79:
	setp.lt.s32	%p53, %r100, 257;
	@%p53 bra 	BB26_81;

	add.s32 	%r530, %r10, 256;
	cvt.s64.s32	%rd318, %r530;
	add.s64 	%rd319, %rd318, %rd37;
	shl.b64 	%rd320, %rd319, 2;
	add.s64 	%rd317, %rd144, %rd320;
	// inline asm
	ld.global.nc.u32 %r1305, [%rd317];
	// inline asm

BB26_81:
	setp.lt.s32	%p54, %r100, 385;
	@%p54 bra 	BB26_83;

	add.s32 	%r532, %r10, 384;
	cvt.s64.s32	%rd322, %r532;
	add.s64 	%rd323, %rd322, %rd37;
	shl.b64 	%rd324, %rd323, 2;
	add.s64 	%rd321, %rd144, %rd324;
	// inline asm
	ld.global.nc.u32 %r1306, [%rd321];
	// inline asm

BB26_83:
	setp.lt.s32	%p55, %r100, 513;
	@%p55 bra 	BB26_85;

	add.s32 	%r534, %r10, 512;
	cvt.s64.s32	%rd326, %r534;
	add.s64 	%rd327, %rd326, %rd37;
	shl.b64 	%rd328, %rd327, 2;
	add.s64 	%rd325, %rd144, %rd328;
	// inline asm
	ld.global.nc.u32 %r1307, [%rd325];
	// inline asm

BB26_85:
	setp.lt.s32	%p56, %r100, 641;
	@%p56 bra 	BB26_87;

	add.s32 	%r536, %r10, 640;
	cvt.s64.s32	%rd330, %r536;
	add.s64 	%rd331, %rd330, %rd37;
	shl.b64 	%rd332, %rd331, 2;
	add.s64 	%rd329, %rd144, %rd332;
	// inline asm
	ld.global.nc.u32 %r1308, [%rd329];
	// inline asm

BB26_87:
	setp.lt.s32	%p57, %r100, 769;
	@%p57 bra 	BB26_89;

	add.s32 	%r538, %r10, 768;
	cvt.s64.s32	%rd334, %r538;
	add.s64 	%rd335, %rd334, %rd37;
	shl.b64 	%rd336, %rd335, 2;
	add.s64 	%rd333, %rd144, %rd336;
	// inline asm
	ld.global.nc.u32 %r1309, [%rd333];
	// inline asm

BB26_89:
	setp.lt.s32	%p58, %r100, 897;
	@%p58 bra 	BB26_91;

	add.s32 	%r540, %r10, 896;
	cvt.s64.s32	%rd338, %r540;
	add.s64 	%rd339, %rd338, %rd37;
	shl.b64 	%rd340, %rd339, 2;
	add.s64 	%rd337, %rd144, %rd340;
	// inline asm
	ld.global.nc.u32 %r1310, [%rd337];
	// inline asm

BB26_91:
	setp.lt.s32	%p59, %r100, 1025;
	@%p59 bra 	BB26_93;

	add.s32 	%r542, %r10, 1024;
	cvt.s64.s32	%rd342, %r542;
	add.s64 	%rd343, %rd342, %rd37;
	shl.b64 	%rd344, %rd343, 2;
	add.s64 	%rd341, %rd144, %rd344;
	// inline asm
	ld.global.nc.u32 %r1311, [%rd341];
	// inline asm

BB26_93:
	setp.lt.s32	%p60, %r100, 1153;
	@%p60 bra 	BB26_95;

	add.s32 	%r544, %r10, 1152;
	cvt.s64.s32	%rd346, %r544;
	add.s64 	%rd347, %rd346, %rd37;
	shl.b64 	%rd348, %rd347, 2;
	add.s64 	%rd345, %rd144, %rd348;
	// inline asm
	ld.global.nc.u32 %r1312, [%rd345];
	// inline asm

BB26_95:
	setp.lt.s32	%p61, %r100, 1281;
	@%p61 bra 	BB26_97;

	add.s32 	%r546, %r10, 1280;
	cvt.s64.s32	%rd350, %r546;
	add.s64 	%rd351, %rd350, %rd37;
	shl.b64 	%rd352, %rd351, 2;
	add.s64 	%rd349, %rd144, %rd352;
	// inline asm
	ld.global.nc.u32 %r1313, [%rd349];
	// inline asm

BB26_97:
	setp.lt.s32	%p62, %r100, 1409;
	@%p62 bra 	BB26_99;

	add.s32 	%r548, %r10, 1408;
	cvt.s64.s32	%rd354, %r548;
	add.s64 	%rd355, %rd354, %rd37;
	shl.b64 	%rd356, %rd355, 2;
	add.s64 	%rd353, %rd144, %rd356;
	// inline asm
	ld.global.nc.u32 %r1314, [%rd353];
	// inline asm

BB26_99:
	setp.lt.s32	%p63, %r100, 1537;
	@%p63 bra 	BB26_101;

	add.s32 	%r550, %r10, 1536;
	cvt.s64.s32	%rd358, %r550;
	add.s64 	%rd359, %rd358, %rd37;
	shl.b64 	%rd360, %rd359, 2;
	add.s64 	%rd357, %rd144, %rd360;
	// inline asm
	ld.global.nc.u32 %r1315, [%rd357];
	// inline asm

BB26_101:
	setp.lt.s32	%p64, %r100, 1665;
	@%p64 bra 	BB26_103;

	add.s32 	%r552, %r10, 1664;
	cvt.s64.s32	%rd362, %r552;
	add.s64 	%rd363, %rd362, %rd37;
	shl.b64 	%rd364, %rd363, 2;
	add.s64 	%rd361, %rd144, %rd364;
	// inline asm
	ld.global.nc.u32 %r1316, [%rd361];
	// inline asm

BB26_103:
	setp.lt.s32	%p65, %r100, 1793;
	@%p65 bra 	BB26_105;

	add.s32 	%r554, %r10, 1792;
	cvt.s64.s32	%rd366, %r554;
	add.s64 	%rd367, %rd366, %rd37;
	shl.b64 	%rd368, %rd367, 2;
	add.s64 	%rd365, %rd144, %rd368;
	// inline asm
	ld.global.nc.u32 %r1317, [%rd365];
	// inline asm

BB26_105:
	bar.sync 	0;
	cvt.s64.s32	%rd369, %r10;
	add.s64 	%rd370, %rd369, %rd37;
	shl.b64 	%rd371, %rd370, 2;
	add.s64 	%rd38, %rd1, %rd371;
	setp.le.s32	%p66, %r99, %r10;
	@%p66 bra 	BB26_107;

	st.global.u32 	[%rd38], %r1303;

BB26_107:
	add.s32 	%r555, %r10, 128;
	setp.ge.s32	%p67, %r555, %r99;
	@%p67 bra 	BB26_109;

	st.global.u32 	[%rd38+512], %r1304;

BB26_109:
	add.s32 	%r556, %r10, 256;
	setp.ge.s32	%p68, %r556, %r99;
	@%p68 bra 	BB26_111;

	st.global.u32 	[%rd38+1024], %r1305;

BB26_111:
	add.s32 	%r557, %r10, 384;
	setp.ge.s32	%p69, %r557, %r99;
	@%p69 bra 	BB26_113;

	st.global.u32 	[%rd38+1536], %r1306;

BB26_113:
	add.s32 	%r558, %r10, 512;
	setp.ge.s32	%p70, %r558, %r99;
	@%p70 bra 	BB26_115;

	st.global.u32 	[%rd38+2048], %r1307;

BB26_115:
	add.s32 	%r559, %r10, 640;
	setp.ge.s32	%p71, %r559, %r99;
	@%p71 bra 	BB26_117;

	st.global.u32 	[%rd38+2560], %r1308;

BB26_117:
	add.s32 	%r560, %r10, 768;
	setp.ge.s32	%p72, %r560, %r99;
	@%p72 bra 	BB26_119;

	st.global.u32 	[%rd38+3072], %r1309;

BB26_119:
	add.s32 	%r561, %r10, 896;
	setp.ge.s32	%p73, %r561, %r99;
	@%p73 bra 	BB26_121;

	st.global.u32 	[%rd38+3584], %r1310;

BB26_121:
	add.s32 	%r562, %r10, 1024;
	setp.ge.s32	%p74, %r562, %r99;
	@%p74 bra 	BB26_123;

	st.global.u32 	[%rd38+4096], %r1311;

BB26_123:
	add.s32 	%r563, %r10, 1152;
	setp.ge.s32	%p75, %r563, %r99;
	@%p75 bra 	BB26_125;

	st.global.u32 	[%rd38+4608], %r1312;

BB26_125:
	add.s32 	%r564, %r10, 1280;
	setp.ge.s32	%p76, %r564, %r99;
	@%p76 bra 	BB26_127;

	st.global.u32 	[%rd38+5120], %r1313;

BB26_127:
	add.s32 	%r565, %r10, 1408;
	setp.ge.s32	%p77, %r565, %r99;
	@%p77 bra 	BB26_129;

	st.global.u32 	[%rd38+5632], %r1314;

BB26_129:
	add.s32 	%r566, %r10, 1536;
	setp.ge.s32	%p78, %r566, %r99;
	@%p78 bra 	BB26_131;

	st.global.u32 	[%rd38+6144], %r1315;

BB26_131:
	add.s32 	%r567, %r10, 1664;
	setp.ge.s32	%p79, %r567, %r99;
	@%p79 bra 	BB26_133;

	st.global.u32 	[%rd38+6656], %r1316;

BB26_133:
	add.s32 	%r568, %r10, 1792;
	setp.ge.s32	%p80, %r568, %r99;
	@%p80 bra 	BB26_271;

	st.global.u32 	[%rd38+7168], %r1317;
	bra.uni 	BB26_271;

BB26_135:
	setp.gt.s32	%p81, %r13, %r1302;
	mov.u32 	%r1333, %r9;
	@%p81 bra 	BB26_144;

	shr.s32 	%r571, %r10, 31;
	shr.u32 	%r572, %r571, 27;
	add.s32 	%r573, %r10, %r572;
	shr.s32 	%r574, %r573, 5;
	mul.wide.s32 	%rd372, %r574, 8;
	mov.u64 	%rd373, _ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE18PtxDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE$__cuda_local_var_106605_76_non_const_temp_storage;
	add.s64 	%rd374, %rd373, %rd372;
	add.s64 	%rd39, %rd374, 144;
	// inline asm
	mov.u32 %r710, %laneid;
	// inline asm
	mov.u32 	%r1334, %r9;
	mov.u32 	%r1335, %r13;

BB26_137:
	mov.u32 	%r1331, %r1335;
	mov.u32 	%r132, %r1334;
	mov.u32 	%r1334, %r1331;
	mul.lo.s32 	%r590, %r10, 15;
	cvt.s64.s32	%rd390, %r590;
	cvt.s64.s32	%rd391, %r132;
	add.s64 	%rd392, %rd390, %rd391;
	shl.b64 	%rd393, %rd392, 2;
	add.s64 	%rd375, %rd142, %rd393;
	// inline asm
	ld.global.nc.u32 %r575, [%rd375];
	// inline asm
	add.s32 	%r591, %r590, 1;
	cvt.s64.s32	%rd394, %r591;
	add.s64 	%rd395, %rd394, %rd391;
	shl.b64 	%rd396, %rd395, 2;
	add.s64 	%rd376, %rd142, %rd396;
	// inline asm
	ld.global.nc.u32 %r576, [%rd376];
	// inline asm
	add.s32 	%r592, %r590, 2;
	cvt.s64.s32	%rd397, %r592;
	add.s64 	%rd398, %rd397, %rd391;
	shl.b64 	%rd399, %rd398, 2;
	add.s64 	%rd377, %rd142, %rd399;
	// inline asm
	ld.global.nc.u32 %r577, [%rd377];
	// inline asm
	add.s32 	%r593, %r590, 3;
	cvt.s64.s32	%rd400, %r593;
	add.s64 	%rd401, %rd400, %rd391;
	shl.b64 	%rd402, %rd401, 2;
	add.s64 	%rd378, %rd142, %rd402;
	// inline asm
	ld.global.nc.u32 %r578, [%rd378];
	// inline asm
	add.s32 	%r594, %r590, 4;
	cvt.s64.s32	%rd403, %r594;
	add.s64 	%rd404, %rd403, %rd391;
	shl.b64 	%rd405, %rd404, 2;
	add.s64 	%rd379, %rd142, %rd405;
	// inline asm
	ld.global.nc.u32 %r579, [%rd379];
	// inline asm
	add.s32 	%r595, %r590, 5;
	cvt.s64.s32	%rd406, %r595;
	add.s64 	%rd407, %rd406, %rd391;
	shl.b64 	%rd408, %rd407, 2;
	add.s64 	%rd380, %rd142, %rd408;
	// inline asm
	ld.global.nc.u32 %r580, [%rd380];
	// inline asm
	add.s32 	%r596, %r590, 6;
	cvt.s64.s32	%rd409, %r596;
	add.s64 	%rd410, %rd409, %rd391;
	shl.b64 	%rd411, %rd410, 2;
	add.s64 	%rd381, %rd142, %rd411;
	// inline asm
	ld.global.nc.u32 %r581, [%rd381];
	// inline asm
	add.s32 	%r597, %r590, 7;
	cvt.s64.s32	%rd412, %r597;
	add.s64 	%rd413, %rd412, %rd391;
	shl.b64 	%rd414, %rd413, 2;
	add.s64 	%rd382, %rd142, %rd414;
	// inline asm
	ld.global.nc.u32 %r582, [%rd382];
	// inline asm
	add.s32 	%r598, %r590, 8;
	cvt.s64.s32	%rd415, %r598;
	add.s64 	%rd416, %rd415, %rd391;
	shl.b64 	%rd417, %rd416, 2;
	add.s64 	%rd383, %rd142, %rd417;
	// inline asm
	ld.global.nc.u32 %r583, [%rd383];
	// inline asm
	add.s32 	%r599, %r590, 9;
	cvt.s64.s32	%rd418, %r599;
	add.s64 	%rd419, %rd418, %rd391;
	shl.b64 	%rd420, %rd419, 2;
	add.s64 	%rd384, %rd142, %rd420;
	// inline asm
	ld.global.nc.u32 %r584, [%rd384];
	// inline asm
	add.s32 	%r600, %r590, 10;
	cvt.s64.s32	%rd421, %r600;
	add.s64 	%rd422, %rd421, %rd391;
	shl.b64 	%rd423, %rd422, 2;
	add.s64 	%rd385, %rd142, %rd423;
	// inline asm
	ld.global.nc.u32 %r585, [%rd385];
	// inline asm
	add.s32 	%r601, %r590, 11;
	cvt.s64.s32	%rd424, %r601;
	add.s64 	%rd425, %rd424, %rd391;
	shl.b64 	%rd426, %rd425, 2;
	add.s64 	%rd386, %rd142, %rd426;
	// inline asm
	ld.global.nc.u32 %r586, [%rd386];
	// inline asm
	add.s32 	%r602, %r590, 12;
	cvt.s64.s32	%rd427, %r602;
	add.s64 	%rd428, %rd427, %rd391;
	shl.b64 	%rd429, %rd428, 2;
	add.s64 	%rd387, %rd142, %rd429;
	// inline asm
	ld.global.nc.u32 %r587, [%rd387];
	// inline asm
	add.s32 	%r603, %r590, 13;
	cvt.s64.s32	%rd430, %r603;
	add.s64 	%rd431, %rd430, %rd391;
	shl.b64 	%rd432, %rd431, 2;
	add.s64 	%rd388, %rd142, %rd432;
	// inline asm
	ld.global.nc.u32 %r588, [%rd388];
	// inline asm
	add.s32 	%r604, %r590, 14;
	cvt.s64.s32	%rd433, %r604;
	add.s64 	%rd434, %rd433, %rd391;
	shl.b64 	%rd435, %rd434, 2;
	add.s64 	%rd389, %rd142, %rd435;
	// inline asm
	ld.global.nc.u32 %r589, [%rd389];
	// inline asm
	bar.sync 	0;
	xor.b32  	%r606, %r575, -2147483648;
	xor.b32  	%r610, %r576, -2147483648;
	xor.b32  	%r614, %r577, -2147483648;
	xor.b32  	%r618, %r578, -2147483648;
	xor.b32  	%r622, %r579, -2147483648;
	xor.b32  	%r626, %r580, -2147483648;
	xor.b32  	%r630, %r581, -2147483648;
	xor.b32  	%r634, %r582, -2147483648;
	xor.b32  	%r638, %r583, -2147483648;
	xor.b32  	%r642, %r584, -2147483648;
	xor.b32  	%r646, %r585, -2147483648;
	xor.b32  	%r650, %r586, -2147483648;
	xor.b32  	%r654, %r587, -2147483648;
	xor.b32  	%r658, %r588, -2147483648;
	xor.b32  	%r662, %r589, -2147483648;
	cvt.s64.s32	%rd40, %r10;
	mul.wide.s32 	%rd436, %r10, 8;
	add.s64 	%rd438, %rd373, 184;
	add.s64 	%rd439, %rd438, %rd436;
	mov.u64 	%rd440, 0;
	st.shared.u64 	[%rd439], %rd440;
	st.shared.u64 	[%rd439+1024], %rd440;
	st.shared.u64 	[%rd439+2048], %rd440;
	st.shared.u64 	[%rd439+3072], %rd440;
	st.shared.u64 	[%rd439+4096], %rd440;
	st.shared.u64 	[%rd439+5120], %rd440;
	st.shared.u64 	[%rd439+6144], %rd440;
	st.shared.u64 	[%rd439+7168], %rd440;
	st.shared.u64 	[%rd439+8192], %rd440;
	// inline asm
	bfe.u32 %r605, %r606, %r390, %r391;
	// inline asm
	shr.u32 	%r665, %r605, 3;
	and.b32  	%r666, %r605, 7;
	mul.wide.u32 	%rd441, %r666, 1024;
	add.s64 	%rd442, %rd438, %rd441;
	add.s64 	%rd443, %rd442, %rd436;
	mul.wide.u32 	%rd444, %r665, 2;
	add.s64 	%rd41, %rd443, %rd444;
	ld.shared.u16 	%r165, [%rd41];
	add.s32 	%r667, %r165, 1;
	st.shared.u16 	[%rd41], %r667;
	// inline asm
	bfe.u32 %r609, %r610, %r390, %r391;
	// inline asm
	and.b32  	%r668, %r609, 7;
	shr.u32 	%r669, %r609, 3;
	mul.wide.u32 	%rd445, %r668, 1024;
	add.s64 	%rd446, %rd438, %rd445;
	add.s64 	%rd447, %rd446, %rd436;
	mul.wide.u32 	%rd448, %r669, 2;
	add.s64 	%rd42, %rd447, %rd448;
	ld.shared.u16 	%r166, [%rd42];
	add.s32 	%r670, %r166, 1;
	st.shared.u16 	[%rd42], %r670;
	// inline asm
	bfe.u32 %r613, %r614, %r390, %r391;
	// inline asm
	shr.u32 	%r671, %r613, 3;
	and.b32  	%r672, %r613, 7;
	mul.wide.u32 	%rd449, %r672, 1024;
	add.s64 	%rd450, %rd438, %rd449;
	add.s64 	%rd451, %rd450, %rd436;
	mul.wide.u32 	%rd452, %r671, 2;
	add.s64 	%rd43, %rd451, %rd452;
	ld.shared.u16 	%r167, [%rd43];
	add.s32 	%r673, %r167, 1;
	st.shared.u16 	[%rd43], %r673;
	// inline asm
	bfe.u32 %r617, %r618, %r390, %r391;
	// inline asm
	shr.u32 	%r674, %r617, 3;
	and.b32  	%r675, %r617, 7;
	mul.wide.u32 	%rd453, %r675, 1024;
	add.s64 	%rd454, %rd438, %rd453;
	add.s64 	%rd455, %rd454, %rd436;
	mul.wide.u32 	%rd456, %r674, 2;
	add.s64 	%rd44, %rd455, %rd456;
	ld.shared.u16 	%r168, [%rd44];
	add.s32 	%r676, %r168, 1;
	st.shared.u16 	[%rd44], %r676;
	// inline asm
	bfe.u32 %r621, %r622, %r390, %r391;
	// inline asm
	shr.u32 	%r677, %r621, 3;
	and.b32  	%r678, %r621, 7;
	mul.wide.u32 	%rd457, %r678, 1024;
	add.s64 	%rd458, %rd438, %rd457;
	add.s64 	%rd459, %rd458, %rd436;
	mul.wide.u32 	%rd460, %r677, 2;
	add.s64 	%rd45, %rd459, %rd460;
	ld.shared.u16 	%r169, [%rd45];
	add.s32 	%r679, %r169, 1;
	st.shared.u16 	[%rd45], %r679;
	// inline asm
	bfe.u32 %r625, %r626, %r390, %r391;
	// inline asm
	shr.u32 	%r680, %r625, 3;
	and.b32  	%r681, %r625, 7;
	mul.wide.u32 	%rd461, %r681, 1024;
	add.s64 	%rd462, %rd438, %rd461;
	add.s64 	%rd463, %rd462, %rd436;
	mul.wide.u32 	%rd464, %r680, 2;
	add.s64 	%rd46, %rd463, %rd464;
	ld.shared.u16 	%r170, [%rd46];
	add.s32 	%r682, %r170, 1;
	st.shared.u16 	[%rd46], %r682;
	// inline asm
	bfe.u32 %r629, %r630, %r390, %r391;
	// inline asm
	shr.u32 	%r683, %r629, 3;
	and.b32  	%r684, %r629, 7;
	mul.wide.u32 	%rd465, %r684, 1024;
	add.s64 	%rd466, %rd438, %rd465;
	add.s64 	%rd467, %rd466, %rd436;
	mul.wide.u32 	%rd468, %r683, 2;
	add.s64 	%rd47, %rd467, %rd468;
	ld.shared.u16 	%r171, [%rd47];
	add.s32 	%r685, %r171, 1;
	st.shared.u16 	[%rd47], %r685;
	// inline asm
	bfe.u32 %r633, %r634, %r390, %r391;
	// inline asm
	shr.u32 	%r686, %r633, 3;
	and.b32  	%r687, %r633, 7;
	mul.wide.u32 	%rd469, %r687, 1024;
	add.s64 	%rd470, %rd438, %rd469;
	add.s64 	%rd471, %rd470, %rd436;
	mul.wide.u32 	%rd472, %r686, 2;
	add.s64 	%rd48, %rd471, %rd472;
	ld.shared.u16 	%r172, [%rd48];
	add.s32 	%r688, %r172, 1;
	st.shared.u16 	[%rd48], %r688;
	// inline asm
	bfe.u32 %r637, %r638, %r390, %r391;
	// inline asm
	shr.u32 	%r689, %r637, 3;
	and.b32  	%r690, %r637, 7;
	mul.wide.u32 	%rd473, %r690, 1024;
	add.s64 	%rd474, %rd438, %rd473;
	add.s64 	%rd475, %rd474, %rd436;
	mul.wide.u32 	%rd476, %r689, 2;
	add.s64 	%rd49, %rd475, %rd476;
	ld.shared.u16 	%r173, [%rd49];
	add.s32 	%r691, %r173, 1;
	st.shared.u16 	[%rd49], %r691;
	// inline asm
	bfe.u32 %r641, %r642, %r390, %r391;
	// inline asm
	shr.u32 	%r692, %r641, 3;
	and.b32  	%r693, %r641, 7;
	mul.wide.u32 	%rd477, %r693, 1024;
	add.s64 	%rd478, %rd438, %rd477;
	add.s64 	%rd479, %rd478, %rd436;
	mul.wide.u32 	%rd480, %r692, 2;
	add.s64 	%rd50, %rd479, %rd480;
	ld.shared.u16 	%r174, [%rd50];
	add.s32 	%r694, %r174, 1;
	st.shared.u16 	[%rd50], %r694;
	// inline asm
	bfe.u32 %r645, %r646, %r390, %r391;
	// inline asm
	shr.u32 	%r695, %r645, 3;
	and.b32  	%r696, %r645, 7;
	mul.wide.u32 	%rd481, %r696, 1024;
	add.s64 	%rd482, %rd438, %rd481;
	add.s64 	%rd483, %rd482, %rd436;
	mul.wide.u32 	%rd484, %r695, 2;
	add.s64 	%rd51, %rd483, %rd484;
	ld.shared.u16 	%r175, [%rd51];
	add.s32 	%r697, %r175, 1;
	st.shared.u16 	[%rd51], %r697;
	// inline asm
	bfe.u32 %r649, %r650, %r390, %r391;
	// inline asm
	shr.u32 	%r698, %r649, 3;
	and.b32  	%r699, %r649, 7;
	mul.wide.u32 	%rd485, %r699, 1024;
	add.s64 	%rd486, %rd438, %rd485;
	add.s64 	%rd487, %rd486, %rd436;
	mul.wide.u32 	%rd488, %r698, 2;
	add.s64 	%rd52, %rd487, %rd488;
	ld.shared.u16 	%r176, [%rd52];
	add.s32 	%r700, %r176, 1;
	st.shared.u16 	[%rd52], %r700;
	// inline asm
	bfe.u32 %r653, %r654, %r390, %r391;
	// inline asm
	shr.u32 	%r701, %r653, 3;
	and.b32  	%r702, %r653, 7;
	mul.wide.u32 	%rd489, %r702, 1024;
	add.s64 	%rd490, %rd438, %rd489;
	add.s64 	%rd491, %rd490, %rd436;
	mul.wide.u32 	%rd492, %r701, 2;
	add.s64 	%rd53, %rd491, %rd492;
	ld.shared.u16 	%r177, [%rd53];
	add.s32 	%r703, %r177, 1;
	st.shared.u16 	[%rd53], %r703;
	// inline asm
	bfe.u32 %r657, %r658, %r390, %r391;
	// inline asm
	shr.u32 	%r704, %r657, 3;
	and.b32  	%r705, %r657, 7;
	mul.wide.u32 	%rd493, %r705, 1024;
	add.s64 	%rd494, %rd438, %rd493;
	add.s64 	%rd495, %rd494, %rd436;
	mul.wide.u32 	%rd496, %r704, 2;
	add.s64 	%rd54, %rd495, %rd496;
	ld.shared.u16 	%r178, [%rd54];
	add.s32 	%r706, %r178, 1;
	st.shared.u16 	[%rd54], %r706;
	// inline asm
	bfe.u32 %r661, %r662, %r390, %r391;
	// inline asm
	shr.u32 	%r707, %r661, 3;
	and.b32  	%r708, %r661, 7;
	mul.wide.u32 	%rd497, %r708, 1024;
	add.s64 	%rd498, %rd438, %rd497;
	add.s64 	%rd499, %rd498, %rd436;
	mul.wide.u32 	%rd500, %r707, 2;
	add.s64 	%rd55, %rd499, %rd500;
	ld.shared.u16 	%r179, [%rd55];
	add.s32 	%r709, %r179, 1;
	st.shared.u16 	[%rd55], %r709;
	bar.sync 	0;
	mul.lo.s64 	%rd511, %rd40, 72;
	add.s64 	%rd513, %rd373, %rd511;
	ld.shared.u64 	%rd56, [%rd513+192];
	ld.shared.u64 	%rd57, [%rd513+184];
	add.s64 	%rd514, %rd56, %rd57;
	ld.shared.u64 	%rd58, [%rd513+200];
	add.s64 	%rd515, %rd514, %rd58;
	ld.shared.u64 	%rd59, [%rd513+208];
	add.s64 	%rd516, %rd515, %rd59;
	ld.shared.u64 	%rd60, [%rd513+216];
	add.s64 	%rd517, %rd516, %rd60;
	ld.shared.u64 	%rd61, [%rd513+224];
	add.s64 	%rd518, %rd517, %rd61;
	ld.shared.u64 	%rd62, [%rd513+232];
	add.s64 	%rd519, %rd518, %rd62;
	ld.shared.u64 	%rd63, [%rd513+240];
	add.s64 	%rd520, %rd519, %rd63;
	ld.shared.u64 	%rd521, [%rd513+248];
	add.s64 	%rd502, %rd520, %rd521;
	mov.u32 	%r711, 1;
	mov.u32 	%r720, 0;
	// inline asm
	{  .reg .u32 lo;  .reg .u32 hi;  .reg .pred p;  mov.b64 {lo, hi}, %rd502;  shfl.up.b32 lo|p, lo, %r711, %r720;  shfl.up.b32 hi|p, hi, %r711, %r720;  mov.b64 %rd501, {lo, hi};  @p add.u64 %rd501, %rd501, %rd502;}
	// inline asm
	mov.u32 	%r713, 2;
	// inline asm
	{  .reg .u32 lo;  .reg .u32 hi;  .reg .pred p;  mov.b64 {lo, hi}, %rd501;  shfl.up.b32 lo|p, lo, %r713, %r720;  shfl.up.b32 hi|p, hi, %r713, %r720;  mov.b64 %rd503, {lo, hi};  @p add.u64 %rd503, %rd503, %rd501;}
	// inline asm
	mov.u32 	%r715, 4;
	// inline asm
	{  .reg .u32 lo;  .reg .u32 hi;  .reg .pred p;  mov.b64 {lo, hi}, %rd503;  shfl.up.b32 lo|p, lo, %r715, %r720;  shfl.up.b32 hi|p, hi, %r715, %r720;  mov.b64 %rd505, {lo, hi};  @p add.u64 %rd505, %rd505, %rd503;}
	// inline asm
	mov.u32 	%r717, 8;
	// inline asm
	{  .reg .u32 lo;  .reg .u32 hi;  .reg .pred p;  mov.b64 {lo, hi}, %rd505;  shfl.up.b32 lo|p, lo, %r717, %r720;  shfl.up.b32 hi|p, hi, %r717, %r720;  mov.b64 %rd507, {lo, hi};  @p add.u64 %rd507, %rd507, %rd505;}
	// inline asm
	mov.u32 	%r719, 16;
	// inline asm
	{  .reg .u32 lo;  .reg .u32 hi;  .reg .pred p;  mov.b64 {lo, hi}, %rd507;  shfl.up.b32 lo|p, lo, %r719, %r720;  shfl.up.b32 hi|p, hi, %r719, %r720;  mov.b64 %rd509, {lo, hi};  @p add.u64 %rd509, %rd509, %rd507;}
	// inline asm
	setp.ne.s32	%p82, %r710, 31;
	@%p82 bra 	BB26_139;

	st.shared.u64 	[%rd39], %rd509;

BB26_139:
	sub.s64 	%rd66, %rd509, %rd502;
	setp.lt.s32	%p1, %r10, 32;
	and.b32  	%r721, %r10, -32;
	setp.eq.s32	%p2, %r721, 96;
	setp.eq.s32	%p3, %r721, 64;
	setp.eq.s32	%p4, %r721, 32;
	bar.sync 	0;
	ld.shared.u64 	%rd523, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE18PtxDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE$__cuda_local_var_106605_76_non_const_temp_storage+144];
	selp.b64	%rd524, %rd523, 0, %p4;
	add.s64 	%rd525, %rd66, %rd524;
	ld.shared.u64 	%rd526, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE18PtxDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE$__cuda_local_var_106605_76_non_const_temp_storage+152];
	add.s64 	%rd527, %rd526, %rd523;
	selp.b64	%rd528, %rd527, 0, %p3;
	add.s64 	%rd529, %rd525, %rd528;
	ld.shared.u64 	%rd530, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE18PtxDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE$__cuda_local_var_106605_76_non_const_temp_storage+160];
	add.s64 	%rd531, %rd527, %rd530;
	selp.b64	%rd532, %rd531, 0, %p2;
	add.s64 	%rd533, %rd529, %rd532;
	ld.shared.u64 	%rd534, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE18PtxDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE$__cuda_local_var_106605_76_non_const_temp_storage+168];
	add.s64 	%rd535, %rd531, %rd534;
	shl.b64 	%rd536, %rd535, 16;
	add.s64 	%rd537, %rd536, %rd533;
	shl.b64 	%rd538, %rd535, 32;
	add.s64 	%rd539, %rd538, %rd537;
	shl.b64 	%rd540, %rd535, 48;
	add.s64 	%rd541, %rd540, %rd539;
	add.s64 	%rd542, %rd57, %rd541;
	add.s64 	%rd543, %rd542, %rd56;
	add.s64 	%rd544, %rd543, %rd58;
	add.s64 	%rd545, %rd544, %rd59;
	add.s64 	%rd546, %rd545, %rd60;
	add.s64 	%rd547, %rd546, %rd61;
	add.s64 	%rd548, %rd547, %rd62;
	add.s64 	%rd549, %rd548, %rd63;
	mul.wide.s32 	%rd550, %r10, 72;
	add.s64 	%rd551, %rd373, %rd550;
	st.shared.u64 	[%rd551+184], %rd541;
	st.shared.u64 	[%rd551+192], %rd542;
	st.shared.u64 	[%rd551+200], %rd543;
	st.shared.u64 	[%rd551+208], %rd544;
	st.shared.u64 	[%rd551+216], %rd545;
	st.shared.u64 	[%rd551+224], %rd546;
	st.shared.u64 	[%rd551+232], %rd547;
	st.shared.u64 	[%rd551+240], %rd548;
	st.shared.u64 	[%rd551+248], %rd549;
	bar.sync 	0;
	ld.shared.u16 	%r722, [%rd41];
	add.s32 	%r180, %r722, %r165;
	ld.shared.u16 	%r723, [%rd42];
	add.s32 	%r181, %r723, %r166;
	ld.shared.u16 	%r724, [%rd43];
	add.s32 	%r182, %r724, %r167;
	ld.shared.u16 	%r725, [%rd44];
	add.s32 	%r183, %r725, %r168;
	ld.shared.u16 	%r726, [%rd45];
	add.s32 	%r184, %r726, %r169;
	ld.shared.u16 	%r727, [%rd46];
	add.s32 	%r185, %r727, %r170;
	ld.shared.u16 	%r728, [%rd47];
	add.s32 	%r186, %r728, %r171;
	ld.shared.u16 	%r729, [%rd48];
	add.s32 	%r187, %r729, %r172;
	ld.shared.u16 	%r730, [%rd49];
	add.s32 	%r188, %r730, %r173;
	ld.shared.u16 	%r731, [%rd50];
	add.s32 	%r189, %r731, %r174;
	ld.shared.u16 	%r732, [%rd51];
	add.s32 	%r190, %r732, %r175;
	ld.shared.u16 	%r733, [%rd52];
	add.s32 	%r191, %r733, %r176;
	ld.shared.u16 	%r734, [%rd53];
	add.s32 	%r192, %r734, %r177;
	ld.shared.u16 	%r735, [%rd54];
	add.s32 	%r193, %r735, %r178;
	ld.shared.u16 	%r736, [%rd55];
	add.s32 	%r194, %r736, %r179;
	@!%p1 bra 	BB26_141;
	bra.uni 	BB26_140;

BB26_140:
	and.b32  	%r737, %r10, 7;
	add.s32 	%r738, %r737, 1;
	shr.s32 	%r739, %r10, 3;
	mul.wide.u32 	%rd552, %r738, 1024;
	add.s64 	%rd554, %rd373, %rd552;
	mul.wide.s32 	%rd555, %r739, 2;
	add.s64 	%rd556, %rd554, %rd555;
	ld.shared.u16 	%r1318, [%rd556+184];

BB26_141:
	@%p9 bra 	BB26_143;

	mov.u32 	%r1296, 0;
	mov.u32 	%r1295, 1;
	setp.eq.s32	%p84, %r10, 0;
	// inline asm
	  shfl.up.b32 %r740, %r1318, %r1295, %r1296;
	// inline asm
	selp.b32	%r744, 0, %r740, %p84;
	sub.s32 	%r745, %r1343, %r744;
	mul.wide.u32 	%rd557, %r10, 4;
	add.s64 	%rd559, %rd373, %rd557;
	st.shared.u32 	[%rd559], %r745;
	add.s32 	%r1343, %r745, %r1318;

BB26_143:
	bar.sync 	0;
	mul.wide.u32 	%rd560, %r180, 4;
	add.s64 	%rd562, %rd373, 136;
	add.s64 	%rd68, %rd562, %rd560;
	st.shared.u32 	[%rd68], %r606;
	mul.wide.u32 	%rd563, %r181, 4;
	add.s64 	%rd69, %rd562, %rd563;
	st.shared.u32 	[%rd69], %r610;
	mul.wide.u32 	%rd564, %r182, 4;
	add.s64 	%rd70, %rd562, %rd564;
	st.shared.u32 	[%rd70], %r614;
	mul.wide.u32 	%rd565, %r183, 4;
	add.s64 	%rd71, %rd562, %rd565;
	st.shared.u32 	[%rd71], %r618;
	mul.wide.u32 	%rd566, %r184, 4;
	add.s64 	%rd72, %rd562, %rd566;
	st.shared.u32 	[%rd72], %r622;
	mul.wide.u32 	%rd567, %r185, 4;
	add.s64 	%rd73, %rd562, %rd567;
	st.shared.u32 	[%rd73], %r626;
	mul.wide.u32 	%rd568, %r186, 4;
	add.s64 	%rd74, %rd562, %rd568;
	st.shared.u32 	[%rd74], %r630;
	mul.wide.u32 	%rd569, %r187, 4;
	add.s64 	%rd75, %rd562, %rd569;
	st.shared.u32 	[%rd75], %r634;
	mul.wide.u32 	%rd570, %r188, 4;
	add.s64 	%rd76, %rd562, %rd570;
	st.shared.u32 	[%rd76], %r638;
	mul.wide.u32 	%rd571, %r189, 4;
	add.s64 	%rd77, %rd562, %rd571;
	st.shared.u32 	[%rd77], %r642;
	mul.wide.u32 	%rd572, %r190, 4;
	add.s64 	%rd78, %rd562, %rd572;
	st.shared.u32 	[%rd78], %r646;
	mul.wide.u32 	%rd573, %r191, 4;
	add.s64 	%rd79, %rd562, %rd573;
	st.shared.u32 	[%rd79], %r650;
	mul.wide.u32 	%rd574, %r192, 4;
	add.s64 	%rd80, %rd562, %rd574;
	st.shared.u32 	[%rd80], %r654;
	mul.wide.u32 	%rd575, %r193, 4;
	add.s64 	%rd81, %rd562, %rd575;
	st.shared.u32 	[%rd81], %r658;
	mul.wide.u32 	%rd576, %r194, 4;
	add.s64 	%rd82, %rd562, %rd576;
	st.shared.u32 	[%rd82], %r662;
	bar.sync 	0;
	shl.b64 	%rd577, %rd40, 2;
	add.s64 	%rd83, %rd373, %rd577;
	ld.shared.u32 	%r747, [%rd83+136];
	ld.shared.u32 	%r751, [%rd83+648];
	ld.shared.u32 	%r755, [%rd83+1160];
	ld.shared.u32 	%r759, [%rd83+1672];
	ld.shared.u32 	%r763, [%rd83+2184];
	ld.shared.u32 	%r767, [%rd83+2696];
	ld.shared.u32 	%r771, [%rd83+3208];
	ld.shared.u32 	%r775, [%rd83+3720];
	ld.shared.u32 	%r779, [%rd83+4232];
	ld.shared.u32 	%r783, [%rd83+4744];
	ld.shared.u32 	%r787, [%rd83+5256];
	ld.shared.u32 	%r791, [%rd83+5768];
	ld.shared.u32 	%r795, [%rd83+6280];
	ld.shared.u32 	%r799, [%rd83+6792];
	ld.shared.u32 	%r803, [%rd83+7304];
	// inline asm
	bfe.u32 %r746, %r747, %r390, %r391;
	// inline asm
	mul.wide.u32 	%rd579, %r746, 4;
	add.s64 	%rd580, %rd373, %rd579;
	ld.shared.u32 	%r806, [%rd580];
	// inline asm
	bfe.u32 %r750, %r751, %r390, %r391;
	// inline asm
	mul.wide.u32 	%rd581, %r750, 4;
	add.s64 	%rd582, %rd373, %rd581;
	ld.shared.u32 	%r807, [%rd582];
	// inline asm
	bfe.u32 %r754, %r755, %r390, %r391;
	// inline asm
	mul.wide.u32 	%rd583, %r754, 4;
	add.s64 	%rd584, %rd373, %rd583;
	ld.shared.u32 	%r808, [%rd584];
	// inline asm
	bfe.u32 %r758, %r759, %r390, %r391;
	// inline asm
	mul.wide.u32 	%rd585, %r758, 4;
	add.s64 	%rd586, %rd373, %rd585;
	ld.shared.u32 	%r809, [%rd586];
	// inline asm
	bfe.u32 %r762, %r763, %r390, %r391;
	// inline asm
	mul.wide.u32 	%rd587, %r762, 4;
	add.s64 	%rd588, %rd373, %rd587;
	ld.shared.u32 	%r810, [%rd588];
	// inline asm
	bfe.u32 %r766, %r767, %r390, %r391;
	// inline asm
	mul.wide.u32 	%rd589, %r766, 4;
	add.s64 	%rd590, %rd373, %rd589;
	ld.shared.u32 	%r811, [%rd590];
	// inline asm
	bfe.u32 %r770, %r771, %r390, %r391;
	// inline asm
	mul.wide.u32 	%rd591, %r770, 4;
	add.s64 	%rd592, %rd373, %rd591;
	ld.shared.u32 	%r812, [%rd592];
	// inline asm
	bfe.u32 %r774, %r775, %r390, %r391;
	// inline asm
	mul.wide.u32 	%rd593, %r774, 4;
	add.s64 	%rd594, %rd373, %rd593;
	ld.shared.u32 	%r813, [%rd594];
	// inline asm
	bfe.u32 %r778, %r779, %r390, %r391;
	// inline asm
	mul.wide.u32 	%rd595, %r778, 4;
	add.s64 	%rd596, %rd373, %rd595;
	ld.shared.u32 	%r814, [%rd596];
	// inline asm
	bfe.u32 %r782, %r783, %r390, %r391;
	// inline asm
	mul.wide.u32 	%rd597, %r782, 4;
	add.s64 	%rd598, %rd373, %rd597;
	ld.shared.u32 	%r815, [%rd598];
	// inline asm
	bfe.u32 %r786, %r787, %r390, %r391;
	// inline asm
	mul.wide.u32 	%rd599, %r786, 4;
	add.s64 	%rd600, %rd373, %rd599;
	ld.shared.u32 	%r816, [%rd600];
	// inline asm
	bfe.u32 %r790, %r791, %r390, %r391;
	// inline asm
	mul.wide.u32 	%rd601, %r790, 4;
	add.s64 	%rd602, %rd373, %rd601;
	ld.shared.u32 	%r817, [%rd602];
	// inline asm
	bfe.u32 %r794, %r795, %r390, %r391;
	// inline asm
	mul.wide.u32 	%rd603, %r794, 4;
	add.s64 	%rd604, %rd373, %rd603;
	ld.shared.u32 	%r818, [%rd604];
	// inline asm
	bfe.u32 %r798, %r799, %r390, %r391;
	// inline asm
	mul.wide.u32 	%rd605, %r798, 4;
	add.s64 	%rd606, %rd373, %rd605;
	ld.shared.u32 	%r819, [%rd606];
	// inline asm
	bfe.u32 %r802, %r803, %r390, %r391;
	// inline asm
	mul.wide.u32 	%rd607, %r802, 4;
	add.s64 	%rd608, %rd373, %rd607;
	ld.shared.u32 	%r820, [%rd608];
	xor.b32  	%r821, %r803, -2147483648;
	xor.b32  	%r822, %r799, -2147483648;
	xor.b32  	%r823, %r795, -2147483648;
	xor.b32  	%r824, %r791, -2147483648;
	xor.b32  	%r825, %r787, -2147483648;
	xor.b32  	%r826, %r783, -2147483648;
	xor.b32  	%r827, %r779, -2147483648;
	xor.b32  	%r828, %r775, -2147483648;
	xor.b32  	%r829, %r771, -2147483648;
	xor.b32  	%r830, %r767, -2147483648;
	xor.b32  	%r831, %r763, -2147483648;
	xor.b32  	%r832, %r759, -2147483648;
	xor.b32  	%r833, %r755, -2147483648;
	xor.b32  	%r834, %r751, -2147483648;
	xor.b32  	%r835, %r747, -2147483648;
	add.s32 	%r836, %r10, %r806;
	cvt.s64.s32	%rd84, %r836;
	mul.wide.s32 	%rd610, %r836, 4;
	add.s64 	%rd611, %rd2, %rd610;
	st.global.u32 	[%rd611], %r835;
	add.s32 	%r837, %r10, 128;
	add.s32 	%r838, %r837, %r807;
	cvt.s64.s32	%rd85, %r838;
	mul.wide.s32 	%rd612, %r838, 4;
	add.s64 	%rd613, %rd2, %rd612;
	st.global.u32 	[%rd613], %r834;
	add.s32 	%r839, %r837, %r808;
	add.s32 	%r840, %r839, 128;
	cvt.s64.s32	%rd86, %r840;
	mul.wide.s32 	%rd614, %r840, 4;
	add.s64 	%rd615, %rd2, %rd614;
	st.global.u32 	[%rd615], %r833;
	add.s32 	%r841, %r837, %r809;
	add.s32 	%r842, %r841, 256;
	cvt.s64.s32	%rd87, %r842;
	mul.wide.s32 	%rd616, %r842, 4;
	add.s64 	%rd617, %rd2, %rd616;
	st.global.u32 	[%rd617], %r832;
	add.s32 	%r843, %r837, %r810;
	add.s32 	%r844, %r843, 384;
	cvt.s64.s32	%rd88, %r844;
	mul.wide.s32 	%rd618, %r844, 4;
	add.s64 	%rd619, %rd2, %rd618;
	st.global.u32 	[%rd619], %r831;
	add.s32 	%r845, %r837, %r811;
	add.s32 	%r846, %r845, 512;
	cvt.s64.s32	%rd89, %r846;
	mul.wide.s32 	%rd620, %r846, 4;
	add.s64 	%rd621, %rd2, %rd620;
	st.global.u32 	[%rd621], %r830;
	add.s32 	%r847, %r837, %r812;
	add.s32 	%r848, %r847, 640;
	cvt.s64.s32	%rd90, %r848;
	mul.wide.s32 	%rd622, %r848, 4;
	add.s64 	%rd623, %rd2, %rd622;
	st.global.u32 	[%rd623], %r829;
	add.s32 	%r849, %r837, %r813;
	add.s32 	%r850, %r849, 768;
	cvt.s64.s32	%rd91, %r850;
	mul.wide.s32 	%rd624, %r850, 4;
	add.s64 	%rd625, %rd2, %rd624;
	st.global.u32 	[%rd625], %r828;
	add.s32 	%r851, %r837, %r814;
	add.s32 	%r852, %r851, 896;
	cvt.s64.s32	%rd92, %r852;
	mul.wide.s32 	%rd626, %r852, 4;
	add.s64 	%rd627, %rd2, %rd626;
	st.global.u32 	[%rd627], %r827;
	add.s32 	%r853, %r837, %r815;
	add.s32 	%r854, %r853, 1024;
	cvt.s64.s32	%rd93, %r854;
	mul.wide.s32 	%rd628, %r854, 4;
	add.s64 	%rd629, %rd2, %rd628;
	st.global.u32 	[%rd629], %r826;
	add.s32 	%r855, %r837, %r816;
	add.s32 	%r856, %r855, 1152;
	cvt.s64.s32	%rd94, %r856;
	mul.wide.s32 	%rd630, %r856, 4;
	add.s64 	%rd631, %rd2, %rd630;
	st.global.u32 	[%rd631], %r825;
	add.s32 	%r857, %r837, %r817;
	add.s32 	%r858, %r857, 1280;
	cvt.s64.s32	%rd95, %r858;
	mul.wide.s32 	%rd632, %r858, 4;
	add.s64 	%rd633, %rd2, %rd632;
	st.global.u32 	[%rd633], %r824;
	add.s32 	%r859, %r837, %r818;
	add.s32 	%r860, %r859, 1408;
	cvt.s64.s32	%rd96, %r860;
	mul.wide.s32 	%rd634, %r860, 4;
	add.s64 	%rd635, %rd2, %rd634;
	st.global.u32 	[%rd635], %r823;
	add.s32 	%r861, %r837, %r819;
	add.s32 	%r862, %r861, 1536;
	cvt.s64.s32	%rd97, %r862;
	mul.wide.s32 	%rd636, %r862, 4;
	add.s64 	%rd637, %rd2, %rd636;
	st.global.u32 	[%rd637], %r822;
	add.s32 	%r863, %r837, %r820;
	add.s32 	%r864, %r863, 1664;
	cvt.s64.s32	%rd98, %r864;
	mul.wide.s32 	%rd638, %r864, 4;
	add.s64 	%rd639, %rd2, %rd638;
	st.global.u32 	[%rd639], %r821;
	bar.sync 	0;
	add.s64 	%rd640, %rd144, %rd393;
	// inline asm
	ld.global.nc.u32 %r865, [%rd640];
	// inline asm
	add.s64 	%rd641, %rd144, %rd396;
	// inline asm
	ld.global.nc.u32 %r866, [%rd641];
	// inline asm
	add.s64 	%rd642, %rd144, %rd399;
	// inline asm
	ld.global.nc.u32 %r867, [%rd642];
	// inline asm
	add.s64 	%rd643, %rd144, %rd402;
	// inline asm
	ld.global.nc.u32 %r868, [%rd643];
	// inline asm
	add.s64 	%rd644, %rd144, %rd405;
	// inline asm
	ld.global.nc.u32 %r869, [%rd644];
	// inline asm
	add.s64 	%rd645, %rd144, %rd408;
	// inline asm
	ld.global.nc.u32 %r870, [%rd645];
	// inline asm
	add.s64 	%rd646, %rd144, %rd411;
	// inline asm
	ld.global.nc.u32 %r871, [%rd646];
	// inline asm
	add.s64 	%rd647, %rd144, %rd414;
	// inline asm
	ld.global.nc.u32 %r872, [%rd647];
	// inline asm
	add.s64 	%rd648, %rd144, %rd417;
	// inline asm
	ld.global.nc.u32 %r873, [%rd648];
	// inline asm
	add.s64 	%rd649, %rd144, %rd420;
	// inline asm
	ld.global.nc.u32 %r874, [%rd649];
	// inline asm
	add.s64 	%rd650, %rd144, %rd423;
	// inline asm
	ld.global.nc.u32 %r875, [%rd650];
	// inline asm
	add.s64 	%rd651, %rd144, %rd426;
	// inline asm
	ld.global.nc.u32 %r876, [%rd651];
	// inline asm
	add.s64 	%rd652, %rd144, %rd429;
	// inline asm
	ld.global.nc.u32 %r877, [%rd652];
	// inline asm
	add.s64 	%rd653, %rd144, %rd432;
	// inline asm
	ld.global.nc.u32 %r878, [%rd653];
	// inline asm
	add.s64 	%rd654, %rd144, %rd435;
	// inline asm
	ld.global.nc.u32 %r879, [%rd654];
	// inline asm
	bar.sync 	0;
	st.shared.u32 	[%rd68], %r865;
	st.shared.u32 	[%rd69], %r866;
	st.shared.u32 	[%rd70], %r867;
	st.shared.u32 	[%rd71], %r868;
	st.shared.u32 	[%rd72], %r869;
	st.shared.u32 	[%rd73], %r870;
	st.shared.u32 	[%rd74], %r871;
	st.shared.u32 	[%rd75], %r872;
	st.shared.u32 	[%rd76], %r873;
	st.shared.u32 	[%rd77], %r874;
	st.shared.u32 	[%rd78], %r875;
	st.shared.u32 	[%rd79], %r876;
	st.shared.u32 	[%rd80], %r877;
	st.shared.u32 	[%rd81], %r878;
	st.shared.u32 	[%rd82], %r879;
	bar.sync 	0;
	ld.shared.u32 	%r1374, [%rd83+136];
	ld.shared.u32 	%r1375, [%rd83+648];
	ld.shared.u32 	%r1376, [%rd83+1160];
	ld.shared.u32 	%r1377, [%rd83+1672];
	ld.shared.u32 	%r1378, [%rd83+2184];
	ld.shared.u32 	%r1379, [%rd83+2696];
	ld.shared.u32 	%r1380, [%rd83+3208];
	ld.shared.u32 	%r1381, [%rd83+3720];
	ld.shared.u32 	%r1382, [%rd83+4232];
	ld.shared.u32 	%r1383, [%rd83+4744];
	ld.shared.u32 	%r1384, [%rd83+5256];
	ld.shared.u32 	%r1385, [%rd83+5768];
	ld.shared.u32 	%r1386, [%rd83+6280];
	ld.shared.u32 	%r1387, [%rd83+6792];
	ld.shared.u32 	%r1388, [%rd83+7304];
	shl.b64 	%rd702, %rd84, 2;
	add.s64 	%rd703, %rd1, %rd702;
	st.global.u32 	[%rd703], %r1374;
	shl.b64 	%rd704, %rd85, 2;
	add.s64 	%rd705, %rd1, %rd704;
	st.global.u32 	[%rd705], %r1375;
	shl.b64 	%rd706, %rd86, 2;
	add.s64 	%rd707, %rd1, %rd706;
	st.global.u32 	[%rd707], %r1376;
	shl.b64 	%rd708, %rd87, 2;
	add.s64 	%rd709, %rd1, %rd708;
	st.global.u32 	[%rd709], %r1377;
	shl.b64 	%rd710, %rd88, 2;
	add.s64 	%rd711, %rd1, %rd710;
	st.global.u32 	[%rd711], %r1378;
	shl.b64 	%rd712, %rd89, 2;
	add.s64 	%rd713, %rd1, %rd712;
	st.global.u32 	[%rd713], %r1379;
	shl.b64 	%rd714, %rd90, 2;
	add.s64 	%rd715, %rd1, %rd714;
	st.global.u32 	[%rd715], %r1380;
	shl.b64 	%rd716, %rd91, 2;
	add.s64 	%rd717, %rd1, %rd716;
	st.global.u32 	[%rd717], %r1381;
	shl.b64 	%rd718, %rd92, 2;
	add.s64 	%rd719, %rd1, %rd718;
	st.global.u32 	[%rd719], %r1382;
	shl.b64 	%rd720, %rd93, 2;
	add.s64 	%rd721, %rd1, %rd720;
	st.global.u32 	[%rd721], %r1383;
	shl.b64 	%rd722, %rd94, 2;
	add.s64 	%rd723, %rd1, %rd722;
	st.global.u32 	[%rd723], %r1384;
	shl.b64 	%rd724, %rd95, 2;
	add.s64 	%rd725, %rd1, %rd724;
	st.global.u32 	[%rd725], %r1385;
	shl.b64 	%rd726, %rd96, 2;
	add.s64 	%rd727, %rd1, %rd726;
	st.global.u32 	[%rd727], %r1386;
	shl.b64 	%rd728, %rd97, 2;
	add.s64 	%rd729, %rd1, %rd728;
	st.global.u32 	[%rd729], %r1387;
	shl.b64 	%rd730, %rd98, 2;
	add.s64 	%rd731, %rd1, %rd730;
	st.global.u32 	[%rd731], %r1388;
	bar.sync 	0;
	add.s32 	%r1335, %r1334, 1920;
	setp.le.s32	%p85, %r1335, %r1302;
	mov.u32 	%r1333, %r1334;
	@%p85 bra 	BB26_137;

BB26_144:
	setp.le.s32	%p86, %r1302, %r1333;
	@%p86 bra 	BB26_271;

	sub.s32 	%r247, %r1302, %r1333;
	cvt.s64.s32	%rd99, %r1333;
	mad.lo.s32 	%r248, %r10, -15, %r247;
	mul.lo.s32 	%r249, %r10, 15;
	mov.u32 	%r895, -1;
	setp.lt.s32	%p87, %r248, 1;
	mov.u32 	%r1372, %r895;
	@%p87 bra 	BB26_147;

	cvt.s64.s32	%rd733, %r249;
	add.s64 	%rd734, %rd733, %rd99;
	shl.b64 	%rd735, %rd734, 2;
	add.s64 	%rd732, %rd142, %rd735;
	// inline asm
	ld.global.nc.u32 %r896, [%rd732];
	// inline asm
	xor.b32  	%r250, %r896, -2147483648;
	mov.u32 	%r1372, %r250;

BB26_147:
	mov.u32 	%r251, %r1372;
	setp.lt.s32	%p88, %r248, 2;
	mov.u32 	%r1371, %r895;
	@%p88 bra 	BB26_149;

	add.s32 	%r899, %r249, 1;
	cvt.s64.s32	%rd737, %r899;
	add.s64 	%rd738, %rd737, %rd99;
	shl.b64 	%rd739, %rd738, 2;
	add.s64 	%rd736, %rd142, %rd739;
	// inline asm
	ld.global.nc.u32 %r898, [%rd736];
	// inline asm
	xor.b32  	%r1371, %r898, -2147483648;

BB26_149:
	setp.lt.s32	%p89, %r248, 3;
	mov.u32 	%r1370, %r895;
	@%p89 bra 	BB26_151;

	add.s32 	%r902, %r249, 2;
	cvt.s64.s32	%rd741, %r902;
	add.s64 	%rd742, %rd741, %rd99;
	shl.b64 	%rd743, %rd742, 2;
	add.s64 	%rd740, %rd142, %rd743;
	// inline asm
	ld.global.nc.u32 %r901, [%rd740];
	// inline asm
	xor.b32  	%r1370, %r901, -2147483648;

BB26_151:
	setp.lt.s32	%p90, %r248, 4;
	mov.u32 	%r1369, %r895;
	@%p90 bra 	BB26_153;

	add.s32 	%r905, %r249, 3;
	cvt.s64.s32	%rd745, %r905;
	add.s64 	%rd746, %rd745, %rd99;
	shl.b64 	%rd747, %rd746, 2;
	add.s64 	%rd744, %rd142, %rd747;
	// inline asm
	ld.global.nc.u32 %r904, [%rd744];
	// inline asm
	xor.b32  	%r1369, %r904, -2147483648;

BB26_153:
	setp.lt.s32	%p91, %r248, 5;
	mov.u32 	%r1368, %r895;
	@%p91 bra 	BB26_155;

	add.s32 	%r908, %r249, 4;
	cvt.s64.s32	%rd749, %r908;
	add.s64 	%rd750, %rd749, %rd99;
	shl.b64 	%rd751, %rd750, 2;
	add.s64 	%rd748, %rd142, %rd751;
	// inline asm
	ld.global.nc.u32 %r907, [%rd748];
	// inline asm
	xor.b32  	%r1368, %r907, -2147483648;

BB26_155:
	setp.lt.s32	%p92, %r248, 6;
	mov.u32 	%r1367, %r895;
	@%p92 bra 	BB26_157;

	add.s32 	%r911, %r249, 5;
	cvt.s64.s32	%rd753, %r911;
	add.s64 	%rd754, %rd753, %rd99;
	shl.b64 	%rd755, %rd754, 2;
	add.s64 	%rd752, %rd142, %rd755;
	// inline asm
	ld.global.nc.u32 %r910, [%rd752];
	// inline asm
	xor.b32  	%r1367, %r910, -2147483648;

BB26_157:
	setp.lt.s32	%p93, %r248, 7;
	mov.u32 	%r1366, %r895;
	@%p93 bra 	BB26_159;

	add.s32 	%r914, %r249, 6;
	cvt.s64.s32	%rd757, %r914;
	add.s64 	%rd758, %rd757, %rd99;
	shl.b64 	%rd759, %rd758, 2;
	add.s64 	%rd756, %rd142, %rd759;
	// inline asm
	ld.global.nc.u32 %r913, [%rd756];
	// inline asm
	xor.b32  	%r1366, %r913, -2147483648;

BB26_159:
	setp.lt.s32	%p94, %r248, 8;
	mov.u32 	%r1365, %r895;
	@%p94 bra 	BB26_161;

	add.s32 	%r917, %r249, 7;
	cvt.s64.s32	%rd761, %r917;
	add.s64 	%rd762, %rd761, %rd99;
	shl.b64 	%rd763, %rd762, 2;
	add.s64 	%rd760, %rd142, %rd763;
	// inline asm
	ld.global.nc.u32 %r916, [%rd760];
	// inline asm
	xor.b32  	%r1365, %r916, -2147483648;

BB26_161:
	setp.lt.s32	%p95, %r248, 9;
	mov.u32 	%r1364, %r895;
	@%p95 bra 	BB26_163;

	add.s32 	%r920, %r249, 8;
	cvt.s64.s32	%rd765, %r920;
	add.s64 	%rd766, %rd765, %rd99;
	shl.b64 	%rd767, %rd766, 2;
	add.s64 	%rd764, %rd142, %rd767;
	// inline asm
	ld.global.nc.u32 %r919, [%rd764];
	// inline asm
	xor.b32  	%r1364, %r919, -2147483648;

BB26_163:
	setp.lt.s32	%p96, %r248, 10;
	mov.u32 	%r1363, %r895;
	@%p96 bra 	BB26_165;

	add.s32 	%r923, %r249, 9;
	cvt.s64.s32	%rd769, %r923;
	add.s64 	%rd770, %rd769, %rd99;
	shl.b64 	%rd771, %rd770, 2;
	add.s64 	%rd768, %rd142, %rd771;
	// inline asm
	ld.global.nc.u32 %r922, [%rd768];
	// inline asm
	xor.b32  	%r1363, %r922, -2147483648;

BB26_165:
	setp.lt.s32	%p97, %r248, 11;
	mov.u32 	%r1362, %r895;
	@%p97 bra 	BB26_167;

	add.s32 	%r926, %r249, 10;
	cvt.s64.s32	%rd773, %r926;
	add.s64 	%rd774, %rd773, %rd99;
	shl.b64 	%rd775, %rd774, 2;
	add.s64 	%rd772, %rd142, %rd775;
	// inline asm
	ld.global.nc.u32 %r925, [%rd772];
	// inline asm
	xor.b32  	%r1362, %r925, -2147483648;

BB26_167:
	setp.lt.s32	%p98, %r248, 12;
	mov.u32 	%r1361, %r895;
	@%p98 bra 	BB26_169;

	add.s32 	%r929, %r249, 11;
	cvt.s64.s32	%rd777, %r929;
	add.s64 	%rd778, %rd777, %rd99;
	shl.b64 	%rd779, %rd778, 2;
	add.s64 	%rd776, %rd142, %rd779;
	// inline asm
	ld.global.nc.u32 %r928, [%rd776];
	// inline asm
	xor.b32  	%r1361, %r928, -2147483648;

BB26_169:
	setp.lt.s32	%p99, %r248, 13;
	mov.u32 	%r1360, %r895;
	@%p99 bra 	BB26_171;

	add.s32 	%r932, %r249, 12;
	cvt.s64.s32	%rd781, %r932;
	add.s64 	%rd782, %rd781, %rd99;
	shl.b64 	%rd783, %rd782, 2;
	add.s64 	%rd780, %rd142, %rd783;
	// inline asm
	ld.global.nc.u32 %r931, [%rd780];
	// inline asm
	xor.b32  	%r1360, %r931, -2147483648;

BB26_171:
	setp.lt.s32	%p100, %r248, 14;
	mov.u32 	%r1359, %r895;
	@%p100 bra 	BB26_173;

	add.s32 	%r935, %r249, 13;
	cvt.s64.s32	%rd785, %r935;
	add.s64 	%rd786, %rd785, %rd99;
	shl.b64 	%rd787, %rd786, 2;
	add.s64 	%rd784, %rd142, %rd787;
	// inline asm
	ld.global.nc.u32 %r934, [%rd784];
	// inline asm
	xor.b32  	%r1359, %r934, -2147483648;

BB26_173:
	setp.lt.s32	%p101, %r248, 15;
	mov.u32 	%r1358, %r895;
	@%p101 bra 	BB26_175;

	add.s32 	%r938, %r249, 14;
	cvt.s64.s32	%rd789, %r938;
	add.s64 	%rd790, %rd789, %rd99;
	shl.b64 	%rd791, %rd790, 2;
	add.s64 	%rd788, %rd142, %rd791;
	// inline asm
	ld.global.nc.u32 %r937, [%rd788];
	// inline asm
	xor.b32  	%r1358, %r937, -2147483648;

BB26_175:
	bar.sync 	0;
	cvt.s64.s32	%rd100, %r10;
	mul.wide.s32 	%rd792, %r10, 8;
	mov.u64 	%rd793, _ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE18PtxDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE$__cuda_local_var_106605_76_non_const_temp_storage;
	add.s64 	%rd794, %rd793, 184;
	add.s64 	%rd795, %rd794, %rd792;
	mov.u64 	%rd796, 0;
	st.shared.u64 	[%rd795], %rd796;
	st.shared.u64 	[%rd795+1024], %rd796;
	st.shared.u64 	[%rd795+2048], %rd796;
	st.shared.u64 	[%rd795+3072], %rd796;
	st.shared.u64 	[%rd795+4096], %rd796;
	st.shared.u64 	[%rd795+5120], %rd796;
	st.shared.u64 	[%rd795+6144], %rd796;
	st.shared.u64 	[%rd795+7168], %rd796;
	st.shared.u64 	[%rd795+8192], %rd796;
	// inline asm
	bfe.u32 %r939, %r251, %r390, %r391;
	// inline asm
	shr.u32 	%r999, %r939, 3;
	and.b32  	%r1000, %r939, 7;
	mul.wide.u32 	%rd797, %r1000, 1024;
	add.s64 	%rd798, %rd794, %rd797;
	add.s64 	%rd799, %rd798, %rd792;
	mul.wide.u32 	%rd800, %r999, 2;
	add.s64 	%rd101, %rd799, %rd800;
	ld.shared.u16 	%r280, [%rd101];
	add.s32 	%r1001, %r280, 1;
	st.shared.u16 	[%rd101], %r1001;
	// inline asm
	bfe.u32 %r943, %r1371, %r390, %r391;
	// inline asm
	and.b32  	%r1002, %r943, 7;
	shr.u32 	%r1003, %r943, 3;
	mul.wide.u32 	%rd801, %r1002, 1024;
	add.s64 	%rd802, %rd794, %rd801;
	add.s64 	%rd803, %rd802, %rd792;
	mul.wide.u32 	%rd804, %r1003, 2;
	add.s64 	%rd102, %rd803, %rd804;
	ld.shared.u16 	%r281, [%rd102];
	add.s32 	%r1004, %r281, 1;
	st.shared.u16 	[%rd102], %r1004;
	// inline asm
	bfe.u32 %r947, %r1370, %r390, %r391;
	// inline asm
	shr.u32 	%r1005, %r947, 3;
	and.b32  	%r1006, %r947, 7;
	mul.wide.u32 	%rd805, %r1006, 1024;
	add.s64 	%rd806, %rd794, %rd805;
	add.s64 	%rd807, %rd806, %rd792;
	mul.wide.u32 	%rd808, %r1005, 2;
	add.s64 	%rd103, %rd807, %rd808;
	ld.shared.u16 	%r282, [%rd103];
	add.s32 	%r1007, %r282, 1;
	st.shared.u16 	[%rd103], %r1007;
	// inline asm
	bfe.u32 %r951, %r1369, %r390, %r391;
	// inline asm
	shr.u32 	%r1008, %r951, 3;
	and.b32  	%r1009, %r951, 7;
	mul.wide.u32 	%rd809, %r1009, 1024;
	add.s64 	%rd810, %rd794, %rd809;
	add.s64 	%rd811, %rd810, %rd792;
	mul.wide.u32 	%rd812, %r1008, 2;
	add.s64 	%rd104, %rd811, %rd812;
	ld.shared.u16 	%r283, [%rd104];
	add.s32 	%r1010, %r283, 1;
	st.shared.u16 	[%rd104], %r1010;
	// inline asm
	bfe.u32 %r955, %r1368, %r390, %r391;
	// inline asm
	shr.u32 	%r1011, %r955, 3;
	and.b32  	%r1012, %r955, 7;
	mul.wide.u32 	%rd813, %r1012, 1024;
	add.s64 	%rd814, %rd794, %rd813;
	add.s64 	%rd815, %rd814, %rd792;
	mul.wide.u32 	%rd816, %r1011, 2;
	add.s64 	%rd105, %rd815, %rd816;
	ld.shared.u16 	%r284, [%rd105];
	add.s32 	%r1013, %r284, 1;
	st.shared.u16 	[%rd105], %r1013;
	// inline asm
	bfe.u32 %r959, %r1367, %r390, %r391;
	// inline asm
	shr.u32 	%r1014, %r959, 3;
	and.b32  	%r1015, %r959, 7;
	mul.wide.u32 	%rd817, %r1015, 1024;
	add.s64 	%rd818, %rd794, %rd817;
	add.s64 	%rd819, %rd818, %rd792;
	mul.wide.u32 	%rd820, %r1014, 2;
	add.s64 	%rd106, %rd819, %rd820;
	ld.shared.u16 	%r285, [%rd106];
	add.s32 	%r1016, %r285, 1;
	st.shared.u16 	[%rd106], %r1016;
	// inline asm
	bfe.u32 %r963, %r1366, %r390, %r391;
	// inline asm
	shr.u32 	%r1017, %r963, 3;
	and.b32  	%r1018, %r963, 7;
	mul.wide.u32 	%rd821, %r1018, 1024;
	add.s64 	%rd822, %rd794, %rd821;
	add.s64 	%rd823, %rd822, %rd792;
	mul.wide.u32 	%rd824, %r1017, 2;
	add.s64 	%rd107, %rd823, %rd824;
	ld.shared.u16 	%r286, [%rd107];
	add.s32 	%r1019, %r286, 1;
	st.shared.u16 	[%rd107], %r1019;
	// inline asm
	bfe.u32 %r967, %r1365, %r390, %r391;
	// inline asm
	shr.u32 	%r1020, %r967, 3;
	and.b32  	%r1021, %r967, 7;
	mul.wide.u32 	%rd825, %r1021, 1024;
	add.s64 	%rd826, %rd794, %rd825;
	add.s64 	%rd827, %rd826, %rd792;
	mul.wide.u32 	%rd828, %r1020, 2;
	add.s64 	%rd108, %rd827, %rd828;
	ld.shared.u16 	%r287, [%rd108];
	add.s32 	%r1022, %r287, 1;
	st.shared.u16 	[%rd108], %r1022;
	// inline asm
	bfe.u32 %r971, %r1364, %r390, %r391;
	// inline asm
	shr.u32 	%r1023, %r971, 3;
	and.b32  	%r1024, %r971, 7;
	mul.wide.u32 	%rd829, %r1024, 1024;
	add.s64 	%rd830, %rd794, %rd829;
	add.s64 	%rd831, %rd830, %rd792;
	mul.wide.u32 	%rd832, %r1023, 2;
	add.s64 	%rd109, %rd831, %rd832;
	ld.shared.u16 	%r288, [%rd109];
	add.s32 	%r1025, %r288, 1;
	st.shared.u16 	[%rd109], %r1025;
	// inline asm
	bfe.u32 %r975, %r1363, %r390, %r391;
	// inline asm
	shr.u32 	%r1026, %r975, 3;
	and.b32  	%r1027, %r975, 7;
	mul.wide.u32 	%rd833, %r1027, 1024;
	add.s64 	%rd834, %rd794, %rd833;
	add.s64 	%rd835, %rd834, %rd792;
	mul.wide.u32 	%rd836, %r1026, 2;
	add.s64 	%rd110, %rd835, %rd836;
	ld.shared.u16 	%r289, [%rd110];
	add.s32 	%r1028, %r289, 1;
	st.shared.u16 	[%rd110], %r1028;
	// inline asm
	bfe.u32 %r979, %r1362, %r390, %r391;
	// inline asm
	shr.u32 	%r1029, %r979, 3;
	and.b32  	%r1030, %r979, 7;
	mul.wide.u32 	%rd837, %r1030, 1024;
	add.s64 	%rd838, %rd794, %rd837;
	add.s64 	%rd839, %rd838, %rd792;
	mul.wide.u32 	%rd840, %r1029, 2;
	add.s64 	%rd111, %rd839, %rd840;
	ld.shared.u16 	%r290, [%rd111];
	add.s32 	%r1031, %r290, 1;
	st.shared.u16 	[%rd111], %r1031;
	// inline asm
	bfe.u32 %r983, %r1361, %r390, %r391;
	// inline asm
	shr.u32 	%r1032, %r983, 3;
	and.b32  	%r1033, %r983, 7;
	mul.wide.u32 	%rd841, %r1033, 1024;
	add.s64 	%rd842, %rd794, %rd841;
	add.s64 	%rd843, %rd842, %rd792;
	mul.wide.u32 	%rd844, %r1032, 2;
	add.s64 	%rd112, %rd843, %rd844;
	ld.shared.u16 	%r291, [%rd112];
	add.s32 	%r1034, %r291, 1;
	st.shared.u16 	[%rd112], %r1034;
	// inline asm
	bfe.u32 %r987, %r1360, %r390, %r391;
	// inline asm
	shr.u32 	%r1035, %r987, 3;
	and.b32  	%r1036, %r987, 7;
	mul.wide.u32 	%rd845, %r1036, 1024;
	add.s64 	%rd846, %rd794, %rd845;
	add.s64 	%rd847, %rd846, %rd792;
	mul.wide.u32 	%rd848, %r1035, 2;
	add.s64 	%rd113, %rd847, %rd848;
	ld.shared.u16 	%r292, [%rd113];
	add.s32 	%r1037, %r292, 1;
	st.shared.u16 	[%rd113], %r1037;
	// inline asm
	bfe.u32 %r991, %r1359, %r390, %r391;
	// inline asm
	shr.u32 	%r1038, %r991, 3;
	and.b32  	%r1039, %r991, 7;
	mul.wide.u32 	%rd849, %r1039, 1024;
	add.s64 	%rd850, %rd794, %rd849;
	add.s64 	%rd851, %rd850, %rd792;
	mul.wide.u32 	%rd852, %r1038, 2;
	add.s64 	%rd114, %rd851, %rd852;
	ld.shared.u16 	%r293, [%rd114];
	add.s32 	%r1040, %r293, 1;
	st.shared.u16 	[%rd114], %r1040;
	// inline asm
	bfe.u32 %r995, %r1358, %r390, %r391;
	// inline asm
	shr.u32 	%r1041, %r995, 3;
	and.b32  	%r1042, %r995, 7;
	mul.wide.u32 	%rd853, %r1042, 1024;
	add.s64 	%rd854, %rd794, %rd853;
	add.s64 	%rd855, %rd854, %rd792;
	mul.wide.u32 	%rd856, %r1041, 2;
	add.s64 	%rd115, %rd855, %rd856;
	ld.shared.u16 	%r294, [%rd115];
	add.s32 	%r1043, %r294, 1;
	st.shared.u16 	[%rd115], %r1043;
	bar.sync 	0;
	mul.lo.s64 	%rd867, %rd100, 72;
	add.s64 	%rd869, %rd793, %rd867;
	ld.shared.u64 	%rd116, [%rd869+192];
	ld.shared.u64 	%rd117, [%rd869+184];
	add.s64 	%rd870, %rd116, %rd117;
	ld.shared.u64 	%rd118, [%rd869+200];
	add.s64 	%rd871, %rd870, %rd118;
	ld.shared.u64 	%rd119, [%rd869+208];
	add.s64 	%rd872, %rd871, %rd119;
	ld.shared.u64 	%rd120, [%rd869+216];
	add.s64 	%rd873, %rd872, %rd120;
	ld.shared.u64 	%rd121, [%rd869+224];
	add.s64 	%rd874, %rd873, %rd121;
	ld.shared.u64 	%rd122, [%rd869+232];
	add.s64 	%rd875, %rd874, %rd122;
	ld.shared.u64 	%rd123, [%rd869+240];
	add.s64 	%rd876, %rd875, %rd123;
	ld.shared.u64 	%rd877, [%rd869+248];
	add.s64 	%rd858, %rd876, %rd877;
	// inline asm
	mov.u32 %r1044, %laneid;
	// inline asm
	mov.u32 	%r1045, 1;
	mov.u32 	%r1054, 0;
	// inline asm
	{  .reg .u32 lo;  .reg .u32 hi;  .reg .pred p;  mov.b64 {lo, hi}, %rd858;  shfl.up.b32 lo|p, lo, %r1045, %r1054;  shfl.up.b32 hi|p, hi, %r1045, %r1054;  mov.b64 %rd857, {lo, hi};  @p add.u64 %rd857, %rd857, %rd858;}
	// inline asm
	mov.u32 	%r1047, 2;
	// inline asm
	{  .reg .u32 lo;  .reg .u32 hi;  .reg .pred p;  mov.b64 {lo, hi}, %rd857;  shfl.up.b32 lo|p, lo, %r1047, %r1054;  shfl.up.b32 hi|p, hi, %r1047, %r1054;  mov.b64 %rd859, {lo, hi};  @p add.u64 %rd859, %rd859, %rd857;}
	// inline asm
	mov.u32 	%r1049, 4;
	// inline asm
	{  .reg .u32 lo;  .reg .u32 hi;  .reg .pred p;  mov.b64 {lo, hi}, %rd859;  shfl.up.b32 lo|p, lo, %r1049, %r1054;  shfl.up.b32 hi|p, hi, %r1049, %r1054;  mov.b64 %rd861, {lo, hi};  @p add.u64 %rd861, %rd861, %rd859;}
	// inline asm
	mov.u32 	%r1051, 8;
	// inline asm
	{  .reg .u32 lo;  .reg .u32 hi;  .reg .pred p;  mov.b64 {lo, hi}, %rd861;  shfl.up.b32 lo|p, lo, %r1051, %r1054;  shfl.up.b32 hi|p, hi, %r1051, %r1054;  mov.b64 %rd863, {lo, hi};  @p add.u64 %rd863, %rd863, %rd861;}
	// inline asm
	mov.u32 	%r1053, 16;
	// inline asm
	{  .reg .u32 lo;  .reg .u32 hi;  .reg .pred p;  mov.b64 {lo, hi}, %rd863;  shfl.up.b32 lo|p, lo, %r1053, %r1054;  shfl.up.b32 hi|p, hi, %r1053, %r1054;  mov.b64 %rd865, {lo, hi};  @p add.u64 %rd865, %rd865, %rd863;}
	// inline asm
	setp.ne.s32	%p102, %r1044, 31;
	@%p102 bra 	BB26_177;

	shr.s32 	%r1056, %r10, 31;
	shr.u32 	%r1057, %r1056, 27;
	add.s32 	%r1058, %r10, %r1057;
	shr.s32 	%r1059, %r1058, 5;
	mul.wide.s32 	%rd878, %r1059, 8;
	add.s64 	%rd880, %rd793, %rd878;
	st.shared.u64 	[%rd880+144], %rd865;

BB26_177:
	sub.s64 	%rd126, %rd865, %rd858;
	bar.sync 	0;
	and.b32  	%r1060, %r10, -32;
	setp.eq.s32	%p103, %r1060, 32;
	ld.shared.u64 	%rd882, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE18PtxDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE$__cuda_local_var_106605_76_non_const_temp_storage+144];
	selp.b64	%rd883, %rd882, 0, %p103;
	add.s64 	%rd884, %rd126, %rd883;
	ld.shared.u64 	%rd885, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE18PtxDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE$__cuda_local_var_106605_76_non_const_temp_storage+152];
	add.s64 	%rd886, %rd885, %rd882;
	setp.eq.s32	%p104, %r1060, 64;
	selp.b64	%rd887, %rd886, 0, %p104;
	add.s64 	%rd888, %rd884, %rd887;
	ld.shared.u64 	%rd889, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE18PtxDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE$__cuda_local_var_106605_76_non_const_temp_storage+160];
	add.s64 	%rd890, %rd886, %rd889;
	setp.eq.s32	%p105, %r1060, 96;
	selp.b64	%rd891, %rd890, 0, %p105;
	add.s64 	%rd892, %rd888, %rd891;
	ld.shared.u64 	%rd893, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE18PtxDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE$__cuda_local_var_106605_76_non_const_temp_storage+168];
	add.s64 	%rd894, %rd890, %rd893;
	shl.b64 	%rd895, %rd894, 16;
	add.s64 	%rd896, %rd895, %rd892;
	shl.b64 	%rd897, %rd894, 32;
	add.s64 	%rd898, %rd897, %rd896;
	shl.b64 	%rd899, %rd894, 48;
	add.s64 	%rd900, %rd899, %rd898;
	add.s64 	%rd901, %rd117, %rd900;
	add.s64 	%rd902, %rd901, %rd116;
	add.s64 	%rd903, %rd902, %rd118;
	add.s64 	%rd904, %rd903, %rd119;
	add.s64 	%rd905, %rd904, %rd120;
	add.s64 	%rd906, %rd905, %rd121;
	add.s64 	%rd907, %rd906, %rd122;
	add.s64 	%rd908, %rd907, %rd123;
	mul.wide.s32 	%rd909, %r10, 72;
	add.s64 	%rd910, %rd793, %rd909;
	st.shared.u64 	[%rd910+184], %rd900;
	st.shared.u64 	[%rd910+192], %rd901;
	st.shared.u64 	[%rd910+200], %rd902;
	st.shared.u64 	[%rd910+208], %rd903;
	st.shared.u64 	[%rd910+216], %rd904;
	st.shared.u64 	[%rd910+224], %rd905;
	st.shared.u64 	[%rd910+232], %rd906;
	st.shared.u64 	[%rd910+240], %rd907;
	st.shared.u64 	[%rd910+248], %rd908;
	bar.sync 	0;
	ld.shared.u16 	%r1062, [%rd101];
	add.s32 	%r296, %r1062, %r280;
	ld.shared.u16 	%r1063, [%rd102];
	add.s32 	%r297, %r1063, %r281;
	ld.shared.u16 	%r1064, [%rd103];
	add.s32 	%r298, %r1064, %r282;
	ld.shared.u16 	%r1065, [%rd104];
	add.s32 	%r299, %r1065, %r283;
	ld.shared.u16 	%r1066, [%rd105];
	add.s32 	%r300, %r1066, %r284;
	ld.shared.u16 	%r1067, [%rd106];
	add.s32 	%r301, %r1067, %r285;
	ld.shared.u16 	%r1068, [%rd107];
	add.s32 	%r302, %r1068, %r286;
	ld.shared.u16 	%r1069, [%rd108];
	add.s32 	%r303, %r1069, %r287;
	ld.shared.u16 	%r1070, [%rd109];
	add.s32 	%r304, %r1070, %r288;
	ld.shared.u16 	%r1071, [%rd110];
	add.s32 	%r305, %r1071, %r289;
	ld.shared.u16 	%r1072, [%rd111];
	add.s32 	%r306, %r1072, %r290;
	ld.shared.u16 	%r1073, [%rd112];
	add.s32 	%r307, %r1073, %r291;
	ld.shared.u16 	%r1074, [%rd113];
	add.s32 	%r308, %r1074, %r292;
	ld.shared.u16 	%r1075, [%rd114];
	add.s32 	%r309, %r1075, %r293;
	ld.shared.u16 	%r1076, [%rd115];
	add.s32 	%r310, %r1076, %r294;
	setp.gt.s32	%p106, %r10, 31;
	@%p106 bra 	BB26_179;

	and.b32  	%r1078, %r10, 7;
	shr.s32 	%r1079, %r10, 3;
	add.s32 	%r1080, %r1078, 1;
	mul.wide.u32 	%rd911, %r1080, 1024;
	add.s64 	%rd913, %rd793, %rd911;
	mul.wide.s32 	%rd914, %r1079, 2;
	add.s64 	%rd915, %rd913, %rd914;
	ld.shared.u16 	%r1373, [%rd915+184];

BB26_179:
	@%p9 bra 	BB26_181;

	mov.u32 	%r1301, 0;
	mov.u32 	%r1300, 1;
	// inline asm
	  shfl.up.b32 %r1082, %r1373, %r1300, %r1301;
	// inline asm
	setp.eq.s32	%p108, %r10, 0;
	selp.b32	%r1087, 0, %r1082, %p108;
	sub.s32 	%r1088, %r1343, %r1087;
	mul.wide.u32 	%rd916, %r10, 4;
	add.s64 	%rd918, %rd793, %rd916;
	st.shared.u32 	[%rd918], %r1088;

BB26_181:
	bar.sync 	0;
	mul.wide.u32 	%rd919, %r296, 4;
	add.s64 	%rd921, %rd793, 136;
	add.s64 	%rd127, %rd921, %rd919;
	st.shared.u32 	[%rd127], %r251;
	mul.wide.u32 	%rd922, %r297, 4;
	add.s64 	%rd128, %rd921, %rd922;
	st.shared.u32 	[%rd128], %r1371;
	mul.wide.u32 	%rd923, %r298, 4;
	add.s64 	%rd129, %rd921, %rd923;
	st.shared.u32 	[%rd129], %r1370;
	mul.wide.u32 	%rd924, %r299, 4;
	add.s64 	%rd130, %rd921, %rd924;
	st.shared.u32 	[%rd130], %r1369;
	mul.wide.u32 	%rd925, %r300, 4;
	add.s64 	%rd131, %rd921, %rd925;
	st.shared.u32 	[%rd131], %r1368;
	mul.wide.u32 	%rd926, %r301, 4;
	add.s64 	%rd132, %rd921, %rd926;
	st.shared.u32 	[%rd132], %r1367;
	mul.wide.u32 	%rd927, %r302, 4;
	add.s64 	%rd133, %rd921, %rd927;
	st.shared.u32 	[%rd133], %r1366;
	mul.wide.u32 	%rd928, %r303, 4;
	add.s64 	%rd134, %rd921, %rd928;
	st.shared.u32 	[%rd134], %r1365;
	mul.wide.u32 	%rd929, %r304, 4;
	add.s64 	%rd135, %rd921, %rd929;
	st.shared.u32 	[%rd135], %r1364;
	mul.wide.u32 	%rd930, %r305, 4;
	add.s64 	%rd136, %rd921, %rd930;
	st.shared.u32 	[%rd136], %r1363;
	mul.wide.u32 	%rd931, %r306, 4;
	add.s64 	%rd137, %rd921, %rd931;
	st.shared.u32 	[%rd137], %r1362;
	mul.wide.u32 	%rd932, %r307, 4;
	add.s64 	%rd138, %rd921, %rd932;
	st.shared.u32 	[%rd138], %r1361;
	mul.wide.u32 	%rd933, %r308, 4;
	add.s64 	%rd139, %rd921, %rd933;
	st.shared.u32 	[%rd139], %r1360;
	mul.wide.u32 	%rd934, %r309, 4;
	add.s64 	%rd140, %rd921, %rd934;
	st.shared.u32 	[%rd140], %r1359;
	mul.wide.u32 	%rd935, %r310, 4;
	add.s64 	%rd141, %rd921, %rd935;
	st.shared.u32 	[%rd141], %r1358;
	bar.sync 	0;
	ld.param.u32 	%r1298, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE18PtxDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_7];
	ld.param.u32 	%r1297, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE18PtxDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_6];
	mul.wide.s32 	%rd936, %r10, 4;
	add.s64 	%rd938, %rd793, %rd936;
	ld.shared.u32 	%r313, [%rd938+136];
	add.s32 	%r314, %r10, 128;
	ld.shared.u32 	%r315, [%rd938+648];
	ld.shared.u32 	%r316, [%rd938+1160];
	ld.shared.u32 	%r317, [%rd938+1672];
	ld.shared.u32 	%r318, [%rd938+2184];
	ld.shared.u32 	%r319, [%rd938+2696];
	ld.shared.u32 	%r320, [%rd938+3208];
	ld.shared.u32 	%r321, [%rd938+3720];
	ld.shared.u32 	%r322, [%rd938+4232];
	ld.shared.u32 	%r323, [%rd938+4744];
	ld.shared.u32 	%r324, [%rd938+5256];
	ld.shared.u32 	%r325, [%rd938+5768];
	ld.shared.u32 	%r326, [%rd938+6280];
	ld.shared.u32 	%r327, [%rd938+6792];
	ld.shared.u32 	%r328, [%rd938+7304];
	// inline asm
	bfe.u32 %r1089, %r313, %r1297, %r1298;
	// inline asm
	mul.wide.u32 	%rd939, %r1089, 4;
	add.s64 	%rd940, %rd793, %rd939;
	ld.shared.u32 	%r329, [%rd940];
	// inline asm
	bfe.u32 %r1093, %r315, %r1297, %r1298;
	// inline asm
	mul.wide.u32 	%rd941, %r1093, 4;
	add.s64 	%rd942, %rd793, %rd941;
	ld.shared.u32 	%r330, [%rd942];
	// inline asm
	bfe.u32 %r1097, %r316, %r1297, %r1298;
	// inline asm
	mul.wide.u32 	%rd943, %r1097, 4;
	add.s64 	%rd944, %rd793, %rd943;
	ld.shared.u32 	%r331, [%rd944];
	// inline asm
	bfe.u32 %r1101, %r317, %r1297, %r1298;
	// inline asm
	mul.wide.u32 	%rd945, %r1101, 4;
	add.s64 	%rd946, %rd793, %rd945;
	ld.shared.u32 	%r332, [%rd946];
	// inline asm
	bfe.u32 %r1105, %r318, %r1297, %r1298;
	// inline asm
	mul.wide.u32 	%rd947, %r1105, 4;
	add.s64 	%rd948, %rd793, %rd947;
	ld.shared.u32 	%r333, [%rd948];
	// inline asm
	bfe.u32 %r1109, %r319, %r1297, %r1298;
	// inline asm
	mul.wide.u32 	%rd949, %r1109, 4;
	add.s64 	%rd950, %rd793, %rd949;
	ld.shared.u32 	%r334, [%rd950];
	// inline asm
	bfe.u32 %r1113, %r320, %r1297, %r1298;
	// inline asm
	mul.wide.u32 	%rd951, %r1113, 4;
	add.s64 	%rd952, %rd793, %rd951;
	ld.shared.u32 	%r335, [%rd952];
	// inline asm
	bfe.u32 %r1117, %r321, %r1297, %r1298;
	// inline asm
	mul.wide.u32 	%rd953, %r1117, 4;
	add.s64 	%rd954, %rd793, %rd953;
	ld.shared.u32 	%r336, [%rd954];
	// inline asm
	bfe.u32 %r1121, %r322, %r1297, %r1298;
	// inline asm
	mul.wide.u32 	%rd955, %r1121, 4;
	add.s64 	%rd956, %rd793, %rd955;
	ld.shared.u32 	%r337, [%rd956];
	// inline asm
	bfe.u32 %r1125, %r323, %r1297, %r1298;
	// inline asm
	mul.wide.u32 	%rd957, %r1125, 4;
	add.s64 	%rd958, %rd793, %rd957;
	ld.shared.u32 	%r338, [%rd958];
	// inline asm
	bfe.u32 %r1129, %r324, %r1297, %r1298;
	// inline asm
	mul.wide.u32 	%rd959, %r1129, 4;
	add.s64 	%rd960, %rd793, %rd959;
	ld.shared.u32 	%r339, [%rd960];
	// inline asm
	bfe.u32 %r1133, %r325, %r1297, %r1298;
	// inline asm
	mul.wide.u32 	%rd961, %r1133, 4;
	add.s64 	%rd962, %rd793, %rd961;
	ld.shared.u32 	%r340, [%rd962];
	// inline asm
	bfe.u32 %r1137, %r326, %r1297, %r1298;
	// inline asm
	mul.wide.u32 	%rd963, %r1137, 4;
	add.s64 	%rd964, %rd793, %rd963;
	ld.shared.u32 	%r341, [%rd964];
	// inline asm
	bfe.u32 %r1141, %r327, %r1297, %r1298;
	// inline asm
	mul.wide.u32 	%rd965, %r1141, 4;
	add.s64 	%rd966, %rd793, %rd965;
	ld.shared.u32 	%r342, [%rd966];
	// inline asm
	bfe.u32 %r1145, %r328, %r1297, %r1298;
	// inline asm
	mul.wide.u32 	%rd967, %r1145, 4;
	add.s64 	%rd968, %rd793, %rd967;
	ld.shared.u32 	%r343, [%rd968];
	setp.ge.s32	%p109, %r10, %r247;
	@%p109 bra 	BB26_183;

	xor.b32  	%r1150, %r313, -2147483648;
	add.s32 	%r1152, %r10, %r329;
	mul.wide.s32 	%rd970, %r1152, 4;
	add.s64 	%rd971, %rd2, %rd970;
	st.global.u32 	[%rd971], %r1150;

BB26_183:
	setp.ge.s32	%p110, %r314, %r247;
	@%p110 bra 	BB26_185;

	xor.b32  	%r1153, %r315, -2147483648;
	add.s32 	%r1154, %r314, %r330;
	mul.wide.s32 	%rd973, %r1154, 4;
	add.s64 	%rd974, %rd2, %rd973;
	st.global.u32 	[%rd974], %r1153;

BB26_185:
	add.s32 	%r1155, %r314, 128;
	setp.ge.s32	%p111, %r1155, %r247;
	@%p111 bra 	BB26_187;

	xor.b32  	%r1156, %r316, -2147483648;
	add.s32 	%r1157, %r314, %r331;
	add.s32 	%r1158, %r1157, 128;
	mul.wide.s32 	%rd976, %r1158, 4;
	add.s64 	%rd977, %rd2, %rd976;
	st.global.u32 	[%rd977], %r1156;

BB26_187:
	add.s32 	%r1159, %r314, 256;
	setp.ge.s32	%p112, %r1159, %r247;
	@%p112 bra 	BB26_189;

	xor.b32  	%r1160, %r317, -2147483648;
	add.s32 	%r1161, %r314, %r332;
	add.s32 	%r1162, %r1161, 256;
	mul.wide.s32 	%rd979, %r1162, 4;
	add.s64 	%rd980, %rd2, %rd979;
	st.global.u32 	[%rd980], %r1160;

BB26_189:
	add.s32 	%r1163, %r314, 384;
	setp.ge.s32	%p113, %r1163, %r247;
	@%p113 bra 	BB26_191;

	xor.b32  	%r1164, %r318, -2147483648;
	add.s32 	%r1165, %r314, %r333;
	add.s32 	%r1166, %r1165, 384;
	mul.wide.s32 	%rd982, %r1166, 4;
	add.s64 	%rd983, %rd2, %rd982;
	st.global.u32 	[%rd983], %r1164;

BB26_191:
	add.s32 	%r1167, %r314, 512;
	setp.ge.s32	%p114, %r1167, %r247;
	@%p114 bra 	BB26_193;

	xor.b32  	%r1168, %r319, -2147483648;
	add.s32 	%r1169, %r314, %r334;
	add.s32 	%r1170, %r1169, 512;
	mul.wide.s32 	%rd985, %r1170, 4;
	add.s64 	%rd986, %rd2, %rd985;
	st.global.u32 	[%rd986], %r1168;

BB26_193:
	add.s32 	%r1171, %r314, 640;
	setp.ge.s32	%p115, %r1171, %r247;
	@%p115 bra 	BB26_195;

	xor.b32  	%r1172, %r320, -2147483648;
	add.s32 	%r1173, %r314, %r335;
	add.s32 	%r1174, %r1173, 640;
	mul.wide.s32 	%rd988, %r1174, 4;
	add.s64 	%rd989, %rd2, %rd988;
	st.global.u32 	[%rd989], %r1172;

BB26_195:
	add.s32 	%r1175, %r314, 768;
	setp.ge.s32	%p116, %r1175, %r247;
	@%p116 bra 	BB26_197;

	xor.b32  	%r1176, %r321, -2147483648;
	add.s32 	%r1177, %r314, %r336;
	add.s32 	%r1178, %r1177, 768;
	mul.wide.s32 	%rd991, %r1178, 4;
	add.s64 	%rd992, %rd2, %rd991;
	st.global.u32 	[%rd992], %r1176;

BB26_197:
	add.s32 	%r1179, %r314, 896;
	setp.ge.s32	%p117, %r1179, %r247;
	@%p117 bra 	BB26_199;

	xor.b32  	%r1180, %r322, -2147483648;
	add.s32 	%r1181, %r314, %r337;
	add.s32 	%r1182, %r1181, 896;
	mul.wide.s32 	%rd994, %r1182, 4;
	add.s64 	%rd995, %rd2, %rd994;
	st.global.u32 	[%rd995], %r1180;

BB26_199:
	add.s32 	%r1183, %r314, 1024;
	setp.ge.s32	%p118, %r1183, %r247;
	@%p118 bra 	BB26_201;

	xor.b32  	%r1184, %r323, -2147483648;
	add.s32 	%r1185, %r314, %r338;
	add.s32 	%r1186, %r1185, 1024;
	mul.wide.s32 	%rd997, %r1186, 4;
	add.s64 	%rd998, %rd2, %rd997;
	st.global.u32 	[%rd998], %r1184;

BB26_201:
	add.s32 	%r1187, %r314, 1152;
	setp.ge.s32	%p119, %r1187, %r247;
	@%p119 bra 	BB26_203;

	xor.b32  	%r1188, %r324, -2147483648;
	add.s32 	%r1189, %r314, %r339;
	add.s32 	%r1190, %r1189, 1152;
	mul.wide.s32 	%rd1000, %r1190, 4;
	add.s64 	%rd1001, %rd2, %rd1000;
	st.global.u32 	[%rd1001], %r1188;

BB26_203:
	add.s32 	%r1191, %r314, 1280;
	setp.ge.s32	%p120, %r1191, %r247;
	@%p120 bra 	BB26_205;

	xor.b32  	%r1192, %r325, -2147483648;
	add.s32 	%r1193, %r314, %r340;
	add.s32 	%r1194, %r1193, 1280;
	mul.wide.s32 	%rd1003, %r1194, 4;
	add.s64 	%rd1004, %rd2, %rd1003;
	st.global.u32 	[%rd1004], %r1192;

BB26_205:
	add.s32 	%r1195, %r314, 1408;
	setp.ge.s32	%p121, %r1195, %r247;
	@%p121 bra 	BB26_207;

	xor.b32  	%r1196, %r326, -2147483648;
	add.s32 	%r1197, %r314, %r341;
	add.s32 	%r1198, %r1197, 1408;
	mul.wide.s32 	%rd1006, %r1198, 4;
	add.s64 	%rd1007, %rd2, %rd1006;
	st.global.u32 	[%rd1007], %r1196;

BB26_207:
	add.s32 	%r1199, %r314, 1536;
	setp.ge.s32	%p122, %r1199, %r247;
	@%p122 bra 	BB26_209;

	xor.b32  	%r1200, %r327, -2147483648;
	add.s32 	%r1201, %r314, %r342;
	add.s32 	%r1202, %r1201, 1536;
	mul.wide.s32 	%rd1009, %r1202, 4;
	add.s64 	%rd1010, %rd2, %rd1009;
	st.global.u32 	[%rd1010], %r1200;

BB26_209:
	add.s32 	%r1203, %r314, 1664;
	setp.ge.s32	%p123, %r1203, %r247;
	@%p123 bra 	BB26_211;

	xor.b32  	%r1204, %r328, -2147483648;
	add.s32 	%r1205, %r314, %r343;
	add.s32 	%r1206, %r1205, 1664;
	mul.wide.s32 	%rd1012, %r1206, 4;
	add.s64 	%rd1013, %rd2, %rd1012;
	st.global.u32 	[%rd1013], %r1204;

BB26_211:
	setp.gt.s32	%p5, %r248, 0;
	bar.sync 	0;
	@!%p5 bra 	BB26_213;
	bra.uni 	BB26_212;

BB26_212:
	mul.lo.s32 	%r1299, %r10, 15;
	cvt.s64.s32	%rd1015, %r1299;
	add.s64 	%rd1016, %rd1015, %rd99;
	shl.b64 	%rd1017, %rd1016, 2;
	add.s64 	%rd1014, %rd144, %rd1017;
	// inline asm
	ld.global.nc.u32 %r1374, [%rd1014];
	// inline asm

BB26_213:
	@%p88 bra 	BB26_215;

	mad.lo.s32 	%r1212, %r10, 15, 1;
	cvt.s64.s32	%rd1019, %r1212;
	add.s64 	%rd1020, %rd1019, %rd99;
	shl.b64 	%rd1021, %rd1020, 2;
	add.s64 	%rd1018, %rd144, %rd1021;
	// inline asm
	ld.global.nc.u32 %r1375, [%rd1018];
	// inline asm

BB26_215:
	@%p89 bra 	BB26_217;

	mad.lo.s32 	%r1215, %r10, 15, 2;
	cvt.s64.s32	%rd1023, %r1215;
	add.s64 	%rd1024, %rd1023, %rd99;
	shl.b64 	%rd1025, %rd1024, 2;
	add.s64 	%rd1022, %rd144, %rd1025;
	// inline asm
	ld.global.nc.u32 %r1376, [%rd1022];
	// inline asm

BB26_217:
	@%p90 bra 	BB26_219;

	mad.lo.s32 	%r1218, %r10, 15, 3;
	cvt.s64.s32	%rd1027, %r1218;
	add.s64 	%rd1028, %rd1027, %rd99;
	shl.b64 	%rd1029, %rd1028, 2;
	add.s64 	%rd1026, %rd144, %rd1029;
	// inline asm
	ld.global.nc.u32 %r1377, [%rd1026];
	// inline asm

BB26_219:
	@%p91 bra 	BB26_221;

	mad.lo.s32 	%r1221, %r10, 15, 4;
	cvt.s64.s32	%rd1031, %r1221;
	add.s64 	%rd1032, %rd1031, %rd99;
	shl.b64 	%rd1033, %rd1032, 2;
	add.s64 	%rd1030, %rd144, %rd1033;
	// inline asm
	ld.global.nc.u32 %r1378, [%rd1030];
	// inline asm

BB26_221:
	@%p92 bra 	BB26_223;

	mad.lo.s32 	%r1224, %r10, 15, 5;
	cvt.s64.s32	%rd1035, %r1224;
	add.s64 	%rd1036, %rd1035, %rd99;
	shl.b64 	%rd1037, %rd1036, 2;
	add.s64 	%rd1034, %rd144, %rd1037;
	// inline asm
	ld.global.nc.u32 %r1379, [%rd1034];
	// inline asm

BB26_223:
	@%p93 bra 	BB26_225;

	mad.lo.s32 	%r1227, %r10, 15, 6;
	cvt.s64.s32	%rd1039, %r1227;
	add.s64 	%rd1040, %rd1039, %rd99;
	shl.b64 	%rd1041, %rd1040, 2;
	add.s64 	%rd1038, %rd144, %rd1041;
	// inline asm
	ld.global.nc.u32 %r1380, [%rd1038];
	// inline asm

BB26_225:
	@%p94 bra 	BB26_227;

	mad.lo.s32 	%r1230, %r10, 15, 7;
	cvt.s64.s32	%rd1043, %r1230;
	add.s64 	%rd1044, %rd1043, %rd99;
	shl.b64 	%rd1045, %rd1044, 2;
	add.s64 	%rd1042, %rd144, %rd1045;
	// inline asm
	ld.global.nc.u32 %r1381, [%rd1042];
	// inline asm

BB26_227:
	@%p95 bra 	BB26_229;

	mad.lo.s32 	%r1233, %r10, 15, 8;
	cvt.s64.s32	%rd1047, %r1233;
	add.s64 	%rd1048, %rd1047, %rd99;
	shl.b64 	%rd1049, %rd1048, 2;
	add.s64 	%rd1046, %rd144, %rd1049;
	// inline asm
	ld.global.nc.u32 %r1382, [%rd1046];
	// inline asm

BB26_229:
	@%p96 bra 	BB26_231;

	mad.lo.s32 	%r1236, %r10, 15, 9;
	cvt.s64.s32	%rd1051, %r1236;
	add.s64 	%rd1052, %rd1051, %rd99;
	shl.b64 	%rd1053, %rd1052, 2;
	add.s64 	%rd1050, %rd144, %rd1053;
	// inline asm
	ld.global.nc.u32 %r1383, [%rd1050];
	// inline asm

BB26_231:
	@%p97 bra 	BB26_233;

	mad.lo.s32 	%r1239, %r10, 15, 10;
	cvt.s64.s32	%rd1055, %r1239;
	add.s64 	%rd1056, %rd1055, %rd99;
	shl.b64 	%rd1057, %rd1056, 2;
	add.s64 	%rd1054, %rd144, %rd1057;
	// inline asm
	ld.global.nc.u32 %r1384, [%rd1054];
	// inline asm

BB26_233:
	@%p98 bra 	BB26_235;

	mad.lo.s32 	%r1242, %r10, 15, 11;
	cvt.s64.s32	%rd1059, %r1242;
	add.s64 	%rd1060, %rd1059, %rd99;
	shl.b64 	%rd1061, %rd1060, 2;
	add.s64 	%rd1058, %rd144, %rd1061;
	// inline asm
	ld.global.nc.u32 %r1385, [%rd1058];
	// inline asm

BB26_235:
	@%p99 bra 	BB26_237;

	mad.lo.s32 	%r1245, %r10, 15, 12;
	cvt.s64.s32	%rd1063, %r1245;
	add.s64 	%rd1064, %rd1063, %rd99;
	shl.b64 	%rd1065, %rd1064, 2;
	add.s64 	%rd1062, %rd144, %rd1065;
	// inline asm
	ld.global.nc.u32 %r1386, [%rd1062];
	// inline asm

BB26_237:
	@%p100 bra 	BB26_239;

	mad.lo.s32 	%r1248, %r10, 15, 13;
	cvt.s64.s32	%rd1067, %r1248;
	add.s64 	%rd1068, %rd1067, %rd99;
	shl.b64 	%rd1069, %rd1068, 2;
	add.s64 	%rd1066, %rd144, %rd1069;
	// inline asm
	ld.global.nc.u32 %r1387, [%rd1066];
	// inline asm

BB26_239:
	@%p101 bra 	BB26_241;

	mad.lo.s32 	%r1251, %r10, 15, 14;
	cvt.s64.s32	%rd1071, %r1251;
	add.s64 	%rd1072, %rd1071, %rd99;
	shl.b64 	%rd1073, %rd1072, 2;
	add.s64 	%rd1070, %rd144, %rd1073;
	// inline asm
	ld.global.nc.u32 %r1388, [%rd1070];
	// inline asm

BB26_241:
	setp.lt.s32	%p6, %r10, %r247;
	bar.sync 	0;
	st.shared.u32 	[%rd127], %r1374;
	st.shared.u32 	[%rd128], %r1375;
	st.shared.u32 	[%rd129], %r1376;
	st.shared.u32 	[%rd130], %r1377;
	st.shared.u32 	[%rd131], %r1378;
	st.shared.u32 	[%rd132], %r1379;
	st.shared.u32 	[%rd133], %r1380;
	st.shared.u32 	[%rd134], %r1381;
	st.shared.u32 	[%rd135], %r1382;
	st.shared.u32 	[%rd136], %r1383;
	st.shared.u32 	[%rd137], %r1384;
	st.shared.u32 	[%rd138], %r1385;
	st.shared.u32 	[%rd139], %r1386;
	st.shared.u32 	[%rd140], %r1387;
	st.shared.u32 	[%rd141], %r1388;
	bar.sync 	0;
	ld.shared.u32 	%r375, [%rd938+648];
	ld.shared.u32 	%r376, [%rd938+1160];
	ld.shared.u32 	%r377, [%rd938+1672];
	ld.shared.u32 	%r378, [%rd938+2184];
	ld.shared.u32 	%r379, [%rd938+2696];
	ld.shared.u32 	%r380, [%rd938+3208];
	ld.shared.u32 	%r381, [%rd938+3720];
	ld.shared.u32 	%r382, [%rd938+4232];
	ld.shared.u32 	%r383, [%rd938+4744];
	ld.shared.u32 	%r384, [%rd938+5256];
	ld.shared.u32 	%r385, [%rd938+5768];
	ld.shared.u32 	%r386, [%rd938+6280];
	ld.shared.u32 	%r387, [%rd938+6792];
	ld.shared.u32 	%r388, [%rd938+7304];
	@!%p6 bra 	BB26_243;
	bra.uni 	BB26_242;

BB26_242:
	ld.shared.u32 	%r1253, [%rd938+136];
	add.s32 	%r1254, %r10, %r329;
	mul.wide.s32 	%rd1081, %r1254, 4;
	add.s64 	%rd1082, %rd1, %rd1081;
	st.global.u32 	[%rd1082], %r1253;

BB26_243:
	@%p110 bra 	BB26_245;

	add.s32 	%r1255, %r314, %r330;
	mul.wide.s32 	%rd1084, %r1255, 4;
	add.s64 	%rd1085, %rd1, %rd1084;
	st.global.u32 	[%rd1085], %r375;

BB26_245:
	@%p111 bra 	BB26_247;

	add.s32 	%r1257, %r314, %r331;
	add.s32 	%r1258, %r1257, 128;
	mul.wide.s32 	%rd1087, %r1258, 4;
	add.s64 	%rd1088, %rd1, %rd1087;
	st.global.u32 	[%rd1088], %r376;

BB26_247:
	@%p112 bra 	BB26_249;

	add.s32 	%r1260, %r314, %r332;
	add.s32 	%r1261, %r1260, 256;
	mul.wide.s32 	%rd1090, %r1261, 4;
	add.s64 	%rd1091, %rd1, %rd1090;
	st.global.u32 	[%rd1091], %r377;

BB26_249:
	@%p113 bra 	BB26_251;

	add.s32 	%r1263, %r314, %r333;
	add.s32 	%r1264, %r1263, 384;
	mul.wide.s32 	%rd1093, %r1264, 4;
	add.s64 	%rd1094, %rd1, %rd1093;
	st.global.u32 	[%rd1094], %r378;

BB26_251:
	@%p114 bra 	BB26_253;

	add.s32 	%r1266, %r314, %r334;
	add.s32 	%r1267, %r1266, 512;
	mul.wide.s32 	%rd1096, %r1267, 4;
	add.s64 	%rd1097, %rd1, %rd1096;
	st.global.u32 	[%rd1097], %r379;

BB26_253:
	@%p115 bra 	BB26_255;

	add.s32 	%r1269, %r314, %r335;
	add.s32 	%r1270, %r1269, 640;
	mul.wide.s32 	%rd1099, %r1270, 4;
	add.s64 	%rd1100, %rd1, %rd1099;
	st.global.u32 	[%rd1100], %r380;

BB26_255:
	@%p116 bra 	BB26_257;

	add.s32 	%r1272, %r314, %r336;
	add.s32 	%r1273, %r1272, 768;
	mul.wide.s32 	%rd1102, %r1273, 4;
	add.s64 	%rd1103, %rd1, %rd1102;
	st.global.u32 	[%rd1103], %r381;

BB26_257:
	@%p117 bra 	BB26_259;

	add.s32 	%r1275, %r314, %r337;
	add.s32 	%r1276, %r1275, 896;
	mul.wide.s32 	%rd1105, %r1276, 4;
	add.s64 	%rd1106, %rd1, %rd1105;
	st.global.u32 	[%rd1106], %r382;

BB26_259:
	@%p118 bra 	BB26_261;

	add.s32 	%r1278, %r314, %r338;
	add.s32 	%r1279, %r1278, 1024;
	mul.wide.s32 	%rd1108, %r1279, 4;
	add.s64 	%rd1109, %rd1, %rd1108;
	st.global.u32 	[%rd1109], %r383;

BB26_261:
	@%p119 bra 	BB26_263;

	add.s32 	%r1281, %r314, %r339;
	add.s32 	%r1282, %r1281, 1152;
	mul.wide.s32 	%rd1111, %r1282, 4;
	add.s64 	%rd1112, %rd1, %rd1111;
	st.global.u32 	[%rd1112], %r384;

BB26_263:
	@%p120 bra 	BB26_265;

	add.s32 	%r1284, %r314, %r340;
	add.s32 	%r1285, %r1284, 1280;
	mul.wide.s32 	%rd1114, %r1285, 4;
	add.s64 	%rd1115, %rd1, %rd1114;
	st.global.u32 	[%rd1115], %r385;

BB26_265:
	@%p121 bra 	BB26_267;

	add.s32 	%r1287, %r314, %r341;
	add.s32 	%r1288, %r1287, 1408;
	mul.wide.s32 	%rd1117, %r1288, 4;
	add.s64 	%rd1118, %rd1, %rd1117;
	st.global.u32 	[%rd1118], %r386;

BB26_267:
	@%p122 bra 	BB26_269;

	add.s32 	%r1290, %r314, %r342;
	add.s32 	%r1291, %r1290, 1536;
	mul.wide.s32 	%rd1120, %r1291, 4;
	add.s64 	%rd1121, %rd1, %rd1120;
	st.global.u32 	[%rd1121], %r387;

BB26_269:
	@%p123 bra 	BB26_271;

	add.s32 	%r1293, %r314, %r343;
	add.s32 	%r1294, %r1293, 1664;
	mul.wide.s32 	%rd1123, %r1294, 4;
	add.s64 	%rd1124, %rd1, %rd1123;
	st.global.u32 	[%rd1124], %r388;

BB26_271:
	ret;
}

	// .globl	_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE21PtxAltDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE
.visible .entry _ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE21PtxAltDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE(
	.param .u64 _ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE21PtxAltDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_0,
	.param .u64 _ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE21PtxAltDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_1,
	.param .u64 _ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE21PtxAltDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_2,
	.param .u64 _ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE21PtxAltDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_3,
	.param .u64 _ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE21PtxAltDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_4,
	.param .u32 _ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE21PtxAltDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_5,
	.param .u32 _ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE21PtxAltDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_6,
	.param .u32 _ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE21PtxAltDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_7,
	.param .u8 _ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE21PtxAltDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_8,
	.param .u8 _ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE21PtxAltDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_9,
	.param .align 4 .b8 _ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE21PtxAltDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_10[36]
)
.maxntid 128, 1, 1
{
	.reg .pred 	%p<152>;
	.reg .b16 	%rs<3>;
	.reg .b32 	%r<1389>;
	.reg .b64 	%rd<1101>;
	// demoted variable
	.shared .align 8 .b8 _ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE21PtxAltDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE$__cuda_local_var_106605_76_non_const_temp_storage[7752];

	ld.param.u64 	%rd134, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE21PtxAltDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_0];
	ld.param.u64 	%rd135, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE21PtxAltDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_1];
	ld.param.u64 	%rd136, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE21PtxAltDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_2];
	ld.param.u64 	%rd137, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE21PtxAltDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_3];
	ld.param.u64 	%rd138, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE21PtxAltDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_4];
	ld.param.u32 	%r389, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE21PtxAltDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_5];
	ld.param.u32 	%r390, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE21PtxAltDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_6];
	ld.param.u32 	%r391, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE21PtxAltDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_7];
	ld.param.u32 	%r400, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE21PtxAltDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_10+32];
	ld.param.u32 	%r399, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE21PtxAltDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_10+28];
	ld.param.u32 	%r397, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE21PtxAltDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_10+20];
	ld.param.u32 	%r396, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE21PtxAltDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_10+16];
	ld.param.u32 	%r395, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE21PtxAltDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_10+12];
	ld.param.u32 	%r394, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE21PtxAltDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_10+8];
	ld.param.u32 	%r392, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE21PtxAltDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_10];
	ld.param.u32 	%r393, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE21PtxAltDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_10+4];
	cvta.to.global.u64 	%rd1, %rd137;
	cvta.to.global.u64 	%rd2, %rd135;
	mov.u32 	%r1, %ctaid.x;
	setp.lt.s32	%p7, %r1, %r393;
	@%p7 bra 	BB27_3;
	bra.uni 	BB27_1;

BB27_3:
	mul.lo.s32 	%r1342, %r1, %r394;
	add.s32 	%r1302, %r1342, %r394;
	bra.uni 	BB27_4;

BB27_1:
	mov.u32 	%r1302, %r400;
	mov.u32 	%r1342, %r399;
	setp.ge.s32	%p8, %r1, %r392;
	@%p8 bra 	BB27_4;

	mad.lo.s32 	%r1342, %r1, %r395, %r396;
	add.s32 	%r401, %r1342, %r395;
	min.s32 	%r1302, %r401, %r397;

BB27_4:
	mov.u32 	%r9, %r1342;
	mov.u32 	%r10, %tid.x;
	setp.gt.u32	%p9, %r10, 15;
	@%p9 bra 	BB27_6;

	cvta.to.global.u64 	%rd139, %rd138;
	mov.u32 	%r405, %nctaid.x;
	mul.lo.s32 	%r406, %r405, %r10;
	mul.wide.u32 	%rd140, %r406, 4;
	add.s64 	%rd141, %rd139, %rd140;
	ld.global.u32 	%r407, [%rd141];
	setp.eq.s32	%p10, %r407, 0;
	setp.eq.s32	%p11, %r407, %r389;
	or.pred  	%p12, %p10, %p11;
	selp.u32	%r404, 1, 0, %p12;
	// inline asm
	{ 
	.reg .pred 	%p1; 
	.reg .pred 	%p2; 
	setp.ne.u32 	%p1, %r404, 0; 
	vote.all.pred 	%p2, %p1; 
	selp.s32 	%r403, 1, 0, %p2; 
	}
	// inline asm
	setp.ne.s32	%p13, %r403, 0;
	selp.u16	%rs1, 1, 0, %p13;
	st.shared.u8 	[_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE21PtxAltDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE$__cuda_local_var_106605_76_non_const_temp_storage+68], %rs1;
	add.s32 	%r408, %r406, %r1;
	mul.wide.u32 	%rd142, %r408, 4;
	add.s64 	%rd143, %rd139, %rd142;
	ld.global.u32 	%r1343, [%rd143];

BB27_6:
	bar.sync 	0;
	ld.shared.u8 	%rs2, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE21PtxAltDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE$__cuda_local_var_106605_76_non_const_temp_storage+68];
	setp.eq.s16	%p14, %rs2, 0;
	add.s32 	%r13, %r9, 1920;
	@%p14 bra 	BB27_135;

	setp.gt.s32	%p15, %r13, %r1302;
	mov.u32 	%r1339, %r9;
	@%p15 bra 	BB27_10;

	cvt.s64.s32	%rd3, %r10;
	add.s32 	%r409, %r10, 128;
	cvt.s64.s32	%rd4, %r409;
	add.s32 	%r410, %r10, 256;
	cvt.s64.s32	%rd5, %r410;
	add.s32 	%r411, %r10, 384;
	cvt.s64.s32	%rd6, %r411;
	add.s32 	%r412, %r10, 512;
	cvt.s64.s32	%rd7, %r412;
	add.s32 	%r413, %r10, 640;
	cvt.s64.s32	%rd8, %r413;
	add.s32 	%r414, %r10, 768;
	cvt.s64.s32	%rd9, %r414;
	add.s32 	%r415, %r10, 896;
	cvt.s64.s32	%rd10, %r415;
	add.s32 	%r416, %r10, 1024;
	cvt.s64.s32	%rd11, %r416;
	add.s32 	%r417, %r10, 1152;
	cvt.s64.s32	%rd12, %r417;
	add.s32 	%r418, %r10, 1280;
	cvt.s64.s32	%rd13, %r418;
	add.s32 	%r419, %r10, 1408;
	cvt.s64.s32	%rd14, %r419;
	add.s32 	%r420, %r10, 1536;
	cvt.s64.s32	%rd15, %r420;
	add.s32 	%r421, %r10, 1664;
	cvt.s64.s32	%rd16, %r421;
	add.s32 	%r422, %r10, 1792;
	cvt.s64.s32	%rd17, %r422;
	mov.u32 	%r1340, %r9;
	mov.u32 	%r1341, %r13;

BB27_9:
	mov.u32 	%r1327, %r1341;
	mov.u32 	%r15, %r1340;
	mov.u32 	%r1340, %r1327;
	cvt.s64.s32	%rd159, %r15;
	add.s64 	%rd18, %rd3, %rd159;
	shl.b64 	%rd160, %rd18, 2;
	add.s64 	%rd144, %rd134, %rd160;
	// inline asm
	ld.global.nc.u32 %r423, [%rd144];
	// inline asm
	add.s64 	%rd161, %rd4, %rd159;
	shl.b64 	%rd162, %rd161, 2;
	add.s64 	%rd145, %rd134, %rd162;
	// inline asm
	ld.global.nc.u32 %r424, [%rd145];
	// inline asm
	add.s64 	%rd163, %rd5, %rd159;
	shl.b64 	%rd164, %rd163, 2;
	add.s64 	%rd146, %rd134, %rd164;
	// inline asm
	ld.global.nc.u32 %r425, [%rd146];
	// inline asm
	add.s64 	%rd165, %rd6, %rd159;
	shl.b64 	%rd166, %rd165, 2;
	add.s64 	%rd147, %rd134, %rd166;
	// inline asm
	ld.global.nc.u32 %r426, [%rd147];
	// inline asm
	add.s64 	%rd167, %rd7, %rd159;
	shl.b64 	%rd168, %rd167, 2;
	add.s64 	%rd148, %rd134, %rd168;
	// inline asm
	ld.global.nc.u32 %r427, [%rd148];
	// inline asm
	add.s64 	%rd169, %rd8, %rd159;
	shl.b64 	%rd170, %rd169, 2;
	add.s64 	%rd149, %rd134, %rd170;
	// inline asm
	ld.global.nc.u32 %r428, [%rd149];
	// inline asm
	add.s64 	%rd171, %rd9, %rd159;
	shl.b64 	%rd172, %rd171, 2;
	add.s64 	%rd150, %rd134, %rd172;
	// inline asm
	ld.global.nc.u32 %r429, [%rd150];
	// inline asm
	add.s64 	%rd173, %rd10, %rd159;
	shl.b64 	%rd174, %rd173, 2;
	add.s64 	%rd151, %rd134, %rd174;
	// inline asm
	ld.global.nc.u32 %r430, [%rd151];
	// inline asm
	add.s64 	%rd175, %rd11, %rd159;
	shl.b64 	%rd176, %rd175, 2;
	add.s64 	%rd152, %rd134, %rd176;
	// inline asm
	ld.global.nc.u32 %r431, [%rd152];
	// inline asm
	add.s64 	%rd177, %rd12, %rd159;
	shl.b64 	%rd178, %rd177, 2;
	add.s64 	%rd153, %rd134, %rd178;
	// inline asm
	ld.global.nc.u32 %r432, [%rd153];
	// inline asm
	add.s64 	%rd179, %rd13, %rd159;
	shl.b64 	%rd180, %rd179, 2;
	add.s64 	%rd154, %rd134, %rd180;
	// inline asm
	ld.global.nc.u32 %r433, [%rd154];
	// inline asm
	add.s64 	%rd181, %rd14, %rd159;
	shl.b64 	%rd182, %rd181, 2;
	add.s64 	%rd155, %rd134, %rd182;
	// inline asm
	ld.global.nc.u32 %r434, [%rd155];
	// inline asm
	add.s64 	%rd183, %rd15, %rd159;
	shl.b64 	%rd184, %rd183, 2;
	add.s64 	%rd156, %rd134, %rd184;
	// inline asm
	ld.global.nc.u32 %r435, [%rd156];
	// inline asm
	add.s64 	%rd185, %rd16, %rd159;
	shl.b64 	%rd186, %rd185, 2;
	add.s64 	%rd157, %rd134, %rd186;
	// inline asm
	ld.global.nc.u32 %r436, [%rd157];
	// inline asm
	add.s64 	%rd187, %rd17, %rd159;
	shl.b64 	%rd188, %rd187, 2;
	add.s64 	%rd158, %rd134, %rd188;
	// inline asm
	ld.global.nc.u32 %r437, [%rd158];
	// inline asm
	bar.sync 	0;
	add.s64 	%rd190, %rd2, %rd160;
	st.global.u32 	[%rd190], %r423;
	st.global.u32 	[%rd190+512], %r424;
	st.global.u32 	[%rd190+1024], %r425;
	st.global.u32 	[%rd190+1536], %r426;
	st.global.u32 	[%rd190+2048], %r427;
	st.global.u32 	[%rd190+2560], %r428;
	st.global.u32 	[%rd190+3072], %r429;
	st.global.u32 	[%rd190+3584], %r430;
	st.global.u32 	[%rd190+4096], %r431;
	st.global.u32 	[%rd190+4608], %r432;
	st.global.u32 	[%rd190+5120], %r433;
	st.global.u32 	[%rd190+5632], %r434;
	st.global.u32 	[%rd190+6144], %r435;
	st.global.u32 	[%rd190+6656], %r436;
	st.global.u32 	[%rd190+7168], %r437;
	add.s32 	%r31, %r1340, 1920;
	setp.le.s32	%p16, %r31, %r1302;
	mov.u32 	%r1328, %r1340;
	mov.u32 	%r1339, %r1328;
	mov.u32 	%r1341, %r31;
	@%p16 bra 	BB27_9;

BB27_10:
	mov.u32 	%r32, %r1339;
	setp.le.s32	%p17, %r1302, %r32;
	@%p17 bra 	BB27_71;

	sub.s32 	%r33, %r1302, %r32;
	cvt.s64.s32	%rd19, %r32;
	sub.s32 	%r34, %r33, %r10;
	setp.lt.s32	%p18, %r34, 1;
	@%p18 bra 	BB27_13;

	cvt.s64.s32	%rd192, %r10;
	add.s64 	%rd193, %rd192, %rd19;
	shl.b64 	%rd194, %rd193, 2;
	add.s64 	%rd191, %rd134, %rd194;
	// inline asm
	ld.global.nc.u32 %r1303, [%rd191];
	// inline asm

BB27_13:
	setp.lt.s32	%p19, %r34, 129;
	@%p19 bra 	BB27_15;

	add.s32 	%r443, %r10, 128;
	cvt.s64.s32	%rd196, %r443;
	add.s64 	%rd197, %rd196, %rd19;
	shl.b64 	%rd198, %rd197, 2;
	add.s64 	%rd195, %rd134, %rd198;
	// inline asm
	ld.global.nc.u32 %r1304, [%rd195];
	// inline asm

BB27_15:
	setp.lt.s32	%p20, %r34, 257;
	@%p20 bra 	BB27_17;

	add.s32 	%r446, %r10, 256;
	cvt.s64.s32	%rd200, %r446;
	add.s64 	%rd201, %rd200, %rd19;
	shl.b64 	%rd202, %rd201, 2;
	add.s64 	%rd199, %rd134, %rd202;
	// inline asm
	ld.global.nc.u32 %r1305, [%rd199];
	// inline asm

BB27_17:
	setp.lt.s32	%p21, %r34, 385;
	@%p21 bra 	BB27_19;

	add.s32 	%r449, %r10, 384;
	cvt.s64.s32	%rd204, %r449;
	add.s64 	%rd205, %rd204, %rd19;
	shl.b64 	%rd206, %rd205, 2;
	add.s64 	%rd203, %rd134, %rd206;
	// inline asm
	ld.global.nc.u32 %r1306, [%rd203];
	// inline asm

BB27_19:
	setp.lt.s32	%p22, %r34, 513;
	@%p22 bra 	BB27_21;

	add.s32 	%r452, %r10, 512;
	cvt.s64.s32	%rd208, %r452;
	add.s64 	%rd209, %rd208, %rd19;
	shl.b64 	%rd210, %rd209, 2;
	add.s64 	%rd207, %rd134, %rd210;
	// inline asm
	ld.global.nc.u32 %r1307, [%rd207];
	// inline asm

BB27_21:
	setp.lt.s32	%p23, %r34, 641;
	@%p23 bra 	BB27_23;

	add.s32 	%r455, %r10, 640;
	cvt.s64.s32	%rd212, %r455;
	add.s64 	%rd213, %rd212, %rd19;
	shl.b64 	%rd214, %rd213, 2;
	add.s64 	%rd211, %rd134, %rd214;
	// inline asm
	ld.global.nc.u32 %r1308, [%rd211];
	// inline asm

BB27_23:
	setp.lt.s32	%p24, %r34, 769;
	@%p24 bra 	BB27_25;

	add.s32 	%r458, %r10, 768;
	cvt.s64.s32	%rd216, %r458;
	add.s64 	%rd217, %rd216, %rd19;
	shl.b64 	%rd218, %rd217, 2;
	add.s64 	%rd215, %rd134, %rd218;
	// inline asm
	ld.global.nc.u32 %r1309, [%rd215];
	// inline asm

BB27_25:
	setp.lt.s32	%p25, %r34, 897;
	@%p25 bra 	BB27_27;

	add.s32 	%r461, %r10, 896;
	cvt.s64.s32	%rd220, %r461;
	add.s64 	%rd221, %rd220, %rd19;
	shl.b64 	%rd222, %rd221, 2;
	add.s64 	%rd219, %rd134, %rd222;
	// inline asm
	ld.global.nc.u32 %r1310, [%rd219];
	// inline asm

BB27_27:
	setp.lt.s32	%p26, %r34, 1025;
	@%p26 bra 	BB27_29;

	add.s32 	%r464, %r10, 1024;
	cvt.s64.s32	%rd224, %r464;
	add.s64 	%rd225, %rd224, %rd19;
	shl.b64 	%rd226, %rd225, 2;
	add.s64 	%rd223, %rd134, %rd226;
	// inline asm
	ld.global.nc.u32 %r1311, [%rd223];
	// inline asm

BB27_29:
	setp.lt.s32	%p27, %r34, 1153;
	@%p27 bra 	BB27_31;

	add.s32 	%r467, %r10, 1152;
	cvt.s64.s32	%rd228, %r467;
	add.s64 	%rd229, %rd228, %rd19;
	shl.b64 	%rd230, %rd229, 2;
	add.s64 	%rd227, %rd134, %rd230;
	// inline asm
	ld.global.nc.u32 %r1312, [%rd227];
	// inline asm

BB27_31:
	setp.lt.s32	%p28, %r34, 1281;
	@%p28 bra 	BB27_33;

	add.s32 	%r470, %r10, 1280;
	cvt.s64.s32	%rd232, %r470;
	add.s64 	%rd233, %rd232, %rd19;
	shl.b64 	%rd234, %rd233, 2;
	add.s64 	%rd231, %rd134, %rd234;
	// inline asm
	ld.global.nc.u32 %r1313, [%rd231];
	// inline asm

BB27_33:
	setp.lt.s32	%p29, %r34, 1409;
	@%p29 bra 	BB27_35;

	add.s32 	%r473, %r10, 1408;
	cvt.s64.s32	%rd236, %r473;
	add.s64 	%rd237, %rd236, %rd19;
	shl.b64 	%rd238, %rd237, 2;
	add.s64 	%rd235, %rd134, %rd238;
	// inline asm
	ld.global.nc.u32 %r1314, [%rd235];
	// inline asm

BB27_35:
	setp.lt.s32	%p30, %r34, 1537;
	@%p30 bra 	BB27_37;

	add.s32 	%r476, %r10, 1536;
	cvt.s64.s32	%rd240, %r476;
	add.s64 	%rd241, %rd240, %rd19;
	shl.b64 	%rd242, %rd241, 2;
	add.s64 	%rd239, %rd134, %rd242;
	// inline asm
	ld.global.nc.u32 %r1315, [%rd239];
	// inline asm

BB27_37:
	setp.lt.s32	%p31, %r34, 1665;
	@%p31 bra 	BB27_39;

	add.s32 	%r479, %r10, 1664;
	cvt.s64.s32	%rd244, %r479;
	add.s64 	%rd245, %rd244, %rd19;
	shl.b64 	%rd246, %rd245, 2;
	add.s64 	%rd243, %rd134, %rd246;
	// inline asm
	ld.global.nc.u32 %r1316, [%rd243];
	// inline asm

BB27_39:
	setp.lt.s32	%p32, %r34, 1793;
	@%p32 bra 	BB27_41;

	add.s32 	%r482, %r10, 1792;
	cvt.s64.s32	%rd248, %r482;
	add.s64 	%rd249, %rd248, %rd19;
	shl.b64 	%rd250, %rd249, 2;
	add.s64 	%rd247, %rd134, %rd250;
	// inline asm
	ld.global.nc.u32 %r1317, [%rd247];
	// inline asm

BB27_41:
	bar.sync 	0;
	cvt.s64.s32	%rd251, %r10;
	add.s64 	%rd252, %rd251, %rd19;
	shl.b64 	%rd253, %rd252, 2;
	add.s64 	%rd20, %rd2, %rd253;
	setp.le.s32	%p33, %r33, %r10;
	@%p33 bra 	BB27_43;

	st.global.u32 	[%rd20], %r1303;

BB27_43:
	add.s32 	%r483, %r10, 128;
	setp.ge.s32	%p34, %r483, %r33;
	@%p34 bra 	BB27_45;

	st.global.u32 	[%rd20+512], %r1304;

BB27_45:
	add.s32 	%r484, %r10, 256;
	setp.ge.s32	%p35, %r484, %r33;
	@%p35 bra 	BB27_47;

	st.global.u32 	[%rd20+1024], %r1305;

BB27_47:
	add.s32 	%r485, %r10, 384;
	setp.ge.s32	%p36, %r485, %r33;
	@%p36 bra 	BB27_49;

	st.global.u32 	[%rd20+1536], %r1306;

BB27_49:
	add.s32 	%r486, %r10, 512;
	setp.ge.s32	%p37, %r486, %r33;
	@%p37 bra 	BB27_51;

	st.global.u32 	[%rd20+2048], %r1307;

BB27_51:
	add.s32 	%r487, %r10, 640;
	setp.ge.s32	%p38, %r487, %r33;
	@%p38 bra 	BB27_53;

	st.global.u32 	[%rd20+2560], %r1308;

BB27_53:
	add.s32 	%r488, %r10, 768;
	setp.ge.s32	%p39, %r488, %r33;
	@%p39 bra 	BB27_55;

	st.global.u32 	[%rd20+3072], %r1309;

BB27_55:
	add.s32 	%r489, %r10, 896;
	setp.ge.s32	%p40, %r489, %r33;
	@%p40 bra 	BB27_57;

	st.global.u32 	[%rd20+3584], %r1310;

BB27_57:
	add.s32 	%r490, %r10, 1024;
	setp.ge.s32	%p41, %r490, %r33;
	@%p41 bra 	BB27_59;

	st.global.u32 	[%rd20+4096], %r1311;

BB27_59:
	add.s32 	%r491, %r10, 1152;
	setp.ge.s32	%p42, %r491, %r33;
	@%p42 bra 	BB27_61;

	st.global.u32 	[%rd20+4608], %r1312;

BB27_61:
	add.s32 	%r492, %r10, 1280;
	setp.ge.s32	%p43, %r492, %r33;
	@%p43 bra 	BB27_63;

	st.global.u32 	[%rd20+5120], %r1313;

BB27_63:
	add.s32 	%r493, %r10, 1408;
	setp.ge.s32	%p44, %r493, %r33;
	@%p44 bra 	BB27_65;

	st.global.u32 	[%rd20+5632], %r1314;

BB27_65:
	add.s32 	%r494, %r10, 1536;
	setp.ge.s32	%p45, %r494, %r33;
	@%p45 bra 	BB27_67;

	st.global.u32 	[%rd20+6144], %r1315;

BB27_67:
	add.s32 	%r495, %r10, 1664;
	setp.ge.s32	%p46, %r495, %r33;
	@%p46 bra 	BB27_69;

	st.global.u32 	[%rd20+6656], %r1316;

BB27_69:
	add.s32 	%r496, %r10, 1792;
	setp.ge.s32	%p47, %r496, %r33;
	@%p47 bra 	BB27_71;

	st.global.u32 	[%rd20+7168], %r1317;

BB27_71:
	mov.u32 	%r1336, %r9;
	@%p15 bra 	BB27_74;

	cvt.s64.s32	%rd21, %r10;
	add.s32 	%r497, %r10, 128;
	cvt.s64.s32	%rd22, %r497;
	add.s32 	%r498, %r10, 256;
	cvt.s64.s32	%rd23, %r498;
	add.s32 	%r499, %r10, 384;
	cvt.s64.s32	%rd24, %r499;
	add.s32 	%r500, %r10, 512;
	cvt.s64.s32	%rd25, %r500;
	add.s32 	%r501, %r10, 640;
	cvt.s64.s32	%rd26, %r501;
	add.s32 	%r502, %r10, 768;
	cvt.s64.s32	%rd27, %r502;
	add.s32 	%r503, %r10, 896;
	cvt.s64.s32	%rd28, %r503;
	add.s32 	%r504, %r10, 1024;
	cvt.s64.s32	%rd29, %r504;
	add.s32 	%r505, %r10, 1152;
	cvt.s64.s32	%rd30, %r505;
	add.s32 	%r506, %r10, 1280;
	cvt.s64.s32	%rd31, %r506;
	add.s32 	%r507, %r10, 1408;
	cvt.s64.s32	%rd32, %r507;
	add.s32 	%r508, %r10, 1536;
	cvt.s64.s32	%rd33, %r508;
	add.s32 	%r509, %r10, 1664;
	cvt.s64.s32	%rd34, %r509;
	add.s32 	%r510, %r10, 1792;
	cvt.s64.s32	%rd35, %r510;
	mov.u32 	%r1337, %r9;
	mov.u32 	%r1338, %r13;

BB27_73:
	mov.u32 	%r1329, %r1338;
	mov.u32 	%r81, %r1337;
	mov.u32 	%r1337, %r1329;
	cvt.s64.s32	%rd269, %r81;
	add.s64 	%rd36, %rd21, %rd269;
	shl.b64 	%rd270, %rd36, 2;
	add.s64 	%rd254, %rd136, %rd270;
	// inline asm
	ld.global.nc.u32 %r511, [%rd254];
	// inline asm
	add.s64 	%rd271, %rd22, %rd269;
	shl.b64 	%rd272, %rd271, 2;
	add.s64 	%rd255, %rd136, %rd272;
	// inline asm
	ld.global.nc.u32 %r512, [%rd255];
	// inline asm
	add.s64 	%rd273, %rd23, %rd269;
	shl.b64 	%rd274, %rd273, 2;
	add.s64 	%rd256, %rd136, %rd274;
	// inline asm
	ld.global.nc.u32 %r513, [%rd256];
	// inline asm
	add.s64 	%rd275, %rd24, %rd269;
	shl.b64 	%rd276, %rd275, 2;
	add.s64 	%rd257, %rd136, %rd276;
	// inline asm
	ld.global.nc.u32 %r514, [%rd257];
	// inline asm
	add.s64 	%rd277, %rd25, %rd269;
	shl.b64 	%rd278, %rd277, 2;
	add.s64 	%rd258, %rd136, %rd278;
	// inline asm
	ld.global.nc.u32 %r515, [%rd258];
	// inline asm
	add.s64 	%rd279, %rd26, %rd269;
	shl.b64 	%rd280, %rd279, 2;
	add.s64 	%rd259, %rd136, %rd280;
	// inline asm
	ld.global.nc.u32 %r516, [%rd259];
	// inline asm
	add.s64 	%rd281, %rd27, %rd269;
	shl.b64 	%rd282, %rd281, 2;
	add.s64 	%rd260, %rd136, %rd282;
	// inline asm
	ld.global.nc.u32 %r517, [%rd260];
	// inline asm
	add.s64 	%rd283, %rd28, %rd269;
	shl.b64 	%rd284, %rd283, 2;
	add.s64 	%rd261, %rd136, %rd284;
	// inline asm
	ld.global.nc.u32 %r518, [%rd261];
	// inline asm
	add.s64 	%rd285, %rd29, %rd269;
	shl.b64 	%rd286, %rd285, 2;
	add.s64 	%rd262, %rd136, %rd286;
	// inline asm
	ld.global.nc.u32 %r519, [%rd262];
	// inline asm
	add.s64 	%rd287, %rd30, %rd269;
	shl.b64 	%rd288, %rd287, 2;
	add.s64 	%rd263, %rd136, %rd288;
	// inline asm
	ld.global.nc.u32 %r520, [%rd263];
	// inline asm
	add.s64 	%rd289, %rd31, %rd269;
	shl.b64 	%rd290, %rd289, 2;
	add.s64 	%rd264, %rd136, %rd290;
	// inline asm
	ld.global.nc.u32 %r521, [%rd264];
	// inline asm
	add.s64 	%rd291, %rd32, %rd269;
	shl.b64 	%rd292, %rd291, 2;
	add.s64 	%rd265, %rd136, %rd292;
	// inline asm
	ld.global.nc.u32 %r522, [%rd265];
	// inline asm
	add.s64 	%rd293, %rd33, %rd269;
	shl.b64 	%rd294, %rd293, 2;
	add.s64 	%rd266, %rd136, %rd294;
	// inline asm
	ld.global.nc.u32 %r523, [%rd266];
	// inline asm
	add.s64 	%rd295, %rd34, %rd269;
	shl.b64 	%rd296, %rd295, 2;
	add.s64 	%rd267, %rd136, %rd296;
	// inline asm
	ld.global.nc.u32 %r524, [%rd267];
	// inline asm
	add.s64 	%rd297, %rd35, %rd269;
	shl.b64 	%rd298, %rd297, 2;
	add.s64 	%rd268, %rd136, %rd298;
	// inline asm
	ld.global.nc.u32 %r525, [%rd268];
	// inline asm
	bar.sync 	0;
	add.s64 	%rd300, %rd1, %rd270;
	st.global.u32 	[%rd300], %r511;
	st.global.u32 	[%rd300+512], %r512;
	st.global.u32 	[%rd300+1024], %r513;
	st.global.u32 	[%rd300+1536], %r514;
	st.global.u32 	[%rd300+2048], %r515;
	st.global.u32 	[%rd300+2560], %r516;
	st.global.u32 	[%rd300+3072], %r517;
	st.global.u32 	[%rd300+3584], %r518;
	st.global.u32 	[%rd300+4096], %r519;
	st.global.u32 	[%rd300+4608], %r520;
	st.global.u32 	[%rd300+5120], %r521;
	st.global.u32 	[%rd300+5632], %r522;
	st.global.u32 	[%rd300+6144], %r523;
	st.global.u32 	[%rd300+6656], %r524;
	st.global.u32 	[%rd300+7168], %r525;
	add.s32 	%r1338, %r1337, 1920;
	setp.le.s32	%p49, %r1338, %r1302;
	mov.u32 	%r1336, %r1337;
	@%p49 bra 	BB27_73;

BB27_74:
	setp.le.s32	%p50, %r1302, %r1336;
	@%p50 bra 	BB27_271;

	sub.s32 	%r99, %r1302, %r1336;
	cvt.s64.s32	%rd37, %r1336;
	sub.s32 	%r100, %r99, %r10;
	setp.lt.s32	%p51, %r100, 1;
	@%p51 bra 	BB27_77;

	cvt.s64.s32	%rd302, %r10;
	add.s64 	%rd303, %rd302, %rd37;
	shl.b64 	%rd304, %rd303, 2;
	add.s64 	%rd301, %rd136, %rd304;
	// inline asm
	ld.global.nc.u32 %r1303, [%rd301];
	// inline asm

BB27_77:
	setp.lt.s32	%p52, %r100, 129;
	@%p52 bra 	BB27_79;

	add.s32 	%r528, %r10, 128;
	cvt.s64.s32	%rd306, %r528;
	add.s64 	%rd307, %rd306, %rd37;
	shl.b64 	%rd308, %rd307, 2;
	add.s64 	%rd305, %rd136, %rd308;
	// inline asm
	ld.global.nc.u32 %r1304, [%rd305];
	// inline asm

BB27_79:
	setp.lt.s32	%p53, %r100, 257;
	@%p53 bra 	BB27_81;

	add.s32 	%r530, %r10, 256;
	cvt.s64.s32	%rd310, %r530;
	add.s64 	%rd311, %rd310, %rd37;
	shl.b64 	%rd312, %rd311, 2;
	add.s64 	%rd309, %rd136, %rd312;
	// inline asm
	ld.global.nc.u32 %r1305, [%rd309];
	// inline asm

BB27_81:
	setp.lt.s32	%p54, %r100, 385;
	@%p54 bra 	BB27_83;

	add.s32 	%r532, %r10, 384;
	cvt.s64.s32	%rd314, %r532;
	add.s64 	%rd315, %rd314, %rd37;
	shl.b64 	%rd316, %rd315, 2;
	add.s64 	%rd313, %rd136, %rd316;
	// inline asm
	ld.global.nc.u32 %r1306, [%rd313];
	// inline asm

BB27_83:
	setp.lt.s32	%p55, %r100, 513;
	@%p55 bra 	BB27_85;

	add.s32 	%r534, %r10, 512;
	cvt.s64.s32	%rd318, %r534;
	add.s64 	%rd319, %rd318, %rd37;
	shl.b64 	%rd320, %rd319, 2;
	add.s64 	%rd317, %rd136, %rd320;
	// inline asm
	ld.global.nc.u32 %r1307, [%rd317];
	// inline asm

BB27_85:
	setp.lt.s32	%p56, %r100, 641;
	@%p56 bra 	BB27_87;

	add.s32 	%r536, %r10, 640;
	cvt.s64.s32	%rd322, %r536;
	add.s64 	%rd323, %rd322, %rd37;
	shl.b64 	%rd324, %rd323, 2;
	add.s64 	%rd321, %rd136, %rd324;
	// inline asm
	ld.global.nc.u32 %r1308, [%rd321];
	// inline asm

BB27_87:
	setp.lt.s32	%p57, %r100, 769;
	@%p57 bra 	BB27_89;

	add.s32 	%r538, %r10, 768;
	cvt.s64.s32	%rd326, %r538;
	add.s64 	%rd327, %rd326, %rd37;
	shl.b64 	%rd328, %rd327, 2;
	add.s64 	%rd325, %rd136, %rd328;
	// inline asm
	ld.global.nc.u32 %r1309, [%rd325];
	// inline asm

BB27_89:
	setp.lt.s32	%p58, %r100, 897;
	@%p58 bra 	BB27_91;

	add.s32 	%r540, %r10, 896;
	cvt.s64.s32	%rd330, %r540;
	add.s64 	%rd331, %rd330, %rd37;
	shl.b64 	%rd332, %rd331, 2;
	add.s64 	%rd329, %rd136, %rd332;
	// inline asm
	ld.global.nc.u32 %r1310, [%rd329];
	// inline asm

BB27_91:
	setp.lt.s32	%p59, %r100, 1025;
	@%p59 bra 	BB27_93;

	add.s32 	%r542, %r10, 1024;
	cvt.s64.s32	%rd334, %r542;
	add.s64 	%rd335, %rd334, %rd37;
	shl.b64 	%rd336, %rd335, 2;
	add.s64 	%rd333, %rd136, %rd336;
	// inline asm
	ld.global.nc.u32 %r1311, [%rd333];
	// inline asm

BB27_93:
	setp.lt.s32	%p60, %r100, 1153;
	@%p60 bra 	BB27_95;

	add.s32 	%r544, %r10, 1152;
	cvt.s64.s32	%rd338, %r544;
	add.s64 	%rd339, %rd338, %rd37;
	shl.b64 	%rd340, %rd339, 2;
	add.s64 	%rd337, %rd136, %rd340;
	// inline asm
	ld.global.nc.u32 %r1312, [%rd337];
	// inline asm

BB27_95:
	setp.lt.s32	%p61, %r100, 1281;
	@%p61 bra 	BB27_97;

	add.s32 	%r546, %r10, 1280;
	cvt.s64.s32	%rd342, %r546;
	add.s64 	%rd343, %rd342, %rd37;
	shl.b64 	%rd344, %rd343, 2;
	add.s64 	%rd341, %rd136, %rd344;
	// inline asm
	ld.global.nc.u32 %r1313, [%rd341];
	// inline asm

BB27_97:
	setp.lt.s32	%p62, %r100, 1409;
	@%p62 bra 	BB27_99;

	add.s32 	%r548, %r10, 1408;
	cvt.s64.s32	%rd346, %r548;
	add.s64 	%rd347, %rd346, %rd37;
	shl.b64 	%rd348, %rd347, 2;
	add.s64 	%rd345, %rd136, %rd348;
	// inline asm
	ld.global.nc.u32 %r1314, [%rd345];
	// inline asm

BB27_99:
	setp.lt.s32	%p63, %r100, 1537;
	@%p63 bra 	BB27_101;

	add.s32 	%r550, %r10, 1536;
	cvt.s64.s32	%rd350, %r550;
	add.s64 	%rd351, %rd350, %rd37;
	shl.b64 	%rd352, %rd351, 2;
	add.s64 	%rd349, %rd136, %rd352;
	// inline asm
	ld.global.nc.u32 %r1315, [%rd349];
	// inline asm

BB27_101:
	setp.lt.s32	%p64, %r100, 1665;
	@%p64 bra 	BB27_103;

	add.s32 	%r552, %r10, 1664;
	cvt.s64.s32	%rd354, %r552;
	add.s64 	%rd355, %rd354, %rd37;
	shl.b64 	%rd356, %rd355, 2;
	add.s64 	%rd353, %rd136, %rd356;
	// inline asm
	ld.global.nc.u32 %r1316, [%rd353];
	// inline asm

BB27_103:
	setp.lt.s32	%p65, %r100, 1793;
	@%p65 bra 	BB27_105;

	add.s32 	%r554, %r10, 1792;
	cvt.s64.s32	%rd358, %r554;
	add.s64 	%rd359, %rd358, %rd37;
	shl.b64 	%rd360, %rd359, 2;
	add.s64 	%rd357, %rd136, %rd360;
	// inline asm
	ld.global.nc.u32 %r1317, [%rd357];
	// inline asm

BB27_105:
	bar.sync 	0;
	cvt.s64.s32	%rd361, %r10;
	add.s64 	%rd362, %rd361, %rd37;
	shl.b64 	%rd363, %rd362, 2;
	add.s64 	%rd38, %rd1, %rd363;
	setp.le.s32	%p66, %r99, %r10;
	@%p66 bra 	BB27_107;

	st.global.u32 	[%rd38], %r1303;

BB27_107:
	add.s32 	%r555, %r10, 128;
	setp.ge.s32	%p67, %r555, %r99;
	@%p67 bra 	BB27_109;

	st.global.u32 	[%rd38+512], %r1304;

BB27_109:
	add.s32 	%r556, %r10, 256;
	setp.ge.s32	%p68, %r556, %r99;
	@%p68 bra 	BB27_111;

	st.global.u32 	[%rd38+1024], %r1305;

BB27_111:
	add.s32 	%r557, %r10, 384;
	setp.ge.s32	%p69, %r557, %r99;
	@%p69 bra 	BB27_113;

	st.global.u32 	[%rd38+1536], %r1306;

BB27_113:
	add.s32 	%r558, %r10, 512;
	setp.ge.s32	%p70, %r558, %r99;
	@%p70 bra 	BB27_115;

	st.global.u32 	[%rd38+2048], %r1307;

BB27_115:
	add.s32 	%r559, %r10, 640;
	setp.ge.s32	%p71, %r559, %r99;
	@%p71 bra 	BB27_117;

	st.global.u32 	[%rd38+2560], %r1308;

BB27_117:
	add.s32 	%r560, %r10, 768;
	setp.ge.s32	%p72, %r560, %r99;
	@%p72 bra 	BB27_119;

	st.global.u32 	[%rd38+3072], %r1309;

BB27_119:
	add.s32 	%r561, %r10, 896;
	setp.ge.s32	%p73, %r561, %r99;
	@%p73 bra 	BB27_121;

	st.global.u32 	[%rd38+3584], %r1310;

BB27_121:
	add.s32 	%r562, %r10, 1024;
	setp.ge.s32	%p74, %r562, %r99;
	@%p74 bra 	BB27_123;

	st.global.u32 	[%rd38+4096], %r1311;

BB27_123:
	add.s32 	%r563, %r10, 1152;
	setp.ge.s32	%p75, %r563, %r99;
	@%p75 bra 	BB27_125;

	st.global.u32 	[%rd38+4608], %r1312;

BB27_125:
	add.s32 	%r564, %r10, 1280;
	setp.ge.s32	%p76, %r564, %r99;
	@%p76 bra 	BB27_127;

	st.global.u32 	[%rd38+5120], %r1313;

BB27_127:
	add.s32 	%r565, %r10, 1408;
	setp.ge.s32	%p77, %r565, %r99;
	@%p77 bra 	BB27_129;

	st.global.u32 	[%rd38+5632], %r1314;

BB27_129:
	add.s32 	%r566, %r10, 1536;
	setp.ge.s32	%p78, %r566, %r99;
	@%p78 bra 	BB27_131;

	st.global.u32 	[%rd38+6144], %r1315;

BB27_131:
	add.s32 	%r567, %r10, 1664;
	setp.ge.s32	%p79, %r567, %r99;
	@%p79 bra 	BB27_133;

	st.global.u32 	[%rd38+6656], %r1316;

BB27_133:
	add.s32 	%r568, %r10, 1792;
	setp.ge.s32	%p80, %r568, %r99;
	@%p80 bra 	BB27_271;

	st.global.u32 	[%rd38+7168], %r1317;
	bra.uni 	BB27_271;

BB27_135:
	setp.gt.s32	%p81, %r13, %r1302;
	mov.u32 	%r1333, %r9;
	@%p81 bra 	BB27_144;

	shr.s32 	%r571, %r10, 31;
	shr.u32 	%r572, %r571, 27;
	add.s32 	%r573, %r10, %r572;
	shr.s32 	%r574, %r573, 5;
	mul.wide.s32 	%rd364, %r574, 8;
	mov.u64 	%rd365, _ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE21PtxAltDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE$__cuda_local_var_106605_76_non_const_temp_storage;
	add.s64 	%rd366, %rd365, %rd364;
	add.s64 	%rd39, %rd366, 80;
	// inline asm
	mov.u32 %r710, %laneid;
	// inline asm
	mov.u32 	%r1334, %r9;
	mov.u32 	%r1335, %r13;

BB27_137:
	mov.u32 	%r1331, %r1335;
	mov.u32 	%r132, %r1334;
	mov.u32 	%r1334, %r1331;
	mul.lo.s32 	%r590, %r10, 15;
	cvt.s64.s32	%rd382, %r590;
	cvt.s64.s32	%rd383, %r132;
	add.s64 	%rd384, %rd382, %rd383;
	shl.b64 	%rd385, %rd384, 2;
	add.s64 	%rd367, %rd134, %rd385;
	// inline asm
	ld.global.nc.u32 %r575, [%rd367];
	// inline asm
	add.s32 	%r591, %r590, 1;
	cvt.s64.s32	%rd386, %r591;
	add.s64 	%rd387, %rd386, %rd383;
	shl.b64 	%rd388, %rd387, 2;
	add.s64 	%rd368, %rd134, %rd388;
	// inline asm
	ld.global.nc.u32 %r576, [%rd368];
	// inline asm
	add.s32 	%r592, %r590, 2;
	cvt.s64.s32	%rd389, %r592;
	add.s64 	%rd390, %rd389, %rd383;
	shl.b64 	%rd391, %rd390, 2;
	add.s64 	%rd369, %rd134, %rd391;
	// inline asm
	ld.global.nc.u32 %r577, [%rd369];
	// inline asm
	add.s32 	%r593, %r590, 3;
	cvt.s64.s32	%rd392, %r593;
	add.s64 	%rd393, %rd392, %rd383;
	shl.b64 	%rd394, %rd393, 2;
	add.s64 	%rd370, %rd134, %rd394;
	// inline asm
	ld.global.nc.u32 %r578, [%rd370];
	// inline asm
	add.s32 	%r594, %r590, 4;
	cvt.s64.s32	%rd395, %r594;
	add.s64 	%rd396, %rd395, %rd383;
	shl.b64 	%rd397, %rd396, 2;
	add.s64 	%rd371, %rd134, %rd397;
	// inline asm
	ld.global.nc.u32 %r579, [%rd371];
	// inline asm
	add.s32 	%r595, %r590, 5;
	cvt.s64.s32	%rd398, %r595;
	add.s64 	%rd399, %rd398, %rd383;
	shl.b64 	%rd400, %rd399, 2;
	add.s64 	%rd372, %rd134, %rd400;
	// inline asm
	ld.global.nc.u32 %r580, [%rd372];
	// inline asm
	add.s32 	%r596, %r590, 6;
	cvt.s64.s32	%rd401, %r596;
	add.s64 	%rd402, %rd401, %rd383;
	shl.b64 	%rd403, %rd402, 2;
	add.s64 	%rd373, %rd134, %rd403;
	// inline asm
	ld.global.nc.u32 %r581, [%rd373];
	// inline asm
	add.s32 	%r597, %r590, 7;
	cvt.s64.s32	%rd404, %r597;
	add.s64 	%rd405, %rd404, %rd383;
	shl.b64 	%rd406, %rd405, 2;
	add.s64 	%rd374, %rd134, %rd406;
	// inline asm
	ld.global.nc.u32 %r582, [%rd374];
	// inline asm
	add.s32 	%r598, %r590, 8;
	cvt.s64.s32	%rd407, %r598;
	add.s64 	%rd408, %rd407, %rd383;
	shl.b64 	%rd409, %rd408, 2;
	add.s64 	%rd375, %rd134, %rd409;
	// inline asm
	ld.global.nc.u32 %r583, [%rd375];
	// inline asm
	add.s32 	%r599, %r590, 9;
	cvt.s64.s32	%rd410, %r599;
	add.s64 	%rd411, %rd410, %rd383;
	shl.b64 	%rd412, %rd411, 2;
	add.s64 	%rd376, %rd134, %rd412;
	// inline asm
	ld.global.nc.u32 %r584, [%rd376];
	// inline asm
	add.s32 	%r600, %r590, 10;
	cvt.s64.s32	%rd413, %r600;
	add.s64 	%rd414, %rd413, %rd383;
	shl.b64 	%rd415, %rd414, 2;
	add.s64 	%rd377, %rd134, %rd415;
	// inline asm
	ld.global.nc.u32 %r585, [%rd377];
	// inline asm
	add.s32 	%r601, %r590, 11;
	cvt.s64.s32	%rd416, %r601;
	add.s64 	%rd417, %rd416, %rd383;
	shl.b64 	%rd418, %rd417, 2;
	add.s64 	%rd378, %rd134, %rd418;
	// inline asm
	ld.global.nc.u32 %r586, [%rd378];
	// inline asm
	add.s32 	%r602, %r590, 12;
	cvt.s64.s32	%rd419, %r602;
	add.s64 	%rd420, %rd419, %rd383;
	shl.b64 	%rd421, %rd420, 2;
	add.s64 	%rd379, %rd134, %rd421;
	// inline asm
	ld.global.nc.u32 %r587, [%rd379];
	// inline asm
	add.s32 	%r603, %r590, 13;
	cvt.s64.s32	%rd422, %r603;
	add.s64 	%rd423, %rd422, %rd383;
	shl.b64 	%rd424, %rd423, 2;
	add.s64 	%rd380, %rd134, %rd424;
	// inline asm
	ld.global.nc.u32 %r588, [%rd380];
	// inline asm
	add.s32 	%r604, %r590, 14;
	cvt.s64.s32	%rd425, %r604;
	add.s64 	%rd426, %rd425, %rd383;
	shl.b64 	%rd427, %rd426, 2;
	add.s64 	%rd381, %rd134, %rd427;
	// inline asm
	ld.global.nc.u32 %r589, [%rd381];
	// inline asm
	bar.sync 	0;
	xor.b32  	%r606, %r575, -2147483648;
	xor.b32  	%r610, %r576, -2147483648;
	xor.b32  	%r614, %r577, -2147483648;
	xor.b32  	%r618, %r578, -2147483648;
	xor.b32  	%r622, %r579, -2147483648;
	xor.b32  	%r626, %r580, -2147483648;
	xor.b32  	%r630, %r581, -2147483648;
	xor.b32  	%r634, %r582, -2147483648;
	xor.b32  	%r638, %r583, -2147483648;
	xor.b32  	%r642, %r584, -2147483648;
	xor.b32  	%r646, %r585, -2147483648;
	xor.b32  	%r650, %r586, -2147483648;
	xor.b32  	%r654, %r587, -2147483648;
	xor.b32  	%r658, %r588, -2147483648;
	xor.b32  	%r662, %r589, -2147483648;
	cvt.s64.s32	%rd40, %r10;
	mul.wide.s32 	%rd428, %r10, 8;
	add.s64 	%rd430, %rd365, 120;
	add.s64 	%rd431, %rd430, %rd428;
	mov.u64 	%rd432, 0;
	st.shared.u64 	[%rd431], %rd432;
	st.shared.u64 	[%rd431+1024], %rd432;
	st.shared.u64 	[%rd431+2048], %rd432;
	st.shared.u64 	[%rd431+3072], %rd432;
	st.shared.u64 	[%rd431+4096], %rd432;
	// inline asm
	bfe.u32 %r605, %r606, %r390, %r391;
	// inline asm
	shr.u32 	%r665, %r605, 2;
	and.b32  	%r666, %r605, 3;
	mul.wide.u32 	%rd433, %r666, 1024;
	add.s64 	%rd434, %rd430, %rd433;
	add.s64 	%rd435, %rd434, %rd428;
	mul.wide.u32 	%rd436, %r665, 2;
	add.s64 	%rd41, %rd435, %rd436;
	ld.shared.u16 	%r165, [%rd41];
	add.s32 	%r667, %r165, 1;
	st.shared.u16 	[%rd41], %r667;
	// inline asm
	bfe.u32 %r609, %r610, %r390, %r391;
	// inline asm
	and.b32  	%r668, %r609, 3;
	shr.u32 	%r669, %r609, 2;
	mul.wide.u32 	%rd437, %r668, 1024;
	add.s64 	%rd438, %rd430, %rd437;
	add.s64 	%rd439, %rd438, %rd428;
	mul.wide.u32 	%rd440, %r669, 2;
	add.s64 	%rd42, %rd439, %rd440;
	ld.shared.u16 	%r166, [%rd42];
	add.s32 	%r670, %r166, 1;
	st.shared.u16 	[%rd42], %r670;
	// inline asm
	bfe.u32 %r613, %r614, %r390, %r391;
	// inline asm
	shr.u32 	%r671, %r613, 2;
	and.b32  	%r672, %r613, 3;
	mul.wide.u32 	%rd441, %r672, 1024;
	add.s64 	%rd442, %rd430, %rd441;
	add.s64 	%rd443, %rd442, %rd428;
	mul.wide.u32 	%rd444, %r671, 2;
	add.s64 	%rd43, %rd443, %rd444;
	ld.shared.u16 	%r167, [%rd43];
	add.s32 	%r673, %r167, 1;
	st.shared.u16 	[%rd43], %r673;
	// inline asm
	bfe.u32 %r617, %r618, %r390, %r391;
	// inline asm
	shr.u32 	%r674, %r617, 2;
	and.b32  	%r675, %r617, 3;
	mul.wide.u32 	%rd445, %r675, 1024;
	add.s64 	%rd446, %rd430, %rd445;
	add.s64 	%rd447, %rd446, %rd428;
	mul.wide.u32 	%rd448, %r674, 2;
	add.s64 	%rd44, %rd447, %rd448;
	ld.shared.u16 	%r168, [%rd44];
	add.s32 	%r676, %r168, 1;
	st.shared.u16 	[%rd44], %r676;
	// inline asm
	bfe.u32 %r621, %r622, %r390, %r391;
	// inline asm
	shr.u32 	%r677, %r621, 2;
	and.b32  	%r678, %r621, 3;
	mul.wide.u32 	%rd449, %r678, 1024;
	add.s64 	%rd450, %rd430, %rd449;
	add.s64 	%rd451, %rd450, %rd428;
	mul.wide.u32 	%rd452, %r677, 2;
	add.s64 	%rd45, %rd451, %rd452;
	ld.shared.u16 	%r169, [%rd45];
	add.s32 	%r679, %r169, 1;
	st.shared.u16 	[%rd45], %r679;
	// inline asm
	bfe.u32 %r625, %r626, %r390, %r391;
	// inline asm
	shr.u32 	%r680, %r625, 2;
	and.b32  	%r681, %r625, 3;
	mul.wide.u32 	%rd453, %r681, 1024;
	add.s64 	%rd454, %rd430, %rd453;
	add.s64 	%rd455, %rd454, %rd428;
	mul.wide.u32 	%rd456, %r680, 2;
	add.s64 	%rd46, %rd455, %rd456;
	ld.shared.u16 	%r170, [%rd46];
	add.s32 	%r682, %r170, 1;
	st.shared.u16 	[%rd46], %r682;
	// inline asm
	bfe.u32 %r629, %r630, %r390, %r391;
	// inline asm
	shr.u32 	%r683, %r629, 2;
	and.b32  	%r684, %r629, 3;
	mul.wide.u32 	%rd457, %r684, 1024;
	add.s64 	%rd458, %rd430, %rd457;
	add.s64 	%rd459, %rd458, %rd428;
	mul.wide.u32 	%rd460, %r683, 2;
	add.s64 	%rd47, %rd459, %rd460;
	ld.shared.u16 	%r171, [%rd47];
	add.s32 	%r685, %r171, 1;
	st.shared.u16 	[%rd47], %r685;
	// inline asm
	bfe.u32 %r633, %r634, %r390, %r391;
	// inline asm
	shr.u32 	%r686, %r633, 2;
	and.b32  	%r687, %r633, 3;
	mul.wide.u32 	%rd461, %r687, 1024;
	add.s64 	%rd462, %rd430, %rd461;
	add.s64 	%rd463, %rd462, %rd428;
	mul.wide.u32 	%rd464, %r686, 2;
	add.s64 	%rd48, %rd463, %rd464;
	ld.shared.u16 	%r172, [%rd48];
	add.s32 	%r688, %r172, 1;
	st.shared.u16 	[%rd48], %r688;
	// inline asm
	bfe.u32 %r637, %r638, %r390, %r391;
	// inline asm
	shr.u32 	%r689, %r637, 2;
	and.b32  	%r690, %r637, 3;
	mul.wide.u32 	%rd465, %r690, 1024;
	add.s64 	%rd466, %rd430, %rd465;
	add.s64 	%rd467, %rd466, %rd428;
	mul.wide.u32 	%rd468, %r689, 2;
	add.s64 	%rd49, %rd467, %rd468;
	ld.shared.u16 	%r173, [%rd49];
	add.s32 	%r691, %r173, 1;
	st.shared.u16 	[%rd49], %r691;
	// inline asm
	bfe.u32 %r641, %r642, %r390, %r391;
	// inline asm
	shr.u32 	%r692, %r641, 2;
	and.b32  	%r693, %r641, 3;
	mul.wide.u32 	%rd469, %r693, 1024;
	add.s64 	%rd470, %rd430, %rd469;
	add.s64 	%rd471, %rd470, %rd428;
	mul.wide.u32 	%rd472, %r692, 2;
	add.s64 	%rd50, %rd471, %rd472;
	ld.shared.u16 	%r174, [%rd50];
	add.s32 	%r694, %r174, 1;
	st.shared.u16 	[%rd50], %r694;
	// inline asm
	bfe.u32 %r645, %r646, %r390, %r391;
	// inline asm
	shr.u32 	%r695, %r645, 2;
	and.b32  	%r696, %r645, 3;
	mul.wide.u32 	%rd473, %r696, 1024;
	add.s64 	%rd474, %rd430, %rd473;
	add.s64 	%rd475, %rd474, %rd428;
	mul.wide.u32 	%rd476, %r695, 2;
	add.s64 	%rd51, %rd475, %rd476;
	ld.shared.u16 	%r175, [%rd51];
	add.s32 	%r697, %r175, 1;
	st.shared.u16 	[%rd51], %r697;
	// inline asm
	bfe.u32 %r649, %r650, %r390, %r391;
	// inline asm
	shr.u32 	%r698, %r649, 2;
	and.b32  	%r699, %r649, 3;
	mul.wide.u32 	%rd477, %r699, 1024;
	add.s64 	%rd478, %rd430, %rd477;
	add.s64 	%rd479, %rd478, %rd428;
	mul.wide.u32 	%rd480, %r698, 2;
	add.s64 	%rd52, %rd479, %rd480;
	ld.shared.u16 	%r176, [%rd52];
	add.s32 	%r700, %r176, 1;
	st.shared.u16 	[%rd52], %r700;
	// inline asm
	bfe.u32 %r653, %r654, %r390, %r391;
	// inline asm
	shr.u32 	%r701, %r653, 2;
	and.b32  	%r702, %r653, 3;
	mul.wide.u32 	%rd481, %r702, 1024;
	add.s64 	%rd482, %rd430, %rd481;
	add.s64 	%rd483, %rd482, %rd428;
	mul.wide.u32 	%rd484, %r701, 2;
	add.s64 	%rd53, %rd483, %rd484;
	ld.shared.u16 	%r177, [%rd53];
	add.s32 	%r703, %r177, 1;
	st.shared.u16 	[%rd53], %r703;
	// inline asm
	bfe.u32 %r657, %r658, %r390, %r391;
	// inline asm
	shr.u32 	%r704, %r657, 2;
	and.b32  	%r705, %r657, 3;
	mul.wide.u32 	%rd485, %r705, 1024;
	add.s64 	%rd486, %rd430, %rd485;
	add.s64 	%rd487, %rd486, %rd428;
	mul.wide.u32 	%rd488, %r704, 2;
	add.s64 	%rd54, %rd487, %rd488;
	ld.shared.u16 	%r178, [%rd54];
	add.s32 	%r706, %r178, 1;
	st.shared.u16 	[%rd54], %r706;
	// inline asm
	bfe.u32 %r661, %r662, %r390, %r391;
	// inline asm
	shr.u32 	%r707, %r661, 2;
	and.b32  	%r708, %r661, 3;
	mul.wide.u32 	%rd489, %r708, 1024;
	add.s64 	%rd490, %rd430, %rd489;
	add.s64 	%rd491, %rd490, %rd428;
	mul.wide.u32 	%rd492, %r707, 2;
	add.s64 	%rd55, %rd491, %rd492;
	ld.shared.u16 	%r179, [%rd55];
	add.s32 	%r709, %r179, 1;
	st.shared.u16 	[%rd55], %r709;
	bar.sync 	0;
	mul.lo.s64 	%rd503, %rd40, 40;
	add.s64 	%rd505, %rd365, %rd503;
	ld.shared.u64 	%rd56, [%rd505+128];
	ld.shared.u64 	%rd57, [%rd505+120];
	add.s64 	%rd506, %rd56, %rd57;
	ld.shared.u64 	%rd58, [%rd505+136];
	add.s64 	%rd507, %rd506, %rd58;
	ld.shared.u64 	%rd59, [%rd505+144];
	add.s64 	%rd508, %rd507, %rd59;
	ld.shared.u64 	%rd509, [%rd505+152];
	add.s64 	%rd494, %rd508, %rd509;
	mov.u32 	%r711, 1;
	mov.u32 	%r720, 0;
	// inline asm
	{  .reg .u32 lo;  .reg .u32 hi;  .reg .pred p;  mov.b64 {lo, hi}, %rd494;  shfl.up.b32 lo|p, lo, %r711, %r720;  shfl.up.b32 hi|p, hi, %r711, %r720;  mov.b64 %rd493, {lo, hi};  @p add.u64 %rd493, %rd493, %rd494;}
	// inline asm
	mov.u32 	%r713, 2;
	// inline asm
	{  .reg .u32 lo;  .reg .u32 hi;  .reg .pred p;  mov.b64 {lo, hi}, %rd493;  shfl.up.b32 lo|p, lo, %r713, %r720;  shfl.up.b32 hi|p, hi, %r713, %r720;  mov.b64 %rd495, {lo, hi};  @p add.u64 %rd495, %rd495, %rd493;}
	// inline asm
	mov.u32 	%r715, 4;
	// inline asm
	{  .reg .u32 lo;  .reg .u32 hi;  .reg .pred p;  mov.b64 {lo, hi}, %rd495;  shfl.up.b32 lo|p, lo, %r715, %r720;  shfl.up.b32 hi|p, hi, %r715, %r720;  mov.b64 %rd497, {lo, hi};  @p add.u64 %rd497, %rd497, %rd495;}
	// inline asm
	mov.u32 	%r717, 8;
	// inline asm
	{  .reg .u32 lo;  .reg .u32 hi;  .reg .pred p;  mov.b64 {lo, hi}, %rd497;  shfl.up.b32 lo|p, lo, %r717, %r720;  shfl.up.b32 hi|p, hi, %r717, %r720;  mov.b64 %rd499, {lo, hi};  @p add.u64 %rd499, %rd499, %rd497;}
	// inline asm
	mov.u32 	%r719, 16;
	// inline asm
	{  .reg .u32 lo;  .reg .u32 hi;  .reg .pred p;  mov.b64 {lo, hi}, %rd499;  shfl.up.b32 lo|p, lo, %r719, %r720;  shfl.up.b32 hi|p, hi, %r719, %r720;  mov.b64 %rd501, {lo, hi};  @p add.u64 %rd501, %rd501, %rd499;}
	// inline asm
	setp.ne.s32	%p82, %r710, 31;
	@%p82 bra 	BB27_139;

	st.shared.u64 	[%rd39], %rd501;

BB27_139:
	sub.s64 	%rd62, %rd501, %rd494;
	setp.lt.s32	%p1, %r10, 16;
	and.b32  	%r721, %r10, -32;
	setp.eq.s32	%p2, %r721, 96;
	setp.eq.s32	%p3, %r721, 64;
	setp.eq.s32	%p4, %r721, 32;
	bar.sync 	0;
	ld.shared.u64 	%rd511, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE21PtxAltDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE$__cuda_local_var_106605_76_non_const_temp_storage+80];
	selp.b64	%rd512, %rd511, 0, %p4;
	add.s64 	%rd513, %rd62, %rd512;
	ld.shared.u64 	%rd514, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE21PtxAltDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE$__cuda_local_var_106605_76_non_const_temp_storage+88];
	add.s64 	%rd515, %rd514, %rd511;
	selp.b64	%rd516, %rd515, 0, %p3;
	add.s64 	%rd517, %rd513, %rd516;
	ld.shared.u64 	%rd518, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE21PtxAltDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE$__cuda_local_var_106605_76_non_const_temp_storage+96];
	add.s64 	%rd519, %rd515, %rd518;
	selp.b64	%rd520, %rd519, 0, %p2;
	add.s64 	%rd521, %rd517, %rd520;
	ld.shared.u64 	%rd522, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE21PtxAltDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE$__cuda_local_var_106605_76_non_const_temp_storage+104];
	add.s64 	%rd523, %rd519, %rd522;
	shl.b64 	%rd524, %rd523, 16;
	add.s64 	%rd525, %rd524, %rd521;
	shl.b64 	%rd526, %rd523, 32;
	add.s64 	%rd527, %rd526, %rd525;
	shl.b64 	%rd528, %rd523, 48;
	add.s64 	%rd529, %rd528, %rd527;
	add.s64 	%rd530, %rd57, %rd529;
	add.s64 	%rd531, %rd530, %rd56;
	add.s64 	%rd532, %rd531, %rd58;
	add.s64 	%rd533, %rd532, %rd59;
	mul.wide.s32 	%rd534, %r10, 40;
	add.s64 	%rd535, %rd365, %rd534;
	st.shared.u64 	[%rd535+120], %rd529;
	st.shared.u64 	[%rd535+128], %rd530;
	st.shared.u64 	[%rd535+136], %rd531;
	st.shared.u64 	[%rd535+144], %rd532;
	st.shared.u64 	[%rd535+152], %rd533;
	bar.sync 	0;
	ld.shared.u16 	%r722, [%rd41];
	add.s32 	%r180, %r722, %r165;
	ld.shared.u16 	%r723, [%rd42];
	add.s32 	%r181, %r723, %r166;
	ld.shared.u16 	%r724, [%rd43];
	add.s32 	%r182, %r724, %r167;
	ld.shared.u16 	%r725, [%rd44];
	add.s32 	%r183, %r725, %r168;
	ld.shared.u16 	%r726, [%rd45];
	add.s32 	%r184, %r726, %r169;
	ld.shared.u16 	%r727, [%rd46];
	add.s32 	%r185, %r727, %r170;
	ld.shared.u16 	%r728, [%rd47];
	add.s32 	%r186, %r728, %r171;
	ld.shared.u16 	%r729, [%rd48];
	add.s32 	%r187, %r729, %r172;
	ld.shared.u16 	%r730, [%rd49];
	add.s32 	%r188, %r730, %r173;
	ld.shared.u16 	%r731, [%rd50];
	add.s32 	%r189, %r731, %r174;
	ld.shared.u16 	%r732, [%rd51];
	add.s32 	%r190, %r732, %r175;
	ld.shared.u16 	%r733, [%rd52];
	add.s32 	%r191, %r733, %r176;
	ld.shared.u16 	%r734, [%rd53];
	add.s32 	%r192, %r734, %r177;
	ld.shared.u16 	%r735, [%rd54];
	add.s32 	%r193, %r735, %r178;
	ld.shared.u16 	%r736, [%rd55];
	add.s32 	%r194, %r736, %r179;
	@!%p1 bra 	BB27_141;
	bra.uni 	BB27_140;

BB27_140:
	and.b32  	%r737, %r10, 3;
	add.s32 	%r738, %r737, 1;
	shr.s32 	%r739, %r10, 2;
	mul.wide.u32 	%rd536, %r738, 1024;
	add.s64 	%rd538, %rd365, %rd536;
	mul.wide.s32 	%rd539, %r739, 2;
	add.s64 	%rd540, %rd538, %rd539;
	ld.shared.u16 	%r1318, [%rd540+120];

BB27_141:
	@%p9 bra 	BB27_143;

	mov.u32 	%r1296, 0;
	mov.u32 	%r1295, 1;
	setp.eq.s32	%p84, %r10, 0;
	// inline asm
	  shfl.up.b32 %r740, %r1318, %r1295, %r1296;
	// inline asm
	selp.b32	%r744, 0, %r740, %p84;
	sub.s32 	%r745, %r1343, %r744;
	mul.wide.u32 	%rd541, %r10, 4;
	add.s64 	%rd543, %rd365, %rd541;
	st.shared.u32 	[%rd543], %r745;
	add.s32 	%r1343, %r745, %r1318;

BB27_143:
	bar.sync 	0;
	mul.wide.u32 	%rd544, %r180, 4;
	add.s64 	%rd546, %rd365, 72;
	add.s64 	%rd64, %rd546, %rd544;
	st.shared.u32 	[%rd64], %r606;
	mul.wide.u32 	%rd547, %r181, 4;
	add.s64 	%rd65, %rd546, %rd547;
	st.shared.u32 	[%rd65], %r610;
	mul.wide.u32 	%rd548, %r182, 4;
	add.s64 	%rd66, %rd546, %rd548;
	st.shared.u32 	[%rd66], %r614;
	mul.wide.u32 	%rd549, %r183, 4;
	add.s64 	%rd67, %rd546, %rd549;
	st.shared.u32 	[%rd67], %r618;
	mul.wide.u32 	%rd550, %r184, 4;
	add.s64 	%rd68, %rd546, %rd550;
	st.shared.u32 	[%rd68], %r622;
	mul.wide.u32 	%rd551, %r185, 4;
	add.s64 	%rd69, %rd546, %rd551;
	st.shared.u32 	[%rd69], %r626;
	mul.wide.u32 	%rd552, %r186, 4;
	add.s64 	%rd70, %rd546, %rd552;
	st.shared.u32 	[%rd70], %r630;
	mul.wide.u32 	%rd553, %r187, 4;
	add.s64 	%rd71, %rd546, %rd553;
	st.shared.u32 	[%rd71], %r634;
	mul.wide.u32 	%rd554, %r188, 4;
	add.s64 	%rd72, %rd546, %rd554;
	st.shared.u32 	[%rd72], %r638;
	mul.wide.u32 	%rd555, %r189, 4;
	add.s64 	%rd73, %rd546, %rd555;
	st.shared.u32 	[%rd73], %r642;
	mul.wide.u32 	%rd556, %r190, 4;
	add.s64 	%rd74, %rd546, %rd556;
	st.shared.u32 	[%rd74], %r646;
	mul.wide.u32 	%rd557, %r191, 4;
	add.s64 	%rd75, %rd546, %rd557;
	st.shared.u32 	[%rd75], %r650;
	mul.wide.u32 	%rd558, %r192, 4;
	add.s64 	%rd76, %rd546, %rd558;
	st.shared.u32 	[%rd76], %r654;
	mul.wide.u32 	%rd559, %r193, 4;
	add.s64 	%rd77, %rd546, %rd559;
	st.shared.u32 	[%rd77], %r658;
	mul.wide.u32 	%rd560, %r194, 4;
	add.s64 	%rd78, %rd546, %rd560;
	st.shared.u32 	[%rd78], %r662;
	bar.sync 	0;
	shl.b64 	%rd561, %rd40, 2;
	add.s64 	%rd79, %rd365, %rd561;
	ld.shared.u32 	%r747, [%rd79+72];
	ld.shared.u32 	%r751, [%rd79+584];
	ld.shared.u32 	%r755, [%rd79+1096];
	ld.shared.u32 	%r759, [%rd79+1608];
	ld.shared.u32 	%r763, [%rd79+2120];
	ld.shared.u32 	%r767, [%rd79+2632];
	ld.shared.u32 	%r771, [%rd79+3144];
	ld.shared.u32 	%r775, [%rd79+3656];
	ld.shared.u32 	%r779, [%rd79+4168];
	ld.shared.u32 	%r783, [%rd79+4680];
	ld.shared.u32 	%r787, [%rd79+5192];
	ld.shared.u32 	%r791, [%rd79+5704];
	ld.shared.u32 	%r795, [%rd79+6216];
	ld.shared.u32 	%r799, [%rd79+6728];
	ld.shared.u32 	%r803, [%rd79+7240];
	// inline asm
	bfe.u32 %r746, %r747, %r390, %r391;
	// inline asm
	mul.wide.u32 	%rd563, %r746, 4;
	add.s64 	%rd564, %rd365, %rd563;
	ld.shared.u32 	%r806, [%rd564];
	// inline asm
	bfe.u32 %r750, %r751, %r390, %r391;
	// inline asm
	mul.wide.u32 	%rd565, %r750, 4;
	add.s64 	%rd566, %rd365, %rd565;
	ld.shared.u32 	%r807, [%rd566];
	// inline asm
	bfe.u32 %r754, %r755, %r390, %r391;
	// inline asm
	mul.wide.u32 	%rd567, %r754, 4;
	add.s64 	%rd568, %rd365, %rd567;
	ld.shared.u32 	%r808, [%rd568];
	// inline asm
	bfe.u32 %r758, %r759, %r390, %r391;
	// inline asm
	mul.wide.u32 	%rd569, %r758, 4;
	add.s64 	%rd570, %rd365, %rd569;
	ld.shared.u32 	%r809, [%rd570];
	// inline asm
	bfe.u32 %r762, %r763, %r390, %r391;
	// inline asm
	mul.wide.u32 	%rd571, %r762, 4;
	add.s64 	%rd572, %rd365, %rd571;
	ld.shared.u32 	%r810, [%rd572];
	// inline asm
	bfe.u32 %r766, %r767, %r390, %r391;
	// inline asm
	mul.wide.u32 	%rd573, %r766, 4;
	add.s64 	%rd574, %rd365, %rd573;
	ld.shared.u32 	%r811, [%rd574];
	// inline asm
	bfe.u32 %r770, %r771, %r390, %r391;
	// inline asm
	mul.wide.u32 	%rd575, %r770, 4;
	add.s64 	%rd576, %rd365, %rd575;
	ld.shared.u32 	%r812, [%rd576];
	// inline asm
	bfe.u32 %r774, %r775, %r390, %r391;
	// inline asm
	mul.wide.u32 	%rd577, %r774, 4;
	add.s64 	%rd578, %rd365, %rd577;
	ld.shared.u32 	%r813, [%rd578];
	// inline asm
	bfe.u32 %r778, %r779, %r390, %r391;
	// inline asm
	mul.wide.u32 	%rd579, %r778, 4;
	add.s64 	%rd580, %rd365, %rd579;
	ld.shared.u32 	%r814, [%rd580];
	// inline asm
	bfe.u32 %r782, %r783, %r390, %r391;
	// inline asm
	mul.wide.u32 	%rd581, %r782, 4;
	add.s64 	%rd582, %rd365, %rd581;
	ld.shared.u32 	%r815, [%rd582];
	// inline asm
	bfe.u32 %r786, %r787, %r390, %r391;
	// inline asm
	mul.wide.u32 	%rd583, %r786, 4;
	add.s64 	%rd584, %rd365, %rd583;
	ld.shared.u32 	%r816, [%rd584];
	// inline asm
	bfe.u32 %r790, %r791, %r390, %r391;
	// inline asm
	mul.wide.u32 	%rd585, %r790, 4;
	add.s64 	%rd586, %rd365, %rd585;
	ld.shared.u32 	%r817, [%rd586];
	// inline asm
	bfe.u32 %r794, %r795, %r390, %r391;
	// inline asm
	mul.wide.u32 	%rd587, %r794, 4;
	add.s64 	%rd588, %rd365, %rd587;
	ld.shared.u32 	%r818, [%rd588];
	// inline asm
	bfe.u32 %r798, %r799, %r390, %r391;
	// inline asm
	mul.wide.u32 	%rd589, %r798, 4;
	add.s64 	%rd590, %rd365, %rd589;
	ld.shared.u32 	%r819, [%rd590];
	// inline asm
	bfe.u32 %r802, %r803, %r390, %r391;
	// inline asm
	mul.wide.u32 	%rd591, %r802, 4;
	add.s64 	%rd592, %rd365, %rd591;
	ld.shared.u32 	%r820, [%rd592];
	xor.b32  	%r821, %r803, -2147483648;
	xor.b32  	%r822, %r799, -2147483648;
	xor.b32  	%r823, %r795, -2147483648;
	xor.b32  	%r824, %r791, -2147483648;
	xor.b32  	%r825, %r787, -2147483648;
	xor.b32  	%r826, %r783, -2147483648;
	xor.b32  	%r827, %r779, -2147483648;
	xor.b32  	%r828, %r775, -2147483648;
	xor.b32  	%r829, %r771, -2147483648;
	xor.b32  	%r830, %r767, -2147483648;
	xor.b32  	%r831, %r763, -2147483648;
	xor.b32  	%r832, %r759, -2147483648;
	xor.b32  	%r833, %r755, -2147483648;
	xor.b32  	%r834, %r751, -2147483648;
	xor.b32  	%r835, %r747, -2147483648;
	add.s32 	%r836, %r10, %r806;
	cvt.s64.s32	%rd80, %r836;
	mul.wide.s32 	%rd594, %r836, 4;
	add.s64 	%rd595, %rd2, %rd594;
	st.global.u32 	[%rd595], %r835;
	add.s32 	%r837, %r10, 128;
	add.s32 	%r838, %r837, %r807;
	cvt.s64.s32	%rd81, %r838;
	mul.wide.s32 	%rd596, %r838, 4;
	add.s64 	%rd597, %rd2, %rd596;
	st.global.u32 	[%rd597], %r834;
	add.s32 	%r839, %r837, %r808;
	add.s32 	%r840, %r839, 128;
	cvt.s64.s32	%rd82, %r840;
	mul.wide.s32 	%rd598, %r840, 4;
	add.s64 	%rd599, %rd2, %rd598;
	st.global.u32 	[%rd599], %r833;
	add.s32 	%r841, %r837, %r809;
	add.s32 	%r842, %r841, 256;
	cvt.s64.s32	%rd83, %r842;
	mul.wide.s32 	%rd600, %r842, 4;
	add.s64 	%rd601, %rd2, %rd600;
	st.global.u32 	[%rd601], %r832;
	add.s32 	%r843, %r837, %r810;
	add.s32 	%r844, %r843, 384;
	cvt.s64.s32	%rd84, %r844;
	mul.wide.s32 	%rd602, %r844, 4;
	add.s64 	%rd603, %rd2, %rd602;
	st.global.u32 	[%rd603], %r831;
	add.s32 	%r845, %r837, %r811;
	add.s32 	%r846, %r845, 512;
	cvt.s64.s32	%rd85, %r846;
	mul.wide.s32 	%rd604, %r846, 4;
	add.s64 	%rd605, %rd2, %rd604;
	st.global.u32 	[%rd605], %r830;
	add.s32 	%r847, %r837, %r812;
	add.s32 	%r848, %r847, 640;
	cvt.s64.s32	%rd86, %r848;
	mul.wide.s32 	%rd606, %r848, 4;
	add.s64 	%rd607, %rd2, %rd606;
	st.global.u32 	[%rd607], %r829;
	add.s32 	%r849, %r837, %r813;
	add.s32 	%r850, %r849, 768;
	cvt.s64.s32	%rd87, %r850;
	mul.wide.s32 	%rd608, %r850, 4;
	add.s64 	%rd609, %rd2, %rd608;
	st.global.u32 	[%rd609], %r828;
	add.s32 	%r851, %r837, %r814;
	add.s32 	%r852, %r851, 896;
	cvt.s64.s32	%rd88, %r852;
	mul.wide.s32 	%rd610, %r852, 4;
	add.s64 	%rd611, %rd2, %rd610;
	st.global.u32 	[%rd611], %r827;
	add.s32 	%r853, %r837, %r815;
	add.s32 	%r854, %r853, 1024;
	cvt.s64.s32	%rd89, %r854;
	mul.wide.s32 	%rd612, %r854, 4;
	add.s64 	%rd613, %rd2, %rd612;
	st.global.u32 	[%rd613], %r826;
	add.s32 	%r855, %r837, %r816;
	add.s32 	%r856, %r855, 1152;
	cvt.s64.s32	%rd90, %r856;
	mul.wide.s32 	%rd614, %r856, 4;
	add.s64 	%rd615, %rd2, %rd614;
	st.global.u32 	[%rd615], %r825;
	add.s32 	%r857, %r837, %r817;
	add.s32 	%r858, %r857, 1280;
	cvt.s64.s32	%rd91, %r858;
	mul.wide.s32 	%rd616, %r858, 4;
	add.s64 	%rd617, %rd2, %rd616;
	st.global.u32 	[%rd617], %r824;
	add.s32 	%r859, %r837, %r818;
	add.s32 	%r860, %r859, 1408;
	cvt.s64.s32	%rd92, %r860;
	mul.wide.s32 	%rd618, %r860, 4;
	add.s64 	%rd619, %rd2, %rd618;
	st.global.u32 	[%rd619], %r823;
	add.s32 	%r861, %r837, %r819;
	add.s32 	%r862, %r861, 1536;
	cvt.s64.s32	%rd93, %r862;
	mul.wide.s32 	%rd620, %r862, 4;
	add.s64 	%rd621, %rd2, %rd620;
	st.global.u32 	[%rd621], %r822;
	add.s32 	%r863, %r837, %r820;
	add.s32 	%r864, %r863, 1664;
	cvt.s64.s32	%rd94, %r864;
	mul.wide.s32 	%rd622, %r864, 4;
	add.s64 	%rd623, %rd2, %rd622;
	st.global.u32 	[%rd623], %r821;
	bar.sync 	0;
	add.s64 	%rd624, %rd136, %rd385;
	// inline asm
	ld.global.nc.u32 %r865, [%rd624];
	// inline asm
	add.s64 	%rd625, %rd136, %rd388;
	// inline asm
	ld.global.nc.u32 %r866, [%rd625];
	// inline asm
	add.s64 	%rd626, %rd136, %rd391;
	// inline asm
	ld.global.nc.u32 %r867, [%rd626];
	// inline asm
	add.s64 	%rd627, %rd136, %rd394;
	// inline asm
	ld.global.nc.u32 %r868, [%rd627];
	// inline asm
	add.s64 	%rd628, %rd136, %rd397;
	// inline asm
	ld.global.nc.u32 %r869, [%rd628];
	// inline asm
	add.s64 	%rd629, %rd136, %rd400;
	// inline asm
	ld.global.nc.u32 %r870, [%rd629];
	// inline asm
	add.s64 	%rd630, %rd136, %rd403;
	// inline asm
	ld.global.nc.u32 %r871, [%rd630];
	// inline asm
	add.s64 	%rd631, %rd136, %rd406;
	// inline asm
	ld.global.nc.u32 %r872, [%rd631];
	// inline asm
	add.s64 	%rd632, %rd136, %rd409;
	// inline asm
	ld.global.nc.u32 %r873, [%rd632];
	// inline asm
	add.s64 	%rd633, %rd136, %rd412;
	// inline asm
	ld.global.nc.u32 %r874, [%rd633];
	// inline asm
	add.s64 	%rd634, %rd136, %rd415;
	// inline asm
	ld.global.nc.u32 %r875, [%rd634];
	// inline asm
	add.s64 	%rd635, %rd136, %rd418;
	// inline asm
	ld.global.nc.u32 %r876, [%rd635];
	// inline asm
	add.s64 	%rd636, %rd136, %rd421;
	// inline asm
	ld.global.nc.u32 %r877, [%rd636];
	// inline asm
	add.s64 	%rd637, %rd136, %rd424;
	// inline asm
	ld.global.nc.u32 %r878, [%rd637];
	// inline asm
	add.s64 	%rd638, %rd136, %rd427;
	// inline asm
	ld.global.nc.u32 %r879, [%rd638];
	// inline asm
	bar.sync 	0;
	st.shared.u32 	[%rd64], %r865;
	st.shared.u32 	[%rd65], %r866;
	st.shared.u32 	[%rd66], %r867;
	st.shared.u32 	[%rd67], %r868;
	st.shared.u32 	[%rd68], %r869;
	st.shared.u32 	[%rd69], %r870;
	st.shared.u32 	[%rd70], %r871;
	st.shared.u32 	[%rd71], %r872;
	st.shared.u32 	[%rd72], %r873;
	st.shared.u32 	[%rd73], %r874;
	st.shared.u32 	[%rd74], %r875;
	st.shared.u32 	[%rd75], %r876;
	st.shared.u32 	[%rd76], %r877;
	st.shared.u32 	[%rd77], %r878;
	st.shared.u32 	[%rd78], %r879;
	bar.sync 	0;
	ld.shared.u32 	%r1374, [%rd79+72];
	ld.shared.u32 	%r1375, [%rd79+584];
	ld.shared.u32 	%r1376, [%rd79+1096];
	ld.shared.u32 	%r1377, [%rd79+1608];
	ld.shared.u32 	%r1378, [%rd79+2120];
	ld.shared.u32 	%r1379, [%rd79+2632];
	ld.shared.u32 	%r1380, [%rd79+3144];
	ld.shared.u32 	%r1381, [%rd79+3656];
	ld.shared.u32 	%r1382, [%rd79+4168];
	ld.shared.u32 	%r1383, [%rd79+4680];
	ld.shared.u32 	%r1384, [%rd79+5192];
	ld.shared.u32 	%r1385, [%rd79+5704];
	ld.shared.u32 	%r1386, [%rd79+6216];
	ld.shared.u32 	%r1387, [%rd79+6728];
	ld.shared.u32 	%r1388, [%rd79+7240];
	shl.b64 	%rd686, %rd80, 2;
	add.s64 	%rd687, %rd1, %rd686;
	st.global.u32 	[%rd687], %r1374;
	shl.b64 	%rd688, %rd81, 2;
	add.s64 	%rd689, %rd1, %rd688;
	st.global.u32 	[%rd689], %r1375;
	shl.b64 	%rd690, %rd82, 2;
	add.s64 	%rd691, %rd1, %rd690;
	st.global.u32 	[%rd691], %r1376;
	shl.b64 	%rd692, %rd83, 2;
	add.s64 	%rd693, %rd1, %rd692;
	st.global.u32 	[%rd693], %r1377;
	shl.b64 	%rd694, %rd84, 2;
	add.s64 	%rd695, %rd1, %rd694;
	st.global.u32 	[%rd695], %r1378;
	shl.b64 	%rd696, %rd85, 2;
	add.s64 	%rd697, %rd1, %rd696;
	st.global.u32 	[%rd697], %r1379;
	shl.b64 	%rd698, %rd86, 2;
	add.s64 	%rd699, %rd1, %rd698;
	st.global.u32 	[%rd699], %r1380;
	shl.b64 	%rd700, %rd87, 2;
	add.s64 	%rd701, %rd1, %rd700;
	st.global.u32 	[%rd701], %r1381;
	shl.b64 	%rd702, %rd88, 2;
	add.s64 	%rd703, %rd1, %rd702;
	st.global.u32 	[%rd703], %r1382;
	shl.b64 	%rd704, %rd89, 2;
	add.s64 	%rd705, %rd1, %rd704;
	st.global.u32 	[%rd705], %r1383;
	shl.b64 	%rd706, %rd90, 2;
	add.s64 	%rd707, %rd1, %rd706;
	st.global.u32 	[%rd707], %r1384;
	shl.b64 	%rd708, %rd91, 2;
	add.s64 	%rd709, %rd1, %rd708;
	st.global.u32 	[%rd709], %r1385;
	shl.b64 	%rd710, %rd92, 2;
	add.s64 	%rd711, %rd1, %rd710;
	st.global.u32 	[%rd711], %r1386;
	shl.b64 	%rd712, %rd93, 2;
	add.s64 	%rd713, %rd1, %rd712;
	st.global.u32 	[%rd713], %r1387;
	shl.b64 	%rd714, %rd94, 2;
	add.s64 	%rd715, %rd1, %rd714;
	st.global.u32 	[%rd715], %r1388;
	bar.sync 	0;
	add.s32 	%r1335, %r1334, 1920;
	setp.le.s32	%p85, %r1335, %r1302;
	mov.u32 	%r1333, %r1334;
	@%p85 bra 	BB27_137;

BB27_144:
	setp.le.s32	%p86, %r1302, %r1333;
	@%p86 bra 	BB27_271;

	sub.s32 	%r247, %r1302, %r1333;
	cvt.s64.s32	%rd95, %r1333;
	mad.lo.s32 	%r248, %r10, -15, %r247;
	mul.lo.s32 	%r249, %r10, 15;
	mov.u32 	%r895, -1;
	setp.lt.s32	%p87, %r248, 1;
	mov.u32 	%r1372, %r895;
	@%p87 bra 	BB27_147;

	cvt.s64.s32	%rd717, %r249;
	add.s64 	%rd718, %rd717, %rd95;
	shl.b64 	%rd719, %rd718, 2;
	add.s64 	%rd716, %rd134, %rd719;
	// inline asm
	ld.global.nc.u32 %r896, [%rd716];
	// inline asm
	xor.b32  	%r250, %r896, -2147483648;
	mov.u32 	%r1372, %r250;

BB27_147:
	mov.u32 	%r251, %r1372;
	setp.lt.s32	%p88, %r248, 2;
	mov.u32 	%r1371, %r895;
	@%p88 bra 	BB27_149;

	add.s32 	%r899, %r249, 1;
	cvt.s64.s32	%rd721, %r899;
	add.s64 	%rd722, %rd721, %rd95;
	shl.b64 	%rd723, %rd722, 2;
	add.s64 	%rd720, %rd134, %rd723;
	// inline asm
	ld.global.nc.u32 %r898, [%rd720];
	// inline asm
	xor.b32  	%r1371, %r898, -2147483648;

BB27_149:
	setp.lt.s32	%p89, %r248, 3;
	mov.u32 	%r1370, %r895;
	@%p89 bra 	BB27_151;

	add.s32 	%r902, %r249, 2;
	cvt.s64.s32	%rd725, %r902;
	add.s64 	%rd726, %rd725, %rd95;
	shl.b64 	%rd727, %rd726, 2;
	add.s64 	%rd724, %rd134, %rd727;
	// inline asm
	ld.global.nc.u32 %r901, [%rd724];
	// inline asm
	xor.b32  	%r1370, %r901, -2147483648;

BB27_151:
	setp.lt.s32	%p90, %r248, 4;
	mov.u32 	%r1369, %r895;
	@%p90 bra 	BB27_153;

	add.s32 	%r905, %r249, 3;
	cvt.s64.s32	%rd729, %r905;
	add.s64 	%rd730, %rd729, %rd95;
	shl.b64 	%rd731, %rd730, 2;
	add.s64 	%rd728, %rd134, %rd731;
	// inline asm
	ld.global.nc.u32 %r904, [%rd728];
	// inline asm
	xor.b32  	%r1369, %r904, -2147483648;

BB27_153:
	setp.lt.s32	%p91, %r248, 5;
	mov.u32 	%r1368, %r895;
	@%p91 bra 	BB27_155;

	add.s32 	%r908, %r249, 4;
	cvt.s64.s32	%rd733, %r908;
	add.s64 	%rd734, %rd733, %rd95;
	shl.b64 	%rd735, %rd734, 2;
	add.s64 	%rd732, %rd134, %rd735;
	// inline asm
	ld.global.nc.u32 %r907, [%rd732];
	// inline asm
	xor.b32  	%r1368, %r907, -2147483648;

BB27_155:
	setp.lt.s32	%p92, %r248, 6;
	mov.u32 	%r1367, %r895;
	@%p92 bra 	BB27_157;

	add.s32 	%r911, %r249, 5;
	cvt.s64.s32	%rd737, %r911;
	add.s64 	%rd738, %rd737, %rd95;
	shl.b64 	%rd739, %rd738, 2;
	add.s64 	%rd736, %rd134, %rd739;
	// inline asm
	ld.global.nc.u32 %r910, [%rd736];
	// inline asm
	xor.b32  	%r1367, %r910, -2147483648;

BB27_157:
	setp.lt.s32	%p93, %r248, 7;
	mov.u32 	%r1366, %r895;
	@%p93 bra 	BB27_159;

	add.s32 	%r914, %r249, 6;
	cvt.s64.s32	%rd741, %r914;
	add.s64 	%rd742, %rd741, %rd95;
	shl.b64 	%rd743, %rd742, 2;
	add.s64 	%rd740, %rd134, %rd743;
	// inline asm
	ld.global.nc.u32 %r913, [%rd740];
	// inline asm
	xor.b32  	%r1366, %r913, -2147483648;

BB27_159:
	setp.lt.s32	%p94, %r248, 8;
	mov.u32 	%r1365, %r895;
	@%p94 bra 	BB27_161;

	add.s32 	%r917, %r249, 7;
	cvt.s64.s32	%rd745, %r917;
	add.s64 	%rd746, %rd745, %rd95;
	shl.b64 	%rd747, %rd746, 2;
	add.s64 	%rd744, %rd134, %rd747;
	// inline asm
	ld.global.nc.u32 %r916, [%rd744];
	// inline asm
	xor.b32  	%r1365, %r916, -2147483648;

BB27_161:
	setp.lt.s32	%p95, %r248, 9;
	mov.u32 	%r1364, %r895;
	@%p95 bra 	BB27_163;

	add.s32 	%r920, %r249, 8;
	cvt.s64.s32	%rd749, %r920;
	add.s64 	%rd750, %rd749, %rd95;
	shl.b64 	%rd751, %rd750, 2;
	add.s64 	%rd748, %rd134, %rd751;
	// inline asm
	ld.global.nc.u32 %r919, [%rd748];
	// inline asm
	xor.b32  	%r1364, %r919, -2147483648;

BB27_163:
	setp.lt.s32	%p96, %r248, 10;
	mov.u32 	%r1363, %r895;
	@%p96 bra 	BB27_165;

	add.s32 	%r923, %r249, 9;
	cvt.s64.s32	%rd753, %r923;
	add.s64 	%rd754, %rd753, %rd95;
	shl.b64 	%rd755, %rd754, 2;
	add.s64 	%rd752, %rd134, %rd755;
	// inline asm
	ld.global.nc.u32 %r922, [%rd752];
	// inline asm
	xor.b32  	%r1363, %r922, -2147483648;

BB27_165:
	setp.lt.s32	%p97, %r248, 11;
	mov.u32 	%r1362, %r895;
	@%p97 bra 	BB27_167;

	add.s32 	%r926, %r249, 10;
	cvt.s64.s32	%rd757, %r926;
	add.s64 	%rd758, %rd757, %rd95;
	shl.b64 	%rd759, %rd758, 2;
	add.s64 	%rd756, %rd134, %rd759;
	// inline asm
	ld.global.nc.u32 %r925, [%rd756];
	// inline asm
	xor.b32  	%r1362, %r925, -2147483648;

BB27_167:
	setp.lt.s32	%p98, %r248, 12;
	mov.u32 	%r1361, %r895;
	@%p98 bra 	BB27_169;

	add.s32 	%r929, %r249, 11;
	cvt.s64.s32	%rd761, %r929;
	add.s64 	%rd762, %rd761, %rd95;
	shl.b64 	%rd763, %rd762, 2;
	add.s64 	%rd760, %rd134, %rd763;
	// inline asm
	ld.global.nc.u32 %r928, [%rd760];
	// inline asm
	xor.b32  	%r1361, %r928, -2147483648;

BB27_169:
	setp.lt.s32	%p99, %r248, 13;
	mov.u32 	%r1360, %r895;
	@%p99 bra 	BB27_171;

	add.s32 	%r932, %r249, 12;
	cvt.s64.s32	%rd765, %r932;
	add.s64 	%rd766, %rd765, %rd95;
	shl.b64 	%rd767, %rd766, 2;
	add.s64 	%rd764, %rd134, %rd767;
	// inline asm
	ld.global.nc.u32 %r931, [%rd764];
	// inline asm
	xor.b32  	%r1360, %r931, -2147483648;

BB27_171:
	setp.lt.s32	%p100, %r248, 14;
	mov.u32 	%r1359, %r895;
	@%p100 bra 	BB27_173;

	add.s32 	%r935, %r249, 13;
	cvt.s64.s32	%rd769, %r935;
	add.s64 	%rd770, %rd769, %rd95;
	shl.b64 	%rd771, %rd770, 2;
	add.s64 	%rd768, %rd134, %rd771;
	// inline asm
	ld.global.nc.u32 %r934, [%rd768];
	// inline asm
	xor.b32  	%r1359, %r934, -2147483648;

BB27_173:
	setp.lt.s32	%p101, %r248, 15;
	mov.u32 	%r1358, %r895;
	@%p101 bra 	BB27_175;

	add.s32 	%r938, %r249, 14;
	cvt.s64.s32	%rd773, %r938;
	add.s64 	%rd774, %rd773, %rd95;
	shl.b64 	%rd775, %rd774, 2;
	add.s64 	%rd772, %rd134, %rd775;
	// inline asm
	ld.global.nc.u32 %r937, [%rd772];
	// inline asm
	xor.b32  	%r1358, %r937, -2147483648;

BB27_175:
	bar.sync 	0;
	cvt.s64.s32	%rd96, %r10;
	mul.wide.s32 	%rd776, %r10, 8;
	mov.u64 	%rd777, _ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE21PtxAltDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE$__cuda_local_var_106605_76_non_const_temp_storage;
	add.s64 	%rd778, %rd777, 120;
	add.s64 	%rd779, %rd778, %rd776;
	mov.u64 	%rd780, 0;
	st.shared.u64 	[%rd779], %rd780;
	st.shared.u64 	[%rd779+1024], %rd780;
	st.shared.u64 	[%rd779+2048], %rd780;
	st.shared.u64 	[%rd779+3072], %rd780;
	st.shared.u64 	[%rd779+4096], %rd780;
	// inline asm
	bfe.u32 %r939, %r251, %r390, %r391;
	// inline asm
	shr.u32 	%r999, %r939, 2;
	and.b32  	%r1000, %r939, 3;
	mul.wide.u32 	%rd781, %r1000, 1024;
	add.s64 	%rd782, %rd778, %rd781;
	add.s64 	%rd783, %rd782, %rd776;
	mul.wide.u32 	%rd784, %r999, 2;
	add.s64 	%rd97, %rd783, %rd784;
	ld.shared.u16 	%r280, [%rd97];
	add.s32 	%r1001, %r280, 1;
	st.shared.u16 	[%rd97], %r1001;
	// inline asm
	bfe.u32 %r943, %r1371, %r390, %r391;
	// inline asm
	and.b32  	%r1002, %r943, 3;
	shr.u32 	%r1003, %r943, 2;
	mul.wide.u32 	%rd785, %r1002, 1024;
	add.s64 	%rd786, %rd778, %rd785;
	add.s64 	%rd787, %rd786, %rd776;
	mul.wide.u32 	%rd788, %r1003, 2;
	add.s64 	%rd98, %rd787, %rd788;
	ld.shared.u16 	%r281, [%rd98];
	add.s32 	%r1004, %r281, 1;
	st.shared.u16 	[%rd98], %r1004;
	// inline asm
	bfe.u32 %r947, %r1370, %r390, %r391;
	// inline asm
	shr.u32 	%r1005, %r947, 2;
	and.b32  	%r1006, %r947, 3;
	mul.wide.u32 	%rd789, %r1006, 1024;
	add.s64 	%rd790, %rd778, %rd789;
	add.s64 	%rd791, %rd790, %rd776;
	mul.wide.u32 	%rd792, %r1005, 2;
	add.s64 	%rd99, %rd791, %rd792;
	ld.shared.u16 	%r282, [%rd99];
	add.s32 	%r1007, %r282, 1;
	st.shared.u16 	[%rd99], %r1007;
	// inline asm
	bfe.u32 %r951, %r1369, %r390, %r391;
	// inline asm
	shr.u32 	%r1008, %r951, 2;
	and.b32  	%r1009, %r951, 3;
	mul.wide.u32 	%rd793, %r1009, 1024;
	add.s64 	%rd794, %rd778, %rd793;
	add.s64 	%rd795, %rd794, %rd776;
	mul.wide.u32 	%rd796, %r1008, 2;
	add.s64 	%rd100, %rd795, %rd796;
	ld.shared.u16 	%r283, [%rd100];
	add.s32 	%r1010, %r283, 1;
	st.shared.u16 	[%rd100], %r1010;
	// inline asm
	bfe.u32 %r955, %r1368, %r390, %r391;
	// inline asm
	shr.u32 	%r1011, %r955, 2;
	and.b32  	%r1012, %r955, 3;
	mul.wide.u32 	%rd797, %r1012, 1024;
	add.s64 	%rd798, %rd778, %rd797;
	add.s64 	%rd799, %rd798, %rd776;
	mul.wide.u32 	%rd800, %r1011, 2;
	add.s64 	%rd101, %rd799, %rd800;
	ld.shared.u16 	%r284, [%rd101];
	add.s32 	%r1013, %r284, 1;
	st.shared.u16 	[%rd101], %r1013;
	// inline asm
	bfe.u32 %r959, %r1367, %r390, %r391;
	// inline asm
	shr.u32 	%r1014, %r959, 2;
	and.b32  	%r1015, %r959, 3;
	mul.wide.u32 	%rd801, %r1015, 1024;
	add.s64 	%rd802, %rd778, %rd801;
	add.s64 	%rd803, %rd802, %rd776;
	mul.wide.u32 	%rd804, %r1014, 2;
	add.s64 	%rd102, %rd803, %rd804;
	ld.shared.u16 	%r285, [%rd102];
	add.s32 	%r1016, %r285, 1;
	st.shared.u16 	[%rd102], %r1016;
	// inline asm
	bfe.u32 %r963, %r1366, %r390, %r391;
	// inline asm
	shr.u32 	%r1017, %r963, 2;
	and.b32  	%r1018, %r963, 3;
	mul.wide.u32 	%rd805, %r1018, 1024;
	add.s64 	%rd806, %rd778, %rd805;
	add.s64 	%rd807, %rd806, %rd776;
	mul.wide.u32 	%rd808, %r1017, 2;
	add.s64 	%rd103, %rd807, %rd808;
	ld.shared.u16 	%r286, [%rd103];
	add.s32 	%r1019, %r286, 1;
	st.shared.u16 	[%rd103], %r1019;
	// inline asm
	bfe.u32 %r967, %r1365, %r390, %r391;
	// inline asm
	shr.u32 	%r1020, %r967, 2;
	and.b32  	%r1021, %r967, 3;
	mul.wide.u32 	%rd809, %r1021, 1024;
	add.s64 	%rd810, %rd778, %rd809;
	add.s64 	%rd811, %rd810, %rd776;
	mul.wide.u32 	%rd812, %r1020, 2;
	add.s64 	%rd104, %rd811, %rd812;
	ld.shared.u16 	%r287, [%rd104];
	add.s32 	%r1022, %r287, 1;
	st.shared.u16 	[%rd104], %r1022;
	// inline asm
	bfe.u32 %r971, %r1364, %r390, %r391;
	// inline asm
	shr.u32 	%r1023, %r971, 2;
	and.b32  	%r1024, %r971, 3;
	mul.wide.u32 	%rd813, %r1024, 1024;
	add.s64 	%rd814, %rd778, %rd813;
	add.s64 	%rd815, %rd814, %rd776;
	mul.wide.u32 	%rd816, %r1023, 2;
	add.s64 	%rd105, %rd815, %rd816;
	ld.shared.u16 	%r288, [%rd105];
	add.s32 	%r1025, %r288, 1;
	st.shared.u16 	[%rd105], %r1025;
	// inline asm
	bfe.u32 %r975, %r1363, %r390, %r391;
	// inline asm
	shr.u32 	%r1026, %r975, 2;
	and.b32  	%r1027, %r975, 3;
	mul.wide.u32 	%rd817, %r1027, 1024;
	add.s64 	%rd818, %rd778, %rd817;
	add.s64 	%rd819, %rd818, %rd776;
	mul.wide.u32 	%rd820, %r1026, 2;
	add.s64 	%rd106, %rd819, %rd820;
	ld.shared.u16 	%r289, [%rd106];
	add.s32 	%r1028, %r289, 1;
	st.shared.u16 	[%rd106], %r1028;
	// inline asm
	bfe.u32 %r979, %r1362, %r390, %r391;
	// inline asm
	shr.u32 	%r1029, %r979, 2;
	and.b32  	%r1030, %r979, 3;
	mul.wide.u32 	%rd821, %r1030, 1024;
	add.s64 	%rd822, %rd778, %rd821;
	add.s64 	%rd823, %rd822, %rd776;
	mul.wide.u32 	%rd824, %r1029, 2;
	add.s64 	%rd107, %rd823, %rd824;
	ld.shared.u16 	%r290, [%rd107];
	add.s32 	%r1031, %r290, 1;
	st.shared.u16 	[%rd107], %r1031;
	// inline asm
	bfe.u32 %r983, %r1361, %r390, %r391;
	// inline asm
	shr.u32 	%r1032, %r983, 2;
	and.b32  	%r1033, %r983, 3;
	mul.wide.u32 	%rd825, %r1033, 1024;
	add.s64 	%rd826, %rd778, %rd825;
	add.s64 	%rd827, %rd826, %rd776;
	mul.wide.u32 	%rd828, %r1032, 2;
	add.s64 	%rd108, %rd827, %rd828;
	ld.shared.u16 	%r291, [%rd108];
	add.s32 	%r1034, %r291, 1;
	st.shared.u16 	[%rd108], %r1034;
	// inline asm
	bfe.u32 %r987, %r1360, %r390, %r391;
	// inline asm
	shr.u32 	%r1035, %r987, 2;
	and.b32  	%r1036, %r987, 3;
	mul.wide.u32 	%rd829, %r1036, 1024;
	add.s64 	%rd830, %rd778, %rd829;
	add.s64 	%rd831, %rd830, %rd776;
	mul.wide.u32 	%rd832, %r1035, 2;
	add.s64 	%rd109, %rd831, %rd832;
	ld.shared.u16 	%r292, [%rd109];
	add.s32 	%r1037, %r292, 1;
	st.shared.u16 	[%rd109], %r1037;
	// inline asm
	bfe.u32 %r991, %r1359, %r390, %r391;
	// inline asm
	shr.u32 	%r1038, %r991, 2;
	and.b32  	%r1039, %r991, 3;
	mul.wide.u32 	%rd833, %r1039, 1024;
	add.s64 	%rd834, %rd778, %rd833;
	add.s64 	%rd835, %rd834, %rd776;
	mul.wide.u32 	%rd836, %r1038, 2;
	add.s64 	%rd110, %rd835, %rd836;
	ld.shared.u16 	%r293, [%rd110];
	add.s32 	%r1040, %r293, 1;
	st.shared.u16 	[%rd110], %r1040;
	// inline asm
	bfe.u32 %r995, %r1358, %r390, %r391;
	// inline asm
	shr.u32 	%r1041, %r995, 2;
	and.b32  	%r1042, %r995, 3;
	mul.wide.u32 	%rd837, %r1042, 1024;
	add.s64 	%rd838, %rd778, %rd837;
	add.s64 	%rd839, %rd838, %rd776;
	mul.wide.u32 	%rd840, %r1041, 2;
	add.s64 	%rd111, %rd839, %rd840;
	ld.shared.u16 	%r294, [%rd111];
	add.s32 	%r1043, %r294, 1;
	st.shared.u16 	[%rd111], %r1043;
	bar.sync 	0;
	mul.lo.s64 	%rd851, %rd96, 40;
	add.s64 	%rd853, %rd777, %rd851;
	ld.shared.u64 	%rd112, [%rd853+128];
	ld.shared.u64 	%rd113, [%rd853+120];
	add.s64 	%rd854, %rd112, %rd113;
	ld.shared.u64 	%rd114, [%rd853+136];
	add.s64 	%rd855, %rd854, %rd114;
	ld.shared.u64 	%rd115, [%rd853+144];
	add.s64 	%rd856, %rd855, %rd115;
	ld.shared.u64 	%rd857, [%rd853+152];
	add.s64 	%rd842, %rd856, %rd857;
	// inline asm
	mov.u32 %r1044, %laneid;
	// inline asm
	mov.u32 	%r1045, 1;
	mov.u32 	%r1054, 0;
	// inline asm
	{  .reg .u32 lo;  .reg .u32 hi;  .reg .pred p;  mov.b64 {lo, hi}, %rd842;  shfl.up.b32 lo|p, lo, %r1045, %r1054;  shfl.up.b32 hi|p, hi, %r1045, %r1054;  mov.b64 %rd841, {lo, hi};  @p add.u64 %rd841, %rd841, %rd842;}
	// inline asm
	mov.u32 	%r1047, 2;
	// inline asm
	{  .reg .u32 lo;  .reg .u32 hi;  .reg .pred p;  mov.b64 {lo, hi}, %rd841;  shfl.up.b32 lo|p, lo, %r1047, %r1054;  shfl.up.b32 hi|p, hi, %r1047, %r1054;  mov.b64 %rd843, {lo, hi};  @p add.u64 %rd843, %rd843, %rd841;}
	// inline asm
	mov.u32 	%r1049, 4;
	// inline asm
	{  .reg .u32 lo;  .reg .u32 hi;  .reg .pred p;  mov.b64 {lo, hi}, %rd843;  shfl.up.b32 lo|p, lo, %r1049, %r1054;  shfl.up.b32 hi|p, hi, %r1049, %r1054;  mov.b64 %rd845, {lo, hi};  @p add.u64 %rd845, %rd845, %rd843;}
	// inline asm
	mov.u32 	%r1051, 8;
	// inline asm
	{  .reg .u32 lo;  .reg .u32 hi;  .reg .pred p;  mov.b64 {lo, hi}, %rd845;  shfl.up.b32 lo|p, lo, %r1051, %r1054;  shfl.up.b32 hi|p, hi, %r1051, %r1054;  mov.b64 %rd847, {lo, hi};  @p add.u64 %rd847, %rd847, %rd845;}
	// inline asm
	mov.u32 	%r1053, 16;
	// inline asm
	{  .reg .u32 lo;  .reg .u32 hi;  .reg .pred p;  mov.b64 {lo, hi}, %rd847;  shfl.up.b32 lo|p, lo, %r1053, %r1054;  shfl.up.b32 hi|p, hi, %r1053, %r1054;  mov.b64 %rd849, {lo, hi};  @p add.u64 %rd849, %rd849, %rd847;}
	// inline asm
	setp.ne.s32	%p102, %r1044, 31;
	@%p102 bra 	BB27_177;

	shr.s32 	%r1056, %r10, 31;
	shr.u32 	%r1057, %r1056, 27;
	add.s32 	%r1058, %r10, %r1057;
	shr.s32 	%r1059, %r1058, 5;
	mul.wide.s32 	%rd858, %r1059, 8;
	add.s64 	%rd860, %rd777, %rd858;
	st.shared.u64 	[%rd860+80], %rd849;

BB27_177:
	sub.s64 	%rd118, %rd849, %rd842;
	bar.sync 	0;
	and.b32  	%r1060, %r10, -32;
	setp.eq.s32	%p103, %r1060, 32;
	ld.shared.u64 	%rd862, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE21PtxAltDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE$__cuda_local_var_106605_76_non_const_temp_storage+80];
	selp.b64	%rd863, %rd862, 0, %p103;
	add.s64 	%rd864, %rd118, %rd863;
	ld.shared.u64 	%rd865, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE21PtxAltDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE$__cuda_local_var_106605_76_non_const_temp_storage+88];
	add.s64 	%rd866, %rd865, %rd862;
	setp.eq.s32	%p104, %r1060, 64;
	selp.b64	%rd867, %rd866, 0, %p104;
	add.s64 	%rd868, %rd864, %rd867;
	ld.shared.u64 	%rd869, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE21PtxAltDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE$__cuda_local_var_106605_76_non_const_temp_storage+96];
	add.s64 	%rd870, %rd866, %rd869;
	setp.eq.s32	%p105, %r1060, 96;
	selp.b64	%rd871, %rd870, 0, %p105;
	add.s64 	%rd872, %rd868, %rd871;
	ld.shared.u64 	%rd873, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE21PtxAltDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE$__cuda_local_var_106605_76_non_const_temp_storage+104];
	add.s64 	%rd874, %rd870, %rd873;
	shl.b64 	%rd875, %rd874, 16;
	add.s64 	%rd876, %rd875, %rd872;
	shl.b64 	%rd877, %rd874, 32;
	add.s64 	%rd878, %rd877, %rd876;
	shl.b64 	%rd879, %rd874, 48;
	add.s64 	%rd880, %rd879, %rd878;
	add.s64 	%rd881, %rd113, %rd880;
	add.s64 	%rd882, %rd881, %rd112;
	add.s64 	%rd883, %rd882, %rd114;
	add.s64 	%rd884, %rd883, %rd115;
	mul.wide.s32 	%rd885, %r10, 40;
	add.s64 	%rd886, %rd777, %rd885;
	st.shared.u64 	[%rd886+120], %rd880;
	st.shared.u64 	[%rd886+128], %rd881;
	st.shared.u64 	[%rd886+136], %rd882;
	st.shared.u64 	[%rd886+144], %rd883;
	st.shared.u64 	[%rd886+152], %rd884;
	bar.sync 	0;
	ld.shared.u16 	%r1062, [%rd97];
	add.s32 	%r296, %r1062, %r280;
	ld.shared.u16 	%r1063, [%rd98];
	add.s32 	%r297, %r1063, %r281;
	ld.shared.u16 	%r1064, [%rd99];
	add.s32 	%r298, %r1064, %r282;
	ld.shared.u16 	%r1065, [%rd100];
	add.s32 	%r299, %r1065, %r283;
	ld.shared.u16 	%r1066, [%rd101];
	add.s32 	%r300, %r1066, %r284;
	ld.shared.u16 	%r1067, [%rd102];
	add.s32 	%r301, %r1067, %r285;
	ld.shared.u16 	%r1068, [%rd103];
	add.s32 	%r302, %r1068, %r286;
	ld.shared.u16 	%r1069, [%rd104];
	add.s32 	%r303, %r1069, %r287;
	ld.shared.u16 	%r1070, [%rd105];
	add.s32 	%r304, %r1070, %r288;
	ld.shared.u16 	%r1071, [%rd106];
	add.s32 	%r305, %r1071, %r289;
	ld.shared.u16 	%r1072, [%rd107];
	add.s32 	%r306, %r1072, %r290;
	ld.shared.u16 	%r1073, [%rd108];
	add.s32 	%r307, %r1073, %r291;
	ld.shared.u16 	%r1074, [%rd109];
	add.s32 	%r308, %r1074, %r292;
	ld.shared.u16 	%r1075, [%rd110];
	add.s32 	%r309, %r1075, %r293;
	ld.shared.u16 	%r1076, [%rd111];
	add.s32 	%r310, %r1076, %r294;
	setp.gt.s32	%p106, %r10, 15;
	@%p106 bra 	BB27_179;

	and.b32  	%r1078, %r10, 3;
	shr.s32 	%r1079, %r10, 2;
	add.s32 	%r1080, %r1078, 1;
	mul.wide.u32 	%rd887, %r1080, 1024;
	add.s64 	%rd889, %rd777, %rd887;
	mul.wide.s32 	%rd890, %r1079, 2;
	add.s64 	%rd891, %rd889, %rd890;
	ld.shared.u16 	%r1373, [%rd891+120];

BB27_179:
	@%p9 bra 	BB27_181;

	mov.u32 	%r1301, 0;
	mov.u32 	%r1300, 1;
	// inline asm
	  shfl.up.b32 %r1082, %r1373, %r1300, %r1301;
	// inline asm
	setp.eq.s32	%p108, %r10, 0;
	selp.b32	%r1087, 0, %r1082, %p108;
	sub.s32 	%r1088, %r1343, %r1087;
	mul.wide.u32 	%rd892, %r10, 4;
	add.s64 	%rd894, %rd777, %rd892;
	st.shared.u32 	[%rd894], %r1088;

BB27_181:
	bar.sync 	0;
	mul.wide.u32 	%rd895, %r296, 4;
	add.s64 	%rd897, %rd777, 72;
	add.s64 	%rd119, %rd897, %rd895;
	st.shared.u32 	[%rd119], %r251;
	mul.wide.u32 	%rd898, %r297, 4;
	add.s64 	%rd120, %rd897, %rd898;
	st.shared.u32 	[%rd120], %r1371;
	mul.wide.u32 	%rd899, %r298, 4;
	add.s64 	%rd121, %rd897, %rd899;
	st.shared.u32 	[%rd121], %r1370;
	mul.wide.u32 	%rd900, %r299, 4;
	add.s64 	%rd122, %rd897, %rd900;
	st.shared.u32 	[%rd122], %r1369;
	mul.wide.u32 	%rd901, %r300, 4;
	add.s64 	%rd123, %rd897, %rd901;
	st.shared.u32 	[%rd123], %r1368;
	mul.wide.u32 	%rd902, %r301, 4;
	add.s64 	%rd124, %rd897, %rd902;
	st.shared.u32 	[%rd124], %r1367;
	mul.wide.u32 	%rd903, %r302, 4;
	add.s64 	%rd125, %rd897, %rd903;
	st.shared.u32 	[%rd125], %r1366;
	mul.wide.u32 	%rd904, %r303, 4;
	add.s64 	%rd126, %rd897, %rd904;
	st.shared.u32 	[%rd126], %r1365;
	mul.wide.u32 	%rd905, %r304, 4;
	add.s64 	%rd127, %rd897, %rd905;
	st.shared.u32 	[%rd127], %r1364;
	mul.wide.u32 	%rd906, %r305, 4;
	add.s64 	%rd128, %rd897, %rd906;
	st.shared.u32 	[%rd128], %r1363;
	mul.wide.u32 	%rd907, %r306, 4;
	add.s64 	%rd129, %rd897, %rd907;
	st.shared.u32 	[%rd129], %r1362;
	mul.wide.u32 	%rd908, %r307, 4;
	add.s64 	%rd130, %rd897, %rd908;
	st.shared.u32 	[%rd130], %r1361;
	mul.wide.u32 	%rd909, %r308, 4;
	add.s64 	%rd131, %rd897, %rd909;
	st.shared.u32 	[%rd131], %r1360;
	mul.wide.u32 	%rd910, %r309, 4;
	add.s64 	%rd132, %rd897, %rd910;
	st.shared.u32 	[%rd132], %r1359;
	mul.wide.u32 	%rd911, %r310, 4;
	add.s64 	%rd133, %rd897, %rd911;
	st.shared.u32 	[%rd133], %r1358;
	bar.sync 	0;
	ld.param.u32 	%r1298, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE21PtxAltDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_7];
	ld.param.u32 	%r1297, [_ZN6thrust6system4cuda6detail4cub_30DeviceRadixSortDownsweepKernelINS3_23DeviceRadixSortDispatchILb0EiiiE21PtxAltDownsweepPolicyELb0EiiiEEvPT1_S9_PT2_SB_PT3_SC_iibbNS3_13GridEvenShareISC_EE_param_6];
	mul.wide.s32 	%rd912, %r10, 4;
	add.s64 	%rd914, %rd777, %rd912;
	ld.shared.u32 	%r313, [%rd914+72];
	add.s32 	%r314, %r10, 128;
	ld.shared.u32 	%r315, [%rd914+584];
	ld.shared.u32 	%r316, [%rd914+1096];
	ld.shared.u32 	%r317, [%rd914+1608];
	ld.shared.u32 	%r318, [%rd914+2120];
	ld.shared.u32 	%r319, [%rd914+2632];
	ld.shared.u32 	%r320, [%rd914+3144];
	ld.shared.u32 	%r321, [%rd914+3656];
	ld.shared.u32 	%r322, [%rd914+4168];
	ld.shared.u32 	%r323, [%rd914+4680];
	ld.shared.u32 	%r324, [%rd914+5192];
	ld.shared.u32 	%r325, [%rd914+5704];
	ld.shared.u32 	%r326, [%rd914+6216];
	ld.shared.u32 	%r327, [%rd914+6728];
	ld.shared.u32 	%r328, [%rd914+7240];
	// inline asm
	bfe.u32 %r1089, %r313, %r1297, %r1298;
	// inline asm
	mul.wide.u32 	%rd915, %r1089, 4;
	add.s64 	%rd916, %rd777, %rd915;
	ld.shared.u32 	%r329, [%rd916];
	// inline asm
	bfe.u32 %r1093, %r315, %r1297, %r1298;
	// inline asm
	mul.wide.u32 	%rd917, %r1093, 4;
	add.s64 	%rd918, %rd777, %rd917;
	ld.shared.u32 	%r330, [%rd918];
	// inline asm
	bfe.u32 %r1097, %r316, %r1297, %r1298;
	// inline asm
	mul.wide.u32 	%rd919, %r1097, 4;
	add.s64 	%rd920, %rd777, %rd919;
	ld.shared.u32 	%r331, [%rd920];
	// inline asm
	bfe.u32 %r1101, %r317, %r1297, %r1298;
	// inline asm
	mul.wide.u32 	%rd921, %r1101, 4;
	add.s64 	%rd922, %rd777, %rd921;
	ld.shared.u32 	%r332, [%rd922];
	// inline asm
	bfe.u32 %r1105, %r318, %r1297, %r1298;
	// inline asm
	mul.wide.u32 	%rd923, %r1105, 4;
	add.s64 	%rd924, %rd777, %rd923;
	ld.shared.u32 	%r333, [%rd924];
	// inline asm
	bfe.u32 %r1109, %r319, %r1297, %r1298;
	// inline asm
	mul.wide.u32 	%rd925, %r1109, 4;
	add.s64 	%rd926, %rd777, %rd925;
	ld.shared.u32 	%r334, [%rd926];
	// inline asm
	bfe.u32 %r1113, %r320, %r1297, %r1298;
	// inline asm
	mul.wide.u32 	%rd927, %r1113, 4;
	add.s64 	%rd928, %rd777, %rd927;
	ld.shared.u32 	%r335, [%rd928];
	// inline asm
	bfe.u32 %r1117, %r321, %r1297, %r1298;
	// inline asm
	mul.wide.u32 	%rd929, %r1117, 4;
	add.s64 	%rd930, %rd777, %rd929;
	ld.shared.u32 	%r336, [%rd930];
	// inline asm
	bfe.u32 %r1121, %r322, %r1297, %r1298;
	// inline asm
	mul.wide.u32 	%rd931, %r1121, 4;
	add.s64 	%rd932, %rd777, %rd931;
	ld.shared.u32 	%r337, [%rd932];
	// inline asm
	bfe.u32 %r1125, %r323, %r1297, %r1298;
	// inline asm
	mul.wide.u32 	%rd933, %r1125, 4;
	add.s64 	%rd934, %rd777, %rd933;
	ld.shared.u32 	%r338, [%rd934];
	// inline asm
	bfe.u32 %r1129, %r324, %r1297, %r1298;
	// inline asm
	mul.wide.u32 	%rd935, %r1129, 4;
	add.s64 	%rd936, %rd777, %rd935;
	ld.shared.u32 	%r339, [%rd936];
	// inline asm
	bfe.u32 %r1133, %r325, %r1297, %r1298;
	// inline asm
	mul.wide.u32 	%rd937, %r1133, 4;
	add.s64 	%rd938, %rd777, %rd937;
	ld.shared.u32 	%r340, [%rd938];
	// inline asm
	bfe.u32 %r1137, %r326, %r1297, %r1298;
	// inline asm
	mul.wide.u32 	%rd939, %r1137, 4;
	add.s64 	%rd940, %rd777, %rd939;
	ld.shared.u32 	%r341, [%rd940];
	// inline asm
	bfe.u32 %r1141, %r327, %r1297, %r1298;
	// inline asm
	mul.wide.u32 	%rd941, %r1141, 4;
	add.s64 	%rd942, %rd777, %rd941;
	ld.shared.u32 	%r342, [%rd942];
	// inline asm
	bfe.u32 %r1145, %r328, %r1297, %r1298;
	// inline asm
	mul.wide.u32 	%rd943, %r1145, 4;
	add.s64 	%rd944, %rd777, %rd943;
	ld.shared.u32 	%r343, [%rd944];
	setp.ge.s32	%p109, %r10, %r247;
	@%p109 bra 	BB27_183;

	xor.b32  	%r1150, %r313, -2147483648;
	add.s32 	%r1152, %r10, %r329;
	mul.wide.s32 	%rd946, %r1152, 4;
	add.s64 	%rd947, %rd2, %rd946;
	st.global.u32 	[%rd947], %r1150;

BB27_183:
	setp.ge.s32	%p110, %r314, %r247;
	@%p110 bra 	BB27_185;

	xor.b32  	%r1153, %r315, -2147483648;
	add.s32 	%r1154, %r314, %r330;
	mul.wide.s32 	%rd949, %r1154, 4;
	add.s64 	%rd950, %rd2, %rd949;
	st.global.u32 	[%rd950], %r1153;

BB27_185:
	add.s32 	%r1155, %r314, 128;
	setp.ge.s32	%p111, %r1155, %r247;
	@%p111 bra 	BB27_187;

	xor.b32  	%r1156, %r316, -2147483648;
	add.s32 	%r1157, %r314, %r331;
	add.s32 	%r1158, %r1157, 128;
	mul.wide.s32 	%rd952, %r1158, 4;
	add.s64 	%rd953, %rd2, %rd952;
	st.global.u32 	[%rd953], %r1156;

BB27_187:
	add.s32 	%r1159, %r314, 256;
	setp.ge.s32	%p112, %r1159, %r247;
	@%p112 bra 	BB27_189;

	xor.b32  	%r1160, %r317, -2147483648;
	add.s32 	%r1161, %r314, %r332;
	add.s32 	%r1162, %r1161, 256;
	mul.wide.s32 	%rd955, %r1162, 4;
	add.s64 	%rd956, %rd2, %rd955;
	st.global.u32 	[%rd956], %r1160;

BB27_189:
	add.s32 	%r1163, %r314, 384;
	setp.ge.s32	%p113, %r1163, %r247;
	@%p113 bra 	BB27_191;

	xor.b32  	%r1164, %r318, -2147483648;
	add.s32 	%r1165, %r314, %r333;
	add.s32 	%r1166, %r1165, 384;
	mul.wide.s32 	%rd958, %r1166, 4;
	add.s64 	%rd959, %rd2, %rd958;
	st.global.u32 	[%rd959], %r1164;

BB27_191:
	add.s32 	%r1167, %r314, 512;
	setp.ge.s32	%p114, %r1167, %r247;
	@%p114 bra 	BB27_193;

	xor.b32  	%r1168, %r319, -2147483648;
	add.s32 	%r1169, %r314, %r334;
	add.s32 	%r1170, %r1169, 512;
	mul.wide.s32 	%rd961, %r1170, 4;
	add.s64 	%rd962, %rd2, %rd961;
	st.global.u32 	[%rd962], %r1168;

BB27_193:
	add.s32 	%r1171, %r314, 640;
	setp.ge.s32	%p115, %r1171, %r247;
	@%p115 bra 	BB27_195;

	xor.b32  	%r1172, %r320, -2147483648;
	add.s32 	%r1173, %r314, %r335;
	add.s32 	%r1174, %r1173, 640;
	mul.wide.s32 	%rd964, %r1174, 4;
	add.s64 	%rd965, %rd2, %rd964;
	st.global.u32 	[%rd965], %r1172;

BB27_195:
	add.s32 	%r1175, %r314, 768;
	setp.ge.s32	%p116, %r1175, %r247;
	@%p116 bra 	BB27_197;

	xor.b32  	%r1176, %r321, -2147483648;
	add.s32 	%r1177, %r314, %r336;
	add.s32 	%r1178, %r1177, 768;
	mul.wide.s32 	%rd967, %r1178, 4;
	add.s64 	%rd968, %rd2, %rd967;
	st.global.u32 	[%rd968], %r1176;

BB27_197:
	add.s32 	%r1179, %r314, 896;
	setp.ge.s32	%p117, %r1179, %r247;
	@%p117 bra 	BB27_199;

	xor.b32  	%r1180, %r322, -2147483648;
	add.s32 	%r1181, %r314, %r337;
	add.s32 	%r1182, %r1181, 896;
	mul.wide.s32 	%rd970, %r1182, 4;
	add.s64 	%rd971, %rd2, %rd970;
	st.global.u32 	[%rd971], %r1180;

BB27_199:
	add.s32 	%r1183, %r314, 1024;
	setp.ge.s32	%p118, %r1183, %r247;
	@%p118 bra 	BB27_201;

	xor.b32  	%r1184, %r323, -2147483648;
	add.s32 	%r1185, %r314, %r338;
	add.s32 	%r1186, %r1185, 1024;
	mul.wide.s32 	%rd973, %r1186, 4;
	add.s64 	%rd974, %rd2, %rd973;
	st.global.u32 	[%rd974], %r1184;

BB27_201:
	add.s32 	%r1187, %r314, 1152;
	setp.ge.s32	%p119, %r1187, %r247;
	@%p119 bra 	BB27_203;

	xor.b32  	%r1188, %r324, -2147483648;
	add.s32 	%r1189, %r314, %r339;
	add.s32 	%r1190, %r1189, 1152;
	mul.wide.s32 	%rd976, %r1190, 4;
	add.s64 	%rd977, %rd2, %rd976;
	st.global.u32 	[%rd977], %r1188;

BB27_203:
	add.s32 	%r1191, %r314, 1280;
	setp.ge.s32	%p120, %r1191, %r247;
	@%p120 bra 	BB27_205;

	xor.b32  	%r1192, %r325, -2147483648;
	add.s32 	%r1193, %r314, %r340;
	add.s32 	%r1194, %r1193, 1280;
	mul.wide.s32 	%rd979, %r1194, 4;
	add.s64 	%rd980, %rd2, %rd979;
	st.global.u32 	[%rd980], %r1192;

BB27_205:
	add.s32 	%r1195, %r314, 1408;
	setp.ge.s32	%p121, %r1195, %r247;
	@%p121 bra 	BB27_207;

	xor.b32  	%r1196, %r326, -2147483648;
	add.s32 	%r1197, %r314, %r341;
	add.s32 	%r1198, %r1197, 1408;
	mul.wide.s32 	%rd982, %r1198, 4;
	add.s64 	%rd983, %rd2, %rd982;
	st.global.u32 	[%rd983], %r1196;

BB27_207:
	add.s32 	%r1199, %r314, 1536;
	setp.ge.s32	%p122, %r1199, %r247;
	@%p122 bra 	BB27_209;

	xor.b32  	%r1200, %r327, -2147483648;
	add.s32 	%r1201, %r314, %r342;
	add.s32 	%r1202, %r1201, 1536;
	mul.wide.s32 	%rd985, %r1202, 4;
	add.s64 	%rd986, %rd2, %rd985;
	st.global.u32 	[%rd986], %r1200;

BB27_209:
	add.s32 	%r1203, %r314, 1664;
	setp.ge.s32	%p123, %r1203, %r247;
	@%p123 bra 	BB27_211;

	xor.b32  	%r1204, %r328, -2147483648;
	add.s32 	%r1205, %r314, %r343;
	add.s32 	%r1206, %r1205, 1664;
	mul.wide.s32 	%rd988, %r1206, 4;
	add.s64 	%rd989, %rd2, %rd988;
	st.global.u32 	[%rd989], %r1204;

BB27_211:
	setp.gt.s32	%p5, %r248, 0;
	bar.sync 	0;
	@!%p5 bra 	BB27_213;
	bra.uni 	BB27_212;

BB27_212:
	mul.lo.s32 	%r1299, %r10, 15;
	cvt.s64.s32	%rd991, %r1299;
	add.s64 	%rd992, %rd991, %rd95;
	shl.b64 	%rd993, %rd992, 2;
	add.s64 	%rd990, %rd136, %rd993;
	// inline asm
	ld.global.nc.u32 %r1374, [%rd990];
	// inline asm

BB27_213:
	@%p88 bra 	BB27_215;

	mad.lo.s32 	%r1212, %r10, 15, 1;
	cvt.s64.s32	%rd995, %r1212;
	add.s64 	%rd996, %rd995, %rd95;
	shl.b64 	%rd997, %rd996, 2;
	add.s64 	%rd994, %rd136, %rd997;
	// inline asm
	ld.global.nc.u32 %r1375, [%rd994];
	// inline asm

BB27_215:
	@%p89 bra 	BB27_217;

	mad.lo.s32 	%r1215, %r10, 15, 2;
	cvt.s64.s32	%rd999, %r1215;
	add.s64 	%rd1000, %rd999, %rd95;
	shl.b64 	%rd1001, %rd1000, 2;
	add.s64 	%rd998, %rd136, %rd1001;
	// inline asm
	ld.global.nc.u32 %r1376, [%rd998];
	// inline asm

BB27_217:
	@%p90 bra 	BB27_219;

	mad.lo.s32 	%r1218, %r10, 15, 3;
	cvt.s64.s32	%rd1003, %r1218;
	add.s64 	%rd1004, %rd1003, %rd95;
	shl.b64 	%rd1005, %rd1004, 2;
	add.s64 	%rd1002, %rd136, %rd1005;
	// inline asm
	ld.global.nc.u32 %r1377, [%rd1002];
	// inline asm

BB27_219:
	@%p91 bra 	BB27_221;

	mad.lo.s32 	%r1221, %r10, 15, 4;
	cvt.s64.s32	%rd1007, %r1221;
	add.s64 	%rd1008, %rd1007, %rd95;
	shl.b64 	%rd1009, %rd1008, 2;
	add.s64 	%rd1006, %rd136, %rd1009;
	// inline asm
	ld.global.nc.u32 %r1378, [%rd1006];
	// inline asm

BB27_221:
	@%p92 bra 	BB27_223;

	mad.lo.s32 	%r1224, %r10, 15, 5;
	cvt.s64.s32	%rd1011, %r1224;
	add.s64 	%rd1012, %rd1011, %rd95;
	shl.b64 	%rd1013, %rd1012, 2;
	add.s64 	%rd1010, %rd136, %rd1013;
	// inline asm
	ld.global.nc.u32 %r1379, [%rd1010];
	// inline asm

BB27_223:
	@%p93 bra 	BB27_225;

	mad.lo.s32 	%r1227, %r10, 15, 6;
	cvt.s64.s32	%rd1015, %r1227;
	add.s64 	%rd1016, %rd1015, %rd95;
	shl.b64 	%rd1017, %rd1016, 2;
	add.s64 	%rd1014, %rd136, %rd1017;
	// inline asm
	ld.global.nc.u32 %r1380, [%rd1014];
	// inline asm

BB27_225:
	@%p94 bra 	BB27_227;

	mad.lo.s32 	%r1230, %r10, 15, 7;
	cvt.s64.s32	%rd1019, %r1230;
	add.s64 	%rd1020, %rd1019, %rd95;
	shl.b64 	%rd1021, %rd1020, 2;
	add.s64 	%rd1018, %rd136, %rd1021;
	// inline asm
	ld.global.nc.u32 %r1381, [%rd1018];
	// inline asm

BB27_227:
	@%p95 bra 	BB27_229;

	mad.lo.s32 	%r1233, %r10, 15, 8;
	cvt.s64.s32	%rd1023, %r1233;
	add.s64 	%rd1024, %rd1023, %rd95;
	shl.b64 	%rd1025, %rd1024, 2;
	add.s64 	%rd1022, %rd136, %rd1025;
	// inline asm
	ld.global.nc.u32 %r1382, [%rd1022];
	// inline asm

BB27_229:
	@%p96 bra 	BB27_231;

	mad.lo.s32 	%r1236, %r10, 15, 9;
	cvt.s64.s32	%rd1027, %r1236;
	add.s64 	%rd1028, %rd1027, %rd95;
	shl.b64 	%rd1029, %rd1028, 2;
	add.s64 	%rd1026, %rd136, %rd1029;
	// inline asm
	ld.global.nc.u32 %r1383, [%rd1026];
	// inline asm

BB27_231:
	@%p97 bra 	BB27_233;

	mad.lo.s32 	%r1239, %r10, 15, 10;
	cvt.s64.s32	%rd1031, %r1239;
	add.s64 	%rd1032, %rd1031, %rd95;
	shl.b64 	%rd1033, %rd1032, 2;
	add.s64 	%rd1030, %rd136, %rd1033;
	// inline asm
	ld.global.nc.u32 %r1384, [%rd1030];
	// inline asm

BB27_233:
	@%p98 bra 	BB27_235;

	mad.lo.s32 	%r1242, %r10, 15, 11;
	cvt.s64.s32	%rd1035, %r1242;
	add.s64 	%rd1036, %rd1035, %rd95;
	shl.b64 	%rd1037, %rd1036, 2;
	add.s64 	%rd1034, %rd136, %rd1037;
	// inline asm
	ld.global.nc.u32 %r1385, [%rd1034];
	// inline asm

BB27_235:
	@%p99 bra 	BB27_237;

	mad.lo.s32 	%r1245, %r10, 15, 12;
	cvt.s64.s32	%rd1039, %r1245;
	add.s64 	%rd1040, %rd1039, %rd95;
	shl.b64 	%rd1041, %rd1040, 2;
	add.s64 	%rd1038, %rd136, %rd1041;
	// inline asm
	ld.global.nc.u32 %r1386, [%rd1038];
	// inline asm

BB27_237:
	@%p100 bra 	BB27_239;

	mad.lo.s32 	%r1248, %r10, 15, 13;
	cvt.s64.s32	%rd1043, %r1248;
	add.s64 	%rd1044, %rd1043, %rd95;
	shl.b64 	%rd1045, %rd1044, 2;
	add.s64 	%rd1042, %rd136, %rd1045;
	// inline asm
	ld.global.nc.u32 %r1387, [%rd1042];
	// inline asm

BB27_239:
	@%p101 bra 	BB27_241;

	mad.lo.s32 	%r1251, %r10, 15, 14;
	cvt.s64.s32	%rd1047, %r1251;
	add.s64 	%rd1048, %rd1047, %rd95;
	shl.b64 	%rd1049, %rd1048, 2;
	add.s64 	%rd1046, %rd136, %rd1049;
	// inline asm
	ld.global.nc.u32 %r1388, [%rd1046];
	// inline asm

BB27_241:
	setp.lt.s32	%p6, %r10, %r247;
	bar.sync 	0;
	st.shared.u32 	[%rd119], %r1374;
	st.shared.u32 	[%rd120], %r1375;
	st.shared.u32 	[%rd121], %r1376;
	st.shared.u32 	[%rd122], %r1377;
	st.shared.u32 	[%rd123], %r1378;
	st.shared.u32 	[%rd124], %r1379;
	st.shared.u32 	[%rd125], %r1380;
	st.shared.u32 	[%rd126], %r1381;
	st.shared.u32 	[%rd127], %r1382;
	st.shared.u32 	[%rd128], %r1383;
	st.shared.u32 	[%rd129], %r1384;
	st.shared.u32 	[%rd130], %r1385;
	st.shared.u32 	[%rd131], %r1386;
	st.shared.u32 	[%rd132], %r1387;
	st.shared.u32 	[%rd133], %r1388;
	bar.sync 	0;
	ld.shared.u32 	%r375, [%rd914+584];
	ld.shared.u32 	%r376, [%rd914+1096];
	ld.shared.u32 	%r377, [%rd914+1608];
	ld.shared.u32 	%r378, [%rd914+2120];
	ld.shared.u32 	%r379, [%rd914+2632];
	ld.shared.u32 	%r380, [%rd914+3144];
	ld.shared.u32 	%r381, [%rd914+3656];
	ld.shared.u32 	%r382, [%rd914+4168];
	ld.shared.u32 	%r383, [%rd914+4680];
	ld.shared.u32 	%r384, [%rd914+5192];
	ld.shared.u32 	%r385, [%rd914+5704];
	ld.shared.u32 	%r386, [%rd914+6216];
	ld.shared.u32 	%r387, [%rd914+6728];
	ld.shared.u32 	%r388, [%rd914+7240];
	@!%p6 bra 	BB27_243;
	bra.uni 	BB27_242;

BB27_242:
	ld.shared.u32 	%r1253, [%rd914+72];
	add.s32 	%r1254, %r10, %r329;
	mul.wide.s32 	%rd1057, %r1254, 4;
	add.s64 	%rd1058, %rd1, %rd1057;
	st.global.u32 	[%rd1058], %r1253;

BB27_243:
	@%p110 bra 	BB27_245;

	add.s32 	%r1255, %r314, %r330;
	mul.wide.s32 	%rd1060, %r1255, 4;
	add.s64 	%rd1061, %rd1, %rd1060;
	st.global.u32 	[%rd1061], %r375;

BB27_245:
	@%p111 bra 	BB27_247;

	add.s32 	%r1257, %r314, %r331;
	add.s32 	%r1258, %r1257, 128;
	mul.wide.s32 	%rd1063, %r1258, 4;
	add.s64 	%rd1064, %rd1, %rd1063;
	st.global.u32 	[%rd1064], %r376;

BB27_247:
	@%p112 bra 	BB27_249;

	add.s32 	%r1260, %r314, %r332;
	add.s32 	%r1261, %r1260, 256;
	mul.wide.s32 	%rd1066, %r1261, 4;
	add.s64 	%rd1067, %rd1, %rd1066;
	st.global.u32 	[%rd1067], %r377;

BB27_249:
	@%p113 bra 	BB27_251;

	add.s32 	%r1263, %r314, %r333;
	add.s32 	%r1264, %r1263, 384;
	mul.wide.s32 	%rd1069, %r1264, 4;
	add.s64 	%rd1070, %rd1, %rd1069;
	st.global.u32 	[%rd1070], %r378;

BB27_251:
	@%p114 bra 	BB27_253;

	add.s32 	%r1266, %r314, %r334;
	add.s32 	%r1267, %r1266, 512;
	mul.wide.s32 	%rd1072, %r1267, 4;
	add.s64 	%rd1073, %rd1, %rd1072;
	st.global.u32 	[%rd1073], %r379;

BB27_253:
	@%p115 bra 	BB27_255;

	add.s32 	%r1269, %r314, %r335;
	add.s32 	%r1270, %r1269, 640;
	mul.wide.s32 	%rd1075, %r1270, 4;
	add.s64 	%rd1076, %rd1, %rd1075;
	st.global.u32 	[%rd1076], %r380;

BB27_255:
	@%p116 bra 	BB27_257;

	add.s32 	%r1272, %r314, %r336;
	add.s32 	%r1273, %r1272, 768;
	mul.wide.s32 	%rd1078, %r1273, 4;
	add.s64 	%rd1079, %rd1, %rd1078;
	st.global.u32 	[%rd1079], %r381;

BB27_257:
	@%p117 bra 	BB27_259;

	add.s32 	%r1275, %r314, %r337;
	add.s32 	%r1276, %r1275, 896;
	mul.wide.s32 	%rd1081, %r1276, 4;
	add.s64 	%rd1082, %rd1, %rd1081;
	st.global.u32 	[%rd1082], %r382;

BB27_259:
	@%p118 bra 	BB27_261;

	add.s32 	%r1278, %r314, %r338;
	add.s32 	%r1279, %r1278, 1024;
	mul.wide.s32 	%rd1084, %r1279, 4;
	add.s64 	%rd1085, %rd1, %rd1084;
	st.global.u32 	[%rd1085], %r383;

BB27_261:
	@%p119 bra 	BB27_263;

	add.s32 	%r1281, %r314, %r339;
	add.s32 	%r1282, %r1281, 1152;
	mul.wide.s32 	%rd1087, %r1282, 4;
	add.s64 	%rd1088, %rd1, %rd1087;
	st.global.u32 	[%rd1088], %r384;

BB27_263:
	@%p120 bra 	BB27_265;

	add.s32 	%r1284, %r314, %r340;
	add.s32 	%r1285, %r1284, 1280;
	mul.wide.s32 	%rd1090, %r1285, 4;
	add.s64 	%rd1091, %rd1, %rd1090;
	st.global.u32 	[%rd1091], %r385;

BB27_265:
	@%p121 bra 	BB27_267;

	add.s32 	%r1287, %r314, %r341;
	add.s32 	%r1288, %r1287, 1408;
	mul.wide.s32 	%rd1093, %r1288, 4;
	add.s64 	%rd1094, %rd1, %rd1093;
	st.global.u32 	[%rd1094], %r386;

BB27_267:
	@%p122 bra 	BB27_269;

	add.s32 	%r1290, %r314, %r342;
	add.s32 	%r1291, %r1290, 1536;
	mul.wide.s32 	%rd1096, %r1291, 4;
	add.s64 	%rd1097, %rd1, %rd1096;
	st.global.u32 	[%rd1097], %r387;

BB27_269:
	@%p123 bra 	BB27_271;

	add.s32 	%r1293, %r314, %r343;
	add.s32 	%r1294, %r1293, 1664;
	mul.wide.s32 	%rd1099, %r1294, 4;
	add.s64 	%rd1100, %rd1, %rd1099;
	st.global.u32 	[%rd1100], %r388;

BB27_271:
	ret;
}

.func  (.param .b64 func_retval0) __internal_trig_reduction_slowpathd(
	.param .b64 __internal_trig_reduction_slowpathd_param_0,
	.param .b64 __internal_trig_reduction_slowpathd_param_1
)
{
	.local .align 8 .b8 	__local_depot28[40];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<9>;
	.reg .b32 	%r<42>;
	.reg .f64 	%fd<5>;
	.reg .b64 	%rd<101>;


	mov.u64 	%rd100, __local_depot28;
	cvta.local.u64 	%SP, %rd100;
	ld.param.f64 	%fd4, [__internal_trig_reduction_slowpathd_param_0];
	ld.param.u64 	%rd37, [__internal_trig_reduction_slowpathd_param_1];
	add.u64 	%rd38, %SP, 0;
	cvta.to.local.u64 	%rd1, %rd38;
	{
	.reg .b32 %temp; 
	mov.b64 	{%temp, %r1}, %fd4;
	}
	and.b32  	%r40, %r1, -2147483648;
	shr.u32 	%r3, %r1, 20;
	bfe.u32 	%r4, %r1, 20, 11;
	setp.eq.s32	%p1, %r4, 2047;
	@%p1 bra 	BB28_13;

	add.s32 	%r16, %r4, -1024;
	shr.u32 	%r17, %r16, 6;
	mov.u32 	%r18, 16;
	sub.s32 	%r5, %r18, %r17;
	mov.u32 	%r19, 19;
	sub.s32 	%r20, %r19, %r17;
	mov.u32 	%r21, 18;
	min.s32 	%r6, %r21, %r20;
	setp.gt.s32	%p2, %r5, %r6;
	mov.u64 	%rd94, 0;
	mov.u64 	%rd93, %rd1;
	@%p2 bra 	BB28_4;

	mov.b64 	 %rd41, %fd4;
	shl.b64 	%rd42, %rd41, 11;
	or.b64  	%rd3, %rd42, -9223372036854775808;
	add.s32 	%r7, %r5, -1;
	mov.u64 	%rd92, %rd1;
	bfe.u32 	%r22, %r1, 20, 11;
	add.s32 	%r23, %r22, -1024;
	shr.u32 	%r24, %r23, 6;
	neg.s32 	%r25, %r24;
	mul.wide.s32 	%rd43, %r25, 8;
	mov.u64 	%rd44, __cudart_i2opi_d;
	add.s64 	%rd45, %rd43, %rd44;
	add.s64 	%rd90, %rd45, 120;
	mov.u64 	%rd94, 0;
	mov.u64 	%rd91, %rd1;
	mov.u32 	%r39, %r7;

BB28_3:
	.pragma "nounroll";
	mov.u32 	%r8, %r39;
	mov.u64 	%rd7, %rd91;
	ld.const.u64 	%rd48, [%rd90];
	// inline asm
	{
	.reg .u32 r0, r1, r2, r3, alo, ahi, blo, bhi, clo, chi;
	mov.b64         {alo,ahi}, %rd48;    
	mov.b64         {blo,bhi}, %rd3;    
	mov.b64         {clo,chi}, %rd94;    
	mad.lo.cc.u32   r0, alo, blo, clo;
	madc.hi.cc.u32  r1, alo, blo, chi;
	madc.hi.u32     r2, alo, bhi,   0;
	mad.lo.cc.u32   r1, alo, bhi,  r1;
	madc.hi.cc.u32  r2, ahi, blo,  r2;
	madc.hi.u32     r3, ahi, bhi,   0;
	mad.lo.cc.u32   r1, ahi, blo,  r1;
	madc.lo.cc.u32  r2, ahi, bhi,  r2;
	addc.u32        r3,  r3,   0;     
	mov.b64         %rd46, {r0,r1};      
	mov.b64         %rd94, {r2,r3};      
	}
	// inline asm
	st.local.u64 	[%rd92], %rd46;
	add.s32 	%r9, %r8, 1;
	sub.s32 	%r26, %r9, %r7;
	mul.wide.s32 	%rd51, %r26, 8;
	add.s64 	%rd92, %rd1, %rd51;
	add.s64 	%rd13, %rd7, 8;
	mov.u64 	%rd93, %rd13;
	add.s64 	%rd90, %rd90, 8;
	setp.lt.s32	%p3, %r9, %r6;
	mov.u64 	%rd91, %rd13;
	mov.u32 	%r39, %r9;
	@%p3 bra 	BB28_3;

BB28_4:
	st.local.u64 	[%rd93], %rd94;
	ld.local.u64 	%rd95, [%rd1+16];
	ld.local.u64 	%rd96, [%rd1+24];
	and.b32  	%r10, %r3, 63;
	setp.eq.s32	%p4, %r10, 0;
	@%p4 bra 	BB28_6;

	mov.u32 	%r27, 64;
	sub.s32 	%r28, %r27, %r10;
	shl.b64 	%rd52, %rd96, %r10;
	shr.u64 	%rd53, %rd95, %r28;
	or.b64  	%rd96, %rd52, %rd53;
	shl.b64 	%rd54, %rd95, %r10;
	ld.local.u64 	%rd55, [%rd1+8];
	shr.u64 	%rd56, %rd55, %r28;
	or.b64  	%rd95, %rd56, %rd54;

BB28_6:
	cvta.to.local.u64 	%rd57, %rd37;
	shr.u64 	%rd58, %rd96, 62;
	cvt.u32.u64	%r29, %rd58;
	shr.u64 	%rd59, %rd95, 62;
	shl.b64 	%rd60, %rd96, 2;
	or.b64  	%rd98, %rd60, %rd59;
	shl.b64 	%rd97, %rd95, 2;
	shr.u64 	%rd61, %rd96, 61;
	cvt.u32.u64	%r30, %rd61;
	and.b32  	%r31, %r30, 1;
	add.s32 	%r32, %r31, %r29;
	neg.s32 	%r33, %r32;
	setp.eq.s32	%p5, %r40, 0;
	selp.b32	%r34, %r32, %r33, %p5;
	st.local.u32 	[%rd57], %r34;
	setp.eq.s32	%p6, %r31, 0;
	@%p6 bra 	BB28_8;

	mov.u64 	%rd65, 0;
	// inline asm
	{
	.reg .u32 r0, r1, r2, r3, a0, a1, a2, a3, b0, b1, b2, b3;
	mov.b64         {a0,a1}, %rd65;
	mov.b64         {a2,a3}, %rd65;
	mov.b64         {b0,b1}, %rd97;
	mov.b64         {b2,b3}, %rd98;
	sub.cc.u32      r0, a0, b0; 
	subc.cc.u32     r1, a1, b1; 
	subc.cc.u32     r2, a2, b2; 
	subc.u32        r3, a3, b3; 
	mov.b64         %rd97, {r0,r1};
	mov.b64         %rd98, {r2,r3};
	}
	// inline asm
	xor.b32  	%r40, %r40, -2147483648;

BB28_8:
	clz.b64 	%r41, %rd98;
	setp.eq.s32	%p7, %r41, 0;
	@%p7 bra 	BB28_10;

	shl.b64 	%rd68, %rd98, %r41;
	mov.u32 	%r35, 64;
	sub.s32 	%r36, %r35, %r41;
	shr.u64 	%rd69, %rd97, %r36;
	or.b64  	%rd98, %rd69, %rd68;

BB28_10:
	mov.u64 	%rd73, -3958705157555305931;
	// inline asm
	{
	.reg .u32 r0, r1, r2, r3, alo, ahi, blo, bhi;
	mov.b64         {alo,ahi}, %rd98;   
	mov.b64         {blo,bhi}, %rd73;   
	mul.lo.u32      r0, alo, blo;    
	mul.hi.u32      r1, alo, blo;    
	mad.lo.cc.u32   r1, alo, bhi, r1;
	madc.hi.u32     r2, alo, bhi,  0;
	mad.lo.cc.u32   r1, ahi, blo, r1;
	madc.hi.cc.u32  r2, ahi, blo, r2;
	madc.hi.u32     r3, ahi, bhi,  0;
	mad.lo.cc.u32   r2, ahi, bhi, r2;
	addc.u32        r3, r3,  0;      
	mov.b64         %rd70, {r0,r1};     
	mov.b64         %rd99, {r2,r3};     
	}
	// inline asm
	setp.lt.s64	%p8, %rd99, 1;
	@%p8 bra 	BB28_12;

	// inline asm
	{
	.reg .u32 r0, r1, r2, r3, a0, a1, a2, a3, b0, b1, b2, b3;
	mov.b64         {a0,a1}, %rd70;
	mov.b64         {a2,a3}, %rd99;
	mov.b64         {b0,b1}, %rd70;
	mov.b64         {b2,b3}, %rd99;
	add.cc.u32      r0, a0, b0; 
	addc.cc.u32     r1, a1, b1; 
	addc.cc.u32     r2, a2, b2; 
	addc.u32        r3, a3, b3; 
	mov.b64         %rd74, {r0,r1};
	mov.b64         %rd99, {r2,r3};
	}
	// inline asm
	add.s32 	%r41, %r41, 1;

BB28_12:
	cvt.u64.u32	%rd80, %r40;
	shl.b64 	%rd81, %rd80, 32;
	mov.u32 	%r37, 1022;
	sub.s32 	%r38, %r37, %r41;
	cvt.u64.u32	%rd82, %r38;
	shl.b64 	%rd83, %rd82, 52;
	add.s64 	%rd84, %rd99, 1;
	shr.u64 	%rd85, %rd84, 10;
	add.s64 	%rd86, %rd85, 1;
	shr.u64 	%rd87, %rd86, 1;
	add.s64 	%rd88, %rd87, %rd83;
	or.b64  	%rd89, %rd88, %rd81;
	mov.b64 	 %fd4, %rd89;

BB28_13:
	st.param.f64	[func_retval0+0], %fd4;
	ret;
}


