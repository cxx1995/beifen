# 1 "gpu_setup.cu"
#pragma GCC diagnostic ignored "-Wunused-local-typedefs"
# 1
#pragma GCC diagnostic push
# 1
#pragma GCC diagnostic ignored "-Wunused-variable"
# 1
#pragma GCC diagnostic ignored "-Wunused-function"
# 1
static char __nv_inited_managed_rt = 0; static void **__nv_fatbinhandle_for_managed_rt; static void __nv_save_fatbinhandle_for_managed_rt(void **in){__nv_fatbinhandle_for_managed_rt = in;} static char __nv_init_managed_rt_with_module(void **); static inline void __nv_init_managed_rt(void) { __nv_inited_managed_rt = (__nv_inited_managed_rt ? __nv_inited_managed_rt                 : __nv_init_managed_rt_with_module(__nv_fatbinhandle_for_managed_rt));}
# 1
#pragma GCC diagnostic pop
# 1
#pragma GCC diagnostic ignored "-Wunused-variable"

# 1
#define __nv_is_extended_device_lambda_closure_type(X) false
#define __nv_is_extended_host_device_lambda_closure_type(X) false

# 1
# 56 "/usr/local/cuda-8.0/include/cuda_runtime.h"
#pragma GCC diagnostic push
# 59
#pragma GCC diagnostic ignored "-Wunused-function"
# 61 "/usr/local/cuda-8.0/include/device_types.h"
#if 0
# 61
enum cudaRoundMode { 
# 63
cudaRoundNearest, 
# 64
cudaRoundZero, 
# 65
cudaRoundPosInf, 
# 66
cudaRoundMinInf
# 67
}; 
#endif
# 147 "/usr/lib/gcc/ppc64le-redhat-linux/4.8.5/include/stddef.h" 3
typedef long ptrdiff_t; 
# 212
typedef unsigned long size_t; 
#include "crt/host_runtime.h"
# 156 "/usr/local/cuda-8.0/include/driver_types.h"
#if 0
# 156
enum cudaError { 
# 163
cudaSuccess, 
# 169
cudaErrorMissingConfiguration, 
# 175
cudaErrorMemoryAllocation, 
# 181
cudaErrorInitializationError, 
# 191
cudaErrorLaunchFailure, 
# 200
cudaErrorPriorLaunchFailure, 
# 210
cudaErrorLaunchTimeout, 
# 219
cudaErrorLaunchOutOfResources, 
# 225
cudaErrorInvalidDeviceFunction, 
# 234
cudaErrorInvalidConfiguration, 
# 240
cudaErrorInvalidDevice, 
# 246
cudaErrorInvalidValue, 
# 252
cudaErrorInvalidPitchValue, 
# 258
cudaErrorInvalidSymbol, 
# 263
cudaErrorMapBufferObjectFailed, 
# 268
cudaErrorUnmapBufferObjectFailed, 
# 274
cudaErrorInvalidHostPointer, 
# 280
cudaErrorInvalidDevicePointer, 
# 286
cudaErrorInvalidTexture, 
# 292
cudaErrorInvalidTextureBinding, 
# 299
cudaErrorInvalidChannelDescriptor, 
# 305
cudaErrorInvalidMemcpyDirection, 
# 315
cudaErrorAddressOfConstant, 
# 324
cudaErrorTextureFetchFailed, 
# 333
cudaErrorTextureNotBound, 
# 342
cudaErrorSynchronizationError, 
# 348
cudaErrorInvalidFilterSetting, 
# 354
cudaErrorInvalidNormSetting, 
# 362
cudaErrorMixedDeviceExecution, 
# 369
cudaErrorCudartUnloading, 
# 374
cudaErrorUnknown, 
# 382
cudaErrorNotYetImplemented, 
# 391
cudaErrorMemoryValueTooLarge, 
# 398
cudaErrorInvalidResourceHandle, 
# 406
cudaErrorNotReady, 
# 413
cudaErrorInsufficientDriver, 
# 426
cudaErrorSetOnActiveProcess, 
# 432
cudaErrorInvalidSurface, 
# 438
cudaErrorNoDevice, 
# 444
cudaErrorECCUncorrectable, 
# 449
cudaErrorSharedObjectSymbolNotFound, 
# 454
cudaErrorSharedObjectInitFailed, 
# 460
cudaErrorUnsupportedLimit, 
# 466
cudaErrorDuplicateVariableName, 
# 472
cudaErrorDuplicateTextureName, 
# 478
cudaErrorDuplicateSurfaceName, 
# 488
cudaErrorDevicesUnavailable, 
# 493
cudaErrorInvalidKernelImage, 
# 501
cudaErrorNoKernelImageForDevice, 
# 514
cudaErrorIncompatibleDriverContext, 
# 521
cudaErrorPeerAccessAlreadyEnabled, 
# 528
cudaErrorPeerAccessNotEnabled, 
# 534
cudaErrorDeviceAlreadyInUse = 54, 
# 541
cudaErrorProfilerDisabled, 
# 549
cudaErrorProfilerNotInitialized, 
# 556
cudaErrorProfilerAlreadyStarted, 
# 563
cudaErrorProfilerAlreadyStopped, 
# 571
cudaErrorAssert, 
# 578
cudaErrorTooManyPeers, 
# 584
cudaErrorHostMemoryAlreadyRegistered, 
# 590
cudaErrorHostMemoryNotRegistered, 
# 595
cudaErrorOperatingSystem, 
# 601
cudaErrorPeerAccessUnsupported, 
# 608
cudaErrorLaunchMaxDepthExceeded, 
# 616
cudaErrorLaunchFileScopedTex, 
# 624
cudaErrorLaunchFileScopedSurf, 
# 639
cudaErrorSyncDepthExceeded, 
# 651
cudaErrorLaunchPendingCountExceeded, 
# 656
cudaErrorNotPermitted, 
# 662
cudaErrorNotSupported, 
# 671
cudaErrorHardwareStackError, 
# 679
cudaErrorIllegalInstruction, 
# 688
cudaErrorMisalignedAddress, 
# 699
cudaErrorInvalidAddressSpace, 
# 707
cudaErrorInvalidPc, 
# 715
cudaErrorIllegalAddress, 
# 721
cudaErrorInvalidPtx, 
# 726
cudaErrorInvalidGraphicsContext, 
# 732
cudaErrorNvlinkUncorrectable, 
# 737
cudaErrorStartupFailure = 127, 
# 745
cudaErrorApiFailureBase = 10000
# 746
}; 
#endif
# 751 "/usr/local/cuda-8.0/include/driver_types.h"
#if 0
# 751
enum cudaChannelFormatKind { 
# 753
cudaChannelFormatKindSigned, 
# 754
cudaChannelFormatKindUnsigned, 
# 755
cudaChannelFormatKindFloat, 
# 756
cudaChannelFormatKindNone
# 757
}; 
#endif
# 762 "/usr/local/cuda-8.0/include/driver_types.h"
#if 0
# 762
struct cudaChannelFormatDesc { 
# 764
int x; 
# 765
int y; 
# 766
int z; 
# 767
int w; 
# 768
cudaChannelFormatKind f; 
# 769
}; 
#endif
# 774 "/usr/local/cuda-8.0/include/driver_types.h"
typedef struct cudaArray *cudaArray_t; 
# 779
typedef const cudaArray *cudaArray_const_t; 
# 781
struct cudaArray; 
# 786
typedef struct cudaMipmappedArray *cudaMipmappedArray_t; 
# 791
typedef const cudaMipmappedArray *cudaMipmappedArray_const_t; 
# 793
struct cudaMipmappedArray; 
# 798
#if 0
# 798
enum cudaMemoryType { 
# 800
cudaMemoryTypeHost = 1, 
# 801
cudaMemoryTypeDevice
# 802
}; 
#endif
# 807 "/usr/local/cuda-8.0/include/driver_types.h"
#if 0
# 807
enum cudaMemcpyKind { 
# 809
cudaMemcpyHostToHost, 
# 810
cudaMemcpyHostToDevice, 
# 811
cudaMemcpyDeviceToHost, 
# 812
cudaMemcpyDeviceToDevice, 
# 813
cudaMemcpyDefault
# 814
}; 
#endif
# 821 "/usr/local/cuda-8.0/include/driver_types.h"
#if 0
# 821
struct cudaPitchedPtr { 
# 823
void *ptr; 
# 824
size_t pitch; 
# 825
size_t xsize; 
# 826
size_t ysize; 
# 827
}; 
#endif
# 834 "/usr/local/cuda-8.0/include/driver_types.h"
#if 0
# 834
struct cudaExtent { 
# 836
size_t width; 
# 837
size_t height; 
# 838
size_t depth; 
# 839
}; 
#endif
# 846 "/usr/local/cuda-8.0/include/driver_types.h"
#if 0
# 846
struct cudaPos { 
# 848
size_t x; 
# 849
size_t y; 
# 850
size_t z; 
# 851
}; 
#endif
# 856 "/usr/local/cuda-8.0/include/driver_types.h"
#if 0
# 856
struct cudaMemcpy3DParms { 
# 858
cudaArray_t srcArray; 
# 859
cudaPos srcPos; 
# 860
cudaPitchedPtr srcPtr; 
# 862
cudaArray_t dstArray; 
# 863
cudaPos dstPos; 
# 864
cudaPitchedPtr dstPtr; 
# 866
cudaExtent extent; 
# 867
cudaMemcpyKind kind; __pad__(volatile char:8;)__pad__(volatile char:8;)__pad__(volatile char:8;)__pad__(volatile char:8;)
# 868
}; 
#endif
# 873 "/usr/local/cuda-8.0/include/driver_types.h"
#if 0
# 873
struct cudaMemcpy3DPeerParms { 
# 875
cudaArray_t srcArray; 
# 876
cudaPos srcPos; 
# 877
cudaPitchedPtr srcPtr; 
# 878
int srcDevice; 
# 880
cudaArray_t dstArray; 
# 881
cudaPos dstPos; 
# 882
cudaPitchedPtr dstPtr; 
# 883
int dstDevice; 
# 885
cudaExtent extent; 
# 886
}; 
#endif
# 891 "/usr/local/cuda-8.0/include/driver_types.h"
struct cudaGraphicsResource; 
# 896
#if 0
# 896
enum cudaGraphicsRegisterFlags { 
# 898
cudaGraphicsRegisterFlagsNone, 
# 899
cudaGraphicsRegisterFlagsReadOnly, 
# 900
cudaGraphicsRegisterFlagsWriteDiscard, 
# 901
cudaGraphicsRegisterFlagsSurfaceLoadStore = 4, 
# 902
cudaGraphicsRegisterFlagsTextureGather = 8
# 903
}; 
#endif
# 908 "/usr/local/cuda-8.0/include/driver_types.h"
#if 0
# 908
enum cudaGraphicsMapFlags { 
# 910
cudaGraphicsMapFlagsNone, 
# 911
cudaGraphicsMapFlagsReadOnly, 
# 912
cudaGraphicsMapFlagsWriteDiscard
# 913
}; 
#endif
# 918 "/usr/local/cuda-8.0/include/driver_types.h"
#if 0
# 918
enum cudaGraphicsCubeFace { 
# 920
cudaGraphicsCubeFacePositiveX, 
# 921
cudaGraphicsCubeFaceNegativeX, 
# 922
cudaGraphicsCubeFacePositiveY, 
# 923
cudaGraphicsCubeFaceNegativeY, 
# 924
cudaGraphicsCubeFacePositiveZ, 
# 925
cudaGraphicsCubeFaceNegativeZ
# 926
}; 
#endif
# 931 "/usr/local/cuda-8.0/include/driver_types.h"
#if 0
# 931
enum cudaResourceType { 
# 933
cudaResourceTypeArray, 
# 934
cudaResourceTypeMipmappedArray, 
# 935
cudaResourceTypeLinear, 
# 936
cudaResourceTypePitch2D
# 937
}; 
#endif
# 942 "/usr/local/cuda-8.0/include/driver_types.h"
#if 0
# 942
enum cudaResourceViewFormat { 
# 944
cudaResViewFormatNone, 
# 945
cudaResViewFormatUnsignedChar1, 
# 946
cudaResViewFormatUnsignedChar2, 
# 947
cudaResViewFormatUnsignedChar4, 
# 948
cudaResViewFormatSignedChar1, 
# 949
cudaResViewFormatSignedChar2, 
# 950
cudaResViewFormatSignedChar4, 
# 951
cudaResViewFormatUnsignedShort1, 
# 952
cudaResViewFormatUnsignedShort2, 
# 953
cudaResViewFormatUnsignedShort4, 
# 954
cudaResViewFormatSignedShort1, 
# 955
cudaResViewFormatSignedShort2, 
# 956
cudaResViewFormatSignedShort4, 
# 957
cudaResViewFormatUnsignedInt1, 
# 958
cudaResViewFormatUnsignedInt2, 
# 959
cudaResViewFormatUnsignedInt4, 
# 960
cudaResViewFormatSignedInt1, 
# 961
cudaResViewFormatSignedInt2, 
# 962
cudaResViewFormatSignedInt4, 
# 963
cudaResViewFormatHalf1, 
# 964
cudaResViewFormatHalf2, 
# 965
cudaResViewFormatHalf4, 
# 966
cudaResViewFormatFloat1, 
# 967
cudaResViewFormatFloat2, 
# 968
cudaResViewFormatFloat4, 
# 969
cudaResViewFormatUnsignedBlockCompressed1, 
# 970
cudaResViewFormatUnsignedBlockCompressed2, 
# 971
cudaResViewFormatUnsignedBlockCompressed3, 
# 972
cudaResViewFormatUnsignedBlockCompressed4, 
# 973
cudaResViewFormatSignedBlockCompressed4, 
# 974
cudaResViewFormatUnsignedBlockCompressed5, 
# 975
cudaResViewFormatSignedBlockCompressed5, 
# 976
cudaResViewFormatUnsignedBlockCompressed6H, 
# 977
cudaResViewFormatSignedBlockCompressed6H, 
# 978
cudaResViewFormatUnsignedBlockCompressed7
# 979
}; 
#endif
# 984 "/usr/local/cuda-8.0/include/driver_types.h"
#if 0
# 984
struct cudaResourceDesc { 
# 985
cudaResourceType resType; 
# 987
union { 
# 988
struct { 
# 989
cudaArray_t array; 
# 990
} array; 
# 991
struct { 
# 992
cudaMipmappedArray_t mipmap; 
# 993
} mipmap; 
# 994
struct { 
# 995
void *devPtr; 
# 996
cudaChannelFormatDesc desc; 
# 997
size_t sizeInBytes; 
# 998
} linear; 
# 999
struct { 
# 1000
void *devPtr; 
# 1001
cudaChannelFormatDesc desc; 
# 1002
size_t width; 
# 1003
size_t height; 
# 1004
size_t pitchInBytes; 
# 1005
} pitch2D; 
# 1006
} res; 
# 1007
}; 
#endif
# 1012 "/usr/local/cuda-8.0/include/driver_types.h"
#if 0
# 1012
struct cudaResourceViewDesc { 
# 1014
cudaResourceViewFormat format; 
# 1015
size_t width; 
# 1016
size_t height; 
# 1017
size_t depth; 
# 1018
unsigned firstMipmapLevel; 
# 1019
unsigned lastMipmapLevel; 
# 1020
unsigned firstLayer; 
# 1021
unsigned lastLayer; 
# 1022
}; 
#endif
# 1027 "/usr/local/cuda-8.0/include/driver_types.h"
#if 0
# 1027
struct cudaPointerAttributes { 
# 1033
cudaMemoryType memoryType; 
# 1044
int device; 
# 1050
void *devicePointer; 
# 1056
void *hostPointer; 
# 1061
int isManaged; __pad__(volatile char:8;)__pad__(volatile char:8;)__pad__(volatile char:8;)__pad__(volatile char:8;)
# 1062
}; 
#endif
# 1067 "/usr/local/cuda-8.0/include/driver_types.h"
#if 0
# 1067
struct cudaFuncAttributes { 
# 1074
size_t sharedSizeBytes; 
# 1080
size_t constSizeBytes; 
# 1085
size_t localSizeBytes; 
# 1092
int maxThreadsPerBlock; 
# 1097
int numRegs; 
# 1104
int ptxVersion; 
# 1111
int binaryVersion; 
# 1117
int cacheModeCA; 
# 1118
}; 
#endif
# 1123 "/usr/local/cuda-8.0/include/driver_types.h"
#if 0
# 1123
enum cudaFuncCache { 
# 1125
cudaFuncCachePreferNone, 
# 1126
cudaFuncCachePreferShared, 
# 1127
cudaFuncCachePreferL1, 
# 1128
cudaFuncCachePreferEqual
# 1129
}; 
#endif
# 1135 "/usr/local/cuda-8.0/include/driver_types.h"
#if 0
# 1135
enum cudaSharedMemConfig { 
# 1137
cudaSharedMemBankSizeDefault, 
# 1138
cudaSharedMemBankSizeFourByte, 
# 1139
cudaSharedMemBankSizeEightByte
# 1140
}; 
#endif
# 1145 "/usr/local/cuda-8.0/include/driver_types.h"
#if 0
# 1145
enum cudaComputeMode { 
# 1147
cudaComputeModeDefault, 
# 1148
cudaComputeModeExclusive, 
# 1149
cudaComputeModeProhibited, 
# 1150
cudaComputeModeExclusiveProcess
# 1151
}; 
#endif
# 1156 "/usr/local/cuda-8.0/include/driver_types.h"
#if 0
# 1156
enum cudaLimit { 
# 1158
cudaLimitStackSize, 
# 1159
cudaLimitPrintfFifoSize, 
# 1160
cudaLimitMallocHeapSize, 
# 1161
cudaLimitDevRuntimeSyncDepth, 
# 1162
cudaLimitDevRuntimePendingLaunchCount
# 1163
}; 
#endif
# 1168 "/usr/local/cuda-8.0/include/driver_types.h"
#if 0
# 1168
enum cudaMemoryAdvise { 
# 1170
cudaMemAdviseSetReadMostly = 1, 
# 1171
cudaMemAdviseUnsetReadMostly, 
# 1172
cudaMemAdviseSetPreferredLocation, 
# 1173
cudaMemAdviseUnsetPreferredLocation, 
# 1174
cudaMemAdviseSetAccessedBy, 
# 1175
cudaMemAdviseUnsetAccessedBy
# 1176
}; 
#endif
# 1181 "/usr/local/cuda-8.0/include/driver_types.h"
#if 0
# 1181
enum cudaMemRangeAttribute { 
# 1183
cudaMemRangeAttributeReadMostly = 1, 
# 1184
cudaMemRangeAttributePreferredLocation, 
# 1185
cudaMemRangeAttributeAccessedBy, 
# 1186
cudaMemRangeAttributeLastPrefetchLocation
# 1187
}; 
#endif
# 1192 "/usr/local/cuda-8.0/include/driver_types.h"
#if 0
# 1192
enum cudaOutputMode { 
# 1194
cudaKeyValuePair, 
# 1195
cudaCSV
# 1196
}; 
#endif
# 1201 "/usr/local/cuda-8.0/include/driver_types.h"
#if 0
# 1201
enum cudaDeviceAttr { 
# 1203
cudaDevAttrMaxThreadsPerBlock = 1, 
# 1204
cudaDevAttrMaxBlockDimX, 
# 1205
cudaDevAttrMaxBlockDimY, 
# 1206
cudaDevAttrMaxBlockDimZ, 
# 1207
cudaDevAttrMaxGridDimX, 
# 1208
cudaDevAttrMaxGridDimY, 
# 1209
cudaDevAttrMaxGridDimZ, 
# 1210
cudaDevAttrMaxSharedMemoryPerBlock, 
# 1211
cudaDevAttrTotalConstantMemory, 
# 1212
cudaDevAttrWarpSize, 
# 1213
cudaDevAttrMaxPitch, 
# 1214
cudaDevAttrMaxRegistersPerBlock, 
# 1215
cudaDevAttrClockRate, 
# 1216
cudaDevAttrTextureAlignment, 
# 1217
cudaDevAttrGpuOverlap, 
# 1218
cudaDevAttrMultiProcessorCount, 
# 1219
cudaDevAttrKernelExecTimeout, 
# 1220
cudaDevAttrIntegrated, 
# 1221
cudaDevAttrCanMapHostMemory, 
# 1222
cudaDevAttrComputeMode, 
# 1223
cudaDevAttrMaxTexture1DWidth, 
# 1224
cudaDevAttrMaxTexture2DWidth, 
# 1225
cudaDevAttrMaxTexture2DHeight, 
# 1226
cudaDevAttrMaxTexture3DWidth, 
# 1227
cudaDevAttrMaxTexture3DHeight, 
# 1228
cudaDevAttrMaxTexture3DDepth, 
# 1229
cudaDevAttrMaxTexture2DLayeredWidth, 
# 1230
cudaDevAttrMaxTexture2DLayeredHeight, 
# 1231
cudaDevAttrMaxTexture2DLayeredLayers, 
# 1232
cudaDevAttrSurfaceAlignment, 
# 1233
cudaDevAttrConcurrentKernels, 
# 1234
cudaDevAttrEccEnabled, 
# 1235
cudaDevAttrPciBusId, 
# 1236
cudaDevAttrPciDeviceId, 
# 1237
cudaDevAttrTccDriver, 
# 1238
cudaDevAttrMemoryClockRate, 
# 1239
cudaDevAttrGlobalMemoryBusWidth, 
# 1240
cudaDevAttrL2CacheSize, 
# 1241
cudaDevAttrMaxThreadsPerMultiProcessor, 
# 1242
cudaDevAttrAsyncEngineCount, 
# 1243
cudaDevAttrUnifiedAddressing, 
# 1244
cudaDevAttrMaxTexture1DLayeredWidth, 
# 1245
cudaDevAttrMaxTexture1DLayeredLayers, 
# 1246
cudaDevAttrMaxTexture2DGatherWidth = 45, 
# 1247
cudaDevAttrMaxTexture2DGatherHeight, 
# 1248
cudaDevAttrMaxTexture3DWidthAlt, 
# 1249
cudaDevAttrMaxTexture3DHeightAlt, 
# 1250
cudaDevAttrMaxTexture3DDepthAlt, 
# 1251
cudaDevAttrPciDomainId, 
# 1252
cudaDevAttrTexturePitchAlignment, 
# 1253
cudaDevAttrMaxTextureCubemapWidth, 
# 1254
cudaDevAttrMaxTextureCubemapLayeredWidth, 
# 1255
cudaDevAttrMaxTextureCubemapLayeredLayers, 
# 1256
cudaDevAttrMaxSurface1DWidth, 
# 1257
cudaDevAttrMaxSurface2DWidth, 
# 1258
cudaDevAttrMaxSurface2DHeight, 
# 1259
cudaDevAttrMaxSurface3DWidth, 
# 1260
cudaDevAttrMaxSurface3DHeight, 
# 1261
cudaDevAttrMaxSurface3DDepth, 
# 1262
cudaDevAttrMaxSurface1DLayeredWidth, 
# 1263
cudaDevAttrMaxSurface1DLayeredLayers, 
# 1264
cudaDevAttrMaxSurface2DLayeredWidth, 
# 1265
cudaDevAttrMaxSurface2DLayeredHeight, 
# 1266
cudaDevAttrMaxSurface2DLayeredLayers, 
# 1267
cudaDevAttrMaxSurfaceCubemapWidth, 
# 1268
cudaDevAttrMaxSurfaceCubemapLayeredWidth, 
# 1269
cudaDevAttrMaxSurfaceCubemapLayeredLayers, 
# 1270
cudaDevAttrMaxTexture1DLinearWidth, 
# 1271
cudaDevAttrMaxTexture2DLinearWidth, 
# 1272
cudaDevAttrMaxTexture2DLinearHeight, 
# 1273
cudaDevAttrMaxTexture2DLinearPitch, 
# 1274
cudaDevAttrMaxTexture2DMipmappedWidth, 
# 1275
cudaDevAttrMaxTexture2DMipmappedHeight, 
# 1276
cudaDevAttrComputeCapabilityMajor, 
# 1277
cudaDevAttrComputeCapabilityMinor, 
# 1278
cudaDevAttrMaxTexture1DMipmappedWidth, 
# 1279
cudaDevAttrStreamPrioritiesSupported, 
# 1280
cudaDevAttrGlobalL1CacheSupported, 
# 1281
cudaDevAttrLocalL1CacheSupported, 
# 1282
cudaDevAttrMaxSharedMemoryPerMultiprocessor, 
# 1283
cudaDevAttrMaxRegistersPerMultiprocessor, 
# 1284
cudaDevAttrManagedMemory, 
# 1285
cudaDevAttrIsMultiGpuBoard, 
# 1286
cudaDevAttrMultiGpuBoardGroupID, 
# 1287
cudaDevAttrHostNativeAtomicSupported, 
# 1288
cudaDevAttrSingleToDoublePrecisionPerfRatio, 
# 1289
cudaDevAttrPageableMemoryAccess, 
# 1290
cudaDevAttrConcurrentManagedAccess, 
# 1291
cudaDevAttrComputePreemptionSupported, 
# 1292
cudaDevAttrCanUseHostPointerForRegisteredMem
# 1293
}; 
#endif
# 1299 "/usr/local/cuda-8.0/include/driver_types.h"
#if 0
# 1299
enum cudaDeviceP2PAttr { 
# 1300
cudaDevP2PAttrPerformanceRank = 1, 
# 1301
cudaDevP2PAttrAccessSupported, 
# 1302
cudaDevP2PAttrNativeAtomicSupported
# 1303
}; 
#endif
# 1307 "/usr/local/cuda-8.0/include/driver_types.h"
#if 0
# 1307
struct cudaDeviceProp { 
# 1309
char name[256]; 
# 1310
size_t totalGlobalMem; 
# 1311
size_t sharedMemPerBlock; 
# 1312
int regsPerBlock; 
# 1313
int warpSize; 
# 1314
size_t memPitch; 
# 1315
int maxThreadsPerBlock; 
# 1316
int maxThreadsDim[3]; 
# 1317
int maxGridSize[3]; 
# 1318
int clockRate; 
# 1319
size_t totalConstMem; 
# 1320
int major; 
# 1321
int minor; 
# 1322
size_t textureAlignment; 
# 1323
size_t texturePitchAlignment; 
# 1324
int deviceOverlap; 
# 1325
int multiProcessorCount; 
# 1326
int kernelExecTimeoutEnabled; 
# 1327
int integrated; 
# 1328
int canMapHostMemory; 
# 1329
int computeMode; 
# 1330
int maxTexture1D; 
# 1331
int maxTexture1DMipmap; 
# 1332
int maxTexture1DLinear; 
# 1333
int maxTexture2D[2]; 
# 1334
int maxTexture2DMipmap[2]; 
# 1335
int maxTexture2DLinear[3]; 
# 1336
int maxTexture2DGather[2]; 
# 1337
int maxTexture3D[3]; 
# 1338
int maxTexture3DAlt[3]; 
# 1339
int maxTextureCubemap; 
# 1340
int maxTexture1DLayered[2]; 
# 1341
int maxTexture2DLayered[3]; 
# 1342
int maxTextureCubemapLayered[2]; 
# 1343
int maxSurface1D; 
# 1344
int maxSurface2D[2]; 
# 1345
int maxSurface3D[3]; 
# 1346
int maxSurface1DLayered[2]; 
# 1347
int maxSurface2DLayered[3]; 
# 1348
int maxSurfaceCubemap; 
# 1349
int maxSurfaceCubemapLayered[2]; 
# 1350
size_t surfaceAlignment; 
# 1351
int concurrentKernels; 
# 1352
int ECCEnabled; 
# 1353
int pciBusID; 
# 1354
int pciDeviceID; 
# 1355
int pciDomainID; 
# 1356
int tccDriver; 
# 1357
int asyncEngineCount; 
# 1358
int unifiedAddressing; 
# 1359
int memoryClockRate; 
# 1360
int memoryBusWidth; 
# 1361
int l2CacheSize; 
# 1362
int maxThreadsPerMultiProcessor; 
# 1363
int streamPrioritiesSupported; 
# 1364
int globalL1CacheSupported; 
# 1365
int localL1CacheSupported; 
# 1366
size_t sharedMemPerMultiprocessor; 
# 1367
int regsPerMultiprocessor; 
# 1368
int managedMemory; 
# 1369
int isMultiGpuBoard; 
# 1370
int multiGpuBoardGroupID; 
# 1371
int hostNativeAtomicSupported; 
# 1372
int singleToDoublePrecisionPerfRatio; 
# 1373
int pageableMemoryAccess; 
# 1374
int concurrentManagedAccess; 
# 1375
}; 
#endif
# 1458 "/usr/local/cuda-8.0/include/driver_types.h"
#if 0
typedef 
# 1455
struct cudaIpcEventHandle_st { 
# 1457
char reserved[64]; 
# 1458
} cudaIpcEventHandle_t; 
#endif
# 1466 "/usr/local/cuda-8.0/include/driver_types.h"
#if 0
typedef 
# 1463
struct cudaIpcMemHandle_st { 
# 1465
char reserved[64]; 
# 1466
} cudaIpcMemHandle_t; 
#endif
# 1477 "/usr/local/cuda-8.0/include/driver_types.h"
#if 0
typedef cudaError 
# 1477
cudaError_t; 
#endif
# 1482 "/usr/local/cuda-8.0/include/driver_types.h"
#if 0
typedef struct CUstream_st *
# 1482
cudaStream_t; 
#endif
# 1487 "/usr/local/cuda-8.0/include/driver_types.h"
#if 0
typedef struct CUevent_st *
# 1487
cudaEvent_t; 
#endif
# 1492 "/usr/local/cuda-8.0/include/driver_types.h"
#if 0
typedef cudaGraphicsResource *
# 1492
cudaGraphicsResource_t; 
#endif
# 1497 "/usr/local/cuda-8.0/include/driver_types.h"
#if 0
typedef struct CUuuid_st 
# 1497
cudaUUID_t; 
#endif
# 1502 "/usr/local/cuda-8.0/include/driver_types.h"
#if 0
typedef cudaOutputMode 
# 1502
cudaOutputMode_t; 
#endif
# 84 "/usr/local/cuda-8.0/include/surface_types.h"
#if 0
# 84
enum cudaSurfaceBoundaryMode { 
# 86
cudaBoundaryModeZero, 
# 87
cudaBoundaryModeClamp, 
# 88
cudaBoundaryModeTrap
# 89
}; 
#endif
# 94 "/usr/local/cuda-8.0/include/surface_types.h"
#if 0
# 94
enum cudaSurfaceFormatMode { 
# 96
cudaFormatModeForced, 
# 97
cudaFormatModeAuto
# 98
}; 
#endif
# 103 "/usr/local/cuda-8.0/include/surface_types.h"
#if 0
# 103
struct surfaceReference { 
# 108
cudaChannelFormatDesc channelDesc; 
# 109
}; 
#endif
# 114 "/usr/local/cuda-8.0/include/surface_types.h"
#if 0
typedef unsigned long long 
# 114
cudaSurfaceObject_t; 
#endif
# 84 "/usr/local/cuda-8.0/include/texture_types.h"
#if 0
# 84
enum cudaTextureAddressMode { 
# 86
cudaAddressModeWrap, 
# 87
cudaAddressModeClamp, 
# 88
cudaAddressModeMirror, 
# 89
cudaAddressModeBorder
# 90
}; 
#endif
# 95 "/usr/local/cuda-8.0/include/texture_types.h"
#if 0
# 95
enum cudaTextureFilterMode { 
# 97
cudaFilterModePoint, 
# 98
cudaFilterModeLinear
# 99
}; 
#endif
# 104 "/usr/local/cuda-8.0/include/texture_types.h"
#if 0
# 104
enum cudaTextureReadMode { 
# 106
cudaReadModeElementType, 
# 107
cudaReadModeNormalizedFloat
# 108
}; 
#endif
# 113 "/usr/local/cuda-8.0/include/texture_types.h"
#if 0
# 113
struct textureReference { 
# 118
int normalized; 
# 122
cudaTextureFilterMode filterMode; 
# 126
cudaTextureAddressMode addressMode[3]; 
# 130
cudaChannelFormatDesc channelDesc; 
# 134
int sRGB; 
# 138
unsigned maxAnisotropy; 
# 142
cudaTextureFilterMode mipmapFilterMode; 
# 146
float mipmapLevelBias; 
# 150
float minMipmapLevelClamp; 
# 154
float maxMipmapLevelClamp; 
# 155
int __cudaReserved[15]; 
# 156
}; 
#endif
# 161 "/usr/local/cuda-8.0/include/texture_types.h"
#if 0
# 161
struct cudaTextureDesc { 
# 166
cudaTextureAddressMode addressMode[3]; 
# 170
cudaTextureFilterMode filterMode; 
# 174
cudaTextureReadMode readMode; 
# 178
int sRGB; 
# 182
float borderColor[4]; 
# 186
int normalizedCoords; 
# 190
unsigned maxAnisotropy; 
# 194
cudaTextureFilterMode mipmapFilterMode; 
# 198
float mipmapLevelBias; 
# 202
float minMipmapLevelClamp; 
# 206
float maxMipmapLevelClamp; 
# 207
}; 
#endif
# 212 "/usr/local/cuda-8.0/include/texture_types.h"
#if 0
typedef unsigned long long 
# 212
cudaTextureObject_t; 
#endif
# 98 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
# 98
struct char1 { 
# 100
signed char x; 
# 101
}; 
#endif
# 103 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
# 103
struct uchar1 { 
# 105
unsigned char x; 
# 106
}; 
#endif
# 109 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
# 109
struct __attribute((aligned(2))) char2 { 
# 111
signed char x, y; 
# 112
}; 
#endif
# 114 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
# 114
struct __attribute((aligned(2))) uchar2 { 
# 116
unsigned char x, y; 
# 117
}; 
#endif
# 119 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
# 119
struct char3 { 
# 121
signed char x, y, z; 
# 122
}; 
#endif
# 124 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
# 124
struct uchar3 { 
# 126
unsigned char x, y, z; 
# 127
}; 
#endif
# 129 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
# 129
struct __attribute((aligned(4))) char4 { 
# 131
signed char x, y, z, w; 
# 132
}; 
#endif
# 134 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
# 134
struct __attribute((aligned(4))) uchar4 { 
# 136
unsigned char x, y, z, w; 
# 137
}; 
#endif
# 139 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
# 139
struct short1 { 
# 141
short x; 
# 142
}; 
#endif
# 144 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
# 144
struct ushort1 { 
# 146
unsigned short x; 
# 147
}; 
#endif
# 149 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
# 149
struct __attribute((aligned(4))) short2 { 
# 151
short x, y; 
# 152
}; 
#endif
# 154 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
# 154
struct __attribute((aligned(4))) ushort2 { 
# 156
unsigned short x, y; 
# 157
}; 
#endif
# 159 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
# 159
struct short3 { 
# 161
short x, y, z; 
# 162
}; 
#endif
# 164 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
# 164
struct ushort3 { 
# 166
unsigned short x, y, z; 
# 167
}; 
#endif
# 169 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
# 169
struct __attribute((aligned(8))) short4 { short x; short y; short z; short w; }; 
#endif
# 170 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
# 170
struct __attribute((aligned(8))) ushort4 { unsigned short x; unsigned short y; unsigned short z; unsigned short w; }; 
#endif
# 172 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
# 172
struct int1 { 
# 174
int x; 
# 175
}; 
#endif
# 177 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
# 177
struct uint1 { 
# 179
unsigned x; 
# 180
}; 
#endif
# 182 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
# 182
struct __attribute((aligned(8))) int2 { int x; int y; }; 
#endif
# 183 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
# 183
struct __attribute((aligned(8))) uint2 { unsigned x; unsigned y; }; 
#endif
# 185 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
# 185
struct int3 { 
# 187
int x, y, z; 
# 188
}; 
#endif
# 190 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
# 190
struct uint3 { 
# 192
unsigned x, y, z; 
# 193
}; 
#endif
# 195 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
# 195
struct __attribute((aligned(16))) int4 { 
# 197
int x, y, z, w; 
# 198
}; 
#endif
# 200 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
# 200
struct __attribute((aligned(16))) uint4 { 
# 202
unsigned x, y, z, w; 
# 203
}; 
#endif
# 205 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
# 205
struct long1 { 
# 207
long x; 
# 208
}; 
#endif
# 210 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
# 210
struct ulong1 { 
# 212
unsigned long x; 
# 213
}; 
#endif
# 220 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
# 220
struct __attribute((aligned((2) * sizeof(long)))) long2 { 
# 222
long x, y; 
# 223
}; 
#endif
# 225 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
# 225
struct __attribute((aligned((2) * sizeof(unsigned long)))) ulong2 { 
# 227
unsigned long x, y; 
# 228
}; 
#endif
# 232 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
# 232
struct long3 { 
# 234
long x, y, z; 
# 235
}; 
#endif
# 237 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
# 237
struct ulong3 { 
# 239
unsigned long x, y, z; 
# 240
}; 
#endif
# 242 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
# 242
struct __attribute((aligned(16))) long4 { 
# 244
long x, y, z, w; 
# 245
}; 
#endif
# 247 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
# 247
struct __attribute((aligned(16))) ulong4 { 
# 249
unsigned long x, y, z, w; 
# 250
}; 
#endif
# 252 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
# 252
struct float1 { 
# 254
float x; 
# 255
}; 
#endif
# 274 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
# 274
struct __attribute((aligned(8))) float2 { float x; float y; }; 
#endif
# 279 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
# 279
struct float3 { 
# 281
float x, y, z; 
# 282
}; 
#endif
# 284 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
# 284
struct __attribute((aligned(16))) float4 { 
# 286
float x, y, z, w; 
# 287
}; 
#endif
# 289 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
# 289
struct longlong1 { 
# 291
long long x; 
# 292
}; 
#endif
# 294 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
# 294
struct ulonglong1 { 
# 296
unsigned long long x; 
# 297
}; 
#endif
# 299 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
# 299
struct __attribute((aligned(16))) longlong2 { 
# 301
long long x, y; 
# 302
}; 
#endif
# 304 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
# 304
struct __attribute((aligned(16))) ulonglong2 { 
# 306
unsigned long long x, y; 
# 307
}; 
#endif
# 309 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
# 309
struct longlong3 { 
# 311
long long x, y, z; 
# 312
}; 
#endif
# 314 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
# 314
struct ulonglong3 { 
# 316
unsigned long long x, y, z; 
# 317
}; 
#endif
# 319 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
# 319
struct __attribute((aligned(16))) longlong4 { 
# 321
long long x, y, z, w; 
# 322
}; 
#endif
# 324 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
# 324
struct __attribute((aligned(16))) ulonglong4 { 
# 326
unsigned long long x, y, z, w; 
# 327
}; 
#endif
# 329 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
# 329
struct double1 { 
# 331
double x; 
# 332
}; 
#endif
# 334 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
# 334
struct __attribute((aligned(16))) double2 { 
# 336
double x, y; 
# 337
}; 
#endif
# 339 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
# 339
struct double3 { 
# 341
double x, y, z; 
# 342
}; 
#endif
# 344 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
# 344
struct __attribute((aligned(16))) double4 { 
# 346
double x, y, z, w; 
# 347
}; 
#endif
# 362 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
typedef char1 
# 362
char1; 
#endif
# 363 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
typedef uchar1 
# 363
uchar1; 
#endif
# 364 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
typedef char2 
# 364
char2; 
#endif
# 365 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
typedef uchar2 
# 365
uchar2; 
#endif
# 366 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
typedef char3 
# 366
char3; 
#endif
# 367 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
typedef uchar3 
# 367
uchar3; 
#endif
# 368 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
typedef char4 
# 368
char4; 
#endif
# 369 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
typedef uchar4 
# 369
uchar4; 
#endif
# 370 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
typedef short1 
# 370
short1; 
#endif
# 371 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
typedef ushort1 
# 371
ushort1; 
#endif
# 372 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
typedef short2 
# 372
short2; 
#endif
# 373 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
typedef ushort2 
# 373
ushort2; 
#endif
# 374 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
typedef short3 
# 374
short3; 
#endif
# 375 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
typedef ushort3 
# 375
ushort3; 
#endif
# 376 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
typedef short4 
# 376
short4; 
#endif
# 377 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
typedef ushort4 
# 377
ushort4; 
#endif
# 378 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
typedef int1 
# 378
int1; 
#endif
# 379 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
typedef uint1 
# 379
uint1; 
#endif
# 380 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
typedef int2 
# 380
int2; 
#endif
# 381 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
typedef uint2 
# 381
uint2; 
#endif
# 382 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
typedef int3 
# 382
int3; 
#endif
# 383 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
typedef uint3 
# 383
uint3; 
#endif
# 384 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
typedef int4 
# 384
int4; 
#endif
# 385 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
typedef uint4 
# 385
uint4; 
#endif
# 386 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
typedef long1 
# 386
long1; 
#endif
# 387 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
typedef ulong1 
# 387
ulong1; 
#endif
# 388 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
typedef long2 
# 388
long2; 
#endif
# 389 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
typedef ulong2 
# 389
ulong2; 
#endif
# 390 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
typedef long3 
# 390
long3; 
#endif
# 391 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
typedef ulong3 
# 391
ulong3; 
#endif
# 392 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
typedef long4 
# 392
long4; 
#endif
# 393 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
typedef ulong4 
# 393
ulong4; 
#endif
# 394 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
typedef float1 
# 394
float1; 
#endif
# 395 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
typedef float2 
# 395
float2; 
#endif
# 396 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
typedef float3 
# 396
float3; 
#endif
# 397 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
typedef float4 
# 397
float4; 
#endif
# 398 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
typedef longlong1 
# 398
longlong1; 
#endif
# 399 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
typedef ulonglong1 
# 399
ulonglong1; 
#endif
# 400 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
typedef longlong2 
# 400
longlong2; 
#endif
# 401 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
typedef ulonglong2 
# 401
ulonglong2; 
#endif
# 402 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
typedef longlong3 
# 402
longlong3; 
#endif
# 403 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
typedef ulonglong3 
# 403
ulonglong3; 
#endif
# 404 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
typedef longlong4 
# 404
longlong4; 
#endif
# 405 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
typedef ulonglong4 
# 405
ulonglong4; 
#endif
# 406 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
typedef double1 
# 406
double1; 
#endif
# 407 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
typedef double2 
# 407
double2; 
#endif
# 408 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
typedef double3 
# 408
double3; 
#endif
# 409 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
typedef double4 
# 409
double4; 
#endif
# 417 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
# 417
struct dim3 { 
# 419
unsigned x, y, z; 
# 425
}; 
#endif
# 427 "/usr/local/cuda-8.0/include/vector_types.h"
#if 0
typedef dim3 
# 427
dim3; 
#endif
# 70 "/usr/local/cuda-8.0/include/library_types.h"
typedef 
# 54
enum cudaDataType_t { 
# 56
CUDA_R_16F = 2, 
# 57
CUDA_C_16F = 6, 
# 58
CUDA_R_32F = 0, 
# 59
CUDA_C_32F = 4, 
# 60
CUDA_R_64F = 1, 
# 61
CUDA_C_64F = 5, 
# 62
CUDA_R_8I = 3, 
# 63
CUDA_C_8I = 7, 
# 64
CUDA_R_8U, 
# 65
CUDA_C_8U, 
# 66
CUDA_R_32I, 
# 67
CUDA_C_32I, 
# 68
CUDA_R_32U, 
# 69
CUDA_C_32U
# 70
} cudaDataType; 
# 78
typedef 
# 73
enum libraryPropertyType_t { 
# 75
MAJOR_VERSION, 
# 76
MINOR_VERSION, 
# 77
PATCH_LEVEL
# 78
} libraryPropertyType; 
# 104 "/usr/local/cuda-8.0/include/cuda_device_runtime_api.h"
extern "C" {
# 106
extern cudaError_t cudaDeviceGetAttribute(int * value, cudaDeviceAttr attr, int device); 
# 107
extern cudaError_t cudaDeviceGetLimit(size_t * pValue, cudaLimit limit); 
# 108
extern cudaError_t cudaDeviceGetCacheConfig(cudaFuncCache * pCacheConfig); 
# 109
extern cudaError_t cudaDeviceGetSharedMemConfig(cudaSharedMemConfig * pConfig); 
# 110
extern cudaError_t cudaDeviceSynchronize(); 
# 111
extern cudaError_t cudaGetLastError(); 
# 112
extern cudaError_t cudaPeekAtLastError(); 
# 113
extern const char *cudaGetErrorString(cudaError_t error); 
# 114
extern const char *cudaGetErrorName(cudaError_t error); 
# 115
extern cudaError_t cudaGetDeviceCount(int * count); 
# 116
extern cudaError_t cudaGetDevice(int * device); 
# 117
extern cudaError_t cudaStreamCreateWithFlags(cudaStream_t * pStream, unsigned flags); 
# 118
extern cudaError_t cudaStreamDestroy(cudaStream_t stream); 
# 119
extern cudaError_t cudaStreamWaitEvent(cudaStream_t stream, cudaEvent_t event, unsigned flags); 
# 120
__attribute__((unused)) extern cudaError_t cudaStreamWaitEvent_ptsz(cudaStream_t stream, cudaEvent_t event, unsigned flags); 
# 121
extern cudaError_t cudaEventCreateWithFlags(cudaEvent_t * event, unsigned flags); 
# 122
extern cudaError_t cudaEventRecord(cudaEvent_t event, cudaStream_t stream); 
# 123
__attribute__((unused)) extern cudaError_t cudaEventRecord_ptsz(cudaEvent_t event, cudaStream_t stream); 
# 124
extern cudaError_t cudaEventDestroy(cudaEvent_t event); 
# 125
extern cudaError_t cudaFuncGetAttributes(cudaFuncAttributes * attr, const void * func); 
# 126
extern cudaError_t cudaFree(void * devPtr); 
# 127
extern cudaError_t cudaMalloc(void ** devPtr, size_t size); 
# 128
extern cudaError_t cudaMemcpyAsync(void * dst, const void * src, size_t count, cudaMemcpyKind kind, cudaStream_t stream); 
# 129
__attribute__((unused)) extern cudaError_t cudaMemcpyAsync_ptsz(void * dst, const void * src, size_t count, cudaMemcpyKind kind, cudaStream_t stream); 
# 130
extern cudaError_t cudaMemcpy2DAsync(void * dst, size_t dpitch, const void * src, size_t spitch, size_t width, size_t height, cudaMemcpyKind kind, cudaStream_t stream); 
# 131
__attribute__((unused)) extern cudaError_t cudaMemcpy2DAsync_ptsz(void * dst, size_t dpitch, const void * src, size_t spitch, size_t width, size_t height, cudaMemcpyKind kind, cudaStream_t stream); 
# 132
extern cudaError_t cudaMemcpy3DAsync(const cudaMemcpy3DParms * p, cudaStream_t stream); 
# 133
__attribute__((unused)) extern cudaError_t cudaMemcpy3DAsync_ptsz(const cudaMemcpy3DParms * p, cudaStream_t stream); 
# 134
extern cudaError_t cudaMemsetAsync(void * devPtr, int value, size_t count, cudaStream_t stream); 
# 135
__attribute__((unused)) extern cudaError_t cudaMemsetAsync_ptsz(void * devPtr, int value, size_t count, cudaStream_t stream); 
# 136
extern cudaError_t cudaMemset2DAsync(void * devPtr, size_t pitch, int value, size_t width, size_t height, cudaStream_t stream); 
# 137
__attribute__((unused)) extern cudaError_t cudaMemset2DAsync_ptsz(void * devPtr, size_t pitch, int value, size_t width, size_t height, cudaStream_t stream); 
# 138
extern cudaError_t cudaMemset3DAsync(cudaPitchedPtr pitchedDevPtr, int value, cudaExtent extent, cudaStream_t stream); 
# 139
__attribute__((unused)) extern cudaError_t cudaMemset3DAsync_ptsz(cudaPitchedPtr pitchedDevPtr, int value, cudaExtent extent, cudaStream_t stream); 
# 140
extern cudaError_t cudaRuntimeGetVersion(int * runtimeVersion); 
# 161
__attribute__((unused)) extern void *cudaGetParameterBuffer(size_t alignment, size_t size); 
# 189
__attribute__((unused)) extern void *cudaGetParameterBufferV2(void * func, dim3 gridDimension, dim3 blockDimension, unsigned sharedMemSize); 
# 190
__attribute__((unused)) extern cudaError_t cudaLaunchDevice_ptsz(void * func, void * parameterBuffer, dim3 gridDimension, dim3 blockDimension, unsigned sharedMemSize, cudaStream_t stream); 
# 191
__attribute__((unused)) extern cudaError_t cudaLaunchDeviceV2_ptsz(void * parameterBuffer, cudaStream_t stream); 
# 209
__attribute__((unused)) extern cudaError_t cudaLaunchDevice(void * func, void * parameterBuffer, dim3 gridDimension, dim3 blockDimension, unsigned sharedMemSize, cudaStream_t stream); 
# 210
__attribute__((unused)) extern cudaError_t cudaLaunchDeviceV2(void * parameterBuffer, cudaStream_t stream); 
# 213
extern cudaError_t cudaOccupancyMaxActiveBlocksPerMultiprocessor(int * numBlocks, const void * func, int blockSize, size_t dynamicSmemSize); 
# 214
extern cudaError_t cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags(int * numBlocks, const void * func, int blockSize, size_t dynamicSmemSize, unsigned flags); 
# 216
}
# 218
template< class T> static inline cudaError_t cudaMalloc(T ** devPtr, size_t size); 
# 219
template< class T> static inline cudaError_t cudaFuncGetAttributes(cudaFuncAttributes * attr, T * entry); 
# 220
template< class T> static inline cudaError_t cudaOccupancyMaxActiveBlocksPerMultiprocessor(int * numBlocks, T func, int blockSize, size_t dynamicSmemSize); 
# 221
template< class T> static inline cudaError_t cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags(int * numBlocks, T func, int blockSize, size_t dynamicSmemSize, unsigned flags); 
# 219 "/usr/local/cuda-8.0/include/cuda_runtime_api.h"
extern "C" {
# 252
extern cudaError_t cudaDeviceReset(); 
# 269
extern cudaError_t cudaDeviceSynchronize(); 
# 344
extern cudaError_t cudaDeviceSetLimit(cudaLimit limit, size_t value); 
# 373
extern cudaError_t cudaDeviceGetLimit(size_t * pValue, cudaLimit limit); 
# 404
extern cudaError_t cudaDeviceGetCacheConfig(cudaFuncCache * pCacheConfig); 
# 439
extern cudaError_t cudaDeviceGetStreamPriorityRange(int * leastPriority, int * greatestPriority); 
# 481
extern cudaError_t cudaDeviceSetCacheConfig(cudaFuncCache cacheConfig); 
# 510
extern cudaError_t cudaDeviceGetSharedMemConfig(cudaSharedMemConfig * pConfig); 
# 552
extern cudaError_t cudaDeviceSetSharedMemConfig(cudaSharedMemConfig config); 
# 575
extern cudaError_t cudaDeviceGetByPCIBusId(int * device, const char * pciBusId); 
# 602
extern cudaError_t cudaDeviceGetPCIBusId(char * pciBusId, int len, int device); 
# 644
extern cudaError_t cudaIpcGetEventHandle(cudaIpcEventHandle_t * handle, cudaEvent_t event); 
# 679
extern cudaError_t cudaIpcOpenEventHandle(cudaEvent_t * event, cudaIpcEventHandle_t handle); 
# 717
extern cudaError_t cudaIpcGetMemHandle(cudaIpcMemHandle_t * handle, void * devPtr); 
# 767
extern cudaError_t cudaIpcOpenMemHandle(void ** devPtr, cudaIpcMemHandle_t handle, unsigned flags); 
# 797
extern cudaError_t cudaIpcCloseMemHandle(void * devPtr); 
# 837
extern cudaError_t cudaThreadExit(); 
# 861
extern cudaError_t cudaThreadSynchronize(); 
# 908
extern cudaError_t cudaThreadSetLimit(cudaLimit limit, size_t value); 
# 939
extern cudaError_t cudaThreadGetLimit(size_t * pValue, cudaLimit limit); 
# 974
extern cudaError_t cudaThreadGetCacheConfig(cudaFuncCache * pCacheConfig); 
# 1020
extern cudaError_t cudaThreadSetCacheConfig(cudaFuncCache cacheConfig); 
# 1074
extern cudaError_t cudaGetLastError(); 
# 1115
extern cudaError_t cudaPeekAtLastError(); 
# 1130
extern const char *cudaGetErrorName(cudaError_t error); 
# 1145
extern const char *cudaGetErrorString(cudaError_t error); 
# 1175
extern cudaError_t cudaGetDeviceCount(int * count); 
# 1421
extern cudaError_t cudaGetDeviceProperties(cudaDeviceProp * prop, int device); 
# 1593
extern cudaError_t cudaDeviceGetAttribute(int * value, cudaDeviceAttr attr, int device); 
# 1628
extern cudaError_t cudaDeviceGetP2PAttribute(int * value, cudaDeviceP2PAttr attr, int srcDevice, int dstDevice); 
# 1647
extern cudaError_t cudaChooseDevice(int * device, const cudaDeviceProp * prop); 
# 1681
extern cudaError_t cudaSetDevice(int device); 
# 1698
extern cudaError_t cudaGetDevice(int * device); 
# 1727
extern cudaError_t cudaSetValidDevices(int * device_arr, int len); 
# 1789
extern cudaError_t cudaSetDeviceFlags(unsigned flags); 
# 1830
extern cudaError_t cudaGetDeviceFlags(unsigned * flags); 
# 1867
extern cudaError_t cudaStreamCreate(cudaStream_t * pStream); 
# 1896
extern cudaError_t cudaStreamCreateWithFlags(cudaStream_t * pStream, unsigned flags); 
# 1939
extern cudaError_t cudaStreamCreateWithPriority(cudaStream_t * pStream, unsigned flags, int priority); 
# 1963
extern cudaError_t cudaStreamGetPriority(cudaStream_t hStream, int * priority); 
# 1984
extern cudaError_t cudaStreamGetFlags(cudaStream_t hStream, unsigned * flags); 
# 2005
extern cudaError_t cudaStreamDestroy(cudaStream_t stream); 
# 2037
extern cudaError_t cudaStreamWaitEvent(cudaStream_t stream, cudaEvent_t event, unsigned flags); 
# 2051
typedef void (*cudaStreamCallback_t)(cudaStream_t stream, cudaError_t status, void * userData); 
# 2108
extern cudaError_t cudaStreamAddCallback(cudaStream_t stream, cudaStreamCallback_t callback, void * userData, unsigned flags); 
# 2128
extern cudaError_t cudaStreamSynchronize(cudaStream_t stream); 
# 2149
extern cudaError_t cudaStreamQuery(cudaStream_t stream); 
# 2220
extern cudaError_t cudaStreamAttachMemAsync(cudaStream_t stream, void * devPtr, size_t length = 0, unsigned flags = 4); 
# 2256
extern cudaError_t cudaEventCreate(cudaEvent_t * event); 
# 2290
extern cudaError_t cudaEventCreateWithFlags(cudaEvent_t * event, unsigned flags); 
# 2321
extern cudaError_t cudaEventRecord(cudaEvent_t event, cudaStream_t stream = 0); 
# 2353
extern cudaError_t cudaEventQuery(cudaEvent_t event); 
# 2385
extern cudaError_t cudaEventSynchronize(cudaEvent_t event); 
# 2410
extern cudaError_t cudaEventDestroy(cudaEvent_t event); 
# 2451
extern cudaError_t cudaEventElapsedTime(float * ms, cudaEvent_t start, cudaEvent_t end); 
# 2510
extern cudaError_t cudaLaunchKernel(const void * func, dim3 gridDim, dim3 blockDim, void ** args, size_t sharedMem, cudaStream_t stream); 
# 2560
extern cudaError_t cudaFuncSetCacheConfig(const void * func, cudaFuncCache cacheConfig); 
# 2614
extern cudaError_t cudaFuncSetSharedMemConfig(const void * func, cudaSharedMemConfig config); 
# 2648
extern cudaError_t cudaFuncGetAttributes(cudaFuncAttributes * attr, const void * func); 
# 2671
extern cudaError_t cudaSetDoubleForDevice(double * d); 
# 2694
extern cudaError_t cudaSetDoubleForHost(double * d); 
# 2750
extern cudaError_t cudaOccupancyMaxActiveBlocksPerMultiprocessor(int * numBlocks, const void * func, int blockSize, size_t dynamicSMemSize); 
# 2794
extern cudaError_t cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags(int * numBlocks, const void * func, int blockSize, size_t dynamicSMemSize, unsigned flags); 
# 2845
extern cudaError_t cudaConfigureCall(dim3 gridDim, dim3 blockDim, size_t sharedMem = 0, cudaStream_t stream = 0); 
# 2874
extern cudaError_t cudaSetupArgument(const void * arg, size_t size, size_t offset); 
# 2912
extern cudaError_t cudaLaunch(const void * func); 
# 3030
extern cudaError_t cudaMallocManaged(void ** devPtr, size_t size, unsigned flags = 1); 
# 3056
extern cudaError_t cudaMalloc(void ** devPtr, size_t size); 
# 3085
extern cudaError_t cudaMallocHost(void ** ptr, size_t size); 
# 3124
extern cudaError_t cudaMallocPitch(void ** devPtr, size_t * pitch, size_t width, size_t height); 
# 3166
extern cudaError_t cudaMallocArray(cudaArray_t * array, const cudaChannelFormatDesc * desc, size_t width, size_t height = 0, unsigned flags = 0); 
# 3193
extern cudaError_t cudaFree(void * devPtr); 
# 3213
extern cudaError_t cudaFreeHost(void * ptr); 
# 3235
extern cudaError_t cudaFreeArray(cudaArray_t array); 
# 3257
extern cudaError_t cudaFreeMipmappedArray(cudaMipmappedArray_t mipmappedArray); 
# 3316
extern cudaError_t cudaHostAlloc(void ** pHost, size_t size, unsigned flags); 
# 3393
extern cudaError_t cudaHostRegister(void * ptr, size_t size, unsigned flags); 
# 3412
extern cudaError_t cudaHostUnregister(void * ptr); 
# 3454
extern cudaError_t cudaHostGetDevicePointer(void ** pDevice, void * pHost, unsigned flags); 
# 3473
extern cudaError_t cudaHostGetFlags(unsigned * pFlags, void * pHost); 
# 3508
extern cudaError_t cudaMalloc3D(cudaPitchedPtr * pitchedDevPtr, cudaExtent extent); 
# 3643
extern cudaError_t cudaMalloc3DArray(cudaArray_t * array, const cudaChannelFormatDesc * desc, cudaExtent extent, unsigned flags = 0); 
# 3764
extern cudaError_t cudaMallocMipmappedArray(cudaMipmappedArray_t * mipmappedArray, const cudaChannelFormatDesc * desc, cudaExtent extent, unsigned numLevels, unsigned flags = 0); 
# 3790
extern cudaError_t cudaGetMipmappedArrayLevel(cudaArray_t * levelArray, cudaMipmappedArray_const_t mipmappedArray, unsigned level); 
# 3890
extern cudaError_t cudaMemcpy3D(const cudaMemcpy3DParms * p); 
# 3918
extern cudaError_t cudaMemcpy3DPeer(const cudaMemcpy3DPeerParms * p); 
# 4029
extern cudaError_t cudaMemcpy3DAsync(const cudaMemcpy3DParms * p, cudaStream_t stream = 0); 
# 4052
extern cudaError_t cudaMemcpy3DPeerAsync(const cudaMemcpy3DPeerParms * p, cudaStream_t stream = 0); 
# 4071
extern cudaError_t cudaMemGetInfo(size_t * free, size_t * total); 
# 4092
extern cudaError_t cudaArrayGetInfo(cudaChannelFormatDesc * desc, cudaExtent * extent, unsigned * flags, cudaArray_t array); 
# 4130
extern cudaError_t cudaMemcpy(void * dst, const void * src, size_t count, cudaMemcpyKind kind); 
# 4162
extern cudaError_t cudaMemcpyPeer(void * dst, int dstDevice, const void * src, int srcDevice, size_t count); 
# 4200
extern cudaError_t cudaMemcpyToArray(cudaArray_t dst, size_t wOffset, size_t hOffset, const void * src, size_t count, cudaMemcpyKind kind); 
# 4237
extern cudaError_t cudaMemcpyFromArray(void * dst, cudaArray_const_t src, size_t wOffset, size_t hOffset, size_t count, cudaMemcpyKind kind); 
# 4275
extern cudaError_t cudaMemcpyArrayToArray(cudaArray_t dst, size_t wOffsetDst, size_t hOffsetDst, cudaArray_const_t src, size_t wOffsetSrc, size_t hOffsetSrc, size_t count, cudaMemcpyKind kind = cudaMemcpyDeviceToDevice); 
# 4320
extern cudaError_t cudaMemcpy2D(void * dst, size_t dpitch, const void * src, size_t spitch, size_t width, size_t height, cudaMemcpyKind kind); 
# 4366
extern cudaError_t cudaMemcpy2DToArray(cudaArray_t dst, size_t wOffset, size_t hOffset, const void * src, size_t spitch, size_t width, size_t height, cudaMemcpyKind kind); 
# 4412
extern cudaError_t cudaMemcpy2DFromArray(void * dst, size_t dpitch, cudaArray_const_t src, size_t wOffset, size_t hOffset, size_t width, size_t height, cudaMemcpyKind kind); 
# 4455
extern cudaError_t cudaMemcpy2DArrayToArray(cudaArray_t dst, size_t wOffsetDst, size_t hOffsetDst, cudaArray_const_t src, size_t wOffsetSrc, size_t hOffsetSrc, size_t width, size_t height, cudaMemcpyKind kind = cudaMemcpyDeviceToDevice); 
# 4493
extern cudaError_t cudaMemcpyToSymbol(const void * symbol, const void * src, size_t count, size_t offset = 0, cudaMemcpyKind kind = cudaMemcpyHostToDevice); 
# 4531
extern cudaError_t cudaMemcpyFromSymbol(void * dst, const void * symbol, size_t count, size_t offset = 0, cudaMemcpyKind kind = cudaMemcpyDeviceToHost); 
# 4582
extern cudaError_t cudaMemcpyAsync(void * dst, const void * src, size_t count, cudaMemcpyKind kind, cudaStream_t stream = 0); 
# 4614
extern cudaError_t cudaMemcpyPeerAsync(void * dst, int dstDevice, const void * src, int srcDevice, size_t count, cudaStream_t stream = 0); 
# 4660
extern cudaError_t cudaMemcpyToArrayAsync(cudaArray_t dst, size_t wOffset, size_t hOffset, const void * src, size_t count, cudaMemcpyKind kind, cudaStream_t stream = 0); 
# 4705
extern cudaError_t cudaMemcpyFromArrayAsync(void * dst, cudaArray_const_t src, size_t wOffset, size_t hOffset, size_t count, cudaMemcpyKind kind, cudaStream_t stream = 0); 
# 4765
extern cudaError_t cudaMemcpy2DAsync(void * dst, size_t dpitch, const void * src, size_t spitch, size_t width, size_t height, cudaMemcpyKind kind, cudaStream_t stream = 0); 
# 4820
extern cudaError_t cudaMemcpy2DToArrayAsync(cudaArray_t dst, size_t wOffset, size_t hOffset, const void * src, size_t spitch, size_t width, size_t height, cudaMemcpyKind kind, cudaStream_t stream = 0); 
# 4874
extern cudaError_t cudaMemcpy2DFromArrayAsync(void * dst, size_t dpitch, cudaArray_const_t src, size_t wOffset, size_t hOffset, size_t width, size_t height, cudaMemcpyKind kind, cudaStream_t stream = 0); 
# 4920
extern cudaError_t cudaMemcpyToSymbolAsync(const void * symbol, const void * src, size_t count, size_t offset, cudaMemcpyKind kind, cudaStream_t stream = 0); 
# 4966
extern cudaError_t cudaMemcpyFromSymbolAsync(void * dst, const void * symbol, size_t count, size_t offset, cudaMemcpyKind kind, cudaStream_t stream = 0); 
# 4992
extern cudaError_t cudaMemset(void * devPtr, int value, size_t count); 
# 5022
extern cudaError_t cudaMemset2D(void * devPtr, size_t pitch, int value, size_t width, size_t height); 
# 5065
extern cudaError_t cudaMemset3D(cudaPitchedPtr pitchedDevPtr, int value, cudaExtent extent); 
# 5097
extern cudaError_t cudaMemsetAsync(void * devPtr, int value, size_t count, cudaStream_t stream = 0); 
# 5134
extern cudaError_t cudaMemset2DAsync(void * devPtr, size_t pitch, int value, size_t width, size_t height, cudaStream_t stream = 0); 
# 5184
extern cudaError_t cudaMemset3DAsync(cudaPitchedPtr pitchedDevPtr, int value, cudaExtent extent, cudaStream_t stream = 0); 
# 5207
extern cudaError_t cudaGetSymbolAddress(void ** devPtr, const void * symbol); 
# 5229
extern cudaError_t cudaGetSymbolSize(size_t * size, const void * symbol); 
# 5296
extern cudaError_t cudaMemPrefetchAsync(const void * devPtr, size_t count, int dstDevice, cudaStream_t stream = 0); 
# 5382
extern cudaError_t cudaMemAdvise(const void * devPtr, size_t count, cudaMemoryAdvise advice, int device); 
# 5438
extern cudaError_t cudaMemRangeGetAttribute(void * data, size_t dataSize, cudaMemRangeAttribute attribute, const void * devPtr, size_t count); 
# 5474
extern cudaError_t cudaMemRangeGetAttributes(void ** data, size_t * dataSizes, cudaMemRangeAttribute * attributes, size_t numAttributes, const void * devPtr, size_t count); 
# 5627
extern cudaError_t cudaPointerGetAttributes(cudaPointerAttributes * attributes, const void * ptr); 
# 5665
extern cudaError_t cudaDeviceCanAccessPeer(int * canAccessPeer, int device, int peerDevice); 
# 5704
extern cudaError_t cudaDeviceEnablePeerAccess(int peerDevice, unsigned flags); 
# 5723
extern cudaError_t cudaDeviceDisablePeerAccess(int peerDevice); 
# 5783
extern cudaError_t cudaGraphicsUnregisterResource(cudaGraphicsResource_t resource); 
# 5815
extern cudaError_t cudaGraphicsResourceSetMapFlags(cudaGraphicsResource_t resource, unsigned flags); 
# 5851
extern cudaError_t cudaGraphicsMapResources(int count, cudaGraphicsResource_t * resources, cudaStream_t stream = 0); 
# 5883
extern cudaError_t cudaGraphicsUnmapResources(int count, cudaGraphicsResource_t * resources, cudaStream_t stream = 0); 
# 5912
extern cudaError_t cudaGraphicsResourceGetMappedPointer(void ** devPtr, size_t * size, cudaGraphicsResource_t resource); 
# 5946
extern cudaError_t cudaGraphicsSubResourceGetMappedArray(cudaArray_t * array, cudaGraphicsResource_t resource, unsigned arrayIndex, unsigned mipLevel); 
# 5971
extern cudaError_t cudaGraphicsResourceGetMappedMipmappedArray(cudaMipmappedArray_t * mipmappedArray, cudaGraphicsResource_t resource); 
# 6011
extern cudaError_t cudaGetChannelDesc(cudaChannelFormatDesc * desc, cudaArray_const_t array); 
# 6046
extern cudaChannelFormatDesc cudaCreateChannelDesc(int x, int y, int z, int w, cudaChannelFormatKind f); 
# 6093
extern cudaError_t cudaBindTexture(size_t * offset, const textureReference * texref, const void * devPtr, const cudaChannelFormatDesc * desc, size_t size = ((2147483647) * 2U) + 1U); 
# 6144
extern cudaError_t cudaBindTexture2D(size_t * offset, const textureReference * texref, const void * devPtr, const cudaChannelFormatDesc * desc, size_t width, size_t height, size_t pitch); 
# 6172
extern cudaError_t cudaBindTextureToArray(const textureReference * texref, cudaArray_const_t array, const cudaChannelFormatDesc * desc); 
# 6200
extern cudaError_t cudaBindTextureToMipmappedArray(const textureReference * texref, cudaMipmappedArray_const_t mipmappedArray, const cudaChannelFormatDesc * desc); 
# 6221
extern cudaError_t cudaUnbindTexture(const textureReference * texref); 
# 6246
extern cudaError_t cudaGetTextureAlignmentOffset(size_t * offset, const textureReference * texref); 
# 6271
extern cudaError_t cudaGetTextureReference(const textureReference ** texref, const void * symbol); 
# 6311
extern cudaError_t cudaBindSurfaceToArray(const surfaceReference * surfref, cudaArray_const_t array, const cudaChannelFormatDesc * desc); 
# 6330
extern cudaError_t cudaGetSurfaceReference(const surfaceReference ** surfref, const void * symbol); 
# 6556
extern cudaError_t cudaCreateTextureObject(cudaTextureObject_t * pTexObject, const cudaResourceDesc * pResDesc, const cudaTextureDesc * pTexDesc, const cudaResourceViewDesc * pResViewDesc); 
# 6571
extern cudaError_t cudaDestroyTextureObject(cudaTextureObject_t texObject); 
# 6587
extern cudaError_t cudaGetTextureObjectResourceDesc(cudaResourceDesc * pResDesc, cudaTextureObject_t texObject); 
# 6603
extern cudaError_t cudaGetTextureObjectTextureDesc(cudaTextureDesc * pTexDesc, cudaTextureObject_t texObject); 
# 6620
extern cudaError_t cudaGetTextureObjectResourceViewDesc(cudaResourceViewDesc * pResViewDesc, cudaTextureObject_t texObject); 
# 6659
extern cudaError_t cudaCreateSurfaceObject(cudaSurfaceObject_t * pSurfObject, const cudaResourceDesc * pResDesc); 
# 6674
extern cudaError_t cudaDestroySurfaceObject(cudaSurfaceObject_t surfObject); 
# 6689
extern cudaError_t cudaGetSurfaceObjectResourceDesc(cudaResourceDesc * pResDesc, cudaSurfaceObject_t surfObject); 
# 6716
extern cudaError_t cudaDriverGetVersion(int * driverVersion); 
# 6733
extern cudaError_t cudaRuntimeGetVersion(int * runtimeVersion); 
# 6738
extern cudaError_t cudaGetExportTable(const void ** ppExportTable, const cudaUUID_t * pExportTableId); 
# 6964
}
# 107 "/usr/local/cuda-8.0/include/channel_descriptor.h"
template< class T> inline cudaChannelFormatDesc cudaCreateChannelDesc() 
# 108
{ 
# 109
return cudaCreateChannelDesc(0, 0, 0, 0, cudaChannelFormatKindNone); 
# 110
} 
# 112
static inline cudaChannelFormatDesc cudaCreateChannelDescHalf() 
# 113
{ 
# 114
int e = (((int)sizeof(unsigned short)) * 8); 
# 116
return cudaCreateChannelDesc(e, 0, 0, 0, cudaChannelFormatKindFloat); 
# 117
} 
# 119
static inline cudaChannelFormatDesc cudaCreateChannelDescHalf1() 
# 120
{ 
# 121
int e = (((int)sizeof(unsigned short)) * 8); 
# 123
return cudaCreateChannelDesc(e, 0, 0, 0, cudaChannelFormatKindFloat); 
# 124
} 
# 126
static inline cudaChannelFormatDesc cudaCreateChannelDescHalf2() 
# 127
{ 
# 128
int e = (((int)sizeof(unsigned short)) * 8); 
# 130
return cudaCreateChannelDesc(e, e, 0, 0, cudaChannelFormatKindFloat); 
# 131
} 
# 133
static inline cudaChannelFormatDesc cudaCreateChannelDescHalf4() 
# 134
{ 
# 135
int e = (((int)sizeof(unsigned short)) * 8); 
# 137
return cudaCreateChannelDesc(e, e, e, e, cudaChannelFormatKindFloat); 
# 138
} 
# 140
template<> inline cudaChannelFormatDesc cudaCreateChannelDesc< char> () 
# 141
{ 
# 142
int e = (((int)sizeof(char)) * 8); 
# 145
return cudaCreateChannelDesc(e, 0, 0, 0, cudaChannelFormatKindUnsigned); 
# 149
} 
# 151
template<> inline cudaChannelFormatDesc cudaCreateChannelDesc< signed char> () 
# 152
{ 
# 153
int e = (((int)sizeof(signed char)) * 8); 
# 155
return cudaCreateChannelDesc(e, 0, 0, 0, cudaChannelFormatKindSigned); 
# 156
} 
# 158
template<> inline cudaChannelFormatDesc cudaCreateChannelDesc< unsigned char> () 
# 159
{ 
# 160
int e = (((int)sizeof(unsigned char)) * 8); 
# 162
return cudaCreateChannelDesc(e, 0, 0, 0, cudaChannelFormatKindUnsigned); 
# 163
} 
# 165
template<> inline cudaChannelFormatDesc cudaCreateChannelDesc< char1> () 
# 166
{ 
# 167
int e = (((int)sizeof(signed char)) * 8); 
# 169
return cudaCreateChannelDesc(e, 0, 0, 0, cudaChannelFormatKindSigned); 
# 170
} 
# 172
template<> inline cudaChannelFormatDesc cudaCreateChannelDesc< uchar1> () 
# 173
{ 
# 174
int e = (((int)sizeof(unsigned char)) * 8); 
# 176
return cudaCreateChannelDesc(e, 0, 0, 0, cudaChannelFormatKindUnsigned); 
# 177
} 
# 179
template<> inline cudaChannelFormatDesc cudaCreateChannelDesc< char2> () 
# 180
{ 
# 181
int e = (((int)sizeof(signed char)) * 8); 
# 183
return cudaCreateChannelDesc(e, e, 0, 0, cudaChannelFormatKindSigned); 
# 184
} 
# 186
template<> inline cudaChannelFormatDesc cudaCreateChannelDesc< uchar2> () 
# 187
{ 
# 188
int e = (((int)sizeof(unsigned char)) * 8); 
# 190
return cudaCreateChannelDesc(e, e, 0, 0, cudaChannelFormatKindUnsigned); 
# 191
} 
# 193
template<> inline cudaChannelFormatDesc cudaCreateChannelDesc< char4> () 
# 194
{ 
# 195
int e = (((int)sizeof(signed char)) * 8); 
# 197
return cudaCreateChannelDesc(e, e, e, e, cudaChannelFormatKindSigned); 
# 198
} 
# 200
template<> inline cudaChannelFormatDesc cudaCreateChannelDesc< uchar4> () 
# 201
{ 
# 202
int e = (((int)sizeof(unsigned char)) * 8); 
# 204
return cudaCreateChannelDesc(e, e, e, e, cudaChannelFormatKindUnsigned); 
# 205
} 
# 207
template<> inline cudaChannelFormatDesc cudaCreateChannelDesc< short> () 
# 208
{ 
# 209
int e = (((int)sizeof(short)) * 8); 
# 211
return cudaCreateChannelDesc(e, 0, 0, 0, cudaChannelFormatKindSigned); 
# 212
} 
# 214
template<> inline cudaChannelFormatDesc cudaCreateChannelDesc< unsigned short> () 
# 215
{ 
# 216
int e = (((int)sizeof(unsigned short)) * 8); 
# 218
return cudaCreateChannelDesc(e, 0, 0, 0, cudaChannelFormatKindUnsigned); 
# 219
} 
# 221
template<> inline cudaChannelFormatDesc cudaCreateChannelDesc< short1> () 
# 222
{ 
# 223
int e = (((int)sizeof(short)) * 8); 
# 225
return cudaCreateChannelDesc(e, 0, 0, 0, cudaChannelFormatKindSigned); 
# 226
} 
# 228
template<> inline cudaChannelFormatDesc cudaCreateChannelDesc< ushort1> () 
# 229
{ 
# 230
int e = (((int)sizeof(unsigned short)) * 8); 
# 232
return cudaCreateChannelDesc(e, 0, 0, 0, cudaChannelFormatKindUnsigned); 
# 233
} 
# 235
template<> inline cudaChannelFormatDesc cudaCreateChannelDesc< short2> () 
# 236
{ 
# 237
int e = (((int)sizeof(short)) * 8); 
# 239
return cudaCreateChannelDesc(e, e, 0, 0, cudaChannelFormatKindSigned); 
# 240
} 
# 242
template<> inline cudaChannelFormatDesc cudaCreateChannelDesc< ushort2> () 
# 243
{ 
# 244
int e = (((int)sizeof(unsigned short)) * 8); 
# 246
return cudaCreateChannelDesc(e, e, 0, 0, cudaChannelFormatKindUnsigned); 
# 247
} 
# 249
template<> inline cudaChannelFormatDesc cudaCreateChannelDesc< short4> () 
# 250
{ 
# 251
int e = (((int)sizeof(short)) * 8); 
# 253
return cudaCreateChannelDesc(e, e, e, e, cudaChannelFormatKindSigned); 
# 254
} 
# 256
template<> inline cudaChannelFormatDesc cudaCreateChannelDesc< ushort4> () 
# 257
{ 
# 258
int e = (((int)sizeof(unsigned short)) * 8); 
# 260
return cudaCreateChannelDesc(e, e, e, e, cudaChannelFormatKindUnsigned); 
# 261
} 
# 263
template<> inline cudaChannelFormatDesc cudaCreateChannelDesc< int> () 
# 264
{ 
# 265
int e = (((int)sizeof(int)) * 8); 
# 267
return cudaCreateChannelDesc(e, 0, 0, 0, cudaChannelFormatKindSigned); 
# 268
} 
# 270
template<> inline cudaChannelFormatDesc cudaCreateChannelDesc< unsigned> () 
# 271
{ 
# 272
int e = (((int)sizeof(unsigned)) * 8); 
# 274
return cudaCreateChannelDesc(e, 0, 0, 0, cudaChannelFormatKindUnsigned); 
# 275
} 
# 277
template<> inline cudaChannelFormatDesc cudaCreateChannelDesc< int1> () 
# 278
{ 
# 279
int e = (((int)sizeof(int)) * 8); 
# 281
return cudaCreateChannelDesc(e, 0, 0, 0, cudaChannelFormatKindSigned); 
# 282
} 
# 284
template<> inline cudaChannelFormatDesc cudaCreateChannelDesc< uint1> () 
# 285
{ 
# 286
int e = (((int)sizeof(unsigned)) * 8); 
# 288
return cudaCreateChannelDesc(e, 0, 0, 0, cudaChannelFormatKindUnsigned); 
# 289
} 
# 291
template<> inline cudaChannelFormatDesc cudaCreateChannelDesc< int2> () 
# 292
{ 
# 293
int e = (((int)sizeof(int)) * 8); 
# 295
return cudaCreateChannelDesc(e, e, 0, 0, cudaChannelFormatKindSigned); 
# 296
} 
# 298
template<> inline cudaChannelFormatDesc cudaCreateChannelDesc< uint2> () 
# 299
{ 
# 300
int e = (((int)sizeof(unsigned)) * 8); 
# 302
return cudaCreateChannelDesc(e, e, 0, 0, cudaChannelFormatKindUnsigned); 
# 303
} 
# 305
template<> inline cudaChannelFormatDesc cudaCreateChannelDesc< int4> () 
# 306
{ 
# 307
int e = (((int)sizeof(int)) * 8); 
# 309
return cudaCreateChannelDesc(e, e, e, e, cudaChannelFormatKindSigned); 
# 310
} 
# 312
template<> inline cudaChannelFormatDesc cudaCreateChannelDesc< uint4> () 
# 313
{ 
# 314
int e = (((int)sizeof(unsigned)) * 8); 
# 316
return cudaCreateChannelDesc(e, e, e, e, cudaChannelFormatKindUnsigned); 
# 317
} 
# 379
template<> inline cudaChannelFormatDesc cudaCreateChannelDesc< float> () 
# 380
{ 
# 381
int e = (((int)sizeof(float)) * 8); 
# 383
return cudaCreateChannelDesc(e, 0, 0, 0, cudaChannelFormatKindFloat); 
# 384
} 
# 386
template<> inline cudaChannelFormatDesc cudaCreateChannelDesc< float1> () 
# 387
{ 
# 388
int e = (((int)sizeof(float)) * 8); 
# 390
return cudaCreateChannelDesc(e, 0, 0, 0, cudaChannelFormatKindFloat); 
# 391
} 
# 393
template<> inline cudaChannelFormatDesc cudaCreateChannelDesc< float2> () 
# 394
{ 
# 395
int e = (((int)sizeof(float)) * 8); 
# 397
return cudaCreateChannelDesc(e, e, 0, 0, cudaChannelFormatKindFloat); 
# 398
} 
# 400
template<> inline cudaChannelFormatDesc cudaCreateChannelDesc< float4> () 
# 401
{ 
# 402
int e = (((int)sizeof(float)) * 8); 
# 404
return cudaCreateChannelDesc(e, e, e, e, cudaChannelFormatKindFloat); 
# 405
} 
# 79 "/usr/local/cuda-8.0/include/driver_functions.h"
static inline cudaPitchedPtr make_cudaPitchedPtr(void *d, size_t p, size_t xsz, size_t ysz) 
# 80
{ 
# 81
cudaPitchedPtr s; 
# 83
(s.ptr) = d; 
# 84
(s.pitch) = p; 
# 85
(s.xsize) = xsz; 
# 86
(s.ysize) = ysz; 
# 88
return s; 
# 89
} 
# 106
static inline cudaPos make_cudaPos(size_t x, size_t y, size_t z) 
# 107
{ 
# 108
cudaPos p; 
# 110
(p.x) = x; 
# 111
(p.y) = y; 
# 112
(p.z) = z; 
# 114
return p; 
# 115
} 
# 132
static inline cudaExtent make_cudaExtent(size_t w, size_t h, size_t d) 
# 133
{ 
# 134
cudaExtent e; 
# 136
(e.width) = w; 
# 137
(e.height) = h; 
# 138
(e.depth) = d; 
# 140
return e; 
# 141
} 
# 75 "/usr/local/cuda-8.0/include/vector_functions.hpp"
static inline char1 make_char1(signed char x) 
# 76
{ 
# 77
char1 t; (t.x) = x; return t; 
# 78
} 
# 80
static inline uchar1 make_uchar1(unsigned char x) 
# 81
{ 
# 82
uchar1 t; (t.x) = x; return t; 
# 83
} 
# 85
static inline char2 make_char2(signed char x, signed char y) 
# 86
{ 
# 87
char2 t; (t.x) = x; (t.y) = y; return t; 
# 88
} 
# 90
static inline uchar2 make_uchar2(unsigned char x, unsigned char y) 
# 91
{ 
# 92
uchar2 t; (t.x) = x; (t.y) = y; return t; 
# 93
} 
# 95
static inline char3 make_char3(signed char x, signed char y, signed char z) 
# 96
{ 
# 97
char3 t; (t.x) = x; (t.y) = y; (t.z) = z; return t; 
# 98
} 
# 100
static inline uchar3 make_uchar3(unsigned char x, unsigned char y, unsigned char z) 
# 101
{ 
# 102
uchar3 t; (t.x) = x; (t.y) = y; (t.z) = z; return t; 
# 103
} 
# 105
static inline char4 make_char4(signed char x, signed char y, signed char z, signed char w) 
# 106
{ 
# 107
char4 t; (t.x) = x; (t.y) = y; (t.z) = z; (t.w) = w; return t; 
# 108
} 
# 110
static inline uchar4 make_uchar4(unsigned char x, unsigned char y, unsigned char z, unsigned char w) 
# 111
{ 
# 112
uchar4 t; (t.x) = x; (t.y) = y; (t.z) = z; (t.w) = w; return t; 
# 113
} 
# 115
static inline short1 make_short1(short x) 
# 116
{ 
# 117
short1 t; (t.x) = x; return t; 
# 118
} 
# 120
static inline ushort1 make_ushort1(unsigned short x) 
# 121
{ 
# 122
ushort1 t; (t.x) = x; return t; 
# 123
} 
# 125
static inline short2 make_short2(short x, short y) 
# 126
{ 
# 127
short2 t; (t.x) = x; (t.y) = y; return t; 
# 128
} 
# 130
static inline ushort2 make_ushort2(unsigned short x, unsigned short y) 
# 131
{ 
# 132
ushort2 t; (t.x) = x; (t.y) = y; return t; 
# 133
} 
# 135
static inline short3 make_short3(short x, short y, short z) 
# 136
{ 
# 137
short3 t; (t.x) = x; (t.y) = y; (t.z) = z; return t; 
# 138
} 
# 140
static inline ushort3 make_ushort3(unsigned short x, unsigned short y, unsigned short z) 
# 141
{ 
# 142
ushort3 t; (t.x) = x; (t.y) = y; (t.z) = z; return t; 
# 143
} 
# 145
static inline short4 make_short4(short x, short y, short z, short w) 
# 146
{ 
# 147
short4 t; (t.x) = x; (t.y) = y; (t.z) = z; (t.w) = w; return t; 
# 148
} 
# 150
static inline ushort4 make_ushort4(unsigned short x, unsigned short y, unsigned short z, unsigned short w) 
# 151
{ 
# 152
ushort4 t; (t.x) = x; (t.y) = y; (t.z) = z; (t.w) = w; return t; 
# 153
} 
# 155
static inline int1 make_int1(int x) 
# 156
{ 
# 157
int1 t; (t.x) = x; return t; 
# 158
} 
# 160
static inline uint1 make_uint1(unsigned x) 
# 161
{ 
# 162
uint1 t; (t.x) = x; return t; 
# 163
} 
# 165
static inline int2 make_int2(int x, int y) 
# 166
{ 
# 167
int2 t; (t.x) = x; (t.y) = y; return t; 
# 168
} 
# 170
static inline uint2 make_uint2(unsigned x, unsigned y) 
# 171
{ 
# 172
uint2 t; (t.x) = x; (t.y) = y; return t; 
# 173
} 
# 175
static inline int3 make_int3(int x, int y, int z) 
# 176
{ 
# 177
int3 t; (t.x) = x; (t.y) = y; (t.z) = z; return t; 
# 178
} 
# 180
static inline uint3 make_uint3(unsigned x, unsigned y, unsigned z) 
# 181
{ 
# 182
uint3 t; (t.x) = x; (t.y) = y; (t.z) = z; return t; 
# 183
} 
# 185
static inline int4 make_int4(int x, int y, int z, int w) 
# 186
{ 
# 187
int4 t; (t.x) = x; (t.y) = y; (t.z) = z; (t.w) = w; return t; 
# 188
} 
# 190
static inline uint4 make_uint4(unsigned x, unsigned y, unsigned z, unsigned w) 
# 191
{ 
# 192
uint4 t; (t.x) = x; (t.y) = y; (t.z) = z; (t.w) = w; return t; 
# 193
} 
# 195
static inline long1 make_long1(long x) 
# 196
{ 
# 197
long1 t; (t.x) = x; return t; 
# 198
} 
# 200
static inline ulong1 make_ulong1(unsigned long x) 
# 201
{ 
# 202
ulong1 t; (t.x) = x; return t; 
# 203
} 
# 205
static inline long2 make_long2(long x, long y) 
# 206
{ 
# 207
long2 t; (t.x) = x; (t.y) = y; return t; 
# 208
} 
# 210
static inline ulong2 make_ulong2(unsigned long x, unsigned long y) 
# 211
{ 
# 212
ulong2 t; (t.x) = x; (t.y) = y; return t; 
# 213
} 
# 215
static inline long3 make_long3(long x, long y, long z) 
# 216
{ 
# 217
long3 t; (t.x) = x; (t.y) = y; (t.z) = z; return t; 
# 218
} 
# 220
static inline ulong3 make_ulong3(unsigned long x, unsigned long y, unsigned long z) 
# 221
{ 
# 222
ulong3 t; (t.x) = x; (t.y) = y; (t.z) = z; return t; 
# 223
} 
# 225
static inline long4 make_long4(long x, long y, long z, long w) 
# 226
{ 
# 227
long4 t; (t.x) = x; (t.y) = y; (t.z) = z; (t.w) = w; return t; 
# 228
} 
# 230
static inline ulong4 make_ulong4(unsigned long x, unsigned long y, unsigned long z, unsigned long w) 
# 231
{ 
# 232
ulong4 t; (t.x) = x; (t.y) = y; (t.z) = z; (t.w) = w; return t; 
# 233
} 
# 235
static inline float1 make_float1(float x) 
# 236
{ 
# 237
float1 t; (t.x) = x; return t; 
# 238
} 
# 240
static inline float2 make_float2(float x, float y) 
# 241
{ 
# 242
float2 t; (t.x) = x; (t.y) = y; return t; 
# 243
} 
# 245
static inline float3 make_float3(float x, float y, float z) 
# 246
{ 
# 247
float3 t; (t.x) = x; (t.y) = y; (t.z) = z; return t; 
# 248
} 
# 250
static inline float4 make_float4(float x, float y, float z, float w) 
# 251
{ 
# 252
float4 t; (t.x) = x; (t.y) = y; (t.z) = z; (t.w) = w; return t; 
# 253
} 
# 255
static inline longlong1 make_longlong1(long long x) 
# 256
{ 
# 257
longlong1 t; (t.x) = x; return t; 
# 258
} 
# 260
static inline ulonglong1 make_ulonglong1(unsigned long long x) 
# 261
{ 
# 262
ulonglong1 t; (t.x) = x; return t; 
# 263
} 
# 265
static inline longlong2 make_longlong2(long long x, long long y) 
# 266
{ 
# 267
longlong2 t; (t.x) = x; (t.y) = y; return t; 
# 268
} 
# 270
static inline ulonglong2 make_ulonglong2(unsigned long long x, unsigned long long y) 
# 271
{ 
# 272
ulonglong2 t; (t.x) = x; (t.y) = y; return t; 
# 273
} 
# 275
static inline longlong3 make_longlong3(long long x, long long y, long long z) 
# 276
{ 
# 277
longlong3 t; (t.x) = x; (t.y) = y; (t.z) = z; return t; 
# 278
} 
# 280
static inline ulonglong3 make_ulonglong3(unsigned long long x, unsigned long long y, unsigned long long z) 
# 281
{ 
# 282
ulonglong3 t; (t.x) = x; (t.y) = y; (t.z) = z; return t; 
# 283
} 
# 285
static inline longlong4 make_longlong4(long long x, long long y, long long z, long long w) 
# 286
{ 
# 287
longlong4 t; (t.x) = x; (t.y) = y; (t.z) = z; (t.w) = w; return t; 
# 288
} 
# 290
static inline ulonglong4 make_ulonglong4(unsigned long long x, unsigned long long y, unsigned long long z, unsigned long long w) 
# 291
{ 
# 292
ulonglong4 t; (t.x) = x; (t.y) = y; (t.z) = z; (t.w) = w; return t; 
# 293
} 
# 295
static inline double1 make_double1(double x) 
# 296
{ 
# 297
double1 t; (t.x) = x; return t; 
# 298
} 
# 300
static inline double2 make_double2(double x, double y) 
# 301
{ 
# 302
double2 t; (t.x) = x; (t.y) = y; return t; 
# 303
} 
# 305
static inline double3 make_double3(double x, double y, double z) 
# 306
{ 
# 307
double3 t; (t.x) = x; (t.y) = y; (t.z) = z; return t; 
# 308
} 
# 310
static inline double4 make_double4(double x, double y, double z, double w) 
# 311
{ 
# 312
double4 t; (t.x) = x; (t.y) = y; (t.z) = z; (t.w) = w; return t; 
# 313
} 
# 27 "/usr/include/string.h" 3
extern "C" {
# 42
extern void *memcpy(void *__restrict__ __dest, const void *__restrict__ __src, size_t __n) throw()
# 43
 __attribute((__nonnull__(1, 2))); 
# 46
extern void *memmove(void * __dest, const void * __src, size_t __n) throw()
# 47
 __attribute((__nonnull__(1, 2))); 
# 54
extern void *memccpy(void *__restrict__ __dest, const void *__restrict__ __src, int __c, size_t __n) throw()
# 56
 __attribute((__nonnull__(1, 2))); 
# 62
extern void *memset(void * __s, int __c, size_t __n) throw() __attribute((__nonnull__(1))); 
# 65
extern int memcmp(const void * __s1, const void * __s2, size_t __n) throw()
# 66
 __attribute((__pure__)) __attribute((__nonnull__(1, 2))); 
# 70
extern "C++" {
# 72
extern __attribute((gnu_inline)) inline void *memchr(void * __s, int __c, size_t __n) throw() __asm__("memchr")
# 73
 __attribute((__pure__)) __attribute((__nonnull__(1))); 
# 74
extern __attribute((gnu_inline)) inline const void *memchr(const void * __s, int __c, size_t __n) throw() __asm__("memchr")
# 75
 __attribute((__pure__)) __attribute((__nonnull__(1))); 
# 78
__attribute((__always_inline__)) __attribute((__gnu_inline__)) extern inline void *
# 79
memchr(void *__s, int __c, size_t __n) throw() 
# 80
{ 
# 81
return __builtin_memchr(__s, __c, __n); 
# 82
} 
# 84
__attribute((__always_inline__)) __attribute((__gnu_inline__)) extern inline const void *
# 85
memchr(const void *__s, int __c, size_t __n) throw() 
# 86
{ 
# 87
return __builtin_memchr(__s, __c, __n); 
# 88
} 
# 90
}
# 101
extern "C++" void *rawmemchr(void * __s, int __c) throw() __asm__("rawmemchr")
# 102
 __attribute((__pure__)) __attribute((__nonnull__(1))); 
# 103
extern "C++" const void *rawmemchr(const void * __s, int __c) throw() __asm__("rawmemchr")
# 104
 __attribute((__pure__)) __attribute((__nonnull__(1))); 
# 112
extern "C++" void *memrchr(void * __s, int __c, size_t __n) throw() __asm__("memrchr")
# 113
 __attribute((__pure__)) __attribute((__nonnull__(1))); 
# 114
extern "C++" const void *memrchr(const void * __s, int __c, size_t __n) throw() __asm__("memrchr")
# 115
 __attribute((__pure__)) __attribute((__nonnull__(1))); 
# 125
extern char *strcpy(char *__restrict__ __dest, const char *__restrict__ __src) throw()
# 126
 __attribute((__nonnull__(1, 2))); 
# 128
extern char *strncpy(char *__restrict__ __dest, const char *__restrict__ __src, size_t __n) throw()
# 130
 __attribute((__nonnull__(1, 2))); 
# 133
extern char *strcat(char *__restrict__ __dest, const char *__restrict__ __src) throw()
# 134
 __attribute((__nonnull__(1, 2))); 
# 136
extern char *strncat(char *__restrict__ __dest, const char *__restrict__ __src, size_t __n) throw()
# 137
 __attribute((__nonnull__(1, 2))); 
# 140
extern int strcmp(const char * __s1, const char * __s2) throw()
# 141
 __attribute((__pure__)) __attribute((__nonnull__(1, 2))); 
# 143
extern int strncmp(const char * __s1, const char * __s2, size_t __n) throw()
# 144
 __attribute((__pure__)) __attribute((__nonnull__(1, 2))); 
# 147
extern int strcoll(const char * __s1, const char * __s2) throw()
# 148
 __attribute((__pure__)) __attribute((__nonnull__(1, 2))); 
# 150
extern size_t strxfrm(char *__restrict__ __dest, const char *__restrict__ __src, size_t __n) throw()
# 152
 __attribute((__nonnull__(2))); 
# 39 "/usr/include/xlocale.h" 3
typedef 
# 27
struct __locale_struct { 
# 30
struct __locale_data *__locales[13]; 
# 33
const unsigned short *__ctype_b; 
# 34
const int *__ctype_tolower; 
# 35
const int *__ctype_toupper; 
# 38
const char *__names[13]; 
# 39
} *__locale_t; 
# 42
typedef __locale_t locale_t; 
# 162 "/usr/include/string.h" 3
extern int strcoll_l(const char * __s1, const char * __s2, __locale_t __l) throw()
# 163
 __attribute((__pure__)) __attribute((__nonnull__(1, 2, 3))); 
# 165
extern size_t strxfrm_l(char * __dest, const char * __src, size_t __n, __locale_t __l) throw()
# 166
 __attribute((__nonnull__(2, 4))); 
# 172
extern char *strdup(const char * __s) throw()
# 173
 __attribute((__malloc__)) __attribute((__nonnull__(1))); 
# 180
extern char *strndup(const char * __string, size_t __n) throw()
# 181
 __attribute((__malloc__)) __attribute((__nonnull__(1))); 
# 210
extern "C++" {
# 212
extern __attribute((gnu_inline)) inline char *strchr(char * __s, int __c) throw() __asm__("strchr")
# 213
 __attribute((__pure__)) __attribute((__nonnull__(1))); 
# 214
extern __attribute((gnu_inline)) inline const char *strchr(const char * __s, int __c) throw() __asm__("strchr")
# 215
 __attribute((__pure__)) __attribute((__nonnull__(1))); 
# 218
__attribute((__always_inline__)) __attribute((__gnu_inline__)) extern inline char *
# 219
strchr(char *__s, int __c) throw() 
# 220
{ 
# 221
return __builtin_strchr(__s, __c); 
# 222
} 
# 224
__attribute((__always_inline__)) __attribute((__gnu_inline__)) extern inline const char *
# 225
strchr(const char *__s, int __c) throw() 
# 226
{ 
# 227
return __builtin_strchr(__s, __c); 
# 228
} 
# 230
}
# 237
extern "C++" {
# 239
extern __attribute((gnu_inline)) inline char *strrchr(char * __s, int __c) throw() __asm__("strrchr")
# 240
 __attribute((__pure__)) __attribute((__nonnull__(1))); 
# 241
extern __attribute((gnu_inline)) inline const char *strrchr(const char * __s, int __c) throw() __asm__("strrchr")
# 242
 __attribute((__pure__)) __attribute((__nonnull__(1))); 
# 245
__attribute((__always_inline__)) __attribute((__gnu_inline__)) extern inline char *
# 246
strrchr(char *__s, int __c) throw() 
# 247
{ 
# 248
return __builtin_strrchr(__s, __c); 
# 249
} 
# 251
__attribute((__always_inline__)) __attribute((__gnu_inline__)) extern inline const char *
# 252
strrchr(const char *__s, int __c) throw() 
# 253
{ 
# 254
return __builtin_strrchr(__s, __c); 
# 255
} 
# 257
}
# 268
extern "C++" char *strchrnul(char * __s, int __c) throw() __asm__("strchrnul")
# 269
 __attribute((__pure__)) __attribute((__nonnull__(1))); 
# 270
extern "C++" const char *strchrnul(const char * __s, int __c) throw() __asm__("strchrnul")
# 271
 __attribute((__pure__)) __attribute((__nonnull__(1))); 
# 281
extern size_t strcspn(const char * __s, const char * __reject) throw()
# 282
 __attribute((__pure__)) __attribute((__nonnull__(1, 2))); 
# 285
extern size_t strspn(const char * __s, const char * __accept) throw()
# 286
 __attribute((__pure__)) __attribute((__nonnull__(1, 2))); 
# 289
extern "C++" {
# 291
extern __attribute((gnu_inline)) inline char *strpbrk(char * __s, const char * __accept) throw() __asm__("strpbrk")
# 292
 __attribute((__pure__)) __attribute((__nonnull__(1, 2))); 
# 293
extern __attribute((gnu_inline)) inline const char *strpbrk(const char * __s, const char * __accept) throw() __asm__("strpbrk")
# 294
 __attribute((__pure__)) __attribute((__nonnull__(1, 2))); 
# 297
__attribute((__always_inline__)) __attribute((__gnu_inline__)) extern inline char *
# 298
strpbrk(char *__s, const char *__accept) throw() 
# 299
{ 
# 300
return __builtin_strpbrk(__s, __accept); 
# 301
} 
# 303
__attribute((__always_inline__)) __attribute((__gnu_inline__)) extern inline const char *
# 304
strpbrk(const char *__s, const char *__accept) throw() 
# 305
{ 
# 306
return __builtin_strpbrk(__s, __accept); 
# 307
} 
# 309
}
# 316
extern "C++" {
# 318
extern __attribute((gnu_inline)) inline char *strstr(char * __haystack, const char * __needle) throw() __asm__("strstr")
# 319
 __attribute((__pure__)) __attribute((__nonnull__(1, 2))); 
# 320
extern __attribute((gnu_inline)) inline const char *strstr(const char * __haystack, const char * __needle) throw() __asm__("strstr")
# 321
 __attribute((__pure__)) __attribute((__nonnull__(1, 2))); 
# 324
__attribute((__always_inline__)) __attribute((__gnu_inline__)) extern inline char *
# 325
strstr(char *__haystack, const char *__needle) throw() 
# 326
{ 
# 327
return __builtin_strstr(__haystack, __needle); 
# 328
} 
# 330
__attribute((__always_inline__)) __attribute((__gnu_inline__)) extern inline const char *
# 331
strstr(const char *__haystack, const char *__needle) throw() 
# 332
{ 
# 333
return __builtin_strstr(__haystack, __needle); 
# 334
} 
# 336
}
# 344
extern char *strtok(char *__restrict__ __s, const char *__restrict__ __delim) throw()
# 345
 __attribute((__nonnull__(2))); 
# 350
extern char *__strtok_r(char *__restrict__ __s, const char *__restrict__ __delim, char **__restrict__ __save_ptr) throw()
# 353
 __attribute((__nonnull__(2, 3))); 
# 355
extern char *strtok_r(char *__restrict__ __s, const char *__restrict__ __delim, char **__restrict__ __save_ptr) throw()
# 357
 __attribute((__nonnull__(2, 3))); 
# 363
extern "C++" char *strcasestr(char * __haystack, const char * __needle) throw() __asm__("strcasestr")
# 364
 __attribute((__pure__)) __attribute((__nonnull__(1, 2))); 
# 365
extern "C++" const char *strcasestr(const char * __haystack, const char * __needle) throw() __asm__("strcasestr")
# 367
 __attribute((__pure__)) __attribute((__nonnull__(1, 2))); 
# 378
extern void *memmem(const void * __haystack, size_t __haystacklen, const void * __needle, size_t __needlelen) throw()
# 380
 __attribute((__pure__)) __attribute((__nonnull__(1, 3))); 
# 384
extern void *__mempcpy(void *__restrict__ __dest, const void *__restrict__ __src, size_t __n) throw()
# 386
 __attribute((__nonnull__(1, 2))); 
# 387
extern void *mempcpy(void *__restrict__ __dest, const void *__restrict__ __src, size_t __n) throw()
# 389
 __attribute((__nonnull__(1, 2))); 
# 395
extern size_t strlen(const char * __s) throw()
# 396
 __attribute((__pure__)) __attribute((__nonnull__(1))); 
# 402
extern size_t strnlen(const char * __string, size_t __maxlen) throw()
# 403
 __attribute((__pure__)) __attribute((__nonnull__(1))); 
# 409
extern char *strerror(int __errnum) throw(); 
# 434
extern char *strerror_r(int __errnum, char * __buf, size_t __buflen) throw()
# 435
 __attribute((__nonnull__(2))); 
# 441
extern char *strerror_l(int __errnum, __locale_t __l) throw(); 
# 447
extern void __bzero(void * __s, size_t __n) throw() __attribute((__nonnull__(1))); 
# 451
extern void bcopy(const void * __src, void * __dest, size_t __n) throw()
# 452
 __attribute((__nonnull__(1, 2))); 
# 455
extern void bzero(void * __s, size_t __n) throw() __attribute((__nonnull__(1))); 
# 458
extern int bcmp(const void * __s1, const void * __s2, size_t __n) throw()
# 459
 __attribute((__pure__)) __attribute((__nonnull__(1, 2))); 
# 463
extern "C++" {
# 465
extern __attribute((gnu_inline)) inline char *index(char * __s, int __c) throw() __asm__("index")
# 466
 __attribute((__pure__)) __attribute((__nonnull__(1))); 
# 467
extern __attribute((gnu_inline)) inline const char *index(const char * __s, int __c) throw() __asm__("index")
# 468
 __attribute((__pure__)) __attribute((__nonnull__(1))); 
# 471
__attribute((__always_inline__)) __attribute((__gnu_inline__)) extern inline char *
# 472
index(char *__s, int __c) throw() 
# 473
{ 
# 474
return __builtin_index(__s, __c); 
# 475
} 
# 477
__attribute((__always_inline__)) __attribute((__gnu_inline__)) extern inline const char *
# 478
index(const char *__s, int __c) throw() 
# 479
{ 
# 480
return __builtin_index(__s, __c); 
# 481
} 
# 483
}
# 491
extern "C++" {
# 493
extern __attribute((gnu_inline)) inline char *rindex(char * __s, int __c) throw() __asm__("rindex")
# 494
 __attribute((__pure__)) __attribute((__nonnull__(1))); 
# 495
extern __attribute((gnu_inline)) inline const char *rindex(const char * __s, int __c) throw() __asm__("rindex")
# 496
 __attribute((__pure__)) __attribute((__nonnull__(1))); 
# 499
__attribute((__always_inline__)) __attribute((__gnu_inline__)) extern inline char *
# 500
rindex(char *__s, int __c) throw() 
# 501
{ 
# 502
return __builtin_rindex(__s, __c); 
# 503
} 
# 505
__attribute((__always_inline__)) __attribute((__gnu_inline__)) extern inline const char *
# 506
rindex(const char *__s, int __c) throw() 
# 507
{ 
# 508
return __builtin_rindex(__s, __c); 
# 509
} 
# 511
}
# 519
extern int ffs(int __i) throw() __attribute((const)); 
# 524
extern int ffsl(long __l) throw() __attribute((const)); 
# 526
__extension__ extern int ffsll(long long __ll) throw()
# 527
 __attribute((const)); 
# 532
extern int strcasecmp(const char * __s1, const char * __s2) throw()
# 533
 __attribute((__pure__)) __attribute((__nonnull__(1, 2))); 
# 536
extern int strncasecmp(const char * __s1, const char * __s2, size_t __n) throw()
# 537
 __attribute((__pure__)) __attribute((__nonnull__(1, 2))); 
# 543
extern int strcasecmp_l(const char * __s1, const char * __s2, __locale_t __loc) throw()
# 545
 __attribute((__pure__)) __attribute((__nonnull__(1, 2, 3))); 
# 547
extern int strncasecmp_l(const char * __s1, const char * __s2, size_t __n, __locale_t __loc) throw()
# 549
 __attribute((__pure__)) __attribute((__nonnull__(1, 2, 4))); 
# 555
extern char *strsep(char **__restrict__ __stringp, const char *__restrict__ __delim) throw()
# 557
 __attribute((__nonnull__(1, 2))); 
# 562
extern char *strsignal(int __sig) throw(); 
# 565
extern char *__stpcpy(char *__restrict__ __dest, const char *__restrict__ __src) throw()
# 566
 __attribute((__nonnull__(1, 2))); 
# 567
extern char *stpcpy(char *__restrict__ __dest, const char *__restrict__ __src) throw()
# 568
 __attribute((__nonnull__(1, 2))); 
# 572
extern char *__stpncpy(char *__restrict__ __dest, const char *__restrict__ __src, size_t __n) throw()
# 574
 __attribute((__nonnull__(1, 2))); 
# 575
extern char *stpncpy(char *__restrict__ __dest, const char *__restrict__ __src, size_t __n) throw()
# 577
 __attribute((__nonnull__(1, 2))); 
# 582
extern int strverscmp(const char * __s1, const char * __s2) throw()
# 583
 __attribute((__pure__)) __attribute((__nonnull__(1, 2))); 
# 586
extern char *strfry(char * __string) throw() __attribute((__nonnull__(1))); 
# 589
extern void *memfrob(void * __s, size_t __n) throw() __attribute((__nonnull__(1))); 
# 597
extern "C++" char *basename(char * __filename) throw() __asm__("basename")
# 598
 __attribute((__nonnull__(1))); 
# 599
extern "C++" const char *basename(const char * __filename) throw() __asm__("basename")
# 600
 __attribute((__nonnull__(1))); 
# 642
}
# 29 "/usr/include/time.h" 3
extern "C" {
# 30 "/usr/include/bits/types.h" 3
typedef unsigned char __u_char; 
# 31
typedef unsigned short __u_short; 
# 32
typedef unsigned __u_int; 
# 33
typedef unsigned long __u_long; 
# 36
typedef signed char __int8_t; 
# 37
typedef unsigned char __uint8_t; 
# 38
typedef signed short __int16_t; 
# 39
typedef unsigned short __uint16_t; 
# 40
typedef signed int __int32_t; 
# 41
typedef unsigned __uint32_t; 
# 43
typedef signed long __int64_t; 
# 44
typedef unsigned long __uint64_t; 
# 52
typedef long __quad_t; 
# 53
typedef unsigned long __u_quad_t; 
# 133
typedef unsigned long __dev_t; 
# 134
typedef unsigned __uid_t; 
# 135
typedef unsigned __gid_t; 
# 136
typedef unsigned long __ino_t; 
# 137
typedef unsigned long __ino64_t; 
# 138
typedef unsigned __mode_t; 
# 139
typedef unsigned long __nlink_t; 
# 140
typedef long __off_t; 
# 141
typedef long __off64_t; 
# 142
typedef int __pid_t; 
# 143
typedef struct { int __val[2]; } __fsid_t; 
# 144
typedef long __clock_t; 
# 145
typedef unsigned long __rlim_t; 
# 146
typedef unsigned long __rlim64_t; 
# 147
typedef unsigned __id_t; 
# 148
typedef long __time_t; 
# 149
typedef unsigned __useconds_t; 
# 150
typedef long __suseconds_t; 
# 152
typedef int __daddr_t; 
# 153
typedef int __key_t; 
# 156
typedef int __clockid_t; 
# 159
typedef void *__timer_t; 
# 162
typedef long __blksize_t; 
# 167
typedef long __blkcnt_t; 
# 168
typedef long __blkcnt64_t; 
# 171
typedef unsigned long __fsblkcnt_t; 
# 172
typedef unsigned long __fsblkcnt64_t; 
# 175
typedef unsigned long __fsfilcnt_t; 
# 176
typedef unsigned long __fsfilcnt64_t; 
# 179
typedef long __fsword_t; 
# 181
typedef long __ssize_t; 
# 184
typedef long __syscall_slong_t; 
# 186
typedef unsigned long __syscall_ulong_t; 
# 190
typedef __off64_t __loff_t; 
# 191
typedef __quad_t *__qaddr_t; 
# 192
typedef char *__caddr_t; 
# 195
typedef long __intptr_t; 
# 198
typedef unsigned __socklen_t; 
# 30 "/usr/include/bits/time.h" 3
struct timeval { 
# 32
__time_t tv_sec; 
# 33
__suseconds_t tv_usec; 
# 34
}; 
# 25 "/usr/include/bits/timex.h" 3
struct timex { 
# 27
unsigned modes; 
# 28
__syscall_slong_t offset; 
# 29
__syscall_slong_t freq; 
# 30
__syscall_slong_t maxerror; 
# 31
__syscall_slong_t esterror; 
# 32
int status; 
# 33
__syscall_slong_t constant; 
# 34
__syscall_slong_t precision; 
# 35
__syscall_slong_t tolerance; 
# 36
timeval time; 
# 37
__syscall_slong_t tick; 
# 38
__syscall_slong_t ppsfreq; 
# 39
__syscall_slong_t jitter; 
# 40
int shift; 
# 41
__syscall_slong_t stabil; 
# 42
__syscall_slong_t jitcnt; 
# 43
__syscall_slong_t calcnt; 
# 44
__syscall_slong_t errcnt; 
# 45
__syscall_slong_t stbcnt; 
# 47
int tai; 
# 50
int:32; int:32; int:32; int:32; 
# 51
int:32; int:32; int:32; int:32; 
# 52
int:32; int:32; int:32; 
# 53
}; 
# 88 "/usr/include/bits/time.h" 3
extern "C" {
# 91
extern int clock_adjtime(__clockid_t __clock_id, timex * __utx) throw(); 
# 93
}
# 59 "/usr/include/time.h" 3
typedef __clock_t clock_t; 
# 75
typedef __time_t time_t; 
# 91
typedef __clockid_t clockid_t; 
# 103
typedef __timer_t timer_t; 
# 120
struct timespec { 
# 122
__time_t tv_sec; 
# 123
__syscall_slong_t tv_nsec; 
# 124
}; 
# 133
struct tm { 
# 135
int tm_sec; 
# 136
int tm_min; 
# 137
int tm_hour; 
# 138
int tm_mday; 
# 139
int tm_mon; 
# 140
int tm_year; 
# 141
int tm_wday; 
# 142
int tm_yday; 
# 143
int tm_isdst; 
# 146
long tm_gmtoff; 
# 147
const char *tm_zone; 
# 152
}; 
# 161
struct itimerspec { 
# 163
timespec it_interval; 
# 164
timespec it_value; 
# 165
}; 
# 168
struct sigevent; 
# 174
typedef __pid_t pid_t; 
# 189
extern clock_t clock() throw(); 
# 192
extern time_t time(time_t * __timer) throw(); 
# 195
extern double difftime(time_t __time1, time_t __time0) throw()
# 196
 __attribute((const)); 
# 199
extern time_t mktime(tm * __tp) throw(); 
# 205
extern size_t strftime(char *__restrict__ __s, size_t __maxsize, const char *__restrict__ __format, const tm *__restrict__ __tp) throw(); 
# 213
extern char *strptime(const char *__restrict__ __s, const char *__restrict__ __fmt, tm * __tp) throw(); 
# 223
extern size_t strftime_l(char *__restrict__ __s, size_t __maxsize, const char *__restrict__ __format, const tm *__restrict__ __tp, __locale_t __loc) throw(); 
# 230
extern char *strptime_l(const char *__restrict__ __s, const char *__restrict__ __fmt, tm * __tp, __locale_t __loc) throw(); 
# 239
extern tm *gmtime(const time_t * __timer) throw(); 
# 243
extern tm *localtime(const time_t * __timer) throw(); 
# 249
extern tm *gmtime_r(const time_t *__restrict__ __timer, tm *__restrict__ __tp) throw(); 
# 254
extern tm *localtime_r(const time_t *__restrict__ __timer, tm *__restrict__ __tp) throw(); 
# 261
extern char *asctime(const tm * __tp) throw(); 
# 264
extern char *ctime(const time_t * __timer) throw(); 
# 272
extern char *asctime_r(const tm *__restrict__ __tp, char *__restrict__ __buf) throw(); 
# 276
extern char *ctime_r(const time_t *__restrict__ __timer, char *__restrict__ __buf) throw(); 
# 282
extern char *__tzname[2]; 
# 283
extern int __daylight; 
# 284
extern long __timezone; 
# 289
extern char *tzname[2]; 
# 293
extern void tzset() throw(); 
# 297
extern int daylight; 
# 298
extern long timezone; 
# 304
extern int stime(const time_t * __when) throw(); 
# 319
extern time_t timegm(tm * __tp) throw(); 
# 322
extern time_t timelocal(tm * __tp) throw(); 
# 325
extern int dysize(int __year) throw() __attribute((const)); 
# 334
extern int nanosleep(const timespec * __requested_time, timespec * __remaining); 
# 339
extern int clock_getres(clockid_t __clock_id, timespec * __res) throw(); 
# 342
extern int clock_gettime(clockid_t __clock_id, timespec * __tp) throw(); 
# 345
extern int clock_settime(clockid_t __clock_id, const timespec * __tp) throw(); 
# 353
extern int clock_nanosleep(clockid_t __clock_id, int __flags, const timespec * __req, timespec * __rem); 
# 358
extern int clock_getcpuclockid(pid_t __pid, clockid_t * __clock_id) throw(); 
# 363
extern int timer_create(clockid_t __clock_id, sigevent *__restrict__ __evp, timer_t *__restrict__ __timerid) throw(); 
# 368
extern int timer_delete(timer_t __timerid) throw(); 
# 371
extern int timer_settime(timer_t __timerid, int __flags, const itimerspec *__restrict__ __value, itimerspec *__restrict__ __ovalue) throw(); 
# 376
extern int timer_gettime(timer_t __timerid, itimerspec * __value) throw(); 
# 380
extern int timer_getoverrun(timer_t __timerid) throw(); 
# 386
extern int timespec_get(timespec * __ts, int __base) throw()
# 387
 __attribute((__nonnull__(1))); 
# 403
extern int getdate_err; 
# 412
extern tm *getdate(const char * __string); 
# 426
extern int getdate_r(const char *__restrict__ __string, tm *__restrict__ __resbufp); 
# 430
}
# 68 "/usr/local/cuda-8.0/include/common_functions.h"
extern "C" {
# 71
extern clock_t clock() throw(); 
# 72
extern void *memset(void *, int, size_t) throw(); 
# 73
extern void *memcpy(void *, const void *, size_t) throw(); 
# 75
}
# 93 "/usr/local/cuda-8.0/include/math_functions.h"
extern "C" {
# 164
extern int abs(int) throw(); 
# 165
extern long labs(long) throw(); 
# 166
extern long long llabs(long long) throw(); 
# 216
extern double fabs(double x) throw(); 
# 257
extern float fabsf(float x) throw(); 
# 261
extern inline int min(int, int); 
# 263
extern inline unsigned umin(unsigned, unsigned); 
# 264
extern inline long long llmin(long long, long long); 
# 265
extern inline unsigned long long ullmin(unsigned long long, unsigned long long); 
# 286
extern float fminf(float x, float y) throw(); 
# 306
extern double fmin(double x, double y) throw(); 
# 313
extern inline int max(int, int); 
# 315
extern inline unsigned umax(unsigned, unsigned); 
# 316
extern inline long long llmax(long long, long long); 
# 317
extern inline unsigned long long ullmax(unsigned long long, unsigned long long); 
# 338
extern float fmaxf(float x, float y) throw(); 
# 358
extern double fmax(double, double) throw(); 
# 402
extern double sin(double x) throw(); 
# 435
extern double cos(double x) throw(); 
# 454
extern void sincos(double x, double * sptr, double * cptr) throw(); 
# 470
extern void sincosf(float x, float * sptr, float * cptr) throw(); 
# 515
extern double tan(double x) throw(); 
# 584
extern double sqrt(double x) throw(); 
# 656
extern double rsqrt(double x); 
# 726
extern float rsqrtf(float x); 
# 782
extern double log2(double x) throw(); 
# 807
extern double exp2(double x) throw(); 
# 832
extern float exp2f(float x) throw(); 
# 859
extern double exp10(double x) throw(); 
# 882
extern float exp10f(float x) throw(); 
# 928
extern double expm1(double x) throw(); 
# 973
extern float expm1f(float x) throw(); 
# 1028
extern float log2f(float x) throw(); 
# 1082
extern double log10(double x) throw(); 
# 1153
extern double log(double x) throw(); 
# 1247
extern double log1p(double x) throw(); 
# 1344
extern float log1pf(float x) throw(); 
# 1419
extern double floor(double x) throw(); 
# 1458
extern double exp(double x) throw(); 
# 1489
extern double cosh(double x) throw(); 
# 1519
extern double sinh(double x) throw(); 
# 1549
extern double tanh(double x) throw(); 
# 1584
extern double acosh(double x) throw(); 
# 1622
extern float acoshf(float x) throw(); 
# 1638
extern double asinh(double x) throw(); 
# 1654
extern float asinhf(float x) throw(); 
# 1708
extern double atanh(double x) throw(); 
# 1762
extern float atanhf(float x) throw(); 
# 1821
extern double ldexp(double x, int exp) throw(); 
# 1877
extern float ldexpf(float x, int exp) throw(); 
# 1929
extern double logb(double x) throw(); 
# 1984
extern float logbf(float x) throw(); 
# 2014
extern int ilogb(double x) throw(); 
# 2044
extern int ilogbf(float x) throw(); 
# 2120
extern double scalbn(double x, int n) throw(); 
# 2196
extern float scalbnf(float x, int n) throw(); 
# 2272
extern double scalbln(double x, long n) throw(); 
# 2348
extern float scalblnf(float x, long n) throw(); 
# 2426
extern double frexp(double x, int * nptr) throw(); 
# 2501
extern float frexpf(float x, int * nptr) throw(); 
# 2515
extern double round(double x) throw(); 
# 2532
extern float roundf(float x) throw(); 
# 2550
extern long lround(double x) throw(); 
# 2568
extern long lroundf(float x) throw(); 
# 2586
extern long long llround(double x) throw(); 
# 2604
extern long long llroundf(float x) throw(); 
# 2656
extern float rintf(float x) throw(); 
# 2672
extern long lrint(double x) throw(); 
# 2688
extern long lrintf(float x) throw(); 
# 2704
extern long long llrint(double x) throw(); 
# 2720
extern long long llrintf(float x) throw(); 
# 2773
extern double nearbyint(double x) throw(); 
# 2826
extern float nearbyintf(float x) throw(); 
# 2888
extern double ceil(double x) throw(); 
# 2900
extern double trunc(double x) throw(); 
# 2915
extern float truncf(float x) throw(); 
# 2941
extern __attribute((gnu_inline)) inline double fdim(double x, double y) throw(); 
# 2967
extern __attribute((gnu_inline)) inline float fdimf(float x, float y) throw(); 
# 3003
extern double atan2(double y, double x) throw(); 
# 3034
extern double atan(double x) throw(); 
# 3057
extern double acos(double x) throw(); 
# 3089
extern double asin(double x) throw(); 
# 3135
extern double hypot(double x, double y) throw(); 
# 3187
extern double rhypot(double x, double y) throw(); 
# 3233
extern float hypotf(float x, float y) throw(); 
# 3285
extern float rhypotf(float x, float y) throw(); 
# 3332
extern double norm3d(double a, double b, double c) throw(); 
# 3383
extern double rnorm3d(double a, double b, double c) throw(); 
# 3432
extern double norm4d(double a, double b, double c, double d) throw(); 
# 3488
extern double rnorm4d(double a, double b, double c, double d) throw(); 
# 3533
extern double norm(int dim, const double * t) throw(); 
# 3584
extern double rnorm(int dim, const double * t) throw(); 
# 3636
extern float rnormf(int dim, const float * a) throw(); 
# 3680
extern float normf(int dim, const float * a) throw(); 
# 3725
extern float norm3df(float a, float b, float c) throw(); 
# 3776
extern float rnorm3df(float a, float b, float c) throw(); 
# 3825
extern float norm4df(float a, float b, float c, float d) throw(); 
# 3881
extern float rnorm4df(float a, float b, float c, float d) throw(); 
# 3965
extern double cbrt(double x) throw(); 
# 4051
extern float cbrtf(float x) throw(); 
# 4106
extern double rcbrt(double x); 
# 4156
extern float rcbrtf(float x); 
# 4216
extern double sinpi(double x); 
# 4276
extern float sinpif(float x); 
# 4328
extern double cospi(double x); 
# 4380
extern float cospif(float x); 
# 4410
extern void sincospi(double x, double * sptr, double * cptr); 
# 4440
extern void sincospif(float x, float * sptr, float * cptr); 
# 4752
extern double pow(double x, double y) throw(); 
# 4808
extern double modf(double x, double * iptr) throw(); 
# 4867
extern double fmod(double x, double y) throw(); 
# 4953
extern double remainder(double x, double y) throw(); 
# 5043
extern float remainderf(float x, float y) throw(); 
# 5097
extern double remquo(double x, double y, int * quo) throw(); 
# 5151
extern float remquof(float x, float y, int * quo) throw(); 
# 5192
extern double j0(double x) throw(); 
# 5234
extern float j0f(float x) throw(); 
# 5295
extern double j1(double x) throw(); 
# 5356
extern float j1f(float x) throw(); 
# 5399
extern double jn(int n, double x) throw(); 
# 5442
extern float jnf(int n, float x) throw(); 
# 5494
extern double y0(double x) throw(); 
# 5546
extern float y0f(float x) throw(); 
# 5598
extern double y1(double x) throw(); 
# 5650
extern float y1f(float x) throw(); 
# 5703
extern double yn(int n, double x) throw(); 
# 5756
extern float ynf(int n, float x) throw(); 
# 5783
extern double cyl_bessel_i0(double x) throw(); 
# 5809
extern float cyl_bessel_i0f(float x) throw(); 
# 5836
extern double cyl_bessel_i1(double x) throw(); 
# 5862
extern float cyl_bessel_i1f(float x) throw(); 
# 5945
extern double erf(double x) throw(); 
# 6027
extern float erff(float x) throw(); 
# 6091
extern double erfinv(double y); 
# 6148
extern float erfinvf(float y); 
# 6187
extern double erfc(double x) throw(); 
# 6225
extern float erfcf(float x) throw(); 
# 6353
extern double lgamma(double x) throw(); 
# 6416
extern double erfcinv(double y); 
# 6472
extern float erfcinvf(float y); 
# 6530
extern double normcdfinv(double y); 
# 6588
extern float normcdfinvf(float y); 
# 6631
extern double normcdf(double y); 
# 6674
extern float normcdff(float y); 
# 6749
extern double erfcx(double x); 
# 6824
extern float erfcxf(float x); 
# 6958
extern float lgammaf(float x) throw(); 
# 7067
extern double tgamma(double x) throw(); 
# 7176
extern float tgammaf(float x) throw(); 
# 7189
extern double copysign(double x, double y) throw(); 
# 7202
extern float copysignf(float x, float y) throw(); 
# 7239
extern double nextafter(double x, double y) throw(); 
# 7276
extern float nextafterf(float x, float y) throw(); 
# 7292
extern double nan(const char * tagp) throw(); 
# 7308
extern float nanf(const char * tagp) throw(); 
# 7315
extern int __isinff(float) throw(); 
# 7316
extern int __isnanf(float) throw(); 
# 7326
extern int __finite(double) throw(); 
# 7327
extern int __finitef(float) throw(); 
# 7328
extern __attribute((gnu_inline)) inline int __signbit(double) throw(); 
# 7329
extern int __isnan(double) throw(); 
# 7330
extern int __isinf(double) throw(); 
# 7333
extern __attribute((gnu_inline)) inline int __signbitf(float) throw(); 
# 7492
extern double fma(double x, double y, double z) throw(); 
# 7650
extern float fmaf(float x, float y, float z) throw(); 
# 7661
extern __attribute((gnu_inline)) inline int __signbitl(long double) throw(); 
# 7667
extern int __finitel(long double) throw(); 
# 7668
extern int __isinfl(long double) throw(); 
# 7669
extern int __isnanl(long double) throw(); 
# 7719
extern float acosf(float x) throw(); 
# 7759
extern float asinf(float x) throw(); 
# 7799
extern float atanf(float x) throw(); 
# 7832
extern float atan2f(float y, float x) throw(); 
# 7856
extern float cosf(float x) throw(); 
# 7898
extern float sinf(float x) throw(); 
# 7940
extern float tanf(float x) throw(); 
# 7964
extern float coshf(float x) throw(); 
# 8005
extern float sinhf(float x) throw(); 
# 8035
extern float tanhf(float x) throw(); 
# 8086
extern float logf(float x) throw(); 
# 8136
extern float expf(float x) throw(); 
# 8187
extern float log10f(float x) throw(); 
# 8242
extern float modff(float x, float * iptr) throw(); 
# 8550
extern float powf(float x, float y) throw(); 
# 8619
extern float sqrtf(float x) throw(); 
# 8678
extern float ceilf(float x) throw(); 
# 8750
extern float floorf(float x) throw(); 
# 8809
extern float fmodf(float x, float y) throw(); 
# 8823
}
# 29 "/usr/include/math.h" 3
extern "C" {
# 34 "/usr/include/bits/mathdef.h" 3
typedef float float_t; 
# 35
typedef double double_t; 
# 54 "/usr/include/bits/mathcalls.h" 3
extern double acos(double __x) throw(); extern double __acos(double __x) throw(); 
# 56
extern double asin(double __x) throw(); extern double __asin(double __x) throw(); 
# 58
extern double atan(double __x) throw(); extern double __atan(double __x) throw(); 
# 60
extern double atan2(double __y, double __x) throw(); extern double __atan2(double __y, double __x) throw(); 
# 63
extern double cos(double __x) throw(); extern double __cos(double __x) throw(); 
# 65
extern double sin(double __x) throw(); extern double __sin(double __x) throw(); 
# 67
extern double tan(double __x) throw(); extern double __tan(double __x) throw(); 
# 72
extern double cosh(double __x) throw(); extern double __cosh(double __x) throw(); 
# 74
extern double sinh(double __x) throw(); extern double __sinh(double __x) throw(); 
# 76
extern double tanh(double __x) throw(); extern double __tanh(double __x) throw(); 
# 81
extern void sincos(double __x, double * __sinx, double * __cosx) throw(); extern void __sincos(double __x, double * __sinx, double * __cosx) throw(); 
# 88
extern double acosh(double __x) throw(); extern double __acosh(double __x) throw(); 
# 90
extern double asinh(double __x) throw(); extern double __asinh(double __x) throw(); 
# 92
extern double atanh(double __x) throw(); extern double __atanh(double __x) throw(); 
# 100
extern double exp(double __x) throw(); extern double __exp(double __x) throw(); 
# 103
extern double frexp(double __x, int * __exponent) throw(); extern double __frexp(double __x, int * __exponent) throw(); 
# 106
extern double ldexp(double __x, int __exponent) throw(); extern double __ldexp(double __x, int __exponent) throw(); 
# 109
extern double log(double __x) throw(); extern double __log(double __x) throw(); 
# 112
extern double log10(double __x) throw(); extern double __log10(double __x) throw(); 
# 115
extern double modf(double __x, double * __iptr) throw(); extern double __modf(double __x, double * __iptr) throw()
# 116
 __attribute((__nonnull__(2))); 
# 121
extern double exp10(double __x) throw(); extern double __exp10(double __x) throw(); 
# 123
extern double pow10(double __x) throw(); extern double __pow10(double __x) throw(); 
# 129
extern double expm1(double __x) throw(); extern double __expm1(double __x) throw(); 
# 132
extern double log1p(double __x) throw(); extern double __log1p(double __x) throw(); 
# 135
extern double logb(double __x) throw(); extern double __logb(double __x) throw(); 
# 142
extern double exp2(double __x) throw(); extern double __exp2(double __x) throw(); 
# 145
extern double log2(double __x) throw(); extern double __log2(double __x) throw(); 
# 154
extern double pow(double __x, double __y) throw(); extern double __pow(double __x, double __y) throw(); 
# 157
extern double sqrt(double __x) throw(); extern double __sqrt(double __x) throw(); 
# 163
extern double hypot(double __x, double __y) throw(); extern double __hypot(double __x, double __y) throw(); 
# 170
extern double cbrt(double __x) throw(); extern double __cbrt(double __x) throw(); 
# 179
extern double ceil(double __x) throw() __attribute((const)); extern double __ceil(double __x) throw() __attribute((const)); 
# 182
extern double fabs(double __x) throw() __attribute((const)); extern double __fabs(double __x) throw() __attribute((const)); 
# 185
extern double floor(double __x) throw() __attribute((const)); extern double __floor(double __x) throw() __attribute((const)); 
# 188
extern double fmod(double __x, double __y) throw(); extern double __fmod(double __x, double __y) throw(); 
# 193
extern int __isinf(double __value) throw() __attribute((const)); 
# 196
extern int __finite(double __value) throw() __attribute((const)); 
# 202
extern inline int isinf(double __value) throw() __attribute((const)); 
# 205
extern int finite(double __value) throw() __attribute((const)); 
# 208
extern double drem(double __x, double __y) throw(); extern double __drem(double __x, double __y) throw(); 
# 212
extern double significand(double __x) throw(); extern double __significand(double __x) throw(); 
# 218
extern double copysign(double __x, double __y) throw() __attribute((const)); extern double __copysign(double __x, double __y) throw() __attribute((const)); 
# 225
extern double nan(const char * __tagb) throw() __attribute((const)); extern double __nan(const char * __tagb) throw() __attribute((const)); 
# 231
extern int __isnan(double __value) throw() __attribute((const)); 
# 235
extern inline int isnan(double __value) throw() __attribute((const)); 
# 238
extern double j0(double) throw(); extern double __j0(double) throw(); 
# 239
extern double j1(double) throw(); extern double __j1(double) throw(); 
# 240
extern double jn(int, double) throw(); extern double __jn(int, double) throw(); 
# 241
extern double y0(double) throw(); extern double __y0(double) throw(); 
# 242
extern double y1(double) throw(); extern double __y1(double) throw(); 
# 243
extern double yn(int, double) throw(); extern double __yn(int, double) throw(); 
# 250
extern double erf(double) throw(); extern double __erf(double) throw(); 
# 251
extern double erfc(double) throw(); extern double __erfc(double) throw(); 
# 252
extern double lgamma(double) throw(); extern double __lgamma(double) throw(); 
# 259
extern double tgamma(double) throw(); extern double __tgamma(double) throw(); 
# 265
extern double gamma(double) throw(); extern double __gamma(double) throw(); 
# 272
extern double lgamma_r(double, int * __signgamp) throw(); extern double __lgamma_r(double, int * __signgamp) throw(); 
# 280
extern double rint(double __x) throw(); extern double __rint(double __x) throw(); 
# 283
extern double nextafter(double __x, double __y) throw() __attribute((const)); extern double __nextafter(double __x, double __y) throw() __attribute((const)); 
# 285
extern double nexttoward(double __x, long double __y) throw() __attribute((const)); extern double __nexttoward(double __x, long double __y) throw() __attribute((const)); 
# 289
extern double remainder(double __x, double __y) throw(); extern double __remainder(double __x, double __y) throw(); 
# 293
extern double scalbn(double __x, int __n) throw(); extern double __scalbn(double __x, int __n) throw(); 
# 297
extern int ilogb(double __x) throw(); extern int __ilogb(double __x) throw(); 
# 302
extern double scalbln(double __x, long __n) throw(); extern double __scalbln(double __x, long __n) throw(); 
# 306
extern double nearbyint(double __x) throw(); extern double __nearbyint(double __x) throw(); 
# 310
extern double round(double __x) throw() __attribute((const)); extern double __round(double __x) throw() __attribute((const)); 
# 314
extern double trunc(double __x) throw() __attribute((const)); extern double __trunc(double __x) throw() __attribute((const)); 
# 319
extern double remquo(double __x, double __y, int * __quo) throw(); extern double __remquo(double __x, double __y, int * __quo) throw(); 
# 326
extern long lrint(double __x) throw(); extern long __lrint(double __x) throw(); 
# 327
extern long long llrint(double __x) throw(); extern long long __llrint(double __x) throw(); 
# 331
extern long lround(double __x) throw(); extern long __lround(double __x) throw(); 
# 332
extern long long llround(double __x) throw(); extern long long __llround(double __x) throw(); 
# 336
extern __attribute((gnu_inline)) inline double fdim(double __x, double __y) throw(); extern double __fdim(double __x, double __y) throw(); 
# 339
extern double fmax(double __x, double __y) throw() __attribute((const)); extern double __fmax(double __x, double __y) throw() __attribute((const)); 
# 342
extern double fmin(double __x, double __y) throw() __attribute((const)); extern double __fmin(double __x, double __y) throw() __attribute((const)); 
# 346
extern int __fpclassify(double __value) throw()
# 347
 __attribute((const)); 
# 350
extern __attribute((gnu_inline)) inline int __signbit(double __value) throw()
# 351
 __attribute((const)); 
# 355
extern double fma(double __x, double __y, double __z) throw(); extern double __fma(double __x, double __y, double __z) throw(); 
# 364
extern double scalb(double __x, double __n) throw(); extern double __scalb(double __x, double __n) throw(); 
# 54 "/usr/include/bits/mathcalls.h" 3
extern float acosf(float __x) throw(); extern float __acosf(float __x) throw(); 
# 56
extern float asinf(float __x) throw(); extern float __asinf(float __x) throw(); 
# 58
extern float atanf(float __x) throw(); extern float __atanf(float __x) throw(); 
# 60
extern float atan2f(float __y, float __x) throw(); extern float __atan2f(float __y, float __x) throw(); 
# 63
extern float cosf(float __x) throw(); 
# 65
extern float sinf(float __x) throw(); 
# 67
extern float tanf(float __x) throw(); 
# 72
extern float coshf(float __x) throw(); extern float __coshf(float __x) throw(); 
# 74
extern float sinhf(float __x) throw(); extern float __sinhf(float __x) throw(); 
# 76
extern float tanhf(float __x) throw(); extern float __tanhf(float __x) throw(); 
# 81
extern void sincosf(float __x, float * __sinx, float * __cosx) throw(); 
# 88
extern float acoshf(float __x) throw(); extern float __acoshf(float __x) throw(); 
# 90
extern float asinhf(float __x) throw(); extern float __asinhf(float __x) throw(); 
# 92
extern float atanhf(float __x) throw(); extern float __atanhf(float __x) throw(); 
# 100
extern float expf(float __x) throw(); 
# 103
extern float frexpf(float __x, int * __exponent) throw(); extern float __frexpf(float __x, int * __exponent) throw(); 
# 106
extern float ldexpf(float __x, int __exponent) throw(); extern float __ldexpf(float __x, int __exponent) throw(); 
# 109
extern float logf(float __x) throw(); 
# 112
extern float log10f(float __x) throw(); 
# 115
extern float modff(float __x, float * __iptr) throw(); extern float __modff(float __x, float * __iptr) throw()
# 116
 __attribute((__nonnull__(2))); 
# 121
extern float exp10f(float __x) throw(); 
# 123
extern float pow10f(float __x) throw(); extern float __pow10f(float __x) throw(); 
# 129
extern float expm1f(float __x) throw(); extern float __expm1f(float __x) throw(); 
# 132
extern float log1pf(float __x) throw(); extern float __log1pf(float __x) throw(); 
# 135
extern float logbf(float __x) throw(); extern float __logbf(float __x) throw(); 
# 142
extern float exp2f(float __x) throw(); extern float __exp2f(float __x) throw(); 
# 145
extern float log2f(float __x) throw(); 
# 154
extern float powf(float __x, float __y) throw(); 
# 157
extern float sqrtf(float __x) throw(); extern float __sqrtf(float __x) throw(); 
# 163
extern float hypotf(float __x, float __y) throw(); extern float __hypotf(float __x, float __y) throw(); 
# 170
extern float cbrtf(float __x) throw(); extern float __cbrtf(float __x) throw(); 
# 179
extern float ceilf(float __x) throw() __attribute((const)); extern float __ceilf(float __x) throw() __attribute((const)); 
# 182
extern float fabsf(float __x) throw() __attribute((const)); extern float __fabsf(float __x) throw() __attribute((const)); 
# 185
extern float floorf(float __x) throw() __attribute((const)); extern float __floorf(float __x) throw() __attribute((const)); 
# 188
extern float fmodf(float __x, float __y) throw(); extern float __fmodf(float __x, float __y) throw(); 
# 193
extern int __isinff(float __value) throw() __attribute((const)); 
# 196
extern int __finitef(float __value) throw() __attribute((const)); 
# 202
extern int isinff(float __value) throw() __attribute((const)); 
# 205
extern int finitef(float __value) throw() __attribute((const)); 
# 208
extern float dremf(float __x, float __y) throw(); extern float __dremf(float __x, float __y) throw(); 
# 212
extern float significandf(float __x) throw(); extern float __significandf(float __x) throw(); 
# 218
extern float copysignf(float __x, float __y) throw() __attribute((const)); extern float __copysignf(float __x, float __y) throw() __attribute((const)); 
# 225
extern float nanf(const char * __tagb) throw() __attribute((const)); extern float __nanf(const char * __tagb) throw() __attribute((const)); 
# 231
extern int __isnanf(float __value) throw() __attribute((const)); 
# 235
extern int isnanf(float __value) throw() __attribute((const)); 
# 238
extern float j0f(float) throw(); extern float __j0f(float) throw(); 
# 239
extern float j1f(float) throw(); extern float __j1f(float) throw(); 
# 240
extern float jnf(int, float) throw(); extern float __jnf(int, float) throw(); 
# 241
extern float y0f(float) throw(); extern float __y0f(float) throw(); 
# 242
extern float y1f(float) throw(); extern float __y1f(float) throw(); 
# 243
extern float ynf(int, float) throw(); extern float __ynf(int, float) throw(); 
# 250
extern float erff(float) throw(); extern float __erff(float) throw(); 
# 251
extern float erfcf(float) throw(); extern float __erfcf(float) throw(); 
# 252
extern float lgammaf(float) throw(); extern float __lgammaf(float) throw(); 
# 259
extern float tgammaf(float) throw(); extern float __tgammaf(float) throw(); 
# 265
extern float gammaf(float) throw(); extern float __gammaf(float) throw(); 
# 272
extern float lgammaf_r(float, int * __signgamp) throw(); extern float __lgammaf_r(float, int * __signgamp) throw(); 
# 280
extern float rintf(float __x) throw(); extern float __rintf(float __x) throw(); 
# 283
extern float nextafterf(float __x, float __y) throw() __attribute((const)); extern float __nextafterf(float __x, float __y) throw() __attribute((const)); 
# 285
extern float nexttowardf(float __x, long double __y) throw() __attribute((const)); extern float __nexttowardf(float __x, long double __y) throw() __attribute((const)); 
# 289
extern float remainderf(float __x, float __y) throw(); extern float __remainderf(float __x, float __y) throw(); 
# 293
extern float scalbnf(float __x, int __n) throw(); extern float __scalbnf(float __x, int __n) throw(); 
# 297
extern int ilogbf(float __x) throw(); extern int __ilogbf(float __x) throw(); 
# 302
extern float scalblnf(float __x, long __n) throw(); extern float __scalblnf(float __x, long __n) throw(); 
# 306
extern float nearbyintf(float __x) throw(); extern float __nearbyintf(float __x) throw(); 
# 310
extern float roundf(float __x) throw() __attribute((const)); extern float __roundf(float __x) throw() __attribute((const)); 
# 314
extern float truncf(float __x) throw() __attribute((const)); extern float __truncf(float __x) throw() __attribute((const)); 
# 319
extern float remquof(float __x, float __y, int * __quo) throw(); extern float __remquof(float __x, float __y, int * __quo) throw(); 
# 326
extern long lrintf(float __x) throw(); extern long __lrintf(float __x) throw(); 
# 327
extern long long llrintf(float __x) throw(); extern long long __llrintf(float __x) throw(); 
# 331
extern long lroundf(float __x) throw(); extern long __lroundf(float __x) throw(); 
# 332
extern long long llroundf(float __x) throw(); extern long long __llroundf(float __x) throw(); 
# 336
extern __attribute((gnu_inline)) inline float fdimf(float __x, float __y) throw(); extern float __fdimf(float __x, float __y) throw(); 
# 339
extern float fmaxf(float __x, float __y) throw() __attribute((const)); extern float __fmaxf(float __x, float __y) throw() __attribute((const)); 
# 342
extern float fminf(float __x, float __y) throw() __attribute((const)); extern float __fminf(float __x, float __y) throw() __attribute((const)); 
# 346
extern int __fpclassifyf(float __value) throw()
# 347
 __attribute((const)); 
# 350
extern __attribute((gnu_inline)) inline int __signbitf(float __value) throw()
# 351
 __attribute((const)); 
# 355
extern float fmaf(float __x, float __y, float __z) throw(); extern float __fmaf(float __x, float __y, float __z) throw(); 
# 364
extern float scalbf(float __x, float __n) throw(); extern float __scalbf(float __x, float __n) throw(); 
# 54 "/usr/include/bits/mathcalls.h" 3
extern long double acosl(long double __x) throw(); extern long double __acosl(long double __x) throw(); 
# 56
extern long double asinl(long double __x) throw(); extern long double __asinl(long double __x) throw(); 
# 58
extern long double atanl(long double __x) throw(); extern long double __atanl(long double __x) throw(); 
# 60
extern long double atan2l(long double __y, long double __x) throw(); extern long double __atan2l(long double __y, long double __x) throw(); 
# 63
extern long double cosl(long double __x) throw(); extern long double __cosl(long double __x) throw(); 
# 65
extern long double sinl(long double __x) throw(); extern long double __sinl(long double __x) throw(); 
# 67
extern long double tanl(long double __x) throw(); extern long double __tanl(long double __x) throw(); 
# 72
extern long double coshl(long double __x) throw(); extern long double __coshl(long double __x) throw(); 
# 74
extern long double sinhl(long double __x) throw(); extern long double __sinhl(long double __x) throw(); 
# 76
extern long double tanhl(long double __x) throw(); extern long double __tanhl(long double __x) throw(); 
# 81
extern void sincosl(long double __x, long double * __sinx, long double * __cosx) throw(); extern void __sincosl(long double __x, long double * __sinx, long double * __cosx) throw(); 
# 88
extern long double acoshl(long double __x) throw(); extern long double __acoshl(long double __x) throw(); 
# 90
extern long double asinhl(long double __x) throw(); extern long double __asinhl(long double __x) throw(); 
# 92
extern long double atanhl(long double __x) throw(); extern long double __atanhl(long double __x) throw(); 
# 100
extern long double expl(long double __x) throw(); extern long double __expl(long double __x) throw(); 
# 103
extern long double frexpl(long double __x, int * __exponent) throw(); extern long double __frexpl(long double __x, int * __exponent) throw(); 
# 106
extern long double ldexpl(long double __x, int __exponent) throw(); extern long double __ldexpl(long double __x, int __exponent) throw(); 
# 109
extern long double logl(long double __x) throw(); extern long double __logl(long double __x) throw(); 
# 112
extern long double log10l(long double __x) throw(); extern long double __log10l(long double __x) throw(); 
# 115
extern long double modfl(long double __x, long double * __iptr) throw(); extern long double __modfl(long double __x, long double * __iptr) throw()
# 116
 __attribute((__nonnull__(2))); 
# 121
extern long double exp10l(long double __x) throw(); extern long double __exp10l(long double __x) throw(); 
# 123
extern long double pow10l(long double __x) throw(); extern long double __pow10l(long double __x) throw(); 
# 129
extern long double expm1l(long double __x) throw(); extern long double __expm1l(long double __x) throw(); 
# 132
extern long double log1pl(long double __x) throw(); extern long double __log1pl(long double __x) throw(); 
# 135
extern long double logbl(long double __x) throw(); extern long double __logbl(long double __x) throw(); 
# 142
extern long double exp2l(long double __x) throw(); extern long double __exp2l(long double __x) throw(); 
# 145
extern long double log2l(long double __x) throw(); extern long double __log2l(long double __x) throw(); 
# 154
extern long double powl(long double __x, long double __y) throw(); extern long double __powl(long double __x, long double __y) throw(); 
# 157
extern long double sqrtl(long double __x) throw(); extern long double __sqrtl(long double __x) throw(); 
# 163
extern long double hypotl(long double __x, long double __y) throw(); extern long double __hypotl(long double __x, long double __y) throw(); 
# 170
extern long double cbrtl(long double __x) throw(); extern long double __cbrtl(long double __x) throw(); 
# 179
extern long double ceill(long double __x) throw() __attribute((const)); extern long double __ceill(long double __x) throw() __attribute((const)); 
# 182
extern long double fabsl(long double __x) throw() __attribute((const)); extern long double __fabsl(long double __x) throw() __attribute((const)); 
# 185
extern long double floorl(long double __x) throw() __attribute((const)); extern long double __floorl(long double __x) throw() __attribute((const)); 
# 188
extern long double fmodl(long double __x, long double __y) throw(); extern long double __fmodl(long double __x, long double __y) throw(); 
# 193
extern int __isinfl(long double __value) throw() __attribute((const)); 
# 196
extern int __finitel(long double __value) throw() __attribute((const)); 
# 202
extern int isinfl(long double __value) throw() __attribute((const)); 
# 205
extern int finitel(long double __value) throw() __attribute((const)); 
# 208
extern long double dreml(long double __x, long double __y) throw(); extern long double __dreml(long double __x, long double __y) throw(); 
# 212
extern long double significandl(long double __x) throw(); extern long double __significandl(long double __x) throw(); 
# 218
extern long double copysignl(long double __x, long double __y) throw() __attribute((const)); extern long double __copysignl(long double __x, long double __y) throw() __attribute((const)); 
# 225
extern long double nanl(const char * __tagb) throw() __attribute((const)); extern long double __nanl(const char * __tagb) throw() __attribute((const)); 
# 231
extern int __isnanl(long double __value) throw() __attribute((const)); 
# 235
extern int isnanl(long double __value) throw() __attribute((const)); 
# 238
extern long double j0l(long double) throw(); extern long double __j0l(long double) throw(); 
# 239
extern long double j1l(long double) throw(); extern long double __j1l(long double) throw(); 
# 240
extern long double jnl(int, long double) throw(); extern long double __jnl(int, long double) throw(); 
# 241
extern long double y0l(long double) throw(); extern long double __y0l(long double) throw(); 
# 242
extern long double y1l(long double) throw(); extern long double __y1l(long double) throw(); 
# 243
extern long double ynl(int, long double) throw(); extern long double __ynl(int, long double) throw(); 
# 250
extern long double erfl(long double) throw(); extern long double __erfl(long double) throw(); 
# 251
extern long double erfcl(long double) throw(); extern long double __erfcl(long double) throw(); 
# 252
extern long double lgammal(long double) throw(); extern long double __lgammal(long double) throw(); 
# 259
extern long double tgammal(long double) throw(); extern long double __tgammal(long double) throw(); 
# 265
extern long double gammal(long double) throw(); extern long double __gammal(long double) throw(); 
# 272
extern long double lgammal_r(long double, int * __signgamp) throw(); extern long double __lgammal_r(long double, int * __signgamp) throw(); 
# 280
extern long double rintl(long double __x) throw(); extern long double __rintl(long double __x) throw(); 
# 283
extern long double nextafterl(long double __x, long double __y) throw() __attribute((const)); extern long double __nextafterl(long double __x, long double __y) throw() __attribute((const)); 
# 285
extern long double nexttowardl(long double __x, long double __y) throw() __attribute((const)); extern long double __nexttowardl(long double __x, long double __y) throw() __attribute((const)); 
# 289
extern long double remainderl(long double __x, long double __y) throw(); extern long double __remainderl(long double __x, long double __y) throw(); 
# 293
extern long double scalbnl(long double __x, int __n) throw(); extern long double __scalbnl(long double __x, int __n) throw(); 
# 297
extern int ilogbl(long double __x) throw(); extern int __ilogbl(long double __x) throw(); 
# 302
extern long double scalblnl(long double __x, long __n) throw(); extern long double __scalblnl(long double __x, long __n) throw(); 
# 306
extern long double nearbyintl(long double __x) throw(); extern long double __nearbyintl(long double __x) throw(); 
# 310
extern long double roundl(long double __x) throw() __attribute((const)); extern long double __roundl(long double __x) throw() __attribute((const)); 
# 314
extern long double truncl(long double __x) throw() __attribute((const)); extern long double __truncl(long double __x) throw() __attribute((const)); 
# 319
extern long double remquol(long double __x, long double __y, int * __quo) throw(); extern long double __remquol(long double __x, long double __y, int * __quo) throw(); 
# 326
extern long lrintl(long double __x) throw(); extern long __lrintl(long double __x) throw(); 
# 327
extern long long llrintl(long double __x) throw(); extern long long __llrintl(long double __x) throw(); 
# 331
extern long lroundl(long double __x) throw(); extern long __lroundl(long double __x) throw(); 
# 332
extern long long llroundl(long double __x) throw(); extern long long __llroundl(long double __x) throw(); 
# 336
extern long double fdiml(long double __x, long double __y) throw(); extern long double __fdiml(long double __x, long double __y) throw(); 
# 339
extern long double fmaxl(long double __x, long double __y) throw() __attribute((const)); extern long double __fmaxl(long double __x, long double __y) throw() __attribute((const)); 
# 342
extern long double fminl(long double __x, long double __y) throw() __attribute((const)); extern long double __fminl(long double __x, long double __y) throw() __attribute((const)); 
# 346
extern int __fpclassifyl(long double __value) throw()
# 347
 __attribute((const)); 
# 350
extern __attribute((gnu_inline)) inline int __signbitl(long double __value) throw()
# 351
 __attribute((const)); 
# 355
extern long double fmal(long double __x, long double __y, long double __z) throw(); extern long double __fmal(long double __x, long double __y, long double __z) throw(); 
# 364
extern long double scalbl(long double __x, long double __n) throw(); extern long double __scalbl(long double __x, long double __n) throw(); 
# 149 "/usr/include/math.h" 3
extern int signgam; 
# 191
enum { 
# 192
FP_NAN, 
# 195
FP_INFINITE, 
# 198
FP_ZERO, 
# 201
FP_SUBNORMAL, 
# 204
FP_NORMAL
# 207
}; 
# 295
typedef 
# 289
enum { 
# 290
_IEEE_ = (-1), 
# 291
_SVID_ = 0, 
# 292
_XOPEN_, 
# 293
_POSIX_, 
# 294
_ISOC_
# 295
} _LIB_VERSION_TYPE; 
# 300
extern _LIB_VERSION_TYPE _LIB_VERSION; 
# 311
struct __exception { 
# 316
int type; 
# 317
char *name; 
# 318
double arg1; 
# 319
double arg2; 
# 320
double retval; 
# 321
}; 
# 324
extern int matherr(__exception * __exc) throw(); 
# 62 "/usr/include/bits/mathinline.h" 3
__attribute((__gnu_inline__)) extern inline int
# 63
 __attribute((__leaf__)) __signbitf(float __x) throw() 
# 64
{ 
# 66
return __builtin_signbitf(__x); 
# 71
} 
# 72
__attribute((__gnu_inline__)) extern inline int
# 73
 __attribute((__leaf__)) __signbit(double __x) throw() 
# 74
{ 
# 76
return __builtin_signbit(__x); 
# 81
} 
# 83
__attribute((__gnu_inline__)) extern inline int
# 84
 __attribute((__leaf__)) __signbitl(long double __x) throw() 
# 85
{ 
# 86
return __signbit((double)__x); 
# 87
} 
# 117
__attribute((__gnu_inline__)) extern inline double fdim(double __x, double __y) throw(); 
# 118
__attribute((__gnu_inline__)) extern inline double
# 119
 __attribute((__leaf__)) fdim(double __x, double __y) throw() 
# 120
{ 
# 121
return (__x <= __y) ? 0 : (__x - __y); 
# 122
} 
# 124
__attribute((__gnu_inline__)) extern inline float fdimf(float __x, float __y) throw(); 
# 125
__attribute((__gnu_inline__)) extern inline float
# 126
 __attribute((__leaf__)) fdimf(float __x, float __y) throw() 
# 127
{ 
# 128
return (__x <= __y) ? 0 : (__x - __y); 
# 129
} 
# 475 "/usr/include/math.h" 3
}
# 34 "/usr/include/stdlib.h" 3
extern "C" {
# 44 "/usr/include/bits/byteswap.h" 3
static inline unsigned __bswap_32(unsigned __bsx) 
# 45
{ 
# 46
return __builtin_bswap32(__bsx); 
# 47
} 
# 75
static inline __uint64_t __bswap_64(__uint64_t __bsx) 
# 76
{ 
# 77
return __builtin_bswap64(__bsx); 
# 78
} 
# 66 "/usr/include/bits/waitstatus.h" 3
union wait { 
# 68
int w_status; 
# 70
struct { 
# 72
unsigned __w_termsig:7; 
# 73
unsigned __w_coredump:1; 
# 74
unsigned __w_retcode:8; 
# 75
unsigned:16; 
# 83
} __wait_terminated; 
# 85
struct { 
# 87
unsigned __w_stopval:8; 
# 88
unsigned __w_stopsig:8; 
# 89
unsigned:16; 
# 96
} __wait_stopped; 
# 97
}; 
# 101 "/usr/include/stdlib.h" 3
typedef 
# 98
struct { 
# 99
int quot; 
# 100
int rem; 
# 101
} div_t; 
# 109
typedef 
# 106
struct { 
# 107
long quot; 
# 108
long rem; 
# 109
} ldiv_t; 
# 121
__extension__ typedef 
# 118
struct { 
# 119
long long quot; 
# 120
long long rem; 
# 121
} lldiv_t; 
# 139
extern size_t __ctype_get_mb_cur_max() throw(); 
# 144
extern __attribute((gnu_inline)) inline double atof(const char * __nptr) throw()
# 145
 __attribute((__pure__)) __attribute((__nonnull__(1))); 
# 147
extern __attribute((gnu_inline)) inline int atoi(const char * __nptr) throw()
# 148
 __attribute((__pure__)) __attribute((__nonnull__(1))); 
# 150
extern __attribute((gnu_inline)) inline long atol(const char * __nptr) throw()
# 151
 __attribute((__pure__)) __attribute((__nonnull__(1))); 
# 157
__extension__ extern __attribute((gnu_inline)) inline long long atoll(const char * __nptr) throw()
# 158
 __attribute((__pure__)) __attribute((__nonnull__(1))); 
# 164
extern double strtod(const char *__restrict__ __nptr, char **__restrict__ __endptr) throw()
# 166
 __attribute((__nonnull__(1))); 
# 172
extern float strtof(const char *__restrict__ __nptr, char **__restrict__ __endptr) throw()
# 173
 __attribute((__nonnull__(1))); 
# 175
extern long double strtold(const char *__restrict__ __nptr, char **__restrict__ __endptr) throw()
# 177
 __attribute((__nonnull__(1))); 
# 183
extern long strtol(const char *__restrict__ __nptr, char **__restrict__ __endptr, int __base) throw()
# 185
 __attribute((__nonnull__(1))); 
# 187
extern unsigned long strtoul(const char *__restrict__ __nptr, char **__restrict__ __endptr, int __base) throw()
# 189
 __attribute((__nonnull__(1))); 
# 195
__extension__ extern long long strtoq(const char *__restrict__ __nptr, char **__restrict__ __endptr, int __base) throw()
# 197
 __attribute((__nonnull__(1))); 
# 200
__extension__ extern unsigned long long strtouq(const char *__restrict__ __nptr, char **__restrict__ __endptr, int __base) throw()
# 202
 __attribute((__nonnull__(1))); 
# 209
__extension__ extern long long strtoll(const char *__restrict__ __nptr, char **__restrict__ __endptr, int __base) throw()
# 211
 __attribute((__nonnull__(1))); 
# 214
__extension__ extern unsigned long long strtoull(const char *__restrict__ __nptr, char **__restrict__ __endptr, int __base) throw()
# 216
 __attribute((__nonnull__(1))); 
# 239
extern long strtol_l(const char *__restrict__ __nptr, char **__restrict__ __endptr, int __base, __locale_t __loc) throw()
# 241
 __attribute((__nonnull__(1, 4))); 
# 243
extern unsigned long strtoul_l(const char *__restrict__ __nptr, char **__restrict__ __endptr, int __base, __locale_t __loc) throw()
# 246
 __attribute((__nonnull__(1, 4))); 
# 249
__extension__ extern long long strtoll_l(const char *__restrict__ __nptr, char **__restrict__ __endptr, int __base, __locale_t __loc) throw()
# 252
 __attribute((__nonnull__(1, 4))); 
# 255
__extension__ extern unsigned long long strtoull_l(const char *__restrict__ __nptr, char **__restrict__ __endptr, int __base, __locale_t __loc) throw()
# 258
 __attribute((__nonnull__(1, 4))); 
# 260
extern double strtod_l(const char *__restrict__ __nptr, char **__restrict__ __endptr, __locale_t __loc) throw()
# 262
 __attribute((__nonnull__(1, 3))); 
# 264
extern float strtof_l(const char *__restrict__ __nptr, char **__restrict__ __endptr, __locale_t __loc) throw()
# 266
 __attribute((__nonnull__(1, 3))); 
# 268
extern long double strtold_l(const char *__restrict__ __nptr, char **__restrict__ __endptr, __locale_t __loc) throw()
# 271
 __attribute((__nonnull__(1, 3))); 
# 277
__attribute((__gnu_inline__)) extern inline int
# 278
 __attribute((__leaf__)) atoi(const char *__nptr) throw() 
# 279
{ 
# 280
return (int)strtol(__nptr, (char **)__null, 10); 
# 281
} 
# 282
__attribute((__gnu_inline__)) extern inline long
# 283
 __attribute((__leaf__)) atol(const char *__nptr) throw() 
# 284
{ 
# 285
return strtol(__nptr, (char **)__null, 10); 
# 286
} 
# 292
__extension__ 
# 291
__attribute((__gnu_inline__)) extern inline long long
# 292
 __attribute((__leaf__)) atoll(const char *__nptr) throw() 
# 293
{ 
# 294
return strtoll(__nptr, (char **)__null, 10); 
# 295
} 
# 305
extern char *l64a(long __n) throw(); 
# 308
extern long a64l(const char * __s) throw()
# 309
 __attribute((__pure__)) __attribute((__nonnull__(1))); 
# 27 "/usr/include/sys/types.h" 3
extern "C" {
# 33
typedef __u_char u_char; 
# 34
typedef __u_short u_short; 
# 35
typedef __u_int u_int; 
# 36
typedef __u_long u_long; 
# 37
typedef __quad_t quad_t; 
# 38
typedef __u_quad_t u_quad_t; 
# 39
typedef __fsid_t fsid_t; 
# 44
typedef __loff_t loff_t; 
# 48
typedef __ino_t ino_t; 
# 55
typedef __ino64_t ino64_t; 
# 60
typedef __dev_t dev_t; 
# 65
typedef __gid_t gid_t; 
# 70
typedef __mode_t mode_t; 
# 75
typedef __nlink_t nlink_t; 
# 80
typedef __uid_t uid_t; 
# 86
typedef __off_t off_t; 
# 93
typedef __off64_t off64_t; 
# 104
typedef __id_t id_t; 
# 109
typedef __ssize_t ssize_t; 
# 115
typedef __daddr_t daddr_t; 
# 116
typedef __caddr_t caddr_t; 
# 122
typedef __key_t key_t; 
# 136
typedef __useconds_t useconds_t; 
# 140
typedef __suseconds_t suseconds_t; 
# 150
typedef unsigned long ulong; 
# 151
typedef unsigned short ushort; 
# 152
typedef unsigned uint; 
# 194
typedef signed char int8_t __attribute((__mode__(__QI__))); 
# 195
typedef short int16_t __attribute((__mode__(__HI__))); 
# 196
typedef int int32_t __attribute((__mode__(__SI__))); 
# 197
typedef long int64_t __attribute((__mode__(__DI__))); 
# 200
typedef unsigned char u_int8_t __attribute((__mode__(__QI__))); 
# 201
typedef unsigned short u_int16_t __attribute((__mode__(__HI__))); 
# 202
typedef unsigned u_int32_t __attribute((__mode__(__SI__))); 
# 203
typedef unsigned long u_int64_t __attribute((__mode__(__DI__))); 
# 205
typedef long register_t __attribute((__mode__(__word__))); 
# 23 "/usr/include/bits/sigset.h" 3
typedef int __sig_atomic_t; 
# 31
typedef 
# 29
struct { 
# 30
unsigned long __val[(1024) / ((8) * sizeof(unsigned long))]; 
# 31
} __sigset_t; 
# 37 "/usr/include/sys/select.h" 3
typedef __sigset_t sigset_t; 
# 54
typedef long __fd_mask; 
# 75
typedef 
# 65
struct { 
# 69
__fd_mask fds_bits[1024 / (8 * ((int)sizeof(__fd_mask)))]; 
# 75
} fd_set; 
# 82
typedef __fd_mask fd_mask; 
# 96
extern "C" {
# 106
extern int select(int __nfds, fd_set *__restrict__ __readfds, fd_set *__restrict__ __writefds, fd_set *__restrict__ __exceptfds, timeval *__restrict__ __timeout); 
# 118
extern int pselect(int __nfds, fd_set *__restrict__ __readfds, fd_set *__restrict__ __writefds, fd_set *__restrict__ __exceptfds, const timespec *__restrict__ __timeout, const __sigset_t *__restrict__ __sigmask); 
# 131
}
# 29 "/usr/include/sys/sysmacros.h" 3
extern "C" {
# 32
__extension__ extern __attribute((gnu_inline)) inline unsigned gnu_dev_major(unsigned long long __dev) throw()
# 33
 __attribute((const)); 
# 35
__extension__ extern __attribute((gnu_inline)) inline unsigned gnu_dev_minor(unsigned long long __dev) throw()
# 36
 __attribute((const)); 
# 38
__extension__ extern __attribute((gnu_inline)) inline unsigned long long gnu_dev_makedev(unsigned __major, unsigned __minor) throw()
# 40
 __attribute((const)); 
# 44
__extension__ 
# 43
__attribute((__gnu_inline__)) __attribute((const)) extern inline unsigned
# 44
 __attribute((__leaf__)) gnu_dev_major(unsigned long long __dev) throw() 
# 45
{ 
# 46
return ((__dev >> 8) & (4095)) | (((unsigned)(__dev >> 32)) & (~4095)); 
# 47
} 
# 50
__extension__ 
# 49
__attribute((__gnu_inline__)) __attribute((const)) extern inline unsigned
# 50
 __attribute((__leaf__)) gnu_dev_minor(unsigned long long __dev) throw() 
# 51
{ 
# 52
return (__dev & (255)) | (((unsigned)(__dev >> 12)) & (~255)); 
# 53
} 
# 56
__extension__ 
# 55
__attribute((__gnu_inline__)) __attribute((const)) extern inline unsigned long long
# 56
 __attribute((__leaf__)) gnu_dev_makedev(unsigned __major, unsigned __minor) throw() 
# 57
{ 
# 58
return (((__minor & (255)) | ((__major & (4095)) << 8)) | (((unsigned long long)(__minor & (~255))) << 12)) | (((unsigned long long)(__major & (~4095))) << 32); 
# 61
} 
# 63
}
# 228 "/usr/include/sys/types.h" 3
typedef __blksize_t blksize_t; 
# 235
typedef __blkcnt_t blkcnt_t; 
# 239
typedef __fsblkcnt_t fsblkcnt_t; 
# 243
typedef __fsfilcnt_t fsfilcnt_t; 
# 262
typedef __blkcnt64_t blkcnt64_t; 
# 263
typedef __fsblkcnt64_t fsblkcnt64_t; 
# 264
typedef __fsfilcnt64_t fsfilcnt64_t; 
# 49 "/usr/include/bits/pthreadtypes.h" 3
typedef unsigned long pthread_t; 
# 52
union pthread_attr_t { 
# 54
char __size[56]; 
# 55
long __align; 
# 56
}; 
# 58
typedef pthread_attr_t pthread_attr_t; 
# 68
typedef 
# 64
struct __pthread_internal_list { 
# 66
__pthread_internal_list *__prev; 
# 67
__pthread_internal_list *__next; 
# 68
} __pthread_list_t; 
# 107
typedef 
# 80
union { 
# 81
struct __pthread_mutex_s { 
# 83
int __lock; 
# 84
unsigned __count; 
# 85
int __owner; 
# 87
unsigned __nusers; 
# 91
int __kind; 
# 93
int __spins; 
# 94
__pthread_list_t __list; 
# 104
} __data; 
# 105
char __size[40]; 
# 106
long __align; 
# 107
} pthread_mutex_t; 
# 113
typedef 
# 110
union { 
# 111
char __size[4]; 
# 112
int __align; 
# 113
} pthread_mutexattr_t; 
# 133
typedef 
# 119
union { 
# 121
struct { 
# 122
int __lock; 
# 123
unsigned __futex; 
# 124
__extension__ unsigned long long __total_seq; 
# 125
__extension__ unsigned long long __wakeup_seq; 
# 126
__extension__ unsigned long long __woken_seq; 
# 127
void *__mutex; 
# 128
unsigned __nwaiters; 
# 129
unsigned __broadcast_seq; 
# 130
} __data; 
# 131
char __size[48]; 
# 132
__extension__ long long __align; 
# 133
} pthread_cond_t; 
# 139
typedef 
# 136
union { 
# 137
char __size[4]; 
# 138
int __align; 
# 139
} pthread_condattr_t; 
# 143
typedef unsigned pthread_key_t; 
# 147
typedef int pthread_once_t; 
# 192
typedef 
# 154
union { 
# 157
struct { 
# 158
int __lock; 
# 159
unsigned __nr_readers; 
# 160
unsigned __readers_wakeup; 
# 161
unsigned __writer_wakeup; 
# 162
unsigned __nr_readers_queued; 
# 163
unsigned __nr_writers_queued; 
# 164
int __writer; 
# 165
int __shared; 
# 166
unsigned long __pad1; 
# 167
unsigned long __pad2; 
# 170
unsigned __flags; 
# 171
} __data; 
# 190
char __size[56]; 
# 191
long __align; 
# 192
} pthread_rwlock_t; 
# 198
typedef 
# 195
union { 
# 196
char __size[8]; 
# 197
long __align; 
# 198
} pthread_rwlockattr_t; 
# 204
typedef volatile int pthread_spinlock_t; 
# 213
typedef 
# 210
union { 
# 211
char __size[32]; 
# 212
long __align; 
# 213
} pthread_barrier_t; 
# 219
typedef 
# 216
union { 
# 217
char __size[4]; 
# 218
int __align; 
# 219
} pthread_barrierattr_t; 
# 273 "/usr/include/sys/types.h" 3
}
# 321 "/usr/include/stdlib.h" 3
extern long random() throw(); 
# 324
extern void srandom(unsigned __seed) throw(); 
# 330
extern char *initstate(unsigned __seed, char * __statebuf, size_t __statelen) throw()
# 331
 __attribute((__nonnull__(2))); 
# 335
extern char *setstate(char * __statebuf) throw() __attribute((__nonnull__(1))); 
# 343
struct random_data { 
# 345
int32_t *fptr; 
# 346
int32_t *rptr; 
# 347
int32_t *state; 
# 348
int rand_type; 
# 349
int rand_deg; 
# 350
int rand_sep; 
# 351
int32_t *end_ptr; 
# 352
}; 
# 354
extern int random_r(random_data *__restrict__ __buf, int32_t *__restrict__ __result) throw()
# 355
 __attribute((__nonnull__(1, 2))); 
# 357
extern int srandom_r(unsigned __seed, random_data * __buf) throw()
# 358
 __attribute((__nonnull__(2))); 
# 360
extern int initstate_r(unsigned __seed, char *__restrict__ __statebuf, size_t __statelen, random_data *__restrict__ __buf) throw()
# 363
 __attribute((__nonnull__(2, 4))); 
# 365
extern int setstate_r(char *__restrict__ __statebuf, random_data *__restrict__ __buf) throw()
# 367
 __attribute((__nonnull__(1, 2))); 
# 374
extern int rand() throw(); 
# 376
extern void srand(unsigned __seed) throw(); 
# 381
extern int rand_r(unsigned * __seed) throw(); 
# 389
extern double drand48() throw(); 
# 390
extern double erand48(unsigned short  __xsubi[3]) throw() __attribute((__nonnull__(1))); 
# 393
extern long lrand48() throw(); 
# 394
extern long nrand48(unsigned short  __xsubi[3]) throw()
# 395
 __attribute((__nonnull__(1))); 
# 398
extern long mrand48() throw(); 
# 399
extern long jrand48(unsigned short  __xsubi[3]) throw()
# 400
 __attribute((__nonnull__(1))); 
# 403
extern void srand48(long __seedval) throw(); 
# 404
extern unsigned short *seed48(unsigned short  __seed16v[3]) throw()
# 405
 __attribute((__nonnull__(1))); 
# 406
extern void lcong48(unsigned short  __param[7]) throw() __attribute((__nonnull__(1))); 
# 412
struct drand48_data { 
# 414
unsigned short __x[3]; 
# 415
unsigned short __old_x[3]; 
# 416
unsigned short __c; 
# 417
unsigned short __init; 
# 418
unsigned long long __a; 
# 419
}; 
# 422
extern int drand48_r(drand48_data *__restrict__ __buffer, double *__restrict__ __result) throw()
# 423
 __attribute((__nonnull__(1, 2))); 
# 424
extern int erand48_r(unsigned short  __xsubi[3], drand48_data *__restrict__ __buffer, double *__restrict__ __result) throw()
# 426
 __attribute((__nonnull__(1, 2))); 
# 429
extern int lrand48_r(drand48_data *__restrict__ __buffer, long *__restrict__ __result) throw()
# 431
 __attribute((__nonnull__(1, 2))); 
# 432
extern int nrand48_r(unsigned short  __xsubi[3], drand48_data *__restrict__ __buffer, long *__restrict__ __result) throw()
# 435
 __attribute((__nonnull__(1, 2))); 
# 438
extern int mrand48_r(drand48_data *__restrict__ __buffer, long *__restrict__ __result) throw()
# 440
 __attribute((__nonnull__(1, 2))); 
# 441
extern int jrand48_r(unsigned short  __xsubi[3], drand48_data *__restrict__ __buffer, long *__restrict__ __result) throw()
# 444
 __attribute((__nonnull__(1, 2))); 
# 447
extern int srand48_r(long __seedval, drand48_data * __buffer) throw()
# 448
 __attribute((__nonnull__(2))); 
# 450
extern int seed48_r(unsigned short  __seed16v[3], drand48_data * __buffer) throw()
# 451
 __attribute((__nonnull__(1, 2))); 
# 453
extern int lcong48_r(unsigned short  __param[7], drand48_data * __buffer) throw()
# 455
 __attribute((__nonnull__(1, 2))); 
# 465
extern void *malloc(size_t __size) throw() __attribute((__malloc__)); 
# 467
extern void *calloc(size_t __nmemb, size_t __size) throw()
# 468
 __attribute((__malloc__)); 
# 479
extern void *realloc(void * __ptr, size_t __size) throw()
# 480
 __attribute((__warn_unused_result__)); 
# 482
extern void free(void * __ptr) throw(); 
# 487
extern void cfree(void * __ptr) throw(); 
# 26 "/usr/include/alloca.h" 3
extern "C" {
# 32
extern void *alloca(size_t __size) throw(); 
# 38
}
# 497 "/usr/include/stdlib.h" 3
extern void *valloc(size_t __size) throw() __attribute((__malloc__)); 
# 502
extern int posix_memalign(void ** __memptr, size_t __alignment, size_t __size) throw()
# 503
 __attribute((__nonnull__(1))); 
# 508
extern void *aligned_alloc(size_t __alignment, size_t __size) throw()
# 509
 __attribute((__malloc__, __alloc_size__(2))); 
# 514
extern void abort() throw() __attribute((__noreturn__)); 
# 518
extern int atexit(void (* __func)(void)) throw() __attribute((__nonnull__(1))); 
# 523
extern "C++" int at_quick_exit(void (* __func)(void)) throw() __asm__("at_quick_exit")
# 524
 __attribute((__nonnull__(1))); 
# 534
extern int on_exit(void (* __func)(int __status, void * __arg), void * __arg) throw()
# 535
 __attribute((__nonnull__(1))); 
# 542
extern void exit(int __status) throw() __attribute((__noreturn__)); 
# 548
extern void quick_exit(int __status) throw() __attribute((__noreturn__)); 
# 556
extern void _Exit(int __status) throw() __attribute((__noreturn__)); 
# 563
extern char *getenv(const char * __name) throw() __attribute((__nonnull__(1))); 
# 569
extern char *secure_getenv(const char * __name) throw()
# 570
 __attribute((__nonnull__(1))); 
# 577
extern int putenv(char * __string) throw() __attribute((__nonnull__(1))); 
# 583
extern int setenv(const char * __name, const char * __value, int __replace) throw()
# 584
 __attribute((__nonnull__(2))); 
# 587
extern int unsetenv(const char * __name) throw() __attribute((__nonnull__(1))); 
# 594
extern int clearenv() throw(); 
# 605
extern char *mktemp(char * __template) throw() __attribute((__nonnull__(1))); 
# 619
extern int mkstemp(char * __template) __attribute((__nonnull__(1))); 
# 629
extern int mkstemp64(char * __template) __attribute((__nonnull__(1))); 
# 641
extern int mkstemps(char * __template, int __suffixlen) __attribute((__nonnull__(1))); 
# 651
extern int mkstemps64(char * __template, int __suffixlen)
# 652
 __attribute((__nonnull__(1))); 
# 662
extern char *mkdtemp(char * __template) throw() __attribute((__nonnull__(1))); 
# 673
extern int mkostemp(char * __template, int __flags) __attribute((__nonnull__(1))); 
# 683
extern int mkostemp64(char * __template, int __flags) __attribute((__nonnull__(1))); 
# 693
extern int mkostemps(char * __template, int __suffixlen, int __flags)
# 694
 __attribute((__nonnull__(1))); 
# 705
extern int mkostemps64(char * __template, int __suffixlen, int __flags)
# 706
 __attribute((__nonnull__(1))); 
# 716
extern int system(const char * __command); 
# 723
extern char *canonicalize_file_name(const char * __name) throw()
# 724
 __attribute((__nonnull__(1))); 
# 733
extern char *realpath(const char *__restrict__ __name, char *__restrict__ __resolved) throw(); 
# 741
typedef int (*__compar_fn_t)(const void *, const void *); 
# 744
typedef __compar_fn_t comparison_fn_t; 
# 748
typedef int (*__compar_d_fn_t)(const void *, const void *, void *); 
# 754
extern void *bsearch(const void * __key, const void * __base, size_t __nmemb, size_t __size, __compar_fn_t __compar)
# 756
 __attribute((__nonnull__(1, 2, 5))); 
# 760
extern void qsort(void * __base, size_t __nmemb, size_t __size, __compar_fn_t __compar)
# 761
 __attribute((__nonnull__(1, 4))); 
# 763
extern void qsort_r(void * __base, size_t __nmemb, size_t __size, __compar_d_fn_t __compar, void * __arg)
# 765
 __attribute((__nonnull__(1, 4))); 
# 770
extern int abs(int __x) throw() __attribute((const)); 
# 771
extern long labs(long __x) throw() __attribute((const)); 
# 775
__extension__ extern long long llabs(long long __x) throw()
# 776
 __attribute((const)); 
# 784
extern div_t div(int __numer, int __denom) throw()
# 785
 __attribute((const)); 
# 786
extern ldiv_t ldiv(long __numer, long __denom) throw()
# 787
 __attribute((const)); 
# 792
__extension__ extern lldiv_t lldiv(long long __numer, long long __denom) throw()
# 794
 __attribute((const)); 
# 807
extern char *ecvt(double __value, int __ndigit, int *__restrict__ __decpt, int *__restrict__ __sign) throw()
# 808
 __attribute((__nonnull__(3, 4))); 
# 813
extern char *fcvt(double __value, int __ndigit, int *__restrict__ __decpt, int *__restrict__ __sign) throw()
# 814
 __attribute((__nonnull__(3, 4))); 
# 819
extern char *gcvt(double __value, int __ndigit, char * __buf) throw()
# 820
 __attribute((__nonnull__(3))); 
# 825
extern char *qecvt(long double __value, int __ndigit, int *__restrict__ __decpt, int *__restrict__ __sign) throw()
# 827
 __attribute((__nonnull__(3, 4))); 
# 828
extern char *qfcvt(long double __value, int __ndigit, int *__restrict__ __decpt, int *__restrict__ __sign) throw()
# 830
 __attribute((__nonnull__(3, 4))); 
# 831
extern char *qgcvt(long double __value, int __ndigit, char * __buf) throw()
# 832
 __attribute((__nonnull__(3))); 
# 837
extern int ecvt_r(double __value, int __ndigit, int *__restrict__ __decpt, int *__restrict__ __sign, char *__restrict__ __buf, size_t __len) throw()
# 839
 __attribute((__nonnull__(3, 4, 5))); 
# 840
extern int fcvt_r(double __value, int __ndigit, int *__restrict__ __decpt, int *__restrict__ __sign, char *__restrict__ __buf, size_t __len) throw()
# 842
 __attribute((__nonnull__(3, 4, 5))); 
# 844
extern int qecvt_r(long double __value, int __ndigit, int *__restrict__ __decpt, int *__restrict__ __sign, char *__restrict__ __buf, size_t __len) throw()
# 847
 __attribute((__nonnull__(3, 4, 5))); 
# 848
extern int qfcvt_r(long double __value, int __ndigit, int *__restrict__ __decpt, int *__restrict__ __sign, char *__restrict__ __buf, size_t __len) throw()
# 851
 __attribute((__nonnull__(3, 4, 5))); 
# 859
extern int mblen(const char * __s, size_t __n) throw(); 
# 862
extern int mbtowc(wchar_t *__restrict__ __pwc, const char *__restrict__ __s, size_t __n) throw(); 
# 866
extern int wctomb(char * __s, wchar_t __wchar) throw(); 
# 870
extern size_t mbstowcs(wchar_t *__restrict__ __pwcs, const char *__restrict__ __s, size_t __n) throw(); 
# 873
extern size_t wcstombs(char *__restrict__ __s, const wchar_t *__restrict__ __pwcs, size_t __n) throw(); 
# 884
extern int rpmatch(const char * __response) throw() __attribute((__nonnull__(1))); 
# 895
extern int getsubopt(char **__restrict__ __optionp, char *const *__restrict__ __tokens, char **__restrict__ __valuep) throw()
# 898
 __attribute((__nonnull__(1, 2, 3))); 
# 904
extern void setkey(const char * __key) throw() __attribute((__nonnull__(1))); 
# 912
extern int posix_openpt(int __oflag); 
# 920
extern int grantpt(int __fd) throw(); 
# 924
extern int unlockpt(int __fd) throw(); 
# 929
extern char *ptsname(int __fd) throw(); 
# 936
extern int ptsname_r(int __fd, char * __buf, size_t __buflen) throw()
# 937
 __attribute((__nonnull__(2))); 
# 940
extern int getpt(); 
# 947
extern int getloadavg(double  __loadavg[], int __nelem) throw()
# 948
 __attribute((__nonnull__(1))); 
# 25 "/usr/include/bits/stdlib-float.h" 3
__attribute((__gnu_inline__)) extern inline double
# 26
 __attribute((__leaf__)) atof(const char *__nptr) throw() 
# 27
{ 
# 28
return strtod(__nptr, (char **)__null); 
# 29
} 
# 964 "/usr/include/stdlib.h" 3
}
# 184 "/usr/include/c++/4.8.2/ppc64le-redhat-linux/bits/c++config.h" 3
namespace std { 
# 186
typedef unsigned long size_t; 
# 187
typedef long ptrdiff_t; 
# 192
}
# 346
namespace std { 
# 348
inline namespace __gnu_cxx_ldbl128 { }
# 349
}
# 68 "/usr/include/c++/4.8.2/bits/cpp_type_traits.h" 3
namespace __gnu_cxx __attribute((__visibility__("default"))) { 
# 72
template< class _Iterator, class _Container> class __normal_iterator; 
# 76
}
# 78
namespace std __attribute((__visibility__("default"))) { 
# 82
struct __true_type { }; 
# 83
struct __false_type { }; 
# 85
template< bool > 
# 86
struct __truth_type { 
# 87
typedef __false_type __type; }; 
# 90
template<> struct __truth_type< true>  { 
# 91
typedef __true_type __type; }; 
# 95
template< class _Sp, class _Tp> 
# 96
struct __traitor { 
# 98
enum { __value = ((bool)_Sp::__value) || ((bool)_Tp::__value)}; 
# 99
typedef typename __truth_type< __value> ::__type __type; 
# 100
}; 
# 103
template< class , class > 
# 104
struct __are_same { 
# 106
enum { __value}; 
# 107
typedef __false_type __type; 
# 108
}; 
# 110
template< class _Tp> 
# 111
struct __are_same< _Tp, _Tp>  { 
# 113
enum { __value = 1}; 
# 114
typedef __true_type __type; 
# 115
}; 
# 118
template< class _Tp> 
# 119
struct __is_void { 
# 121
enum { __value}; 
# 122
typedef __false_type __type; 
# 123
}; 
# 126
template<> struct __is_void< void>  { 
# 128
enum { __value = 1}; 
# 129
typedef __true_type __type; 
# 130
}; 
# 135
template< class _Tp> 
# 136
struct __is_integer { 
# 138
enum { __value}; 
# 139
typedef __false_type __type; 
# 140
}; 
# 146
template<> struct __is_integer< bool>  { 
# 148
enum { __value = 1}; 
# 149
typedef __true_type __type; 
# 150
}; 
# 153
template<> struct __is_integer< char>  { 
# 155
enum { __value = 1}; 
# 156
typedef __true_type __type; 
# 157
}; 
# 160
template<> struct __is_integer< signed char>  { 
# 162
enum { __value = 1}; 
# 163
typedef __true_type __type; 
# 164
}; 
# 167
template<> struct __is_integer< unsigned char>  { 
# 169
enum { __value = 1}; 
# 170
typedef __true_type __type; 
# 171
}; 
# 175
template<> struct __is_integer< wchar_t>  { 
# 177
enum { __value = 1}; 
# 178
typedef __true_type __type; 
# 179
}; 
# 199
template<> struct __is_integer< short>  { 
# 201
enum { __value = 1}; 
# 202
typedef __true_type __type; 
# 203
}; 
# 206
template<> struct __is_integer< unsigned short>  { 
# 208
enum { __value = 1}; 
# 209
typedef __true_type __type; 
# 210
}; 
# 213
template<> struct __is_integer< int>  { 
# 215
enum { __value = 1}; 
# 216
typedef __true_type __type; 
# 217
}; 
# 220
template<> struct __is_integer< unsigned>  { 
# 222
enum { __value = 1}; 
# 223
typedef __true_type __type; 
# 224
}; 
# 227
template<> struct __is_integer< long>  { 
# 229
enum { __value = 1}; 
# 230
typedef __true_type __type; 
# 231
}; 
# 234
template<> struct __is_integer< unsigned long>  { 
# 236
enum { __value = 1}; 
# 237
typedef __true_type __type; 
# 238
}; 
# 241
template<> struct __is_integer< long long>  { 
# 243
enum { __value = 1}; 
# 244
typedef __true_type __type; 
# 245
}; 
# 248
template<> struct __is_integer< unsigned long long>  { 
# 250
enum { __value = 1}; 
# 251
typedef __true_type __type; 
# 252
}; 
# 257
template< class _Tp> 
# 258
struct __is_floating { 
# 260
enum { __value}; 
# 261
typedef __false_type __type; 
# 262
}; 
# 266
template<> struct __is_floating< float>  { 
# 268
enum { __value = 1}; 
# 269
typedef __true_type __type; 
# 270
}; 
# 273
template<> struct __is_floating< double>  { 
# 275
enum { __value = 1}; 
# 276
typedef __true_type __type; 
# 277
}; 
# 280
template<> struct __is_floating< long double>  { 
# 282
enum { __value = 1}; 
# 283
typedef __true_type __type; 
# 284
}; 
# 289
template< class _Tp> 
# 290
struct __is_pointer { 
# 292
enum { __value}; 
# 293
typedef __false_type __type; 
# 294
}; 
# 296
template< class _Tp> 
# 297
struct __is_pointer< _Tp *>  { 
# 299
enum { __value = 1}; 
# 300
typedef __true_type __type; 
# 301
}; 
# 306
template< class _Tp> 
# 307
struct __is_normal_iterator { 
# 309
enum { __value}; 
# 310
typedef __false_type __type; 
# 311
}; 
# 313
template< class _Iterator, class _Container> 
# 314
struct __is_normal_iterator< __gnu_cxx::__normal_iterator< _Iterator, _Container> >  { 
# 317
enum { __value = 1}; 
# 318
typedef __true_type __type; 
# 319
}; 
# 324
template< class _Tp> 
# 325
struct __is_arithmetic : public __traitor< __is_integer< _Tp> , __is_floating< _Tp> >  { 
# 327
}; 
# 332
template< class _Tp> 
# 333
struct __is_fundamental : public __traitor< __is_void< _Tp> , __is_arithmetic< _Tp> >  { 
# 335
}; 
# 340
template< class _Tp> 
# 341
struct __is_scalar : public __traitor< __is_arithmetic< _Tp> , __is_pointer< _Tp> >  { 
# 343
}; 
# 348
template< class _Tp> 
# 349
struct __is_char { 
# 351
enum { __value}; 
# 352
typedef __false_type __type; 
# 353
}; 
# 356
template<> struct __is_char< char>  { 
# 358
enum { __value = 1}; 
# 359
typedef __true_type __type; 
# 360
}; 
# 364
template<> struct __is_char< wchar_t>  { 
# 366
enum { __value = 1}; 
# 367
typedef __true_type __type; 
# 368
}; 
# 371
template< class _Tp> 
# 372
struct __is_byte { 
# 374
enum { __value}; 
# 375
typedef __false_type __type; 
# 376
}; 
# 379
template<> struct __is_byte< char>  { 
# 381
enum { __value = 1}; 
# 382
typedef __true_type __type; 
# 383
}; 
# 386
template<> struct __is_byte< signed char>  { 
# 388
enum { __value = 1}; 
# 389
typedef __true_type __type; 
# 390
}; 
# 393
template<> struct __is_byte< unsigned char>  { 
# 395
enum { __value = 1}; 
# 396
typedef __true_type __type; 
# 397
}; 
# 402
template< class _Tp> 
# 403
struct __is_move_iterator { 
# 405
enum { __value}; 
# 406
typedef __false_type __type; 
# 407
}; 
# 422
}
# 37 "/usr/include/c++/4.8.2/ext/type_traits.h" 3
namespace __gnu_cxx __attribute((__visibility__("default"))) { 
# 42
template< bool , class > 
# 43
struct __enable_if { 
# 44
}; 
# 46
template< class _Tp> 
# 47
struct __enable_if< true, _Tp>  { 
# 48
typedef _Tp __type; }; 
# 52
template< bool _Cond, class _Iftrue, class _Iffalse> 
# 53
struct __conditional_type { 
# 54
typedef _Iftrue __type; }; 
# 56
template< class _Iftrue, class _Iffalse> 
# 57
struct __conditional_type< false, _Iftrue, _Iffalse>  { 
# 58
typedef _Iffalse __type; }; 
# 62
template< class _Tp> 
# 63
struct __add_unsigned { 
# 66
private: typedef __enable_if< std::__is_integer< _Tp> ::__value, _Tp>  __if_type; 
# 69
public: typedef typename __enable_if< std::__is_integer< _Tp> ::__value, _Tp> ::__type __type; 
# 70
}; 
# 73
template<> struct __add_unsigned< char>  { 
# 74
typedef unsigned char __type; }; 
# 77
template<> struct __add_unsigned< signed char>  { 
# 78
typedef unsigned char __type; }; 
# 81
template<> struct __add_unsigned< short>  { 
# 82
typedef unsigned short __type; }; 
# 85
template<> struct __add_unsigned< int>  { 
# 86
typedef unsigned __type; }; 
# 89
template<> struct __add_unsigned< long>  { 
# 90
typedef unsigned long __type; }; 
# 93
template<> struct __add_unsigned< long long>  { 
# 94
typedef unsigned long long __type; }; 
# 98
template<> struct __add_unsigned< bool> ; 
# 101
template<> struct __add_unsigned< wchar_t> ; 
# 105
template< class _Tp> 
# 106
struct __remove_unsigned { 
# 109
private: typedef __enable_if< std::__is_integer< _Tp> ::__value, _Tp>  __if_type; 
# 112
public: typedef typename __enable_if< std::__is_integer< _Tp> ::__value, _Tp> ::__type __type; 
# 113
}; 
# 116
template<> struct __remove_unsigned< char>  { 
# 117
typedef signed char __type; }; 
# 120
template<> struct __remove_unsigned< unsigned char>  { 
# 121
typedef signed char __type; }; 
# 124
template<> struct __remove_unsigned< unsigned short>  { 
# 125
typedef short __type; }; 
# 128
template<> struct __remove_unsigned< unsigned>  { 
# 129
typedef int __type; }; 
# 132
template<> struct __remove_unsigned< unsigned long>  { 
# 133
typedef long __type; }; 
# 136
template<> struct __remove_unsigned< unsigned long long>  { 
# 137
typedef long long __type; }; 
# 141
template<> struct __remove_unsigned< bool> ; 
# 144
template<> struct __remove_unsigned< wchar_t> ; 
# 148
template< class _Type> inline bool 
# 150
__is_null_pointer(_Type *__ptr) 
# 151
{ return __ptr == 0; } 
# 153
template< class _Type> inline bool 
# 155
__is_null_pointer(_Type) 
# 156
{ return false; } 
# 160
template< class _Tp, bool  = std::__is_integer< _Tp> ::__value> 
# 161
struct __promote { 
# 162
typedef double __type; }; 
# 167
template< class _Tp> 
# 168
struct __promote< _Tp, false>  { 
# 169
}; 
# 172
template<> struct __promote< long double>  { 
# 173
typedef long double __type; }; 
# 176
template<> struct __promote< double>  { 
# 177
typedef double __type; }; 
# 180
template<> struct __promote< float>  { 
# 181
typedef float __type; }; 
# 183
template< class _Tp, class _Up, class 
# 184
_Tp2 = typename __promote< _Tp> ::__type, class 
# 185
_Up2 = typename __promote< _Up> ::__type> 
# 186
struct __promote_2 { 
# 188
typedef __typeof__(_Tp2() + _Up2()) __type; 
# 189
}; 
# 191
template< class _Tp, class _Up, class _Vp, class 
# 192
_Tp2 = typename __promote< _Tp> ::__type, class 
# 193
_Up2 = typename __promote< _Up> ::__type, class 
# 194
_Vp2 = typename __promote< _Vp> ::__type> 
# 195
struct __promote_3 { 
# 197
typedef __typeof__((_Tp2() + _Up2()) + _Vp2()) __type; 
# 198
}; 
# 200
template< class _Tp, class _Up, class _Vp, class _Wp, class 
# 201
_Tp2 = typename __promote< _Tp> ::__type, class 
# 202
_Up2 = typename __promote< _Up> ::__type, class 
# 203
_Vp2 = typename __promote< _Vp> ::__type, class 
# 204
_Wp2 = typename __promote< _Wp> ::__type> 
# 205
struct __promote_4 { 
# 207
typedef __typeof__(((_Tp2() + _Up2()) + _Vp2()) + _Wp2()) __type; 
# 208
}; 
# 211
}
# 75 "/usr/include/c++/4.8.2/cmath" 3
namespace std __attribute((__visibility__("default"))) { 
# 81
inline double abs(double __x) 
# 82
{ return __builtin_fabs(__x); } 
# 87
inline float abs(float __x) 
# 88
{ return __builtin_fabsf(__x); } 
# 91
inline long double abs(long double __x) 
# 92
{ return __builtin_fabsl(__x); } 
# 95
template< class _Tp> inline typename __gnu_cxx::__enable_if< __is_integer< _Tp> ::__value, double> ::__type 
# 99
abs(_Tp __x) 
# 100
{ return __builtin_fabs(__x); } 
# 102
using ::acos;
# 106
inline float acos(float __x) 
# 107
{ return __builtin_acosf(__x); } 
# 110
inline long double acos(long double __x) 
# 111
{ return __builtin_acosl(__x); } 
# 114
template< class _Tp> inline typename __gnu_cxx::__enable_if< __is_integer< _Tp> ::__value, double> ::__type 
# 118
acos(_Tp __x) 
# 119
{ return __builtin_acos(__x); } 
# 121
using ::asin;
# 125
inline float asin(float __x) 
# 126
{ return __builtin_asinf(__x); } 
# 129
inline long double asin(long double __x) 
# 130
{ return __builtin_asinl(__x); } 
# 133
template< class _Tp> inline typename __gnu_cxx::__enable_if< __is_integer< _Tp> ::__value, double> ::__type 
# 137
asin(_Tp __x) 
# 138
{ return __builtin_asin(__x); } 
# 140
using ::atan;
# 144
inline float atan(float __x) 
# 145
{ return __builtin_atanf(__x); } 
# 148
inline long double atan(long double __x) 
# 149
{ return __builtin_atanl(__x); } 
# 152
template< class _Tp> inline typename __gnu_cxx::__enable_if< __is_integer< _Tp> ::__value, double> ::__type 
# 156
atan(_Tp __x) 
# 157
{ return __builtin_atan(__x); } 
# 159
using ::atan2;
# 163
inline float atan2(float __y, float __x) 
# 164
{ return __builtin_atan2f(__y, __x); } 
# 167
inline long double atan2(long double __y, long double __x) 
# 168
{ return __builtin_atan2l(__y, __x); } 
# 171
template< class _Tp, class _Up> inline typename __gnu_cxx::__promote_2< _Tp, _Up> ::__type 
# 174
atan2(_Tp __y, _Up __x) 
# 175
{ 
# 176
typedef typename __gnu_cxx::__promote_2< _Tp, _Up> ::__type __type; 
# 177
return atan2((__type)__y, (__type)__x); 
# 178
} 
# 180
using ::ceil;
# 184
inline float ceil(float __x) 
# 185
{ return __builtin_ceilf(__x); } 
# 188
inline long double ceil(long double __x) 
# 189
{ return __builtin_ceill(__x); } 
# 192
template< class _Tp> inline typename __gnu_cxx::__enable_if< __is_integer< _Tp> ::__value, double> ::__type 
# 196
ceil(_Tp __x) 
# 197
{ return __builtin_ceil(__x); } 
# 199
using ::cos;
# 203
inline float cos(float __x) 
# 204
{ return __builtin_cosf(__x); } 
# 207
inline long double cos(long double __x) 
# 208
{ return __builtin_cosl(__x); } 
# 211
template< class _Tp> inline typename __gnu_cxx::__enable_if< __is_integer< _Tp> ::__value, double> ::__type 
# 215
cos(_Tp __x) 
# 216
{ return __builtin_cos(__x); } 
# 218
using ::cosh;
# 222
inline float cosh(float __x) 
# 223
{ return __builtin_coshf(__x); } 
# 226
inline long double cosh(long double __x) 
# 227
{ return __builtin_coshl(__x); } 
# 230
template< class _Tp> inline typename __gnu_cxx::__enable_if< __is_integer< _Tp> ::__value, double> ::__type 
# 234
cosh(_Tp __x) 
# 235
{ return __builtin_cosh(__x); } 
# 237
using ::exp;
# 241
inline float exp(float __x) 
# 242
{ return __builtin_expf(__x); } 
# 245
inline long double exp(long double __x) 
# 246
{ return __builtin_expl(__x); } 
# 249
template< class _Tp> inline typename __gnu_cxx::__enable_if< __is_integer< _Tp> ::__value, double> ::__type 
# 253
exp(_Tp __x) 
# 254
{ return __builtin_exp(__x); } 
# 256
using ::fabs;
# 260
inline float fabs(float __x) 
# 261
{ return __builtin_fabsf(__x); } 
# 264
inline long double fabs(long double __x) 
# 265
{ return __builtin_fabsl(__x); } 
# 268
template< class _Tp> inline typename __gnu_cxx::__enable_if< __is_integer< _Tp> ::__value, double> ::__type 
# 272
fabs(_Tp __x) 
# 273
{ return __builtin_fabs(__x); } 
# 275
using ::floor;
# 279
inline float floor(float __x) 
# 280
{ return __builtin_floorf(__x); } 
# 283
inline long double floor(long double __x) 
# 284
{ return __builtin_floorl(__x); } 
# 287
template< class _Tp> inline typename __gnu_cxx::__enable_if< __is_integer< _Tp> ::__value, double> ::__type 
# 291
floor(_Tp __x) 
# 292
{ return __builtin_floor(__x); } 
# 294
using ::fmod;
# 298
inline float fmod(float __x, float __y) 
# 299
{ return __builtin_fmodf(__x, __y); } 
# 302
inline long double fmod(long double __x, long double __y) 
# 303
{ return __builtin_fmodl(__x, __y); } 
# 306
template< class _Tp, class _Up> inline typename __gnu_cxx::__promote_2< _Tp, _Up> ::__type 
# 309
fmod(_Tp __x, _Up __y) 
# 310
{ 
# 311
typedef typename __gnu_cxx::__promote_2< _Tp, _Up> ::__type __type; 
# 312
return fmod((__type)__x, (__type)__y); 
# 313
} 
# 315
using ::frexp;
# 319
inline float frexp(float __x, int *__exp) 
# 320
{ return __builtin_frexpf(__x, __exp); } 
# 323
inline long double frexp(long double __x, int *__exp) 
# 324
{ return __builtin_frexpl(__x, __exp); } 
# 327
template< class _Tp> inline typename __gnu_cxx::__enable_if< __is_integer< _Tp> ::__value, double> ::__type 
# 331
frexp(_Tp __x, int *__exp) 
# 332
{ return __builtin_frexp(__x, __exp); } 
# 334
using ::ldexp;
# 338
inline float ldexp(float __x, int __exp) 
# 339
{ return __builtin_ldexpf(__x, __exp); } 
# 342
inline long double ldexp(long double __x, int __exp) 
# 343
{ return __builtin_ldexpl(__x, __exp); } 
# 346
template< class _Tp> inline typename __gnu_cxx::__enable_if< __is_integer< _Tp> ::__value, double> ::__type 
# 350
ldexp(_Tp __x, int __exp) 
# 351
{ return __builtin_ldexp(__x, __exp); } 
# 353
using ::log;
# 357
inline float log(float __x) 
# 358
{ return __builtin_logf(__x); } 
# 361
inline long double log(long double __x) 
# 362
{ return __builtin_logl(__x); } 
# 365
template< class _Tp> inline typename __gnu_cxx::__enable_if< __is_integer< _Tp> ::__value, double> ::__type 
# 369
log(_Tp __x) 
# 370
{ return __builtin_log(__x); } 
# 372
using ::log10;
# 376
inline float log10(float __x) 
# 377
{ return __builtin_log10f(__x); } 
# 380
inline long double log10(long double __x) 
# 381
{ return __builtin_log10l(__x); } 
# 384
template< class _Tp> inline typename __gnu_cxx::__enable_if< __is_integer< _Tp> ::__value, double> ::__type 
# 388
log10(_Tp __x) 
# 389
{ return __builtin_log10(__x); } 
# 391
using ::modf;
# 395
inline float modf(float __x, float *__iptr) 
# 396
{ return __builtin_modff(__x, __iptr); } 
# 399
inline long double modf(long double __x, long double *__iptr) 
# 400
{ return __builtin_modfl(__x, __iptr); } 
# 403
using ::pow;
# 407
inline float pow(float __x, float __y) 
# 408
{ return __builtin_powf(__x, __y); } 
# 411
inline long double pow(long double __x, long double __y) 
# 412
{ return __builtin_powl(__x, __y); } 
# 418
inline double pow(double __x, int __i) 
# 419
{ return __builtin_powi(__x, __i); } 
# 422
inline float pow(float __x, int __n) 
# 423
{ return __builtin_powif(__x, __n); } 
# 426
inline long double pow(long double __x, int __n) 
# 427
{ return __builtin_powil(__x, __n); } 
# 431
template< class _Tp, class _Up> inline typename __gnu_cxx::__promote_2< _Tp, _Up> ::__type 
# 434
pow(_Tp __x, _Up __y) 
# 435
{ 
# 436
typedef typename __gnu_cxx::__promote_2< _Tp, _Up> ::__type __type; 
# 437
return pow((__type)__x, (__type)__y); 
# 438
} 
# 440
using ::sin;
# 444
inline float sin(float __x) 
# 445
{ return __builtin_sinf(__x); } 
# 448
inline long double sin(long double __x) 
# 449
{ return __builtin_sinl(__x); } 
# 452
template< class _Tp> inline typename __gnu_cxx::__enable_if< __is_integer< _Tp> ::__value, double> ::__type 
# 456
sin(_Tp __x) 
# 457
{ return __builtin_sin(__x); } 
# 459
using ::sinh;
# 463
inline float sinh(float __x) 
# 464
{ return __builtin_sinhf(__x); } 
# 467
inline long double sinh(long double __x) 
# 468
{ return __builtin_sinhl(__x); } 
# 471
template< class _Tp> inline typename __gnu_cxx::__enable_if< __is_integer< _Tp> ::__value, double> ::__type 
# 475
sinh(_Tp __x) 
# 476
{ return __builtin_sinh(__x); } 
# 478
using ::sqrt;
# 482
inline float sqrt(float __x) 
# 483
{ return __builtin_sqrtf(__x); } 
# 486
inline long double sqrt(long double __x) 
# 487
{ return __builtin_sqrtl(__x); } 
# 490
template< class _Tp> inline typename __gnu_cxx::__enable_if< __is_integer< _Tp> ::__value, double> ::__type 
# 494
sqrt(_Tp __x) 
# 495
{ return __builtin_sqrt(__x); } 
# 497
using ::tan;
# 501
inline float tan(float __x) 
# 502
{ return __builtin_tanf(__x); } 
# 505
inline long double tan(long double __x) 
# 506
{ return __builtin_tanl(__x); } 
# 509
template< class _Tp> inline typename __gnu_cxx::__enable_if< __is_integer< _Tp> ::__value, double> ::__type 
# 513
tan(_Tp __x) 
# 514
{ return __builtin_tan(__x); } 
# 516
using ::tanh;
# 520
inline float tanh(float __x) 
# 521
{ return __builtin_tanhf(__x); } 
# 524
inline long double tanh(long double __x) 
# 525
{ return __builtin_tanhl(__x); } 
# 528
template< class _Tp> inline typename __gnu_cxx::__enable_if< __is_integer< _Tp> ::__value, double> ::__type 
# 532
tanh(_Tp __x) 
# 533
{ return __builtin_tanh(__x); } 
# 536
}
# 555
namespace std __attribute((__visibility__("default"))) { 
# 805
template< class _Tp> inline typename __gnu_cxx::__enable_if< __is_arithmetic< _Tp> ::__value, int> ::__type 
# 808
fpclassify(_Tp __f) 
# 809
{ 
# 810
typedef typename __gnu_cxx::__promote< _Tp> ::__type __type; 
# 811
return __builtin_fpclassify(0, 1, 4, 3, 2, (__type)__f); 
# 813
} 
# 815
template< class _Tp> inline typename __gnu_cxx::__enable_if< __is_arithmetic< _Tp> ::__value, int> ::__type 
# 818
isfinite(_Tp __f) 
# 819
{ 
# 820
typedef typename __gnu_cxx::__promote< _Tp> ::__type __type; 
# 821
return __builtin_isfinite((__type)__f); 
# 822
} 
# 824
template< class _Tp> inline typename __gnu_cxx::__enable_if< __is_arithmetic< _Tp> ::__value, int> ::__type 
# 827
isinf(_Tp __f) 
# 828
{ 
# 829
typedef typename __gnu_cxx::__promote< _Tp> ::__type __type; 
# 830
return __builtin_isinf((__type)__f); 
# 831
} 
# 833
template< class _Tp> inline typename __gnu_cxx::__enable_if< __is_arithmetic< _Tp> ::__value, int> ::__type 
# 836
isnan(_Tp __f) 
# 837
{ 
# 838
typedef typename __gnu_cxx::__promote< _Tp> ::__type __type; 
# 839
return __builtin_isnan((__type)__f); 
# 840
} 
# 842
template< class _Tp> inline typename __gnu_cxx::__enable_if< __is_arithmetic< _Tp> ::__value, int> ::__type 
# 845
isnormal(_Tp __f) 
# 846
{ 
# 847
typedef typename __gnu_cxx::__promote< _Tp> ::__type __type; 
# 848
return __builtin_isnormal((__type)__f); 
# 849
} 
# 851
template< class _Tp> inline typename __gnu_cxx::__enable_if< __is_arithmetic< _Tp> ::__value, int> ::__type 
# 854
signbit(_Tp __f) 
# 855
{ 
# 856
typedef typename __gnu_cxx::__promote< _Tp> ::__type __type; 
# 857
return __builtin_signbit((__type)__f); 
# 858
} 
# 860
template< class _Tp> inline typename __gnu_cxx::__enable_if< __is_arithmetic< _Tp> ::__value, int> ::__type 
# 863
isgreater(_Tp __f1, _Tp __f2) 
# 864
{ 
# 865
typedef typename __gnu_cxx::__promote< _Tp> ::__type __type; 
# 866
return __builtin_isgreater((__type)__f1, (__type)__f2); 
# 867
} 
# 869
template< class _Tp> inline typename __gnu_cxx::__enable_if< __is_arithmetic< _Tp> ::__value, int> ::__type 
# 872
isgreaterequal(_Tp __f1, _Tp __f2) 
# 873
{ 
# 874
typedef typename __gnu_cxx::__promote< _Tp> ::__type __type; 
# 875
return __builtin_isgreaterequal((__type)__f1, (__type)__f2); 
# 876
} 
# 878
template< class _Tp> inline typename __gnu_cxx::__enable_if< __is_arithmetic< _Tp> ::__value, int> ::__type 
# 881
isless(_Tp __f1, _Tp __f2) 
# 882
{ 
# 883
typedef typename __gnu_cxx::__promote< _Tp> ::__type __type; 
# 884
return __builtin_isless((__type)__f1, (__type)__f2); 
# 885
} 
# 887
template< class _Tp> inline typename __gnu_cxx::__enable_if< __is_arithmetic< _Tp> ::__value, int> ::__type 
# 890
islessequal(_Tp __f1, _Tp __f2) 
# 891
{ 
# 892
typedef typename __gnu_cxx::__promote< _Tp> ::__type __type; 
# 893
return __builtin_islessequal((__type)__f1, (__type)__f2); 
# 894
} 
# 896
template< class _Tp> inline typename __gnu_cxx::__enable_if< __is_arithmetic< _Tp> ::__value, int> ::__type 
# 899
islessgreater(_Tp __f1, _Tp __f2) 
# 900
{ 
# 901
typedef typename __gnu_cxx::__promote< _Tp> ::__type __type; 
# 902
return __builtin_islessgreater((__type)__f1, (__type)__f2); 
# 903
} 
# 905
template< class _Tp> inline typename __gnu_cxx::__enable_if< __is_arithmetic< _Tp> ::__value, int> ::__type 
# 908
isunordered(_Tp __f1, _Tp __f2) 
# 909
{ 
# 910
typedef typename __gnu_cxx::__promote< _Tp> ::__type __type; 
# 911
return __builtin_isunordered((__type)__f1, (__type)__f2); 
# 912
} 
# 917
}
# 114 "/usr/include/c++/4.8.2/cstdlib" 3
namespace std __attribute((__visibility__("default"))) { 
# 118
using ::div_t;
# 119
using ::ldiv_t;
# 121
using ::abort;
# 122
using ::abs;
# 123
using ::atexit;
# 129
using ::atof;
# 130
using ::atoi;
# 131
using ::atol;
# 132
using ::bsearch;
# 133
using ::calloc;
# 134
using ::div;
# 135
using ::exit;
# 136
using ::free;
# 137
using ::getenv;
# 138
using ::labs;
# 139
using ::ldiv;
# 140
using ::malloc;
# 142
using ::mblen;
# 143
using ::mbstowcs;
# 144
using ::mbtowc;
# 146
using ::qsort;
# 152
using ::rand;
# 153
using ::realloc;
# 154
using ::srand;
# 155
using ::strtod;
# 156
using ::strtol;
# 157
using ::strtoul;
# 158
using ::system;
# 160
using ::wcstombs;
# 161
using ::wctomb;
# 166
inline long abs(long __i) { return __builtin_labs(__i); } 
# 169
inline ldiv_t div(long __i, long __j) { return ldiv(__i, __j); } 
# 174
inline long long abs(long long __x) { return __builtin_llabs(__x); } 
# 179
inline __int128_t abs(__int128_t __x) { return (__x >= (0)) ? __x : (-__x); } 
# 183
}
# 196
namespace __gnu_cxx __attribute((__visibility__("default"))) { 
# 201
using ::lldiv_t;
# 207
using ::_Exit;
# 211
using ::llabs;
# 214
inline lldiv_t div(long long __n, long long __d) 
# 215
{ lldiv_t __q; (__q.quot) = (__n / __d); (__q.rem) = (__n % __d); return __q; } 
# 217
using ::lldiv;
# 228
using ::atoll;
# 229
using ::strtoll;
# 230
using ::strtoull;
# 232
using ::strtof;
# 233
using ::strtold;
# 236
}
# 238
namespace std { 
# 241
using __gnu_cxx::lldiv_t;
# 243
using __gnu_cxx::_Exit;
# 245
using __gnu_cxx::llabs;
# 246
using __gnu_cxx::div;
# 247
using __gnu_cxx::lldiv;
# 249
using __gnu_cxx::atoll;
# 250
using __gnu_cxx::strtof;
# 251
using __gnu_cxx::strtoll;
# 252
using __gnu_cxx::strtoull;
# 253
using __gnu_cxx::strtold;
# 254
}
# 8925 "/usr/local/cuda-8.0/include/math_functions.h"
__attribute((always_inline)) inline int signbit(float x); 
# 8929
__attribute((always_inline)) inline int signbit(double x); 
# 8931
__attribute((always_inline)) inline int signbit(long double x); 
# 8933
__attribute((always_inline)) inline int isfinite(float x); 
# 8937
__attribute((always_inline)) inline int isfinite(double x); 
# 8939
__attribute((always_inline)) inline int isfinite(long double x); 
# 8941
__attribute((always_inline)) inline int isnan(float x); 
# 8945
extern "C" __attribute((always_inline)) inline int isnan(double x) throw(); 
# 8947
__attribute((always_inline)) inline int isnan(long double x); 
# 8949
__attribute((always_inline)) inline int isinf(float x); 
# 8953
extern "C" __attribute((always_inline)) inline int isinf(double x) throw(); 
# 8955
__attribute((always_inline)) inline int isinf(long double x); 
# 9002
namespace std { 
# 9004
template< class T> extern T __pow_helper(T, int); 
# 9005
template< class T> extern T __cmath_power(T, unsigned); 
# 9006
}
# 9008
using std::abs;
# 9009
using std::fabs;
# 9010
using std::ceil;
# 9011
using std::floor;
# 9012
using std::sqrt;
# 9013
using std::pow;
# 9014
using std::log;
# 9015
using std::log10;
# 9016
using std::fmod;
# 9017
using std::modf;
# 9018
using std::exp;
# 9019
using std::frexp;
# 9020
using std::ldexp;
# 9021
using std::asin;
# 9022
using std::sin;
# 9023
using std::sinh;
# 9024
using std::acos;
# 9025
using std::cos;
# 9026
using std::cosh;
# 9027
using std::atan;
# 9028
using std::atan2;
# 9029
using std::tan;
# 9030
using std::tanh;
# 9393
namespace std { 
# 9406
extern inline long long abs(long long); 
# 9412
extern inline long abs(long); 
# 9413
extern inline float abs(float); 
# 9414
extern inline double abs(double); 
# 9415
extern inline float fabs(float); 
# 9416
extern inline float ceil(float); 
# 9417
extern inline float floor(float); 
# 9418
extern inline float sqrt(float); 
# 9419
extern inline float pow(float, float); 
# 9428
extern inline float pow(float, int); 
# 9429
extern inline double pow(double, int); 
# 9434
extern inline float log(float); 
# 9435
extern inline float log10(float); 
# 9436
extern inline float fmod(float, float); 
# 9437
extern inline float modf(float, float *); 
# 9438
extern inline float exp(float); 
# 9439
extern inline float frexp(float, int *); 
# 9440
extern inline float ldexp(float, int); 
# 9441
extern inline float asin(float); 
# 9442
extern inline float sin(float); 
# 9443
extern inline float sinh(float); 
# 9444
extern inline float acos(float); 
# 9445
extern inline float cos(float); 
# 9446
extern inline float cosh(float); 
# 9447
extern inline float atan(float); 
# 9448
extern inline float atan2(float, float); 
# 9449
extern inline float tan(float); 
# 9450
extern inline float tanh(float); 
# 9518
}
# 9609
static inline float logb(float a); 
# 9611
static inline int ilogb(float a); 
# 9613
static inline float scalbn(float a, int b); 
# 9615
static inline float scalbln(float a, long b); 
# 9617
static inline float exp2(float a); 
# 9619
static inline float expm1(float a); 
# 9621
static inline float log2(float a); 
# 9623
static inline float log1p(float a); 
# 9625
static inline float acosh(float a); 
# 9627
static inline float asinh(float a); 
# 9629
static inline float atanh(float a); 
# 9631
static inline float hypot(float a, float b); 
# 9633
static inline float norm3d(float a, float b, float c); 
# 9635
static inline float norm4d(float a, float b, float c, float d); 
# 9637
static inline float cbrt(float a); 
# 9639
static inline float erf(float a); 
# 9641
static inline float erfc(float a); 
# 9643
static inline float lgamma(float a); 
# 9645
static inline float tgamma(float a); 
# 9647
static inline float copysign(float a, float b); 
# 9649
static inline float nextafter(float a, float b); 
# 9651
static inline float remainder(float a, float b); 
# 9653
static inline float remquo(float a, float b, int * quo); 
# 9655
static inline float round(float a); 
# 9657
static inline long lround(float a); 
# 9659
static inline long long llround(float a); 
# 9661
static inline float trunc(float a); 
# 9663
static inline float rint(float a); 
# 9665
static inline long lrint(float a); 
# 9667
static inline long long llrint(float a); 
# 9669
static inline float nearbyint(float a); 
# 9671
static inline float fdim(float a, float b); 
# 9673
static inline float fma(float a, float b, float c); 
# 9675
static inline float fmax(float a, float b); 
# 9677
static inline float fmin(float a, float b); 
# 9718
static inline float exp10(float a); 
# 9720
static inline float rsqrt(float a); 
# 9722
static inline float rcbrt(float a); 
# 9724
static inline float sinpi(float a); 
# 9726
static inline float cospi(float a); 
# 9728
static inline void sincospi(float a, float * sptr, float * cptr); 
# 9730
static inline void sincos(float a, float * sptr, float * cptr); 
# 9732
static inline float j0(float a); 
# 9734
static inline float j1(float a); 
# 9736
static inline float jn(int n, float a); 
# 9738
static inline float y0(float a); 
# 9740
static inline float y1(float a); 
# 9742
static inline float yn(int n, float a); 
# 9744
static inline float cyl_bessel_i0(float a); 
# 9746
static inline float cyl_bessel_i1(float a); 
# 9748
static inline float erfinv(float a); 
# 9750
static inline float erfcinv(float a); 
# 9752
static inline float normcdfinv(float a); 
# 9754
static inline float normcdf(float a); 
# 9756
static inline float erfcx(float a); 
# 9758
static inline double copysign(double a, float b); 
# 9760
static inline float copysign(float a, double b); 
# 9762
static inline unsigned min(unsigned a, unsigned b); 
# 9764
static inline unsigned min(int a, unsigned b); 
# 9766
static inline unsigned min(unsigned a, int b); 
# 9768
static inline long min(long a, long b); 
# 9770
static inline unsigned long min(unsigned long a, unsigned long b); 
# 9772
static inline unsigned long min(long a, unsigned long b); 
# 9774
static inline unsigned long min(unsigned long a, long b); 
# 9776
static inline long long min(long long a, long long b); 
# 9778
static inline unsigned long long min(unsigned long long a, unsigned long long b); 
# 9780
static inline unsigned long long min(long long a, unsigned long long b); 
# 9782
static inline unsigned long long min(unsigned long long a, long long b); 
# 9784
static inline float min(float a, float b); 
# 9786
static inline double min(double a, double b); 
# 9788
static inline double min(float a, double b); 
# 9790
static inline double min(double a, float b); 
# 9792
static inline unsigned max(unsigned a, unsigned b); 
# 9794
static inline unsigned max(int a, unsigned b); 
# 9796
static inline unsigned max(unsigned a, int b); 
# 9798
static inline long max(long a, long b); 
# 9800
static inline unsigned long max(unsigned long a, unsigned long b); 
# 9802
static inline unsigned long max(long a, unsigned long b); 
# 9804
static inline unsigned long max(unsigned long a, long b); 
# 9806
static inline long long max(long long a, long long b); 
# 9808
static inline unsigned long long max(unsigned long long a, unsigned long long b); 
# 9810
static inline unsigned long long max(long long a, unsigned long long b); 
# 9812
static inline unsigned long long max(unsigned long long a, long long b); 
# 9814
static inline float max(float a, float b); 
# 9816
static inline double max(double a, double b); 
# 9818
static inline double max(float a, double b); 
# 9820
static inline double max(double a, float b); 
# 248 "/usr/local/cuda-8.0/include/math_functions.hpp"
__attribute((always_inline)) inline int signbit(float x) { return __signbitf(x); } 
# 252
__attribute((always_inline)) inline int signbit(double x) { return __signbit(x); } 
# 254
__attribute((always_inline)) inline int signbit(long double x) { return __signbitl(x); } 
# 265
__attribute((always_inline)) inline int isfinite(float x) { return __finitef(x); } 
# 280
__attribute((always_inline)) inline int isfinite(double x) { return __finite(x); } 
# 293
__attribute((always_inline)) inline int isfinite(long double x) { return __finitel(x); } 
# 296
__attribute((always_inline)) inline int isnan(float x) { return __isnanf(x); } 
# 300
extern "C" __attribute((always_inline)) inline int isnan(double x) throw() { return __isnan(x); } 
# 302
__attribute((always_inline)) inline int isnan(long double x) { return __isnanl(x); } 
# 304
__attribute((always_inline)) inline int isinf(float x) { return __isinff(x); } 
# 308
extern "C" __attribute((always_inline)) inline int isinf(double x) throw() { return __isinf(x); } 
# 310
__attribute((always_inline)) inline int isinf(long double x) { return __isinfl(x); } 
# 503
static inline float logb(float a) 
# 504
{ 
# 505
return logbf(a); 
# 506
} 
# 508
static inline int ilogb(float a) 
# 509
{ 
# 510
return ilogbf(a); 
# 511
} 
# 513
static inline float scalbn(float a, int b) 
# 514
{ 
# 515
return scalbnf(a, b); 
# 516
} 
# 518
static inline float scalbln(float a, long b) 
# 519
{ 
# 520
return scalblnf(a, b); 
# 521
} 
# 523
static inline float exp2(float a) 
# 524
{ 
# 525
return exp2f(a); 
# 526
} 
# 528
static inline float expm1(float a) 
# 529
{ 
# 530
return expm1f(a); 
# 531
} 
# 533
static inline float log2(float a) 
# 534
{ 
# 535
return log2f(a); 
# 536
} 
# 538
static inline float log1p(float a) 
# 539
{ 
# 540
return log1pf(a); 
# 541
} 
# 543
static inline float acosh(float a) 
# 544
{ 
# 545
return acoshf(a); 
# 546
} 
# 548
static inline float asinh(float a) 
# 549
{ 
# 550
return asinhf(a); 
# 551
} 
# 553
static inline float atanh(float a) 
# 554
{ 
# 555
return atanhf(a); 
# 556
} 
# 558
static inline float hypot(float a, float b) 
# 559
{ 
# 560
return hypotf(a, b); 
# 561
} 
# 563
static inline float norm3d(float a, float b, float c) 
# 564
{ 
# 565
return norm3df(a, b, c); 
# 566
} 
# 568
static inline float norm4d(float a, float b, float c, float d) 
# 569
{ 
# 570
return norm4df(a, b, c, d); 
# 571
} 
# 573
static inline float cbrt(float a) 
# 574
{ 
# 575
return cbrtf(a); 
# 576
} 
# 578
static inline float erf(float a) 
# 579
{ 
# 580
return erff(a); 
# 581
} 
# 583
static inline float erfc(float a) 
# 584
{ 
# 585
return erfcf(a); 
# 586
} 
# 588
static inline float lgamma(float a) 
# 589
{ 
# 590
return lgammaf(a); 
# 591
} 
# 593
static inline float tgamma(float a) 
# 594
{ 
# 595
return tgammaf(a); 
# 596
} 
# 598
static inline float copysign(float a, float b) 
# 599
{ 
# 600
return copysignf(a, b); 
# 601
} 
# 603
static inline float nextafter(float a, float b) 
# 604
{ 
# 605
return nextafterf(a, b); 
# 606
} 
# 608
static inline float remainder(float a, float b) 
# 609
{ 
# 610
return remainderf(a, b); 
# 611
} 
# 613
static inline float remquo(float a, float b, int *quo) 
# 614
{ 
# 615
return remquof(a, b, quo); 
# 616
} 
# 618
static inline float round(float a) 
# 619
{ 
# 620
return roundf(a); 
# 621
} 
# 623
static inline long lround(float a) 
# 624
{ 
# 625
return lroundf(a); 
# 626
} 
# 628
static inline long long llround(float a) 
# 629
{ 
# 630
return llroundf(a); 
# 631
} 
# 633
static inline float trunc(float a) 
# 634
{ 
# 635
return truncf(a); 
# 636
} 
# 638
static inline float rint(float a) 
# 639
{ 
# 640
return rintf(a); 
# 641
} 
# 643
static inline long lrint(float a) 
# 644
{ 
# 645
return lrintf(a); 
# 646
} 
# 648
static inline long long llrint(float a) 
# 649
{ 
# 650
return llrintf(a); 
# 651
} 
# 653
static inline float nearbyint(float a) 
# 654
{ 
# 655
return nearbyintf(a); 
# 656
} 
# 658
static inline float fdim(float a, float b) 
# 659
{ 
# 660
return fdimf(a, b); 
# 661
} 
# 663
static inline float fma(float a, float b, float c) 
# 664
{ 
# 665
return fmaf(a, b, c); 
# 666
} 
# 668
static inline float fmax(float a, float b) 
# 669
{ 
# 670
return fmaxf(a, b); 
# 671
} 
# 673
static inline float fmin(float a, float b) 
# 674
{ 
# 675
return fminf(a, b); 
# 676
} 
# 681
static inline float exp10(float a) 
# 682
{ 
# 683
return exp10f(a); 
# 684
} 
# 686
static inline float rsqrt(float a) 
# 687
{ 
# 688
return rsqrtf(a); 
# 689
} 
# 691
static inline float rcbrt(float a) 
# 692
{ 
# 693
return rcbrtf(a); 
# 694
} 
# 696
static inline float sinpi(float a) 
# 697
{ 
# 698
return sinpif(a); 
# 699
} 
# 701
static inline float cospi(float a) 
# 702
{ 
# 703
return cospif(a); 
# 704
} 
# 706
static inline void sincospi(float a, float *sptr, float *cptr) 
# 707
{ 
# 708
sincospif(a, sptr, cptr); 
# 709
} 
# 711
static inline void sincos(float a, float *sptr, float *cptr) 
# 712
{ 
# 713
sincosf(a, sptr, cptr); 
# 714
} 
# 716
static inline float j0(float a) 
# 717
{ 
# 718
return j0f(a); 
# 719
} 
# 721
static inline float j1(float a) 
# 722
{ 
# 723
return j1f(a); 
# 724
} 
# 726
static inline float jn(int n, float a) 
# 727
{ 
# 728
return jnf(n, a); 
# 729
} 
# 731
static inline float y0(float a) 
# 732
{ 
# 733
return y0f(a); 
# 734
} 
# 736
static inline float y1(float a) 
# 737
{ 
# 738
return y1f(a); 
# 739
} 
# 741
static inline float yn(int n, float a) 
# 742
{ 
# 743
return ynf(n, a); 
# 744
} 
# 746
static inline float cyl_bessel_i0(float a) 
# 747
{ 
# 748
return cyl_bessel_i0f(a); 
# 749
} 
# 751
static inline float cyl_bessel_i1(float a) 
# 752
{ 
# 753
return cyl_bessel_i1f(a); 
# 754
} 
# 756
static inline float erfinv(float a) 
# 757
{ 
# 758
return erfinvf(a); 
# 759
} 
# 761
static inline float erfcinv(float a) 
# 762
{ 
# 763
return erfcinvf(a); 
# 764
} 
# 766
static inline float normcdfinv(float a) 
# 767
{ 
# 768
return normcdfinvf(a); 
# 769
} 
# 771
static inline float normcdf(float a) 
# 772
{ 
# 773
return normcdff(a); 
# 774
} 
# 776
static inline float erfcx(float a) 
# 777
{ 
# 778
return erfcxf(a); 
# 779
} 
# 781
static inline double copysign(double a, float b) 
# 782
{ 
# 783
return copysign(a, (double)b); 
# 784
} 
# 786
static inline float copysign(float a, double b) 
# 787
{ 
# 788
return copysignf(a, (float)b); 
# 789
} 
# 791
static inline unsigned min(unsigned a, unsigned b) 
# 792
{ 
# 793
return umin(a, b); 
# 794
} 
# 796
static inline unsigned min(int a, unsigned b) 
# 797
{ 
# 798
return umin((unsigned)a, b); 
# 799
} 
# 801
static inline unsigned min(unsigned a, int b) 
# 802
{ 
# 803
return umin(a, (unsigned)b); 
# 804
} 
# 806
static inline long min(long a, long b) 
# 807
{ 
# 813
if (sizeof(long) == sizeof(int)) { 
# 817
return (long)min((int)a, (int)b); 
# 818
} else { 
# 819
return (long)llmin((long long)a, (long long)b); 
# 820
}  
# 821
} 
# 823
static inline unsigned long min(unsigned long a, unsigned long b) 
# 824
{ 
# 828
if (sizeof(unsigned long) == sizeof(unsigned)) { 
# 832
return (unsigned long)umin((unsigned)a, (unsigned)b); 
# 833
} else { 
# 834
return (unsigned long)ullmin((unsigned long long)a, (unsigned long long)b); 
# 835
}  
# 836
} 
# 838
static inline unsigned long min(long a, unsigned long b) 
# 839
{ 
# 843
if (sizeof(unsigned long) == sizeof(unsigned)) { 
# 847
return (unsigned long)umin((unsigned)a, (unsigned)b); 
# 848
} else { 
# 849
return (unsigned long)ullmin((unsigned long long)a, (unsigned long long)b); 
# 850
}  
# 851
} 
# 853
static inline unsigned long min(unsigned long a, long b) 
# 854
{ 
# 858
if (sizeof(unsigned long) == sizeof(unsigned)) { 
# 862
return (unsigned long)umin((unsigned)a, (unsigned)b); 
# 863
} else { 
# 864
return (unsigned long)ullmin((unsigned long long)a, (unsigned long long)b); 
# 865
}  
# 866
} 
# 868
static inline long long min(long long a, long long b) 
# 869
{ 
# 870
return llmin(a, b); 
# 871
} 
# 873
static inline unsigned long long min(unsigned long long a, unsigned long long b) 
# 874
{ 
# 875
return ullmin(a, b); 
# 876
} 
# 878
static inline unsigned long long min(long long a, unsigned long long b) 
# 879
{ 
# 880
return ullmin((unsigned long long)a, b); 
# 881
} 
# 883
static inline unsigned long long min(unsigned long long a, long long b) 
# 884
{ 
# 885
return ullmin(a, (unsigned long long)b); 
# 886
} 
# 888
static inline float min(float a, float b) 
# 889
{ 
# 890
return fminf(a, b); 
# 891
} 
# 893
static inline double min(double a, double b) 
# 894
{ 
# 895
return fmin(a, b); 
# 896
} 
# 898
static inline double min(float a, double b) 
# 899
{ 
# 900
return fmin((double)a, b); 
# 901
} 
# 903
static inline double min(double a, float b) 
# 904
{ 
# 905
return fmin(a, (double)b); 
# 906
} 
# 908
static inline unsigned max(unsigned a, unsigned b) 
# 909
{ 
# 910
return umax(a, b); 
# 911
} 
# 913
static inline unsigned max(int a, unsigned b) 
# 914
{ 
# 915
return umax((unsigned)a, b); 
# 916
} 
# 918
static inline unsigned max(unsigned a, int b) 
# 919
{ 
# 920
return umax(a, (unsigned)b); 
# 921
} 
# 923
static inline long max(long a, long b) 
# 924
{ 
# 929
if (sizeof(long) == sizeof(int)) { 
# 933
return (long)max((int)a, (int)b); 
# 934
} else { 
# 935
return (long)llmax((long long)a, (long long)b); 
# 936
}  
# 937
} 
# 939
static inline unsigned long max(unsigned long a, unsigned long b) 
# 940
{ 
# 944
if (sizeof(unsigned long) == sizeof(unsigned)) { 
# 948
return (unsigned long)umax((unsigned)a, (unsigned)b); 
# 949
} else { 
# 950
return (unsigned long)ullmax((unsigned long long)a, (unsigned long long)b); 
# 951
}  
# 952
} 
# 954
static inline unsigned long max(long a, unsigned long b) 
# 955
{ 
# 959
if (sizeof(unsigned long) == sizeof(unsigned)) { 
# 963
return (unsigned long)umax((unsigned)a, (unsigned)b); 
# 964
} else { 
# 965
return (unsigned long)ullmax((unsigned long long)a, (unsigned long long)b); 
# 966
}  
# 967
} 
# 969
static inline unsigned long max(unsigned long a, long b) 
# 970
{ 
# 974
if (sizeof(unsigned long) == sizeof(unsigned)) { 
# 978
return (unsigned long)umax((unsigned)a, (unsigned)b); 
# 979
} else { 
# 980
return (unsigned long)ullmax((unsigned long long)a, (unsigned long long)b); 
# 981
}  
# 982
} 
# 984
static inline long long max(long long a, long long b) 
# 985
{ 
# 986
return llmax(a, b); 
# 987
} 
# 989
static inline unsigned long long max(unsigned long long a, unsigned long long b) 
# 990
{ 
# 991
return ullmax(a, b); 
# 992
} 
# 994
static inline unsigned long long max(long long a, unsigned long long b) 
# 995
{ 
# 996
return ullmax((unsigned long long)a, b); 
# 997
} 
# 999
static inline unsigned long long max(unsigned long long a, long long b) 
# 1000
{ 
# 1001
return ullmax(a, (unsigned long long)b); 
# 1002
} 
# 1004
static inline float max(float a, float b) 
# 1005
{ 
# 1006
return fmaxf(a, b); 
# 1007
} 
# 1009
static inline double max(double a, double b) 
# 1010
{ 
# 1011
return fmax(a, b); 
# 1012
} 
# 1014
static inline double max(float a, double b) 
# 1015
{ 
# 1016
return fmax((double)a, b); 
# 1017
} 
# 1019
static inline double max(double a, float b) 
# 1020
{ 
# 1021
return fmax(a, (double)b); 
# 1022
} 
# 1033
extern "C" inline int min(int a, int b) 
# 1034
{ 
# 1035
return (a < b) ? a : b; 
# 1036
} 
# 1038
extern "C" inline unsigned umin(unsigned a, unsigned b) 
# 1039
{ 
# 1040
return (a < b) ? a : b; 
# 1041
} 
# 1043
extern "C" inline long long llmin(long long a, long long b) 
# 1044
{ 
# 1045
return (a < b) ? a : b; 
# 1046
} 
# 1048
extern "C" inline unsigned long long ullmin(unsigned long long a, unsigned long long 
# 1049
b) 
# 1050
{ 
# 1051
return (a < b) ? a : b; 
# 1052
} 
# 1054
extern "C" inline int max(int a, int b) 
# 1055
{ 
# 1056
return (a > b) ? a : b; 
# 1057
} 
# 1059
extern "C" inline unsigned umax(unsigned a, unsigned b) 
# 1060
{ 
# 1061
return (a > b) ? a : b; 
# 1062
} 
# 1064
extern "C" inline long long llmax(long long a, long long b) 
# 1065
{ 
# 1066
return (a > b) ? a : b; 
# 1067
} 
# 1069
extern "C" inline unsigned long long ullmax(unsigned long long a, unsigned long long 
# 1070
b) 
# 1071
{ 
# 1072
return (a > b) ? a : b; 
# 1073
} 
# 77 "/usr/local/cuda-8.0/include/cuda_surface_types.h"
template< class T, int dim = 1> 
# 78
struct surface : public surfaceReference { 
# 81
surface() 
# 82
{ 
# 83
(surfaceReference::channelDesc) = cudaCreateChannelDesc< T> (); 
# 84
} 
# 86
surface(cudaChannelFormatDesc desc) 
# 87
{ 
# 88
(surfaceReference::channelDesc) = desc; 
# 89
} 
# 91
}; 
# 93
template< int dim> 
# 94
struct surface< void, dim>  : public surfaceReference { 
# 97
surface() 
# 98
{ 
# 99
(surfaceReference::channelDesc) = cudaCreateChannelDesc< void> (); 
# 100
} 
# 102
}; 
# 77 "/usr/local/cuda-8.0/include/cuda_texture_types.h"
template< class T, int texType = 1, cudaTextureReadMode mode = cudaReadModeElementType> 
# 78
struct texture : public textureReference { 
# 81
texture(int norm = 0, cudaTextureFilterMode 
# 82
fMode = cudaFilterModePoint, cudaTextureAddressMode 
# 83
aMode = cudaAddressModeClamp) 
# 84
{ 
# 85
(textureReference::normalized) = norm; 
# 86
(textureReference::filterMode) = fMode; 
# 87
((textureReference::addressMode)[0]) = aMode; 
# 88
((textureReference::addressMode)[1]) = aMode; 
# 89
((textureReference::addressMode)[2]) = aMode; 
# 90
(textureReference::channelDesc) = cudaCreateChannelDesc< T> (); 
# 91
(textureReference::sRGB) = 0; 
# 92
} 
# 94
texture(int norm, cudaTextureFilterMode 
# 95
fMode, cudaTextureAddressMode 
# 96
aMode, cudaChannelFormatDesc 
# 97
desc) 
# 98
{ 
# 99
(textureReference::normalized) = norm; 
# 100
(textureReference::filterMode) = fMode; 
# 101
((textureReference::addressMode)[0]) = aMode; 
# 102
((textureReference::addressMode)[1]) = aMode; 
# 103
((textureReference::addressMode)[2]) = aMode; 
# 104
(textureReference::channelDesc) = desc; 
# 105
(textureReference::sRGB) = 0; 
# 106
} 
# 108
}; 
# 90 "/usr/local/cuda-8.0/include/device_functions.h"
extern "C" {
# 3230
}
# 3238
__attribute__((unused)) static inline int mulhi(int a, int b); 
# 3240
__attribute__((unused)) static inline unsigned mulhi(unsigned a, unsigned b); 
# 3242
__attribute__((unused)) static inline unsigned mulhi(int a, unsigned b); 
# 3244
__attribute__((unused)) static inline unsigned mulhi(unsigned a, int b); 
# 3246
__attribute__((unused)) static inline long long mul64hi(long long a, long long b); 
# 3248
__attribute__((unused)) static inline unsigned long long mul64hi(unsigned long long a, unsigned long long b); 
# 3250
__attribute__((unused)) static inline unsigned long long mul64hi(long long a, unsigned long long b); 
# 3252
__attribute__((unused)) static inline unsigned long long mul64hi(unsigned long long a, long long b); 
# 3254
__attribute__((unused)) static inline int float_as_int(float a); 
# 3256
__attribute__((unused)) static inline float int_as_float(int a); 
# 3258
__attribute__((unused)) static inline unsigned float_as_uint(float a); 
# 3260
__attribute__((unused)) static inline float uint_as_float(unsigned a); 
# 3262
__attribute__((unused)) static inline float saturate(float a); 
# 3264
__attribute__((unused)) static inline int mul24(int a, int b); 
# 3266
__attribute__((unused)) static inline unsigned umul24(unsigned a, unsigned b); 
# 3268
__attribute((deprecated("Please use __trap() instead."))) __attribute__((unused)) static inline void trap(); 
# 3271
__attribute((deprecated("Please use __brkpt() instead."))) __attribute__((unused)) static inline void brkpt(int c = 0); 
# 3273
__attribute((deprecated("Please use __syncthreads() instead."))) __attribute__((unused)) static inline void syncthreads(); 
# 3275
__attribute((deprecated("Please use __prof_trigger() instead."))) __attribute__((unused)) static inline void prof_trigger(int e); 
# 3277
__attribute((deprecated("Please use __threadfence() instead."))) __attribute__((unused)) static inline void threadfence(bool global = true); 
# 3279
__attribute__((unused)) static inline int float2int(float a, cudaRoundMode mode = cudaRoundZero); 
# 3281
__attribute__((unused)) static inline unsigned float2uint(float a, cudaRoundMode mode = cudaRoundZero); 
# 3283
__attribute__((unused)) static inline float int2float(int a, cudaRoundMode mode = cudaRoundNearest); 
# 3285
__attribute__((unused)) static inline float uint2float(unsigned a, cudaRoundMode mode = cudaRoundNearest); 
# 83 "/usr/local/cuda-8.0/include/device_functions.hpp"
__attribute__((unused)) static inline int mulhi(int a, int b) 
# 84
{int volatile ___ = 1;(void)a;(void)b;
# 86
::exit(___);}
#if 0
# 84
{ 
# 85
return __mulhi(a, b); 
# 86
} 
#endif
# 88 "/usr/local/cuda-8.0/include/device_functions.hpp"
__attribute__((unused)) static inline unsigned mulhi(unsigned a, unsigned b) 
# 89
{int volatile ___ = 1;(void)a;(void)b;
# 91
::exit(___);}
#if 0
# 89
{ 
# 90
return __umulhi(a, b); 
# 91
} 
#endif
# 93 "/usr/local/cuda-8.0/include/device_functions.hpp"
__attribute__((unused)) static inline unsigned mulhi(int a, unsigned b) 
# 94
{int volatile ___ = 1;(void)a;(void)b;
# 96
::exit(___);}
#if 0
# 94
{ 
# 95
return __umulhi((unsigned)a, b); 
# 96
} 
#endif
# 98 "/usr/local/cuda-8.0/include/device_functions.hpp"
__attribute__((unused)) static inline unsigned mulhi(unsigned a, int b) 
# 99
{int volatile ___ = 1;(void)a;(void)b;
# 101
::exit(___);}
#if 0
# 99
{ 
# 100
return __umulhi(a, (unsigned)b); 
# 101
} 
#endif
# 103 "/usr/local/cuda-8.0/include/device_functions.hpp"
__attribute__((unused)) static inline long long mul64hi(long long a, long long b) 
# 104
{int volatile ___ = 1;(void)a;(void)b;
# 106
::exit(___);}
#if 0
# 104
{ 
# 105
return __mul64hi(a, b); 
# 106
} 
#endif
# 108 "/usr/local/cuda-8.0/include/device_functions.hpp"
__attribute__((unused)) static inline unsigned long long mul64hi(unsigned long long a, unsigned long long b) 
# 109
{int volatile ___ = 1;(void)a;(void)b;
# 111
::exit(___);}
#if 0
# 109
{ 
# 110
return __umul64hi(a, b); 
# 111
} 
#endif
# 113 "/usr/local/cuda-8.0/include/device_functions.hpp"
__attribute__((unused)) static inline unsigned long long mul64hi(long long a, unsigned long long b) 
# 114
{int volatile ___ = 1;(void)a;(void)b;
# 116
::exit(___);}
#if 0
# 114
{ 
# 115
return __umul64hi((unsigned long long)a, b); 
# 116
} 
#endif
# 118 "/usr/local/cuda-8.0/include/device_functions.hpp"
__attribute__((unused)) static inline unsigned long long mul64hi(unsigned long long a, long long b) 
# 119
{int volatile ___ = 1;(void)a;(void)b;
# 121
::exit(___);}
#if 0
# 119
{ 
# 120
return __umul64hi(a, (unsigned long long)b); 
# 121
} 
#endif
# 123 "/usr/local/cuda-8.0/include/device_functions.hpp"
__attribute__((unused)) static inline int float_as_int(float a) 
# 124
{int volatile ___ = 1;(void)a;
# 126
::exit(___);}
#if 0
# 124
{ 
# 125
return __float_as_int(a); 
# 126
} 
#endif
# 128 "/usr/local/cuda-8.0/include/device_functions.hpp"
__attribute__((unused)) static inline float int_as_float(int a) 
# 129
{int volatile ___ = 1;(void)a;
# 131
::exit(___);}
#if 0
# 129
{ 
# 130
return __int_as_float(a); 
# 131
} 
#endif
# 133 "/usr/local/cuda-8.0/include/device_functions.hpp"
__attribute__((unused)) static inline unsigned float_as_uint(float a) 
# 134
{int volatile ___ = 1;(void)a;
# 136
::exit(___);}
#if 0
# 134
{ 
# 135
return __float_as_uint(a); 
# 136
} 
#endif
# 138 "/usr/local/cuda-8.0/include/device_functions.hpp"
__attribute__((unused)) static inline float uint_as_float(unsigned a) 
# 139
{int volatile ___ = 1;(void)a;
# 141
::exit(___);}
#if 0
# 139
{ 
# 140
return __uint_as_float(a); 
# 141
} 
#endif
# 142 "/usr/local/cuda-8.0/include/device_functions.hpp"
__attribute__((unused)) static inline float saturate(float a) 
# 143
{int volatile ___ = 1;(void)a;
# 145
::exit(___);}
#if 0
# 143
{ 
# 144
return __saturatef(a); 
# 145
} 
#endif
# 147 "/usr/local/cuda-8.0/include/device_functions.hpp"
__attribute__((unused)) static inline int mul24(int a, int b) 
# 148
{int volatile ___ = 1;(void)a;(void)b;
# 150
::exit(___);}
#if 0
# 148
{ 
# 149
return __mul24(a, b); 
# 150
} 
#endif
# 152 "/usr/local/cuda-8.0/include/device_functions.hpp"
__attribute__((unused)) static inline unsigned umul24(unsigned a, unsigned b) 
# 153
{int volatile ___ = 1;(void)a;(void)b;
# 155
::exit(___);}
#if 0
# 153
{ 
# 154
return __umul24(a, b); 
# 155
} 
#endif
# 157 "/usr/local/cuda-8.0/include/device_functions.hpp"
__attribute__((unused)) static inline void trap() 
# 158
{int volatile ___ = 1;
# 160
::exit(___);}
#if 0
# 158
{ 
# 159
__trap(); 
# 160
} 
#endif
# 163 "/usr/local/cuda-8.0/include/device_functions.hpp"
__attribute__((unused)) static inline void brkpt(int c) 
# 164
{int volatile ___ = 1;(void)c;
# 166
::exit(___);}
#if 0
# 164
{ 
# 165
__brkpt(c); 
# 166
} 
#endif
# 168 "/usr/local/cuda-8.0/include/device_functions.hpp"
__attribute__((unused)) static inline void syncthreads() 
# 169
{int volatile ___ = 1;
# 171
::exit(___);}
#if 0
# 169
{ 
# 170
__syncthreads(); 
# 171
} 
#endif
# 173 "/usr/local/cuda-8.0/include/device_functions.hpp"
__attribute__((unused)) static inline void prof_trigger(int e) 
# 174
{int volatile ___ = 1;(void)e;
# 191
::exit(___);}
#if 0
# 174
{ 
# 175
if (e == 0) { __prof_trigger(0); } else { 
# 176
if (e == 1) { __prof_trigger(1); } else { 
# 177
if (e == 2) { __prof_trigger(2); } else { 
# 178
if (e == 3) { __prof_trigger(3); } else { 
# 179
if (e == 4) { __prof_trigger(4); } else { 
# 180
if (e == 5) { __prof_trigger(5); } else { 
# 181
if (e == 6) { __prof_trigger(6); } else { 
# 182
if (e == 7) { __prof_trigger(7); } else { 
# 183
if (e == 8) { __prof_trigger(8); } else { 
# 184
if (e == 9) { __prof_trigger(9); } else { 
# 185
if (e == 10) { __prof_trigger(10); } else { 
# 186
if (e == 11) { __prof_trigger(11); } else { 
# 187
if (e == 12) { __prof_trigger(12); } else { 
# 188
if (e == 13) { __prof_trigger(13); } else { 
# 189
if (e == 14) { __prof_trigger(14); } else { 
# 190
if (e == 15) { __prof_trigger(15); }  }  }  }  }  }  }  }  }  }  }  }  }  }  }  }  
# 191
} 
#endif
# 193 "/usr/local/cuda-8.0/include/device_functions.hpp"
__attribute__((unused)) static inline void threadfence(bool global) 
# 194
{int volatile ___ = 1;(void)global;
# 196
::exit(___);}
#if 0
# 194
{ 
# 195
global ? __threadfence() : __threadfence_block(); 
# 196
} 
#endif
# 198 "/usr/local/cuda-8.0/include/device_functions.hpp"
__attribute__((unused)) static inline int float2int(float a, cudaRoundMode mode) 
# 199
{int volatile ___ = 1;(void)a;(void)mode;
# 204
::exit(___);}
#if 0
# 199
{ 
# 200
return (mode == (cudaRoundNearest)) ? __float2int_rn(a) : ((mode == (cudaRoundPosInf)) ? __float2int_ru(a) : ((mode == (cudaRoundMinInf)) ? __float2int_rd(a) : __float2int_rz(a))); 
# 204
} 
#endif
# 206 "/usr/local/cuda-8.0/include/device_functions.hpp"
__attribute__((unused)) static inline unsigned float2uint(float a, cudaRoundMode mode) 
# 207
{int volatile ___ = 1;(void)a;(void)mode;
# 212
::exit(___);}
#if 0
# 207
{ 
# 208
return (mode == (cudaRoundNearest)) ? __float2uint_rn(a) : ((mode == (cudaRoundPosInf)) ? __float2uint_ru(a) : ((mode == (cudaRoundMinInf)) ? __float2uint_rd(a) : __float2uint_rz(a))); 
# 212
} 
#endif
# 214 "/usr/local/cuda-8.0/include/device_functions.hpp"
__attribute__((unused)) static inline float int2float(int a, cudaRoundMode mode) 
# 215
{int volatile ___ = 1;(void)a;(void)mode;
# 220
::exit(___);}
#if 0
# 215
{ 
# 216
return (mode == (cudaRoundZero)) ? __int2float_rz(a) : ((mode == (cudaRoundPosInf)) ? __int2float_ru(a) : ((mode == (cudaRoundMinInf)) ? __int2float_rd(a) : __int2float_rn(a))); 
# 220
} 
#endif
# 222 "/usr/local/cuda-8.0/include/device_functions.hpp"
__attribute__((unused)) static inline float uint2float(unsigned a, cudaRoundMode mode) 
# 223
{int volatile ___ = 1;(void)a;(void)mode;
# 228
::exit(___);}
#if 0
# 223
{ 
# 224
return (mode == (cudaRoundZero)) ? __uint2float_rz(a) : ((mode == (cudaRoundPosInf)) ? __uint2float_ru(a) : ((mode == (cudaRoundMinInf)) ? __uint2float_rd(a) : __uint2float_rn(a))); 
# 228
} 
#endif
# 111 "/usr/local/cuda-8.0/include/device_atomic_functions.h"
__attribute__((unused)) static inline int atomicAdd(int *address, int val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 111
{ } 
#endif
# 113 "/usr/local/cuda-8.0/include/device_atomic_functions.h"
__attribute__((unused)) static inline unsigned atomicAdd(unsigned *address, unsigned val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 113
{ } 
#endif
# 115 "/usr/local/cuda-8.0/include/device_atomic_functions.h"
__attribute__((unused)) static inline int atomicSub(int *address, int val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 115
{ } 
#endif
# 117 "/usr/local/cuda-8.0/include/device_atomic_functions.h"
__attribute__((unused)) static inline unsigned atomicSub(unsigned *address, unsigned val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 117
{ } 
#endif
# 119 "/usr/local/cuda-8.0/include/device_atomic_functions.h"
__attribute__((unused)) static inline int atomicExch(int *address, int val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 119
{ } 
#endif
# 121 "/usr/local/cuda-8.0/include/device_atomic_functions.h"
__attribute__((unused)) static inline unsigned atomicExch(unsigned *address, unsigned val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 121
{ } 
#endif
# 123 "/usr/local/cuda-8.0/include/device_atomic_functions.h"
__attribute__((unused)) static inline float atomicExch(float *address, float val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 123
{ } 
#endif
# 125 "/usr/local/cuda-8.0/include/device_atomic_functions.h"
__attribute__((unused)) static inline int atomicMin(int *address, int val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 125
{ } 
#endif
# 127 "/usr/local/cuda-8.0/include/device_atomic_functions.h"
__attribute__((unused)) static inline unsigned atomicMin(unsigned *address, unsigned val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 127
{ } 
#endif
# 129 "/usr/local/cuda-8.0/include/device_atomic_functions.h"
__attribute__((unused)) static inline int atomicMax(int *address, int val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 129
{ } 
#endif
# 131 "/usr/local/cuda-8.0/include/device_atomic_functions.h"
__attribute__((unused)) static inline unsigned atomicMax(unsigned *address, unsigned val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 131
{ } 
#endif
# 133 "/usr/local/cuda-8.0/include/device_atomic_functions.h"
__attribute__((unused)) static inline unsigned atomicInc(unsigned *address, unsigned val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 133
{ } 
#endif
# 135 "/usr/local/cuda-8.0/include/device_atomic_functions.h"
__attribute__((unused)) static inline unsigned atomicDec(unsigned *address, unsigned val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 135
{ } 
#endif
# 137 "/usr/local/cuda-8.0/include/device_atomic_functions.h"
__attribute__((unused)) static inline int atomicAnd(int *address, int val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 137
{ } 
#endif
# 139 "/usr/local/cuda-8.0/include/device_atomic_functions.h"
__attribute__((unused)) static inline unsigned atomicAnd(unsigned *address, unsigned val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 139
{ } 
#endif
# 141 "/usr/local/cuda-8.0/include/device_atomic_functions.h"
__attribute__((unused)) static inline int atomicOr(int *address, int val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 141
{ } 
#endif
# 143 "/usr/local/cuda-8.0/include/device_atomic_functions.h"
__attribute__((unused)) static inline unsigned atomicOr(unsigned *address, unsigned val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 143
{ } 
#endif
# 145 "/usr/local/cuda-8.0/include/device_atomic_functions.h"
__attribute__((unused)) static inline int atomicXor(int *address, int val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 145
{ } 
#endif
# 147 "/usr/local/cuda-8.0/include/device_atomic_functions.h"
__attribute__((unused)) static inline unsigned atomicXor(unsigned *address, unsigned val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 147
{ } 
#endif
# 149 "/usr/local/cuda-8.0/include/device_atomic_functions.h"
__attribute__((unused)) static inline int atomicCAS(int *address, int compare, int val) {int volatile ___ = 1;(void)address;(void)compare;(void)val;::exit(___);}
#if 0
# 149
{ } 
#endif
# 151 "/usr/local/cuda-8.0/include/device_atomic_functions.h"
__attribute__((unused)) static inline unsigned atomicCAS(unsigned *address, unsigned compare, unsigned val) {int volatile ___ = 1;(void)address;(void)compare;(void)val;::exit(___);}
#if 0
# 151
{ } 
#endif
# 164 "/usr/local/cuda-8.0/include/device_atomic_functions.h"
extern "C" {
# 175
}
# 185
__attribute__((unused)) static inline unsigned long long atomicAdd(unsigned long long *address, unsigned long long val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 185
{ } 
#endif
# 187 "/usr/local/cuda-8.0/include/device_atomic_functions.h"
__attribute__((unused)) static inline unsigned long long atomicExch(unsigned long long *address, unsigned long long val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 187
{ } 
#endif
# 189 "/usr/local/cuda-8.0/include/device_atomic_functions.h"
__attribute__((unused)) static inline unsigned long long atomicCAS(unsigned long long *address, unsigned long long compare, unsigned long long val) {int volatile ___ = 1;(void)address;(void)compare;(void)val;::exit(___);}
#if 0
# 189
{ } 
#endif
# 191 "/usr/local/cuda-8.0/include/device_atomic_functions.h"
__attribute__((unused)) static inline bool any(bool cond) {int volatile ___ = 1;(void)cond;::exit(___);}
#if 0
# 191
{ } 
#endif
# 193 "/usr/local/cuda-8.0/include/device_atomic_functions.h"
__attribute__((unused)) static inline bool all(bool cond) {int volatile ___ = 1;(void)cond;::exit(___);}
#if 0
# 193
{ } 
#endif
# 80 "/usr/local/cuda-8.0/include/device_double_functions.h"
extern "C" {
# 1134
}
# 1143
__attribute__((unused)) static inline double fma(double a, double b, double c, cudaRoundMode mode); 
# 1145
__attribute__((unused)) static inline double dmul(double a, double b, cudaRoundMode mode = cudaRoundNearest); 
# 1147
__attribute__((unused)) static inline double dadd(double a, double b, cudaRoundMode mode = cudaRoundNearest); 
# 1149
__attribute__((unused)) static inline double dsub(double a, double b, cudaRoundMode mode = cudaRoundNearest); 
# 1151
__attribute__((unused)) static inline int double2int(double a, cudaRoundMode mode = cudaRoundZero); 
# 1153
__attribute__((unused)) static inline unsigned double2uint(double a, cudaRoundMode mode = cudaRoundZero); 
# 1155
__attribute__((unused)) static inline long long double2ll(double a, cudaRoundMode mode = cudaRoundZero); 
# 1157
__attribute__((unused)) static inline unsigned long long double2ull(double a, cudaRoundMode mode = cudaRoundZero); 
# 1159
__attribute__((unused)) static inline double ll2double(long long a, cudaRoundMode mode = cudaRoundNearest); 
# 1161
__attribute__((unused)) static inline double ull2double(unsigned long long a, cudaRoundMode mode = cudaRoundNearest); 
# 1163
__attribute__((unused)) static inline double int2double(int a, cudaRoundMode mode = cudaRoundNearest); 
# 1165
__attribute__((unused)) static inline double uint2double(unsigned a, cudaRoundMode mode = cudaRoundNearest); 
# 1167
__attribute__((unused)) static inline double float2double(float a, cudaRoundMode mode = cudaRoundNearest); 
# 85 "/usr/local/cuda-8.0/include/device_double_functions.hpp"
__attribute__((unused)) static inline double fma(double a, double b, double c, cudaRoundMode mode) 
# 86
{int volatile ___ = 1;(void)a;(void)b;(void)c;(void)mode;
# 91
::exit(___);}
#if 0
# 86
{ 
# 87
return (mode == (cudaRoundZero)) ? __fma_rz(a, b, c) : ((mode == (cudaRoundPosInf)) ? __fma_ru(a, b, c) : ((mode == (cudaRoundMinInf)) ? __fma_rd(a, b, c) : __fma_rn(a, b, c))); 
# 91
} 
#endif
# 93 "/usr/local/cuda-8.0/include/device_double_functions.hpp"
__attribute__((unused)) static inline double dmul(double a, double b, cudaRoundMode mode) 
# 94
{int volatile ___ = 1;(void)a;(void)b;(void)mode;
# 99
::exit(___);}
#if 0
# 94
{ 
# 95
return (mode == (cudaRoundZero)) ? __dmul_rz(a, b) : ((mode == (cudaRoundPosInf)) ? __dmul_ru(a, b) : ((mode == (cudaRoundMinInf)) ? __dmul_rd(a, b) : __dmul_rn(a, b))); 
# 99
} 
#endif
# 101 "/usr/local/cuda-8.0/include/device_double_functions.hpp"
__attribute__((unused)) static inline double dadd(double a, double b, cudaRoundMode mode) 
# 102
{int volatile ___ = 1;(void)a;(void)b;(void)mode;
# 107
::exit(___);}
#if 0
# 102
{ 
# 103
return (mode == (cudaRoundZero)) ? __dadd_rz(a, b) : ((mode == (cudaRoundPosInf)) ? __dadd_ru(a, b) : ((mode == (cudaRoundMinInf)) ? __dadd_rd(a, b) : __dadd_rn(a, b))); 
# 107
} 
#endif
# 109 "/usr/local/cuda-8.0/include/device_double_functions.hpp"
__attribute__((unused)) static inline double dsub(double a, double b, cudaRoundMode mode) 
# 110
{int volatile ___ = 1;(void)a;(void)b;(void)mode;
# 115
::exit(___);}
#if 0
# 110
{ 
# 111
return (mode == (cudaRoundZero)) ? __dsub_rz(a, b) : ((mode == (cudaRoundPosInf)) ? __dsub_ru(a, b) : ((mode == (cudaRoundMinInf)) ? __dsub_rd(a, b) : __dsub_rn(a, b))); 
# 115
} 
#endif
# 117 "/usr/local/cuda-8.0/include/device_double_functions.hpp"
__attribute__((unused)) static inline int double2int(double a, cudaRoundMode mode) 
# 118
{int volatile ___ = 1;(void)a;(void)mode;
# 123
::exit(___);}
#if 0
# 118
{ 
# 119
return (mode == (cudaRoundNearest)) ? __double2int_rn(a) : ((mode == (cudaRoundPosInf)) ? __double2int_ru(a) : ((mode == (cudaRoundMinInf)) ? __double2int_rd(a) : __double2int_rz(a))); 
# 123
} 
#endif
# 125 "/usr/local/cuda-8.0/include/device_double_functions.hpp"
__attribute__((unused)) static inline unsigned double2uint(double a, cudaRoundMode mode) 
# 126
{int volatile ___ = 1;(void)a;(void)mode;
# 131
::exit(___);}
#if 0
# 126
{ 
# 127
return (mode == (cudaRoundNearest)) ? __double2uint_rn(a) : ((mode == (cudaRoundPosInf)) ? __double2uint_ru(a) : ((mode == (cudaRoundMinInf)) ? __double2uint_rd(a) : __double2uint_rz(a))); 
# 131
} 
#endif
# 133 "/usr/local/cuda-8.0/include/device_double_functions.hpp"
__attribute__((unused)) static inline long long double2ll(double a, cudaRoundMode mode) 
# 134
{int volatile ___ = 1;(void)a;(void)mode;
# 139
::exit(___);}
#if 0
# 134
{ 
# 135
return (mode == (cudaRoundNearest)) ? __double2ll_rn(a) : ((mode == (cudaRoundPosInf)) ? __double2ll_ru(a) : ((mode == (cudaRoundMinInf)) ? __double2ll_rd(a) : __double2ll_rz(a))); 
# 139
} 
#endif
# 141 "/usr/local/cuda-8.0/include/device_double_functions.hpp"
__attribute__((unused)) static inline unsigned long long double2ull(double a, cudaRoundMode mode) 
# 142
{int volatile ___ = 1;(void)a;(void)mode;
# 147
::exit(___);}
#if 0
# 142
{ 
# 143
return (mode == (cudaRoundNearest)) ? __double2ull_rn(a) : ((mode == (cudaRoundPosInf)) ? __double2ull_ru(a) : ((mode == (cudaRoundMinInf)) ? __double2ull_rd(a) : __double2ull_rz(a))); 
# 147
} 
#endif
# 149 "/usr/local/cuda-8.0/include/device_double_functions.hpp"
__attribute__((unused)) static inline double ll2double(long long a, cudaRoundMode mode) 
# 150
{int volatile ___ = 1;(void)a;(void)mode;
# 155
::exit(___);}
#if 0
# 150
{ 
# 151
return (mode == (cudaRoundZero)) ? __ll2double_rz(a) : ((mode == (cudaRoundPosInf)) ? __ll2double_ru(a) : ((mode == (cudaRoundMinInf)) ? __ll2double_rd(a) : __ll2double_rn(a))); 
# 155
} 
#endif
# 157 "/usr/local/cuda-8.0/include/device_double_functions.hpp"
__attribute__((unused)) static inline double ull2double(unsigned long long a, cudaRoundMode mode) 
# 158
{int volatile ___ = 1;(void)a;(void)mode;
# 163
::exit(___);}
#if 0
# 158
{ 
# 159
return (mode == (cudaRoundZero)) ? __ull2double_rz(a) : ((mode == (cudaRoundPosInf)) ? __ull2double_ru(a) : ((mode == (cudaRoundMinInf)) ? __ull2double_rd(a) : __ull2double_rn(a))); 
# 163
} 
#endif
# 165 "/usr/local/cuda-8.0/include/device_double_functions.hpp"
__attribute__((unused)) static inline double int2double(int a, cudaRoundMode mode) 
# 166
{int volatile ___ = 1;(void)a;(void)mode;
# 168
::exit(___);}
#if 0
# 166
{ 
# 167
return (double)a; 
# 168
} 
#endif
# 170 "/usr/local/cuda-8.0/include/device_double_functions.hpp"
__attribute__((unused)) static inline double uint2double(unsigned a, cudaRoundMode mode) 
# 171
{int volatile ___ = 1;(void)a;(void)mode;
# 173
::exit(___);}
#if 0
# 171
{ 
# 172
return (double)a; 
# 173
} 
#endif
# 175 "/usr/local/cuda-8.0/include/device_double_functions.hpp"
__attribute__((unused)) static inline double float2double(float a, cudaRoundMode mode) 
# 176
{int volatile ___ = 1;(void)a;(void)mode;
# 178
::exit(___);}
#if 0
# 176
{ 
# 177
return (double)a; 
# 178
} 
#endif
# 94 "/usr/local/cuda-8.0/include/sm_20_atomic_functions.h"
__attribute__((unused)) static inline float atomicAdd(float *address, float val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 94
{ } 
#endif
# 102 "/usr/local/cuda-8.0/include/sm_32_atomic_functions.h"
__attribute__((unused)) static inline long long atomicMin(long long *address, long long val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 102
{ } 
#endif
# 104 "/usr/local/cuda-8.0/include/sm_32_atomic_functions.h"
__attribute__((unused)) static inline long long atomicMax(long long *address, long long val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 104
{ } 
#endif
# 106 "/usr/local/cuda-8.0/include/sm_32_atomic_functions.h"
__attribute__((unused)) static inline unsigned long long atomicMin(unsigned long long *address, unsigned long long val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 106
{ } 
#endif
# 108 "/usr/local/cuda-8.0/include/sm_32_atomic_functions.h"
__attribute__((unused)) static inline unsigned long long atomicMax(unsigned long long *address, unsigned long long val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 108
{ } 
#endif
# 110 "/usr/local/cuda-8.0/include/sm_32_atomic_functions.h"
__attribute__((unused)) static inline unsigned long long atomicAnd(unsigned long long *address, unsigned long long val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 110
{ } 
#endif
# 112 "/usr/local/cuda-8.0/include/sm_32_atomic_functions.h"
__attribute__((unused)) static inline unsigned long long atomicOr(unsigned long long *address, unsigned long long val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 112
{ } 
#endif
# 114 "/usr/local/cuda-8.0/include/sm_32_atomic_functions.h"
__attribute__((unused)) static inline unsigned long long atomicXor(unsigned long long *address, unsigned long long val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 114
{ } 
#endif
# 308 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline double atomicAdd(double *address, double val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 308
{ } 
#endif
# 311 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline int atomicAdd_block(int *address, int val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 311
{ } 
#endif
# 314 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline int atomicAdd_system(int *address, int val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 314
{ } 
#endif
# 317 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline unsigned atomicAdd_block(unsigned *address, unsigned val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 317
{ } 
#endif
# 320 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline unsigned atomicAdd_system(unsigned *address, unsigned val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 320
{ } 
#endif
# 323 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline unsigned long long atomicAdd_block(unsigned long long *address, unsigned long long val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 323
{ } 
#endif
# 326 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline unsigned long long atomicAdd_system(unsigned long long *address, unsigned long long val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 326
{ } 
#endif
# 329 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline float atomicAdd_block(float *address, float val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 329
{ } 
#endif
# 332 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline float atomicAdd_system(float *address, float val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 332
{ } 
#endif
# 335 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline double atomicAdd_block(double *address, double val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 335
{ } 
#endif
# 338 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline double atomicAdd_system(double *address, double val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 338
{ } 
#endif
# 341 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline int atomicExch_block(int *address, int val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 341
{ } 
#endif
# 344 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline int atomicExch_system(int *address, int val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 344
{ } 
#endif
# 347 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline unsigned atomicExch_block(unsigned *address, unsigned val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 347
{ } 
#endif
# 350 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline unsigned atomicExch_system(unsigned *address, unsigned val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 350
{ } 
#endif
# 353 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline unsigned long long atomicExch_block(unsigned long long *address, unsigned long long val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 353
{ } 
#endif
# 356 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline unsigned long long atomicExch_system(unsigned long long *address, unsigned long long val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 356
{ } 
#endif
# 359 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline float atomicExch_block(float *address, float val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 359
{ } 
#endif
# 362 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline float atomicExch_system(float *address, float val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 362
{ } 
#endif
# 365 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline int atomicMin_block(int *address, int val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 365
{ } 
#endif
# 368 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline int atomicMin_system(int *address, int val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 368
{ } 
#endif
# 371 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline long long atomicMin_block(long long *address, long long val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 371
{ } 
#endif
# 374 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline long long atomicMin_system(long long *address, long long val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 374
{ } 
#endif
# 377 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline unsigned atomicMin_block(unsigned *address, unsigned val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 377
{ } 
#endif
# 380 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline unsigned atomicMin_system(unsigned *address, unsigned val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 380
{ } 
#endif
# 383 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline unsigned long long atomicMin_block(unsigned long long *address, unsigned long long val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 383
{ } 
#endif
# 386 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline unsigned long long atomicMin_system(unsigned long long *address, unsigned long long val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 386
{ } 
#endif
# 389 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline int atomicMax_block(int *address, int val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 389
{ } 
#endif
# 392 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline int atomicMax_system(int *address, int val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 392
{ } 
#endif
# 395 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline long long atomicMax_block(long long *address, long long val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 395
{ } 
#endif
# 398 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline long long atomicMax_system(long long *address, long long val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 398
{ } 
#endif
# 401 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline unsigned atomicMax_block(unsigned *address, unsigned val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 401
{ } 
#endif
# 404 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline unsigned atomicMax_system(unsigned *address, unsigned val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 404
{ } 
#endif
# 407 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline unsigned long long atomicMax_block(unsigned long long *address, unsigned long long val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 407
{ } 
#endif
# 410 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline unsigned long long atomicMax_system(unsigned long long *address, unsigned long long val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 410
{ } 
#endif
# 413 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline unsigned atomicInc_block(unsigned *address, unsigned val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 413
{ } 
#endif
# 416 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline unsigned atomicInc_system(unsigned *address, unsigned val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 416
{ } 
#endif
# 419 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline unsigned atomicDec_block(unsigned *address, unsigned val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 419
{ } 
#endif
# 422 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline unsigned atomicDec_system(unsigned *address, unsigned val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 422
{ } 
#endif
# 425 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline int atomicCAS_block(int *address, int compare, int val) {int volatile ___ = 1;(void)address;(void)compare;(void)val;::exit(___);}
#if 0
# 425
{ } 
#endif
# 428 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline int atomicCAS_system(int *address, int compare, int val) {int volatile ___ = 1;(void)address;(void)compare;(void)val;::exit(___);}
#if 0
# 428
{ } 
#endif
# 431 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline unsigned atomicCAS_block(unsigned *address, unsigned compare, unsigned 
# 432
val) {int volatile ___ = 1;(void)address;(void)compare;(void)val;::exit(___);}
#if 0
# 432
{ } 
#endif
# 435 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline unsigned atomicCAS_system(unsigned *address, unsigned compare, unsigned 
# 436
val) {int volatile ___ = 1;(void)address;(void)compare;(void)val;::exit(___);}
#if 0
# 436
{ } 
#endif
# 439 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline unsigned long long atomicCAS_block(unsigned long long *address, unsigned long long 
# 440
compare, unsigned long long 
# 441
val) {int volatile ___ = 1;(void)address;(void)compare;(void)val;::exit(___);}
#if 0
# 441
{ } 
#endif
# 444 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline unsigned long long atomicCAS_system(unsigned long long *address, unsigned long long 
# 445
compare, unsigned long long 
# 446
val) {int volatile ___ = 1;(void)address;(void)compare;(void)val;::exit(___);}
#if 0
# 446
{ } 
#endif
# 449 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline int atomicAnd_block(int *address, int val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 449
{ } 
#endif
# 452 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline int atomicAnd_system(int *address, int val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 452
{ } 
#endif
# 455 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline long long atomicAnd_block(long long *address, long long val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 455
{ } 
#endif
# 458 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline long long atomicAnd_system(long long *address, long long val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 458
{ } 
#endif
# 461 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline unsigned atomicAnd_block(unsigned *address, unsigned val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 461
{ } 
#endif
# 464 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline unsigned atomicAnd_system(unsigned *address, unsigned val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 464
{ } 
#endif
# 467 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline unsigned long long atomicAnd_block(unsigned long long *address, unsigned long long val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 467
{ } 
#endif
# 470 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline unsigned long long atomicAnd_system(unsigned long long *address, unsigned long long val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 470
{ } 
#endif
# 473 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline int atomicOr_block(int *address, int val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 473
{ } 
#endif
# 476 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline int atomicOr_system(int *address, int val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 476
{ } 
#endif
# 479 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline long long atomicOr_block(long long *address, long long val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 479
{ } 
#endif
# 482 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline long long atomicOr_system(long long *address, long long val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 482
{ } 
#endif
# 485 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline unsigned atomicOr_block(unsigned *address, unsigned val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 485
{ } 
#endif
# 488 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline unsigned atomicOr_system(unsigned *address, unsigned val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 488
{ } 
#endif
# 491 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline unsigned long long atomicOr_block(unsigned long long *address, unsigned long long val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 491
{ } 
#endif
# 494 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline unsigned long long atomicOr_system(unsigned long long *address, unsigned long long val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 494
{ } 
#endif
# 497 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline int atomicXor_block(int *address, int val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 497
{ } 
#endif
# 500 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline int atomicXor_system(int *address, int val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 500
{ } 
#endif
# 503 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline long long atomicXor_block(long long *address, long long val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 503
{ } 
#endif
# 506 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline long long atomicXor_system(long long *address, long long val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 506
{ } 
#endif
# 509 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline unsigned atomicXor_block(unsigned *address, unsigned val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 509
{ } 
#endif
# 512 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline unsigned atomicXor_system(unsigned *address, unsigned val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 512
{ } 
#endif
# 515 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline unsigned long long atomicXor_block(unsigned long long *address, unsigned long long val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 515
{ } 
#endif
# 518 "/usr/local/cuda-8.0/include/sm_60_atomic_functions.h"
__attribute__((unused)) static inline unsigned long long atomicXor_system(unsigned long long *address, unsigned long long val) {int volatile ___ = 1;(void)address;(void)val;::exit(___);}
#if 0
# 518
{ } 
#endif
# 79 "/usr/local/cuda-8.0/include/sm_20_intrinsics.h"
extern "C" {
# 1466
}
# 1475
__attribute__((unused)) static inline unsigned ballot(bool pred) {int volatile ___ = 1;(void)pred;::exit(___);}
#if 0
# 1475
{ } 
#endif
# 1477 "/usr/local/cuda-8.0/include/sm_20_intrinsics.h"
__attribute__((unused)) static inline int syncthreads_count(bool pred) {int volatile ___ = 1;(void)pred;::exit(___);}
#if 0
# 1477
{ } 
#endif
# 1479 "/usr/local/cuda-8.0/include/sm_20_intrinsics.h"
__attribute__((unused)) static inline bool syncthreads_and(bool pred) {int volatile ___ = 1;(void)pred;::exit(___);}
#if 0
# 1479
{ } 
#endif
# 1481 "/usr/local/cuda-8.0/include/sm_20_intrinsics.h"
__attribute__((unused)) static inline bool syncthreads_or(bool pred) {int volatile ___ = 1;(void)pred;::exit(___);}
#if 0
# 1481
{ } 
#endif
# 1486 "/usr/local/cuda-8.0/include/sm_20_intrinsics.h"
__attribute__((unused)) static inline unsigned __isGlobal(const void *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 1486
{ } 
#endif
# 98 "/usr/local/cuda-8.0/include/sm_30_intrinsics.h"
__attribute__((unused)) static inline int __shfl(int var, int srcLane, int width = 32) {int volatile ___ = 1;(void)var;(void)srcLane;(void)width;::exit(___);}
#if 0
# 98
{ } 
#endif
# 100 "/usr/local/cuda-8.0/include/sm_30_intrinsics.h"
__attribute__((unused)) static inline unsigned __shfl(unsigned var, int srcLane, int width = 32) {int volatile ___ = 1;(void)var;(void)srcLane;(void)width;::exit(___);}
#if 0
# 100
{ } 
#endif
# 102 "/usr/local/cuda-8.0/include/sm_30_intrinsics.h"
__attribute__((unused)) static inline int __shfl_up(int var, unsigned delta, int width = 32) {int volatile ___ = 1;(void)var;(void)delta;(void)width;::exit(___);}
#if 0
# 102
{ } 
#endif
# 103 "/usr/local/cuda-8.0/include/sm_30_intrinsics.h"
__attribute__((unused)) static inline unsigned __shfl_up(unsigned var, unsigned delta, int width = 32) {int volatile ___ = 1;(void)var;(void)delta;(void)width;::exit(___);}
#if 0
# 103
{ } 
#endif
# 105 "/usr/local/cuda-8.0/include/sm_30_intrinsics.h"
__attribute__((unused)) static inline int __shfl_down(int var, unsigned delta, int width = 32) {int volatile ___ = 1;(void)var;(void)delta;(void)width;::exit(___);}
#if 0
# 105
{ } 
#endif
# 107 "/usr/local/cuda-8.0/include/sm_30_intrinsics.h"
__attribute__((unused)) static inline unsigned __shfl_down(unsigned var, unsigned delta, int width = 32) {int volatile ___ = 1;(void)var;(void)delta;(void)width;::exit(___);}
#if 0
# 107
{ } 
#endif
# 109 "/usr/local/cuda-8.0/include/sm_30_intrinsics.h"
__attribute__((unused)) static inline int __shfl_xor(int var, int laneMask, int width = 32) {int volatile ___ = 1;(void)var;(void)laneMask;(void)width;::exit(___);}
#if 0
# 109
{ } 
#endif
# 111 "/usr/local/cuda-8.0/include/sm_30_intrinsics.h"
__attribute__((unused)) static inline unsigned __shfl_xor(unsigned var, int laneMask, int width = 32) {int volatile ___ = 1;(void)var;(void)laneMask;(void)width;::exit(___);}
#if 0
# 111
{ } 
#endif
# 113 "/usr/local/cuda-8.0/include/sm_30_intrinsics.h"
__attribute__((unused)) static inline float __shfl(float var, int srcLane, int width = 32) {int volatile ___ = 1;(void)var;(void)srcLane;(void)width;::exit(___);}
#if 0
# 113
{ } 
#endif
# 115 "/usr/local/cuda-8.0/include/sm_30_intrinsics.h"
__attribute__((unused)) static inline float __shfl_up(float var, unsigned delta, int width = 32) {int volatile ___ = 1;(void)var;(void)delta;(void)width;::exit(___);}
#if 0
# 115
{ } 
#endif
# 117 "/usr/local/cuda-8.0/include/sm_30_intrinsics.h"
__attribute__((unused)) static inline float __shfl_down(float var, unsigned delta, int width = 32) {int volatile ___ = 1;(void)var;(void)delta;(void)width;::exit(___);}
#if 0
# 117
{ } 
#endif
# 119 "/usr/local/cuda-8.0/include/sm_30_intrinsics.h"
__attribute__((unused)) static inline float __shfl_xor(float var, int laneMask, int width = 32) {int volatile ___ = 1;(void)var;(void)laneMask;(void)width;::exit(___);}
#if 0
# 119
{ } 
#endif
# 122 "/usr/local/cuda-8.0/include/sm_30_intrinsics.h"
__attribute__((unused)) static inline long long __shfl(long long var, int srcLane, int width = 32) {int volatile ___ = 1;(void)var;(void)srcLane;(void)width;::exit(___);}
#if 0
# 122
{ } 
#endif
# 124 "/usr/local/cuda-8.0/include/sm_30_intrinsics.h"
__attribute__((unused)) static inline unsigned long long __shfl(unsigned long long var, int srcLane, int width = 32) {int volatile ___ = 1;(void)var;(void)srcLane;(void)width;::exit(___);}
#if 0
# 124
{ } 
#endif
# 126 "/usr/local/cuda-8.0/include/sm_30_intrinsics.h"
__attribute__((unused)) static inline long long __shfl_up(long long var, unsigned delta, int width = 32) {int volatile ___ = 1;(void)var;(void)delta;(void)width;::exit(___);}
#if 0
# 126
{ } 
#endif
# 128 "/usr/local/cuda-8.0/include/sm_30_intrinsics.h"
__attribute__((unused)) static inline unsigned long long __shfl_up(unsigned long long var, unsigned delta, int width = 32) {int volatile ___ = 1;(void)var;(void)delta;(void)width;::exit(___);}
#if 0
# 128
{ } 
#endif
# 130 "/usr/local/cuda-8.0/include/sm_30_intrinsics.h"
__attribute__((unused)) static inline long long __shfl_down(long long var, unsigned delta, int width = 32) {int volatile ___ = 1;(void)var;(void)delta;(void)width;::exit(___);}
#if 0
# 130
{ } 
#endif
# 132 "/usr/local/cuda-8.0/include/sm_30_intrinsics.h"
__attribute__((unused)) static inline unsigned long long __shfl_down(unsigned long long var, unsigned delta, int width = 32) {int volatile ___ = 1;(void)var;(void)delta;(void)width;::exit(___);}
#if 0
# 132
{ } 
#endif
# 134 "/usr/local/cuda-8.0/include/sm_30_intrinsics.h"
__attribute__((unused)) static inline long long __shfl_xor(long long var, int laneMask, int width = 32) {int volatile ___ = 1;(void)var;(void)laneMask;(void)width;::exit(___);}
#if 0
# 134
{ } 
#endif
# 136 "/usr/local/cuda-8.0/include/sm_30_intrinsics.h"
__attribute__((unused)) static inline unsigned long long __shfl_xor(unsigned long long var, int laneMask, int width = 32) {int volatile ___ = 1;(void)var;(void)laneMask;(void)width;::exit(___);}
#if 0
# 136
{ } 
#endif
# 138 "/usr/local/cuda-8.0/include/sm_30_intrinsics.h"
__attribute__((unused)) static inline double __shfl(double var, int srcLane, int width = 32) {int volatile ___ = 1;(void)var;(void)srcLane;(void)width;::exit(___);}
#if 0
# 138
{ } 
#endif
# 140 "/usr/local/cuda-8.0/include/sm_30_intrinsics.h"
__attribute__((unused)) static inline double __shfl_up(double var, unsigned delta, int width = 32) {int volatile ___ = 1;(void)var;(void)delta;(void)width;::exit(___);}
#if 0
# 140
{ } 
#endif
# 142 "/usr/local/cuda-8.0/include/sm_30_intrinsics.h"
__attribute__((unused)) static inline double __shfl_down(double var, unsigned delta, int width = 32) {int volatile ___ = 1;(void)var;(void)delta;(void)width;::exit(___);}
#if 0
# 142
{ } 
#endif
# 144 "/usr/local/cuda-8.0/include/sm_30_intrinsics.h"
__attribute__((unused)) static inline double __shfl_xor(double var, int laneMask, int width = 32) {int volatile ___ = 1;(void)var;(void)laneMask;(void)width;::exit(___);}
#if 0
# 144
{ } 
#endif
# 148 "/usr/local/cuda-8.0/include/sm_30_intrinsics.h"
__attribute__((unused)) static inline long __shfl(long var, int srcLane, int width = 32) {int volatile ___ = 1;(void)var;(void)srcLane;(void)width;::exit(___);}
#if 0
# 148
{ } 
#endif
# 150 "/usr/local/cuda-8.0/include/sm_30_intrinsics.h"
__attribute__((unused)) static inline unsigned long __shfl(unsigned long var, int srcLane, int width = 32) {int volatile ___ = 1;(void)var;(void)srcLane;(void)width;::exit(___);}
#if 0
# 150
{ } 
#endif
# 152 "/usr/local/cuda-8.0/include/sm_30_intrinsics.h"
__attribute__((unused)) static inline long __shfl_up(long var, unsigned delta, int width = 32) {int volatile ___ = 1;(void)var;(void)delta;(void)width;::exit(___);}
#if 0
# 152
{ } 
#endif
# 154 "/usr/local/cuda-8.0/include/sm_30_intrinsics.h"
__attribute__((unused)) static inline unsigned long __shfl_up(unsigned long var, unsigned delta, int width = 32) {int volatile ___ = 1;(void)var;(void)delta;(void)width;::exit(___);}
#if 0
# 154
{ } 
#endif
# 156 "/usr/local/cuda-8.0/include/sm_30_intrinsics.h"
__attribute__((unused)) static inline long __shfl_down(long var, unsigned delta, int width = 32) {int volatile ___ = 1;(void)var;(void)delta;(void)width;::exit(___);}
#if 0
# 156
{ } 
#endif
# 158 "/usr/local/cuda-8.0/include/sm_30_intrinsics.h"
__attribute__((unused)) static inline unsigned long __shfl_down(unsigned long var, unsigned delta, int width = 32) {int volatile ___ = 1;(void)var;(void)delta;(void)width;::exit(___);}
#if 0
# 158
{ } 
#endif
# 160 "/usr/local/cuda-8.0/include/sm_30_intrinsics.h"
__attribute__((unused)) static inline long __shfl_xor(long var, int laneMask, int width = 32) {int volatile ___ = 1;(void)var;(void)laneMask;(void)width;::exit(___);}
#if 0
# 160
{ } 
#endif
# 162 "/usr/local/cuda-8.0/include/sm_30_intrinsics.h"
__attribute__((unused)) static inline unsigned long __shfl_xor(unsigned long var, int laneMask, int width = 32) {int volatile ___ = 1;(void)var;(void)laneMask;(void)width;::exit(___);}
#if 0
# 162
{ } 
#endif
# 89 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline long __ldg(const long *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 89
{ } 
#endif
# 90 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline unsigned long __ldg(const unsigned long *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 90
{ } 
#endif
# 92 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline char __ldg(const char *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 92
{ } 
#endif
# 93 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline signed char __ldg(const signed char *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 93
{ } 
#endif
# 94 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline short __ldg(const short *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 94
{ } 
#endif
# 95 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline int __ldg(const int *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 95
{ } 
#endif
# 96 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline long long __ldg(const long long *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 96
{ } 
#endif
# 97 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline char2 __ldg(const char2 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 97
{ } 
#endif
# 98 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline char4 __ldg(const char4 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 98
{ } 
#endif
# 99 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline short2 __ldg(const short2 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 99
{ } 
#endif
# 100 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline short4 __ldg(const short4 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 100
{ } 
#endif
# 101 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline int2 __ldg(const int2 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 101
{ } 
#endif
# 102 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline int4 __ldg(const int4 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 102
{ } 
#endif
# 103 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline longlong2 __ldg(const longlong2 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 103
{ } 
#endif
# 105 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline unsigned char __ldg(const unsigned char *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 105
{ } 
#endif
# 106 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline unsigned short __ldg(const unsigned short *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 106
{ } 
#endif
# 107 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline unsigned __ldg(const unsigned *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 107
{ } 
#endif
# 108 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline unsigned long long __ldg(const unsigned long long *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 108
{ } 
#endif
# 109 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline uchar2 __ldg(const uchar2 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 109
{ } 
#endif
# 110 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline uchar4 __ldg(const uchar4 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 110
{ } 
#endif
# 111 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline ushort2 __ldg(const ushort2 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 111
{ } 
#endif
# 112 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline ushort4 __ldg(const ushort4 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 112
{ } 
#endif
# 113 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline uint2 __ldg(const uint2 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 113
{ } 
#endif
# 114 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline uint4 __ldg(const uint4 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 114
{ } 
#endif
# 115 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline ulonglong2 __ldg(const ulonglong2 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 115
{ } 
#endif
# 117 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline float __ldg(const float *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 117
{ } 
#endif
# 118 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline double __ldg(const double *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 118
{ } 
#endif
# 119 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline float2 __ldg(const float2 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 119
{ } 
#endif
# 120 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline float4 __ldg(const float4 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 120
{ } 
#endif
# 121 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline double2 __ldg(const double2 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 121
{ } 
#endif
# 125 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline long __ldcg(const long *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 125
{ } 
#endif
# 126 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline unsigned long __ldcg(const unsigned long *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 126
{ } 
#endif
# 128 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline char __ldcg(const char *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 128
{ } 
#endif
# 129 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline signed char __ldcg(const signed char *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 129
{ } 
#endif
# 130 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline short __ldcg(const short *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 130
{ } 
#endif
# 131 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline int __ldcg(const int *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 131
{ } 
#endif
# 132 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline long long __ldcg(const long long *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 132
{ } 
#endif
# 133 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline char2 __ldcg(const char2 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 133
{ } 
#endif
# 134 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline char4 __ldcg(const char4 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 134
{ } 
#endif
# 135 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline short2 __ldcg(const short2 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 135
{ } 
#endif
# 136 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline short4 __ldcg(const short4 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 136
{ } 
#endif
# 137 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline int2 __ldcg(const int2 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 137
{ } 
#endif
# 138 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline int4 __ldcg(const int4 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 138
{ } 
#endif
# 139 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline longlong2 __ldcg(const longlong2 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 139
{ } 
#endif
# 141 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline unsigned char __ldcg(const unsigned char *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 141
{ } 
#endif
# 142 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline unsigned short __ldcg(const unsigned short *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 142
{ } 
#endif
# 143 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline unsigned __ldcg(const unsigned *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 143
{ } 
#endif
# 144 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline unsigned long long __ldcg(const unsigned long long *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 144
{ } 
#endif
# 145 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline uchar2 __ldcg(const uchar2 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 145
{ } 
#endif
# 146 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline uchar4 __ldcg(const uchar4 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 146
{ } 
#endif
# 147 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline ushort2 __ldcg(const ushort2 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 147
{ } 
#endif
# 148 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline ushort4 __ldcg(const ushort4 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 148
{ } 
#endif
# 149 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline uint2 __ldcg(const uint2 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 149
{ } 
#endif
# 150 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline uint4 __ldcg(const uint4 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 150
{ } 
#endif
# 151 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline ulonglong2 __ldcg(const ulonglong2 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 151
{ } 
#endif
# 153 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline float __ldcg(const float *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 153
{ } 
#endif
# 154 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline double __ldcg(const double *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 154
{ } 
#endif
# 155 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline float2 __ldcg(const float2 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 155
{ } 
#endif
# 156 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline float4 __ldcg(const float4 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 156
{ } 
#endif
# 157 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline double2 __ldcg(const double2 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 157
{ } 
#endif
# 161 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline long __ldca(const long *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 161
{ } 
#endif
# 162 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline unsigned long __ldca(const unsigned long *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 162
{ } 
#endif
# 164 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline char __ldca(const char *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 164
{ } 
#endif
# 165 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline signed char __ldca(const signed char *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 165
{ } 
#endif
# 166 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline short __ldca(const short *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 166
{ } 
#endif
# 167 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline int __ldca(const int *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 167
{ } 
#endif
# 168 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline long long __ldca(const long long *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 168
{ } 
#endif
# 169 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline char2 __ldca(const char2 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 169
{ } 
#endif
# 170 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline char4 __ldca(const char4 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 170
{ } 
#endif
# 171 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline short2 __ldca(const short2 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 171
{ } 
#endif
# 172 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline short4 __ldca(const short4 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 172
{ } 
#endif
# 173 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline int2 __ldca(const int2 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 173
{ } 
#endif
# 174 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline int4 __ldca(const int4 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 174
{ } 
#endif
# 175 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline longlong2 __ldca(const longlong2 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 175
{ } 
#endif
# 177 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline unsigned char __ldca(const unsigned char *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 177
{ } 
#endif
# 178 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline unsigned short __ldca(const unsigned short *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 178
{ } 
#endif
# 179 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline unsigned __ldca(const unsigned *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 179
{ } 
#endif
# 180 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline unsigned long long __ldca(const unsigned long long *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 180
{ } 
#endif
# 181 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline uchar2 __ldca(const uchar2 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 181
{ } 
#endif
# 182 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline uchar4 __ldca(const uchar4 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 182
{ } 
#endif
# 183 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline ushort2 __ldca(const ushort2 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 183
{ } 
#endif
# 184 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline ushort4 __ldca(const ushort4 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 184
{ } 
#endif
# 185 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline uint2 __ldca(const uint2 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 185
{ } 
#endif
# 186 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline uint4 __ldca(const uint4 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 186
{ } 
#endif
# 187 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline ulonglong2 __ldca(const ulonglong2 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 187
{ } 
#endif
# 189 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline float __ldca(const float *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 189
{ } 
#endif
# 190 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline double __ldca(const double *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 190
{ } 
#endif
# 191 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline float2 __ldca(const float2 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 191
{ } 
#endif
# 192 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline float4 __ldca(const float4 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 192
{ } 
#endif
# 193 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline double2 __ldca(const double2 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 193
{ } 
#endif
# 197 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline long __ldcs(const long *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 197
{ } 
#endif
# 198 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline unsigned long __ldcs(const unsigned long *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 198
{ } 
#endif
# 200 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline char __ldcs(const char *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 200
{ } 
#endif
# 201 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline signed char __ldcs(const signed char *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 201
{ } 
#endif
# 202 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline short __ldcs(const short *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 202
{ } 
#endif
# 203 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline int __ldcs(const int *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 203
{ } 
#endif
# 204 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline long long __ldcs(const long long *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 204
{ } 
#endif
# 205 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline char2 __ldcs(const char2 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 205
{ } 
#endif
# 206 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline char4 __ldcs(const char4 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 206
{ } 
#endif
# 207 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline short2 __ldcs(const short2 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 207
{ } 
#endif
# 208 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline short4 __ldcs(const short4 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 208
{ } 
#endif
# 209 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline int2 __ldcs(const int2 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 209
{ } 
#endif
# 210 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline int4 __ldcs(const int4 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 210
{ } 
#endif
# 211 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline longlong2 __ldcs(const longlong2 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 211
{ } 
#endif
# 213 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline unsigned char __ldcs(const unsigned char *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 213
{ } 
#endif
# 214 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline unsigned short __ldcs(const unsigned short *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 214
{ } 
#endif
# 215 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline unsigned __ldcs(const unsigned *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 215
{ } 
#endif
# 216 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline unsigned long long __ldcs(const unsigned long long *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 216
{ } 
#endif
# 217 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline uchar2 __ldcs(const uchar2 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 217
{ } 
#endif
# 218 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline uchar4 __ldcs(const uchar4 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 218
{ } 
#endif
# 219 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline ushort2 __ldcs(const ushort2 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 219
{ } 
#endif
# 220 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline ushort4 __ldcs(const ushort4 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 220
{ } 
#endif
# 221 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline uint2 __ldcs(const uint2 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 221
{ } 
#endif
# 222 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline uint4 __ldcs(const uint4 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 222
{ } 
#endif
# 223 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline ulonglong2 __ldcs(const ulonglong2 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 223
{ } 
#endif
# 225 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline float __ldcs(const float *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 225
{ } 
#endif
# 226 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline double __ldcs(const double *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 226
{ } 
#endif
# 227 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline float2 __ldcs(const float2 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 227
{ } 
#endif
# 228 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline float4 __ldcs(const float4 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 228
{ } 
#endif
# 229 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline double2 __ldcs(const double2 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 229
{ } 
#endif
# 236 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline unsigned __funnelshift_l(unsigned lo, unsigned hi, unsigned shift) {int volatile ___ = 1;(void)lo;(void)hi;(void)shift;::exit(___);}
#if 0
# 236
{ } 
#endif
# 237 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline unsigned __funnelshift_lc(unsigned lo, unsigned hi, unsigned shift) {int volatile ___ = 1;(void)lo;(void)hi;(void)shift;::exit(___);}
#if 0
# 237
{ } 
#endif
# 240 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline unsigned __funnelshift_r(unsigned lo, unsigned hi, unsigned shift) {int volatile ___ = 1;(void)lo;(void)hi;(void)shift;::exit(___);}
#if 0
# 240
{ } 
#endif
# 241 "/usr/local/cuda-8.0/include/sm_32_intrinsics.h"
__attribute__((unused)) static inline unsigned __funnelshift_rc(unsigned lo, unsigned hi, unsigned shift) {int volatile ___ = 1;(void)lo;(void)hi;(void)shift;::exit(___);}
#if 0
# 241
{ } 
#endif
# 91 "/usr/local/cuda-8.0/include/sm_61_intrinsics.h"
__attribute__((unused)) static inline int __dp2a_lo(int srcA, int srcB, int c) {int volatile ___ = 1;(void)srcA;(void)srcB;(void)c;::exit(___);}
#if 0
# 91
{ } 
#endif
# 92 "/usr/local/cuda-8.0/include/sm_61_intrinsics.h"
__attribute__((unused)) static inline unsigned __dp2a_lo(unsigned srcA, unsigned srcB, unsigned c) {int volatile ___ = 1;(void)srcA;(void)srcB;(void)c;::exit(___);}
#if 0
# 92
{ } 
#endif
# 94 "/usr/local/cuda-8.0/include/sm_61_intrinsics.h"
__attribute__((unused)) static inline int __dp2a_lo(short2 srcA, char4 srcB, int c) {int volatile ___ = 1;(void)srcA;(void)srcB;(void)c;::exit(___);}
#if 0
# 94
{ } 
#endif
# 95 "/usr/local/cuda-8.0/include/sm_61_intrinsics.h"
__attribute__((unused)) static inline unsigned __dp2a_lo(ushort2 srcA, uchar4 srcB, unsigned c) {int volatile ___ = 1;(void)srcA;(void)srcB;(void)c;::exit(___);}
#if 0
# 95
{ } 
#endif
# 97 "/usr/local/cuda-8.0/include/sm_61_intrinsics.h"
__attribute__((unused)) static inline int __dp2a_hi(int srcA, int srcB, int c) {int volatile ___ = 1;(void)srcA;(void)srcB;(void)c;::exit(___);}
#if 0
# 97
{ } 
#endif
# 98 "/usr/local/cuda-8.0/include/sm_61_intrinsics.h"
__attribute__((unused)) static inline unsigned __dp2a_hi(unsigned srcA, unsigned srcB, unsigned c) {int volatile ___ = 1;(void)srcA;(void)srcB;(void)c;::exit(___);}
#if 0
# 98
{ } 
#endif
# 100 "/usr/local/cuda-8.0/include/sm_61_intrinsics.h"
__attribute__((unused)) static inline int __dp2a_hi(short2 srcA, char4 srcB, int c) {int volatile ___ = 1;(void)srcA;(void)srcB;(void)c;::exit(___);}
#if 0
# 100
{ } 
#endif
# 101 "/usr/local/cuda-8.0/include/sm_61_intrinsics.h"
__attribute__((unused)) static inline unsigned __dp2a_hi(ushort2 srcA, uchar4 srcB, unsigned c) {int volatile ___ = 1;(void)srcA;(void)srcB;(void)c;::exit(___);}
#if 0
# 101
{ } 
#endif
# 108 "/usr/local/cuda-8.0/include/sm_61_intrinsics.h"
__attribute__((unused)) static inline int __dp4a(int srcA, int srcB, int c) {int volatile ___ = 1;(void)srcA;(void)srcB;(void)c;::exit(___);}
#if 0
# 108
{ } 
#endif
# 109 "/usr/local/cuda-8.0/include/sm_61_intrinsics.h"
__attribute__((unused)) static inline unsigned __dp4a(unsigned srcA, unsigned srcB, unsigned c) {int volatile ___ = 1;(void)srcA;(void)srcB;(void)c;::exit(___);}
#if 0
# 109
{ } 
#endif
# 111 "/usr/local/cuda-8.0/include/sm_61_intrinsics.h"
__attribute__((unused)) static inline int __dp4a(char4 srcA, char4 srcB, int c) {int volatile ___ = 1;(void)srcA;(void)srcB;(void)c;::exit(___);}
#if 0
# 111
{ } 
#endif
# 112 "/usr/local/cuda-8.0/include/sm_61_intrinsics.h"
__attribute__((unused)) static inline unsigned __dp4a(uchar4 srcA, uchar4 srcB, unsigned c) {int volatile ___ = 1;(void)srcA;(void)srcB;(void)c;::exit(___);}
#if 0
# 112
{ } 
#endif
# 100 "/usr/local/cuda-8.0/include/surface_functions.h"
template< class T> 
# 101
__attribute((always_inline)) __attribute__((unused)) inline void surf1Dread(T *res, surface< void, 1>  surf, int x, int s, cudaSurfaceBoundaryMode mode = cudaBoundaryModeTrap) 
# 102
{int volatile ___ = 1;(void)res;(void)surf;(void)x;(void)s;(void)mode;
# 111
::exit(___);}
#if 0
# 102
{ 
# 111
} 
#endif
# 113 "/usr/local/cuda-8.0/include/surface_functions.h"
template< class T> 
# 114
__attribute((always_inline)) __attribute__((unused)) inline T surf1Dread(surface< void, 1>  surf, int x, cudaSurfaceBoundaryMode mode = cudaBoundaryModeTrap) 
# 115
{int volatile ___ = 1;(void)surf;(void)x;(void)mode;
# 123
::exit(___);}
#if 0
# 115
{ 
# 123
} 
#endif
# 125 "/usr/local/cuda-8.0/include/surface_functions.h"
template< class T> 
# 126
__attribute((always_inline)) __attribute__((unused)) inline void surf1Dread(T *res, surface< void, 1>  surf, int x, cudaSurfaceBoundaryMode mode = cudaBoundaryModeTrap) 
# 127
{int volatile ___ = 1;(void)res;(void)surf;(void)x;(void)mode;
# 131
::exit(___);}
#if 0
# 127
{ 
# 131
} 
#endif
# 260 "/usr/local/cuda-8.0/include/surface_functions.h"
template< class T> 
# 261
__attribute((always_inline)) __attribute__((unused)) inline void surf2Dread(T *res, surface< void, 2>  surf, int x, int y, int s, cudaSurfaceBoundaryMode mode = cudaBoundaryModeTrap) 
# 262
{int volatile ___ = 1;(void)res;(void)surf;(void)x;(void)y;(void)s;(void)mode;
# 271
::exit(___);}
#if 0
# 262
{ 
# 271
} 
#endif
# 273 "/usr/local/cuda-8.0/include/surface_functions.h"
template< class T> 
# 274
__attribute((always_inline)) __attribute__((unused)) inline T surf2Dread(surface< void, 2>  surf, int x, int y, cudaSurfaceBoundaryMode mode = cudaBoundaryModeTrap) 
# 275
{int volatile ___ = 1;(void)surf;(void)x;(void)y;(void)mode;
# 283
::exit(___);}
#if 0
# 275
{ 
# 283
} 
#endif
# 285 "/usr/local/cuda-8.0/include/surface_functions.h"
template< class T> 
# 286
__attribute((always_inline)) __attribute__((unused)) inline void surf2Dread(T *res, surface< void, 2>  surf, int x, int y, cudaSurfaceBoundaryMode mode = cudaBoundaryModeTrap) 
# 287
{int volatile ___ = 1;(void)res;(void)surf;(void)x;(void)y;(void)mode;
# 291
::exit(___);}
#if 0
# 287
{ 
# 291
} 
#endif
# 422 "/usr/local/cuda-8.0/include/surface_functions.h"
template< class T> 
# 423
__attribute((always_inline)) __attribute__((unused)) inline void surf3Dread(T *res, surface< void, 3>  surf, int x, int y, int z, int s, cudaSurfaceBoundaryMode mode = cudaBoundaryModeTrap) 
# 424
{int volatile ___ = 1;(void)res;(void)surf;(void)x;(void)y;(void)z;(void)s;(void)mode;
# 433
::exit(___);}
#if 0
# 424
{ 
# 433
} 
#endif
# 435 "/usr/local/cuda-8.0/include/surface_functions.h"
template< class T> 
# 436
__attribute((always_inline)) __attribute__((unused)) inline T surf3Dread(surface< void, 3>  surf, int x, int y, int z, cudaSurfaceBoundaryMode mode = cudaBoundaryModeTrap) 
# 437
{int volatile ___ = 1;(void)surf;(void)x;(void)y;(void)z;(void)mode;
# 445
::exit(___);}
#if 0
# 437
{ 
# 445
} 
#endif
# 447 "/usr/local/cuda-8.0/include/surface_functions.h"
template< class T> 
# 448
__attribute((always_inline)) __attribute__((unused)) inline void surf3Dread(T *res, surface< void, 3>  surf, int x, int y, int z, cudaSurfaceBoundaryMode mode = cudaBoundaryModeTrap) 
# 449
{int volatile ___ = 1;(void)res;(void)surf;(void)x;(void)y;(void)z;(void)mode;
# 453
::exit(___);}
#if 0
# 449
{ 
# 453
} 
#endif
# 582 "/usr/local/cuda-8.0/include/surface_functions.h"
template< class T> 
# 583
__attribute((always_inline)) __attribute__((unused)) inline void surf1DLayeredread(T *res, surface< void, 241>  surf, int x, int layer, int s, cudaSurfaceBoundaryMode mode = cudaBoundaryModeTrap) 
# 584
{int volatile ___ = 1;(void)res;(void)surf;(void)x;(void)layer;(void)s;(void)mode;
# 593
::exit(___);}
#if 0
# 584
{ 
# 593
} 
#endif
# 595 "/usr/local/cuda-8.0/include/surface_functions.h"
template< class T> 
# 596
__attribute((always_inline)) __attribute__((unused)) inline T surf1DLayeredread(surface< void, 241>  surf, int x, int layer, cudaSurfaceBoundaryMode mode = cudaBoundaryModeTrap) 
# 597
{int volatile ___ = 1;(void)surf;(void)x;(void)layer;(void)mode;
# 605
::exit(___);}
#if 0
# 597
{ 
# 605
} 
#endif
# 607 "/usr/local/cuda-8.0/include/surface_functions.h"
template< class T> 
# 608
__attribute((always_inline)) __attribute__((unused)) inline void surf1DLayeredread(T *res, surface< void, 241>  surf, int x, int layer, cudaSurfaceBoundaryMode mode = cudaBoundaryModeTrap) 
# 609
{int volatile ___ = 1;(void)res;(void)surf;(void)x;(void)layer;(void)mode;
# 613
::exit(___);}
#if 0
# 609
{ 
# 613
} 
#endif
# 768 "/usr/local/cuda-8.0/include/surface_functions.h"
template< class T> 
# 769
__attribute((always_inline)) __attribute__((unused)) inline void surf2DLayeredread(T *res, surface< void, 242>  surf, int x, int y, int layer, int s, cudaSurfaceBoundaryMode mode = cudaBoundaryModeTrap) 
# 770
{int volatile ___ = 1;(void)res;(void)surf;(void)x;(void)y;(void)layer;(void)s;(void)mode;
# 779
::exit(___);}
#if 0
# 770
{ 
# 779
} 
#endif
# 781 "/usr/local/cuda-8.0/include/surface_functions.h"
template< class T> 
# 782
__attribute((always_inline)) __attribute__((unused)) inline T surf2DLayeredread(surface< void, 242>  surf, int x, int y, int layer, cudaSurfaceBoundaryMode mode = cudaBoundaryModeTrap) 
# 783
{int volatile ___ = 1;(void)surf;(void)x;(void)y;(void)layer;(void)mode;
# 791
::exit(___);}
#if 0
# 783
{ 
# 791
} 
#endif
# 793 "/usr/local/cuda-8.0/include/surface_functions.h"
template< class T> 
# 794
__attribute((always_inline)) __attribute__((unused)) inline void surf2DLayeredread(T *res, surface< void, 242>  surf, int x, int y, int layer, cudaSurfaceBoundaryMode mode = cudaBoundaryModeTrap) 
# 795
{int volatile ___ = 1;(void)res;(void)surf;(void)x;(void)y;(void)layer;(void)mode;
# 799
::exit(___);}
#if 0
# 795
{ 
# 799
} 
#endif
# 919 "/usr/local/cuda-8.0/include/surface_functions.h"
template< class T> 
# 920
__attribute((always_inline)) __attribute__((unused)) inline void surfCubemapread(T *res, surface< void, 12>  surf, int x, int y, int face, int s, cudaSurfaceBoundaryMode mode = cudaBoundaryModeTrap) 
# 921
{int volatile ___ = 1;(void)res;(void)surf;(void)x;(void)y;(void)face;(void)s;(void)mode;
# 930
::exit(___);}
#if 0
# 921
{ 
# 930
} 
#endif
# 932 "/usr/local/cuda-8.0/include/surface_functions.h"
template< class T> 
# 933
__attribute((always_inline)) __attribute__((unused)) inline T surfCubemapread(surface< void, 12>  surf, int x, int y, int face, cudaSurfaceBoundaryMode mode = cudaBoundaryModeTrap) 
# 934
{int volatile ___ = 1;(void)surf;(void)x;(void)y;(void)face;(void)mode;
# 942
::exit(___);}
#if 0
# 934
{ 
# 942
} 
#endif
# 944 "/usr/local/cuda-8.0/include/surface_functions.h"
template< class T> 
# 945
__attribute((always_inline)) __attribute__((unused)) inline void surfCubemapread(T *res, surface< void, 12>  surf, int x, int y, int face, cudaSurfaceBoundaryMode mode = cudaBoundaryModeTrap) 
# 946
{int volatile ___ = 1;(void)res;(void)surf;(void)x;(void)y;(void)face;(void)mode;
# 950
::exit(___);}
#if 0
# 946
{ 
# 950
} 
#endif
# 1070 "/usr/local/cuda-8.0/include/surface_functions.h"
template< class T> 
# 1071
__attribute((always_inline)) __attribute__((unused)) inline void surfCubemapLayeredread(T *res, surface< void, 252>  surf, int x, int y, int layerFace, int s, cudaSurfaceBoundaryMode mode = cudaBoundaryModeTrap) 
# 1072
{int volatile ___ = 1;(void)res;(void)surf;(void)x;(void)y;(void)layerFace;(void)s;(void)mode;
# 1081
::exit(___);}
#if 0
# 1072
{ 
# 1081
} 
#endif
# 1083 "/usr/local/cuda-8.0/include/surface_functions.h"
template< class T> 
# 1084
__attribute((always_inline)) __attribute__((unused)) inline T surfCubemapLayeredread(surface< void, 252>  surf, int x, int y, int layerFace, cudaSurfaceBoundaryMode mode = cudaBoundaryModeTrap) 
# 1085
{int volatile ___ = 1;(void)surf;(void)x;(void)y;(void)layerFace;(void)mode;
# 1093
::exit(___);}
#if 0
# 1085
{ 
# 1093
} 
#endif
# 1095 "/usr/local/cuda-8.0/include/surface_functions.h"
template< class T> 
# 1096
__attribute((always_inline)) __attribute__((unused)) inline void surfCubemapLayeredread(T *res, surface< void, 252>  surf, int x, int y, int layerFace, cudaSurfaceBoundaryMode mode = cudaBoundaryModeTrap) 
# 1097
{int volatile ___ = 1;(void)res;(void)surf;(void)x;(void)y;(void)layerFace;(void)mode;
# 1101
::exit(___);}
#if 0
# 1097
{ 
# 1101
} 
#endif
# 1232 "/usr/local/cuda-8.0/include/surface_functions.h"
template< class T> 
# 1233
__attribute((always_inline)) __attribute__((unused)) inline void surf1Dwrite(T val, surface< void, 1>  surf, int x, int s, cudaSurfaceBoundaryMode mode = cudaBoundaryModeTrap) 
# 1234
{int volatile ___ = 1;(void)val;(void)surf;(void)x;(void)s;(void)mode;
# 1254
::exit(___);}
#if 0
# 1234
{ 
# 1254
} 
#endif
# 1256 "/usr/local/cuda-8.0/include/surface_functions.h"
template< class T> 
# 1257
__attribute((always_inline)) __attribute__((unused)) inline void surf1Dwrite(T val, surface< void, 1>  surf, int x, cudaSurfaceBoundaryMode mode = cudaBoundaryModeTrap) 
# 1258
{int volatile ___ = 1;(void)val;(void)surf;(void)x;(void)mode;
# 1262
::exit(___);}
#if 0
# 1258
{ 
# 1262
} 
#endif
# 1377 "/usr/local/cuda-8.0/include/surface_functions.h"
template< class T> 
# 1378
__attribute((always_inline)) __attribute__((unused)) inline void surf2Dwrite(T val, surface< void, 2>  surf, int x, int y, int s, cudaSurfaceBoundaryMode mode = cudaBoundaryModeTrap) 
# 1379
{int volatile ___ = 1;(void)val;(void)surf;(void)x;(void)y;(void)s;(void)mode;
# 1399
::exit(___);}
#if 0
# 1379
{ 
# 1399
} 
#endif
# 1401 "/usr/local/cuda-8.0/include/surface_functions.h"
template< class T> 
# 1402
__attribute((always_inline)) __attribute__((unused)) inline void surf2Dwrite(T val, surface< void, 2>  surf, int x, int y, cudaSurfaceBoundaryMode mode = cudaBoundaryModeTrap) 
# 1403
{int volatile ___ = 1;(void)val;(void)surf;(void)x;(void)y;(void)mode;
# 1407
::exit(___);}
#if 0
# 1403
{ 
# 1407
} 
#endif
# 1520 "/usr/local/cuda-8.0/include/surface_functions.h"
template< class T> 
# 1521
__attribute((always_inline)) __attribute__((unused)) inline void surf3Dwrite(T val, surface< void, 3>  surf, int x, int y, int z, int s, cudaSurfaceBoundaryMode mode = cudaBoundaryModeTrap) 
# 1522
{int volatile ___ = 1;(void)val;(void)surf;(void)x;(void)y;(void)z;(void)s;(void)mode;
# 1542
::exit(___);}
#if 0
# 1522
{ 
# 1542
} 
#endif
# 1544 "/usr/local/cuda-8.0/include/surface_functions.h"
template< class T> 
# 1545
__attribute((always_inline)) __attribute__((unused)) inline void surf3Dwrite(T val, surface< void, 3>  surf, int x, int y, int z, cudaSurfaceBoundaryMode mode = cudaBoundaryModeTrap) 
# 1546
{int volatile ___ = 1;(void)val;(void)surf;(void)x;(void)y;(void)z;(void)mode;
# 1550
::exit(___);}
#if 0
# 1546
{ 
# 1550
} 
#endif
# 1666 "/usr/local/cuda-8.0/include/surface_functions.h"
template< class T> 
# 1667
__attribute((always_inline)) __attribute__((unused)) static inline void surf1DLayeredwrite(T val, surface< void, 241>  surf, int x, int layer, int s, cudaSurfaceBoundaryMode mode = cudaBoundaryModeTrap) 
# 1668
{int volatile ___ = 1;(void)val;(void)surf;(void)x;(void)layer;(void)s;(void)mode;
# 1688
::exit(___);}
#if 0
# 1668
{ 
# 1688
} 
#endif
# 1690 "/usr/local/cuda-8.0/include/surface_functions.h"
template< class T> 
# 1691
__attribute((always_inline)) __attribute__((unused)) static inline void surf1DLayeredwrite(T val, surface< void, 241>  surf, int x, int layer, cudaSurfaceBoundaryMode mode = cudaBoundaryModeTrap) 
# 1692
{int volatile ___ = 1;(void)val;(void)surf;(void)x;(void)layer;(void)mode;
# 1696
::exit(___);}
#if 0
# 1692
{ 
# 1696
} 
#endif
# 1822 "/usr/local/cuda-8.0/include/surface_functions.h"
template< class T> 
# 1823
__attribute((always_inline)) __attribute__((unused)) inline void surf2DLayeredwrite(T val, surface< void, 242>  surf, int x, int y, int layer, int s, cudaSurfaceBoundaryMode mode = cudaBoundaryModeTrap) 
# 1824
{int volatile ___ = 1;(void)val;(void)surf;(void)x;(void)y;(void)layer;(void)s;(void)mode;
# 1844
::exit(___);}
#if 0
# 1824
{ 
# 1844
} 
#endif
# 1846 "/usr/local/cuda-8.0/include/surface_functions.h"
template< class T> 
# 1847
__attribute((always_inline)) __attribute__((unused)) inline void surf2DLayeredwrite(T val, surface< void, 242>  surf, int x, int y, int layer, cudaSurfaceBoundaryMode mode = cudaBoundaryModeTrap) 
# 1848
{int volatile ___ = 1;(void)val;(void)surf;(void)x;(void)y;(void)layer;(void)mode;
# 1852
::exit(___);}
#if 0
# 1848
{ 
# 1852
} 
#endif
# 1958 "/usr/local/cuda-8.0/include/surface_functions.h"
template< class T> 
# 1959
__attribute((always_inline)) __attribute__((unused)) inline void surfCubemapwrite(T val, surface< void, 12>  surf, int x, int y, int face, int s, cudaSurfaceBoundaryMode mode = cudaBoundaryModeTrap) 
# 1960
{int volatile ___ = 1;(void)val;(void)surf;(void)x;(void)y;(void)face;(void)s;(void)mode;
# 1980
::exit(___);}
#if 0
# 1960
{ 
# 1980
} 
#endif
# 1982 "/usr/local/cuda-8.0/include/surface_functions.h"
template< class T> 
# 1983
__attribute((always_inline)) __attribute__((unused)) inline void surfCubemapwrite(T val, surface< void, 12>  surf, int x, int y, int face, cudaSurfaceBoundaryMode mode = cudaBoundaryModeTrap) 
# 1984
{int volatile ___ = 1;(void)val;(void)surf;(void)x;(void)y;(void)face;(void)mode;
# 1988
::exit(___);}
#if 0
# 1984
{ 
# 1988
} 
#endif
# 2093 "/usr/local/cuda-8.0/include/surface_functions.h"
template< class T> 
# 2094
__attribute((always_inline)) __attribute__((unused)) static inline void surfCubemapLayeredwrite(T val, surface< void, 252>  surf, int x, int y, int layerFace, int s, cudaSurfaceBoundaryMode mode = cudaBoundaryModeTrap) 
# 2095
{int volatile ___ = 1;(void)val;(void)surf;(void)x;(void)y;(void)layerFace;(void)s;(void)mode;
# 2115
::exit(___);}
#if 0
# 2095
{ 
# 2115
} 
#endif
# 2117 "/usr/local/cuda-8.0/include/surface_functions.h"
template< class T> 
# 2118
__attribute((always_inline)) __attribute__((unused)) static inline void surfCubemapLayeredwrite(T val, surface< void, 252>  surf, int x, int y, int layerFace, cudaSurfaceBoundaryMode mode = cudaBoundaryModeTrap) 
# 2119
{int volatile ___ = 1;(void)val;(void)surf;(void)x;(void)y;(void)layerFace;(void)mode;
# 2123
::exit(___);}
#if 0
# 2119
{ 
# 2123
} 
#endif
# 70 "/usr/local/cuda-8.0/include/texture_fetch_functions.h"
template< class T> __attribute__((unused)) static T 
# 71
tex1Dfetch(texture< T, 1, cudaReadModeElementType> , int) {int volatile ___ = 1;::exit(___);}
#if 0
# 71
{ } 
#endif
# 73 "/usr/local/cuda-8.0/include/texture_fetch_functions.h"
template< class T> 
# 74
struct __nv_tex_rmnf_ret { }; 
# 76
template<> struct __nv_tex_rmnf_ret< char>  { typedef float type; }; 
# 77
template<> struct __nv_tex_rmnf_ret< signed char>  { typedef float type; }; 
# 78
template<> struct __nv_tex_rmnf_ret< unsigned char>  { typedef float type; }; 
# 79
template<> struct __nv_tex_rmnf_ret< short>  { typedef float type; }; 
# 80
template<> struct __nv_tex_rmnf_ret< unsigned short>  { typedef float type; }; 
# 81
template<> struct __nv_tex_rmnf_ret< char1>  { typedef float1 type; }; 
# 82
template<> struct __nv_tex_rmnf_ret< uchar1>  { typedef float1 type; }; 
# 83
template<> struct __nv_tex_rmnf_ret< short1>  { typedef float1 type; }; 
# 84
template<> struct __nv_tex_rmnf_ret< ushort1>  { typedef float1 type; }; 
# 85
template<> struct __nv_tex_rmnf_ret< char2>  { typedef float2 type; }; 
# 86
template<> struct __nv_tex_rmnf_ret< uchar2>  { typedef float2 type; }; 
# 87
template<> struct __nv_tex_rmnf_ret< short2>  { typedef float2 type; }; 
# 88
template<> struct __nv_tex_rmnf_ret< ushort2>  { typedef float2 type; }; 
# 89
template<> struct __nv_tex_rmnf_ret< char4>  { typedef float4 type; }; 
# 90
template<> struct __nv_tex_rmnf_ret< uchar4>  { typedef float4 type; }; 
# 91
template<> struct __nv_tex_rmnf_ret< short4>  { typedef float4 type; }; 
# 92
template<> struct __nv_tex_rmnf_ret< ushort4>  { typedef float4 type; }; 
# 94
template< class T> __attribute__((unused)) static typename __nv_tex_rmnf_ret< T> ::type 
# 95
tex1Dfetch(texture< T, 1, cudaReadModeNormalizedFloat> , int) {int volatile ___ = 1;::exit(___);}
#if 0
# 95
{ } 
#endif
# 215 "/usr/local/cuda-8.0/include/texture_fetch_functions.h"
template< class T> __attribute__((unused)) static T 
# 216
tex1D(texture< T, 1, cudaReadModeElementType> , float) {int volatile ___ = 1;::exit(___);}
#if 0
# 216
{ } 
#endif
# 218 "/usr/local/cuda-8.0/include/texture_fetch_functions.h"
template< class T> __attribute__((unused)) static typename __nv_tex_rmnf_ret< T> ::type 
# 219
tex1D(texture< T, 1, cudaReadModeNormalizedFloat> , float) {int volatile ___ = 1;::exit(___);}
#if 0
# 219
{ } 
#endif
# 345 "/usr/local/cuda-8.0/include/texture_fetch_functions.h"
template< class T> __attribute__((unused)) static T 
# 346
tex2D(texture< T, 2, cudaReadModeElementType> , float, float) {int volatile ___ = 1;::exit(___);}
#if 0
# 346
{ } 
#endif
# 348 "/usr/local/cuda-8.0/include/texture_fetch_functions.h"
template< class T> __attribute__((unused)) static typename __nv_tex_rmnf_ret< T> ::type 
# 349
tex2D(texture< T, 2, cudaReadModeNormalizedFloat> , float, float) {int volatile ___ = 1;::exit(___);}
#if 0
# 349
{ } 
#endif
# 475 "/usr/local/cuda-8.0/include/texture_fetch_functions.h"
template< class T> __attribute__((unused)) static T 
# 476
tex1DLayered(texture< T, 241, cudaReadModeElementType> , float, int) {int volatile ___ = 1;::exit(___);}
#if 0
# 476
{ } 
#endif
# 478 "/usr/local/cuda-8.0/include/texture_fetch_functions.h"
template< class T> __attribute__((unused)) static typename __nv_tex_rmnf_ret< T> ::type 
# 479
tex1DLayered(texture< T, 241, cudaReadModeNormalizedFloat> , float, int) {int volatile ___ = 1;::exit(___);}
#if 0
# 479
{ } 
#endif
# 603 "/usr/local/cuda-8.0/include/texture_fetch_functions.h"
template< class T> __attribute__((unused)) static T 
# 604
tex2DLayered(texture< T, 242, cudaReadModeElementType> , float, float, int) {int volatile ___ = 1;::exit(___);}
#if 0
# 604
{ } 
#endif
# 606 "/usr/local/cuda-8.0/include/texture_fetch_functions.h"
template< class T> __attribute__((unused)) static typename __nv_tex_rmnf_ret< T> ::type 
# 607
tex2DLayered(texture< T, 242, cudaReadModeNormalizedFloat> , float, float, int) {int volatile ___ = 1;::exit(___);}
#if 0
# 607
{ } 
#endif
# 735 "/usr/local/cuda-8.0/include/texture_fetch_functions.h"
template< class T> __attribute__((unused)) static T 
# 736
tex3D(texture< T, 3, cudaReadModeElementType> , float, float, float) {int volatile ___ = 1;::exit(___);}
#if 0
# 736
{ } 
#endif
# 738 "/usr/local/cuda-8.0/include/texture_fetch_functions.h"
template< class T> __attribute__((unused)) static typename __nv_tex_rmnf_ret< T> ::type 
# 739
tex3D(texture< T, 3, cudaReadModeNormalizedFloat> , float, float, float) {int volatile ___ = 1;::exit(___);}
#if 0
# 739
{ } 
#endif
# 864 "/usr/local/cuda-8.0/include/texture_fetch_functions.h"
template< class T> __attribute__((unused)) static T 
# 865
texCubemap(texture< T, 12, cudaReadModeElementType> , float, float, float) {int volatile ___ = 1;::exit(___);}
#if 0
# 865
{ } 
#endif
# 867 "/usr/local/cuda-8.0/include/texture_fetch_functions.h"
template< class T> __attribute__((unused)) static typename __nv_tex_rmnf_ret< T> ::type 
# 868
texCubemap(texture< T, 12, cudaReadModeNormalizedFloat> , float, float, float) {int volatile ___ = 1;::exit(___);}
#if 0
# 868
{ } 
#endif
# 992 "/usr/local/cuda-8.0/include/texture_fetch_functions.h"
template< class T> __attribute__((unused)) static T 
# 993
texCubemapLayered(texture< T, 252, cudaReadModeElementType> , float, float, float, int) {int volatile ___ = 1;::exit(___);}
#if 0
# 993
{ } 
#endif
# 995 "/usr/local/cuda-8.0/include/texture_fetch_functions.h"
template< class T> __attribute__((unused)) static typename __nv_tex_rmnf_ret< T> ::type 
# 996
texCubemapLayered(texture< T, 252, cudaReadModeNormalizedFloat> , float, float, float, int) {int volatile ___ = 1;::exit(___);}
#if 0
# 996
{ } 
#endif
# 1121 "/usr/local/cuda-8.0/include/texture_fetch_functions.h"
template< class T> 
# 1122
struct __nv_tex2dgather_ret { }; 
# 1123
template<> struct __nv_tex2dgather_ret< char>  { typedef char4 type; }; 
# 1124
template<> struct __nv_tex2dgather_ret< signed char>  { typedef char4 type; }; 
# 1125
template<> struct __nv_tex2dgather_ret< char1>  { typedef char4 type; }; 
# 1126
template<> struct __nv_tex2dgather_ret< char2>  { typedef char4 type; }; 
# 1127
template<> struct __nv_tex2dgather_ret< char3>  { typedef char4 type; }; 
# 1128
template<> struct __nv_tex2dgather_ret< char4>  { typedef char4 type; }; 
# 1129
template<> struct __nv_tex2dgather_ret< unsigned char>  { typedef uchar4 type; }; 
# 1130
template<> struct __nv_tex2dgather_ret< uchar1>  { typedef uchar4 type; }; 
# 1131
template<> struct __nv_tex2dgather_ret< uchar2>  { typedef uchar4 type; }; 
# 1132
template<> struct __nv_tex2dgather_ret< uchar3>  { typedef uchar4 type; }; 
# 1133
template<> struct __nv_tex2dgather_ret< uchar4>  { typedef uchar4 type; }; 
# 1135
template<> struct __nv_tex2dgather_ret< short>  { typedef short4 type; }; 
# 1136
template<> struct __nv_tex2dgather_ret< short1>  { typedef short4 type; }; 
# 1137
template<> struct __nv_tex2dgather_ret< short2>  { typedef short4 type; }; 
# 1138
template<> struct __nv_tex2dgather_ret< short3>  { typedef short4 type; }; 
# 1139
template<> struct __nv_tex2dgather_ret< short4>  { typedef short4 type; }; 
# 1140
template<> struct __nv_tex2dgather_ret< unsigned short>  { typedef ushort4 type; }; 
# 1141
template<> struct __nv_tex2dgather_ret< ushort1>  { typedef ushort4 type; }; 
# 1142
template<> struct __nv_tex2dgather_ret< ushort2>  { typedef ushort4 type; }; 
# 1143
template<> struct __nv_tex2dgather_ret< ushort3>  { typedef ushort4 type; }; 
# 1144
template<> struct __nv_tex2dgather_ret< ushort4>  { typedef ushort4 type; }; 
# 1146
template<> struct __nv_tex2dgather_ret< int>  { typedef int4 type; }; 
# 1147
template<> struct __nv_tex2dgather_ret< int1>  { typedef int4 type; }; 
# 1148
template<> struct __nv_tex2dgather_ret< int2>  { typedef int4 type; }; 
# 1149
template<> struct __nv_tex2dgather_ret< int3>  { typedef int4 type; }; 
# 1150
template<> struct __nv_tex2dgather_ret< int4>  { typedef int4 type; }; 
# 1151
template<> struct __nv_tex2dgather_ret< unsigned>  { typedef uint4 type; }; 
# 1152
template<> struct __nv_tex2dgather_ret< uint1>  { typedef uint4 type; }; 
# 1153
template<> struct __nv_tex2dgather_ret< uint2>  { typedef uint4 type; }; 
# 1154
template<> struct __nv_tex2dgather_ret< uint3>  { typedef uint4 type; }; 
# 1155
template<> struct __nv_tex2dgather_ret< uint4>  { typedef uint4 type; }; 
# 1157
template<> struct __nv_tex2dgather_ret< float>  { typedef float4 type; }; 
# 1158
template<> struct __nv_tex2dgather_ret< float1>  { typedef float4 type; }; 
# 1159
template<> struct __nv_tex2dgather_ret< float2>  { typedef float4 type; }; 
# 1160
template<> struct __nv_tex2dgather_ret< float3>  { typedef float4 type; }; 
# 1161
template<> struct __nv_tex2dgather_ret< float4>  { typedef float4 type; }; 
# 1163
template< class T> __attribute__((unused)) static typename __nv_tex2dgather_ret< T> ::type 
# 1164
tex2Dgather(texture< T, 2, cudaReadModeElementType> , float, float, int = 0) {int volatile ___ = 1;::exit(___);}
#if 0
# 1164
{ } 
#endif
# 1166 "/usr/local/cuda-8.0/include/texture_fetch_functions.h"
template< class T> __attribute__((unused)) static float4 
# 1167
tex2Dgather(texture< T, 2, cudaReadModeNormalizedFloat> , float, float, int = 0) {int volatile ___ = 1;::exit(___);}
#if 0
# 1167
{ } 
#endif
# 1232 "/usr/local/cuda-8.0/include/texture_fetch_functions.h"
template< class T> __attribute__((unused)) static T 
# 1233
tex1DLod(texture< T, 1, cudaReadModeElementType> , float, float) {int volatile ___ = 1;::exit(___);}
#if 0
# 1233
{ } 
#endif
# 1235 "/usr/local/cuda-8.0/include/texture_fetch_functions.h"
template< class T> __attribute__((unused)) static typename __nv_tex_rmnf_ret< T> ::type 
# 1236
tex1DLod(texture< T, 1, cudaReadModeNormalizedFloat> , float, float) {int volatile ___ = 1;::exit(___);}
#if 0
# 1236
{ } 
#endif
# 1360 "/usr/local/cuda-8.0/include/texture_fetch_functions.h"
template< class T> __attribute__((unused)) static T 
# 1361
tex2DLod(texture< T, 2, cudaReadModeElementType> , float, float, float) {int volatile ___ = 1;::exit(___);}
#if 0
# 1361
{ } 
#endif
# 1363 "/usr/local/cuda-8.0/include/texture_fetch_functions.h"
template< class T> __attribute__((unused)) static typename __nv_tex_rmnf_ret< T> ::type 
# 1364
tex2DLod(texture< T, 2, cudaReadModeNormalizedFloat> , float, float, float) {int volatile ___ = 1;::exit(___);}
#if 0
# 1364
{ } 
#endif
# 1484 "/usr/local/cuda-8.0/include/texture_fetch_functions.h"
template< class T> __attribute__((unused)) static T 
# 1485
tex1DLayeredLod(texture< T, 241, cudaReadModeElementType> , float, int, float) {int volatile ___ = 1;::exit(___);}
#if 0
# 1485
{ } 
#endif
# 1487 "/usr/local/cuda-8.0/include/texture_fetch_functions.h"
template< class T> __attribute__((unused)) static typename __nv_tex_rmnf_ret< T> ::type 
# 1488
tex1DLayeredLod(texture< T, 241, cudaReadModeNormalizedFloat> , float, int, float) {int volatile ___ = 1;::exit(___);}
#if 0
# 1488
{ } 
#endif
# 1612 "/usr/local/cuda-8.0/include/texture_fetch_functions.h"
template< class T> __attribute__((unused)) static T 
# 1613
tex2DLayeredLod(texture< T, 242, cudaReadModeElementType> , float, float, int, float) {int volatile ___ = 1;::exit(___);}
#if 0
# 1613
{ } 
#endif
# 1615 "/usr/local/cuda-8.0/include/texture_fetch_functions.h"
template< class T> __attribute__((unused)) static typename __nv_tex_rmnf_ret< T> ::type 
# 1616
tex2DLayeredLod(texture< T, 242, cudaReadModeNormalizedFloat> , float, float, int, float) {int volatile ___ = 1;::exit(___);}
#if 0
# 1616
{ } 
#endif
# 1740 "/usr/local/cuda-8.0/include/texture_fetch_functions.h"
template< class T> __attribute__((unused)) static T 
# 1741
tex3DLod(texture< T, 3, cudaReadModeElementType> , float, float, float, float) {int volatile ___ = 1;::exit(___);}
#if 0
# 1741
{ } 
#endif
# 1743 "/usr/local/cuda-8.0/include/texture_fetch_functions.h"
template< class T> __attribute__((unused)) static typename __nv_tex_rmnf_ret< T> ::type 
# 1744
tex3DLod(texture< T, 3, cudaReadModeNormalizedFloat> , float, float, float, float) {int volatile ___ = 1;::exit(___);}
#if 0
# 1744
{ } 
#endif
# 1868 "/usr/local/cuda-8.0/include/texture_fetch_functions.h"
template< class T> __attribute__((unused)) static T 
# 1869
texCubemapLod(texture< T, 12, cudaReadModeElementType> , float, float, float, float) {int volatile ___ = 1;::exit(___);}
#if 0
# 1869
{ } 
#endif
# 1871 "/usr/local/cuda-8.0/include/texture_fetch_functions.h"
template< class T> __attribute__((unused)) static typename __nv_tex_rmnf_ret< T> ::type 
# 1872
texCubemapLod(texture< T, 12, cudaReadModeNormalizedFloat> , float, float, float, float) {int volatile ___ = 1;::exit(___);}
#if 0
# 1872
{ } 
#endif
# 1996 "/usr/local/cuda-8.0/include/texture_fetch_functions.h"
template< class T> __attribute__((unused)) static T 
# 1997
texCubemapLayeredLod(texture< T, 252, cudaReadModeElementType> , float, float, float, int, float) {int volatile ___ = 1;::exit(___);}
#if 0
# 1997
{ } 
#endif
# 1999 "/usr/local/cuda-8.0/include/texture_fetch_functions.h"
template< class T> __attribute__((unused)) static typename __nv_tex_rmnf_ret< T> ::type 
# 2000
texCubemapLayeredLod(texture< T, 252, cudaReadModeNormalizedFloat> , float, float, float, int, float) {int volatile ___ = 1;::exit(___);}
#if 0
# 2000
{ } 
#endif
# 2124 "/usr/local/cuda-8.0/include/texture_fetch_functions.h"
template< class T> __attribute__((unused)) static T 
# 2125
tex1DGrad(texture< T, 1, cudaReadModeElementType> , float, float, float) {int volatile ___ = 1;::exit(___);}
#if 0
# 2125
{ } 
#endif
# 2127 "/usr/local/cuda-8.0/include/texture_fetch_functions.h"
template< class T> __attribute__((unused)) static typename __nv_tex_rmnf_ret< T> ::type 
# 2128
tex1DGrad(texture< T, 1, cudaReadModeNormalizedFloat> , float, float, float) {int volatile ___ = 1;::exit(___);}
#if 0
# 2128
{ } 
#endif
# 2252 "/usr/local/cuda-8.0/include/texture_fetch_functions.h"
template< class T> __attribute__((unused)) static T 
# 2253
tex2DGrad(texture< T, 2, cudaReadModeElementType> , float, float, float2, float2) {int volatile ___ = 1;::exit(___);}
#if 0
# 2253
{ } 
#endif
# 2255 "/usr/local/cuda-8.0/include/texture_fetch_functions.h"
template< class T> __attribute__((unused)) static typename __nv_tex_rmnf_ret< T> ::type 
# 2256
tex2DGrad(texture< T, 2, cudaReadModeNormalizedFloat> , float, float, float2, float2) {int volatile ___ = 1;::exit(___);}
#if 0
# 2256
{ } 
#endif
# 2380 "/usr/local/cuda-8.0/include/texture_fetch_functions.h"
template< class T> __attribute__((unused)) static T 
# 2381
tex1DLayeredGrad(texture< T, 241, cudaReadModeElementType> , float, int, float, float) {int volatile ___ = 1;::exit(___);}
#if 0
# 2381
{ } 
#endif
# 2383 "/usr/local/cuda-8.0/include/texture_fetch_functions.h"
template< class T> __attribute__((unused)) static typename __nv_tex_rmnf_ret< T> ::type 
# 2384
tex1DLayeredGrad(texture< T, 241, cudaReadModeNormalizedFloat> , float, int, float, float) {int volatile ___ = 1;::exit(___);}
#if 0
# 2384
{ } 
#endif
# 2509 "/usr/local/cuda-8.0/include/texture_fetch_functions.h"
template< class T> __attribute__((unused)) static T 
# 2510
tex2DLayeredGrad(texture< T, 242, cudaReadModeElementType> , float, float, int, float2, float2) {int volatile ___ = 1;::exit(___);}
#if 0
# 2510
{ } 
#endif
# 2512 "/usr/local/cuda-8.0/include/texture_fetch_functions.h"
template< class T> __attribute__((unused)) static typename __nv_tex_rmnf_ret< T> ::type 
# 2513
tex2DLayeredGrad(texture< T, 242, cudaReadModeNormalizedFloat> , float, float, int, float2, float2) {int volatile ___ = 1;::exit(___);}
#if 0
# 2513
{ } 
#endif
# 2637 "/usr/local/cuda-8.0/include/texture_fetch_functions.h"
template< class T> __attribute__((unused)) static T 
# 2638
tex3DGrad(texture< T, 3, cudaReadModeElementType> , float, float, float, float4, float4) {int volatile ___ = 1;::exit(___);}
#if 0
# 2638
{ } 
#endif
# 2640 "/usr/local/cuda-8.0/include/texture_fetch_functions.h"
template< class T> __attribute__((unused)) static typename __nv_tex_rmnf_ret< T> ::type 
# 2641
tex3DGrad(texture< T, 3, cudaReadModeNormalizedFloat> , float, float, float, float4, float4) {int volatile ___ = 1;::exit(___);}
#if 0
# 2641
{ } 
#endif
# 67 "/usr/local/cuda-8.0/include/texture_indirect_functions.h"
template< class T> __attribute__((unused)) static void 
# 68
tex1Dfetch(T *, cudaTextureObject_t, int) {int volatile ___ = 1;::exit(___);}
#if 0
# 68
{ } 
#endif
# 121 "/usr/local/cuda-8.0/include/texture_indirect_functions.h"
template< class T> __attribute__((unused)) static T 
# 122
tex1Dfetch(cudaTextureObject_t texObject, int x) 
# 123
{int volatile ___ = 1;(void)texObject;(void)x;
# 127
::exit(___);}
#if 0
# 123
{ 
# 124
T ret; 
# 125
tex1Dfetch(&ret, texObject, x); 
# 126
return ret; 
# 127
} 
#endif
# 135 "/usr/local/cuda-8.0/include/texture_indirect_functions.h"
template< class T> __attribute__((unused)) static void 
# 136
tex1D(T *, cudaTextureObject_t, float) {int volatile ___ = 1;::exit(___);}
#if 0
# 136
{ } 
#endif
# 190 "/usr/local/cuda-8.0/include/texture_indirect_functions.h"
template< class T> __attribute__((unused)) static T 
# 191
tex1D(cudaTextureObject_t texObject, float x) 
# 192
{int volatile ___ = 1;(void)texObject;(void)x;
# 196
::exit(___);}
#if 0
# 192
{ 
# 193
T ret; 
# 194
tex1D(&ret, texObject, x); 
# 195
return ret; 
# 196
} 
#endif
# 205 "/usr/local/cuda-8.0/include/texture_indirect_functions.h"
template< class T> __attribute__((unused)) static void 
# 206
tex2D(T *, cudaTextureObject_t, float, float) {int volatile ___ = 1;::exit(___);}
#if 0
# 206
{ } 
#endif
# 258 "/usr/local/cuda-8.0/include/texture_indirect_functions.h"
template< class T> __attribute__((unused)) static T 
# 259
tex2D(cudaTextureObject_t texObject, float x, float y) 
# 260
{int volatile ___ = 1;(void)texObject;(void)x;(void)y;
# 264
::exit(___);}
#if 0
# 260
{ 
# 261
T ret; 
# 262
tex2D(&ret, texObject, x, y); 
# 263
return ret; 
# 264
} 
#endif
# 272 "/usr/local/cuda-8.0/include/texture_indirect_functions.h"
template< class T> __attribute__((unused)) static void 
# 273
tex3D(T *, cudaTextureObject_t, float, float, float) {int volatile ___ = 1;::exit(___);}
#if 0
# 273
{ } 
#endif
# 325 "/usr/local/cuda-8.0/include/texture_indirect_functions.h"
template< class T> __attribute__((unused)) static T 
# 326
tex3D(cudaTextureObject_t texObject, float x, float y, float z) 
# 327
{int volatile ___ = 1;(void)texObject;(void)x;(void)y;(void)z;
# 331
::exit(___);}
#if 0
# 327
{ 
# 328
T ret; 
# 329
tex3D(&ret, texObject, x, y, z); 
# 330
return ret; 
# 331
} 
#endif
# 340 "/usr/local/cuda-8.0/include/texture_indirect_functions.h"
template< class T> __attribute__((unused)) static void 
# 341
tex1DLayered(T *, cudaTextureObject_t, float, int) {int volatile ___ = 1;::exit(___);}
#if 0
# 341
{ } 
#endif
# 393 "/usr/local/cuda-8.0/include/texture_indirect_functions.h"
template< class T> __attribute__((unused)) static T 
# 394
tex1DLayered(cudaTextureObject_t texObject, float x, int layer) 
# 395
{int volatile ___ = 1;(void)texObject;(void)x;(void)layer;
# 399
::exit(___);}
#if 0
# 395
{ 
# 396
T ret; 
# 397
tex1DLayered(&ret, texObject, x, layer); 
# 398
return ret; 
# 399
} 
#endif
# 408 "/usr/local/cuda-8.0/include/texture_indirect_functions.h"
template< class T> __attribute__((unused)) static void 
# 409
tex2DLayered(T *, cudaTextureObject_t, float, float, int) {int volatile ___ = 1;::exit(___);}
#if 0
# 409
{ } 
#endif
# 461 "/usr/local/cuda-8.0/include/texture_indirect_functions.h"
template< class T> __attribute__((unused)) static T 
# 462
tex2DLayered(cudaTextureObject_t texObject, float x, float y, int layer) 
# 463
{int volatile ___ = 1;(void)texObject;(void)x;(void)y;(void)layer;
# 467
::exit(___);}
#if 0
# 463
{ 
# 464
T ret; 
# 465
tex2DLayered(&ret, texObject, x, y, layer); 
# 466
return ret; 
# 467
} 
#endif
# 476 "/usr/local/cuda-8.0/include/texture_indirect_functions.h"
template< class T> __attribute__((unused)) static void 
# 477
texCubemap(T *, cudaTextureObject_t, float, float, float) {int volatile ___ = 1;::exit(___);}
#if 0
# 477
{ } 
#endif
# 529 "/usr/local/cuda-8.0/include/texture_indirect_functions.h"
template< class T> __attribute__((unused)) static T 
# 530
texCubemap(cudaTextureObject_t texObject, float x, float y, float z) 
# 531
{int volatile ___ = 1;(void)texObject;(void)x;(void)y;(void)z;
# 535
::exit(___);}
#if 0
# 531
{ 
# 532
T ret; 
# 533
texCubemap(&ret, texObject, x, y, z); 
# 534
return ret; 
# 535
} 
#endif
# 544 "/usr/local/cuda-8.0/include/texture_indirect_functions.h"
template< class T> __attribute__((unused)) static void 
# 545
texCubemapLayered(T *, cudaTextureObject_t, float, float, float, int) {int volatile ___ = 1;::exit(___);}
#if 0
# 545
{ } 
#endif
# 598 "/usr/local/cuda-8.0/include/texture_indirect_functions.h"
template< class T> __attribute__((unused)) static T 
# 599
texCubemapLayered(cudaTextureObject_t texObject, float x, float y, float z, int layer) 
# 600
{int volatile ___ = 1;(void)texObject;(void)x;(void)y;(void)z;(void)layer;
# 604
::exit(___);}
#if 0
# 600
{ 
# 601
T ret; 
# 602
texCubemapLayered(&ret, texObject, x, y, z, layer); 
# 603
return ret; 
# 604
} 
#endif
# 613 "/usr/local/cuda-8.0/include/texture_indirect_functions.h"
template< class T> __attribute__((unused)) static void 
# 614
tex2Dgather(T *, cudaTextureObject_t, float, float, int = 0) {int volatile ___ = 1;::exit(___);}
#if 0
# 614
{ } 
#endif
# 660 "/usr/local/cuda-8.0/include/texture_indirect_functions.h"
template< class T> __attribute__((unused)) static T 
# 661
tex2Dgather(cudaTextureObject_t to, float x, float y, int comp = 0) 
# 662
{int volatile ___ = 1;(void)to;(void)x;(void)y;(void)comp;
# 666
::exit(___);}
#if 0
# 662
{ 
# 663
T ret; 
# 664
tex2Dgather(&ret, to, x, y, comp); 
# 665
return ret; 
# 666
} 
#endif
# 675 "/usr/local/cuda-8.0/include/texture_indirect_functions.h"
template< class T> __attribute__((unused)) static void 
# 676
tex1DLod(T *, cudaTextureObject_t, float, float) {int volatile ___ = 1;::exit(___);}
#if 0
# 676
{ } 
#endif
# 728 "/usr/local/cuda-8.0/include/texture_indirect_functions.h"
template< class T> __attribute__((unused)) static T 
# 729
tex1DLod(cudaTextureObject_t texObject, float x, float level) 
# 730
{int volatile ___ = 1;(void)texObject;(void)x;(void)level;
# 734
::exit(___);}
#if 0
# 730
{ 
# 731
T ret; 
# 732
tex1DLod(&ret, texObject, x, level); 
# 733
return ret; 
# 734
} 
#endif
# 743 "/usr/local/cuda-8.0/include/texture_indirect_functions.h"
template< class T> __attribute__((unused)) static void 
# 744
tex2DLod(T *, cudaTextureObject_t, float, float, float) {int volatile ___ = 1;::exit(___);}
#if 0
# 744
{ } 
#endif
# 797 "/usr/local/cuda-8.0/include/texture_indirect_functions.h"
template< class T> __attribute__((unused)) static T 
# 798
tex2DLod(cudaTextureObject_t texObject, float x, float y, float level) 
# 799
{int volatile ___ = 1;(void)texObject;(void)x;(void)y;(void)level;
# 803
::exit(___);}
#if 0
# 799
{ 
# 800
T ret; 
# 801
tex2DLod(&ret, texObject, x, y, level); 
# 802
return ret; 
# 803
} 
#endif
# 812 "/usr/local/cuda-8.0/include/texture_indirect_functions.h"
template< class T> __attribute__((unused)) static void 
# 813
tex3DLod(T *, cudaTextureObject_t, float, float, float, float) {int volatile ___ = 1;::exit(___);}
#if 0
# 813
{ } 
#endif
# 865 "/usr/local/cuda-8.0/include/texture_indirect_functions.h"
template< class T> __attribute__((unused)) static T 
# 866
tex3DLod(cudaTextureObject_t texObject, float x, float y, float z, float level) 
# 867
{int volatile ___ = 1;(void)texObject;(void)x;(void)y;(void)z;(void)level;
# 871
::exit(___);}
#if 0
# 867
{ 
# 868
T ret; 
# 869
tex3DLod(&ret, texObject, x, y, z, level); 
# 870
return ret; 
# 871
} 
#endif
# 879 "/usr/local/cuda-8.0/include/texture_indirect_functions.h"
template< class T> __attribute__((unused)) static void 
# 880
tex1DLayeredLod(T *, cudaTextureObject_t, float, int, float) {int volatile ___ = 1;::exit(___);}
#if 0
# 880
{ } 
#endif
# 932 "/usr/local/cuda-8.0/include/texture_indirect_functions.h"
template< class T> __attribute__((unused)) static T 
# 933
tex1DLayeredLod(cudaTextureObject_t texObject, float x, int layer, float level) 
# 934
{int volatile ___ = 1;(void)texObject;(void)x;(void)layer;(void)level;
# 938
::exit(___);}
#if 0
# 934
{ 
# 935
T ret; 
# 936
tex1DLayeredLod(&ret, texObject, x, layer, level); 
# 937
return ret; 
# 938
} 
#endif
# 947 "/usr/local/cuda-8.0/include/texture_indirect_functions.h"
template< class T> __attribute__((unused)) static void 
# 948
tex2DLayeredLod(T *, cudaTextureObject_t, float, float, int, float) {int volatile ___ = 1;::exit(___);}
#if 0
# 948
{ } 
#endif
# 1000 "/usr/local/cuda-8.0/include/texture_indirect_functions.h"
template< class T> __attribute__((unused)) static T 
# 1001
tex2DLayeredLod(cudaTextureObject_t texObject, float x, float y, int layer, float level) 
# 1002
{int volatile ___ = 1;(void)texObject;(void)x;(void)y;(void)layer;(void)level;
# 1006
::exit(___);}
#if 0
# 1002
{ 
# 1003
T ret; 
# 1004
tex2DLayeredLod(&ret, texObject, x, y, layer, level); 
# 1005
return ret; 
# 1006
} 
#endif
# 1014 "/usr/local/cuda-8.0/include/texture_indirect_functions.h"
template< class T> __attribute__((unused)) static void 
# 1015
texCubemapLod(T *, cudaTextureObject_t, float, float, float, float) {int volatile ___ = 1;::exit(___);}
#if 0
# 1015
{ } 
#endif
# 1067 "/usr/local/cuda-8.0/include/texture_indirect_functions.h"
template< class T> __attribute__((unused)) static T 
# 1068
texCubemapLod(cudaTextureObject_t texObject, float x, float y, float z, float level) 
# 1069
{int volatile ___ = 1;(void)texObject;(void)x;(void)y;(void)z;(void)level;
# 1073
::exit(___);}
#if 0
# 1069
{ 
# 1070
T ret; 
# 1071
texCubemapLod(&ret, texObject, x, y, z, level); 
# 1072
return ret; 
# 1073
} 
#endif
# 1081 "/usr/local/cuda-8.0/include/texture_indirect_functions.h"
template< class T> __attribute__((unused)) static void 
# 1082
texCubemapLayeredLod(T *, cudaTextureObject_t, float, float, float, int, float) {int volatile ___ = 1;::exit(___);}
#if 0
# 1082
{ } 
#endif
# 1134 "/usr/local/cuda-8.0/include/texture_indirect_functions.h"
template< class T> __attribute__((unused)) static T 
# 1135
texCubemapLayeredLod(cudaTextureObject_t texObject, float x, float y, float z, int layer, float level) 
# 1136
{int volatile ___ = 1;(void)texObject;(void)x;(void)y;(void)z;(void)layer;(void)level;
# 1140
::exit(___);}
#if 0
# 1136
{ 
# 1137
T ret; 
# 1138
texCubemapLayeredLod(&ret, texObject, x, y, z, layer, level); 
# 1139
return ret; 
# 1140
} 
#endif
# 1148 "/usr/local/cuda-8.0/include/texture_indirect_functions.h"
template< class T> __attribute__((unused)) static void 
# 1149
tex1DGrad(T *, cudaTextureObject_t, float, float, float) {int volatile ___ = 1;::exit(___);}
#if 0
# 1149
{ } 
#endif
# 1202 "/usr/local/cuda-8.0/include/texture_indirect_functions.h"
template< class T> __attribute__((unused)) static T 
# 1203
tex1DGrad(cudaTextureObject_t texObject, float x, float dPdx, float dPdy) 
# 1204
{int volatile ___ = 1;(void)texObject;(void)x;(void)dPdx;(void)dPdy;
# 1208
::exit(___);}
#if 0
# 1204
{ 
# 1205
T ret; 
# 1206
tex1DGrad(&ret, texObject, x, dPdx, dPdy); 
# 1207
return ret; 
# 1208
} 
#endif
# 1216 "/usr/local/cuda-8.0/include/texture_indirect_functions.h"
template< class T> __attribute__((unused)) static void 
# 1217
tex2DGrad(T *, cudaTextureObject_t, float, float, float2, float2) {int volatile ___ = 1;::exit(___);}
#if 0
# 1217
{ } 
#endif
# 1269 "/usr/local/cuda-8.0/include/texture_indirect_functions.h"
template< class T> __attribute__((unused)) static T 
# 1270
tex2DGrad(cudaTextureObject_t texObject, float x, float y, float2 dPdx, float2 dPdy) 
# 1271
{int volatile ___ = 1;(void)texObject;(void)x;(void)y;(void)dPdx;(void)dPdy;
# 1275
::exit(___);}
#if 0
# 1271
{ 
# 1272
T ret; 
# 1273
tex2DGrad(&ret, texObject, x, y, dPdx, dPdy); 
# 1274
return ret; 
# 1275
} 
#endif
# 1283 "/usr/local/cuda-8.0/include/texture_indirect_functions.h"
template< class T> __attribute__((unused)) static void 
# 1284
tex3DGrad(T *, cudaTextureObject_t, float, float, float, float4, float4) {int volatile ___ = 1;::exit(___);}
#if 0
# 1284
{ } 
#endif
# 1336 "/usr/local/cuda-8.0/include/texture_indirect_functions.h"
template< class T> __attribute__((unused)) static T 
# 1337
tex3DGrad(cudaTextureObject_t texObject, float x, float y, float z, float4 dPdx, float4 dPdy) 
# 1338
{int volatile ___ = 1;(void)texObject;(void)x;(void)y;(void)z;(void)dPdx;(void)dPdy;
# 1342
::exit(___);}
#if 0
# 1338
{ 
# 1339
T ret; 
# 1340
tex3DGrad(&ret, texObject, x, y, z, dPdx, dPdy); 
# 1341
return ret; 
# 1342
} 
#endif
# 1350 "/usr/local/cuda-8.0/include/texture_indirect_functions.h"
template< class T> __attribute__((unused)) static void 
# 1351
tex1DLayeredGrad(T *, cudaTextureObject_t, float, int, float, float) {int volatile ___ = 1;::exit(___);}
#if 0
# 1351
{ } 
#endif
# 1404 "/usr/local/cuda-8.0/include/texture_indirect_functions.h"
template< class T> __attribute__((unused)) static T 
# 1405
tex1DLayeredGrad(cudaTextureObject_t texObject, float x, int layer, float dPdx, float dPdy) 
# 1406
{int volatile ___ = 1;(void)texObject;(void)x;(void)layer;(void)dPdx;(void)dPdy;
# 1410
::exit(___);}
#if 0
# 1406
{ 
# 1407
T ret; 
# 1408
tex1DLayeredGrad(&ret, texObject, x, layer, dPdx, dPdy); 
# 1409
return ret; 
# 1410
} 
#endif
# 1418 "/usr/local/cuda-8.0/include/texture_indirect_functions.h"
template< class T> __attribute__((unused)) static void 
# 1419
tex2DLayeredGrad(T *, cudaTextureObject_t, float, float, int, float2, float2) {int volatile ___ = 1;::exit(___);}
#if 0
# 1419
{ } 
#endif
# 1471 "/usr/local/cuda-8.0/include/texture_indirect_functions.h"
template< class T> __attribute__((unused)) static T 
# 1472
tex2DLayeredGrad(cudaTextureObject_t texObject, float x, float y, int layer, float2 dPdx, float2 dPdy) 
# 1473
{int volatile ___ = 1;(void)texObject;(void)x;(void)y;(void)layer;(void)dPdx;(void)dPdy;
# 1477
::exit(___);}
#if 0
# 1473
{ 
# 1474
T ret; 
# 1475
tex2DLayeredGrad(&ret, texObject, x, y, layer, dPdx, dPdy); 
# 1476
return ret; 
# 1477
} 
#endif
# 68 "/usr/local/cuda-8.0/include/surface_indirect_functions.h"
template< class T> __attribute__((unused)) static void 
# 69
surf1Dread(T *, cudaSurfaceObject_t, int, cudaSurfaceBoundaryMode = cudaBoundaryModeTrap) {int volatile ___ = 1;::exit(___);}
#if 0
# 69
{ } 
#endif
# 111 "/usr/local/cuda-8.0/include/surface_indirect_functions.h"
template< class T> __attribute__((unused)) static T 
# 112
surf1Dread(cudaSurfaceObject_t surfObject, int x, cudaSurfaceBoundaryMode boundaryMode = cudaBoundaryModeTrap) 
# 113
{int volatile ___ = 1;(void)surfObject;(void)x;(void)boundaryMode;
# 119
::exit(___);}
#if 0
# 113
{ 
# 119
} 
#endif
# 128 "/usr/local/cuda-8.0/include/surface_indirect_functions.h"
template< class T> __attribute__((unused)) static void 
# 129
surf2Dread(T *, cudaSurfaceObject_t, int, int, cudaSurfaceBoundaryMode = cudaBoundaryModeTrap) {int volatile ___ = 1;::exit(___);}
#if 0
# 129
{ } 
#endif
# 172 "/usr/local/cuda-8.0/include/surface_indirect_functions.h"
template< class T> __attribute__((unused)) static T 
# 173
surf2Dread(cudaSurfaceObject_t surfObject, int x, int y, cudaSurfaceBoundaryMode boundaryMode = cudaBoundaryModeTrap) 
# 174
{int volatile ___ = 1;(void)surfObject;(void)x;(void)y;(void)boundaryMode;
# 180
::exit(___);}
#if 0
# 174
{ 
# 180
} 
#endif
# 189 "/usr/local/cuda-8.0/include/surface_indirect_functions.h"
template< class T> __attribute__((unused)) static void 
# 190
surf3Dread(T *, cudaSurfaceObject_t, int, int, int, cudaSurfaceBoundaryMode = cudaBoundaryModeTrap) {int volatile ___ = 1;::exit(___);}
#if 0
# 190
{ } 
#endif
# 231 "/usr/local/cuda-8.0/include/surface_indirect_functions.h"
template< class T> __attribute__((unused)) static T 
# 232
surf3Dread(cudaSurfaceObject_t surfObject, int x, int y, int z, cudaSurfaceBoundaryMode boundaryMode = cudaBoundaryModeTrap) 
# 233
{int volatile ___ = 1;(void)surfObject;(void)x;(void)y;(void)z;(void)boundaryMode;
# 239
::exit(___);}
#if 0
# 233
{ 
# 239
} 
#endif
# 247 "/usr/local/cuda-8.0/include/surface_indirect_functions.h"
template< class T> __attribute__((unused)) static void 
# 248
surf1DLayeredread(T *, cudaSurfaceObject_t, int, int, cudaSurfaceBoundaryMode = cudaBoundaryModeTrap) {int volatile ___ = 1;::exit(___);}
#if 0
# 248
{ } 
#endif
# 290 "/usr/local/cuda-8.0/include/surface_indirect_functions.h"
template< class T> __attribute__((unused)) static T 
# 291
surf1DLayeredread(cudaSurfaceObject_t surfObject, int x, int layer, cudaSurfaceBoundaryMode boundaryMode = cudaBoundaryModeTrap) 
# 292
{int volatile ___ = 1;(void)surfObject;(void)x;(void)layer;(void)boundaryMode;
# 298
::exit(___);}
#if 0
# 292
{ 
# 298
} 
#endif
# 306 "/usr/local/cuda-8.0/include/surface_indirect_functions.h"
template< class T> __attribute__((unused)) static void 
# 307
surf2DLayeredread(T *, cudaSurfaceObject_t, int, int, int, cudaSurfaceBoundaryMode = cudaBoundaryModeTrap) {int volatile ___ = 1;::exit(___);}
#if 0
# 307
{ } 
#endif
# 348 "/usr/local/cuda-8.0/include/surface_indirect_functions.h"
template< class T> __attribute__((unused)) static T 
# 349
surf2DLayeredread(cudaSurfaceObject_t surfObject, int x, int y, int layer, cudaSurfaceBoundaryMode boundaryMode = cudaBoundaryModeTrap) 
# 350
{int volatile ___ = 1;(void)surfObject;(void)x;(void)y;(void)layer;(void)boundaryMode;
# 356
::exit(___);}
#if 0
# 350
{ 
# 356
} 
#endif
# 364 "/usr/local/cuda-8.0/include/surface_indirect_functions.h"
template< class T> __attribute__((unused)) static void 
# 365
surfCubemapread(T *, cudaSurfaceObject_t, int, int, int, cudaSurfaceBoundaryMode = cudaBoundaryModeTrap) {int volatile ___ = 1;::exit(___);}
#if 0
# 365
{ } 
#endif
# 406 "/usr/local/cuda-8.0/include/surface_indirect_functions.h"
template< class T> __attribute__((unused)) static T 
# 407
surfCubemapread(cudaSurfaceObject_t surfObject, int x, int y, int face, cudaSurfaceBoundaryMode boundaryMode = cudaBoundaryModeTrap) 
# 408
{int volatile ___ = 1;(void)surfObject;(void)x;(void)y;(void)face;(void)boundaryMode;
# 414
::exit(___);}
#if 0
# 408
{ 
# 414
} 
#endif
# 422 "/usr/local/cuda-8.0/include/surface_indirect_functions.h"
template< class T> __attribute__((unused)) static void 
# 423
surfCubemapLayeredread(T *, cudaSurfaceObject_t, int, int, int, cudaSurfaceBoundaryMode = cudaBoundaryModeTrap) {int volatile ___ = 1;::exit(___);}
#if 0
# 423
{ } 
#endif
# 464 "/usr/local/cuda-8.0/include/surface_indirect_functions.h"
template< class T> __attribute__((unused)) static T 
# 465
surfCubemapLayeredread(cudaSurfaceObject_t surfObject, int x, int y, int layerface, cudaSurfaceBoundaryMode boundaryMode = cudaBoundaryModeTrap) 
# 466
{int volatile ___ = 1;(void)surfObject;(void)x;(void)y;(void)layerface;(void)boundaryMode;
# 472
::exit(___);}
#if 0
# 466
{ 
# 472
} 
#endif
# 480 "/usr/local/cuda-8.0/include/surface_indirect_functions.h"
template< class T> __attribute__((unused)) static void 
# 481
surf1Dwrite(T, cudaSurfaceObject_t, int, cudaSurfaceBoundaryMode = cudaBoundaryModeTrap) {int volatile ___ = 1;::exit(___);}
#if 0
# 481
{ } 
#endif
# 528 "/usr/local/cuda-8.0/include/surface_indirect_functions.h"
template< class T> __attribute__((unused)) static void 
# 529
surf2Dwrite(T, cudaSurfaceObject_t, int, int, cudaSurfaceBoundaryMode = cudaBoundaryModeTrap) {int volatile ___ = 1;::exit(___);}
#if 0
# 529
{ } 
#endif
# 576 "/usr/local/cuda-8.0/include/surface_indirect_functions.h"
template< class T> __attribute__((unused)) static void 
# 577
surf3Dwrite(T, cudaSurfaceObject_t, int, int, int, cudaSurfaceBoundaryMode = cudaBoundaryModeTrap) {int volatile ___ = 1;::exit(___);}
#if 0
# 577
{ } 
#endif
# 626 "/usr/local/cuda-8.0/include/surface_indirect_functions.h"
template< class T> __attribute__((unused)) static void 
# 627
surf1DLayeredwrite(T, cudaSurfaceObject_t, int, int, cudaSurfaceBoundaryMode = cudaBoundaryModeTrap) {int volatile ___ = 1;::exit(___);}
#if 0
# 627
{ } 
#endif
# 675 "/usr/local/cuda-8.0/include/surface_indirect_functions.h"
template< class T> __attribute__((unused)) static void 
# 676
surf2DLayeredwrite(T, cudaSurfaceObject_t, int, int, int, cudaSurfaceBoundaryMode = cudaBoundaryModeTrap) {int volatile ___ = 1;::exit(___);}
#if 0
# 676
{ } 
#endif
# 723 "/usr/local/cuda-8.0/include/surface_indirect_functions.h"
template< class T> __attribute__((unused)) static void 
# 724
surfCubemapwrite(T, cudaSurfaceObject_t, int, int, int, cudaSurfaceBoundaryMode = cudaBoundaryModeTrap) {int volatile ___ = 1;::exit(___);}
#if 0
# 724
{ } 
#endif
# 771 "/usr/local/cuda-8.0/include/surface_indirect_functions.h"
template< class T> __attribute__((unused)) static void 
# 772
surfCubemapLayeredwrite(T, cudaSurfaceObject_t, int, int, int, cudaSurfaceBoundaryMode = cudaBoundaryModeTrap) {int volatile ___ = 1;::exit(___);}
#if 0
# 772
{ } 
#endif
# 68 "/usr/local/cuda-8.0/include/device_launch_parameters.h"
extern "C" {
# 71
extern const uint3 __device_builtin_variable_threadIdx; 
# 72
extern const uint3 __device_builtin_variable_blockIdx; 
# 73
extern const dim3 __device_builtin_variable_blockDim; 
# 74
extern const dim3 __device_builtin_variable_gridDim; 
# 75
extern const int __device_builtin_variable_warpSize; 
# 80
}
# 183 "/usr/local/cuda-8.0/include/cuda_runtime.h"
template< class T> static inline cudaError_t 
# 184
cudaLaunchKernel(const T *
# 185
func, dim3 
# 186
gridDim, dim3 
# 187
blockDim, void **
# 188
args, size_t 
# 189
sharedMem = 0, cudaStream_t 
# 190
stream = 0) 
# 192
{ 
# 193
return ::cudaLaunchKernel((const void *)func, gridDim, blockDim, args, sharedMem, stream); 
# 194
} 
# 221
template< class T> static inline cudaError_t 
# 222
cudaSetupArgument(T 
# 223
arg, size_t 
# 224
offset) 
# 226
{ 
# 227
return ::cudaSetupArgument((const void *)(&arg), sizeof(T), offset); 
# 228
} 
# 260
static inline cudaError_t cudaEventCreate(cudaEvent_t *
# 261
event, unsigned 
# 262
flags) 
# 264
{ 
# 265
return ::cudaEventCreateWithFlags(event, flags); 
# 266
} 
# 323
static inline cudaError_t cudaMallocHost(void **
# 324
ptr, size_t 
# 325
size, unsigned 
# 326
flags) 
# 328
{ 
# 329
return ::cudaHostAlloc(ptr, size, flags); 
# 330
} 
# 332
template< class T> static inline cudaError_t 
# 333
cudaHostAlloc(T **
# 334
ptr, size_t 
# 335
size, unsigned 
# 336
flags) 
# 338
{ 
# 339
return ::cudaHostAlloc((void **)((void *)ptr), size, flags); 
# 340
} 
# 342
template< class T> static inline cudaError_t 
# 343
cudaHostGetDevicePointer(T **
# 344
pDevice, void *
# 345
pHost, unsigned 
# 346
flags) 
# 348
{ 
# 349
return ::cudaHostGetDevicePointer((void **)((void *)pDevice), pHost, flags); 
# 350
} 
# 449
template< class T> static inline cudaError_t 
# 450
cudaMallocManaged(T **
# 451
devPtr, size_t 
# 452
size, unsigned 
# 453
flags = 1) 
# 455
{ 
# 456
return ::cudaMallocManaged((void **)((void *)devPtr), size, flags); 
# 457
} 
# 528
template< class T> static inline cudaError_t 
# 529
cudaStreamAttachMemAsync(cudaStream_t 
# 530
stream, T *
# 531
devPtr, size_t 
# 532
length = 0, unsigned 
# 533
flags = 4) 
# 535
{ 
# 536
return ::cudaStreamAttachMemAsync(stream, (void *)devPtr, length, flags); 
# 537
} 
# 539
template< class T> inline cudaError_t 
# 540
cudaMalloc(T **
# 541
devPtr, size_t 
# 542
size) 
# 544
{ 
# 545
return ::cudaMalloc((void **)((void *)devPtr), size); 
# 546
} 
# 548
template< class T> static inline cudaError_t 
# 549
cudaMallocHost(T **
# 550
ptr, size_t 
# 551
size, unsigned 
# 552
flags = 0) 
# 554
{ 
# 555
return cudaMallocHost((void **)((void *)ptr), size, flags); 
# 556
} 
# 558
template< class T> static inline cudaError_t 
# 559
cudaMallocPitch(T **
# 560
devPtr, size_t *
# 561
pitch, size_t 
# 562
width, size_t 
# 563
height) 
# 565
{ 
# 566
return ::cudaMallocPitch((void **)((void *)devPtr), pitch, width, height); 
# 567
} 
# 604
template< class T> static inline cudaError_t 
# 605
cudaMemcpyToSymbol(const T &
# 606
symbol, const void *
# 607
src, size_t 
# 608
count, size_t 
# 609
offset = 0, cudaMemcpyKind 
# 610
kind = cudaMemcpyHostToDevice) 
# 612
{ 
# 613
return ::cudaMemcpyToSymbol((const void *)(&symbol), src, count, offset, kind); 
# 614
} 
# 656
template< class T> static inline cudaError_t 
# 657
cudaMemcpyToSymbolAsync(const T &
# 658
symbol, const void *
# 659
src, size_t 
# 660
count, size_t 
# 661
offset = 0, cudaMemcpyKind 
# 662
kind = cudaMemcpyHostToDevice, cudaStream_t 
# 663
stream = 0) 
# 665
{ 
# 666
return ::cudaMemcpyToSymbolAsync((const void *)(&symbol), src, count, offset, kind, stream); 
# 667
} 
# 702
template< class T> static inline cudaError_t 
# 703
cudaMemcpyFromSymbol(void *
# 704
dst, const T &
# 705
symbol, size_t 
# 706
count, size_t 
# 707
offset = 0, cudaMemcpyKind 
# 708
kind = cudaMemcpyDeviceToHost) 
# 710
{ 
# 711
return ::cudaMemcpyFromSymbol(dst, (const void *)(&symbol), count, offset, kind); 
# 712
} 
# 754
template< class T> static inline cudaError_t 
# 755
cudaMemcpyFromSymbolAsync(void *
# 756
dst, const T &
# 757
symbol, size_t 
# 758
count, size_t 
# 759
offset = 0, cudaMemcpyKind 
# 760
kind = cudaMemcpyDeviceToHost, cudaStream_t 
# 761
stream = 0) 
# 763
{ 
# 764
return ::cudaMemcpyFromSymbolAsync(dst, (const void *)(&symbol), count, offset, kind, stream); 
# 765
} 
# 787
template< class T> static inline cudaError_t 
# 788
cudaGetSymbolAddress(void **
# 789
devPtr, const T &
# 790
symbol) 
# 792
{ 
# 793
return ::cudaGetSymbolAddress(devPtr, (const void *)(&symbol)); 
# 794
} 
# 816
template< class T> static inline cudaError_t 
# 817
cudaGetSymbolSize(size_t *
# 818
size, const T &
# 819
symbol) 
# 821
{ 
# 822
return ::cudaGetSymbolSize(size, (const void *)(&symbol)); 
# 823
} 
# 859
template< class T, int dim, cudaTextureReadMode readMode> static inline cudaError_t 
# 860
cudaBindTexture(size_t *
# 861
offset, const texture< T, dim, readMode>  &
# 862
tex, const void *
# 863
devPtr, const cudaChannelFormatDesc &
# 864
desc, size_t 
# 865
size = ((2147483647) * 2U) + 1U) 
# 867
{ 
# 868
return ::cudaBindTexture(offset, &tex, devPtr, &desc, size); 
# 869
} 
# 904
template< class T, int dim, cudaTextureReadMode readMode> static inline cudaError_t 
# 905
cudaBindTexture(size_t *
# 906
offset, const texture< T, dim, readMode>  &
# 907
tex, const void *
# 908
devPtr, size_t 
# 909
size = ((2147483647) * 2U) + 1U) 
# 911
{ 
# 912
return cudaBindTexture(offset, tex, devPtr, (tex.channelDesc), size); 
# 913
} 
# 960
template< class T, int dim, cudaTextureReadMode readMode> static inline cudaError_t 
# 961
cudaBindTexture2D(size_t *
# 962
offset, const texture< T, dim, readMode>  &
# 963
tex, const void *
# 964
devPtr, const cudaChannelFormatDesc &
# 965
desc, size_t 
# 966
width, size_t 
# 967
height, size_t 
# 968
pitch) 
# 970
{ 
# 971
return ::cudaBindTexture2D(offset, &tex, devPtr, &desc, width, height, pitch); 
# 972
} 
# 1018
template< class T, int dim, cudaTextureReadMode readMode> static inline cudaError_t 
# 1019
cudaBindTexture2D(size_t *
# 1020
offset, const texture< T, dim, readMode>  &
# 1021
tex, const void *
# 1022
devPtr, size_t 
# 1023
width, size_t 
# 1024
height, size_t 
# 1025
pitch) 
# 1027
{ 
# 1028
return ::cudaBindTexture2D(offset, &tex, devPtr, &(tex.channelDesc), width, height, pitch); 
# 1029
} 
# 1060
template< class T, int dim, cudaTextureReadMode readMode> static inline cudaError_t 
# 1061
cudaBindTextureToArray(const texture< T, dim, readMode>  &
# 1062
tex, cudaArray_const_t 
# 1063
array, const cudaChannelFormatDesc &
# 1064
desc) 
# 1066
{ 
# 1067
return ::cudaBindTextureToArray(&tex, array, &desc); 
# 1068
} 
# 1098
template< class T, int dim, cudaTextureReadMode readMode> static inline cudaError_t 
# 1099
cudaBindTextureToArray(const texture< T, dim, readMode>  &
# 1100
tex, cudaArray_const_t 
# 1101
array) 
# 1103
{ 
# 1104
cudaChannelFormatDesc desc; 
# 1105
cudaError_t err = ::cudaGetChannelDesc(&desc, array); 
# 1107
return (err == (cudaSuccess)) ? cudaBindTextureToArray(tex, array, desc) : err; 
# 1108
} 
# 1139
template< class T, int dim, cudaTextureReadMode readMode> static inline cudaError_t 
# 1140
cudaBindTextureToMipmappedArray(const texture< T, dim, readMode>  &
# 1141
tex, cudaMipmappedArray_const_t 
# 1142
mipmappedArray, const cudaChannelFormatDesc &
# 1143
desc) 
# 1145
{ 
# 1146
return ::cudaBindTextureToMipmappedArray(&tex, mipmappedArray, &desc); 
# 1147
} 
# 1177
template< class T, int dim, cudaTextureReadMode readMode> static inline cudaError_t 
# 1178
cudaBindTextureToMipmappedArray(const texture< T, dim, readMode>  &
# 1179
tex, cudaMipmappedArray_const_t 
# 1180
mipmappedArray) 
# 1182
{ 
# 1183
cudaChannelFormatDesc desc; 
# 1184
cudaArray_t levelArray; 
# 1185
cudaError_t err = ::cudaGetMipmappedArrayLevel(&levelArray, mipmappedArray, 0); 
# 1187
if (err != (cudaSuccess)) { 
# 1188
return err; 
# 1189
}  
# 1190
err = ::cudaGetChannelDesc(&desc, levelArray); 
# 1192
return (err == (cudaSuccess)) ? cudaBindTextureToMipmappedArray(tex, mipmappedArray, desc) : err; 
# 1193
} 
# 1216
template< class T, int dim, cudaTextureReadMode readMode> static inline cudaError_t 
# 1217
cudaUnbindTexture(const texture< T, dim, readMode>  &
# 1218
tex) 
# 1220
{ 
# 1221
return ::cudaUnbindTexture(&tex); 
# 1222
} 
# 1250
template< class T, int dim, cudaTextureReadMode readMode> static inline cudaError_t 
# 1251
cudaGetTextureAlignmentOffset(size_t *
# 1252
offset, const texture< T, dim, readMode>  &
# 1253
tex) 
# 1255
{ 
# 1256
return ::cudaGetTextureAlignmentOffset(offset, &tex); 
# 1257
} 
# 1302
template< class T> static inline cudaError_t 
# 1303
cudaFuncSetCacheConfig(T *
# 1304
func, cudaFuncCache 
# 1305
cacheConfig) 
# 1307
{ 
# 1308
return ::cudaFuncSetCacheConfig((const void *)func, cacheConfig); 
# 1309
} 
# 1311
template< class T> static inline cudaError_t 
# 1312
cudaFuncSetSharedMemConfig(T *
# 1313
func, cudaSharedMemConfig 
# 1314
config) 
# 1316
{ 
# 1317
return ::cudaFuncSetSharedMemConfig((const void *)func, config); 
# 1318
} 
# 1347
template< class T> inline cudaError_t 
# 1348
cudaOccupancyMaxActiveBlocksPerMultiprocessor(int *
# 1349
numBlocks, T 
# 1350
func, int 
# 1351
blockSize, size_t 
# 1352
dynamicSMemSize) 
# 1353
{ 
# 1354
return ::cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags(numBlocks, (const void *)func, blockSize, dynamicSMemSize, 0); 
# 1355
} 
# 1398
template< class T> inline cudaError_t 
# 1399
cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags(int *
# 1400
numBlocks, T 
# 1401
func, int 
# 1402
blockSize, size_t 
# 1403
dynamicSMemSize, unsigned 
# 1404
flags) 
# 1405
{ 
# 1406
return ::cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags(numBlocks, (const void *)func, blockSize, dynamicSMemSize, flags); 
# 1407
} 
# 1412
class __cudaOccupancyB2DHelper { 
# 1413
size_t n; 
# 1415
public: __cudaOccupancyB2DHelper(size_t n_) : n(n_) { } 
# 1416
size_t operator()(int) 
# 1417
{ 
# 1418
return n; 
# 1419
} 
# 1420
}; 
# 1467
template< class UnaryFunction, class T> static inline cudaError_t 
# 1468
cudaOccupancyMaxPotentialBlockSizeVariableSMemWithFlags(int *
# 1469
minGridSize, int *
# 1470
blockSize, T 
# 1471
func, UnaryFunction 
# 1472
blockSizeToDynamicSMemSize, int 
# 1473
blockSizeLimit = 0, unsigned 
# 1474
flags = 0) 
# 1475
{ 
# 1476
cudaError_t status; 
# 1479
int device; 
# 1480
cudaFuncAttributes attr; 
# 1483
int maxThreadsPerMultiProcessor; 
# 1484
int warpSize; 
# 1485
int devMaxThreadsPerBlock; 
# 1486
int multiProcessorCount; 
# 1487
int funcMaxThreadsPerBlock; 
# 1488
int occupancyLimit; 
# 1489
int granularity; 
# 1492
int maxBlockSize = 0; 
# 1493
int numBlocks = 0; 
# 1494
int maxOccupancy = 0; 
# 1497
int blockSizeToTryAligned; 
# 1498
int blockSizeToTry; 
# 1499
int blockSizeLimitAligned; 
# 1500
int occupancyInBlocks; 
# 1501
int occupancyInThreads; 
# 1502
size_t dynamicSMemSize; 
# 1508
if (((!minGridSize) || (!blockSize)) || (!func)) { 
# 1509
return cudaErrorInvalidValue; 
# 1510
}  
# 1516
status = ::cudaGetDevice(&device); 
# 1517
if (status != (cudaSuccess)) { 
# 1518
return status; 
# 1519
}  
# 1521
status = cudaDeviceGetAttribute(&maxThreadsPerMultiProcessor, cudaDevAttrMaxThreadsPerMultiProcessor, device); 
# 1525
if (status != (cudaSuccess)) { 
# 1526
return status; 
# 1527
}  
# 1529
status = cudaDeviceGetAttribute(&warpSize, cudaDevAttrWarpSize, device); 
# 1533
if (status != (cudaSuccess)) { 
# 1534
return status; 
# 1535
}  
# 1537
status = cudaDeviceGetAttribute(&devMaxThreadsPerBlock, cudaDevAttrMaxThreadsPerBlock, device); 
# 1541
if (status != (cudaSuccess)) { 
# 1542
return status; 
# 1543
}  
# 1545
status = cudaDeviceGetAttribute(&multiProcessorCount, cudaDevAttrMultiProcessorCount, device); 
# 1549
if (status != (cudaSuccess)) { 
# 1550
return status; 
# 1551
}  
# 1553
status = cudaFuncGetAttributes(&attr, func); 
# 1554
if (status != (cudaSuccess)) { 
# 1555
return status; 
# 1556
}  
# 1558
funcMaxThreadsPerBlock = (attr.maxThreadsPerBlock); 
# 1564
occupancyLimit = maxThreadsPerMultiProcessor; 
# 1565
granularity = warpSize; 
# 1567
if (blockSizeLimit == 0) { 
# 1568
blockSizeLimit = devMaxThreadsPerBlock; 
# 1569
}  
# 1571
if (devMaxThreadsPerBlock < blockSizeLimit) { 
# 1572
blockSizeLimit = devMaxThreadsPerBlock; 
# 1573
}  
# 1575
if (funcMaxThreadsPerBlock < blockSizeLimit) { 
# 1576
blockSizeLimit = funcMaxThreadsPerBlock; 
# 1577
}  
# 1579
blockSizeLimitAligned = (((blockSizeLimit + (granularity - 1)) / granularity) * granularity); 
# 1581
for (blockSizeToTryAligned = blockSizeLimitAligned; blockSizeToTryAligned > 0; blockSizeToTryAligned -= granularity) { 
# 1585
if (blockSizeLimit < blockSizeToTryAligned) { 
# 1586
blockSizeToTry = blockSizeLimit; 
# 1587
} else { 
# 1588
blockSizeToTry = blockSizeToTryAligned; 
# 1589
}  
# 1591
dynamicSMemSize = blockSizeToDynamicSMemSize(blockSizeToTry); 
# 1593
status = cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags(&occupancyInBlocks, func, blockSizeToTry, dynamicSMemSize, flags); 
# 1600
if (status != (cudaSuccess)) { 
# 1601
return status; 
# 1602
}  
# 1604
occupancyInThreads = (blockSizeToTry * occupancyInBlocks); 
# 1606
if (occupancyInThreads > maxOccupancy) { 
# 1607
maxBlockSize = blockSizeToTry; 
# 1608
numBlocks = occupancyInBlocks; 
# 1609
maxOccupancy = occupancyInThreads; 
# 1610
}  
# 1614
if (occupancyLimit == maxOccupancy) { 
# 1615
break; 
# 1616
}  
# 1617
}  
# 1625
(*minGridSize) = (numBlocks * multiProcessorCount); 
# 1626
(*blockSize) = maxBlockSize; 
# 1628
return status; 
# 1629
} 
# 1662
template< class UnaryFunction, class T> static inline cudaError_t 
# 1663
cudaOccupancyMaxPotentialBlockSizeVariableSMem(int *
# 1664
minGridSize, int *
# 1665
blockSize, T 
# 1666
func, UnaryFunction 
# 1667
blockSizeToDynamicSMemSize, int 
# 1668
blockSizeLimit = 0) 
# 1669
{ 
# 1670
return cudaOccupancyMaxPotentialBlockSizeVariableSMemWithFlags(minGridSize, blockSize, func, blockSizeToDynamicSMemSize, blockSizeLimit, 0); 
# 1671
} 
# 1707
template< class T> static inline cudaError_t 
# 1708
cudaOccupancyMaxPotentialBlockSize(int *
# 1709
minGridSize, int *
# 1710
blockSize, T 
# 1711
func, size_t 
# 1712
dynamicSMemSize = 0, int 
# 1713
blockSizeLimit = 0) 
# 1714
{ 
# 1715
return cudaOccupancyMaxPotentialBlockSizeVariableSMemWithFlags(minGridSize, blockSize, func, ((__cudaOccupancyB2DHelper)(dynamicSMemSize)), blockSizeLimit, 0); 
# 1716
} 
# 1766
template< class T> static inline cudaError_t 
# 1767
cudaOccupancyMaxPotentialBlockSizeWithFlags(int *
# 1768
minGridSize, int *
# 1769
blockSize, T 
# 1770
func, size_t 
# 1771
dynamicSMemSize = 0, int 
# 1772
blockSizeLimit = 0, unsigned 
# 1773
flags = 0) 
# 1774
{ 
# 1775
return cudaOccupancyMaxPotentialBlockSizeVariableSMemWithFlags(minGridSize, blockSize, func, ((__cudaOccupancyB2DHelper)(dynamicSMemSize)), blockSizeLimit, flags); 
# 1776
} 
# 1814
template< class T> static inline cudaError_t 
# 1815
cudaLaunch(T *
# 1816
func) 
# 1818
{ 
# 1819
return ::cudaLaunch((const void *)func); 
# 1820
} 
# 1851
template< class T> inline cudaError_t 
# 1852
cudaFuncGetAttributes(cudaFuncAttributes *
# 1853
attr, T *
# 1854
entry) 
# 1856
{ 
# 1857
return ::cudaFuncGetAttributes(attr, (const void *)entry); 
# 1858
} 
# 1880
template< class T, int dim> static inline cudaError_t 
# 1881
cudaBindSurfaceToArray(const surface< T, dim>  &
# 1882
surf, cudaArray_const_t 
# 1883
array, const cudaChannelFormatDesc &
# 1884
desc) 
# 1886
{ 
# 1887
return ::cudaBindSurfaceToArray(&surf, array, &desc); 
# 1888
} 
# 1909
template< class T, int dim> static inline cudaError_t 
# 1910
cudaBindSurfaceToArray(const surface< T, dim>  &
# 1911
surf, cudaArray_const_t 
# 1912
array) 
# 1914
{ 
# 1915
cudaChannelFormatDesc desc; 
# 1916
cudaError_t err = ::cudaGetChannelDesc(&desc, array); 
# 1918
return (err == (cudaSuccess)) ? cudaBindSurfaceToArray(surf, array, desc) : err; 
# 1919
} 
# 1930
#pragma GCC diagnostic pop
# 29 "/usr/include/stdio.h" 3
extern "C" {
# 44
struct _IO_FILE; 
# 48
typedef _IO_FILE FILE; 
# 64
typedef _IO_FILE __FILE; 
# 94 "/usr/include/wchar.h" 3
typedef 
# 83
struct { 
# 84
int __count; 
# 86
union { 
# 88
unsigned __wch; 
# 92
char __wchb[4]; 
# 93
} __value; 
# 94
} __mbstate_t; 
# 25 "/usr/include/_G_config.h" 3
typedef 
# 22
struct { 
# 23
__off_t __pos; 
# 24
__mbstate_t __state; 
# 25
} _G_fpos_t; 
# 30
typedef 
# 27
struct { 
# 28
__off64_t __pos; 
# 29
__mbstate_t __state; 
# 30
} _G_fpos64_t; 
# 40 "/usr/lib/gcc/ppc64le-redhat-linux/4.8.5/include/stdarg.h" 3
typedef __builtin_va_list __gnuc_va_list; 
# 145 "/usr/include/libio.h" 3
struct _IO_jump_t; struct _IO_FILE; 
# 155
typedef void _IO_lock_t; 
# 161
struct _IO_marker { 
# 162
_IO_marker *_next; 
# 163
_IO_FILE *_sbuf; 
# 167
int _pos; 
# 178
}; 
# 181
enum __codecvt_result { 
# 183
__codecvt_ok, 
# 184
__codecvt_partial, 
# 185
__codecvt_error, 
# 186
__codecvt_noconv
# 187
}; 
# 246
struct _IO_FILE { 
# 247
int _flags; 
# 252
char *_IO_read_ptr; 
# 253
char *_IO_read_end; 
# 254
char *_IO_read_base; 
# 255
char *_IO_write_base; 
# 256
char *_IO_write_ptr; 
# 257
char *_IO_write_end; 
# 258
char *_IO_buf_base; 
# 259
char *_IO_buf_end; 
# 261
char *_IO_save_base; 
# 262
char *_IO_backup_base; 
# 263
char *_IO_save_end; 
# 265
_IO_marker *_markers; 
# 267
_IO_FILE *_chain; 
# 269
int _fileno; 
# 273
int _flags2; 
# 275
__off_t _old_offset; 
# 279
unsigned short _cur_column; 
# 280
signed char _vtable_offset; 
# 281
char _shortbuf[1]; 
# 285
_IO_lock_t *_lock; 
# 294
__off64_t _offset; 
# 303
void *__pad1; 
# 304
void *__pad2; 
# 305
void *__pad3; 
# 306
void *__pad4; 
# 307
size_t __pad5; 
# 309
int _mode; 
# 311
char _unused2[(((15) * sizeof(int)) - ((4) * sizeof(void *))) - sizeof(size_t)]; 
# 313
}; 
# 319
struct _IO_FILE_plus; 
# 321
extern _IO_FILE_plus _IO_2_1_stdin_; 
# 322
extern _IO_FILE_plus _IO_2_1_stdout_; 
# 323
extern _IO_FILE_plus _IO_2_1_stderr_; 
# 339
typedef __ssize_t __io_read_fn(void * __cookie, char * __buf, size_t __nbytes); 
# 347
typedef __ssize_t __io_write_fn(void * __cookie, const char * __buf, size_t __n); 
# 356
typedef int __io_seek_fn(void * __cookie, __off64_t * __pos, int __w); 
# 359
typedef int __io_close_fn(void * __cookie); 
# 364
typedef __io_read_fn cookie_read_function_t; 
# 365
typedef __io_write_fn cookie_write_function_t; 
# 366
typedef __io_seek_fn cookie_seek_function_t; 
# 367
typedef __io_close_fn cookie_close_function_t; 
# 376
typedef 
# 371
struct { 
# 372
__io_read_fn *read; 
# 373
__io_write_fn *write; 
# 374
__io_seek_fn *seek; 
# 375
__io_close_fn *close; 
# 376
} _IO_cookie_io_functions_t; 
# 377
typedef _IO_cookie_io_functions_t cookie_io_functions_t; 
# 379
struct _IO_cookie_file; 
# 382
extern void _IO_cookie_init(_IO_cookie_file * __cfile, int __read_write, void * __cookie, _IO_cookie_io_functions_t __fns); 
# 388
extern "C" {
# 391
extern int __underflow(_IO_FILE *); 
# 392
extern int __uflow(_IO_FILE *); 
# 393
extern int __overflow(_IO_FILE *, int); 
# 435
extern int _IO_getc(_IO_FILE * __fp); 
# 436
extern int _IO_putc(int __c, _IO_FILE * __fp); 
# 437
extern int _IO_feof(_IO_FILE * __fp) throw(); 
# 438
extern int _IO_ferror(_IO_FILE * __fp) throw(); 
# 440
extern int _IO_peekc_locked(_IO_FILE * __fp); 
# 446
extern void _IO_flockfile(_IO_FILE *) throw(); 
# 447
extern void _IO_funlockfile(_IO_FILE *) throw(); 
# 448
extern int _IO_ftrylockfile(_IO_FILE *) throw(); 
# 465
extern int _IO_vfscanf(_IO_FILE *__restrict__, const char *__restrict__, __gnuc_va_list, int *__restrict__); 
# 467
extern int _IO_vfprintf(_IO_FILE *__restrict__, const char *__restrict__, __gnuc_va_list); 
# 469
extern __ssize_t _IO_padn(_IO_FILE *, int, __ssize_t); 
# 470
extern size_t _IO_sgetn(_IO_FILE *, void *, size_t); 
# 472
extern __off64_t _IO_seekoff(_IO_FILE *, __off64_t, int, int); 
# 473
extern __off64_t _IO_seekpos(_IO_FILE *, __off64_t, int); 
# 475
extern void _IO_free_backup_area(_IO_FILE *) throw(); 
# 527
}
# 79 "/usr/include/stdio.h" 3
typedef __gnuc_va_list va_list; 
# 110
typedef _G_fpos_t fpos_t; 
# 116
typedef _G_fpos64_t fpos64_t; 
# 168
extern _IO_FILE *stdin; 
# 169
extern _IO_FILE *stdout; 
# 170
extern _IO_FILE *stderr; 
# 178
extern int remove(const char * __filename) throw(); 
# 180
extern int rename(const char * __old, const char * __new) throw(); 
# 185
extern int renameat(int __oldfd, const char * __old, int __newfd, const char * __new) throw(); 
# 195
extern FILE *tmpfile(); 
# 205
extern FILE *tmpfile64(); 
# 209
extern char *tmpnam(char * __s) throw(); 
# 215
extern char *tmpnam_r(char * __s) throw(); 
# 227
extern char *tempnam(const char * __dir, const char * __pfx) throw()
# 228
 __attribute((__malloc__)); 
# 237
extern int fclose(FILE * __stream); 
# 242
extern int fflush(FILE * __stream); 
# 252
extern int fflush_unlocked(FILE * __stream); 
# 262
extern int fcloseall(); 
# 272
extern FILE *fopen(const char *__restrict__ __filename, const char *__restrict__ __modes); 
# 278
extern FILE *freopen(const char *__restrict__ __filename, const char *__restrict__ __modes, FILE *__restrict__ __stream); 
# 297
extern FILE *fopen64(const char *__restrict__ __filename, const char *__restrict__ __modes); 
# 299
extern FILE *freopen64(const char *__restrict__ __filename, const char *__restrict__ __modes, FILE *__restrict__ __stream); 
# 306
extern FILE *fdopen(int __fd, const char * __modes) throw(); 
# 312
extern FILE *fopencookie(void *__restrict__ __magic_cookie, const char *__restrict__ __modes, _IO_cookie_io_functions_t __io_funcs) throw(); 
# 319
extern FILE *fmemopen(void * __s, size_t __len, const char * __modes) throw(); 
# 325
extern FILE *open_memstream(char ** __bufloc, size_t * __sizeloc) throw(); 
# 332
extern void setbuf(FILE *__restrict__ __stream, char *__restrict__ __buf) throw(); 
# 336
extern int setvbuf(FILE *__restrict__ __stream, char *__restrict__ __buf, int __modes, size_t __n) throw(); 
# 343
extern void setbuffer(FILE *__restrict__ __stream, char *__restrict__ __buf, size_t __size) throw(); 
# 347
extern void setlinebuf(FILE * __stream) throw(); 
# 356
extern int fprintf(FILE *__restrict__ __stream, const char *__restrict__ __format, ...); 
# 362
extern int printf(const char *__restrict__ __format, ...); 
# 364
extern int sprintf(char *__restrict__ __s, const char *__restrict__ __format, ...) throw(); 
# 371
extern int vfprintf(FILE *__restrict__ __s, const char *__restrict__ __format, __gnuc_va_list __arg); 
# 377
extern __attribute((gnu_inline)) inline int vprintf(const char *__restrict__ __format, __gnuc_va_list __arg); 
# 379
extern int vsprintf(char *__restrict__ __s, const char *__restrict__ __format, __gnuc_va_list __arg) throw(); 
# 386
extern int snprintf(char *__restrict__ __s, size_t __maxlen, const char *__restrict__ __format, ...) throw()
# 388
 __attribute((__format__(__printf__, 3, 4))); 
# 390
extern int vsnprintf(char *__restrict__ __s, size_t __maxlen, const char *__restrict__ __format, __gnuc_va_list __arg) throw()
# 392
 __attribute((__format__(__printf__, 3, 0))); 
# 399
extern int vasprintf(char **__restrict__ __ptr, const char *__restrict__ __f, __gnuc_va_list __arg) throw()
# 401
 __attribute((__format__(__printf__, 2, 0))); 
# 402
extern int __asprintf(char **__restrict__ __ptr, const char *__restrict__ __fmt, ...) throw()
# 404
 __attribute((__format__(__printf__, 2, 3))); 
# 405
extern int asprintf(char **__restrict__ __ptr, const char *__restrict__ __fmt, ...) throw()
# 407
 __attribute((__format__(__printf__, 2, 3))); 
# 412
extern int vdprintf(int __fd, const char *__restrict__ __fmt, __gnuc_va_list __arg)
# 414
 __attribute((__format__(__printf__, 2, 0))); 
# 415
extern int dprintf(int __fd, const char *__restrict__ __fmt, ...)
# 416
 __attribute((__format__(__printf__, 2, 3))); 
# 425
extern int fscanf(FILE *__restrict__ __stream, const char *__restrict__ __format, ...); 
# 431
extern int scanf(const char *__restrict__ __format, ...); 
# 433
extern int sscanf(const char *__restrict__ __s, const char *__restrict__ __format, ...) throw(); 
# 471
extern int vfscanf(FILE *__restrict__ __s, const char *__restrict__ __format, __gnuc_va_list __arg)
# 473
 __attribute((__format__(__scanf__, 2, 0))); 
# 479
extern int vscanf(const char *__restrict__ __format, __gnuc_va_list __arg)
# 480
 __attribute((__format__(__scanf__, 1, 0))); 
# 483
extern int vsscanf(const char *__restrict__ __s, const char *__restrict__ __format, __gnuc_va_list __arg) throw()
# 485
 __attribute((__format__(__scanf__, 2, 0))); 
# 531
extern int fgetc(FILE * __stream); 
# 532
extern int getc(FILE * __stream); 
# 538
extern __attribute((gnu_inline)) inline int getchar(); 
# 550
extern __attribute((gnu_inline)) inline int getc_unlocked(FILE * __stream); 
# 551
extern __attribute((gnu_inline)) inline int getchar_unlocked(); 
# 561
extern __attribute((gnu_inline)) inline int fgetc_unlocked(FILE * __stream); 
# 573
extern int fputc(int __c, FILE * __stream); 
# 574
extern int putc(int __c, FILE * __stream); 
# 580
extern __attribute((gnu_inline)) inline int putchar(int __c); 
# 594
extern __attribute((gnu_inline)) inline int fputc_unlocked(int __c, FILE * __stream); 
# 602
extern __attribute((gnu_inline)) inline int putc_unlocked(int __c, FILE * __stream); 
# 603
extern __attribute((gnu_inline)) inline int putchar_unlocked(int __c); 
# 610
extern int getw(FILE * __stream); 
# 613
extern int putw(int __w, FILE * __stream); 
# 622
extern char *fgets(char *__restrict__ __s, int __n, FILE *__restrict__ __stream); 
# 638
extern char *gets(char * __s) __attribute((__deprecated__)); 
# 649
extern char *fgets_unlocked(char *__restrict__ __s, int __n, FILE *__restrict__ __stream); 
# 665
extern __ssize_t __getdelim(char **__restrict__ __lineptr, size_t *__restrict__ __n, int __delimiter, FILE *__restrict__ __stream); 
# 668
extern __ssize_t getdelim(char **__restrict__ __lineptr, size_t *__restrict__ __n, int __delimiter, FILE *__restrict__ __stream); 
# 678
extern __attribute((gnu_inline)) inline __ssize_t getline(char **__restrict__ __lineptr, size_t *__restrict__ __n, FILE *__restrict__ __stream); 
# 689
extern int fputs(const char *__restrict__ __s, FILE *__restrict__ __stream); 
# 695
extern int puts(const char * __s); 
# 702
extern int ungetc(int __c, FILE * __stream); 
# 709
extern size_t fread(void *__restrict__ __ptr, size_t __size, size_t __n, FILE *__restrict__ __stream); 
# 715
extern size_t fwrite(const void *__restrict__ __ptr, size_t __size, size_t __n, FILE *__restrict__ __s); 
# 726
extern int fputs_unlocked(const char *__restrict__ __s, FILE *__restrict__ __stream); 
# 737
extern size_t fread_unlocked(void *__restrict__ __ptr, size_t __size, size_t __n, FILE *__restrict__ __stream); 
# 739
extern size_t fwrite_unlocked(const void *__restrict__ __ptr, size_t __size, size_t __n, FILE *__restrict__ __stream); 
# 749
extern int fseek(FILE * __stream, long __off, int __whence); 
# 754
extern long ftell(FILE * __stream); 
# 759
extern void rewind(FILE * __stream); 
# 773
extern int fseeko(FILE * __stream, __off_t __off, int __whence); 
# 778
extern __off_t ftello(FILE * __stream); 
# 798
extern int fgetpos(FILE *__restrict__ __stream, fpos_t *__restrict__ __pos); 
# 803
extern int fsetpos(FILE * __stream, const fpos_t * __pos); 
# 818
extern int fseeko64(FILE * __stream, __off64_t __off, int __whence); 
# 819
extern __off64_t ftello64(FILE * __stream); 
# 820
extern int fgetpos64(FILE *__restrict__ __stream, fpos64_t *__restrict__ __pos); 
# 821
extern int fsetpos64(FILE * __stream, const fpos64_t * __pos); 
# 826
extern void clearerr(FILE * __stream) throw(); 
# 828
extern int feof(FILE * __stream) throw(); 
# 830
extern int ferror(FILE * __stream) throw(); 
# 835
extern void clearerr_unlocked(FILE * __stream) throw(); 
# 836
extern __attribute((gnu_inline)) inline int feof_unlocked(FILE * __stream) throw(); 
# 837
extern __attribute((gnu_inline)) inline int ferror_unlocked(FILE * __stream) throw(); 
# 846
extern void perror(const char * __s); 
# 26 "/usr/include/bits/sys_errlist.h" 3
extern int sys_nerr; 
# 27
extern const char *const sys_errlist[]; 
# 30
extern int _sys_nerr; 
# 31
extern const char *const _sys_errlist[]; 
# 858 "/usr/include/stdio.h" 3
extern int fileno(FILE * __stream) throw(); 
# 863
extern int fileno_unlocked(FILE * __stream) throw(); 
# 873
extern FILE *popen(const char * __command, const char * __modes); 
# 879
extern int pclose(FILE * __stream); 
# 885
extern char *ctermid(char * __s) throw(); 
# 891
extern char *cuserid(char * __s); 
# 896
struct obstack; 
# 899
extern int obstack_printf(obstack *__restrict__ __obstack, const char *__restrict__ __format, ...) throw()
# 901
 __attribute((__format__(__printf__, 2, 3))); 
# 902
extern int obstack_vprintf(obstack *__restrict__ __obstack, const char *__restrict__ __format, __gnuc_va_list __args) throw()
# 905
 __attribute((__format__(__printf__, 2, 0))); 
# 913
extern void flockfile(FILE * __stream) throw(); 
# 917
extern int ftrylockfile(FILE * __stream) throw(); 
# 920
extern void funlockfile(FILE * __stream) throw(); 
# 35 "/usr/include/bits/stdio.h" 3
__attribute((__gnu_inline__)) extern inline int 
# 36
vprintf(const char *__restrict__ __fmt, __gnuc_va_list __arg) 
# 37
{ 
# 38
return vfprintf(stdout, __fmt, __arg); 
# 39
} 
# 43
__attribute((__gnu_inline__)) extern inline int 
# 44
getchar() 
# 45
{ 
# 46
return _IO_getc(stdin); 
# 47
} 
# 52
__attribute((__gnu_inline__)) extern inline int 
# 53
fgetc_unlocked(FILE *__fp) 
# 54
{ 
# 55
return (__builtin_expect((__fp->_IO_read_ptr) >= (__fp->_IO_read_end), 0)) ? __uflow(__fp) : (*((unsigned char *)((__fp->_IO_read_ptr)++))); 
# 56
} 
# 62
__attribute((__gnu_inline__)) extern inline int 
# 63
getc_unlocked(FILE *__fp) 
# 64
{ 
# 65
return (__builtin_expect((__fp->_IO_read_ptr) >= (__fp->_IO_read_end), 0)) ? __uflow(__fp) : (*((unsigned char *)((__fp->_IO_read_ptr)++))); 
# 66
} 
# 69
__attribute((__gnu_inline__)) extern inline int 
# 70
getchar_unlocked() 
# 71
{ 
# 72
return (__builtin_expect((stdin->_IO_read_ptr) >= (stdin->_IO_read_end), 0)) ? __uflow(stdin) : (*((unsigned char *)((stdin->_IO_read_ptr)++))); 
# 73
} 
# 78
__attribute((__gnu_inline__)) extern inline int 
# 79
putchar(int __c) 
# 80
{ 
# 81
return _IO_putc(__c, stdout); 
# 82
} 
# 87
__attribute((__gnu_inline__)) extern inline int 
# 88
fputc_unlocked(int __c, FILE *__stream) 
# 89
{ 
# 90
return (__builtin_expect((__stream->_IO_write_ptr) >= (__stream->_IO_write_end), 0)) ? __overflow(__stream, (unsigned char)__c) : ((unsigned char)((*((__stream->_IO_write_ptr)++)) = __c)); 
# 91
} 
# 97
__attribute((__gnu_inline__)) extern inline int 
# 98
putc_unlocked(int __c, FILE *__stream) 
# 99
{ 
# 100
return (__builtin_expect((__stream->_IO_write_ptr) >= (__stream->_IO_write_end), 0)) ? __overflow(__stream, (unsigned char)__c) : ((unsigned char)((*((__stream->_IO_write_ptr)++)) = __c)); 
# 101
} 
# 104
__attribute((__gnu_inline__)) extern inline int 
# 105
putchar_unlocked(int __c) 
# 106
{ 
# 107
return (__builtin_expect((stdout->_IO_write_ptr) >= (stdout->_IO_write_end), 0)) ? __overflow(stdout, (unsigned char)__c) : ((unsigned char)((*((stdout->_IO_write_ptr)++)) = __c)); 
# 108
} 
# 114
__attribute((__gnu_inline__)) extern inline __ssize_t 
# 115
getline(char **__lineptr, size_t *__n, FILE *__stream) 
# 116
{ 
# 117
return __getdelim(__lineptr, __n, '\n', __stream); 
# 118
} 
# 124
__attribute((__gnu_inline__)) extern inline int
# 125
 __attribute((__leaf__)) feof_unlocked(FILE *__stream) throw() 
# 126
{ 
# 127
return ((__stream->_flags) & 16) != 0; 
# 128
} 
# 131
__attribute((__gnu_inline__)) extern inline int
# 132
 __attribute((__leaf__)) ferror_unlocked(FILE *__stream) throw() 
# 133
{ 
# 134
return ((__stream->_flags) & 32) != 0; 
# 135
} 
# 943 "/usr/include/stdio.h" 3
}
# 48 "/usr/include/stdint.h" 3
typedef unsigned char uint8_t; 
# 49
typedef unsigned short uint16_t; 
# 51
typedef unsigned uint32_t; 
# 55
typedef unsigned long uint64_t; 
# 65
typedef signed char int_least8_t; 
# 66
typedef short int_least16_t; 
# 67
typedef int int_least32_t; 
# 69
typedef long int_least64_t; 
# 76
typedef unsigned char uint_least8_t; 
# 77
typedef unsigned short uint_least16_t; 
# 78
typedef unsigned uint_least32_t; 
# 80
typedef unsigned long uint_least64_t; 
# 90
typedef signed char int_fast8_t; 
# 92
typedef long int_fast16_t; 
# 93
typedef long int_fast32_t; 
# 94
typedef long int_fast64_t; 
# 103
typedef unsigned char uint_fast8_t; 
# 105
typedef unsigned long uint_fast16_t; 
# 106
typedef unsigned long uint_fast32_t; 
# 107
typedef unsigned long uint_fast64_t; 
# 119
typedef long intptr_t; 
# 122
typedef unsigned long uintptr_t; 
# 134
typedef long intmax_t; 
# 135
typedef unsigned long uintmax_t; 
# 18 "bench_gtc.h"
typedef int16_t my_int; 
# 26
typedef float my_real; 
# 32
typedef double real; 
# 33
typedef double wreal; 
# 66
extern real shift_t_comp; 
# 67
extern real shift_t_comm1; 
# 68
extern real shift_t_comm2; 
# 69
extern real charge_t_comp; 
# 70
extern real charge_t_comp_t1; 
# 71
extern real charge_t_comm; 
# 72
extern real charge_t_comm1; 
# 73
extern real charge_t_comm2; 
# 74
extern real charge_t_comm3; 
# 75
extern real grid_t_comm1; 
# 76
extern real grid_t_comm2; 
# 77
extern real push_t_comp; 
# 181
typedef 
# 79
struct { 
# 80
int mi; 
# 81
int mimax; 
# 82
int mgrid; 
# 83
int mpsi; 
# 84
int mthetamax; 
# 85
int mzeta; 
# 86
int mzetamax; 
# 87
int miinit; 
# 88
int holecount; 
# 90
int mpsi_loc; 
# 91
int m2pi; 
# 92
int mumax2; 
# 93
real delvperp; 
# 95
int istep; 
# 96
int ndiag; 
# 97
int ntracer; 
# 98
int msnap; 
# 99
int mstep; 
# 100
int mstepall; 
# 101
int mmomentsoutput; 
# 103
int tstdout; 
# 105
int mype; 
# 106
int numberpe; 
# 108
int mode00; 
# 109
int nbound; 
# 110
int irun; 
# 111
int iload; 
# 112
int irk; 
# 113
int idiag; 
# 114
int ncycle; 
# 115
int mtdiag; 
# 116
int idiag1; 
# 117
int idiag2; 
# 118
int mflux; 
# 120
int ntracer1; 
# 121
int nhybrid; 
# 122
int ihybrid; 
# 124
int nparam; 
# 125
int rng_control; 
# 127
int limit_vpara; 
# 128
int fixed_Tprofile; 
# 130
int mi_total; 
# 131
int micell; 
# 133
int hole_remove_freq; 
# 134
int radial_bin_freq; 
# 136
real nonlinear; 
# 137
real paranl; 
# 138
real a0; 
# 139
real a1; 
# 140
real a; 
# 141
real q0; 
# 142
real q1; 
# 143
real q2; 
# 145
real pi; 
# 146
real tstep; 
# 147
real kappati; 
# 148
real kappate; 
# 149
real kappan; 
# 151
real flow0; 
# 152
real flow1; 
# 153
real flow2; 
# 154
real ulength; 
# 155
real utime; 
# 156
real gyroradius; 
# 157
real deltar; 
# 158
real deltaz; 
# 160
real zetamax; 
# 161
real zetamin; 
# 162
real umax; 
# 163
real tite; 
# 164
real rc; 
# 165
real rw; 
# 166
real tauii; 
# 167
real qion; 
# 168
real qelectron; 
# 169
real aion; 
# 170
real aelectron; 
# 172
real r0; 
# 173
real b0; 
# 174
real temperature; 
# 175
real edensity0; 
# 176
real smu_inv; 
# 177
real delr; 
# 178
real delz; 
# 179
real pi2_inv; 
# 181
} gtc_global_params_t; 
# 206
typedef 
# 185
struct { 
# 186
real *z0; 
# 187
real *z1; 
# 188
real *z2; 
# 189
real *z3; 
# 190
real *z4; 
# 191
real *z5; 
# 193
real *z00; 
# 194
real *z01; 
# 195
real *z02; 
# 196
real *z03; 
# 197
real *z04; 
# 198
real *z05; 
# 202
real *ztmp; 
# 203
real *ztmp2; 
# 204
int *psi_count; 
# 205
int *psi_offsets; 
# 206
} gtc_particle_data_t; 
# 214
typedef 
# 208
struct { 
# 209
int *point_index; 
# 210
my_int *point_index_count; 
# 211
my_int *point_index_count_tid; 
# 212
my_real *point_vect; 
# 214
} gtc_aux_particle_point_t; 
# 225
typedef 
# 216
struct { 
# 217
int *kzion; 
# 218
int *jtion0; 
# 219
int *jtion1; 
# 220
real *wzion; 
# 221
real *wpion; 
# 222
real *wtion0; 
# 223
real *wtion1; 
# 224
int *kzi; 
# 225
} gtc_aux_particle_data_t; 
# 301
typedef 
# 227
struct { 
# 228
int mmpsi; 
# 229
int *itran; 
# 230
int *igrid; 
# 231
int *jtp1; 
# 232
int *jtp2; 
# 234
real *phi00; 
# 235
real *phip00; 
# 236
real *rtemi; 
# 237
real *rden; 
# 238
real *qtinv; 
# 239
real *pmarki; 
# 240
real *zonali; 
# 241
real *adum; 
# 242
real *adum2; 
# 243
real *gradt; 
# 244
real *difft; 
# 246
real *phi; 
# 248
wreal *densityi; 
# 249
wreal *densityi_local; 
# 251
real *dtemp; 
# 252
real *temp; 
# 253
wreal *dnitmp; 
# 255
real *hfluxpsi; 
# 256
real *pfluxpsi; 
# 257
real *vdrtmp; 
# 258
real *markeri; 
# 259
real *pgyro; 
# 260
real *tgyro; 
# 261
real *dtemper; 
# 262
real *heatflux; 
# 263
real *phit; 
# 265
real *evector; 
# 266
real *wtp1; 
# 267
real *wtp2; 
# 268
real *phisave; 
# 269
wreal *recvr; 
# 270
wreal *sendl; 
# 272
real *sendrsf; 
# 273
real *recvlsf; 
# 274
real *sendlf; 
# 275
real *recvlf; 
# 276
real *sendrf; 
# 277
real *recvrf; 
# 279
real *perr; 
# 280
real *ptilde; 
# 281
real *phitmp; 
# 282
real *phitmps; 
# 283
real *dentmp; 
# 284
real *den00; 
# 286
real *delt; 
# 287
int *mtheta; 
# 288
real *deltat; 
# 289
int *indexp; 
# 290
int *nindex; 
# 291
real *ring; 
# 293
real *drdpa; 
# 294
real *diffta; 
# 295
int *idx1a; 
# 296
int *idx2a; 
# 298
int *recvl_index; 
# 299
int *recvr_index; 
# 301
} gtc_field_data_t; 
# 362
typedef 
# 303
struct { 
# 304
int *nmode; 
# 305
int *mmode; 
# 324
real *scalar_data; 
# 325
real *eflux; 
# 326
real *rmarker; 
# 327
real *dmark; 
# 328
real *dden; 
# 329
real *rdtemi; 
# 330
real *rdteme; 
# 332
real *flux_data; 
# 333
real *amp_mode; 
# 334
real *eigenmode; 
# 335
real ptracer[4]; 
# 336
real eflux_average; 
# 362
} gtc_diagnosis_data_t; 
# 391
typedef 
# 364
struct { 
# 365
int mype; 
# 366
int numberpe; 
# 367
int ntoroidal; 
# 368
int npartdom; 
# 369
int nproc_partd; 
# 370
int myrank_partd; 
# 371
int nproc_toroidal; 
# 372
int myrank_toroidal; 
# 373
int left_pe; 
# 374
int right_pe; 
# 375
int toroidal_domain_location; 
# 376
int particle_domain_location; 
# 377
int nthreads; 
# 379
real *recvbuf; 
# 380
int recvbuf_size; 
# 381
real *sendbuf; 
# 382
int sendbuf_size; 
# 391
} gtc_particle_decomp_t; 
# 418
typedef 
# 393
struct { 
# 394
int ipsi_remap_in, ipsi_remap_out, igrid_remap_in, igrid_remap_out, nloc_remap; 
# 395
int mvpara, mvperp2; 
# 396
real deltavpara, deltavperp2; 
# 397
int remap_order; 
# 398
real *df_phase_space, *f_phase_space, *g_phase_space; 
# 399
real *sendl_phase_space, *sendr_phase_space, *recvl_phase_space, *recvr_phase_space; 
# 400
int remapping_freq; 
# 402
int *ghost_remap_comm_list; 
# 403
int *ghost_remap_start; 
# 404
int *ghost_remap_end; 
# 405
int ghost_remap_comm_num; 
# 406
real *ghost_remap_sendrecvbuf; 
# 407
int ghost_remap_bufsize; 
# 409
int *nghost_remap_comm_list; 
# 410
int *nghost_remap_start; 
# 411
int *nghost_remap_end; 
# 412
int nghost_remap_comm_num; 
# 413
real *nghost_remap_sendrecvbuf; 
# 414
int nghost_remap_bufsize; 
# 416
int *igrid_count; 
# 417
int *igrid_offsets; 
# 418
} gtc_particle_remap_t; 
# 473
typedef 
# 420
struct { 
# 421
int ipsi_nover_in; 
# 422
int ipsi_nover_out; 
# 423
int ipsi_in; 
# 424
int ipsi_out; 
# 425
int ipsi_valid_in; 
# 426
int ipsi_valid_out; 
# 427
int igrid_in; 
# 428
int igrid_out; 
# 429
int igrid_nover_in; 
# 430
int igrid_nover_out; 
# 431
int nloc_nover; 
# 432
int nloc_over; 
# 433
int ipsi_nover_in_radiald; 
# 434
int ipsi_nover_out_radiald; 
# 435
int igrid_nover_in_radiald; 
# 436
int igrid_nover_out_radiald; 
# 438
real a_nover_in; 
# 439
real a_nover_out; 
# 440
real a_valid_in; 
# 441
real a_valid_out; 
# 442
real rho_max; 
# 443
int *ri_pe; 
# 444
int *ri_pe2; 
# 446
int npe_radiald; 
# 447
int nradial_dom; 
# 448
int nproc_radiald; 
# 449
int myrank_radiald; 
# 450
int nproc_radial_partd; 
# 451
int myrank_radial_partd; 
# 452
int left_radial_pe; 
# 453
int right_radial_pe; 
# 454
int radial_domain_location; 
# 455
int radial_part_domain_location; 
# 461
int *ghost_comm_list; 
# 462
int *ghost_start; 
# 463
int *ghost_end; 
# 464
int ghost_comm_num; 
# 465
real *ghost_sendrecvbuf; 
# 466
int ghost_bufsize; 
# 467
int *nghost_comm_list; 
# 468
int *nghost_start; 
# 469
int *nghost_end; 
# 470
int nghost_comm_num; 
# 471
real *nghost_sendrecvbuf; 
# 472
int nghost_bufsize; 
# 473
} gtc_radial_decomp_t; 
# 481
typedef 
# 475
struct { 
# 476
int neop, neot, neoz; 
# 477
real *maxwell; 
# 478
real *tmp, *tmp_loc; 
# 479
real *dele, *delm, *marker, *ddum; 
# 480
real *dele_loc, *delm_loc, *marker_loc; 
# 481
} gtc_particle_collision_t; 
# 495
typedef 
# 483
struct { 
# 484
gtc_global_params_t global_params; 
# 485
gtc_field_data_t field_data; 
# 486
gtc_particle_data_t particle_data; 
# 487
gtc_aux_particle_data_t aux_particle_data; 
# 488
gtc_diagnosis_data_t diagnosis_data; 
# 489
gtc_particle_remap_t particle_remap; 
# 490
gtc_particle_collision_t particle_collision; 
# 491
gtc_aux_particle_point_t particle_point; 
# 492
gtc_radial_decomp_t radial_decomp; 
# 494
gtc_particle_decomp_t parallel_decomp; 
# 495
} gtc_bench_data_t; 
# 502
int setup(gtc_bench_data_t *); 
# 503
int chargei(gtc_bench_data_t *); 
# 504
int chargei_init(gtc_bench_data_t *); 
# 506
int pushi(gtc_bench_data_t *); 
# 507
int smooth(int, gtc_bench_data_t *); 
# 508
int field(gtc_bench_data_t *); 
# 509
int poisson(int, gtc_bench_data_t *); 
# 510
int poisson_initial(gtc_bench_data_t *, int mring, int mindex, int * nindex, int * indexp, real * ring); 
# 517
int radial_bin_particles(gtc_bench_data_t *); 
# 518
int shifti_toroidal(gtc_bench_data_t *); 
# 519
int shifti_radial(gtc_bench_data_t *); 
# 523
int restart_read(gtc_bench_data_t *); 
# 524
int gtc_mem_free(gtc_bench_data_t * gtc_input); 
# 525
int collision(gtc_bench_data_t * gtc_input); 
# 527
int restart_write(gtc_bench_data_t * gtc_input); 
# 528
int sum_plane(gtc_bench_data_t * gtc_input); 
# 529
int fix_radial_ghosts(gtc_bench_data_t * gtc_input, real * data, int mzeta, int dim); 
# 533
int calc_moments(gtc_bench_data_t *); 
# 535
int abs_min_int(int arg1, int arg2) __attribute((always_inline)); 
# 536
real abs_min_real(real arg1, real arg2) __attribute((always_inline)); 
# 539
void usage(const char * exec_name); 
# 540
int read_input_file(char * filename, gtc_global_params_t * params, gtc_particle_decomp_t *, gtc_radial_decomp_t *); 
# 543
int cd_comp_fun(const void *, const void *); 
# 545
double timer(); 
# 11 "gtc_kernel_gpu.h"
extern "C" {
# 107
typedef 
# 92
struct { 
# 93
double memtransfer_charge_time; 
# 94
double memtransfer_push_time; 
# 95
double memtransfer_shift_time; 
# 96
double memreset_charge_time; 
# 97
double initialization_charge_time; 
# 98
double interpolation_charge_time; 
# 99
double interpolation_push_point_time; 
# 100
double interpolation_push_gyro_time; 
# 101
double device_charge_time; 
# 102
double device_particle_sort_time; 
# 103
double device_particle_bin_time; 
# 104
double device_push_time; 
# 105
double device_shift_time; 
# 106
cudaEvent_t start, stop; 
# 107
} gpu_timing_t; 
# 113
typedef 
# 109
struct { 
# 110
int *d_sort_key; 
# 111
int *d_value; 
# 112
real *d_aux_zion05; 
# 113
} gtc_sort_particle_t; 
# 144
typedef 
# 115
struct { 
# 116
cudaDeviceProp deviceProp; 
# 117
int nthreads; 
# 118
int d_mimax; 
# 119
int d_max_shift_mi; 
# 120
int d_extra_mimax; 
# 121
int d_nloc_over_cluster; 
# 122
int nblocks; 
# 123
int charge_mi_per_thread; 
# 124
int irk; 
# 125
int istep; 
# 126
int idiag; 
# 127
gpu_timing_t gpu_timing; 
# 129
gtc_particle_data_t d_zion; 
# 130
gtc_particle_data_t d_auxs_zion; 
# 131
gtc_aux_particle_data_t d_aux_zion; 
# 132
gtc_aux_particle_point_t d_aux_point; 
# 133
gtc_field_data_t d_grid; 
# 134
gtc_sort_particle_t d_sort; 
# 135
gtc_diagnosis_data_t d_diagnosis; 
# 137
gtc_particle_data_t *ptr_d_zion; 
# 138
gtc_particle_data_t *ptr_d_auxs_zion; 
# 139
gtc_aux_particle_data_t *ptr_d_aux_zion; 
# 140
gtc_aux_particle_point_t *ptr_d_aux_point; 
# 141
real *ptr_d_zion_shift; 
# 142
gtc_field_data_t *ptr_d_grid; 
# 143
gtc_diagnosis_data_t *ptr_d_diagnosis; 
# 144
} gpu_kernel_args_t; 
# 154
typedef 
# 148
struct { 
# 149
int key; 
# 150
real w1; 
# 151
real w2; 
# 152
real m1; 
# 153
real m2; 
# 154
} cd_update_t; 
# 156
void gpu_setup(gtc_bench_data_t * gtc_input, gpu_kernel_args_t * gpu_kernel_args); 
# 157
void cpy_gtc_data_to_device(gtc_bench_data_t * gtc_input, gpu_kernel_args_t * gpu_kernel_args); 
# 158
void free_gtc_data_on_device(gpu_kernel_args_t * gpu_kernel_input); 
# 160
void gpu_charge_init(gtc_bench_data_t * gtc_input, gpu_kernel_args_t * gpu_kernel_input); 
# 161
int diagnosis(gtc_bench_data_t *); 
# 163
int gpu_chargei(gtc_bench_data_t * gtc_input, gpu_kernel_args_t * gpu_kernel_input); 
# 164
int gpu_shifti_toroidal(gtc_bench_data_t * gtc_input, gpu_kernel_args_t * gpu_kernel_input); 
# 165
int gpu_shifti_radial(gtc_bench_data_t * gtc_input, gpu_kernel_args_t * gpu_kernel_input); 
# 166
int gpu_pushi(gtc_bench_data_t * gtc_input, gpu_kernel_args_t * gpu_kernel_input); 
# 167
int gpu_bin_particles(gtc_bench_data_t * gtc_input, gpu_kernel_args_t * gpu_kernel_input, int shift_direction); 
# 169
void call_gpu_charge_kernel(gtc_bench_data_t * gtc_input, gpu_kernel_args_t * gpu_kernel_input, int idiag); 
# 170
void call_gpu_charge_4p_kernel(gtc_bench_data_t * gtc_input, gpu_kernel_args_t * gpu_kernel_input, int istep, int idiag); 
# 172
void call_gpu_push_kernel(gtc_bench_data_t * gtc_input, gpu_kernel_args_t * gpu_kernel_input, int idiag); 
# 173
void call_gpu_push_4p_kernel(gtc_bench_data_t * gtc_input, gpu_kernel_args_t * gpu_kernel_input, int idiag); 
# 174
void call_gpu_bin_particles_kernel(gtc_bench_data_t * gtc_input, gpu_kernel_args_t * gpu_kernel_input, int shift_direction); 
# 176
void call_gpu_shifti_extract_kernel(gtc_bench_data_t * gtc_input, gpu_kernel_args_t * gpu_kernel_input, unsigned  tops[2], real * sends[2], int shift_direction); 
# 177
void call_gpu_shifti_append_kernel(gtc_bench_data_t * gtc_input, gpu_kernel_args_t * gpu_kernel_input, int mi_append, real * particle_data); 
# 179
void print_gpu_timing(gpu_kernel_args_t * gpu_kernel_args); 
# 182
}
# 37 "./cutil.h"
extern "C" {
# 60
enum CUTBoolean { 
# 62
CUTFalse, 
# 63
CUTTrue
# 64
}; 
# 72
void cutFree(void * ptr); 
# 90
void cutCheckBankAccess(unsigned tidx, unsigned tidy, unsigned tidz, unsigned bdimx, unsigned bdimy, unsigned bdimz, const char * file, const int line, const char * aname, const int index); 
# 103
char *cutFindFilePath(const char * filename, const char * executablePath); 
# 118
CUTBoolean cutReadFilef(const char * filename, float ** data, unsigned * len, bool verbose = false); 
# 134
CUTBoolean cutReadFiled(const char * filename, double ** data, unsigned * len, bool verbose = false); 
# 150
CUTBoolean cutReadFilei(const char * filename, int ** data, unsigned * len, bool verbose = false); 
# 165
CUTBoolean cutReadFileui(const char * filename, unsigned ** data, unsigned * len, bool verbose = false); 
# 181
CUTBoolean cutReadFileb(const char * filename, char ** data, unsigned * len, bool verbose = false); 
# 197
CUTBoolean cutReadFileub(const char * filename, unsigned char ** data, unsigned * len, bool verbose = false); 
# 211
CUTBoolean cutWriteFilef(const char * filename, const float * data, unsigned len, const float epsilon, bool verbose = false); 
# 225
CUTBoolean cutWriteFiled(const char * filename, const float * data, unsigned len, const double epsilon, bool verbose = false); 
# 237
CUTBoolean cutWriteFilei(const char * filename, const int * data, unsigned len, bool verbose = false); 
# 249
CUTBoolean cutWriteFileui(const char * filename, const unsigned * data, unsigned len, bool verbose = false); 
# 261
CUTBoolean cutWriteFileb(const char * filename, const char * data, unsigned len, bool verbose = false); 
# 273
CUTBoolean cutWriteFileub(const char * filename, const unsigned char * data, unsigned len, bool verbose = false); 
# 289
CUTBoolean cutLoadPGMub(const char * file, unsigned char ** data, unsigned * w, unsigned * h); 
# 302
CUTBoolean cutLoadPPMub(const char * file, unsigned char ** data, unsigned * w, unsigned * h); 
# 316
CUTBoolean cutLoadPPM4ub(const char * file, unsigned char ** data, unsigned * w, unsigned * h); 
# 332
CUTBoolean cutLoadPGMi(const char * file, unsigned ** data, unsigned * w, unsigned * h); 
# 348
CUTBoolean cutLoadPGMs(const char * file, unsigned short ** data, unsigned * w, unsigned * h); 
# 363
CUTBoolean cutLoadPGMf(const char * file, float ** data, unsigned * w, unsigned * h); 
# 375
CUTBoolean cutSavePGMub(const char * file, unsigned char * data, unsigned w, unsigned h); 
# 387
CUTBoolean cutSavePPMub(const char * file, unsigned char * data, unsigned w, unsigned h); 
# 400
CUTBoolean cutSavePPM4ub(const char * file, unsigned char * data, unsigned w, unsigned h); 
# 412
CUTBoolean cutSavePGMi(const char * file, unsigned * data, unsigned w, unsigned h); 
# 424
CUTBoolean cutSavePGMs(const char * file, unsigned short * data, unsigned w, unsigned h); 
# 436
CUTBoolean cutSavePGMf(const char * file, float * data, unsigned w, unsigned h); 
# 457
CUTBoolean cutCheckCmdLineFlag(const int argc, const char ** argv, const char * flag_name); 
# 471
CUTBoolean cutGetCmdLineArgumenti(const int argc, const char ** argv, const char * arg_name, int * val); 
# 485
CUTBoolean cutGetCmdLineArgumentf(const int argc, const char ** argv, const char * arg_name, float * val); 
# 499
CUTBoolean cutGetCmdLineArgumentstr(const int argc, const char ** argv, const char * arg_name, char ** val); 
# 514
CUTBoolean cutGetCmdLineArgumentListstr(const int argc, const char ** argv, const char * arg_name, char ** val, unsigned * len); 
# 528
CUTBoolean cutCheckCondition(int val, const char * file, const int line); 
# 540
CUTBoolean cutComparef(const float * reference, const float * data, const unsigned len); 
# 553
CUTBoolean cutComparei(const int * reference, const int * data, const unsigned len); 
# 567
CUTBoolean cutCompareuit(const unsigned * reference, const unsigned * data, const unsigned len, const float epsilon, const float threshold); 
# 580
CUTBoolean cutCompareub(const unsigned char * reference, const unsigned char * data, const unsigned len); 
# 595
CUTBoolean cutCompareubt(const unsigned char * reference, const unsigned char * data, const unsigned len, const float epsilon, const float threshold); 
# 609
CUTBoolean cutCompareube(const unsigned char * reference, const unsigned char * data, const unsigned len, const float epsilon); 
# 623
CUTBoolean cutComparefe(const float * reference, const float * data, const unsigned len, const float epsilon); 
# 638
CUTBoolean cutComparefet(const float * reference, const float * data, const unsigned len, const float epsilon, const float threshold); 
# 653
CUTBoolean cutCompareL2fe(const float * reference, const float * data, const unsigned len, const float epsilon); 
# 668
CUTBoolean cutComparePPM(const char * src_file, const char * ref_file, const float epsilon, const float threshold, bool verboseErrors = false); 
# 681
CUTBoolean cutCreateTimer(unsigned * name); 
# 690
CUTBoolean cutDeleteTimer(unsigned name); 
# 698
CUTBoolean cutStartTimer(const unsigned name); 
# 706
CUTBoolean cutStopTimer(const unsigned name); 
# 714
CUTBoolean cutResetTimer(const unsigned name); 
# 723
float cutGetTimerValue(const unsigned name); 
# 734
float cutGetAverageTimerValue(const unsigned name); 
# 926
}
# 5 "gpu_setup.cu"
static gtc_global_params_t params __attribute((aligned(16))); 
# 6
static real temp[721] __attribute((aligned(16))); 
# 7
static real dtemp[721] __attribute((aligned(16))); 
# 8
static real rtemi[721] __attribute((aligned(16))); 
# 10
static real qtinv[721] __attribute((aligned(16))); 
# 11
static real delt[721] __attribute((aligned(16))); 
# 12
static int igrid[721] __attribute((aligned(16))); 
# 13
static int mtheta[721] __attribute((aligned(16))); 
# 14
static int max_shift_mi __attribute((aligned(16))); 
# 15
static gtc_radial_decomp_t radial_decomp __attribute((aligned(16))); 
# 18
void gpu_timer_start(gpu_kernel_args_t *gpu_kernel_input) 
# 19
{ 
# 20
{ cudaError err = cudaEventCreate(&((gpu_kernel_input->gpu_timing).start)); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 20, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 21
{ cudaError err = cudaEventCreate(&((gpu_kernel_input->gpu_timing).stop)); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 21, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 22
{ cudaError err = cudaEventRecord((gpu_kernel_input->gpu_timing).start, 0); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 22, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 23
} 
# 25
float gpu_timer_measure(gpu_kernel_args_t *gpu_kernel_input) 
# 26
{ 
# 27
float elapsedTime; 
# 28
{ cudaError err = cudaEventRecord((gpu_kernel_input->gpu_timing).stop, 0); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 28, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 29
{ cudaError err = cudaEventSynchronize((gpu_kernel_input->gpu_timing).stop); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 29, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 30
{ cudaError err = cudaEventElapsedTime(&elapsedTime, (gpu_kernel_input->gpu_timing).start, (gpu_kernel_input->gpu_timing).stop); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 30, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 32
cudaEvent_t temp = (gpu_kernel_input->gpu_timing).start; 
# 33
((gpu_kernel_input->gpu_timing).start) = ((gpu_kernel_input->gpu_timing).stop); 
# 34
((gpu_kernel_input->gpu_timing).stop) = temp; 
# 35
return elapsedTime / (1000); 
# 36
} 
# 38
float gpu_timer_measure_end(gpu_kernel_args_t *gpu_kernel_input) 
# 39
{ 
# 40
float elapsedTime; 
# 41
{ cudaError err = cudaEventRecord((gpu_kernel_input->gpu_timing).stop, 0); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 41, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 42
{ cudaError err = cudaEventSynchronize((gpu_kernel_input->gpu_timing).stop); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 42, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 43
{ cudaError err = cudaEventElapsedTime(&elapsedTime, (gpu_kernel_input->gpu_timing).start, (gpu_kernel_input->gpu_timing).stop); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 43, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 44
{ cudaError err = cudaEventDestroy((gpu_kernel_input->gpu_timing).start); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 44, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 45
{ cudaError err = cudaEventDestroy((gpu_kernel_input->gpu_timing).stop); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 45, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 46
return elapsedTime / (1000); 
# 47
} 
# 71
static texture< int2, 1, cudaReadModeElementType>  evectorTexRef; 
# 75
static void allocate_device_data(gtc_bench_data_t *gtc_input, gpu_kernel_args_t *gpu_kernel_args) 
# 76
{ 
# 77
gtc_global_params_t *h_params = &(gtc_input->global_params); 
# 78
gtc_radial_decomp_t *h_radial_decomp = &(gtc_input->radial_decomp); 
# 80
int d_mimax = gpu_kernel_args->d_mimax; 
# 82
int nloc_over = h_radial_decomp->nloc_over; 
# 83
int d_extra_mimax = gpu_kernel_args->d_extra_mimax; 
# 84
int nloc_over_cluster = gpu_kernel_args->d_nloc_over_cluster; 
# 86
int mzeta = h_params->mzeta; 
# 88
gtc_field_data_t *d_grid = &(gpu_kernel_args->d_grid); 
# 89
gtc_particle_data_t *d_zion = &(gpu_kernel_args->d_zion); 
# 90
gtc_diagnosis_data_t *d_diagnosis = &(gpu_kernel_args->d_diagnosis); 
# 91
gtc_field_data_t *h_grid = &(gtc_input->field_data); 
# 94
{ cudaError err = cudaMalloc((void **)(&(gpu_kernel_args->ptr_d_zion)), sizeof(gtc_particle_data_t)); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 94, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 95
{ cudaError err = cudaMalloc((void **)(&(d_zion->z0)), (12 * d_mimax) * sizeof(real)); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 95, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 96
(d_zion->z1) = ((d_zion->z0) + d_mimax); 
# 97
(d_zion->z2) = ((d_zion->z0) + (2 * d_mimax)); 
# 98
(d_zion->z3) = ((d_zion->z0) + (3 * d_mimax)); 
# 99
(d_zion->z4) = ((d_zion->z0) + (4 * d_mimax)); 
# 100
(d_zion->z5) = ((d_zion->z0) + (5 * d_mimax)); 
# 101
(d_zion->z00) = ((d_zion->z0) + (6 * d_mimax)); 
# 102
(d_zion->z01) = ((d_zion->z0) + (7 * d_mimax)); 
# 103
(d_zion->z02) = ((d_zion->z0) + (8 * d_mimax)); 
# 104
(d_zion->z03) = ((d_zion->z0) + (9 * d_mimax)); 
# 105
(d_zion->z04) = ((d_zion->z0) + (10 * d_mimax)); 
# 106
(d_zion->z05) = ((d_zion->z0) + (11 * d_mimax)); 
# 110
gtc_particle_data_t *d_auxs_zion = &(gpu_kernel_args->d_auxs_zion); 
# 111
{ cudaError err = cudaMalloc((void **)(&(gpu_kernel_args->ptr_d_auxs_zion)), sizeof(gtc_particle_data_t)); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 111, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 112
{ cudaError err = cudaMalloc((void **)(&(d_auxs_zion->z0)), (12 * d_mimax) * sizeof(real)); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 112, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 113
(d_auxs_zion->z1) = ((d_auxs_zion->z0) + d_mimax); 
# 114
(d_auxs_zion->z2) = ((d_auxs_zion->z0) + (2 * d_mimax)); 
# 115
(d_auxs_zion->z3) = ((d_auxs_zion->z0) + (3 * d_mimax)); 
# 116
(d_auxs_zion->z4) = ((d_auxs_zion->z0) + (4 * d_mimax)); 
# 117
(d_auxs_zion->z5) = ((d_auxs_zion->z0) + (5 * d_mimax)); 
# 118
(d_auxs_zion->z00) = ((d_auxs_zion->z0) + (6 * d_mimax)); 
# 119
(d_auxs_zion->z01) = ((d_auxs_zion->z0) + (7 * d_mimax)); 
# 120
(d_auxs_zion->z02) = ((d_auxs_zion->z0) + (8 * d_mimax)); 
# 121
(d_auxs_zion->z03) = ((d_auxs_zion->z0) + (9 * d_mimax)); 
# 122
(d_auxs_zion->z04) = ((d_auxs_zion->z0) + (10 * d_mimax)); 
# 123
(d_auxs_zion->z05) = ((d_auxs_zion->z0) + (11 * d_mimax)); 
# 174
gtc_sort_particle_t *d_sort = &(gpu_kernel_args->d_sort); 
# 175
{ cudaError err = cudaMalloc((void **)(&(d_sort->d_sort_key)), (2 * d_mimax) * sizeof(int)); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 175, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 176
(d_sort->d_value) = ((d_sort->d_sort_key) + d_mimax); 
# 177
{ cudaError err = cudaMalloc((void **)(&(d_sort->d_aux_zion05)), d_mimax * sizeof(real)); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 177, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 183
{ cudaError err = cudaMalloc((void **)(&(gpu_kernel_args->ptr_d_diagnosis)), sizeof(gtc_diagnosis_data_t)); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 183, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 184
{ cudaError err = cudaMalloc((void **)(&(d_diagnosis->scalar_data)), (16) * sizeof(real)); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 184, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 185
{ cudaError err = cudaMalloc((void **)(&(d_diagnosis->flux_data)), (5 * 4) * sizeof(real)); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 185, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 193
{ cudaError err = cudaMalloc((void **)(&(gpu_kernel_args->ptr_d_grid)), sizeof(gtc_field_data_t)); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 193, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 195
{ cudaError err = cudaMalloc((void **)(&(d_grid->pgyro)), ((2 * 4) * nloc_over) * sizeof(real)); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 195, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 196
(d_grid->tgyro) = ((d_grid->pgyro) + (4 * nloc_over)); 
# 198
{ cudaError err = cudaMalloc((void **)(&(d_grid->evector)), ((nloc_over * 3) * (mzeta + 1)) * sizeof(real)); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 198, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 201
(d_grid->densityi) = (d_grid->evector); 
# 202
{ cudaError err = cudaMalloc((void **)(&(d_grid->pfluxpsi)), (5) * sizeof(real)); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 202, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 204
} 
# 207
extern "C" void free_gtc_data_on_device(gpu_kernel_args_t *gpu_kernel_input) 
# 208
{ 
# 209
gtc_particle_data_t *d_zion = &(gpu_kernel_input->d_zion); 
# 210
gtc_field_data_t *d_grid = &(gpu_kernel_input->d_grid); 
# 211
gtc_diagnosis_data_t *d_diagnosis = &(gpu_kernel_input->d_diagnosis); 
# 213
{ cudaError err = cudaFree(gpu_kernel_input->ptr_d_zion); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 213, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 214
{ cudaError err = cudaFree(d_zion->z0); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 214, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 231
gtc_particle_data_t *d_auxs_zion = &(gpu_kernel_input->d_auxs_zion); 
# 232
{ cudaError err = cudaFree(gpu_kernel_input->ptr_d_auxs_zion); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 232, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 233
{ cudaError err = cudaFree(d_auxs_zion->z0); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 233, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 247
gtc_sort_particle_t *d_sort = &(gpu_kernel_input->d_sort); 
# 248
{ cudaError err = cudaFree(d_sort->d_sort_key); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 248, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 249
{ cudaError err = cudaFree(d_sort->d_aux_zion05); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 249, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 254
{ cudaError err = cudaFree(gpu_kernel_input->ptr_d_diagnosis); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 254, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 255
{ cudaError err = cudaFree(d_diagnosis->scalar_data); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 255, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 256
{ cudaError err = cudaFree(d_diagnosis->flux_data); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 256, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 262
{ cudaError err = cudaFree(gpu_kernel_input->ptr_d_grid); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 262, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 264
{ cudaError err = cudaFree(d_grid->pgyro); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 264, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 267
{ cudaError err = cudaFree(d_grid->evector); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 267, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 269
{ cudaError err = cudaFree(d_grid->pfluxpsi); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 269, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 270
} 
# 1 "./ptx_custom.cu"
__attribute((always_inline)) __attribute__((unused)) inline int custom_popc(unsigned x) 
# 2
{int volatile ___ = 1;(void)x;
# 12
::exit(___);}
#if 0
# 2
{ 
# 3
int ret; 
# 4
__asm__ volatile("{\n\t.reg .u32 t1,t2;\n\tmov.u32 t1,%1;\n\tpopc.b32 t2,t1;\n\tmov.u32 %0,t2;\n\t}" : "=r" (ret) : "r" (x)); 
# 11
return ret; 
# 12
} 
#endif
# 14 "./ptx_custom.cu"
__attribute((always_inline)) __attribute__((unused)) inline unsigned select_gt_u32(unsigned left, unsigned right) 
# 15
{int volatile ___ = 1;(void)left;(void)right;
# 30
::exit(___);}
#if 0
# 15
{ 
# 17
unsigned ret; 
# 18
__asm__ volatile("{\n\t.reg .u32 a,b,c,d;\n\t.reg .u32 l,r;\n\t.reg .pred p;\n\tmov.u32 l,%1;\n\tmov.u32 r,%2;\n\tsetp.u32.gt p,l,r;\n\tselp.u32 d" ",1,0,p;\n\tmov.u32 %0,d;\n\t}" : "=r" (ret) : "r" (left), "r" (right)); 
# 29
return ret; 
# 30
} 
#endif
# 32 "./ptx_custom.cu"
__attribute((always_inline)) __attribute__((unused)) inline unsigned select_eq_u32(unsigned left, unsigned right) 
# 33
{int volatile ___ = 1;(void)left;(void)right;
# 48
::exit(___);}
#if 0
# 33
{ 
# 35
unsigned ret; 
# 36
__asm__("{\n\t.reg .u32 d;\n\t.reg .u32 l,r;\n\t.reg .pred p;\n\tmov.u32 l,%1;\n\tmov.u32 r,%2;\n\tsetp.u32.eq p,l,r;\n\tselp.u32 d,1,0,p" ";\n\tmov.u32 %0,d;\n\t}" : "=r" (ret) : "r" (left), "r" (right)); 
# 47
return ret; 
# 48
} 
#endif
# 51 "./ptx_custom.cu"
__attribute((always_inline)) __attribute__((unused)) inline unsigned select_gt_f64(real left, real right) 
# 52
{int volatile ___ = 1;(void)left;(void)right;
# 67
::exit(___);}
#if 0
# 52
{ 
# 54
unsigned ret; 
# 55
__asm__("{\n\t.reg .u32 d;\n\t.reg .f64 l,r;\n\t.reg .pred p;\n\tmov.f64 l,%1;\n\tmov.f64 r,%2;\n\tsetp.f64.gt p,l,r;\n\tselp.u32 d,1,0,p" ";\n\tmov.u32 %0,d;\n\t}" : "=r" (ret) : "d" (left), "d" (right)); 
# 66
return ret; 
# 67
} 
#endif
# 69 "./ptx_custom.cu"
__attribute((always_inline)) __attribute__((unused)) inline unsigned select_eq_f64(real left, real right) 
# 70
{int volatile ___ = 1;(void)left;(void)right;
# 85
::exit(___);}
#if 0
# 70
{ 
# 72
unsigned ret; 
# 73
__asm__ volatile("{\n\t.reg .u32 a,b,c,d;\n\t.reg .f64 l,r;\n\t.reg .pred p;\n\tmov.f64 l,%1;\n\tmov.f64 r,%2;\n\tsetp.f64.eq p,l,r;\n\tselp.u32 d" ",1,0,p;\n\tmov.u32 %0,d;\n\t}" : "=r" (ret) : "d" (left), "d" (right)); 
# 84
return ret; 
# 85
} 
#endif
# 88 "./ptx_custom.cu"
__attribute((always_inline)) __attribute__((unused)) inline int sorting_ballot(int sel, unsigned count[3], int tidx, int tidy, unsigned mask) 
# 89
{int volatile ___ = 1;(void)sel;(void)count;(void)tidx;(void)tidy;(void)mask;
# 129
::exit(___);}
#if 0
# 89
{ 
# 90
int keep = sel == 0; 
# 91
int left = sel == 1; 
# 92
int right = sel == 2; 
# 104
__attribute__((unused)) static unsigned count_right_low, count_left_low, count_keep_low; 
# 105
unsigned my_left_ballot = ballot(left); 
# 106
unsigned my_right_ballot = ballot(right); 
# 107
unsigned my_keep_ballot = ballot(keep); 
# 109
unsigned my_count_right = custom_popc(my_right_ballot); 
# 110
unsigned my_count_left = custom_popc(my_left_ballot); 
# 111
unsigned my_count_keep = custom_popc(my_keep_ballot); 
# 112
int my_before_ballot = mask & (((left * my_left_ballot) + (right * my_right_ballot)) + (keep * my_keep_ballot)); 
# 114
int order = custom_popc(my_before_ballot); 
# 115
if ((tidx == 0) && (tidy == 0)) { 
# 116
count_right_low = my_count_right; 
# 117
count_left_low = my_count_left; 
# 118
count_keep_low = my_count_keep; 
# 119
}  
# 120
__syncthreads(); 
# 121
order += (tidy * (((count_right_low * right) + (count_left_low * left)) + (count_keep_low * keep))); 
# 123
if ((tidx == 31) && (tidy == 1)) { 
# 124
(count[2]) = (my_count_right + count_right_low); 
# 125
(count[1]) = (my_count_left + count_left_low); 
# 126
(count[0]) = (my_count_keep + count_keep_low); 
# 127
}  
# 128
return order; 
# 129
} 
#endif
# 138 "./ptx_custom.cu"
enum CacheModifier { 
# 139
CG, 
# 140
CS, 
# 141
CA, 
# 142
LU, 
# 143
CV, 
# 144
WB, 
# 145
WT
# 147
}; 
# 160
template< class T, CacheModifier CACHE_MODIFIER> struct TunedTexLoad; 
# 188
template<> struct TunedTexLoad< double, CG>  { __attribute((always_inline)) static double Ld(const double *d_ptr) {int volatile ___ = 1;(void)d_ptr;::exit(___);}
#if 0
# 188
{ double val; __asm__("ld.global.cg.nc.f64 %0, [%1];" : "=d" (val) : "l" (d_ptr)); return val; } 
#endif
# 188 "./ptx_custom.cu"
}; template<> struct TunedTexLoad< double, CS>  { __attribute((always_inline)) static double Ld(const double *d_ptr) {int volatile ___ = 1;(void)d_ptr;::exit(___);}
#if 0
# 188
{ double val; __asm__("ld.global.cs.nc.f64 %0, [%1];" : "=d" (val) : "l" (d_ptr)); return val; } 
#endif
# 188 "./ptx_custom.cu"
}; template<> struct TunedTexLoad< double, CA>  { __attribute((always_inline)) static double Ld(const double *d_ptr) {int volatile ___ = 1;(void)d_ptr;::exit(___);}
#if 0
# 188
{ double val; __asm__("ld.global.ca.nc.f64 %0, [%1];" : "=d" (val) : "l" (d_ptr)); return val; } 
#endif
# 188 "./ptx_custom.cu"
}; 
# 189
template<> struct TunedTexLoad< float, CG>  { __attribute((always_inline)) static float Ld(const float *d_ptr) {int volatile ___ = 1;(void)d_ptr;::exit(___);}
#if 0
# 189
{ float val; __asm__("ld.global.cg.nc.f32 %0, [%1];" : "=f" (val) : "l" (d_ptr)); return val; } 
#endif
# 189 "./ptx_custom.cu"
}; template<> struct TunedTexLoad< float, CS>  { __attribute((always_inline)) static float Ld(const float *d_ptr) {int volatile ___ = 1;(void)d_ptr;::exit(___);}
#if 0
# 189
{ float val; __asm__("ld.global.cs.nc.f32 %0, [%1];" : "=f" (val) : "l" (d_ptr)); return val; } 
#endif
# 189 "./ptx_custom.cu"
}; template<> struct TunedTexLoad< float, CA>  { __attribute((always_inline)) static float Ld(const float *d_ptr) {int volatile ___ = 1;(void)d_ptr;::exit(___);}
#if 0
# 189
{ float val; __asm__("ld.global.ca.nc.f32 %0, [%1];" : "=f" (val) : "l" (d_ptr)); return val; } 
#endif
# 189 "./ptx_custom.cu"
}; 
# 190
template<> struct TunedTexLoad< short, CG>  { __attribute((always_inline)) static short Ld(const short *d_ptr) {int volatile ___ = 1;(void)d_ptr;::exit(___);}
#if 0
# 190
{ short val; __asm__("ld.global.cg.nc.s16 %0, [%1];" : "=h" (val) : "l" (d_ptr)); return val; } 
#endif
# 190 "./ptx_custom.cu"
}; template<> struct TunedTexLoad< short, CS>  { __attribute((always_inline)) static short Ld(const short *d_ptr) {int volatile ___ = 1;(void)d_ptr;::exit(___);}
#if 0
# 190
{ short val; __asm__("ld.global.cs.nc.s16 %0, [%1];" : "=h" (val) : "l" (d_ptr)); return val; } 
#endif
# 190 "./ptx_custom.cu"
}; template<> struct TunedTexLoad< short, CA>  { __attribute((always_inline)) static short Ld(const short *d_ptr) {int volatile ___ = 1;(void)d_ptr;::exit(___);}
#if 0
# 190
{ short val; __asm__("ld.global.ca.nc.s16 %0, [%1];" : "=h" (val) : "l" (d_ptr)); return val; } 
#endif
# 190 "./ptx_custom.cu"
}; 
# 191
template<> struct TunedTexLoad< int, CG>  { __attribute((always_inline)) static int Ld(const int *d_ptr) {int volatile ___ = 1;(void)d_ptr;::exit(___);}
#if 0
# 191
{ int val; __asm__("ld.global.cg.nc.s32 %0, [%1];" : "=r" (val) : "l" (d_ptr)); return val; } 
#endif
# 191 "./ptx_custom.cu"
}; template<> struct TunedTexLoad< int, CS>  { __attribute((always_inline)) static int Ld(const int *d_ptr) {int volatile ___ = 1;(void)d_ptr;::exit(___);}
#if 0
# 191
{ int val; __asm__("ld.global.cs.nc.s32 %0, [%1];" : "=r" (val) : "l" (d_ptr)); return val; } 
#endif
# 191 "./ptx_custom.cu"
}; template<> struct TunedTexLoad< int, CA>  { __attribute((always_inline)) static int Ld(const int *d_ptr) {int volatile ___ = 1;(void)d_ptr;::exit(___);}
#if 0
# 191
{ int val; __asm__("ld.global.ca.nc.s32 %0, [%1];" : "=r" (val) : "l" (d_ptr)); return val; } 
#endif
# 191 "./ptx_custom.cu"
}; 
# 192
template<> struct TunedTexLoad< long, CG>  { __attribute((always_inline)) static long Ld(const long *d_ptr) {int volatile ___ = 1;(void)d_ptr;::exit(___);}
#if 0
# 192
{ long val; __asm__("ld.global.cg.nc.s64 %0, [%1];" : "=l" (val) : "l" (d_ptr)); return val; } 
#endif
# 192 "./ptx_custom.cu"
}; template<> struct TunedTexLoad< long, CS>  { __attribute((always_inline)) static long Ld(const long *d_ptr) {int volatile ___ = 1;(void)d_ptr;::exit(___);}
#if 0
# 192
{ long val; __asm__("ld.global.cs.nc.s64 %0, [%1];" : "=l" (val) : "l" (d_ptr)); return val; } 
#endif
# 192 "./ptx_custom.cu"
}; template<> struct TunedTexLoad< long, CA>  { __attribute((always_inline)) static long Ld(const long *d_ptr) {int volatile ___ = 1;(void)d_ptr;::exit(___);}
#if 0
# 192
{ long val; __asm__("ld.global.ca.nc.s64 %0, [%1];" : "=l" (val) : "l" (d_ptr)); return val; } 
#endif
# 192 "./ptx_custom.cu"
}; 
# 193
template<> struct TunedTexLoad< unsigned short, CG>  { __attribute((always_inline)) static unsigned short Ld(const unsigned short *d_ptr) {int volatile ___ = 1;(void)d_ptr;::exit(___);}
#if 0
# 193
{ unsigned short val; __asm__("ld.global.cg.nc.u16 %0, [%1];" : "=h" (val) : "l" (d_ptr)); return val; } 
#endif
# 193 "./ptx_custom.cu"
}; template<> struct TunedTexLoad< unsigned short, CS>  { __attribute((always_inline)) static unsigned short Ld(const unsigned short *d_ptr) {int volatile ___ = 1;(void)d_ptr;::exit(___);}
#if 0
# 193
{ unsigned short val; __asm__("ld.global.cs.nc.u16 %0, [%1];" : "=h" (val) : "l" (d_ptr)); return val; } 
#endif
# 193 "./ptx_custom.cu"
}; template<> struct TunedTexLoad< unsigned short, CA>  { __attribute((always_inline)) static unsigned short Ld(const unsigned short *d_ptr) {int volatile ___ = 1;(void)d_ptr;::exit(___);}
#if 0
# 193
{ unsigned short val; __asm__("ld.global.ca.nc.u16 %0, [%1];" : "=h" (val) : "l" (d_ptr)); return val; } 
#endif
# 193 "./ptx_custom.cu"
}; 
# 194
template<> struct TunedTexLoad< unsigned, CG>  { __attribute((always_inline)) static unsigned Ld(const unsigned *d_ptr) {int volatile ___ = 1;(void)d_ptr;::exit(___);}
#if 0
# 194
{ unsigned val; __asm__("ld.global.cg.nc.u32 %0, [%1];" : "=r" (val) : "l" (d_ptr)); return val; } 
#endif
# 194 "./ptx_custom.cu"
}; template<> struct TunedTexLoad< unsigned, CS>  { __attribute((always_inline)) static unsigned Ld(const unsigned *d_ptr) {int volatile ___ = 1;(void)d_ptr;::exit(___);}
#if 0
# 194
{ unsigned val; __asm__("ld.global.cs.nc.u32 %0, [%1];" : "=r" (val) : "l" (d_ptr)); return val; } 
#endif
# 194 "./ptx_custom.cu"
}; template<> struct TunedTexLoad< unsigned, CA>  { __attribute((always_inline)) static unsigned Ld(const unsigned *d_ptr) {int volatile ___ = 1;(void)d_ptr;::exit(___);}
#if 0
# 194
{ unsigned val; __asm__("ld.global.ca.nc.u32 %0, [%1];" : "=r" (val) : "l" (d_ptr)); return val; } 
#endif
# 194 "./ptx_custom.cu"
}; 
# 195
template<> struct TunedTexLoad< unsigned long, CG>  { __attribute((always_inline)) static unsigned long Ld(const unsigned long *d_ptr) {int volatile ___ = 1;(void)d_ptr;::exit(___);}
#if 0
# 195
{ unsigned long val; __asm__("ld.global.cg.nc.u64 %0, [%1];" : "=l" (val) : "l" (d_ptr)); return val; } 
#endif
# 195 "./ptx_custom.cu"
}; template<> struct TunedTexLoad< unsigned long, CS>  { __attribute((always_inline)) static unsigned long Ld(const unsigned long *d_ptr) {int volatile ___ = 1;(void)d_ptr;::exit(___);}
#if 0
# 195
{ unsigned long val; __asm__("ld.global.cs.nc.u64 %0, [%1];" : "=l" (val) : "l" (d_ptr)); return val; } 
#endif
# 195 "./ptx_custom.cu"
}; template<> struct TunedTexLoad< unsigned long, CA>  { __attribute((always_inline)) static unsigned long Ld(const unsigned long *d_ptr) {int volatile ___ = 1;(void)d_ptr;::exit(___);}
#if 0
# 195
{ unsigned long val; __asm__("ld.global.ca.nc.u64 %0, [%1];" : "=l" (val) : "l" (d_ptr)); return val; } 
#endif
# 195 "./ptx_custom.cu"
}; 
# 206
template< class T, CacheModifier CACHE_MODIFIER> struct TunedLoad; 
# 266
template<> struct TunedLoad< short, CG>  { __attribute((always_inline)) static void Ld(short &val, const short *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 266
{ __asm__("ld.global.cg.s16 %0, [%1];" : "=h" (val) : "l" (d_ptr)); } 
#endif
# 266 "./ptx_custom.cu"
}; template<> struct TunedLoad< short, CS>  { __attribute((always_inline)) static void Ld(short &val, const short *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 266
{ __asm__("ld.global.cs.s16 %0, [%1];" : "=h" (val) : "l" (d_ptr)); } 
#endif
# 266 "./ptx_custom.cu"
}; template<> struct TunedLoad< short, LU>  { __attribute((always_inline)) static void Ld(short &val, const short *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 266
{ __asm__("ld.global.lu.s16 %0, [%1];" : "=h" (val) : "l" (d_ptr)); } 
#endif
# 266 "./ptx_custom.cu"
}; template<> struct TunedLoad< short, CV>  { __attribute((always_inline)) static void Ld(short &val, const short *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 266
{ __asm__("ld.global.cv.s16 %0, [%1];" : "=h" (val) : "l" (d_ptr)); } 
#endif
# 266 "./ptx_custom.cu"
}; template<> struct TunedLoad< short, CA>  { __attribute((always_inline)) static void Ld(short &val, const short *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 266
{ __asm__("ld.global.ca.s16 %0, [%1];" : "=h" (val) : "l" (d_ptr)); } 
#endif
# 266 "./ptx_custom.cu"
}; 
# 267
template<> struct TunedLoad< int, CG>  { __attribute((always_inline)) static void Ld(int &val, const int *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 267
{ __asm__("ld.global.cg.s32 %0, [%1];" : "=r" (val) : "l" (d_ptr)); } 
#endif
# 267 "./ptx_custom.cu"
}; template<> struct TunedLoad< int, CS>  { __attribute((always_inline)) static void Ld(int &val, const int *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 267
{ __asm__("ld.global.cs.s32 %0, [%1];" : "=r" (val) : "l" (d_ptr)); } 
#endif
# 267 "./ptx_custom.cu"
}; template<> struct TunedLoad< int, LU>  { __attribute((always_inline)) static void Ld(int &val, const int *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 267
{ __asm__("ld.global.lu.s32 %0, [%1];" : "=r" (val) : "l" (d_ptr)); } 
#endif
# 267 "./ptx_custom.cu"
}; template<> struct TunedLoad< int, CV>  { __attribute((always_inline)) static void Ld(int &val, const int *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 267
{ __asm__("ld.global.cv.s32 %0, [%1];" : "=r" (val) : "l" (d_ptr)); } 
#endif
# 267 "./ptx_custom.cu"
}; template<> struct TunedLoad< int, CA>  { __attribute((always_inline)) static void Ld(int &val, const int *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 267
{ __asm__("ld.global.ca.s32 %0, [%1];" : "=r" (val) : "l" (d_ptr)); } 
#endif
# 267 "./ptx_custom.cu"
}; 
# 268
template<> struct TunedLoad< long, CG>  { __attribute((always_inline)) static void Ld(long &val, const long *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 268
{ __asm__("ld.global.cg.s64 %0, [%1];" : "=l" (val) : "l" (d_ptr)); } 
#endif
# 268 "./ptx_custom.cu"
}; template<> struct TunedLoad< long, CS>  { __attribute((always_inline)) static void Ld(long &val, const long *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 268
{ __asm__("ld.global.cs.s64 %0, [%1];" : "=l" (val) : "l" (d_ptr)); } 
#endif
# 268 "./ptx_custom.cu"
}; template<> struct TunedLoad< long, LU>  { __attribute((always_inline)) static void Ld(long &val, const long *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 268
{ __asm__("ld.global.lu.s64 %0, [%1];" : "=l" (val) : "l" (d_ptr)); } 
#endif
# 268 "./ptx_custom.cu"
}; template<> struct TunedLoad< long, CV>  { __attribute((always_inline)) static void Ld(long &val, const long *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 268
{ __asm__("ld.global.cv.s64 %0, [%1];" : "=l" (val) : "l" (d_ptr)); } 
#endif
# 268 "./ptx_custom.cu"
}; template<> struct TunedLoad< long, CA>  { __attribute((always_inline)) static void Ld(long &val, const long *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 268
{ __asm__("ld.global.ca.s64 %0, [%1];" : "=l" (val) : "l" (d_ptr)); } 
#endif
# 268 "./ptx_custom.cu"
}; 
# 269
template<> struct TunedLoad< long long, CG>  { __attribute((always_inline)) static void Ld(long long &val, const long long *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 269
{ __asm__("ld.global.cg.s64 %0, [%1];" : "=l" (val) : "l" (d_ptr)); } 
#endif
# 269 "./ptx_custom.cu"
}; template<> struct TunedLoad< long long, CS>  { __attribute((always_inline)) static void Ld(long long &val, const long long *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 269
{ __asm__("ld.global.cs.s64 %0, [%1];" : "=l" (val) : "l" (d_ptr)); } 
#endif
# 269 "./ptx_custom.cu"
}; template<> struct TunedLoad< long long, LU>  { __attribute((always_inline)) static void Ld(long long &val, const long long *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 269
{ __asm__("ld.global.lu.s64 %0, [%1];" : "=l" (val) : "l" (d_ptr)); } 
#endif
# 269 "./ptx_custom.cu"
}; template<> struct TunedLoad< long long, CV>  { __attribute((always_inline)) static void Ld(long long &val, const long long *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 269
{ __asm__("ld.global.cv.s64 %0, [%1];" : "=l" (val) : "l" (d_ptr)); } 
#endif
# 269 "./ptx_custom.cu"
}; template<> struct TunedLoad< long long, CA>  { __attribute((always_inline)) static void Ld(long long &val, const long long *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 269
{ __asm__("ld.global.ca.s64 %0, [%1];" : "=l" (val) : "l" (d_ptr)); } 
#endif
# 269 "./ptx_custom.cu"
}; 
# 271
template<> struct TunedLoad< unsigned short, CG>  { __attribute((always_inline)) static void Ld(unsigned short &val, const unsigned short *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 271
{ __asm__("ld.global.cg.u16 %0, [%1];" : "=h" (val) : "l" (d_ptr)); } 
#endif
# 271 "./ptx_custom.cu"
}; template<> struct TunedLoad< unsigned short, CS>  { __attribute((always_inline)) static void Ld(unsigned short &val, const unsigned short *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 271
{ __asm__("ld.global.cs.u16 %0, [%1];" : "=h" (val) : "l" (d_ptr)); } 
#endif
# 271 "./ptx_custom.cu"
}; template<> struct TunedLoad< unsigned short, LU>  { __attribute((always_inline)) static void Ld(unsigned short &val, const unsigned short *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 271
{ __asm__("ld.global.lu.u16 %0, [%1];" : "=h" (val) : "l" (d_ptr)); } 
#endif
# 271 "./ptx_custom.cu"
}; template<> struct TunedLoad< unsigned short, CV>  { __attribute((always_inline)) static void Ld(unsigned short &val, const unsigned short *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 271
{ __asm__("ld.global.cv.u16 %0, [%1];" : "=h" (val) : "l" (d_ptr)); } 
#endif
# 271 "./ptx_custom.cu"
}; template<> struct TunedLoad< unsigned short, CA>  { __attribute((always_inline)) static void Ld(unsigned short &val, const unsigned short *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 271
{ __asm__("ld.global.ca.u16 %0, [%1];" : "=h" (val) : "l" (d_ptr)); } 
#endif
# 271 "./ptx_custom.cu"
}; 
# 272
template<> struct TunedLoad< unsigned, CG>  { __attribute((always_inline)) static void Ld(unsigned &val, const unsigned *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 272
{ __asm__("ld.global.cg.u32 %0, [%1];" : "=r" (val) : "l" (d_ptr)); } 
#endif
# 272 "./ptx_custom.cu"
}; template<> struct TunedLoad< unsigned, CS>  { __attribute((always_inline)) static void Ld(unsigned &val, const unsigned *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 272
{ __asm__("ld.global.cs.u32 %0, [%1];" : "=r" (val) : "l" (d_ptr)); } 
#endif
# 272 "./ptx_custom.cu"
}; template<> struct TunedLoad< unsigned, LU>  { __attribute((always_inline)) static void Ld(unsigned &val, const unsigned *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 272
{ __asm__("ld.global.lu.u32 %0, [%1];" : "=r" (val) : "l" (d_ptr)); } 
#endif
# 272 "./ptx_custom.cu"
}; template<> struct TunedLoad< unsigned, CV>  { __attribute((always_inline)) static void Ld(unsigned &val, const unsigned *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 272
{ __asm__("ld.global.cv.u32 %0, [%1];" : "=r" (val) : "l" (d_ptr)); } 
#endif
# 272 "./ptx_custom.cu"
}; template<> struct TunedLoad< unsigned, CA>  { __attribute((always_inline)) static void Ld(unsigned &val, const unsigned *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 272
{ __asm__("ld.global.ca.u32 %0, [%1];" : "=r" (val) : "l" (d_ptr)); } 
#endif
# 272 "./ptx_custom.cu"
}; 
# 273
template<> struct TunedLoad< unsigned long, CG>  { __attribute((always_inline)) static void Ld(unsigned long &val, const unsigned long *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 273
{ __asm__("ld.global.cg.u64 %0, [%1];" : "=l" (val) : "l" (d_ptr)); } 
#endif
# 273 "./ptx_custom.cu"
}; template<> struct TunedLoad< unsigned long, CS>  { __attribute((always_inline)) static void Ld(unsigned long &val, const unsigned long *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 273
{ __asm__("ld.global.cs.u64 %0, [%1];" : "=l" (val) : "l" (d_ptr)); } 
#endif
# 273 "./ptx_custom.cu"
}; template<> struct TunedLoad< unsigned long, LU>  { __attribute((always_inline)) static void Ld(unsigned long &val, const unsigned long *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 273
{ __asm__("ld.global.lu.u64 %0, [%1];" : "=l" (val) : "l" (d_ptr)); } 
#endif
# 273 "./ptx_custom.cu"
}; template<> struct TunedLoad< unsigned long, CV>  { __attribute((always_inline)) static void Ld(unsigned long &val, const unsigned long *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 273
{ __asm__("ld.global.cv.u64 %0, [%1];" : "=l" (val) : "l" (d_ptr)); } 
#endif
# 273 "./ptx_custom.cu"
}; template<> struct TunedLoad< unsigned long, CA>  { __attribute((always_inline)) static void Ld(unsigned long &val, const unsigned long *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 273
{ __asm__("ld.global.ca.u64 %0, [%1];" : "=l" (val) : "l" (d_ptr)); } 
#endif
# 273 "./ptx_custom.cu"
}; 
# 274
template<> struct TunedLoad< unsigned long long, CG>  { __attribute((always_inline)) static void Ld(unsigned long long &val, const unsigned long long *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 274
{ __asm__("ld.global.cg.u64 %0, [%1];" : "=l" (val) : "l" (d_ptr)); } 
#endif
# 274 "./ptx_custom.cu"
}; template<> struct TunedLoad< unsigned long long, CS>  { __attribute((always_inline)) static void Ld(unsigned long long &val, const unsigned long long *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 274
{ __asm__("ld.global.cs.u64 %0, [%1];" : "=l" (val) : "l" (d_ptr)); } 
#endif
# 274 "./ptx_custom.cu"
}; template<> struct TunedLoad< unsigned long long, LU>  { __attribute((always_inline)) static void Ld(unsigned long long &val, const unsigned long long *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 274
{ __asm__("ld.global.lu.u64 %0, [%1];" : "=l" (val) : "l" (d_ptr)); } 
#endif
# 274 "./ptx_custom.cu"
}; template<> struct TunedLoad< unsigned long long, CV>  { __attribute((always_inline)) static void Ld(unsigned long long &val, const unsigned long long *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 274
{ __asm__("ld.global.cv.u64 %0, [%1];" : "=l" (val) : "l" (d_ptr)); } 
#endif
# 274 "./ptx_custom.cu"
}; template<> struct TunedLoad< unsigned long long, CA>  { __attribute((always_inline)) static void Ld(unsigned long long &val, const unsigned long long *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 274
{ __asm__("ld.global.ca.u64 %0, [%1];" : "=l" (val) : "l" (d_ptr)); } 
#endif
# 274 "./ptx_custom.cu"
}; 
# 275
template<> struct TunedLoad< float, CG>  { __attribute((always_inline)) static void Ld(float &val, const float *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 275
{ __asm__("ld.global.cg.f32 %0, [%1];" : "=f" (val) : "l" (d_ptr)); } 
#endif
# 275 "./ptx_custom.cu"
}; template<> struct TunedLoad< float, CS>  { __attribute((always_inline)) static void Ld(float &val, const float *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 275
{ __asm__("ld.global.cs.f32 %0, [%1];" : "=f" (val) : "l" (d_ptr)); } 
#endif
# 275 "./ptx_custom.cu"
}; template<> struct TunedLoad< float, LU>  { __attribute((always_inline)) static void Ld(float &val, const float *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 275
{ __asm__("ld.global.lu.f32 %0, [%1];" : "=f" (val) : "l" (d_ptr)); } 
#endif
# 275 "./ptx_custom.cu"
}; template<> struct TunedLoad< float, CV>  { __attribute((always_inline)) static void Ld(float &val, const float *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 275
{ __asm__("ld.global.cv.f32 %0, [%1];" : "=f" (val) : "l" (d_ptr)); } 
#endif
# 275 "./ptx_custom.cu"
}; template<> struct TunedLoad< float, CA>  { __attribute((always_inline)) static void Ld(float &val, const float *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 275
{ __asm__("ld.global.ca.f32 %0, [%1];" : "=f" (val) : "l" (d_ptr)); } 
#endif
# 275 "./ptx_custom.cu"
}; 
# 276
template<> struct TunedLoad< double, CG>  { __attribute((always_inline)) static void Ld(double &val, const double *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 276
{ __asm__("ld.global.cg.f64 %0, [%1];" : "=d" (val) : "l" (d_ptr)); } 
#endif
# 276 "./ptx_custom.cu"
}; template<> struct TunedLoad< double, CS>  { __attribute((always_inline)) static void Ld(double &val, const double *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 276
{ __asm__("ld.global.cs.f64 %0, [%1];" : "=d" (val) : "l" (d_ptr)); } 
#endif
# 276 "./ptx_custom.cu"
}; template<> struct TunedLoad< double, LU>  { __attribute((always_inline)) static void Ld(double &val, const double *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 276
{ __asm__("ld.global.lu.f64 %0, [%1];" : "=d" (val) : "l" (d_ptr)); } 
#endif
# 276 "./ptx_custom.cu"
}; template<> struct TunedLoad< double, CV>  { __attribute((always_inline)) static void Ld(double &val, const double *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 276
{ __asm__("ld.global.cv.f64 %0, [%1];" : "=d" (val) : "l" (d_ptr)); } 
#endif
# 276 "./ptx_custom.cu"
}; template<> struct TunedLoad< double, CA>  { __attribute((always_inline)) static void Ld(double &val, const double *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 276
{ __asm__("ld.global.ca.f64 %0, [%1];" : "=d" (val) : "l" (d_ptr)); } 
#endif
# 276 "./ptx_custom.cu"
}; 
# 279
template< class T, CacheModifier CACHE_MODIFIER> struct TunedStore; 
# 327
template<> struct TunedStore< short, CG>  { __attribute((always_inline)) static void St(const short &val, short *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 327
{ __asm__("st.global.cg.s16 [%0], %1;" : : "l" (d_ptr), "h" (val)); } 
#endif
# 327 "./ptx_custom.cu"
}; template<> struct TunedStore< short, CS>  { __attribute((always_inline)) static void St(const short &val, short *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 327
{ __asm__("st.global.cs.s16 [%0], %1;" : : "l" (d_ptr), "h" (val)); } 
#endif
# 327 "./ptx_custom.cu"
}; template<> struct TunedStore< short, WT>  { __attribute((always_inline)) static void St(const short &val, short *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 327
{ __asm__("st.global.wt.s16 [%0], %1;" : : "l" (d_ptr), "h" (val)); } 
#endif
# 327 "./ptx_custom.cu"
}; template<> struct TunedStore< short, WB>  { __attribute((always_inline)) static void St(const short &val, short *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 327
{ __asm__("st.global.wb.s16 [%0], %1;" : : "l" (d_ptr), "h" (val)); } 
#endif
# 327 "./ptx_custom.cu"
}; 
# 328
template<> struct TunedStore< int, CG>  { __attribute((always_inline)) static void St(const int &val, int *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 328
{ __asm__("st.global.cg.s32 [%0], %1;" : : "l" (d_ptr), "r" (val)); } 
#endif
# 328 "./ptx_custom.cu"
}; template<> struct TunedStore< int, CS>  { __attribute((always_inline)) static void St(const int &val, int *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 328
{ __asm__("st.global.cs.s32 [%0], %1;" : : "l" (d_ptr), "r" (val)); } 
#endif
# 328 "./ptx_custom.cu"
}; template<> struct TunedStore< int, WT>  { __attribute((always_inline)) static void St(const int &val, int *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 328
{ __asm__("st.global.wt.s32 [%0], %1;" : : "l" (d_ptr), "r" (val)); } 
#endif
# 328 "./ptx_custom.cu"
}; template<> struct TunedStore< int, WB>  { __attribute((always_inline)) static void St(const int &val, int *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 328
{ __asm__("st.global.wb.s32 [%0], %1;" : : "l" (d_ptr), "r" (val)); } 
#endif
# 328 "./ptx_custom.cu"
}; 
# 329
template<> struct TunedStore< long, CG>  { __attribute((always_inline)) static void St(const long &val, long *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 329
{ __asm__("st.global.cg.s64 [%0], %1;" : : "l" (d_ptr), "l" (val)); } 
#endif
# 329 "./ptx_custom.cu"
}; template<> struct TunedStore< long, CS>  { __attribute((always_inline)) static void St(const long &val, long *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 329
{ __asm__("st.global.cs.s64 [%0], %1;" : : "l" (d_ptr), "l" (val)); } 
#endif
# 329 "./ptx_custom.cu"
}; template<> struct TunedStore< long, WT>  { __attribute((always_inline)) static void St(const long &val, long *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 329
{ __asm__("st.global.wt.s64 [%0], %1;" : : "l" (d_ptr), "l" (val)); } 
#endif
# 329 "./ptx_custom.cu"
}; template<> struct TunedStore< long, WB>  { __attribute((always_inline)) static void St(const long &val, long *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 329
{ __asm__("st.global.wb.s64 [%0], %1;" : : "l" (d_ptr), "l" (val)); } 
#endif
# 329 "./ptx_custom.cu"
}; 
# 330
template<> struct TunedStore< long long, CG>  { __attribute((always_inline)) static void St(const long long &val, long long *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 330
{ __asm__("st.global.cg.s64 [%0], %1;" : : "l" (d_ptr), "l" (val)); } 
#endif
# 330 "./ptx_custom.cu"
}; template<> struct TunedStore< long long, CS>  { __attribute((always_inline)) static void St(const long long &val, long long *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 330
{ __asm__("st.global.cs.s64 [%0], %1;" : : "l" (d_ptr), "l" (val)); } 
#endif
# 330 "./ptx_custom.cu"
}; template<> struct TunedStore< long long, WT>  { __attribute((always_inline)) static void St(const long long &val, long long *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 330
{ __asm__("st.global.wt.s64 [%0], %1;" : : "l" (d_ptr), "l" (val)); } 
#endif
# 330 "./ptx_custom.cu"
}; template<> struct TunedStore< long long, WB>  { __attribute((always_inline)) static void St(const long long &val, long long *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 330
{ __asm__("st.global.wb.s64 [%0], %1;" : : "l" (d_ptr), "l" (val)); } 
#endif
# 330 "./ptx_custom.cu"
}; 
# 332
template<> struct TunedStore< unsigned short, CG>  { __attribute((always_inline)) static void St(const unsigned short &val, unsigned short *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 332
{ __asm__("st.global.cg.u16 [%0], %1;" : : "l" (d_ptr), "h" (val)); } 
#endif
# 332 "./ptx_custom.cu"
}; template<> struct TunedStore< unsigned short, CS>  { __attribute((always_inline)) static void St(const unsigned short &val, unsigned short *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 332
{ __asm__("st.global.cs.u16 [%0], %1;" : : "l" (d_ptr), "h" (val)); } 
#endif
# 332 "./ptx_custom.cu"
}; template<> struct TunedStore< unsigned short, WT>  { __attribute((always_inline)) static void St(const unsigned short &val, unsigned short *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 332
{ __asm__("st.global.wt.u16 [%0], %1;" : : "l" (d_ptr), "h" (val)); } 
#endif
# 332 "./ptx_custom.cu"
}; template<> struct TunedStore< unsigned short, WB>  { __attribute((always_inline)) static void St(const unsigned short &val, unsigned short *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 332
{ __asm__("st.global.wb.u16 [%0], %1;" : : "l" (d_ptr), "h" (val)); } 
#endif
# 332 "./ptx_custom.cu"
}; 
# 333
template<> struct TunedStore< unsigned, CG>  { __attribute((always_inline)) static void St(const unsigned &val, unsigned *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 333
{ __asm__("st.global.cg.u32 [%0], %1;" : : "l" (d_ptr), "r" (val)); } 
#endif
# 333 "./ptx_custom.cu"
}; template<> struct TunedStore< unsigned, CS>  { __attribute((always_inline)) static void St(const unsigned &val, unsigned *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 333
{ __asm__("st.global.cs.u32 [%0], %1;" : : "l" (d_ptr), "r" (val)); } 
#endif
# 333 "./ptx_custom.cu"
}; template<> struct TunedStore< unsigned, WT>  { __attribute((always_inline)) static void St(const unsigned &val, unsigned *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 333
{ __asm__("st.global.wt.u32 [%0], %1;" : : "l" (d_ptr), "r" (val)); } 
#endif
# 333 "./ptx_custom.cu"
}; template<> struct TunedStore< unsigned, WB>  { __attribute((always_inline)) static void St(const unsigned &val, unsigned *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 333
{ __asm__("st.global.wb.u32 [%0], %1;" : : "l" (d_ptr), "r" (val)); } 
#endif
# 333 "./ptx_custom.cu"
}; 
# 334
template<> struct TunedStore< unsigned long, CG>  { __attribute((always_inline)) static void St(const unsigned long &val, unsigned long *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 334
{ __asm__("st.global.cg.u64 [%0], %1;" : : "l" (d_ptr), "l" (val)); } 
#endif
# 334 "./ptx_custom.cu"
}; template<> struct TunedStore< unsigned long, CS>  { __attribute((always_inline)) static void St(const unsigned long &val, unsigned long *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 334
{ __asm__("st.global.cs.u64 [%0], %1;" : : "l" (d_ptr), "l" (val)); } 
#endif
# 334 "./ptx_custom.cu"
}; template<> struct TunedStore< unsigned long, WT>  { __attribute((always_inline)) static void St(const unsigned long &val, unsigned long *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 334
{ __asm__("st.global.wt.u64 [%0], %1;" : : "l" (d_ptr), "l" (val)); } 
#endif
# 334 "./ptx_custom.cu"
}; template<> struct TunedStore< unsigned long, WB>  { __attribute((always_inline)) static void St(const unsigned long &val, unsigned long *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 334
{ __asm__("st.global.wb.u64 [%0], %1;" : : "l" (d_ptr), "l" (val)); } 
#endif
# 334 "./ptx_custom.cu"
}; 
# 335
template<> struct TunedStore< unsigned long long, CG>  { __attribute((always_inline)) static void St(const unsigned long long &val, unsigned long long *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 335
{ __asm__("st.global.cg.u64 [%0], %1;" : : "l" (d_ptr), "l" (val)); } 
#endif
# 335 "./ptx_custom.cu"
}; template<> struct TunedStore< unsigned long long, CS>  { __attribute((always_inline)) static void St(const unsigned long long &val, unsigned long long *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 335
{ __asm__("st.global.cs.u64 [%0], %1;" : : "l" (d_ptr), "l" (val)); } 
#endif
# 335 "./ptx_custom.cu"
}; template<> struct TunedStore< unsigned long long, WT>  { __attribute((always_inline)) static void St(const unsigned long long &val, unsigned long long *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 335
{ __asm__("st.global.wt.u64 [%0], %1;" : : "l" (d_ptr), "l" (val)); } 
#endif
# 335 "./ptx_custom.cu"
}; template<> struct TunedStore< unsigned long long, WB>  { __attribute((always_inline)) static void St(const unsigned long long &val, unsigned long long *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 335
{ __asm__("st.global.wb.u64 [%0], %1;" : : "l" (d_ptr), "l" (val)); } 
#endif
# 335 "./ptx_custom.cu"
}; 
# 336
template<> struct TunedStore< float, CG>  { __attribute((always_inline)) static void St(const float &val, float *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 336
{ __asm__("st.global.cg.f32 [%0], %1;" : : "l" (d_ptr), "f" (val)); } 
#endif
# 336 "./ptx_custom.cu"
}; template<> struct TunedStore< float, CS>  { __attribute((always_inline)) static void St(const float &val, float *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 336
{ __asm__("st.global.cs.f32 [%0], %1;" : : "l" (d_ptr), "f" (val)); } 
#endif
# 336 "./ptx_custom.cu"
}; template<> struct TunedStore< float, WT>  { __attribute((always_inline)) static void St(const float &val, float *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 336
{ __asm__("st.global.wt.f32 [%0], %1;" : : "l" (d_ptr), "f" (val)); } 
#endif
# 336 "./ptx_custom.cu"
}; template<> struct TunedStore< float, WB>  { __attribute((always_inline)) static void St(const float &val, float *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 336
{ __asm__("st.global.wb.f32 [%0], %1;" : : "l" (d_ptr), "f" (val)); } 
#endif
# 336 "./ptx_custom.cu"
}; 
# 337
template<> struct TunedStore< double, CG>  { __attribute((always_inline)) static void St(const double &val, double *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 337
{ __asm__("st.global.cg.f64 [%0], %1;" : : "l" (d_ptr), "d" (val)); } 
#endif
# 337 "./ptx_custom.cu"
}; template<> struct TunedStore< double, CS>  { __attribute((always_inline)) static void St(const double &val, double *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 337
{ __asm__("st.global.cs.f64 [%0], %1;" : : "l" (d_ptr), "d" (val)); } 
#endif
# 337 "./ptx_custom.cu"
}; template<> struct TunedStore< double, WT>  { __attribute((always_inline)) static void St(const double &val, double *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 337
{ __asm__("st.global.wt.f64 [%0], %1;" : : "l" (d_ptr), "d" (val)); } 
#endif
# 337 "./ptx_custom.cu"
}; template<> struct TunedStore< double, WB>  { __attribute((always_inline)) static void St(const double &val, double *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 337
{ __asm__("st.global.wb.f64 [%0], %1;" : : "l" (d_ptr), "d" (val)); } 
#endif
# 337 "./ptx_custom.cu"
}; 
# 346
__attribute((always_inline)) __attribute__((unused)) inline int popc_instr_b32(unsigned x) {int volatile ___ = 1;(void)x;::exit(___);}
#if 0
# 346
{ int ret; __asm__("popc.b32 %0,%1;\n\t" : "=r" (ret) : "r" (x)); return ret; } 
#endif
# 347 "./ptx_custom.cu"
__attribute((always_inline)) __attribute__((unused)) inline int popc_instr_b64(unsigned long long x) {int volatile ___ = 1;(void)x;::exit(___);}
#if 0
# 347
{ int ret; __asm__("popc.b64 %0,%1;\n\t" : "=r" (ret) : "l" (x)); return ret; } 
#endif
# 357 "./ptx_custom.cu"
__attribute((always_inline)) __attribute__((unused)) static inline void ExtractKeyBits(int bit_start, int num_bits, unsigned &bits, const unsigned &source) {int volatile ___ = 1;(void)bit_start;(void)num_bits;(void)bits;(void)source;::exit(___);}
#if 0
# 357
{ __asm__("bfe.u32  %0, %1, %2, %3;" : "=r" (bits) : "r" (source), "r" (bit_start), "r" (num_bits)); } 
#endif
# 358 "./ptx_custom.cu"
__attribute((always_inline)) __attribute__((unused)) static inline void ExtractKeyBits(int bit_start, int num_bits, unsigned long long &bits, const unsigned long long &source) {int volatile ___ = 1;(void)bit_start;(void)num_bits;(void)bits;(void)source;::exit(___);}
#if 0
# 358
{ __asm__("bfe.u64  %0, %1, %2, %3;" : "=l" (bits) : "l" (source), "r" (bit_start), "r" (num_bits)); } 
#endif
# 367 "./ptx_custom.cu"
__attribute((always_inline)) __attribute__((unused)) inline void mirror_bitmap(unsigned &reversed, unsigned input) {int volatile ___ = 1;(void)reversed;(void)input;::exit(___);}
#if 0
# 367
{ __asm__("brev.b32 %0, %1;" : "=r" (reversed) : "r" (input)); } 
#endif
# 368 "./ptx_custom.cu"
__attribute((always_inline)) __attribute__((unused)) inline void mirror_bitmap(unsigned long long &reversed, unsigned long long input) {int volatile ___ = 1;(void)reversed;(void)input;::exit(___);}
#if 0
# 368
{ __asm__("brev.b64 %0, %1;" : "=l" (reversed) : "l" (input)); } 
#endif
# 381 "./ptx_custom.cu"
enum reductionOp { 
# 382
AND, OR, XOR, 
# 383
add, 
# 384
INC, DEC, 
# 385
MIN, MAX
# 386
}; 
# 388
template< class T, reductionOp REDUCTION_OP> struct OptimizedReduction; 
# 399
template<> struct OptimizedReduction< unsigned, AND>  { __attribute((always_inline)) static void Barrier(const unsigned &val, unsigned *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 399
{ __asm__("red.and.b32 [%0], %1;" : : "l" (d_ptr), "r" (val)); } 
#endif
# 399 "./ptx_custom.cu"
}; 
# 400
template<> struct OptimizedReduction< unsigned, OR>  { __attribute((always_inline)) static void Barrier(const unsigned &val, unsigned *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 400
{ __asm__("red.or.b32 [%0], %1;" : : "l" (d_ptr), "r" (val)); } 
#endif
# 400 "./ptx_custom.cu"
}; 
# 401
template<> struct OptimizedReduction< unsigned, XOR>  { __attribute((always_inline)) static void Barrier(const unsigned &val, unsigned *d_ptr) {int volatile ___ = 1;(void)val;(void)d_ptr;::exit(___);}
#if 0
# 401
{ __asm__("red.xor.b32 [%0], %1;" : : "l" (d_ptr), "r" (val)); } 
#endif
# 401 "./ptx_custom.cu"
}; 
# 21 "./gpu_charge_kernel.cu"
__attribute((noinline)) __attribute__((unused)) int fixed_d(double d, int exponent) 
# 22
{int volatile ___ = 1;(void)d;(void)exponent;
# 44
::exit(___);}
#if 0
# 22
{ 
# 23
if (d == (0)) { return 0L; }  
# 25
long long *p_d = (long long *)(&d); 
# 26
long long exp_mask = (9218868437227405312L); 
# 27
long long significand_mask = (4503599627370495L); 
# 28
long long positive_prefix = (4503599627370496L); 
# 29
int r; 
# 31
int e = ((*p_d) & exp_mask) >> 52; 
# 32
long long s; 
# 33
s = (((*p_d) & significand_mask) | positive_prefix); 
# 35
int shift_amt = exponent - e; 
# 36
if (shift_amt > 0) { s = (s >> shift_amt); } else { 
# 37
s = (s << (-shift_amt)); }  
# 39
r = (*(((int *)(&s)) + 1)); 
# 40
if ((*p_d) < (0)) { r = (-r); }  
# 43
return r; 
# 44
} 
#endif
# 46 "./gpu_charge_kernel.cu"
__attribute((noinline)) __attribute__((unused)) double fp_d(int s, int e) 
# 47
{int volatile ___ = 1;(void)s;(void)e;
# 80
::exit(___);}
#if 0
# 47
{ 
# 48
int negative = 0; 
# 49
double r; 
# 50
long long sl; 
# 52
if (s == 0) { return (0.0); } else { 
# 53
if (s < 0) { negative = 1; s = (-s); }  }  
# 55
sl = (((long long)s) << 32); 
# 56
long long one = (4503599627370496L); 
# 59
if (sl < one) { 
# 60
do { 
# 61
sl = (sl << 1); e--; 
# 63
} while (sl < one); 
# 64
} else { 
# 65
if (sl > one) { 
# 66
do { 
# 67
sl = (sl >> 1); e++; 
# 69
} while (sl >= one); 
# 70
sl = (sl << 1); e--; 
# 71
}  }  
# 73
long long exp = ((long long)e) << 52; 
# 75
sl = ((sl & (~one)) | exp); 
# 77
r = (*((double *)(&sl))); 
# 78
if (negative) { return -r; } else { 
# 79
return r; }  
# 80
} 
#endif
# 94 "./gpu_charge_kernel.cu"
__attribute((noinline)) __attribute__((unused)) double atomicDPupdate(double *address, double val) 
# 95
{int volatile ___ = 1;(void)address;(void)val;
# 103
::exit(___);}
#if 0
# 95
{ 
# 96
double old = *address, assumed; 
# 97
do { assumed = old; 
# 98
old = __longlong_as_double(atomicCAS((unsigned long long *)address, __double_as_longlong(assumed), __double_as_longlong(val + assumed))); 
# 101
} while (assumed != old); 
# 102
return old; 
# 103
} 
#endif
# 105 "./gpu_charge_kernel.cu"
__attribute((noinline)) __attribute__((unused)) void atomicFPupdate(float *addr, float delta) 
# 106
{int volatile ___ = 1;(void)addr;(void)delta;
# 116
::exit(___);}
#if 0
# 106
{ 
# 107
float copied; 
# 108
float updated; 
# 109
int *c_ptr = (int *)(&copied), *n_ptr = (int *)(&updated); 
# 111
do { 
# 112
copied = (*addr); 
# 113
updated = (copied + delta); 
# 114
} while (atomicCAS((int *)addr, *c_ptr, *n_ptr) != (*c_ptr)); 
# 116
} 
#endif
# 118 "./gpu_charge_kernel.cu"
__attribute__((unused)) inline int d_abs_min_int(int arg1, int arg2) {int volatile ___ = 1;(void)arg1;(void)arg2;
# 124
::exit(___);}
#if 0
# 118
{ 
# 120
int minval, retval; 
# 121
minval = ((arg1 < arg2) ? arg1 : arg2); 
# 122
retval = ((minval > 0) ? minval : 0); 
# 123
return retval; 
# 124
} 
#endif
# 126 "./gpu_charge_kernel.cu"
__attribute__((unused)) inline real d_abs_min_real(real arg1, real arg2) {int volatile ___ = 1;(void)arg1;(void)arg2;
# 132
::exit(___);}
#if 0
# 126
{ 
# 128
real minval, retval; 
# 129
minval = ((arg1 < arg2) ? arg1 : arg2); 
# 130
retval = ((minval > (0)) ? minval : (0)); 
# 131
return retval; 
# 132
} 
#endif
# 134 "./gpu_charge_kernel.cu"
__attribute__((unused)) inline void swap(int &a, int &b) 
# 135
{int volatile ___ = 1;(void)a;(void)b;
# 139
::exit(___);}
#if 0
# 135
{ 
# 136
int tmp = a; 
# 137
a = b; 
# 138
b = tmp; 
# 139
} 
#endif
# 144 "./gpu_charge_kernel.cu"
static void gpu_charge_multi(gtc_field_data_t *grid, gtc_particle_data_t *zion, gtc_aux_particle_data_t *aux_zion, int mi_per_thread) ;
#if 0
# 144
{ 
# 146
const int tid = __device_builtin_variable_threadIdx.x; 
# 147
const int bid = __device_builtin_variable_blockIdx.x; 
# 148
const int nblocks = __device_builtin_variable_gridDim.x; 
# 149
const int nthreads = __device_builtin_variable_blockDim.x; 
# 150
const int gid = tid + (bid * nthreads); 
# 151
const int np = nblocks * nthreads; 
# 153
const real *__restrict__ zion0; const real *__restrict__ zion1; const real *__restrict__ zion2; 
# 154
const real *__restrict__ zion4; const real *__restrict__ zion5; 
# 162
const real *__restrict__ pgyro; const real *__restrict__ tgyro; 
# 163
int ipjt, idx1; 
# 175
real *densityi; 
# 182
int mi; real smu_inv; real a0; 
# 183
real a1; real delr; real delz; int mpsi; 
# 184
real pi2_inv; real zetamin; int mzeta; 
# 187
real psitmp, thetatmp, zetatmp, weight, rhoi, rhotmp, rho_max, r, wzt, wz1, wz0; 
# 188
int iptmp, ip, jttmp, jt, kk, ii, im, im2, larmor, idx; 
# 189
real rdum, wp1, wp0, tflr; 
# 190
int j01, j00, jtion0tmp, jtion1tmp, ij1, ij2, mpsi_max; 
# 191
real tdumtmp, tdum, tdumtmp2, tdum2, wt10, wt00, wt01, wt11, wtion0tmp, wtion1tmp; 
# 192
real r_diff, a_diff; 
# 194
int igrid_in, ipsi_in, ipsi_out, nloc_over, ipsi_valid_in, ipsi_valid_out; 
# 196
mpsi = (params.mpsi); 
# 197
a0 = (params.a0); a1 = (params.a1); 
# 198
delr = (params.delr); 
# 199
delz = (params.delz); 
# 200
smu_inv = (params.smu_inv); 
# 201
zetamin = (params.zetamin); mzeta = (params.mzeta); 
# 202
pi2_inv = (params.pi2_inv); 
# 203
mi = (params.mi); 
# 205
igrid_in = (radial_decomp.igrid_in); 
# 206
ipsi_in = (radial_decomp.ipsi_in); 
# 207
ipsi_out = (radial_decomp.ipsi_out); 
# 208
nloc_over = (radial_decomp.nloc_over); 
# 209
ipsi_valid_in = (radial_decomp.ipsi_valid_in); 
# 210
ipsi_valid_out = (radial_decomp.ipsi_valid_out); 
# 211
rho_max = (radial_decomp.rho_max); 
# 225
densityi = (grid->densityi); 
# 227
a_diff = (a1 - a0); 
# 228
mpsi_max = (mpsi - 1); 
# 239
pgyro = (grid->pgyro); tgyro = (grid->tgyro); 
# 242
zion0 = (zion->z0); zion1 = (zion->z1); zion2 = (zion->z2); zion4 = (zion->z4); 
# 243
zion5 = (zion->z5); 
# 245
for (int m = gid; m < mi; m += np) { 
# 247
psitmp = (zion0[m]); 
# 248
thetatmp = (zion1[m]); 
# 249
zetatmp = (zion2[m]); 
# 250
weight = (zion4[m]); 
# 251
rhoi = ((zion5[m]) * smu_inv); 
# 254
r = psitmp; 
# 259
iptmp = ((int)(((r - a0) * delr) + (0.5))); 
# 260
ip = d_abs_min_int(mpsi, iptmp); 
# 267
jttmp = ((int)(((thetatmp * pi2_inv) * ((delt)[ip])) + (0.5))); 
# 268
jt = d_abs_min_int((mtheta)[ip], jttmp); 
# 270
wzt = ((zetatmp - zetamin) * delz); 
# 271
kk = d_abs_min_int(mzeta - 1, (int)wzt); 
# 280
wz1 = (weight * (wzt - ((real)kk))); 
# 281
wz0 = (weight - wz1); 
# 282
r_diff = (r - a0); 
# 303
ipjt = (((igrid)[ip]) + jt); 
# 306
for (larmor = 0; larmor < 4; larmor++) { 
# 323
idx1 = (larmor + (4 * (ipjt - igrid_in))); 
# 324
rhotmp = (rhoi * (pgyro[idx1])); 
# 325
if (fabs(rhotmp) > rho_max) { 
# 326
printf("warning: reducing rhoi to %e from %e\n", ((rhotmp / fabs(rhotmp)) * rho_max) / (pgyro[idx1]), rhotmp); 
# 328
rhotmp = ((rhotmp / fabs(rhotmp)) * rho_max); 
# 329
rhoi = (rhotmp / (pgyro[idx1])); 
# 330
}  
# 331
rdum = (delr * d_abs_min_real(a_diff, r_diff + rhotmp)); 
# 333
tflr = (thetatmp + (rhoi * (tgyro[idx1]))); 
# 336
ii = d_abs_min_int(mpsi_max, (int)rdum); 
# 341
wp1 = (rdum - ((real)ii)); 
# 342
wp0 = ((1.0) - wp1); 
# 345
im = ii; 
# 346
tdumtmp = ((pi2_inv * (tflr - (zetatmp * ((qtinv)[im])))) + (10.0)); 
# 347
tdum = ((tdumtmp - ((int)tdumtmp)) * ((delt)[im])); 
# 348
j00 = d_abs_min_int(((mtheta)[im]) - 1, (int)tdum); 
# 349
jtion0tmp = (((igrid)[im]) + j00); 
# 350
wtion0tmp = (tdum - ((real)j00)); 
# 353
im2 = (ii + 1); 
# 354
tdumtmp2 = ((pi2_inv * (tflr - (zetatmp * ((qtinv)[im2])))) + (10.0)); 
# 355
tdum2 = ((tdumtmp2 - ((int)tdumtmp2)) * ((delt)[im2])); 
# 356
j01 = d_abs_min_int(((mtheta)[im2]) - 1, (int)tdum2); 
# 357
jtion1tmp = (((igrid)[im2]) + j01); 
# 358
wtion1tmp = (tdum2 - ((real)j01)); 
# 377
wt10 = (wp0 * wtion0tmp); 
# 378
wt00 = (wp0 - wt10); 
# 380
wt11 = (wp1 * wtion1tmp); 
# 381
wt01 = (wp1 - wt11); 
# 383
ij1 = (kk + ((mzeta + 1) * (jtion0tmp - igrid_in))); 
# 385
atomicDPupdate(densityi + ij1, wz0 * wt00); 
# 386
atomicDPupdate((densityi + ij1) + 1, wz1 * wt00); 
# 387
atomicDPupdate(((densityi + ij1) + mzeta) + 1, wz0 * wt10); 
# 388
atomicDPupdate(((densityi + ij1) + mzeta) + 2, wz1 * wt10); 
# 390
ij2 = (kk + ((mzeta + 1) * (jtion1tmp - igrid_in))); 
# 391
atomicDPupdate(densityi + ij2, wz0 * wt01); 
# 392
atomicDPupdate((densityi + ij2) + 1, wz1 * wt01); 
# 393
atomicDPupdate(((densityi + ij2) + mzeta) + 1, wz0 * wt11); 
# 394
atomicDPupdate(((densityi + ij2) + mzeta) + 2, wz1 * wt11); 
# 396
}  
# 397
}  
# 398
} 
#endif
# 405 "./gpu_charge_kernel.cu"
static void gpu_charge_cooperative(gtc_field_data_t *grid, gtc_particle_data_t *zion, gtc_aux_particle_data_t *aux_zion, int mi_per_thread) ;
#if 0
# 405
{ 
# 407
const int tid = __device_builtin_variable_threadIdx.x; 
# 408
const int bid = __device_builtin_variable_blockIdx.x; 
# 409
const int nblocks = __device_builtin_variable_gridDim.x; 
# 410
const int nthreads = __device_builtin_variable_blockDim.x; 
# 411
const int gid = tid + (bid * nthreads); 
# 412
const int np = nblocks * nthreads; 
# 415
__syncthreads(); 
# 418
__attribute__((unused)) extern int shared_buffer[]; 
# 419
int *update_idx = shared_buffer; 
# 420
real *update_val = (real *)(&((shared_buffer)[nthreads * 4])); 
# 426
const real *__restrict__ zion0; const real *__restrict__ zion1; const real *__restrict__ zion2; 
# 427
const real *__restrict__ zion4; const real *__restrict__ zion5; 
# 435
const real *__restrict__ pgyro; const real *__restrict__ tgyro; 
# 436
int ipjt, idx1; 
# 448
real *__restrict__ densityi; 
# 455
int mi; real smu_inv; real a0; 
# 456
real a1; real delr; real delz; int mpsi; 
# 457
real pi2_inv; real zetamin; int mzeta; 
# 460
real psitmp, thetatmp, zetatmp, weight, rhoi, rhotmp, rho_max, r, wzt, wz1, wz0; 
# 461
int iptmp, ip, jttmp, jt, kk, ii, im, larmor, idx; 
# 462
real rdum, wp1, wp0, tflr; 
# 463
int j01, j00, jtion0tmp, jtion1tmp, ij1, ij2, mpsi_max; 
# 464
real tdumtmp, tdum, wt10, wt00, wt01, wt11, wtion0tmp, wtion1tmp; 
# 465
real r_diff, a_diff; 
# 466
int stride; 
# 467
int last_gthreads, last_threads, last_block, total_iterations; 
# 469
int igrid_in, ipsi_in, ipsi_out; 
# 471
mpsi = (params.mpsi); 
# 472
a0 = (params.a0); a1 = (params.a1); 
# 473
delr = (params.delr); 
# 474
delz = (params.delz); 
# 475
smu_inv = (params.smu_inv); 
# 476
zetamin = (params.zetamin); mzeta = (params.mzeta); 
# 477
pi2_inv = (params.pi2_inv); 
# 478
mi = (params.mi); 
# 480
igrid_in = (radial_decomp.igrid_in); 
# 481
ipsi_in = (radial_decomp.ipsi_in); 
# 482
ipsi_out = (radial_decomp.ipsi_out); 
# 483
rho_max = (radial_decomp.rho_max); 
# 494
densityi = (grid->densityi); 
# 502
a_diff = (a1 - a0); 
# 503
mpsi_max = (mpsi - 1); 
# 514
pgyro = (grid->pgyro); tgyro = (grid->tgyro); 
# 517
zion0 = (zion->z0); zion1 = (zion->z1); zion2 = (zion->z2); zion4 = (zion->z4); 
# 518
zion5 = (zion->z5); 
# 520
last_gthreads = (mi % (nthreads * nblocks)); 
# 521
last_threads = (last_gthreads % nthreads); 
# 522
last_block = (last_gthreads / nthreads); 
# 523
if (last_threads == 0) { last_block--; }  
# 525
total_iterations = ((bid <= last_block) ? mi_per_thread : (mi_per_thread - 1)); 
# 526
stride = nthreads; 
# 527
for (int iter = 0, m = gid; m < mi; (iter++), (m += np)) { 
# 529
TunedLoad< double, CS> ::Ld(psitmp, zion0 + m); 
# 530
TunedLoad< double, CS> ::Ld(thetatmp, zion1 + m); 
# 531
TunedLoad< double, CS> ::Ld(zetatmp, zion2 + m); 
# 532
TunedLoad< double, CS> ::Ld(weight, zion4 + m); 
# 533
TunedLoad< double, CS> ::Ld(rhoi, zion5 + m); 
# 534
rhoi *= smu_inv; 
# 544
r = psitmp; 
# 549
iptmp = ((int)(((r - a0) * delr) + (0.5))); 
# 550
ip = d_abs_min_int(mpsi, iptmp); 
# 552
jttmp = ((int)(((thetatmp * pi2_inv) * ((delt)[ip])) + (0.5))); 
# 553
jt = d_abs_min_int((mtheta)[ip], jttmp); 
# 555
wzt = ((zetatmp - zetamin) * delz); 
# 556
kk = d_abs_min_int(mzeta - 1, (int)wzt); 
# 564
wz1 = (weight * (wzt - ((real)kk))); 
# 565
wz0 = (weight - wz1); 
# 566
r_diff = (r - a0); 
# 587
ipjt = (((igrid)[ip]) + jt); 
# 589
for (larmor = 0; larmor < 4; larmor++) { 
# 604
idx1 = (larmor + (4 * (ipjt - igrid_in))); 
# 605
rhotmp = (rhoi * (pgyro[idx1])); 
# 606
if (fabs(rhotmp) > rho_max) { 
# 607
printf("warning: reducing rhoi to %e from %e\n", ((rhotmp / fabs(rhotmp)) * rho_max) / (pgyro[idx1]), rhoi); 
# 608
rhotmp = ((rhotmp / fabs(rhotmp)) * rho_max); 
# 609
rhoi = (rhotmp / (pgyro[idx1])); 
# 610
}  
# 611
rdum = (delr * d_abs_min_real(a_diff, r_diff + rhotmp)); 
# 612
tflr = (thetatmp + (rhoi * (tgyro[idx1]))); 
# 615
ii = d_abs_min_int(mpsi_max, (int)rdum); 
# 622
wp1 = (rdum - ((real)ii)); 
# 623
wp0 = ((1.0) - wp1); 
# 626
im = ii; 
# 627
tdumtmp = ((pi2_inv * (tflr - (zetatmp * ((qtinv)[im])))) + (10.0)); 
# 628
tdum = ((tdumtmp - ((int)tdumtmp)) * ((delt)[im])); 
# 629
j00 = d_abs_min_int(((mtheta)[im]) - 1, (int)tdum); 
# 630
jtion0tmp = (((igrid)[im]) + j00); 
# 631
wtion0tmp = (tdum - ((real)j00)); 
# 634
im = (ii + 1); 
# 635
tdumtmp = ((pi2_inv * (tflr - (zetatmp * ((qtinv)[im])))) + (10.0)); 
# 636
tdum = ((tdumtmp - ((int)tdumtmp)) * ((delt)[im])); 
# 637
j01 = d_abs_min_int(((mtheta)[im]) - 1, (int)tdum); 
# 638
jtion1tmp = (((igrid)[im]) + j01); 
# 639
wtion1tmp = (tdum - ((real)j01)); 
# 659
wt10 = (wp0 * wtion0tmp); 
# 660
wt00 = (wp0 - wt10); 
# 662
wt11 = (wp1 * wtion1tmp); 
# 663
wt01 = (wp1 - wt11); 
# 665
ij1 = (kk + ((mzeta + 1) * (jtion0tmp - igrid_in))); 
# 677
if ((iter == (total_iterations - 1)) && (bid == last_block) && last_threads) { 
# 679
atomicDPupdate(densityi + ij1, wz0 * wt00); 
# 680
atomicDPupdate((densityi + ij1) + 1, wz1 * wt00); 
# 681
atomicDPupdate(((densityi + ij1) + mzeta) + 1, wz0 * wt10); 
# 682
atomicDPupdate(((densityi + ij1) + mzeta) + 2, wz1 * wt10); 
# 684
ij2 = (kk + ((mzeta + 1) * (jtion1tmp - igrid_in))); 
# 685
atomicDPupdate(densityi + ij2, wz0 * wt01); 
# 686
atomicDPupdate((densityi + ij2) + 1, wz1 * wt01); 
# 687
atomicDPupdate(((densityi + ij2) + mzeta) + 1, wz0 * wt11); 
# 688
atomicDPupdate(((densityi + ij2) + mzeta) + 2, wz1 * wt11); 
# 690
} else 
# 691
{ 
# 692
(update_idx[4 * tid]) = ij1; 
# 693
(update_idx[(4 * tid) + 1]) = (ij1 + 1); 
# 694
(update_idx[(4 * tid) + 2]) = ((ij1 + mzeta) + 1); 
# 695
(update_idx[(4 * tid) + 3]) = ((ij1 + mzeta) + 2); 
# 696
(update_val[4 * tid]) = (wz0 * wt00); 
# 697
(update_val[(4 * tid) + 1]) = (wz1 * wt00); 
# 698
(update_val[(4 * tid) + 2]) = (wz0 * wt10); 
# 699
(update_val[(4 * tid) + 3]) = (wz1 * wt10); 
# 700
__syncthreads(); 
# 702
atomicDPupdate(densityi + (update_idx[tid]), update_val[tid]); 
# 703
atomicDPupdate(densityi + (update_idx[stride + tid]), update_val[stride + tid]); 
# 704
atomicDPupdate(densityi + (update_idx[(2 * stride) + tid]), update_val[(2 * stride) + tid]); 
# 705
atomicDPupdate(densityi + (update_idx[(3 * stride) + tid]), update_val[(3 * stride) + tid]); 
# 707
ij2 = (kk + ((mzeta + 1) * (jtion1tmp - igrid_in))); 
# 708
(update_idx[4 * tid]) = ij2; 
# 709
(update_idx[(4 * tid) + 1]) = (ij2 + 1); 
# 710
(update_idx[(4 * tid) + 2]) = ((ij2 + mzeta) + 1); 
# 711
(update_idx[(4 * tid) + 3]) = ((ij2 + mzeta) + 2); 
# 712
(update_val[4 * tid]) = (wz0 * wt01); 
# 713
(update_val[(4 * tid) + 1]) = (wz1 * wt01); 
# 714
(update_val[(4 * tid) + 2]) = (wz0 * wt11); 
# 715
(update_val[(4 * tid) + 3]) = (wz1 * wt11); 
# 716
__syncthreads(); 
# 718
atomicDPupdate(densityi + (update_idx[tid]), update_val[tid]); 
# 719
atomicDPupdate(densityi + (update_idx[stride + tid]), update_val[stride + tid]); 
# 720
atomicDPupdate(densityi + (update_idx[(2 * stride) + tid]), update_val[(2 * stride) + tid]); 
# 721
atomicDPupdate(densityi + (update_idx[(3 * stride) + tid]), update_val[(3 * stride) + tid]); 
# 722
}  
# 724
}  
# 725
__syncthreads(); 
# 727
}  
# 728
} 
#endif
# 731 "./gpu_charge_kernel.cu"
static void memreset(real *array, int size) ;
#if 0
# 731
{ 
# 732
const int tidx = __device_builtin_variable_threadIdx.x; 
# 733
const int tid = ((__device_builtin_variable_threadIdx.y) * (__device_builtin_variable_blockDim.x)) + tidx; 
# 734
const int bid = (__device_builtin_variable_blockIdx.x) + ((__device_builtin_variable_gridDim.x) * (__device_builtin_variable_blockIdx.y)); 
# 735
const int nthreads = (__device_builtin_variable_blockDim.x) * (__device_builtin_variable_blockDim.y); 
# 736
const int nblocks = (__device_builtin_variable_gridDim.x) * (__device_builtin_variable_gridDim.y); 
# 737
int step = nthreads * nblocks; 
# 738
int i; 
# 739
for (i = (bid * nthreads); i < size; i += step) { 
# 740
(array[i + tid]) = (0); }  
# 741
} 
#endif
# 744 "./gpu_charge_kernel.cu"
extern "C" void call_gpu_charge_kernel(gtc_bench_data_t *gtc_input, gpu_kernel_args_t *gpu_kernel_input, int idiag) 
# 745
{ 
# 746
int mi_per_thread = gpu_kernel_input->charge_mi_per_thread; 
# 747
int nthreads = gpu_kernel_input->nthreads; 
# 748
gtc_global_params_t *h_params = &(gtc_input->global_params); 
# 749
gtc_field_data_t *d_grid = &(gpu_kernel_input->d_grid); 
# 750
gtc_field_data_t *h_grid = &(gtc_input->field_data); 
# 751
gtc_radial_decomp_t *h_radial_decomp = &(gtc_input->radial_decomp); 
# 753
gpu_timer_start(gpu_kernel_input); 
# 754
int mzeta = h_params->mzeta; int nloc_over = h_radial_decomp->nloc_over; 
# 755
int mi = h_params->mi; 
# 756
int mype = (gtc_input->parallel_decomp).mype; 
# 758
int mp = (gpu_kernel_input->deviceProp).multiProcessorCount; 
# 759
int m = ((mi + (nthreads * mp)) - 1) / (nthreads * mp); 
# 760
m = (((m + mi_per_thread) - 1) / mi_per_thread); 
# 761
int nblocks = mp * m; 
# 762
mi_per_thread = (((mi + (nblocks * nthreads)) - 1) / (nblocks * nthreads)); 
# 764
(cudaConfigureCall(mp, 512)) ? (void)0 : (memreset)(d_grid->densityi, (mzeta + 1) * nloc_over); 
# 765
((gpu_kernel_input->gpu_timing).memtransfer_charge_time) += (gpu_timer_measure(gpu_kernel_input)); 
# 774
int shared_buffer_sz = (nthreads * 4) * (sizeof(int) + sizeof(real)); 
# 775
(cudaConfigureCall(nblocks, nthreads, shared_buffer_sz)) ? (void)0 : (gpu_charge_cooperative)(gpu_kernel_input->ptr_d_grid, gpu_kernel_input->ptr_d_zion, gpu_kernel_input->ptr_d_aux_zion, mi_per_thread); 
# 781
if (idiag == 0) { diagnosis(gtc_input); }  
# 783
cudaError_t lasterror = cudaGetLastError(); 
# 784
if (lasterror != (cudaSuccess)) { 
# 785
printf("Error in launching gpu_charge_ routine: %s\n", cudaGetErrorString(lasterror)); }  
# 786
((gpu_kernel_input->gpu_timing).device_charge_time) += (gpu_timer_measure(gpu_kernel_input)); 
# 788
{ cudaError err = cudaMemcpy((void *)(h_grid->densityi), d_grid->densityi, ((mzeta + 1) * nloc_over) * sizeof(wreal), cudaMemcpyDeviceToHost); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "./gpu_charge_kernel.cu", 788, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 789
((gpu_kernel_input->gpu_timing).memtransfer_charge_time) += (gpu_timer_measure_end(gpu_kernel_input)); 
# 828
} 
# 59 "/usr/local/cuda-8.0/include/cuda.h"
typedef uint32_t cuuint32_t; 
# 60
typedef uint64_t cuuint64_t; 
# 211
extern "C" {
# 221
typedef unsigned long long CUdeviceptr; 
# 228
typedef int CUdevice; 
# 229
typedef struct CUctx_st *CUcontext; 
# 230
typedef struct CUmod_st *CUmodule; 
# 231
typedef struct CUfunc_st *CUfunction; 
# 232
typedef struct CUarray_st *CUarray; 
# 233
typedef struct CUmipmappedArray_st *CUmipmappedArray; 
# 234
typedef struct CUtexref_st *CUtexref; 
# 235
typedef struct CUsurfref_st *CUsurfref; 
# 236
typedef CUevent_st *CUevent; 
# 237
typedef CUstream_st *CUstream; 
# 238
typedef struct CUgraphicsResource_st *CUgraphicsResource; 
# 239
typedef unsigned long long CUtexObject; 
# 240
typedef unsigned long long CUsurfObject; 
# 244
typedef 
# 242
struct CUuuid_st { 
# 243
char bytes[16]; 
# 244
} CUuuid; 
# 259
typedef 
# 257
struct CUipcEventHandle_st { 
# 258
char reserved[64]; 
# 259
} CUipcEventHandle; 
# 266
typedef 
# 264
struct CUipcMemHandle_st { 
# 265
char reserved[64]; 
# 266
} CUipcMemHandle; 
# 273
typedef 
# 271
enum CUipcMem_flags_enum { 
# 272
CU_IPC_MEM_LAZY_ENABLE_PEER_ACCESS = 1
# 273
} CUipcMem_flags; 
# 284
typedef 
# 280
enum CUmemAttach_flags_enum { 
# 281
CU_MEM_ATTACH_GLOBAL = 1, 
# 282
CU_MEM_ATTACH_HOST, 
# 283
CU_MEM_ATTACH_SINGLE = 4
# 284
} CUmemAttach_flags; 
# 301
typedef 
# 289
enum CUctx_flags_enum { 
# 290
CU_CTX_SCHED_AUTO, 
# 291
CU_CTX_SCHED_SPIN, 
# 292
CU_CTX_SCHED_YIELD, 
# 293
CU_CTX_SCHED_BLOCKING_SYNC = 4, 
# 294
CU_CTX_BLOCKING_SYNC = 4, 
# 297
CU_CTX_SCHED_MASK = 7, 
# 298
CU_CTX_MAP_HOST, 
# 299
CU_CTX_LMEM_RESIZE_TO_MAX = 16, 
# 300
CU_CTX_FLAGS_MASK = 31
# 301
} CUctx_flags; 
# 309
typedef 
# 306
enum CUstream_flags_enum { 
# 307
CU_STREAM_DEFAULT, 
# 308
CU_STREAM_NON_BLOCKING
# 309
} CUstream_flags; 
# 339
typedef 
# 334
enum CUevent_flags_enum { 
# 335
CU_EVENT_DEFAULT, 
# 336
CU_EVENT_BLOCKING_SYNC, 
# 337
CU_EVENT_DISABLE_TIMING, 
# 338
CU_EVENT_INTERPROCESS = 4
# 339
} CUevent_flags; 
# 357
typedef 
# 345
enum CUstreamWaitValue_flags_enum { 
# 346
CU_STREAM_WAIT_VALUE_GEQ, 
# 348
CU_STREAM_WAIT_VALUE_EQ, 
# 349
CU_STREAM_WAIT_VALUE_AND, 
# 350
CU_STREAM_WAIT_VALUE_FLUSH = 1073741824
# 357
} CUstreamWaitValue_flags; 
# 370
typedef 
# 362
enum CUstreamWriteValue_flags_enum { 
# 363
CU_STREAM_WRITE_VALUE_DEFAULT, 
# 364
CU_STREAM_WRITE_VALUE_NO_MEMORY_BARRIER
# 370
} CUstreamWriteValue_flags; 
# 380
typedef 
# 375
enum CUstreamBatchMemOpType_enum { 
# 376
CU_STREAM_MEM_OP_WAIT_VALUE_32 = 1, 
# 377
CU_STREAM_MEM_OP_WRITE_VALUE_32, 
# 378
CU_STREAM_MEM_OP_FLUSH_REMOTE_WRITES
# 380
} CUstreamBatchMemOpType; 
# 412
typedef 
# 385
union CUstreamBatchMemOpParams_union { 
# 386
CUstreamBatchMemOpType operation; 
# 387
struct CUstreamMemOpWaitValueParams_st { 
# 388
CUstreamBatchMemOpType operation; 
# 389
CUdeviceptr address; 
# 390
union { 
# 391
cuuint32_t value; 
# 392
cuuint64_t pad; 
# 393
}; 
# 394
unsigned flags; 
# 395
CUdeviceptr alias; 
# 396
} waitValue; 
# 397
struct CUstreamMemOpWriteValueParams_st { 
# 398
CUstreamBatchMemOpType operation; 
# 399
CUdeviceptr address; 
# 400
union { 
# 401
cuuint32_t value; 
# 402
cuuint64_t pad; 
# 403
}; 
# 404
unsigned flags; 
# 405
CUdeviceptr alias; 
# 406
} writeValue; 
# 407
struct CUstreamMemOpFlushRemoteWritesParams_st { 
# 408
CUstreamBatchMemOpType operation; 
# 409
unsigned flags; 
# 410
} flushRemoteWrites; 
# 411
cuuint64_t pad[6]; 
# 412
} CUstreamBatchMemOpParams; 
# 421
typedef 
# 418
enum CUoccupancy_flags_enum { 
# 419
CU_OCCUPANCY_DEFAULT, 
# 420
CU_OCCUPANCY_DISABLE_CACHING_OVERRIDE
# 421
} CUoccupancy_flags; 
# 435
typedef 
# 426
enum CUarray_format_enum { 
# 427
CU_AD_FORMAT_UNSIGNED_INT8 = 1, 
# 428
CU_AD_FORMAT_UNSIGNED_INT16, 
# 429
CU_AD_FORMAT_UNSIGNED_INT32, 
# 430
CU_AD_FORMAT_SIGNED_INT8 = 8, 
# 431
CU_AD_FORMAT_SIGNED_INT16, 
# 432
CU_AD_FORMAT_SIGNED_INT32, 
# 433
CU_AD_FORMAT_HALF = 16, 
# 434
CU_AD_FORMAT_FLOAT = 32
# 435
} CUarray_format; 
# 445
typedef 
# 440
enum CUaddress_mode_enum { 
# 441
CU_TR_ADDRESS_MODE_WRAP, 
# 442
CU_TR_ADDRESS_MODE_CLAMP, 
# 443
CU_TR_ADDRESS_MODE_MIRROR, 
# 444
CU_TR_ADDRESS_MODE_BORDER
# 445
} CUaddress_mode; 
# 453
typedef 
# 450
enum CUfilter_mode_enum { 
# 451
CU_TR_FILTER_MODE_POINT, 
# 452
CU_TR_FILTER_MODE_LINEAR
# 453
} CUfilter_mode; 
# 556
typedef 
# 458
enum CUdevice_attribute_enum { 
# 459
CU_DEVICE_ATTRIBUTE_MAX_THREADS_PER_BLOCK = 1, 
# 460
CU_DEVICE_ATTRIBUTE_MAX_BLOCK_DIM_X, 
# 461
CU_DEVICE_ATTRIBUTE_MAX_BLOCK_DIM_Y, 
# 462
CU_DEVICE_ATTRIBUTE_MAX_BLOCK_DIM_Z, 
# 463
CU_DEVICE_ATTRIBUTE_MAX_GRID_DIM_X, 
# 464
CU_DEVICE_ATTRIBUTE_MAX_GRID_DIM_Y, 
# 465
CU_DEVICE_ATTRIBUTE_MAX_GRID_DIM_Z, 
# 466
CU_DEVICE_ATTRIBUTE_MAX_SHARED_MEMORY_PER_BLOCK, 
# 467
CU_DEVICE_ATTRIBUTE_SHARED_MEMORY_PER_BLOCK = 8, 
# 468
CU_DEVICE_ATTRIBUTE_TOTAL_CONSTANT_MEMORY, 
# 469
CU_DEVICE_ATTRIBUTE_WARP_SIZE, 
# 470
CU_DEVICE_ATTRIBUTE_MAX_PITCH, 
# 471
CU_DEVICE_ATTRIBUTE_MAX_REGISTERS_PER_BLOCK, 
# 472
CU_DEVICE_ATTRIBUTE_REGISTERS_PER_BLOCK = 12, 
# 473
CU_DEVICE_ATTRIBUTE_CLOCK_RATE, 
# 474
CU_DEVICE_ATTRIBUTE_TEXTURE_ALIGNMENT, 
# 475
CU_DEVICE_ATTRIBUTE_GPU_OVERLAP, 
# 476
CU_DEVICE_ATTRIBUTE_MULTIPROCESSOR_COUNT, 
# 477
CU_DEVICE_ATTRIBUTE_KERNEL_EXEC_TIMEOUT, 
# 478
CU_DEVICE_ATTRIBUTE_INTEGRATED, 
# 479
CU_DEVICE_ATTRIBUTE_CAN_MAP_HOST_MEMORY, 
# 480
CU_DEVICE_ATTRIBUTE_COMPUTE_MODE, 
# 481
CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE1D_WIDTH, 
# 482
CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_WIDTH, 
# 483
CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_HEIGHT, 
# 484
CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE3D_WIDTH, 
# 485
CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE3D_HEIGHT, 
# 486
CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE3D_DEPTH, 
# 487
CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_LAYERED_WIDTH, 
# 488
CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_LAYERED_HEIGHT, 
# 489
CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_LAYERED_LAYERS, 
# 490
CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_ARRAY_WIDTH = 27, 
# 491
CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_ARRAY_HEIGHT, 
# 492
CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_ARRAY_NUMSLICES, 
# 493
CU_DEVICE_ATTRIBUTE_SURFACE_ALIGNMENT, 
# 494
CU_DEVICE_ATTRIBUTE_CONCURRENT_KERNELS, 
# 495
CU_DEVICE_ATTRIBUTE_ECC_ENABLED, 
# 496
CU_DEVICE_ATTRIBUTE_PCI_BUS_ID, 
# 497
CU_DEVICE_ATTRIBUTE_PCI_DEVICE_ID, 
# 498
CU_DEVICE_ATTRIBUTE_TCC_DRIVER, 
# 499
CU_DEVICE_ATTRIBUTE_MEMORY_CLOCK_RATE, 
# 500
CU_DEVICE_ATTRIBUTE_GLOBAL_MEMORY_BUS_WIDTH, 
# 501
CU_DEVICE_ATTRIBUTE_L2_CACHE_SIZE, 
# 502
CU_DEVICE_ATTRIBUTE_MAX_THREADS_PER_MULTIPROCESSOR, 
# 503
CU_DEVICE_ATTRIBUTE_ASYNC_ENGINE_COUNT, 
# 504
CU_DEVICE_ATTRIBUTE_UNIFIED_ADDRESSING, 
# 505
CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE1D_LAYERED_WIDTH, 
# 506
CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE1D_LAYERED_LAYERS, 
# 507
CU_DEVICE_ATTRIBUTE_CAN_TEX2D_GATHER, 
# 508
CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_GATHER_WIDTH, 
# 509
CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_GATHER_HEIGHT, 
# 510
CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE3D_WIDTH_ALTERNATE, 
# 511
CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE3D_HEIGHT_ALTERNATE, 
# 512
CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE3D_DEPTH_ALTERNATE, 
# 513
CU_DEVICE_ATTRIBUTE_PCI_DOMAIN_ID, 
# 514
CU_DEVICE_ATTRIBUTE_TEXTURE_PITCH_ALIGNMENT, 
# 515
CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURECUBEMAP_WIDTH, 
# 516
CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURECUBEMAP_LAYERED_WIDTH, 
# 517
CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURECUBEMAP_LAYERED_LAYERS, 
# 518
CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE1D_WIDTH, 
# 519
CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE2D_WIDTH, 
# 520
CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE2D_HEIGHT, 
# 521
CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE3D_WIDTH, 
# 522
CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE3D_HEIGHT, 
# 523
CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE3D_DEPTH, 
# 524
CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE1D_LAYERED_WIDTH, 
# 525
CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE1D_LAYERED_LAYERS, 
# 526
CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE2D_LAYERED_WIDTH, 
# 527
CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE2D_LAYERED_HEIGHT, 
# 528
CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE2D_LAYERED_LAYERS, 
# 529
CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACECUBEMAP_WIDTH, 
# 530
CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACECUBEMAP_LAYERED_WIDTH, 
# 531
CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACECUBEMAP_LAYERED_LAYERS, 
# 532
CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE1D_LINEAR_WIDTH, 
# 533
CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_LINEAR_WIDTH, 
# 534
CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_LINEAR_HEIGHT, 
# 535
CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_LINEAR_PITCH, 
# 536
CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_MIPMAPPED_WIDTH, 
# 537
CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_MIPMAPPED_HEIGHT, 
# 538
CU_DEVICE_ATTRIBUTE_COMPUTE_CAPABILITY_MAJOR, 
# 539
CU_DEVICE_ATTRIBUTE_COMPUTE_CAPABILITY_MINOR, 
# 540
CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE1D_MIPMAPPED_WIDTH, 
# 541
CU_DEVICE_ATTRIBUTE_STREAM_PRIORITIES_SUPPORTED, 
# 542
CU_DEVICE_ATTRIBUTE_GLOBAL_L1_CACHE_SUPPORTED, 
# 543
CU_DEVICE_ATTRIBUTE_LOCAL_L1_CACHE_SUPPORTED, 
# 544
CU_DEVICE_ATTRIBUTE_MAX_SHARED_MEMORY_PER_MULTIPROCESSOR, 
# 545
CU_DEVICE_ATTRIBUTE_MAX_REGISTERS_PER_MULTIPROCESSOR, 
# 546
CU_DEVICE_ATTRIBUTE_MANAGED_MEMORY, 
# 547
CU_DEVICE_ATTRIBUTE_MULTI_GPU_BOARD, 
# 548
CU_DEVICE_ATTRIBUTE_MULTI_GPU_BOARD_GROUP_ID, 
# 549
CU_DEVICE_ATTRIBUTE_HOST_NATIVE_ATOMIC_SUPPORTED, 
# 550
CU_DEVICE_ATTRIBUTE_SINGLE_TO_DOUBLE_PRECISION_PERF_RATIO, 
# 551
CU_DEVICE_ATTRIBUTE_PAGEABLE_MEMORY_ACCESS, 
# 552
CU_DEVICE_ATTRIBUTE_CONCURRENT_MANAGED_ACCESS, 
# 553
CU_DEVICE_ATTRIBUTE_COMPUTE_PREEMPTION_SUPPORTED, 
# 554
CU_DEVICE_ATTRIBUTE_CAN_USE_HOST_POINTER_FOR_REGISTERED_MEM, 
# 555
CU_DEVICE_ATTRIBUTE_MAX
# 556
} CUdevice_attribute; 
# 572
typedef 
# 561
struct CUdevprop_st { 
# 562
int maxThreadsPerBlock; 
# 563
int maxThreadsDim[3]; 
# 564
int maxGridSize[3]; 
# 565
int sharedMemPerBlock; 
# 566
int totalConstantMemory; 
# 567
int SIMDWidth; 
# 568
int memPitch; 
# 569
int regsPerBlock; 
# 570
int clockRate; 
# 571
int textureAlign; 
# 572
} CUdevprop; 
# 586
typedef 
# 577
enum CUpointer_attribute_enum { 
# 578
CU_POINTER_ATTRIBUTE_CONTEXT = 1, 
# 579
CU_POINTER_ATTRIBUTE_MEMORY_TYPE, 
# 580
CU_POINTER_ATTRIBUTE_DEVICE_POINTER, 
# 581
CU_POINTER_ATTRIBUTE_HOST_POINTER, 
# 582
CU_POINTER_ATTRIBUTE_P2P_TOKENS, 
# 583
CU_POINTER_ATTRIBUTE_SYNC_MEMOPS, 
# 584
CU_POINTER_ATTRIBUTE_BUFFER_ID, 
# 585
CU_POINTER_ATTRIBUTE_IS_MANAGED
# 586
} CUpointer_attribute; 
# 647
typedef 
# 591
enum CUfunction_attribute_enum { 
# 597
CU_FUNC_ATTRIBUTE_MAX_THREADS_PER_BLOCK, 
# 604
CU_FUNC_ATTRIBUTE_SHARED_SIZE_BYTES, 
# 610
CU_FUNC_ATTRIBUTE_CONST_SIZE_BYTES, 
# 615
CU_FUNC_ATTRIBUTE_LOCAL_SIZE_BYTES, 
# 620
CU_FUNC_ATTRIBUTE_NUM_REGS, 
# 629
CU_FUNC_ATTRIBUTE_PTX_VERSION, 
# 638
CU_FUNC_ATTRIBUTE_BINARY_VERSION, 
# 644
CU_FUNC_ATTRIBUTE_CACHE_MODE_CA, 
# 646
CU_FUNC_ATTRIBUTE_MAX
# 647
} CUfunction_attribute; 
# 657
typedef 
# 652
enum CUfunc_cache_enum { 
# 653
CU_FUNC_CACHE_PREFER_NONE, 
# 654
CU_FUNC_CACHE_PREFER_SHARED, 
# 655
CU_FUNC_CACHE_PREFER_L1, 
# 656
CU_FUNC_CACHE_PREFER_EQUAL
# 657
} CUfunc_cache; 
# 666
typedef 
# 662
enum CUsharedconfig_enum { 
# 663
CU_SHARED_MEM_CONFIG_DEFAULT_BANK_SIZE, 
# 664
CU_SHARED_MEM_CONFIG_FOUR_BYTE_BANK_SIZE, 
# 665
CU_SHARED_MEM_CONFIG_EIGHT_BYTE_BANK_SIZE
# 666
} CUsharedconfig; 
# 676
typedef 
# 671
enum CUmemorytype_enum { 
# 672
CU_MEMORYTYPE_HOST = 1, 
# 673
CU_MEMORYTYPE_DEVICE, 
# 674
CU_MEMORYTYPE_ARRAY, 
# 675
CU_MEMORYTYPE_UNIFIED
# 676
} CUmemorytype; 
# 685
typedef 
# 681
enum CUcomputemode_enum { 
# 682
CU_COMPUTEMODE_DEFAULT, 
# 683
CU_COMPUTEMODE_PROHIBITED = 2, 
# 684
CU_COMPUTEMODE_EXCLUSIVE_PROCESS
# 685
} CUcomputemode; 
# 697
typedef 
# 690
enum CUmem_advise_enum { 
# 691
CU_MEM_ADVISE_SET_READ_MOSTLY = 1, 
# 692
CU_MEM_ADVISE_UNSET_READ_MOSTLY, 
# 693
CU_MEM_ADVISE_SET_PREFERRED_LOCATION, 
# 694
CU_MEM_ADVISE_UNSET_PREFERRED_LOCATION, 
# 695
CU_MEM_ADVISE_SET_ACCESSED_BY, 
# 696
CU_MEM_ADVISE_UNSET_ACCESSED_BY
# 697
} CUmem_advise; 
# 704
typedef 
# 699
enum CUmem_range_attribute_enum { 
# 700
CU_MEM_RANGE_ATTRIBUTE_READ_MOSTLY = 1, 
# 701
CU_MEM_RANGE_ATTRIBUTE_PREFERRED_LOCATION, 
# 702
CU_MEM_RANGE_ATTRIBUTE_ACCESSED_BY, 
# 703
CU_MEM_RANGE_ATTRIBUTE_LAST_PREFETCH_LOCATION
# 704
} CUmem_range_attribute; 
# 848
typedef 
# 709
enum CUjit_option_enum { 
# 716
CU_JIT_MAX_REGISTERS, 
# 731
CU_JIT_THREADS_PER_BLOCK, 
# 739
CU_JIT_WALL_TIME, 
# 748
CU_JIT_INFO_LOG_BUFFER, 
# 757
CU_JIT_INFO_LOG_BUFFER_SIZE_BYTES, 
# 766
CU_JIT_ERROR_LOG_BUFFER, 
# 775
CU_JIT_ERROR_LOG_BUFFER_SIZE_BYTES, 
# 783
CU_JIT_OPTIMIZATION_LEVEL, 
# 791
CU_JIT_TARGET_FROM_CUCONTEXT, 
# 799
CU_JIT_TARGET, 
# 808
CU_JIT_FALLBACK_STRATEGY, 
# 816
CU_JIT_GENERATE_DEBUG_INFO, 
# 823
CU_JIT_LOG_VERBOSE, 
# 830
CU_JIT_GENERATE_LINE_INFO, 
# 838
CU_JIT_CACHE_MODE, 
# 843
CU_JIT_NEW_SM3X_OPT, 
# 844
CU_JIT_FAST_COMPILE, 
# 846
CU_JIT_NUM_OPTIONS
# 848
} CUjit_option; 
# 871
typedef 
# 853
enum CUjit_target_enum { 
# 855
CU_TARGET_COMPUTE_10 = 10, 
# 856
CU_TARGET_COMPUTE_11, 
# 857
CU_TARGET_COMPUTE_12, 
# 858
CU_TARGET_COMPUTE_13, 
# 859
CU_TARGET_COMPUTE_20 = 20, 
# 860
CU_TARGET_COMPUTE_21, 
# 861
CU_TARGET_COMPUTE_30 = 30, 
# 862
CU_TARGET_COMPUTE_32 = 32, 
# 863
CU_TARGET_COMPUTE_35 = 35, 
# 864
CU_TARGET_COMPUTE_37 = 37, 
# 865
CU_TARGET_COMPUTE_50 = 50, 
# 866
CU_TARGET_COMPUTE_52 = 52, 
# 867
CU_TARGET_COMPUTE_53, 
# 868
CU_TARGET_COMPUTE_60 = 60, 
# 869
CU_TARGET_COMPUTE_61, 
# 870
CU_TARGET_COMPUTE_62
# 871
} CUjit_target; 
# 882
typedef 
# 876
enum CUjit_fallback_enum { 
# 878
CU_PREFER_PTX, 
# 880
CU_PREFER_BINARY
# 882
} CUjit_fallback; 
# 892
typedef 
# 887
enum CUjit_cacheMode_enum { 
# 889
CU_JIT_CACHE_OPTION_NONE, 
# 890
CU_JIT_CACHE_OPTION_CG, 
# 891
CU_JIT_CACHE_OPTION_CA
# 892
} CUjit_cacheMode; 
# 930
typedef 
# 897
enum CUjitInputType_enum { 
# 903
CU_JIT_INPUT_CUBIN, 
# 909
CU_JIT_INPUT_PTX, 
# 915
CU_JIT_INPUT_FATBINARY, 
# 921
CU_JIT_INPUT_OBJECT, 
# 927
CU_JIT_INPUT_LIBRARY, 
# 929
CU_JIT_NUM_INPUT_TYPES
# 930
} CUjitInputType; 
# 933
typedef struct CUlinkState_st *CUlinkState; 
# 945
typedef 
# 939
enum CUgraphicsRegisterFlags_enum { 
# 940
CU_GRAPHICS_REGISTER_FLAGS_NONE, 
# 941
CU_GRAPHICS_REGISTER_FLAGS_READ_ONLY, 
# 942
CU_GRAPHICS_REGISTER_FLAGS_WRITE_DISCARD, 
# 943
CU_GRAPHICS_REGISTER_FLAGS_SURFACE_LDST = 4, 
# 944
CU_GRAPHICS_REGISTER_FLAGS_TEXTURE_GATHER = 8
# 945
} CUgraphicsRegisterFlags; 
# 954
typedef 
# 950
enum CUgraphicsMapResourceFlags_enum { 
# 951
CU_GRAPHICS_MAP_RESOURCE_FLAGS_NONE, 
# 952
CU_GRAPHICS_MAP_RESOURCE_FLAGS_READ_ONLY, 
# 953
CU_GRAPHICS_MAP_RESOURCE_FLAGS_WRITE_DISCARD
# 954
} CUgraphicsMapResourceFlags; 
# 966
typedef 
# 959
enum CUarray_cubemap_face_enum { 
# 960
CU_CUBEMAP_FACE_POSITIVE_X, 
# 961
CU_CUBEMAP_FACE_NEGATIVE_X, 
# 962
CU_CUBEMAP_FACE_POSITIVE_Y, 
# 963
CU_CUBEMAP_FACE_NEGATIVE_Y, 
# 964
CU_CUBEMAP_FACE_POSITIVE_Z, 
# 965
CU_CUBEMAP_FACE_NEGATIVE_Z
# 966
} CUarray_cubemap_face; 
# 978
typedef 
# 971
enum CUlimit_enum { 
# 972
CU_LIMIT_STACK_SIZE, 
# 973
CU_LIMIT_PRINTF_FIFO_SIZE, 
# 974
CU_LIMIT_MALLOC_HEAP_SIZE, 
# 975
CU_LIMIT_DEV_RUNTIME_SYNC_DEPTH, 
# 976
CU_LIMIT_DEV_RUNTIME_PENDING_LAUNCH_COUNT, 
# 977
CU_LIMIT_MAX
# 978
} CUlimit; 
# 988
typedef 
# 983
enum CUresourcetype_enum { 
# 984
CU_RESOURCE_TYPE_ARRAY, 
# 985
CU_RESOURCE_TYPE_MIPMAPPED_ARRAY, 
# 986
CU_RESOURCE_TYPE_LINEAR, 
# 987
CU_RESOURCE_TYPE_PITCH2D
# 988
} CUresourcetype; 
# 1390
typedef 
# 993
enum cudaError_enum { 
# 999
CUDA_SUCCESS, 
# 1005
CUDA_ERROR_INVALID_VALUE, 
# 1011
CUDA_ERROR_OUT_OF_MEMORY, 
# 1017
CUDA_ERROR_NOT_INITIALIZED, 
# 1022
CUDA_ERROR_DEINITIALIZED, 
# 1029
CUDA_ERROR_PROFILER_DISABLED, 
# 1037
CUDA_ERROR_PROFILER_NOT_INITIALIZED, 
# 1044
CUDA_ERROR_PROFILER_ALREADY_STARTED, 
# 1051
CUDA_ERROR_PROFILER_ALREADY_STOPPED, 
# 1057
CUDA_ERROR_NO_DEVICE = 100, 
# 1063
CUDA_ERROR_INVALID_DEVICE, 
# 1070
CUDA_ERROR_INVALID_IMAGE = 200, 
# 1080
CUDA_ERROR_INVALID_CONTEXT, 
# 1089
CUDA_ERROR_CONTEXT_ALREADY_CURRENT, 
# 1094
CUDA_ERROR_MAP_FAILED = 205, 
# 1099
CUDA_ERROR_UNMAP_FAILED, 
# 1105
CUDA_ERROR_ARRAY_IS_MAPPED, 
# 1110
CUDA_ERROR_ALREADY_MAPPED, 
# 1118
CUDA_ERROR_NO_BINARY_FOR_GPU, 
# 1123
CUDA_ERROR_ALREADY_ACQUIRED, 
# 1128
CUDA_ERROR_NOT_MAPPED, 
# 1134
CUDA_ERROR_NOT_MAPPED_AS_ARRAY, 
# 1140
CUDA_ERROR_NOT_MAPPED_AS_POINTER, 
# 1146
CUDA_ERROR_ECC_UNCORRECTABLE, 
# 1152
CUDA_ERROR_UNSUPPORTED_LIMIT, 
# 1159
CUDA_ERROR_CONTEXT_ALREADY_IN_USE, 
# 1165
CUDA_ERROR_PEER_ACCESS_UNSUPPORTED, 
# 1170
CUDA_ERROR_INVALID_PTX, 
# 1175
CUDA_ERROR_INVALID_GRAPHICS_CONTEXT, 
# 1181
CUDA_ERROR_NVLINK_UNCORRECTABLE, 
# 1186
CUDA_ERROR_INVALID_SOURCE = 300, 
# 1191
CUDA_ERROR_FILE_NOT_FOUND, 
# 1196
CUDA_ERROR_SHARED_OBJECT_SYMBOL_NOT_FOUND, 
# 1201
CUDA_ERROR_SHARED_OBJECT_INIT_FAILED, 
# 1206
CUDA_ERROR_OPERATING_SYSTEM, 
# 1212
CUDA_ERROR_INVALID_HANDLE = 400, 
# 1218
CUDA_ERROR_NOT_FOUND = 500, 
# 1226
CUDA_ERROR_NOT_READY = 600, 
# 1235
CUDA_ERROR_ILLEGAL_ADDRESS = 700, 
# 1246
CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES, 
# 1257
CUDA_ERROR_LAUNCH_TIMEOUT, 
# 1263
CUDA_ERROR_LAUNCH_INCOMPATIBLE_TEXTURING, 
# 1270
CUDA_ERROR_PEER_ACCESS_ALREADY_ENABLED, 
# 1277
CUDA_ERROR_PEER_ACCESS_NOT_ENABLED, 
# 1283
CUDA_ERROR_PRIMARY_CONTEXT_ACTIVE = 708, 
# 1290
CUDA_ERROR_CONTEXT_IS_DESTROYED, 
# 1298
CUDA_ERROR_ASSERT, 
# 1305
CUDA_ERROR_TOO_MANY_PEERS, 
# 1311
CUDA_ERROR_HOST_MEMORY_ALREADY_REGISTERED, 
# 1317
CUDA_ERROR_HOST_MEMORY_NOT_REGISTERED, 
# 1326
CUDA_ERROR_HARDWARE_STACK_ERROR, 
# 1334
CUDA_ERROR_ILLEGAL_INSTRUCTION, 
# 1343
CUDA_ERROR_MISALIGNED_ADDRESS, 
# 1354
CUDA_ERROR_INVALID_ADDRESS_SPACE, 
# 1362
CUDA_ERROR_INVALID_PC, 
# 1372
CUDA_ERROR_LAUNCH_FAILED, 
# 1378
CUDA_ERROR_NOT_PERMITTED = 800, 
# 1384
CUDA_ERROR_NOT_SUPPORTED, 
# 1389
CUDA_ERROR_UNKNOWN = 999
# 1390
} CUresult; 
# 1399
typedef 
# 1395
enum CUdevice_P2PAttribute_enum { 
# 1396
CU_DEVICE_P2P_ATTRIBUTE_PERFORMANCE_RANK = 1, 
# 1397
CU_DEVICE_P2P_ATTRIBUTE_ACCESS_SUPPORTED, 
# 1398
CU_DEVICE_P2P_ATTRIBUTE_NATIVE_ATOMIC_SUPPORTED
# 1399
} CUdevice_P2PAttribute; 
# 1413
typedef void (*CUstreamCallback)(CUstream hStream, CUresult status, void * userData); 
# 1421
typedef size_t (*CUoccupancyB2DSize)(int blockSize); 
# 1497
typedef 
# 1476
struct CUDA_MEMCPY2D_st { 
# 1477
size_t srcXInBytes; 
# 1478
size_t srcY; 
# 1480
CUmemorytype srcMemoryType; 
# 1481
const void *srcHost; 
# 1482
CUdeviceptr srcDevice; 
# 1483
CUarray srcArray; 
# 1484
size_t srcPitch; 
# 1486
size_t dstXInBytes; 
# 1487
size_t dstY; 
# 1489
CUmemorytype dstMemoryType; 
# 1490
void *dstHost; 
# 1491
CUdeviceptr dstDevice; 
# 1492
CUarray dstArray; 
# 1493
size_t dstPitch; 
# 1495
size_t WidthInBytes; 
# 1496
size_t Height; 
# 1497
} CUDA_MEMCPY2D; 
# 1530
typedef 
# 1502
struct CUDA_MEMCPY3D_st { 
# 1503
size_t srcXInBytes; 
# 1504
size_t srcY; 
# 1505
size_t srcZ; 
# 1506
size_t srcLOD; 
# 1507
CUmemorytype srcMemoryType; 
# 1508
const void *srcHost; 
# 1509
CUdeviceptr srcDevice; 
# 1510
CUarray srcArray; 
# 1511
void *reserved0; 
# 1512
size_t srcPitch; 
# 1513
size_t srcHeight; 
# 1515
size_t dstXInBytes; 
# 1516
size_t dstY; 
# 1517
size_t dstZ; 
# 1518
size_t dstLOD; 
# 1519
CUmemorytype dstMemoryType; 
# 1520
void *dstHost; 
# 1521
CUdeviceptr dstDevice; 
# 1522
CUarray dstArray; 
# 1523
void *reserved1; 
# 1524
size_t dstPitch; 
# 1525
size_t dstHeight; 
# 1527
size_t WidthInBytes; 
# 1528
size_t Height; 
# 1529
size_t Depth; 
# 1530
} CUDA_MEMCPY3D; 
# 1563
typedef 
# 1535
struct CUDA_MEMCPY3D_PEER_st { 
# 1536
size_t srcXInBytes; 
# 1537
size_t srcY; 
# 1538
size_t srcZ; 
# 1539
size_t srcLOD; 
# 1540
CUmemorytype srcMemoryType; 
# 1541
const void *srcHost; 
# 1542
CUdeviceptr srcDevice; 
# 1543
CUarray srcArray; 
# 1544
CUcontext srcContext; 
# 1545
size_t srcPitch; 
# 1546
size_t srcHeight; 
# 1548
size_t dstXInBytes; 
# 1549
size_t dstY; 
# 1550
size_t dstZ; 
# 1551
size_t dstLOD; 
# 1552
CUmemorytype dstMemoryType; 
# 1553
void *dstHost; 
# 1554
CUdeviceptr dstDevice; 
# 1555
CUarray dstArray; 
# 1556
CUcontext dstContext; 
# 1557
size_t dstPitch; 
# 1558
size_t dstHeight; 
# 1560
size_t WidthInBytes; 
# 1561
size_t Height; 
# 1562
size_t Depth; 
# 1563
} CUDA_MEMCPY3D_PEER; 
# 1575
typedef 
# 1568
struct CUDA_ARRAY_DESCRIPTOR_st { 
# 1570
size_t Width; 
# 1571
size_t Height; 
# 1573
CUarray_format Format; 
# 1574
unsigned NumChannels; 
# 1575
} CUDA_ARRAY_DESCRIPTOR; 
# 1589
typedef 
# 1580
struct CUDA_ARRAY3D_DESCRIPTOR_st { 
# 1582
size_t Width; 
# 1583
size_t Height; 
# 1584
size_t Depth; 
# 1586
CUarray_format Format; 
# 1587
unsigned NumChannels; 
# 1588
unsigned Flags; 
# 1589
} CUDA_ARRAY3D_DESCRIPTOR; 
# 1629
typedef 
# 1598
struct CUDA_RESOURCE_DESC_st { 
# 1600
CUresourcetype resType; 
# 1602
union { 
# 1603
struct { 
# 1604
CUarray hArray; 
# 1605
} array; 
# 1606
struct { 
# 1607
CUmipmappedArray hMipmappedArray; 
# 1608
} mipmap; 
# 1609
struct { 
# 1610
CUdeviceptr devPtr; 
# 1611
CUarray_format format; 
# 1612
unsigned numChannels; 
# 1613
size_t sizeInBytes; 
# 1614
} linear; 
# 1615
struct { 
# 1616
CUdeviceptr devPtr; 
# 1617
CUarray_format format; 
# 1618
unsigned numChannels; 
# 1619
size_t width; 
# 1620
size_t height; 
# 1621
size_t pitchInBytes; 
# 1622
} pitch2D; 
# 1623
struct { 
# 1624
int reserved[32]; 
# 1625
} reserved; 
# 1626
} res; 
# 1628
unsigned flags; 
# 1629
} CUDA_RESOURCE_DESC; 
# 1645
typedef 
# 1634
struct CUDA_TEXTURE_DESC_st { 
# 1635
CUaddress_mode addressMode[3]; 
# 1636
CUfilter_mode filterMode; 
# 1637
unsigned flags; 
# 1638
unsigned maxAnisotropy; 
# 1639
CUfilter_mode mipmapFilterMode; 
# 1640
float mipmapLevelBias; 
# 1641
float minMipmapLevelClamp; 
# 1642
float maxMipmapLevelClamp; 
# 1643
float borderColor[4]; 
# 1644
int reserved[12]; 
# 1645
} CUDA_TEXTURE_DESC; 
# 1687
typedef 
# 1650
enum CUresourceViewFormat_enum { 
# 1652
CU_RES_VIEW_FORMAT_NONE, 
# 1653
CU_RES_VIEW_FORMAT_UINT_1X8, 
# 1654
CU_RES_VIEW_FORMAT_UINT_2X8, 
# 1655
CU_RES_VIEW_FORMAT_UINT_4X8, 
# 1656
CU_RES_VIEW_FORMAT_SINT_1X8, 
# 1657
CU_RES_VIEW_FORMAT_SINT_2X8, 
# 1658
CU_RES_VIEW_FORMAT_SINT_4X8, 
# 1659
CU_RES_VIEW_FORMAT_UINT_1X16, 
# 1660
CU_RES_VIEW_FORMAT_UINT_2X16, 
# 1661
CU_RES_VIEW_FORMAT_UINT_4X16, 
# 1662
CU_RES_VIEW_FORMAT_SINT_1X16, 
# 1663
CU_RES_VIEW_FORMAT_SINT_2X16, 
# 1664
CU_RES_VIEW_FORMAT_SINT_4X16, 
# 1665
CU_RES_VIEW_FORMAT_UINT_1X32, 
# 1666
CU_RES_VIEW_FORMAT_UINT_2X32, 
# 1667
CU_RES_VIEW_FORMAT_UINT_4X32, 
# 1668
CU_RES_VIEW_FORMAT_SINT_1X32, 
# 1669
CU_RES_VIEW_FORMAT_SINT_2X32, 
# 1670
CU_RES_VIEW_FORMAT_SINT_4X32, 
# 1671
CU_RES_VIEW_FORMAT_FLOAT_1X16, 
# 1672
CU_RES_VIEW_FORMAT_FLOAT_2X16, 
# 1673
CU_RES_VIEW_FORMAT_FLOAT_4X16, 
# 1674
CU_RES_VIEW_FORMAT_FLOAT_1X32, 
# 1675
CU_RES_VIEW_FORMAT_FLOAT_2X32, 
# 1676
CU_RES_VIEW_FORMAT_FLOAT_4X32, 
# 1677
CU_RES_VIEW_FORMAT_UNSIGNED_BC1, 
# 1678
CU_RES_VIEW_FORMAT_UNSIGNED_BC2, 
# 1679
CU_RES_VIEW_FORMAT_UNSIGNED_BC3, 
# 1680
CU_RES_VIEW_FORMAT_UNSIGNED_BC4, 
# 1681
CU_RES_VIEW_FORMAT_SIGNED_BC4, 
# 1682
CU_RES_VIEW_FORMAT_UNSIGNED_BC5, 
# 1683
CU_RES_VIEW_FORMAT_SIGNED_BC5, 
# 1684
CU_RES_VIEW_FORMAT_UNSIGNED_BC6H, 
# 1685
CU_RES_VIEW_FORMAT_SIGNED_BC6H, 
# 1686
CU_RES_VIEW_FORMAT_UNSIGNED_BC7
# 1687
} CUresourceViewFormat; 
# 1703
typedef 
# 1692
struct CUDA_RESOURCE_VIEW_DESC_st { 
# 1694
CUresourceViewFormat format; 
# 1695
size_t width; 
# 1696
size_t height; 
# 1697
size_t depth; 
# 1698
unsigned firstMipmapLevel; 
# 1699
unsigned lastMipmapLevel; 
# 1700
unsigned firstLayer; 
# 1701
unsigned lastLayer; 
# 1702
unsigned reserved[16]; 
# 1703
} CUDA_RESOURCE_VIEW_DESC; 
# 1711
typedef 
# 1708
struct CUDA_POINTER_ATTRIBUTE_P2P_TOKENS_st { 
# 1709
unsigned long long p2pToken; 
# 1710
unsigned vaSpaceToken; 
# 1711
} CUDA_POINTER_ATTRIBUTE_P2P_TOKENS; 
# 1858
CUresult cuGetErrorString(CUresult error, const char ** pStr); 
# 1877
CUresult cuGetErrorName(CUresult error, const char ** pStr); 
# 1909
CUresult cuInit(unsigned Flags); 
# 1939
CUresult cuDriverGetVersion(int * driverVersion); 
# 1979
CUresult cuDeviceGet(CUdevice * device, int ordinal); 
# 2004
CUresult cuDeviceGetCount(int * count); 
# 2032
CUresult cuDeviceGetName(char * name, int len, CUdevice dev); 
# 2059
CUresult cuDeviceTotalMem_v2(size_t * bytes, CUdevice dev); 
# 2254
CUresult cuDeviceGetAttribute(int * pi, CUdevice_attribute attrib, CUdevice dev); 
# 2331
CUresult cuDeviceGetProperties(CUdevprop * prop, CUdevice dev); 
# 2364
CUresult cuDeviceComputeCapability(int * major, int * minor, CUdevice dev); 
# 2432
CUresult cuDevicePrimaryCtxRetain(CUcontext * pctx, CUdevice dev); 
# 2466
CUresult cuDevicePrimaryCtxRelease(CUdevice dev); 
# 2529
CUresult cuDevicePrimaryCtxSetFlags(CUdevice dev, unsigned flags); 
# 2553
CUresult cuDevicePrimaryCtxGetState(CUdevice dev, unsigned * flags, int * active); 
# 2591
CUresult cuDevicePrimaryCtxReset(CUdevice dev); 
# 2697
CUresult cuCtxCreate_v2(CUcontext * pctx, unsigned flags, CUdevice dev); 
# 2737
CUresult cuCtxDestroy_v2(CUcontext ctx); 
# 2773
CUresult cuCtxPushCurrent_v2(CUcontext ctx); 
# 2807
CUresult cuCtxPopCurrent_v2(CUcontext * pctx); 
# 2833
CUresult cuCtxSetCurrent(CUcontext ctx); 
# 2852
CUresult cuCtxGetCurrent(CUcontext * pctx); 
# 2882
CUresult cuCtxGetDevice(CUdevice * device); 
# 2910
CUresult cuCtxGetFlags(unsigned * flags); 
# 2940
CUresult cuCtxSynchronize(); 
# 3035
CUresult cuCtxSetLimit(CUlimit limit, size_t value); 
# 3074
CUresult cuCtxGetLimit(size_t * pvalue, CUlimit limit); 
# 3117
CUresult cuCtxGetCacheConfig(CUfunc_cache * pconfig); 
# 3167
CUresult cuCtxSetCacheConfig(CUfunc_cache config); 
# 3209
CUresult cuCtxGetSharedMemConfig(CUsharedconfig * pConfig); 
# 3261
CUresult cuCtxSetSharedMemConfig(CUsharedconfig config); 
# 3299
CUresult cuCtxGetApiVersion(CUcontext ctx, unsigned * version); 
# 3338
CUresult cuCtxGetStreamPriorityRange(int * leastPriority, int * greatestPriority); 
# 3393
CUresult cuCtxAttach(CUcontext * pctx, unsigned flags); 
# 3429
CUresult cuCtxDetach(CUcontext ctx); 
# 3483
CUresult cuModuleLoad(CUmodule * module, const char * fname); 
# 3519
CUresult cuModuleLoadData(CUmodule * module, const void * image); 
# 3561
CUresult cuModuleLoadDataEx(CUmodule * module, const void * image, unsigned numOptions, CUjit_option * options, void ** optionValues); 
# 3602
CUresult cuModuleLoadFatBinary(CUmodule * module, const void * fatCubin); 
# 3627
CUresult cuModuleUnload(CUmodule hmod); 
# 3657
CUresult cuModuleGetFunction(CUfunction * hfunc, CUmodule hmod, const char * name); 
# 3691
CUresult cuModuleGetGlobal_v2(CUdeviceptr * dptr, size_t * bytes, CUmodule hmod, const char * name); 
# 3725
CUresult cuModuleGetTexRef(CUtexref * pTexRef, CUmodule hmod, const char * name); 
# 3756
CUresult cuModuleGetSurfRef(CUsurfref * pSurfRef, CUmodule hmod, const char * name); 
# 3798
CUresult cuLinkCreate_v2(unsigned numOptions, CUjit_option * options, void ** optionValues, CUlinkState * stateOut); 
# 3835
CUresult cuLinkAddData_v2(CUlinkState state, CUjitInputType type, void * data, size_t size, const char * name, unsigned numOptions, CUjit_option * options, void ** optionValues); 
# 3874
CUresult cuLinkAddFile_v2(CUlinkState state, CUjitInputType type, const char * path, unsigned numOptions, CUjit_option * options, void ** optionValues); 
# 3901
CUresult cuLinkComplete(CUlinkState state, void ** cubinOut, size_t * sizeOut); 
# 3915
CUresult cuLinkDestroy(CUlinkState state); 
# 3963
CUresult cuMemGetInfo_v2(size_t * free, size_t * total); 
# 3996
CUresult cuMemAlloc_v2(CUdeviceptr * dptr, size_t bytesize); 
# 4057
CUresult cuMemAllocPitch_v2(CUdeviceptr * dptr, size_t * pPitch, size_t WidthInBytes, size_t Height, unsigned ElementSizeBytes); 
# 4086
CUresult cuMemFree_v2(CUdeviceptr dptr); 
# 4119
CUresult cuMemGetAddressRange_v2(CUdeviceptr * pbase, size_t * psize, CUdeviceptr dptr); 
# 4165
CUresult cuMemAllocHost_v2(void ** pp, size_t bytesize); 
# 4195
CUresult cuMemFreeHost(void * p); 
# 4277
CUresult cuMemHostAlloc(void ** pp, size_t bytesize, unsigned Flags); 
# 4330
CUresult cuMemHostGetDevicePointer_v2(CUdeviceptr * pdptr, void * p, unsigned Flags); 
# 4355
CUresult cuMemHostGetFlags(unsigned * pFlags, void * p); 
# 4465
CUresult cuMemAllocManaged(CUdeviceptr * dptr, size_t bytesize, unsigned flags); 
# 4494
CUresult cuDeviceGetByPCIBusId(CUdevice * dev, const char * pciBusId); 
# 4522
CUresult cuDeviceGetPCIBusId(char * pciBusId, int len, CUdevice dev); 
# 4564
CUresult cuIpcGetEventHandle(CUipcEventHandle * pHandle, CUevent event); 
# 4601
CUresult cuIpcOpenEventHandle(CUevent * phEvent, CUipcEventHandle handle); 
# 4638
CUresult cuIpcGetMemHandle(CUipcMemHandle * pHandle, CUdeviceptr dptr); 
# 4689
CUresult cuIpcOpenMemHandle(CUdeviceptr * pdptr, CUipcMemHandle handle, unsigned Flags); 
# 4720
CUresult cuIpcCloseMemHandle(CUdeviceptr dptr); 
# 4803
CUresult cuMemHostRegister_v2(void * p, size_t bytesize, unsigned Flags); 
# 4827
CUresult cuMemHostUnregister(void * p); 
# 4863
CUresult cuMemcpy(CUdeviceptr dst, CUdeviceptr src, size_t ByteCount); 
# 4892
CUresult cuMemcpyPeer(CUdeviceptr dstDevice, CUcontext dstContext, CUdeviceptr srcDevice, CUcontext srcContext, size_t ByteCount); 
# 4928
CUresult cuMemcpyHtoD_v2(CUdeviceptr dstDevice, const void * srcHost, size_t ByteCount); 
# 4961
CUresult cuMemcpyDtoH_v2(void * dstHost, CUdeviceptr srcDevice, size_t ByteCount); 
# 4994
CUresult cuMemcpyDtoD_v2(CUdeviceptr dstDevice, CUdeviceptr srcDevice, size_t ByteCount); 
# 5029
CUresult cuMemcpyDtoA_v2(CUarray dstArray, size_t dstOffset, CUdeviceptr srcDevice, size_t ByteCount); 
# 5066
CUresult cuMemcpyAtoD_v2(CUdeviceptr dstDevice, CUarray srcArray, size_t srcOffset, size_t ByteCount); 
# 5101
CUresult cuMemcpyHtoA_v2(CUarray dstArray, size_t dstOffset, const void * srcHost, size_t ByteCount); 
# 5136
CUresult cuMemcpyAtoH_v2(void * dstHost, CUarray srcArray, size_t srcOffset, size_t ByteCount); 
# 5175
CUresult cuMemcpyAtoA_v2(CUarray dstArray, size_t dstOffset, CUarray srcArray, size_t srcOffset, size_t ByteCount); 
# 5336
CUresult cuMemcpy2D_v2(const CUDA_MEMCPY2D * pCopy); 
# 5495
CUresult cuMemcpy2DUnaligned_v2(const CUDA_MEMCPY2D * pCopy); 
# 5663
CUresult cuMemcpy3D_v2(const CUDA_MEMCPY3D * pCopy); 
# 5688
CUresult cuMemcpy3DPeer(const CUDA_MEMCPY3D_PEER * pCopy); 
# 5728
CUresult cuMemcpyAsync(CUdeviceptr dst, CUdeviceptr src, size_t ByteCount, CUstream hStream); 
# 5759
CUresult cuMemcpyPeerAsync(CUdeviceptr dstDevice, CUcontext dstContext, CUdeviceptr srcDevice, CUcontext srcContext, size_t ByteCount, CUstream hStream); 
# 5798
CUresult cuMemcpyHtoDAsync_v2(CUdeviceptr dstDevice, const void * srcHost, size_t ByteCount, CUstream hStream); 
# 5835
CUresult cuMemcpyDtoHAsync_v2(void * dstHost, CUdeviceptr srcDevice, size_t ByteCount, CUstream hStream); 
# 5872
CUresult cuMemcpyDtoDAsync_v2(CUdeviceptr dstDevice, CUdeviceptr srcDevice, size_t ByteCount, CUstream hStream); 
# 5911
CUresult cuMemcpyHtoAAsync_v2(CUarray dstArray, size_t dstOffset, const void * srcHost, size_t ByteCount, CUstream hStream); 
# 5950
CUresult cuMemcpyAtoHAsync_v2(void * dstHost, CUarray srcArray, size_t srcOffset, size_t ByteCount, CUstream hStream); 
# 6115
CUresult cuMemcpy2DAsync_v2(const CUDA_MEMCPY2D * pCopy, CUstream hStream); 
# 6287
CUresult cuMemcpy3DAsync_v2(const CUDA_MEMCPY3D * pCopy, CUstream hStream); 
# 6314
CUresult cuMemcpy3DPeerAsync(const CUDA_MEMCPY3D_PEER * pCopy, CUstream hStream); 
# 6350
CUresult cuMemsetD8_v2(CUdeviceptr dstDevice, unsigned char uc, size_t N); 
# 6384
CUresult cuMemsetD16_v2(CUdeviceptr dstDevice, unsigned short us, size_t N); 
# 6418
CUresult cuMemsetD32_v2(CUdeviceptr dstDevice, unsigned ui, size_t N); 
# 6457
CUresult cuMemsetD2D8_v2(CUdeviceptr dstDevice, size_t dstPitch, unsigned char uc, size_t Width, size_t Height); 
# 6497
CUresult cuMemsetD2D16_v2(CUdeviceptr dstDevice, size_t dstPitch, unsigned short us, size_t Width, size_t Height); 
# 6537
CUresult cuMemsetD2D32_v2(CUdeviceptr dstDevice, size_t dstPitch, unsigned ui, size_t Width, size_t Height); 
# 6573
CUresult cuMemsetD8Async(CUdeviceptr dstDevice, unsigned char uc, size_t N, CUstream hStream); 
# 6609
CUresult cuMemsetD16Async(CUdeviceptr dstDevice, unsigned short us, size_t N, CUstream hStream); 
# 6644
CUresult cuMemsetD32Async(CUdeviceptr dstDevice, unsigned ui, size_t N, CUstream hStream); 
# 6685
CUresult cuMemsetD2D8Async(CUdeviceptr dstDevice, size_t dstPitch, unsigned char uc, size_t Width, size_t Height, CUstream hStream); 
# 6727
CUresult cuMemsetD2D16Async(CUdeviceptr dstDevice, size_t dstPitch, unsigned short us, size_t Width, size_t Height, CUstream hStream); 
# 6769
CUresult cuMemsetD2D32Async(CUdeviceptr dstDevice, size_t dstPitch, unsigned ui, size_t Width, size_t Height, CUstream hStream); 
# 6872
CUresult cuArrayCreate_v2(CUarray * pHandle, const CUDA_ARRAY_DESCRIPTOR * pAllocateArray); 
# 6905
CUresult cuArrayGetDescriptor_v2(CUDA_ARRAY_DESCRIPTOR * pArrayDescriptor, CUarray hArray); 
# 6936
CUresult cuArrayDestroy(CUarray hArray); 
# 7116
CUresult cuArray3DCreate_v2(CUarray * pHandle, const CUDA_ARRAY3D_DESCRIPTOR * pAllocateArray); 
# 7152
CUresult cuArray3DGetDescriptor_v2(CUDA_ARRAY3D_DESCRIPTOR * pArrayDescriptor, CUarray hArray); 
# 7279
CUresult cuMipmappedArrayCreate(CUmipmappedArray * pHandle, const CUDA_ARRAY3D_DESCRIPTOR * pMipmappedArrayDesc, unsigned numMipmapLevels); 
# 7305
CUresult cuMipmappedArrayGetLevel(CUarray * pLevelArray, CUmipmappedArray hMipmappedArray, unsigned level); 
# 7325
CUresult cuMipmappedArrayDestroy(CUmipmappedArray hMipmappedArray); 
# 7571
CUresult cuPointerGetAttribute(void * data, CUpointer_attribute attribute, CUdeviceptr ptr); 
# 7640
CUresult cuMemPrefetchAsync(CUdeviceptr devPtr, size_t count, CUdevice dstDevice, CUstream hStream); 
# 7726
CUresult cuMemAdvise(CUdeviceptr devPtr, size_t count, CUmem_advise advice, CUdevice device); 
# 7783
CUresult cuMemRangeGetAttribute(void * data, size_t dataSize, CUmem_range_attribute attribute, CUdeviceptr devPtr, size_t count); 
# 7822
CUresult cuMemRangeGetAttributes(void ** data, size_t * dataSizes, CUmem_range_attribute * attributes, size_t numAttributes, CUdeviceptr devPtr, size_t count); 
# 7866
CUresult cuPointerSetAttribute(const void * value, CUpointer_attribute attribute, CUdeviceptr ptr); 
# 7908
CUresult cuPointerGetAttributes(unsigned numAttributes, CUpointer_attribute * attributes, void ** data, CUdeviceptr ptr); 
# 7956
CUresult cuStreamCreate(CUstream * phStream, unsigned Flags); 
# 8004
CUresult cuStreamCreateWithPriority(CUstream * phStream, unsigned flags, int priority); 
# 8034
CUresult cuStreamGetPriority(CUstream hStream, int * priority); 
# 8061
CUresult cuStreamGetFlags(CUstream hStream, unsigned * flags); 
# 8102
CUresult cuStreamWaitEvent(CUstream hStream, CUevent hEvent, unsigned Flags); 
# 8173
CUresult cuStreamAddCallback(CUstream hStream, CUstreamCallback callback, void * userData, unsigned flags); 
# 8252
CUresult cuStreamAttachMemAsync(CUstream hStream, CUdeviceptr dptr, size_t length, unsigned flags); 
# 8283
CUresult cuStreamQuery(CUstream hStream); 
# 8310
CUresult cuStreamSynchronize(CUstream hStream); 
# 8339
CUresult cuStreamDestroy_v2(CUstream hStream); 
# 8394
CUresult cuEventCreate(CUevent * phEvent, unsigned Flags); 
# 8430
CUresult cuEventRecord(CUevent hEvent, CUstream hStream); 
# 8464
CUresult cuEventQuery(CUevent hEvent); 
# 8498
CUresult cuEventSynchronize(CUevent hEvent); 
# 8527
CUresult cuEventDestroy_v2(CUevent hEvent); 
# 8571
CUresult cuEventElapsedTime(float * pMilliseconds, CUevent hStart, CUevent hEnd); 
# 8606
CUresult cuStreamWaitValue32(CUstream stream, CUdeviceptr addr, cuuint32_t value, unsigned flags); 
# 8639
CUresult cuStreamWriteValue32(CUstream stream, CUdeviceptr addr, cuuint32_t value, unsigned flags); 
# 8671
CUresult cuStreamBatchMemOp(CUstream stream, unsigned count, CUstreamBatchMemOpParams * paramArray, unsigned flags); 
# 8739
CUresult cuFuncGetAttribute(int * pi, CUfunction_attribute attrib, CUfunction hfunc); 
# 8782
CUresult cuFuncSetCacheConfig(CUfunction hfunc, CUfunc_cache config); 
# 8834
CUresult cuFuncSetSharedMemConfig(CUfunction hfunc, CUsharedconfig config); 
# 8948
CUresult cuLaunchKernel(CUfunction f, unsigned gridDimX, unsigned gridDimY, unsigned gridDimZ, unsigned blockDimX, unsigned blockDimY, unsigned blockDimZ, unsigned sharedMemBytes, CUstream hStream, void ** kernelParams, void ** extra); 
# 9009
CUresult cuFuncSetBlockShape(CUfunction hfunc, int x, int y, int z); 
# 9043
CUresult cuFuncSetSharedSize(CUfunction hfunc, unsigned bytes); 
# 9075
CUresult cuParamSetSize(CUfunction hfunc, unsigned numbytes); 
# 9108
CUresult cuParamSeti(CUfunction hfunc, int offset, unsigned value); 
# 9141
CUresult cuParamSetf(CUfunction hfunc, int offset, float value); 
# 9176
CUresult cuParamSetv(CUfunction hfunc, int offset, void * ptr, unsigned numbytes); 
# 9213
CUresult cuLaunch(CUfunction f); 
# 9252
CUresult cuLaunchGrid(CUfunction f, int grid_width, int grid_height); 
# 9299
CUresult cuLaunchGridAsync(CUfunction f, int grid_width, int grid_height, CUstream hStream); 
# 9324
CUresult cuParamSetTexRef(CUfunction hfunc, int texunit, CUtexref hTexRef); 
# 9362
CUresult cuOccupancyMaxActiveBlocksPerMultiprocessor(int * numBlocks, CUfunction func, int blockSize, size_t dynamicSMemSize); 
# 9402
CUresult cuOccupancyMaxActiveBlocksPerMultiprocessorWithFlags(int * numBlocks, CUfunction func, int blockSize, size_t dynamicSMemSize, unsigned flags); 
# 9452
CUresult cuOccupancyMaxPotentialBlockSize(int * minGridSize, int * blockSize, CUfunction func, CUoccupancyB2DSize blockSizeToDynamicSMemSize, size_t dynamicSMemSize, int blockSizeLimit); 
# 9496
CUresult cuOccupancyMaxPotentialBlockSizeWithFlags(int * minGridSize, int * blockSize, CUfunction func, CUoccupancyB2DSize blockSizeToDynamicSMemSize, size_t dynamicSMemSize, int blockSizeLimit, unsigned flags); 
# 9539
CUresult cuTexRefSetArray(CUtexref hTexRef, CUarray hArray, unsigned Flags); 
# 9566
CUresult cuTexRefSetMipmappedArray(CUtexref hTexRef, CUmipmappedArray hMipmappedArray, unsigned Flags); 
# 9610
CUresult cuTexRefSetAddress_v2(size_t * ByteOffset, CUtexref hTexRef, CUdeviceptr dptr, size_t bytes); 
# 9662
CUresult cuTexRefSetAddress2D_v3(CUtexref hTexRef, const CUDA_ARRAY_DESCRIPTOR * desc, CUdeviceptr dptr, size_t Pitch); 
# 9691
CUresult cuTexRefSetFormat(CUtexref hTexRef, CUarray_format fmt, int NumPackedComponents); 
# 9731
CUresult cuTexRefSetAddressMode(CUtexref hTexRef, int dim, CUaddress_mode am); 
# 9764
CUresult cuTexRefSetFilterMode(CUtexref hTexRef, CUfilter_mode fm); 
# 9797
CUresult cuTexRefSetMipmapFilterMode(CUtexref hTexRef, CUfilter_mode fm); 
# 9823
CUresult cuTexRefSetMipmapLevelBias(CUtexref hTexRef, float bias); 
# 9851
CUresult cuTexRefSetMipmapLevelClamp(CUtexref hTexRef, float minMipmapLevelClamp, float maxMipmapLevelClamp); 
# 9877
CUresult cuTexRefSetMaxAnisotropy(CUtexref hTexRef, unsigned maxAniso); 
# 9907
CUresult cuTexRefSetBorderColor(CUtexref hTexRef, float * pBorderColor); 
# 9942
CUresult cuTexRefSetFlags(CUtexref hTexRef, unsigned Flags); 
# 9968
CUresult cuTexRefGetAddress_v2(CUdeviceptr * pdptr, CUtexref hTexRef); 
# 9994
CUresult cuTexRefGetArray(CUarray * phArray, CUtexref hTexRef); 
# 10019
CUresult cuTexRefGetMipmappedArray(CUmipmappedArray * phMipmappedArray, CUtexref hTexRef); 
# 10045
CUresult cuTexRefGetAddressMode(CUaddress_mode * pam, CUtexref hTexRef, int dim); 
# 10069
CUresult cuTexRefGetFilterMode(CUfilter_mode * pfm, CUtexref hTexRef); 
# 10095
CUresult cuTexRefGetFormat(CUarray_format * pFormat, int * pNumChannels, CUtexref hTexRef); 
# 10119
CUresult cuTexRefGetMipmapFilterMode(CUfilter_mode * pfm, CUtexref hTexRef); 
# 10143
CUresult cuTexRefGetMipmapLevelBias(float * pbias, CUtexref hTexRef); 
# 10168
CUresult cuTexRefGetMipmapLevelClamp(float * pminMipmapLevelClamp, float * pmaxMipmapLevelClamp, CUtexref hTexRef); 
# 10192
CUresult cuTexRefGetMaxAnisotropy(int * pmaxAniso, CUtexref hTexRef); 
# 10219
CUresult cuTexRefGetBorderColor(float * pBorderColor, CUtexref hTexRef); 
# 10242
CUresult cuTexRefGetFlags(unsigned * pFlags, CUtexref hTexRef); 
# 10281
CUresult cuTexRefCreate(CUtexref * pTexRef); 
# 10301
CUresult cuTexRefDestroy(CUtexref hTexRef); 
# 10340
CUresult cuSurfRefSetArray(CUsurfref hSurfRef, CUarray hArray, unsigned Flags); 
# 10361
CUresult cuSurfRefGetArray(CUarray * phArray, CUsurfref hSurfRef); 
# 10583
CUresult cuTexObjectCreate(CUtexObject * pTexObject, const CUDA_RESOURCE_DESC * pResDesc, const CUDA_TEXTURE_DESC * pTexDesc, const CUDA_RESOURCE_VIEW_DESC * pResViewDesc); 
# 10601
CUresult cuTexObjectDestroy(CUtexObject texObject); 
# 10620
CUresult cuTexObjectGetResourceDesc(CUDA_RESOURCE_DESC * pResDesc, CUtexObject texObject); 
# 10639
CUresult cuTexObjectGetTextureDesc(CUDA_TEXTURE_DESC * pTexDesc, CUtexObject texObject); 
# 10659
CUresult cuTexObjectGetResourceViewDesc(CUDA_RESOURCE_VIEW_DESC * pResViewDesc, CUtexObject texObject); 
# 10700
CUresult cuSurfObjectCreate(CUsurfObject * pSurfObject, const CUDA_RESOURCE_DESC * pResDesc); 
# 10718
CUresult cuSurfObjectDestroy(CUsurfObject surfObject); 
# 10737
CUresult cuSurfObjectGetResourceDesc(CUDA_RESOURCE_DESC * pResDesc, CUsurfObject surfObject); 
# 10779
CUresult cuDeviceCanAccessPeer(int * canAccessPeer, CUdevice dev, CUdevice peerDev); 
# 10816
CUresult cuDeviceGetP2PAttribute(int * value, CUdevice_P2PAttribute attrib, CUdevice srcDevice, CUdevice dstDevice); 
# 10865
CUresult cuCtxEnablePeerAccess(CUcontext peerContext, unsigned Flags); 
# 10890
CUresult cuCtxDisablePeerAccess(CUcontext peerContext); 
# 10934
CUresult cuGraphicsUnregisterResource(CUgraphicsResource resource); 
# 10972
CUresult cuGraphicsSubResourceGetMappedArray(CUarray * pArray, CUgraphicsResource resource, unsigned arrayIndex, unsigned mipLevel); 
# 11003
CUresult cuGraphicsResourceGetMappedMipmappedArray(CUmipmappedArray * pMipmappedArray, CUgraphicsResource resource); 
# 11039
CUresult cuGraphicsResourceGetMappedPointer_v2(CUdeviceptr * pDevPtr, size_t * pSize, CUgraphicsResource resource); 
# 11080
CUresult cuGraphicsResourceSetMapFlags_v2(CUgraphicsResource resource, unsigned flags); 
# 11119
CUresult cuGraphicsMapResources(unsigned count, CUgraphicsResource * resources, CUstream hStream); 
# 11155
CUresult cuGraphicsUnmapResources(unsigned count, CUgraphicsResource * resources, CUstream hStream); 
# 11159
CUresult cuGetExportTable(const void ** ppExportTable, const CUuuid * pExportTableId); 
# 11478
}
# 24 "/usr/local/cuda-8.0/include/thrust/detail/config/global_workarounds.h"
#pragma GCC diagnostic ignored "-Wunused-local-typedefs"
# 42 "/usr/include/c++/4.8.2/bits/functexcept.h" 3
namespace std __attribute((__visibility__("default"))) { 
# 48
void __throw_bad_exception() __attribute((__noreturn__)); 
# 52
void __throw_bad_alloc() __attribute((__noreturn__)); 
# 56
void __throw_bad_cast() __attribute((__noreturn__)); 
# 59
void __throw_bad_typeid() __attribute((__noreturn__)); 
# 63
void __throw_logic_error(const char *) __attribute((__noreturn__)); 
# 66
void __throw_domain_error(const char *) __attribute((__noreturn__)); 
# 69
void __throw_invalid_argument(const char *) __attribute((__noreturn__)); 
# 72
void __throw_length_error(const char *) __attribute((__noreturn__)); 
# 75
void __throw_out_of_range(const char *) __attribute((__noreturn__)); 
# 78
void __throw_runtime_error(const char *) __attribute((__noreturn__)); 
# 81
void __throw_range_error(const char *) __attribute((__noreturn__)); 
# 84
void __throw_overflow_error(const char *) __attribute((__noreturn__)); 
# 87
void __throw_underflow_error(const char *) __attribute((__noreturn__)); 
# 91
void __throw_ios_failure(const char *) __attribute((__noreturn__)); 
# 94
void __throw_system_error(int) __attribute((__noreturn__)); 
# 97
void __throw_future_error(int) __attribute((__noreturn__)); 
# 101
void __throw_bad_function_call() __attribute((__noreturn__)); 
# 104
}
# 37 "/usr/include/c++/4.8.2/ext/numeric_traits.h" 3
namespace __gnu_cxx __attribute((__visibility__("default"))) { 
# 54
template< class _Value> 
# 55
struct __numeric_traits_integer { 
# 58
static const _Value __min = ((((_Value)(-1)) < 0) ? ((_Value)1) << ((sizeof(_Value) * (8)) - (((_Value)(-1)) < 0)) : ((_Value)0)); 
# 59
static const _Value __max = ((((_Value)(-1)) < 0) ? (((((_Value)1) << (((sizeof(_Value) * (8)) - (((_Value)(-1)) < 0)) - (1))) - 1) << 1) + 1 : (~((_Value)0))); 
# 63
static const bool __is_signed = (((_Value)(-1)) < 0); 
# 64
static const int __digits = ((sizeof(_Value) * (8)) - (((_Value)(-1)) < 0)); 
# 65
}; 
# 67
template< class _Value> const _Value 
# 68
__numeric_traits_integer< _Value> ::__min; 
# 70
template< class _Value> const _Value 
# 71
__numeric_traits_integer< _Value> ::__max; 
# 73
template< class _Value> const bool 
# 74
__numeric_traits_integer< _Value> ::__is_signed; 
# 76
template< class _Value> const int 
# 77
__numeric_traits_integer< _Value> ::__digits; 
# 99
template< class _Value> 
# 100
struct __numeric_traits_floating { 
# 103
static const int __max_digits10 = ((2) + ((((std::__are_same< _Value, float> ::__value) ? 24 : ((std::__are_same< _Value, double> ::__value) ? 53 : 106)) * 643L) / (2136))); 
# 106
static const bool __is_signed = true; 
# 107
static const int __digits10 = ((std::__are_same< _Value, float> ::__value) ? 6 : ((std::__are_same< _Value, double> ::__value) ? 15 : 31)); 
# 108
static const int __max_exponent10 = ((std::__are_same< _Value, float> ::__value) ? 38 : ((std::__are_same< _Value, double> ::__value) ? 308 : 308)); 
# 109
}; 
# 111
template< class _Value> const int 
# 112
__numeric_traits_floating< _Value> ::__max_digits10; 
# 114
template< class _Value> const bool 
# 115
__numeric_traits_floating< _Value> ::__is_signed; 
# 117
template< class _Value> const int 
# 118
__numeric_traits_floating< _Value> ::__digits10; 
# 120
template< class _Value> const int 
# 121
__numeric_traits_floating< _Value> ::__max_exponent10; 
# 123
template< class _Value> 
# 124
struct __numeric_traits : public __conditional_type< std::__is_integer< _Value> ::__value, __numeric_traits_integer< _Value> , __numeric_traits_floating< _Value> > ::__type { 
# 128
}; 
# 131
}
# 36 "/usr/include/c++/4.8.2/bits/move.h" 3
namespace std __attribute((__visibility__("default"))) { 
# 45
template< class _Tp> inline _Tp *
# 47
__addressof(_Tp &__r) 
# 48
{ 
# 49
return reinterpret_cast< _Tp *>(&(const_cast< char &>(reinterpret_cast< const volatile char &>(__r)))); 
# 51
} 
# 54
}
# 149
namespace std __attribute((__visibility__("default"))) { 
# 164
template< class _Tp> inline void 
# 166
swap(_Tp &__a, _Tp &__b) 
# 171
{ 
# 175
_Tp __tmp = __a; 
# 176
__a = __b; 
# 177
__b = __tmp; 
# 178
} 
# 183
template< class _Tp, size_t _Nm> inline void 
# 185
swap(_Tp (&__a)[_Nm], _Tp (&__b)[_Nm]) 
# 189
{ 
# 190
for (size_t __n = (0); __n < _Nm; ++__n) { 
# 191
swap((__a)[__n], (__b)[__n]); }  
# 192
} 
# 196
}
# 65 "/usr/include/c++/4.8.2/bits/stl_pair.h" 3
namespace std __attribute((__visibility__("default"))) { 
# 95
template< class _T1, class _T2> 
# 96
struct pair { 
# 98
typedef _T1 first_type; 
# 99
typedef _T2 second_type; 
# 101
_T1 first; 
# 102
_T2 second; 
# 108
pair() : first(), second() 
# 109
{ } 
# 112
pair(const _T1 &__a, const _T2 &__b) : first(__a), second(__b) 
# 113
{ } 
# 117
template< class _U1, class _U2> 
# 118
pair(const std::pair< _U1, _U2>  &__p) : first((__p.first)), second((__p.second)) 
# 119
{ } 
# 209
}; 
# 212
template< class _T1, class _T2> inline bool 
# 214
operator==(const pair< _T1, _T2>  &__x, const pair< _T1, _T2>  &__y) 
# 215
{ return ((__x.first) == (__y.first)) && ((__x.second) == (__y.second)); } 
# 218
template< class _T1, class _T2> inline bool 
# 220
operator<(const pair< _T1, _T2>  &__x, const pair< _T1, _T2>  &__y) 
# 221
{ return ((__x.first) < (__y.first)) || ((!((__y.first) < (__x.first))) && ((__x.second) < (__y.second))); 
# 222
} 
# 225
template< class _T1, class _T2> inline bool 
# 227
operator!=(const pair< _T1, _T2>  &__x, const pair< _T1, _T2>  &__y) 
# 228
{ return !(__x == __y); } 
# 231
template< class _T1, class _T2> inline bool 
# 233
operator>(const pair< _T1, _T2>  &__x, const pair< _T1, _T2>  &__y) 
# 234
{ return __y < __x; } 
# 237
template< class _T1, class _T2> inline bool 
# 239
operator<=(const pair< _T1, _T2>  &__x, const pair< _T1, _T2>  &__y) 
# 240
{ return !(__y < __x); } 
# 243
template< class _T1, class _T2> inline bool 
# 245
operator>=(const pair< _T1, _T2>  &__x, const pair< _T1, _T2>  &__y) 
# 246
{ return !(__x < __y); } 
# 284
template< class _T1, class _T2> inline pair< _T1, _T2>  
# 286
make_pair(_T1 __x, _T2 __y) 
# 287
{ return pair< _T1, _T2> (__x, __y); } 
# 293
}
# 70 "/usr/include/c++/4.8.2/bits/stl_iterator_base_types.h" 3
namespace std __attribute((__visibility__("default"))) { 
# 89
struct input_iterator_tag { }; 
# 92
struct output_iterator_tag { }; 
# 95
struct forward_iterator_tag : public input_iterator_tag { }; 
# 99
struct bidirectional_iterator_tag : public forward_iterator_tag { }; 
# 103
struct random_access_iterator_tag : public bidirectional_iterator_tag { }; 
# 116
template< class _Category, class _Tp, class _Distance = ptrdiff_t, class 
# 117
_Pointer = _Tp *, class _Reference = _Tp &> 
# 118
struct iterator { 
# 121
typedef _Category iterator_category; 
# 123
typedef _Tp value_type; 
# 125
typedef _Distance difference_type; 
# 127
typedef _Pointer pointer; 
# 129
typedef _Reference reference; 
# 130
}; 
# 162
template< class _Iterator> 
# 163
struct iterator_traits { 
# 165
typedef typename _Iterator::iterator_category iterator_category; 
# 166
typedef typename _Iterator::value_type value_type; 
# 167
typedef typename _Iterator::difference_type difference_type; 
# 168
typedef typename _Iterator::pointer pointer; 
# 169
typedef typename _Iterator::reference reference; 
# 170
}; 
# 174
template< class _Tp> 
# 175
struct iterator_traits< _Tp *>  { 
# 177
typedef random_access_iterator_tag iterator_category; 
# 178
typedef _Tp value_type; 
# 179
typedef ptrdiff_t difference_type; 
# 180
typedef _Tp *pointer; 
# 181
typedef _Tp &reference; 
# 182
}; 
# 185
template< class _Tp> 
# 186
struct iterator_traits< const _Tp *>  { 
# 188
typedef random_access_iterator_tag iterator_category; 
# 189
typedef _Tp value_type; 
# 190
typedef ptrdiff_t difference_type; 
# 191
typedef const _Tp *pointer; 
# 192
typedef const _Tp &reference; 
# 193
}; 
# 199
template< class _Iter> inline typename iterator_traits< _Iter> ::iterator_category 
# 201
__iterator_category(const _Iter &) 
# 202
{ return typename iterator_traits< _Iter> ::iterator_category(); } 
# 208
template< class _Iterator, bool _HasBase> 
# 209
struct _Iter_base { 
# 211
typedef _Iterator iterator_type; 
# 212
static iterator_type _S_base(_Iterator __it) 
# 213
{ return __it; } 
# 214
}; 
# 216
template< class _Iterator> 
# 217
struct _Iter_base< _Iterator, true>  { 
# 219
typedef typename _Iterator::iterator_type iterator_type; 
# 220
static iterator_type _S_base(_Iterator __it) 
# 221
{ return (__it.base()); } 
# 222
}; 
# 233
}
# 46 "/usr/include/c++/4.8.2/debug/debug.h" 3
namespace std { 
# 48
namespace __debug { }
# 49
}
# 54
namespace __gnu_debug { 
# 56
using namespace std::__debug;
# 57
}
# 67 "/usr/include/c++/4.8.2/bits/stl_iterator_base_funcs.h" 3
namespace std __attribute((__visibility__("default"))) { 
# 71
template< class _InputIterator> inline typename iterator_traits< _InputIterator> ::difference_type 
# 73
__distance(_InputIterator __first, _InputIterator __last, input_iterator_tag) 
# 75
{ 
# 79
typename iterator_traits< _InputIterator> ::difference_type __n = (0); 
# 80
while (__first != __last) 
# 81
{ 
# 82
++__first; 
# 83
++__n; 
# 84
}  
# 85
return __n; 
# 86
} 
# 88
template< class _RandomAccessIterator> inline typename iterator_traits< _RandomAccessIterator> ::difference_type 
# 90
__distance(_RandomAccessIterator __first, _RandomAccessIterator __last, random_access_iterator_tag) 
# 92
{ 
# 96
return __last - __first; 
# 97
} 
# 112
template< class _InputIterator> inline typename iterator_traits< _InputIterator> ::difference_type 
# 114
distance(_InputIterator __first, _InputIterator __last) 
# 115
{ 
# 117
return std::__distance(__first, __last, std::__iterator_category(__first)); 
# 119
} 
# 121
template< class _InputIterator, class _Distance> inline void 
# 123
__advance(_InputIterator &__i, _Distance __n, input_iterator_tag) 
# 124
{ 
# 127
; 
# 128
while (__n--) { 
# 129
++__i; }  
# 130
} 
# 132
template< class _BidirectionalIterator, class _Distance> inline void 
# 134
__advance(_BidirectionalIterator &__i, _Distance __n, bidirectional_iterator_tag) 
# 136
{ 
# 140
if (__n > 0) { 
# 141
while (__n--) { 
# 142
++__i; }  } else { 
# 144
while (__n++) { 
# 145
--__i; }  }  
# 146
} 
# 148
template< class _RandomAccessIterator, class _Distance> inline void 
# 150
__advance(_RandomAccessIterator &__i, _Distance __n, random_access_iterator_tag) 
# 152
{ 
# 156
__i += __n; 
# 157
} 
# 171
template< class _InputIterator, class _Distance> inline void 
# 173
advance(_InputIterator &__i, _Distance __n) 
# 174
{ 
# 176
typename iterator_traits< _InputIterator> ::difference_type __d = __n; 
# 177
std::__advance(__i, __d, std::__iterator_category(__i)); 
# 178
} 
# 203
}
# 67 "/usr/include/c++/4.8.2/bits/stl_iterator.h" 3
namespace std __attribute((__visibility__("default"))) { 
# 95
template< class _Iterator> 
# 96
class reverse_iterator : public iterator< typename iterator_traits< _Iterator> ::iterator_category, typename iterator_traits< _Iterator> ::value_type, typename iterator_traits< _Iterator> ::difference_type, typename iterator_traits< _Iterator> ::pointer, typename iterator_traits< _Iterator> ::reference>  { 
# 104
protected: _Iterator current; 
# 106
typedef iterator_traits< _Iterator>  __traits_type; 
# 109
public: typedef _Iterator iterator_type; 
# 110
typedef typename iterator_traits< _Iterator> ::difference_type difference_type; 
# 111
typedef typename iterator_traits< _Iterator> ::pointer pointer; 
# 112
typedef typename iterator_traits< _Iterator> ::reference reference; 
# 120
reverse_iterator() : current() { } 
# 126
explicit reverse_iterator(iterator_type __x) : current(__x) { } 
# 131
reverse_iterator(const reverse_iterator &__x) : current(__x.current) 
# 132
{ } 
# 138
template< class _Iter> 
# 139
reverse_iterator(const ::std::reverse_iterator< _Iter>  &__x) : current((__x.base())) 
# 140
{ } 
# 146
iterator_type base() const 
# 147
{ return current; } 
# 160
reference operator*() const 
# 161
{ 
# 162
_Iterator __tmp = current; 
# 163
return *(--__tmp); 
# 164
} 
# 172
pointer operator->() const 
# 173
{ return &operator*(); } 
# 181
reverse_iterator &operator++() 
# 182
{ 
# 183
--(current); 
# 184
return *this; 
# 185
} 
# 193
reverse_iterator operator++(int) 
# 194
{ 
# 195
reverse_iterator __tmp = *this; 
# 196
--(current); 
# 197
return __tmp; 
# 198
} 
# 206
reverse_iterator &operator--() 
# 207
{ 
# 208
++(current); 
# 209
return *this; 
# 210
} 
# 218
reverse_iterator operator--(int) 
# 219
{ 
# 220
reverse_iterator __tmp = *this; 
# 221
++(current); 
# 222
return __tmp; 
# 223
} 
# 231
reverse_iterator operator+(difference_type __n) const 
# 232
{ return ((reverse_iterator)((current) - __n)); } 
# 241
reverse_iterator &operator+=(difference_type __n) 
# 242
{ 
# 243
(current) -= __n; 
# 244
return *this; 
# 245
} 
# 253
reverse_iterator operator-(difference_type __n) const 
# 254
{ return ((reverse_iterator)((current) + __n)); } 
# 263
reverse_iterator &operator-=(difference_type __n) 
# 264
{ 
# 265
(current) += __n; 
# 266
return *this; 
# 267
} 
# 275
reference operator[](difference_type __n) const 
# 276
{ return *((*this) + __n); } 
# 277
}; 
# 289
template< class _Iterator> inline bool 
# 291
operator==(const reverse_iterator< _Iterator>  &__x, const reverse_iterator< _Iterator>  &
# 292
__y) 
# 293
{ return (__x.base()) == (__y.base()); } 
# 295
template< class _Iterator> inline bool 
# 297
operator<(const reverse_iterator< _Iterator>  &__x, const reverse_iterator< _Iterator>  &
# 298
__y) 
# 299
{ return (__y.base()) < (__x.base()); } 
# 301
template< class _Iterator> inline bool 
# 303
operator!=(const reverse_iterator< _Iterator>  &__x, const reverse_iterator< _Iterator>  &
# 304
__y) 
# 305
{ return !(__x == __y); } 
# 307
template< class _Iterator> inline bool 
# 309
operator>(const reverse_iterator< _Iterator>  &__x, const reverse_iterator< _Iterator>  &
# 310
__y) 
# 311
{ return __y < __x; } 
# 313
template< class _Iterator> inline bool 
# 315
operator<=(const reverse_iterator< _Iterator>  &__x, const reverse_iterator< _Iterator>  &
# 316
__y) 
# 317
{ return !(__y < __x); } 
# 319
template< class _Iterator> inline bool 
# 321
operator>=(const reverse_iterator< _Iterator>  &__x, const reverse_iterator< _Iterator>  &
# 322
__y) 
# 323
{ return !(__x < __y); } 
# 325
template< class _Iterator> inline typename reverse_iterator< _Iterator> ::difference_type 
# 327
operator-(const reverse_iterator< _Iterator>  &__x, const reverse_iterator< _Iterator>  &
# 328
__y) 
# 329
{ return (__y.base()) - (__x.base()); } 
# 331
template< class _Iterator> inline reverse_iterator< _Iterator>  
# 333
operator+(typename reverse_iterator< _Iterator> ::difference_type __n, const reverse_iterator< _Iterator>  &
# 334
__x) 
# 335
{ return ((reverse_iterator< _Iterator> )((__x.base()) - __n)); } 
# 339
template< class _IteratorL, class _IteratorR> inline bool 
# 341
operator==(const reverse_iterator< _IteratorL>  &__x, const reverse_iterator< _IteratorR>  &
# 342
__y) 
# 343
{ return (__x.base()) == (__y.base()); } 
# 345
template< class _IteratorL, class _IteratorR> inline bool 
# 347
operator<(const reverse_iterator< _IteratorL>  &__x, const reverse_iterator< _IteratorR>  &
# 348
__y) 
# 349
{ return (__y.base()) < (__x.base()); } 
# 351
template< class _IteratorL, class _IteratorR> inline bool 
# 353
operator!=(const reverse_iterator< _IteratorL>  &__x, const reverse_iterator< _IteratorR>  &
# 354
__y) 
# 355
{ return !(__x == __y); } 
# 357
template< class _IteratorL, class _IteratorR> inline bool 
# 359
operator>(const reverse_iterator< _IteratorL>  &__x, const reverse_iterator< _IteratorR>  &
# 360
__y) 
# 361
{ return __y < __x; } 
# 363
template< class _IteratorL, class _IteratorR> inline bool 
# 365
operator<=(const reverse_iterator< _IteratorL>  &__x, const reverse_iterator< _IteratorR>  &
# 366
__y) 
# 367
{ return !(__y < __x); } 
# 369
template< class _IteratorL, class _IteratorR> inline bool 
# 371
operator>=(const reverse_iterator< _IteratorL>  &__x, const reverse_iterator< _IteratorR>  &
# 372
__y) 
# 373
{ return !(__x < __y); } 
# 375
template< class _IteratorL, class _IteratorR> inline typename reverse_iterator< _IteratorL> ::difference_type 
# 384
operator-(const reverse_iterator< _IteratorL>  &__x, const reverse_iterator< _IteratorR>  &
# 385
__y) 
# 387
{ return (__y.base()) - (__x.base()); } 
# 401
template< class _Container> 
# 402
class back_insert_iterator : public iterator< output_iterator_tag, void, void, void, void>  { 
# 406
protected: _Container *container; 
# 410
public: typedef _Container container_type; 
# 414
explicit back_insert_iterator(_Container &__x) : container((&__x)) { } 
# 429
back_insert_iterator &operator=(typename _Container::const_reference __value) 
# 430
{ 
# 431
((container)->push_back(__value)); 
# 432
return *this; 
# 433
} 
# 452
back_insert_iterator &operator*() 
# 453
{ return *this; } 
# 457
back_insert_iterator &operator++() 
# 458
{ return *this; } 
# 462
back_insert_iterator operator++(int) 
# 463
{ return *this; } 
# 464
}; 
# 477
template< class _Container> inline back_insert_iterator< _Container>  
# 479
back_inserter(_Container &__x) 
# 480
{ return ((back_insert_iterator< _Container> )(__x)); } 
# 492
template< class _Container> 
# 493
class front_insert_iterator : public iterator< output_iterator_tag, void, void, void, void>  { 
# 497
protected: _Container *container; 
# 501
public: typedef _Container container_type; 
# 504
explicit front_insert_iterator(_Container &__x) : container((&__x)) { } 
# 519
front_insert_iterator &operator=(typename _Container::const_reference __value) 
# 520
{ 
# 521
((container)->push_front(__value)); 
# 522
return *this; 
# 523
} 
# 542
front_insert_iterator &operator*() 
# 543
{ return *this; } 
# 547
front_insert_iterator &operator++() 
# 548
{ return *this; } 
# 552
front_insert_iterator operator++(int) 
# 553
{ return *this; } 
# 554
}; 
# 567
template< class _Container> inline front_insert_iterator< _Container>  
# 569
front_inserter(_Container &__x) 
# 570
{ return ((front_insert_iterator< _Container> )(__x)); } 
# 586
template< class _Container> 
# 587
class insert_iterator : public iterator< output_iterator_tag, void, void, void, void>  { 
# 591
protected: _Container *container; 
# 592
typename _Container::iterator iter; 
# 596
public: typedef _Container container_type; 
# 602
insert_iterator(_Container &__x, typename _Container::iterator __i) : container((&__x)), iter(__i) 
# 603
{ } 
# 630
insert_iterator &operator=(typename _Container::const_reference __value) 
# 631
{ 
# 632
(iter) = ((container)->insert(iter, __value)); 
# 633
++(iter); 
# 634
return *this; 
# 635
} 
# 656
insert_iterator &operator*() 
# 657
{ return *this; } 
# 661
insert_iterator &operator++() 
# 662
{ return *this; } 
# 666
insert_iterator &operator++(int) 
# 667
{ return *this; } 
# 668
}; 
# 681
template< class _Container, class _Iterator> inline insert_iterator< _Container>  
# 683
inserter(_Container &__x, _Iterator __i) 
# 684
{ 
# 685
return insert_iterator< _Container> (__x, (typename _Container::iterator)__i); 
# 687
} 
# 692
}
# 694
namespace __gnu_cxx __attribute((__visibility__("default"))) { 
# 705
using std::iterator_traits;
# 706
using std::iterator;
# 707
template< class _Iterator, class _Container> 
# 708
class __normal_iterator { 
# 711
protected: _Iterator _M_current; 
# 713
typedef std::iterator_traits< _Iterator>  __traits_type; 
# 716
public: typedef _Iterator iterator_type; 
# 717
typedef typename std::iterator_traits< _Iterator> ::iterator_category iterator_category; 
# 718
typedef typename std::iterator_traits< _Iterator> ::value_type value_type; 
# 719
typedef typename std::iterator_traits< _Iterator> ::difference_type difference_type; 
# 720
typedef typename std::iterator_traits< _Iterator> ::reference reference; 
# 721
typedef typename std::iterator_traits< _Iterator> ::pointer pointer; 
# 723
__normal_iterator() : _M_current(_Iterator()) { } 
# 726
explicit __normal_iterator(const _Iterator &__i) : _M_current(__i) { } 
# 729
template< class _Iter> 
# 730
__normal_iterator(const __gnu_cxx::__normal_iterator< _Iter, typename __enable_if< std::__are_same< _Iter, typename _Container::pointer> ::__value, _Container> ::__type>  &
# 733
__i) : _M_current((__i.base())) 
# 734
{ } 
# 738
reference operator*() const 
# 739
{ return *(_M_current); } 
# 742
pointer operator->() const 
# 743
{ return _M_current; } 
# 746
__normal_iterator &operator++() 
# 747
{ 
# 748
++(_M_current); 
# 749
return *this; 
# 750
} 
# 753
__normal_iterator operator++(int) 
# 754
{ return ((__normal_iterator)((_M_current)++)); } 
# 758
__normal_iterator &operator--() 
# 759
{ 
# 760
--(_M_current); 
# 761
return *this; 
# 762
} 
# 765
__normal_iterator operator--(int) 
# 766
{ return ((__normal_iterator)((_M_current)--)); } 
# 770
reference operator[](const difference_type &__n) const 
# 771
{ return (_M_current)[__n]; } 
# 774
__normal_iterator &operator+=(const difference_type &__n) 
# 775
{ (_M_current) += __n; return *this; } 
# 778
__normal_iterator operator+(const difference_type &__n) const 
# 779
{ return ((__normal_iterator)((_M_current) + __n)); } 
# 782
__normal_iterator &operator-=(const difference_type &__n) 
# 783
{ (_M_current) -= __n; return *this; } 
# 786
__normal_iterator operator-(const difference_type &__n) const 
# 787
{ return ((__normal_iterator)((_M_current) - __n)); } 
# 790
const _Iterator &base() const 
# 791
{ return _M_current; } 
# 792
}; 
# 803
template< class _IteratorL, class _IteratorR, class _Container> inline bool 
# 805
operator==(const __normal_iterator< _IteratorL, _Container>  &__lhs, const __normal_iterator< _IteratorR, _Container>  &
# 806
__rhs) 
# 807
{ return (__lhs.base()) == (__rhs.base()); } 
# 809
template< class _Iterator, class _Container> inline bool 
# 811
operator==(const __normal_iterator< _Iterator, _Container>  &__lhs, const __normal_iterator< _Iterator, _Container>  &
# 812
__rhs) 
# 813
{ return (__lhs.base()) == (__rhs.base()); } 
# 815
template< class _IteratorL, class _IteratorR, class _Container> inline bool 
# 817
operator!=(const __normal_iterator< _IteratorL, _Container>  &__lhs, const __normal_iterator< _IteratorR, _Container>  &
# 818
__rhs) 
# 819
{ return (__lhs.base()) != (__rhs.base()); } 
# 821
template< class _Iterator, class _Container> inline bool 
# 823
operator!=(const __normal_iterator< _Iterator, _Container>  &__lhs, const __normal_iterator< _Iterator, _Container>  &
# 824
__rhs) 
# 825
{ return (__lhs.base()) != (__rhs.base()); } 
# 828
template< class _IteratorL, class _IteratorR, class _Container> inline bool 
# 830
operator<(const __normal_iterator< _IteratorL, _Container>  &__lhs, const __normal_iterator< _IteratorR, _Container>  &
# 831
__rhs) 
# 832
{ return (__lhs.base()) < (__rhs.base()); } 
# 834
template< class _Iterator, class _Container> inline bool 
# 836
operator<(const __normal_iterator< _Iterator, _Container>  &__lhs, const __normal_iterator< _Iterator, _Container>  &
# 837
__rhs) 
# 838
{ return (__lhs.base()) < (__rhs.base()); } 
# 840
template< class _IteratorL, class _IteratorR, class _Container> inline bool 
# 842
operator>(const __normal_iterator< _IteratorL, _Container>  &__lhs, const __normal_iterator< _IteratorR, _Container>  &
# 843
__rhs) 
# 844
{ return (__lhs.base()) > (__rhs.base()); } 
# 846
template< class _Iterator, class _Container> inline bool 
# 848
operator>(const __normal_iterator< _Iterator, _Container>  &__lhs, const __normal_iterator< _Iterator, _Container>  &
# 849
__rhs) 
# 850
{ return (__lhs.base()) > (__rhs.base()); } 
# 852
template< class _IteratorL, class _IteratorR, class _Container> inline bool 
# 854
operator<=(const __normal_iterator< _IteratorL, _Container>  &__lhs, const __normal_iterator< _IteratorR, _Container>  &
# 855
__rhs) 
# 856
{ return (__lhs.base()) <= (__rhs.base()); } 
# 858
template< class _Iterator, class _Container> inline bool 
# 860
operator<=(const __normal_iterator< _Iterator, _Container>  &__lhs, const __normal_iterator< _Iterator, _Container>  &
# 861
__rhs) 
# 862
{ return (__lhs.base()) <= (__rhs.base()); } 
# 864
template< class _IteratorL, class _IteratorR, class _Container> inline bool 
# 866
operator>=(const __normal_iterator< _IteratorL, _Container>  &__lhs, const __normal_iterator< _IteratorR, _Container>  &
# 867
__rhs) 
# 868
{ return (__lhs.base()) >= (__rhs.base()); } 
# 870
template< class _Iterator, class _Container> inline bool 
# 872
operator>=(const __normal_iterator< _Iterator, _Container>  &__lhs, const __normal_iterator< _Iterator, _Container>  &
# 873
__rhs) 
# 874
{ return (__lhs.base()) >= (__rhs.base()); } 
# 880
template< class _IteratorL, class _IteratorR, class _Container> inline typename __normal_iterator< _IteratorL, _Container> ::difference_type 
# 889
operator-(const __normal_iterator< _IteratorL, _Container>  &__lhs, const __normal_iterator< _IteratorR, _Container>  &
# 890
__rhs) 
# 892
{ return (__lhs.base()) - (__rhs.base()); } 
# 894
template< class _Iterator, class _Container> inline typename __normal_iterator< _Iterator, _Container> ::difference_type 
# 896
operator-(const __normal_iterator< _Iterator, _Container>  &__lhs, const __normal_iterator< _Iterator, _Container>  &
# 897
__rhs) 
# 898
{ return (__lhs.base()) - (__rhs.base()); } 
# 900
template< class _Iterator, class _Container> inline __normal_iterator< _Iterator, _Container>  
# 902
operator+(typename __normal_iterator< _Iterator, _Container> ::difference_type 
# 903
__n, const __normal_iterator< _Iterator, _Container>  &__i) 
# 904
{ return ((__normal_iterator< _Iterator, _Container> )((__i.base()) + __n)); } 
# 907
}
# 72 "/usr/include/c++/4.8.2/bits/stl_algobase.h" 3
namespace std __attribute((__visibility__("default"))) { 
# 80
template< bool _BoolType> 
# 81
struct __iter_swap { 
# 83
template< class _ForwardIterator1, class _ForwardIterator2> static void 
# 85
iter_swap(_ForwardIterator1 __a, _ForwardIterator2 __b) 
# 86
{ 
# 88
typedef typename iterator_traits< _ForwardIterator1> ::value_type _ValueType1; 
# 89
_ValueType1 __tmp = *__a; 
# 90
(*__a) = (*__b); 
# 91
(*__b) = __tmp; 
# 92
} 
# 93
}; 
# 96
template<> struct __iter_swap< true>  { 
# 98
template< class _ForwardIterator1, class _ForwardIterator2> static void 
# 100
iter_swap(_ForwardIterator1 __a, _ForwardIterator2 __b) 
# 101
{ 
# 102
swap(*__a, *__b); 
# 103
} 
# 104
}; 
# 117
template< class _ForwardIterator1, class _ForwardIterator2> inline void 
# 119
iter_swap(_ForwardIterator1 __a, _ForwardIterator2 __b) 
# 120
{ 
# 129
typedef typename iterator_traits< _ForwardIterator1> ::value_type _ValueType1; 
# 131
typedef typename iterator_traits< _ForwardIterator2> ::value_type _ValueType2; 
# 139
typedef typename iterator_traits< _ForwardIterator1> ::reference _ReferenceType1; 
# 141
typedef typename iterator_traits< _ForwardIterator2> ::reference _ReferenceType2; 
# 142
std::__iter_swap< __are_same< typename iterator_traits< _ForwardIterator1> ::value_type, typename iterator_traits< _ForwardIterator2> ::value_type> ::__value && __are_same< typename iterator_traits< _ForwardIterator1> ::value_type &, typename iterator_traits< _ForwardIterator1> ::reference> ::__value && __are_same< typename iterator_traits< _ForwardIterator2> ::value_type &, typename iterator_traits< _ForwardIterator2> ::reference> ::__value> ::iter_swap(__a, __b); 
# 149
} 
# 163
template< class _ForwardIterator1, class _ForwardIterator2> _ForwardIterator2 
# 165
swap_ranges(_ForwardIterator1 __first1, _ForwardIterator1 __last1, _ForwardIterator2 
# 166
__first2) 
# 167
{ 
# 173
; 
# 175
for (; __first1 != __last1; (++__first1), (++__first2)) { 
# 176
std::iter_swap(__first1, __first2); }  
# 177
return __first2; 
# 178
} 
# 191
template< class _Tp> inline const _Tp &
# 193
min(const _Tp &__a, const _Tp &__b) 
# 194
{ 
# 198
if (__b < __a) { 
# 199
return __b; }  
# 200
return __a; 
# 201
} 
# 214
template< class _Tp> inline const _Tp &
# 216
max(const _Tp &__a, const _Tp &__b) 
# 217
{ 
# 221
if (__a < __b) { 
# 222
return __b; }  
# 223
return __a; 
# 224
} 
# 237
template< class _Tp, class _Compare> inline const _Tp &
# 239
min(const _Tp &__a, const _Tp &__b, _Compare __comp) 
# 240
{ 
# 242
if (__comp(__b, __a)) { 
# 243
return __b; }  
# 244
return __a; 
# 245
} 
# 258
template< class _Tp, class _Compare> inline const _Tp &
# 260
max(const _Tp &__a, const _Tp &__b, _Compare __comp) 
# 261
{ 
# 263
if (__comp(__a, __b)) { 
# 264
return __b; }  
# 265
return __a; 
# 266
} 
# 270
template< class _Iterator> 
# 271
struct _Niter_base : public _Iter_base< _Iterator, __is_normal_iterator< _Iterator> ::__value>  { 
# 273
}; 
# 275
template< class _Iterator> inline typename _Niter_base< _Iterator> ::iterator_type 
# 277
__niter_base(_Iterator __it) 
# 278
{ return std::_Niter_base< _Iterator> ::_S_base(__it); } 
# 281
template< class _Iterator> 
# 282
struct _Miter_base : public _Iter_base< _Iterator, __is_move_iterator< _Iterator> ::__value>  { 
# 284
}; 
# 286
template< class _Iterator> inline typename _Miter_base< _Iterator> ::iterator_type 
# 288
__miter_base(_Iterator __it) 
# 289
{ return std::_Miter_base< _Iterator> ::_S_base(__it); } 
# 297
template< bool , bool , class > 
# 298
struct __copy_move { 
# 300
template< class _II, class _OI> static _OI 
# 302
__copy_m(_II __first, _II __last, _OI __result) 
# 303
{ 
# 304
for (; __first != __last; (++__result), (++__first)) { 
# 305
(*__result) = (*__first); }  
# 306
return __result; 
# 307
} 
# 308
}; 
# 326
template<> struct __copy_move< false, false, random_access_iterator_tag>  { 
# 328
template< class _II, class _OI> static _OI 
# 330
__copy_m(_II __first, _II __last, _OI __result) 
# 331
{ 
# 332
typedef typename iterator_traits< _II> ::difference_type _Distance; 
# 333
for (_Distance __n = __last - __first; __n > 0; --__n) 
# 334
{ 
# 335
(*__result) = (*__first); 
# 336
++__first; 
# 337
++__result; 
# 338
}  
# 339
return __result; 
# 340
} 
# 341
}; 
# 363
template< bool _IsMove> 
# 364
struct __copy_move< _IsMove, true, random_access_iterator_tag>  { 
# 366
template< class _Tp> static _Tp *
# 368
__copy_m(const _Tp *__first, const _Tp *__last, _Tp *__result) 
# 369
{ 
# 370
const ptrdiff_t _Num = __last - __first; 
# 371
if (_Num) { 
# 372
__builtin_memmove(__result, __first, sizeof(_Tp) * _Num); }  
# 373
return __result + _Num; 
# 374
} 
# 375
}; 
# 377
template< bool _IsMove, class _II, class _OI> inline _OI 
# 379
__copy_move_a(_II __first, _II __last, _OI __result) 
# 380
{ 
# 381
typedef typename iterator_traits< _II> ::value_type _ValueTypeI; 
# 382
typedef typename iterator_traits< _OI> ::value_type _ValueTypeO; 
# 383
typedef typename iterator_traits< _II> ::iterator_category _Category; 
# 384
const bool __simple = (__is_trivial(_ValueTypeI) && __is_pointer< _II> ::__value && __is_pointer< _OI> ::__value && __are_same< typename iterator_traits< _II> ::value_type, typename iterator_traits< _OI> ::value_type> ::__value); 
# 389
return std::__copy_move< _IsMove, __simple, typename iterator_traits< _II> ::iterator_category> ::__copy_m(__first, __last, __result); 
# 391
} 
# 395
template< class _CharT> struct char_traits; 
# 398
template< class _CharT, class _Traits> class istreambuf_iterator; 
# 401
template< class _CharT, class _Traits> class ostreambuf_iterator; 
# 404
template< bool _IsMove, class _CharT> typename __gnu_cxx::__enable_if< __is_char< _CharT> ::__value, ostreambuf_iterator< _CharT, char_traits< _CharT> > > ::__type __copy_move_a2(_CharT *, _CharT *, ostreambuf_iterator< _CharT, char_traits< _CharT> > ); 
# 410
template< bool _IsMove, class _CharT> typename __gnu_cxx::__enable_if< __is_char< _CharT> ::__value, ostreambuf_iterator< _CharT, char_traits< _CharT> > > ::__type __copy_move_a2(const _CharT *, const _CharT *, ostreambuf_iterator< _CharT, char_traits< _CharT> > ); 
# 416
template< bool _IsMove, class _CharT> typename __gnu_cxx::__enable_if< __is_char< _CharT> ::__value, _CharT *> ::__type __copy_move_a2(istreambuf_iterator< _CharT, char_traits< _CharT> > , istreambuf_iterator< _CharT, char_traits< _CharT> > , _CharT *); 
# 422
template< bool _IsMove, class _II, class _OI> inline _OI 
# 424
__copy_move_a2(_II __first, _II __last, _OI __result) 
# 425
{ 
# 426
return (_OI)std::__copy_move_a< _IsMove> (std::__niter_base(__first), std::__niter_base(__last), std::__niter_base(__result)); 
# 429
} 
# 448
template< class _II, class _OI> inline _OI 
# 450
copy(_II __first, _II __last, _OI __result) 
# 451
{ 
# 456
; 
# 458
return std::__copy_move_a2< __is_move_iterator< _II> ::__value> (std::__miter_base(__first), std::__miter_base(__last), __result); 
# 461
} 
# 500
template< bool , bool , class > 
# 501
struct __copy_move_backward { 
# 503
template< class _BI1, class _BI2> static _BI2 
# 505
__copy_move_b(_BI1 __first, _BI1 __last, _BI2 __result) 
# 506
{ 
# 507
while (__first != __last) { 
# 508
(*(--__result)) = (*(--__last)); }  
# 509
return __result; 
# 510
} 
# 511
}; 
# 529
template<> struct __copy_move_backward< false, false, random_access_iterator_tag>  { 
# 531
template< class _BI1, class _BI2> static _BI2 
# 533
__copy_move_b(_BI1 __first, _BI1 __last, _BI2 __result) 
# 534
{ 
# 535
typename iterator_traits< _BI1> ::difference_type __n; 
# 536
for (__n = (__last - __first); __n > 0; --__n) { 
# 537
(*(--__result)) = (*(--__last)); }  
# 538
return __result; 
# 539
} 
# 540
}; 
# 558
template< bool _IsMove> 
# 559
struct __copy_move_backward< _IsMove, true, random_access_iterator_tag>  { 
# 561
template< class _Tp> static _Tp *
# 563
__copy_move_b(const _Tp *__first, const _Tp *__last, _Tp *__result) 
# 564
{ 
# 565
const ptrdiff_t _Num = __last - __first; 
# 566
if (_Num) { 
# 567
__builtin_memmove(__result - _Num, __first, sizeof(_Tp) * _Num); }  
# 568
return __result - _Num; 
# 569
} 
# 570
}; 
# 572
template< bool _IsMove, class _BI1, class _BI2> inline _BI2 
# 574
__copy_move_backward_a(_BI1 __first, _BI1 __last, _BI2 __result) 
# 575
{ 
# 576
typedef typename iterator_traits< _BI1> ::value_type _ValueType1; 
# 577
typedef typename iterator_traits< _BI2> ::value_type _ValueType2; 
# 578
typedef typename iterator_traits< _BI1> ::iterator_category _Category; 
# 579
const bool __simple = (__is_trivial(_ValueType1) && __is_pointer< _BI1> ::__value && __is_pointer< _BI2> ::__value && __are_same< typename iterator_traits< _BI1> ::value_type, typename iterator_traits< _BI2> ::value_type> ::__value); 
# 584
return std::__copy_move_backward< _IsMove, __simple, typename iterator_traits< _BI1> ::iterator_category> ::__copy_move_b(__first, __last, __result); 
# 588
} 
# 590
template< bool _IsMove, class _BI1, class _BI2> inline _BI2 
# 592
__copy_move_backward_a2(_BI1 __first, _BI1 __last, _BI2 __result) 
# 593
{ 
# 594
return (_BI2)std::__copy_move_backward_a< _IsMove> (std::__niter_base(__first), std::__niter_base(__last), std::__niter_base(__result)); 
# 597
} 
# 617
template< class _BI1, class _BI2> inline _BI2 
# 619
copy_backward(_BI1 __first, _BI1 __last, _BI2 __result) 
# 620
{ 
# 627
; 
# 629
return std::__copy_move_backward_a2< __is_move_iterator< _BI1> ::__value> (std::__miter_base(__first), std::__miter_base(__last), __result); 
# 632
} 
# 675
template< class _ForwardIterator, class _Tp> inline typename __gnu_cxx::__enable_if< !__is_scalar< _Tp> ::__value, void> ::__type 
# 678
__fill_a(_ForwardIterator __first, _ForwardIterator __last, const _Tp &
# 679
__value) 
# 680
{ 
# 681
for (; __first != __last; ++__first) { 
# 682
(*__first) = __value; }  
# 683
} 
# 685
template< class _ForwardIterator, class _Tp> inline typename __gnu_cxx::__enable_if< __is_scalar< _Tp> ::__value, void> ::__type 
# 688
__fill_a(_ForwardIterator __first, _ForwardIterator __last, const _Tp &
# 689
__value) 
# 690
{ 
# 691
const _Tp __tmp = __value; 
# 692
for (; __first != __last; ++__first) { 
# 693
(*__first) = __tmp; }  
# 694
} 
# 697
template< class _Tp> inline typename __gnu_cxx::__enable_if< __is_byte< _Tp> ::__value, void> ::__type 
# 700
__fill_a(_Tp *__first, _Tp *__last, const _Tp &__c) 
# 701
{ 
# 702
const _Tp __tmp = __c; 
# 703
__builtin_memset(__first, static_cast< unsigned char>(__tmp), __last - __first); 
# 705
} 
# 719
template< class _ForwardIterator, class _Tp> inline void 
# 721
fill(_ForwardIterator __first, _ForwardIterator __last, const _Tp &__value) 
# 722
{ 
# 726
; 
# 728
std::__fill_a(std::__niter_base(__first), std::__niter_base(__last), __value); 
# 730
} 
# 732
template< class _OutputIterator, class _Size, class _Tp> inline typename __gnu_cxx::__enable_if< !__is_scalar< _Tp> ::__value, _OutputIterator> ::__type 
# 735
__fill_n_a(_OutputIterator __first, _Size __n, const _Tp &__value) 
# 736
{ 
# 737
for (__decltype((__n + 0)) __niter = __n; __niter > 0; (--__niter), (++__first)) { 
# 739
(*__first) = __value; }  
# 740
return __first; 
# 741
} 
# 743
template< class _OutputIterator, class _Size, class _Tp> inline typename __gnu_cxx::__enable_if< __is_scalar< _Tp> ::__value, _OutputIterator> ::__type 
# 746
__fill_n_a(_OutputIterator __first, _Size __n, const _Tp &__value) 
# 747
{ 
# 748
const _Tp __tmp = __value; 
# 749
for (__decltype((__n + 0)) __niter = __n; __niter > 0; (--__niter), (++__first)) { 
# 751
(*__first) = __tmp; }  
# 752
return __first; 
# 753
} 
# 755
template< class _Size, class _Tp> inline typename __gnu_cxx::__enable_if< __is_byte< _Tp> ::__value, _Tp *> ::__type 
# 758
__fill_n_a(_Tp *__first, _Size __n, const _Tp &__c) 
# 759
{ 
# 760
std::__fill_a(__first, __first + __n, __c); 
# 761
return __first + __n; 
# 762
} 
# 779
template< class _OI, class _Size, class _Tp> inline _OI 
# 781
fill_n(_OI __first, _Size __n, const _Tp &__value) 
# 782
{ 
# 786
return (_OI)std::__fill_n_a(std::__niter_base(__first), __n, __value); 
# 787
} 
# 789
template< bool _BoolType> 
# 790
struct __equal { 
# 792
template< class _II1, class _II2> static bool 
# 794
equal(_II1 __first1, _II1 __last1, _II2 __first2) 
# 795
{ 
# 796
for (; __first1 != __last1; (++__first1), (++__first2)) { 
# 797
if (!((*__first1) == (*__first2))) { 
# 798
return false; }  }  
# 799
return true; 
# 800
} 
# 801
}; 
# 804
template<> struct __equal< true>  { 
# 806
template< class _Tp> static bool 
# 808
equal(const _Tp *__first1, const _Tp *__last1, const _Tp *__first2) 
# 809
{ 
# 810
return !(__builtin_memcmp(__first1, __first2, sizeof(_Tp) * (__last1 - __first1))); 
# 812
} 
# 813
}; 
# 815
template< class _II1, class _II2> inline bool 
# 817
__equal_aux(_II1 __first1, _II1 __last1, _II2 __first2) 
# 818
{ 
# 819
typedef typename iterator_traits< _II1> ::value_type _ValueType1; 
# 820
typedef typename iterator_traits< _II2> ::value_type _ValueType2; 
# 821
const bool __simple = ((__is_integer< typename iterator_traits< _II1> ::value_type> ::__value || __is_pointer< typename iterator_traits< _II1> ::value_type> ::__value) && __is_pointer< _II1> ::__value && __is_pointer< _II2> ::__value && __are_same< typename iterator_traits< _II1> ::value_type, typename iterator_traits< _II2> ::value_type> ::__value); 
# 827
return std::__equal< __simple> ::equal(__first1, __last1, __first2); 
# 828
} 
# 831
template< class , class > 
# 832
struct __lc_rai { 
# 834
template< class _II1, class _II2> static _II1 
# 836
__newlast1(_II1, _II1 __last1, _II2, _II2) 
# 837
{ return __last1; } 
# 839
template< class _II> static bool 
# 841
__cnd2(_II __first, _II __last) 
# 842
{ return __first != __last; } 
# 843
}; 
# 846
template<> struct __lc_rai< random_access_iterator_tag, random_access_iterator_tag>  { 
# 848
template< class _RAI1, class _RAI2> static _RAI1 
# 850
__newlast1(_RAI1 __first1, _RAI1 __last1, _RAI2 
# 851
__first2, _RAI2 __last2) 
# 852
{ 
# 854
const typename iterator_traits< _RAI1> ::difference_type __diff1 = __last1 - __first1; 
# 856
const typename iterator_traits< _RAI2> ::difference_type __diff2 = __last2 - __first2; 
# 857
return (__diff2 < __diff1) ? __first1 + __diff2 : __last1; 
# 858
} 
# 860
template< class _RAI> static bool 
# 862
__cnd2(_RAI, _RAI) 
# 863
{ return true; } 
# 864
}; 
# 866
template< bool _BoolType> 
# 867
struct __lexicographical_compare { 
# 869
template< class _II1, class _II2> static bool __lc(_II1, _II1, _II2, _II2); 
# 871
}; 
# 873
template< bool _BoolType> 
# 874
template< class _II1, class _II2> bool 
# 877
__lexicographical_compare< _BoolType> ::__lc(_II1 __first1, _II1 __last1, _II2 __first2, _II2 __last2) 
# 878
{ 
# 879
typedef typename iterator_traits< _II1> ::iterator_category _Category1; 
# 880
typedef typename iterator_traits< _II2> ::iterator_category _Category2; 
# 881
typedef __lc_rai< typename iterator_traits< _II1> ::iterator_category, typename iterator_traits< _II2> ::iterator_category>  __rai_type; 
# 883
__last1 = __rai_type::__newlast1(__first1, __last1, __first2, __last2); 
# 885
for (; (__first1 != __last1) && __rai_type::__cnd2(__first2, __last2); (++__first1), (++__first2)) 
# 887
{ 
# 888
if ((*__first1) < (*__first2)) { 
# 889
return true; }  
# 890
if ((*__first2) < (*__first1)) { 
# 891
return false; }  
# 892
}  
# 893
return (__first1 == __last1) && (__first2 != __last2); 
# 894
} 
# 897
template<> struct __lexicographical_compare< true>  { 
# 899
template< class _Tp, class _Up> static bool 
# 901
__lc(const _Tp *__first1, const _Tp *__last1, const _Up *
# 902
__first2, const _Up *__last2) 
# 903
{ 
# 904
const size_t __len1 = __last1 - __first1; 
# 905
const size_t __len2 = __last2 - __first2; 
# 906
const int __result = __builtin_memcmp(__first1, __first2, std::min(__len1, __len2)); 
# 908
return (__result != 0) ? __result < 0 : (__len1 < __len2); 
# 909
} 
# 910
}; 
# 912
template< class _II1, class _II2> inline bool 
# 914
__lexicographical_compare_aux(_II1 __first1, _II1 __last1, _II2 
# 915
__first2, _II2 __last2) 
# 916
{ 
# 917
typedef typename iterator_traits< _II1> ::value_type _ValueType1; 
# 918
typedef typename iterator_traits< _II2> ::value_type _ValueType2; 
# 919
const bool __simple = (__is_byte< typename iterator_traits< _II1> ::value_type> ::__value && __is_byte< typename iterator_traits< _II2> ::value_type> ::__value && (!__gnu_cxx::__numeric_traits< typename iterator_traits< _II1> ::value_type> ::__is_signed) && (!__gnu_cxx::__numeric_traits< typename iterator_traits< _II2> ::value_type> ::__is_signed) && __is_pointer< _II1> ::__value && __is_pointer< _II2> ::__value); 
# 926
return std::__lexicographical_compare< __simple> ::__lc(__first1, __last1, __first2, __last2); 
# 928
} 
# 941
template< class _ForwardIterator, class _Tp> _ForwardIterator 
# 943
lower_bound(_ForwardIterator __first, _ForwardIterator __last, const _Tp &
# 944
__val) 
# 945
{ 
# 951
typedef typename iterator_traits< _ForwardIterator> ::difference_type _DistanceType; 
# 956
; 
# 958
_DistanceType __len = std::distance(__first, __last); 
# 960
while (__len > 0) 
# 961
{ 
# 962
_DistanceType __half = __len >> 1; 
# 963
_ForwardIterator __middle = __first; 
# 964
std::advance(__middle, __half); 
# 965
if ((*__middle) < __val) 
# 966
{ 
# 967
__first = __middle; 
# 968
++__first; 
# 969
__len = ((__len - __half) - 1); 
# 970
} else { 
# 972
__len = __half; }  
# 973
}  
# 974
return __first; 
# 975
} 
# 980
inline int __lg(int __n) 
# 981
{ return ((sizeof(int) * (8)) - (1)) - (__builtin_clz(__n)); } 
# 984
inline unsigned __lg(unsigned __n) 
# 985
{ return ((sizeof(int) * (8)) - (1)) - (__builtin_clz(__n)); } 
# 988
inline long __lg(long __n) 
# 989
{ return ((sizeof(long) * (8)) - (1)) - (__builtin_clzl(__n)); } 
# 992
inline unsigned long __lg(unsigned long __n) 
# 993
{ return ((sizeof(long) * (8)) - (1)) - (__builtin_clzl(__n)); } 
# 996
inline long long __lg(long long __n) 
# 997
{ return ((sizeof(long long) * (8)) - (1)) - (__builtin_clzll(__n)); } 
# 1000
inline unsigned long long __lg(unsigned long long __n) 
# 1001
{ return ((sizeof(long long) * (8)) - (1)) - (__builtin_clzll(__n)); } 
# 1019
template< class _II1, class _II2> inline bool 
# 1021
equal(_II1 __first1, _II1 __last1, _II2 __first2) 
# 1022
{ 
# 1029
; 
# 1031
return std::__equal_aux(std::__niter_base(__first1), std::__niter_base(__last1), std::__niter_base(__first2)); 
# 1034
} 
# 1051
template< class _IIter1, class _IIter2, class _BinaryPredicate> inline bool 
# 1053
equal(_IIter1 __first1, _IIter1 __last1, _IIter2 
# 1054
__first2, _BinaryPredicate __binary_pred) 
# 1055
{ 
# 1059
; 
# 1061
for (; __first1 != __last1; (++__first1), (++__first2)) { 
# 1062
if (!((bool)__binary_pred(*__first1, *__first2))) { 
# 1063
return false; }  }  
# 1064
return true; 
# 1065
} 
# 1082
template< class _II1, class _II2> inline bool 
# 1084
lexicographical_compare(_II1 __first1, _II1 __last1, _II2 
# 1085
__first2, _II2 __last2) 
# 1086
{ 
# 1096
; 
# 1097
; 
# 1099
return std::__lexicographical_compare_aux(std::__niter_base(__first1), std::__niter_base(__last1), std::__niter_base(__first2), std::__niter_base(__last2)); 
# 1103
} 
# 1118
template< class _II1, class _II2, class _Compare> bool 
# 1120
lexicographical_compare(_II1 __first1, _II1 __last1, _II2 
# 1121
__first2, _II2 __last2, _Compare __comp) 
# 1122
{ 
# 1123
typedef typename iterator_traits< _II1> ::iterator_category _Category1; 
# 1124
typedef typename iterator_traits< _II2> ::iterator_category _Category2; 
# 1125
typedef __lc_rai< typename iterator_traits< _II1> ::iterator_category, typename iterator_traits< _II2> ::iterator_category>  __rai_type; 
# 1130
; 
# 1131
; 
# 1133
__last1 = __rai_type::__newlast1(__first1, __last1, __first2, __last2); 
# 1134
for (; (__first1 != __last1) && __rai_type::__cnd2(__first2, __last2); (++__first1), (++__first2)) 
# 1136
{ 
# 1137
if (__comp(*__first1, *__first2)) { 
# 1138
return true; }  
# 1139
if (__comp(*__first2, *__first1)) { 
# 1140
return false; }  
# 1141
}  
# 1142
return (__first1 == __last1) && (__first2 != __last2); 
# 1143
} 
# 1158
template< class _InputIterator1, class _InputIterator2> pair< _InputIterator1, _InputIterator2>  
# 1160
mismatch(_InputIterator1 __first1, _InputIterator1 __last1, _InputIterator2 
# 1161
__first2) 
# 1162
{ 
# 1169
; 
# 1171
while ((__first1 != __last1) && ((*__first1) == (*__first2))) 
# 1172
{ 
# 1173
++__first1; 
# 1174
++__first2; 
# 1175
}  
# 1176
return pair< _InputIterator1, _InputIterator2> (__first1, __first2); 
# 1177
} 
# 1195
template< class _InputIterator1, class _InputIterator2, class 
# 1196
_BinaryPredicate> pair< _InputIterator1, _InputIterator2>  
# 1198
mismatch(_InputIterator1 __first1, _InputIterator1 __last1, _InputIterator2 
# 1199
__first2, _BinaryPredicate __binary_pred) 
# 1200
{ 
# 1204
; 
# 1206
while ((__first1 != __last1) && ((bool)__binary_pred(*__first1, *__first2))) 
# 1207
{ 
# 1208
++__first1; 
# 1209
++__first2; 
# 1210
}  
# 1211
return pair< _InputIterator1, _InputIterator2> (__first1, __first2); 
# 1212
} 
# 1215
}
# 35 "/usr/include/c++/4.8.2/exception" 3
#pragma GCC visibility push ( default )
# 40
extern "C++" {
# 42
namespace std { 
# 60
class exception { 
# 63
public: exception() throw() { } 
# 64
virtual ~exception() throw(); 
# 68
virtual const char *what() const throw(); 
# 69
}; 
# 73
class bad_exception : public exception { 
# 76
public: bad_exception() throw() { } 
# 80
virtual ~bad_exception() throw(); 
# 83
virtual const char *what() const throw(); 
# 84
}; 
# 87
typedef void (*terminate_handler)(void); 
# 90
typedef void (*unexpected_handler)(void); 
# 93
terminate_handler set_terminate(terminate_handler) throw(); 
# 97
void terminate() throw() __attribute((__noreturn__)); 
# 100
unexpected_handler set_unexpected(unexpected_handler) throw(); 
# 104
void unexpected() __attribute((__noreturn__)); 
# 117
bool uncaught_exception() throw() __attribute((__pure__)); 
# 120
}
# 122
namespace __gnu_cxx { 
# 142
void __verbose_terminate_handler(); 
# 145
}
# 147
}
# 149
#pragma GCC visibility pop
# 42 "/usr/include/c++/4.8.2/new" 3
#pragma GCC visibility push ( default )
# 44
extern "C++" {
# 46
namespace std { 
# 54
class bad_alloc : public exception { 
# 57
public: bad_alloc() throw() { } 
# 61
virtual ~bad_alloc() throw(); 
# 64
virtual const char *what() const throw(); 
# 65
}; 
# 67
struct nothrow_t { }; 
# 69
extern const nothrow_t nothrow; 
# 73
typedef void (*new_handler)(void); 
# 77
new_handler set_new_handler(new_handler) throw(); 
# 78
}
# 91
void *operator new(std::size_t) throw(std::bad_alloc)
# 92
 __attribute((__externally_visible__)); 
# 93
void *operator new[](std::size_t) throw(std::bad_alloc)
# 94
 __attribute((__externally_visible__)); 
# 95
void operator delete(void *) throw()
# 96
 __attribute((__externally_visible__)); 
# 97
void operator delete[](void *) throw()
# 98
 __attribute((__externally_visible__)); 
# 99
void *operator new(std::size_t, const std::nothrow_t &) throw()
# 100
 __attribute((__externally_visible__)); 
# 101
void *operator new[](std::size_t, const std::nothrow_t &) throw()
# 102
 __attribute((__externally_visible__)); 
# 103
void operator delete(void *, const std::nothrow_t &) throw()
# 104
 __attribute((__externally_visible__)); 
# 105
void operator delete[](void *, const std::nothrow_t &) throw()
# 106
 __attribute((__externally_visible__)); 
# 109
inline void *operator new(std::size_t, void *__p) throw() 
# 110
{ return __p; } 
# 111
inline void *operator new[](std::size_t, void *__p) throw() 
# 112
{ return __p; } 
# 115
inline void operator delete(void *, void *) throw() { } 
# 116
inline void operator delete[](void *, void *) throw() { } 
# 118
}
# 120
#pragma GCC visibility pop
# 40 "/usr/include/c++/4.8.2/ext/new_allocator.h" 3
namespace __gnu_cxx __attribute((__visibility__("default"))) { 
# 44
using std::size_t;
# 45
using std::ptrdiff_t;
# 57
template< class _Tp> 
# 58
class new_allocator { 
# 61
public: typedef std::size_t size_type; 
# 62
typedef std::ptrdiff_t difference_type; 
# 63
typedef _Tp *pointer; 
# 64
typedef const _Tp *const_pointer; 
# 65
typedef _Tp &reference; 
# 66
typedef const _Tp &const_reference; 
# 67
typedef _Tp value_type; 
# 69
template< class _Tp1> 
# 70
struct rebind { 
# 71
typedef __gnu_cxx::new_allocator< _Tp1>  other; }; 
# 79
new_allocator() throw() { } 
# 81
new_allocator(const new_allocator &) throw() { } 
# 83
template< class _Tp1> 
# 84
new_allocator(const __gnu_cxx::new_allocator< _Tp1>  &) throw() { } 
# 86
~new_allocator() throw() { } 
# 89
pointer address(reference __x) const 
# 90
{ return std::__addressof(__x); } 
# 93
const_pointer address(const_reference __x) const 
# 94
{ return std::__addressof(__x); } 
# 99
pointer allocate(size_type __n, const void * = 0) 
# 100
{ 
# 101
if (__n > this->max_size()) { 
# 102
std::__throw_bad_alloc(); }  
# 104
return static_cast< _Tp *>(::operator new(__n * sizeof(_Tp))); 
# 105
} 
# 109
void deallocate(pointer __p, size_type) 
# 110
{ ::operator delete(__p); } 
# 113
size_type max_size() const throw() 
# 114
{ return ((std::size_t)(-1)) / sizeof(_Tp); } 
# 129
void construct(pointer __p, const _Tp &__val) 
# 130
{ ::new ((void *)__p) (_Tp)(__val); } 
# 133
void destroy(pointer __p) { (__p->~_Tp()); } 
# 135
}; 
# 137
template< class _Tp> inline bool 
# 139
operator==(const new_allocator< _Tp>  &, const new_allocator< _Tp>  &) 
# 140
{ return true; } 
# 142
template< class _Tp> inline bool 
# 144
operator!=(const new_allocator< _Tp>  &, const new_allocator< _Tp>  &) 
# 145
{ return false; } 
# 148
}
# 50 "/usr/include/c++/4.8.2/bits/memoryfwd.h" 3
namespace std __attribute((__visibility__("default"))) { 
# 63
template< class > class allocator; 
# 67
template<> class allocator< void> ; 
# 70
template< class , class > struct uses_allocator; 
# 76
}
# 52 "/usr/include/c++/4.8.2/bits/allocator.h" 3
namespace std __attribute((__visibility__("default"))) { 
# 63
template<> class allocator< void>  { 
# 66
public: typedef size_t size_type; 
# 67
typedef ptrdiff_t difference_type; 
# 68
typedef void *pointer; 
# 69
typedef const void *const_pointer; 
# 70
typedef void value_type; 
# 72
template< class _Tp1> 
# 73
struct rebind { 
# 74
typedef std::allocator< _Tp1>  other; }; 
# 81
}; 
# 91
template< class _Tp> 
# 92
class allocator : public __gnu_cxx::new_allocator< _Tp>  { 
# 95
public: typedef ::std::size_t size_type; 
# 96
typedef ::std::ptrdiff_t difference_type; 
# 97
typedef _Tp *pointer; 
# 98
typedef const _Tp *const_pointer; 
# 99
typedef _Tp &reference; 
# 100
typedef const _Tp &const_reference; 
# 101
typedef _Tp value_type; 
# 103
template< class _Tp1> 
# 104
struct rebind { 
# 105
typedef ::std::allocator< _Tp1>  other; }; 
# 113
allocator() throw() { } 
# 115
allocator(const allocator &__a) throw() : ::__gnu_cxx::new_allocator< _Tp> (__a) 
# 116
{ } 
# 118
template< class _Tp1> 
# 119
allocator(const ::std::allocator< _Tp1>  &) throw() { } 
# 121
~allocator() throw() { } 
# 124
}; 
# 126
template< class _T1, class _T2> inline bool 
# 128
operator==(const allocator< _T1>  &, const allocator< _T2>  &) 
# 129
{ return true; } 
# 131
template< class _Tp> inline bool 
# 133
operator==(const allocator< _Tp>  &, const allocator< _Tp>  &) 
# 134
{ return true; } 
# 136
template< class _T1, class _T2> inline bool 
# 138
operator!=(const allocator< _T1>  &, const allocator< _T2>  &) 
# 139
{ return false; } 
# 141
template< class _Tp> inline bool 
# 143
operator!=(const allocator< _Tp>  &, const allocator< _Tp>  &) 
# 144
{ return false; } 
# 151
extern template class allocator< char> ;
# 152
extern template class allocator< wchar_t> ;
# 159
template< class _Alloc, bool  = __is_empty(_Alloc)> 
# 160
struct __alloc_swap { 
# 161
static void _S_do_it(_Alloc &, _Alloc &) { } }; 
# 163
template< class _Alloc> 
# 164
struct __alloc_swap< _Alloc, false>  { 
# 167
static void _S_do_it(_Alloc &__one, _Alloc &__two) 
# 168
{ 
# 170
if (__one != __two) { 
# 171
swap(__one, __two); }  
# 172
} 
# 173
}; 
# 176
template< class _Alloc, bool  = __is_empty(_Alloc)> 
# 177
struct __alloc_neq { 
# 180
static bool _S_do_it(const _Alloc &, const _Alloc &) 
# 181
{ return false; } 
# 182
}; 
# 184
template< class _Alloc> 
# 185
struct __alloc_neq< _Alloc, false>  { 
# 188
static bool _S_do_it(const _Alloc &__one, const _Alloc &__two) 
# 189
{ return __one != __two; } 
# 190
}; 
# 219
}
# 41 "/usr/include/c++/4.8.2/ext/alloc_traits.h" 3
namespace __gnu_cxx __attribute((__visibility__("default"))) { 
# 120
template< class _Alloc> 
# 121
struct __alloc_traits { 
# 126
typedef _Alloc allocator_type; 
# 199
typedef typename _Alloc::pointer pointer; 
# 200
typedef typename _Alloc::const_pointer const_pointer; 
# 201
typedef typename _Alloc::value_type value_type; 
# 202
typedef typename _Alloc::reference reference; 
# 203
typedef typename _Alloc::const_reference const_reference; 
# 204
typedef typename _Alloc::size_type size_type; 
# 205
typedef typename _Alloc::difference_type difference_type; 
# 208
static pointer allocate(_Alloc &__a, size_type __n) 
# 209
{ return (__a.allocate(__n)); } 
# 211
static void deallocate(_Alloc &__a, pointer __p, size_type __n) 
# 212
{ (__a.deallocate(__p, __n)); } 
# 214
template< class _Tp> static void 
# 215
construct(_Alloc &__a, pointer __p, const _Tp &__arg) 
# 216
{ (__a.construct(__p, __arg)); } 
# 218
static void destroy(_Alloc &__a, pointer __p) 
# 219
{ (__a.destroy(__p)); } 
# 221
static size_type max_size(const _Alloc &__a) 
# 222
{ return (__a.max_size()); } 
# 224
static const _Alloc &_S_select_on_copy(const _Alloc &__a) { return __a; } 
# 226
static void _S_on_swap(_Alloc &__a, _Alloc &__b) 
# 227
{ 
# 230
std::__alloc_swap< _Alloc> ::_S_do_it(__a, __b); 
# 231
} 
# 233
template< class _Tp> 
# 234
struct rebind { 
# 235
typedef typename _Alloc::template rebind< _Tp> ::other other; }; 
# 237
}; 
# 240
}
# 63 "/usr/include/c++/4.8.2/bits/stl_construct.h" 3
namespace std __attribute((__visibility__("default"))) { 
# 77
template< class _T1, class _T2> inline void 
# 79
_Construct(_T1 *__p, const _T2 &__value) 
# 80
{ 
# 83
::new (static_cast< void *>(__p)) (_T1)(__value); 
# 84
} 
# 90
template< class _Tp> inline void 
# 92
_Destroy(_Tp *__pointer) 
# 93
{ (__pointer->~_Tp()); } 
# 95
template< bool > 
# 96
struct _Destroy_aux { 
# 98
template< class _ForwardIterator> static void 
# 100
__destroy(_ForwardIterator __first, _ForwardIterator __last) 
# 101
{ 
# 102
for (; __first != __last; ++__first) { 
# 103
std::_Destroy(std::__addressof(*__first)); }  
# 104
} 
# 105
}; 
# 108
template<> struct _Destroy_aux< true>  { 
# 110
template< class _ForwardIterator> static void 
# 112
__destroy(_ForwardIterator, _ForwardIterator) { } 
# 113
}; 
# 120
template< class _ForwardIterator> inline void 
# 122
_Destroy(_ForwardIterator __first, _ForwardIterator __last) 
# 123
{ 
# 125
typedef typename iterator_traits< _ForwardIterator> ::value_type _Value_type; 
# 126
std::_Destroy_aux< __has_trivial_destructor(typename iterator_traits< _ForwardIterator> ::value_type)> ::__destroy(__first, __last); 
# 128
} 
# 136
template< class _ForwardIterator, class _Allocator> void 
# 138
_Destroy(_ForwardIterator __first, _ForwardIterator __last, _Allocator &
# 139
__alloc) 
# 140
{ 
# 141
typedef __gnu_cxx::__alloc_traits< _Allocator>  __traits; 
# 142
for (; __first != __last; ++__first) { 
# 143
__traits::destroy(__alloc, std::__addressof(*__first)); }  
# 144
} 
# 146
template< class _ForwardIterator, class _Tp> inline void 
# 148
_Destroy(_ForwardIterator __first, _ForwardIterator __last, allocator< _Tp>  &) 
# 150
{ 
# 151
_Destroy(__first, __last); 
# 152
} 
# 155
}
# 59 "/usr/include/c++/4.8.2/bits/stl_uninitialized.h" 3
namespace std __attribute((__visibility__("default"))) { 
# 63
template< bool _TrivialValueTypes> 
# 64
struct __uninitialized_copy { 
# 66
template< class _InputIterator, class _ForwardIterator> static _ForwardIterator 
# 68
__uninit_copy(_InputIterator __first, _InputIterator __last, _ForwardIterator 
# 69
__result) 
# 70
{ 
# 71
_ForwardIterator __cur = __result; 
# 72
try 
# 73
{ 
# 74
for (; __first != __last; (++__first), (++__cur)) { 
# 75
std::_Construct(std::__addressof(*__cur), *__first); }  
# 76
return __cur; 
# 77
} 
# 78
catch (...) 
# 79
{ 
# 80
std::_Destroy(__result, __cur); 
# 81
throw; 
# 82
}  
# 83
} 
# 84
}; 
# 87
template<> struct __uninitialized_copy< true>  { 
# 89
template< class _InputIterator, class _ForwardIterator> static _ForwardIterator 
# 91
__uninit_copy(_InputIterator __first, _InputIterator __last, _ForwardIterator 
# 92
__result) 
# 93
{ return std::copy(__first, __last, __result); } 
# 94
}; 
# 105
template< class _InputIterator, class _ForwardIterator> inline _ForwardIterator 
# 107
uninitialized_copy(_InputIterator __first, _InputIterator __last, _ForwardIterator 
# 108
__result) 
# 109
{ 
# 111
typedef typename iterator_traits< _InputIterator> ::value_type _ValueType1; 
# 113
typedef typename iterator_traits< _ForwardIterator> ::value_type _ValueType2; 
# 115
return std::__uninitialized_copy< __is_trivial(typename iterator_traits< _InputIterator> ::value_type) && __is_trivial(typename iterator_traits< _ForwardIterator> ::value_type)> ::__uninit_copy(__first, __last, __result); 
# 118
} 
# 121
template< bool _TrivialValueType> 
# 122
struct __uninitialized_fill { 
# 124
template< class _ForwardIterator, class _Tp> static void 
# 126
__uninit_fill(_ForwardIterator __first, _ForwardIterator __last, const _Tp &
# 127
__x) 
# 128
{ 
# 129
_ForwardIterator __cur = __first; 
# 130
try 
# 131
{ 
# 132
for (; __cur != __last; ++__cur) { 
# 133
std::_Construct(std::__addressof(*__cur), __x); }  
# 134
} 
# 135
catch (...) 
# 136
{ 
# 137
std::_Destroy(__first, __cur); 
# 138
throw; 
# 139
}  
# 140
} 
# 141
}; 
# 144
template<> struct __uninitialized_fill< true>  { 
# 146
template< class _ForwardIterator, class _Tp> static void 
# 148
__uninit_fill(_ForwardIterator __first, _ForwardIterator __last, const _Tp &
# 149
__x) 
# 150
{ std::fill(__first, __last, __x); } 
# 151
}; 
# 162
template< class _ForwardIterator, class _Tp> inline void 
# 164
uninitialized_fill(_ForwardIterator __first, _ForwardIterator __last, const _Tp &
# 165
__x) 
# 166
{ 
# 168
typedef typename iterator_traits< _ForwardIterator> ::value_type _ValueType; 
# 170
std::__uninitialized_fill< __is_trivial(typename iterator_traits< _ForwardIterator> ::value_type)> ::__uninit_fill(__first, __last, __x); 
# 172
} 
# 175
template< bool _TrivialValueType> 
# 176
struct __uninitialized_fill_n { 
# 178
template< class _ForwardIterator, class _Size, class _Tp> static void 
# 180
__uninit_fill_n(_ForwardIterator __first, _Size __n, const _Tp &
# 181
__x) 
# 182
{ 
# 183
_ForwardIterator __cur = __first; 
# 184
try 
# 185
{ 
# 186
for (; __n > 0; (--__n), (++__cur)) { 
# 187
std::_Construct(std::__addressof(*__cur), __x); }  
# 188
} 
# 189
catch (...) 
# 190
{ 
# 191
std::_Destroy(__first, __cur); 
# 192
throw; 
# 193
}  
# 194
} 
# 195
}; 
# 198
template<> struct __uninitialized_fill_n< true>  { 
# 200
template< class _ForwardIterator, class _Size, class _Tp> static void 
# 202
__uninit_fill_n(_ForwardIterator __first, _Size __n, const _Tp &
# 203
__x) 
# 204
{ std::fill_n(__first, __n, __x); } 
# 205
}; 
# 216
template< class _ForwardIterator, class _Size, class _Tp> inline void 
# 218
uninitialized_fill_n(_ForwardIterator __first, _Size __n, const _Tp &__x) 
# 219
{ 
# 221
typedef typename iterator_traits< _ForwardIterator> ::value_type _ValueType; 
# 223
std::__uninitialized_fill_n< __is_trivial(typename iterator_traits< _ForwardIterator> ::value_type)> ::__uninit_fill_n(__first, __n, __x); 
# 225
} 
# 233
template< class _InputIterator, class _ForwardIterator, class 
# 234
_Allocator> _ForwardIterator 
# 236
__uninitialized_copy_a(_InputIterator __first, _InputIterator __last, _ForwardIterator 
# 237
__result, _Allocator &__alloc) 
# 238
{ 
# 239
_ForwardIterator __cur = __result; 
# 240
try 
# 241
{ 
# 242
typedef __gnu_cxx::__alloc_traits< _Allocator>  __traits; 
# 243
for (; __first != __last; (++__first), (++__cur)) { 
# 244
__traits::construct(__alloc, std::__addressof(*__cur), *__first); }  
# 245
return __cur; 
# 246
} 
# 247
catch (...) 
# 248
{ 
# 249
std::_Destroy(__result, __cur, __alloc); 
# 250
throw; 
# 251
}  
# 252
} 
# 254
template< class _InputIterator, class _ForwardIterator, class _Tp> inline _ForwardIterator 
# 256
__uninitialized_copy_a(_InputIterator __first, _InputIterator __last, _ForwardIterator 
# 257
__result, allocator< _Tp>  &) 
# 258
{ return std::uninitialized_copy(__first, __last, __result); } 
# 260
template< class _InputIterator, class _ForwardIterator, class 
# 261
_Allocator> inline _ForwardIterator 
# 263
__uninitialized_move_a(_InputIterator __first, _InputIterator __last, _ForwardIterator 
# 264
__result, _Allocator &__alloc) 
# 265
{ 
# 266
return std::__uninitialized_copy_a(__first, __last, __result, __alloc); 
# 269
} 
# 271
template< class _InputIterator, class _ForwardIterator, class 
# 272
_Allocator> inline _ForwardIterator 
# 274
__uninitialized_move_if_noexcept_a(_InputIterator __first, _InputIterator 
# 275
__last, _ForwardIterator 
# 276
__result, _Allocator &
# 277
__alloc) 
# 278
{ 
# 279
return std::__uninitialized_copy_a(__first, __last, __result, __alloc); 
# 282
} 
# 284
template< class _ForwardIterator, class _Tp, class _Allocator> void 
# 286
__uninitialized_fill_a(_ForwardIterator __first, _ForwardIterator __last, const _Tp &
# 287
__x, _Allocator &__alloc) 
# 288
{ 
# 289
_ForwardIterator __cur = __first; 
# 290
try 
# 291
{ 
# 292
typedef __gnu_cxx::__alloc_traits< _Allocator>  __traits; 
# 293
for (; __cur != __last; ++__cur) { 
# 294
__traits::construct(__alloc, std::__addressof(*__cur), __x); }  
# 295
} 
# 296
catch (...) 
# 297
{ 
# 298
std::_Destroy(__first, __cur, __alloc); 
# 299
throw; 
# 300
}  
# 301
} 
# 303
template< class _ForwardIterator, class _Tp, class _Tp2> inline void 
# 305
__uninitialized_fill_a(_ForwardIterator __first, _ForwardIterator __last, const _Tp &
# 306
__x, allocator< _Tp2>  &) 
# 307
{ std::uninitialized_fill(__first, __last, __x); } 
# 309
template< class _ForwardIterator, class _Size, class _Tp, class 
# 310
_Allocator> void 
# 312
__uninitialized_fill_n_a(_ForwardIterator __first, _Size __n, const _Tp &
# 313
__x, _Allocator &__alloc) 
# 314
{ 
# 315
_ForwardIterator __cur = __first; 
# 316
try 
# 317
{ 
# 318
typedef __gnu_cxx::__alloc_traits< _Allocator>  __traits; 
# 319
for (; __n > 0; (--__n), (++__cur)) { 
# 320
__traits::construct(__alloc, std::__addressof(*__cur), __x); }  
# 321
} 
# 322
catch (...) 
# 323
{ 
# 324
std::_Destroy(__first, __cur, __alloc); 
# 325
throw; 
# 326
}  
# 327
} 
# 329
template< class _ForwardIterator, class _Size, class _Tp, class 
# 330
_Tp2> inline void 
# 332
__uninitialized_fill_n_a(_ForwardIterator __first, _Size __n, const _Tp &
# 333
__x, allocator< _Tp2>  &) 
# 334
{ std::uninitialized_fill_n(__first, __n, __x); } 
# 346
template< class _InputIterator1, class _InputIterator2, class 
# 347
_ForwardIterator, class _Allocator> inline _ForwardIterator 
# 349
__uninitialized_copy_move(_InputIterator1 __first1, _InputIterator1 
# 350
__last1, _InputIterator2 
# 351
__first2, _InputIterator2 
# 352
__last2, _ForwardIterator 
# 353
__result, _Allocator &
# 354
__alloc) 
# 355
{ 
# 356
_ForwardIterator __mid = std::__uninitialized_copy_a(__first1, __last1, __result, __alloc); 
# 359
try 
# 360
{ 
# 361
return std::__uninitialized_move_a(__first2, __last2, __mid, __alloc); 
# 362
} 
# 363
catch (...) 
# 364
{ 
# 365
std::_Destroy(__result, __mid, __alloc); 
# 366
throw; 
# 367
}  
# 368
} 
# 374
template< class _InputIterator1, class _InputIterator2, class 
# 375
_ForwardIterator, class _Allocator> inline _ForwardIterator 
# 377
__uninitialized_move_copy(_InputIterator1 __first1, _InputIterator1 
# 378
__last1, _InputIterator2 
# 379
__first2, _InputIterator2 
# 380
__last2, _ForwardIterator 
# 381
__result, _Allocator &
# 382
__alloc) 
# 383
{ 
# 384
_ForwardIterator __mid = std::__uninitialized_move_a(__first1, __last1, __result, __alloc); 
# 387
try 
# 388
{ 
# 389
return std::__uninitialized_copy_a(__first2, __last2, __mid, __alloc); 
# 390
} 
# 391
catch (...) 
# 392
{ 
# 393
std::_Destroy(__result, __mid, __alloc); 
# 394
throw; 
# 395
}  
# 396
} 
# 401
template< class _ForwardIterator, class _Tp, class _InputIterator, class 
# 402
_Allocator> inline _ForwardIterator 
# 404
__uninitialized_fill_move(_ForwardIterator __result, _ForwardIterator __mid, const _Tp &
# 405
__x, _InputIterator __first, _InputIterator 
# 406
__last, _Allocator &__alloc) 
# 407
{ 
# 408
std::__uninitialized_fill_a(__result, __mid, __x, __alloc); 
# 409
try 
# 410
{ 
# 411
return std::__uninitialized_move_a(__first, __last, __mid, __alloc); 
# 412
} 
# 413
catch (...) 
# 414
{ 
# 415
std::_Destroy(__result, __mid, __alloc); 
# 416
throw; 
# 417
}  
# 418
} 
# 423
template< class _InputIterator, class _ForwardIterator, class _Tp, class 
# 424
_Allocator> inline void 
# 426
__uninitialized_move_fill(_InputIterator __first1, _InputIterator __last1, _ForwardIterator 
# 427
__first2, _ForwardIterator 
# 428
__last2, const _Tp &__x, _Allocator &
# 429
__alloc) 
# 430
{ 
# 431
_ForwardIterator __mid2 = std::__uninitialized_move_a(__first1, __last1, __first2, __alloc); 
# 434
try 
# 435
{ 
# 436
std::__uninitialized_fill_a(__mid2, __last2, __x, __alloc); 
# 437
} 
# 438
catch (...) 
# 439
{ 
# 440
std::_Destroy(__first2, __mid2, __alloc); 
# 441
throw; 
# 442
}  
# 443
} 
# 654
}
# 62 "/usr/include/c++/4.8.2/bits/stl_tempbuf.h" 3
namespace std __attribute((__visibility__("default"))) { 
# 83
template< class _Tp> pair< _Tp *, long>  
# 85
get_temporary_buffer(ptrdiff_t __len) 
# 86
{ 
# 87
const ptrdiff_t __max = (__gnu_cxx::__numeric_traits_integer< long> ::__max / sizeof(_Tp)); 
# 89
if (__len > __max) { 
# 90
__len = __max; }  
# 92
while (__len > (0)) 
# 93
{ 
# 94
_Tp *__tmp = static_cast< _Tp *>(::operator new(__len * sizeof(_Tp), std::nothrow)); 
# 96
if (__tmp != 0) { 
# 97
return pair< _Tp *, long> (__tmp, __len); }  
# 98
__len /= (2); 
# 99
}  
# 100
return pair< _Tp *, long> (static_cast< _Tp *>(0), 0); 
# 101
} 
# 110
template< class _Tp> inline void 
# 112
return_temporary_buffer(_Tp *__p) 
# 113
{ ::operator delete(__p, std::nothrow); } 
# 121
template< class _ForwardIterator, class _Tp> 
# 122
class _Temporary_buffer { 
# 128
public: typedef _Tp value_type; 
# 129
typedef value_type *pointer; 
# 130
typedef pointer iterator; 
# 131
typedef ptrdiff_t size_type; 
# 134
protected: size_type _M_original_len; 
# 135
size_type _M_len; 
# 136
pointer _M_buffer; 
# 141
public: size_type size() const 
# 142
{ return _M_len; } 
# 146
size_type requested_size() const 
# 147
{ return _M_original_len; } 
# 151
iterator begin() 
# 152
{ return _M_buffer; } 
# 156
iterator end() 
# 157
{ return (_M_buffer) + (_M_len); } 
# 163
_Temporary_buffer(_ForwardIterator __first, _ForwardIterator __last); 
# 165
~_Temporary_buffer() 
# 166
{ 
# 167
std::_Destroy(_M_buffer, (_M_buffer) + (_M_len)); 
# 168
std::return_temporary_buffer(_M_buffer); 
# 169
} 
# 173
private: _Temporary_buffer(const _Temporary_buffer &); 
# 176
void operator=(const _Temporary_buffer &); 
# 177
}; 
# 180
template< bool > 
# 181
struct __uninitialized_construct_buf_dispatch { 
# 183
template< class _Pointer, class _ForwardIterator> static void 
# 185
__ucr(_Pointer __first, _Pointer __last, _ForwardIterator 
# 186
__seed) 
# 187
{ 
# 188
if (__first == __last) { 
# 189
return; }  
# 191
_Pointer __cur = __first; 
# 192
try 
# 193
{ 
# 194
std::_Construct(std::__addressof(*__first), *__seed); 
# 196
_Pointer __prev = __cur; 
# 197
++__cur; 
# 198
for (; __cur != __last; (++__cur), (++__prev)) { 
# 199
std::_Construct(std::__addressof(*__cur), *__prev); }  
# 201
(*__seed) = (*__prev); 
# 202
} 
# 203
catch (...) 
# 204
{ 
# 205
std::_Destroy(__first, __cur); 
# 206
throw; 
# 207
}  
# 208
} 
# 209
}; 
# 212
template<> struct __uninitialized_construct_buf_dispatch< true>  { 
# 214
template< class _Pointer, class _ForwardIterator> static void 
# 216
__ucr(_Pointer, _Pointer, _ForwardIterator) { } 
# 217
}; 
# 229
template< class _Pointer, class _ForwardIterator> inline void 
# 231
__uninitialized_construct_buf(_Pointer __first, _Pointer __last, _ForwardIterator 
# 232
__seed) 
# 233
{ 
# 235
typedef typename iterator_traits< _Pointer> ::value_type _ValueType; 
# 237
std::__uninitialized_construct_buf_dispatch< __has_trivial_constructor(typename iterator_traits< _Pointer> ::value_type)> ::__ucr(__first, __last, __seed); 
# 240
} 
# 242
template< class _ForwardIterator, class _Tp> 
# 244
_Temporary_buffer< _ForwardIterator, _Tp> ::_Temporary_buffer(_ForwardIterator __first, _ForwardIterator __last) : _M_original_len(std::distance(__first, __last)), _M_len((0)), _M_buffer((0)) 
# 247
{ 
# 248
try 
# 249
{ 
# 250
pair< _Tp *, long>  __p(std::get_temporary_buffer< value_type> (_M_original_len)); 
# 252
(_M_buffer) = (__p.first); 
# 253
(_M_len) = (__p.second); 
# 254
if (_M_buffer) { 
# 255
std::__uninitialized_construct_buf(_M_buffer, (_M_buffer) + (_M_len), __first); }  
# 257
} 
# 258
catch (...) 
# 259
{ 
# 260
std::return_temporary_buffer(_M_buffer); 
# 261
(_M_buffer) = 0; 
# 262
(_M_len) = (0); 
# 263
throw; 
# 264
}  
# 265
} 
# 268
}
# 59 "/usr/include/c++/4.8.2/bits/stl_raw_storage_iter.h" 3
namespace std __attribute((__visibility__("default"))) { 
# 67
template< class _OutputIterator, class _Tp> 
# 68
class raw_storage_iterator : public iterator< output_iterator_tag, void, void, void, void>  { 
# 72
protected: _OutputIterator _M_iter; 
# 76
public: explicit raw_storage_iterator(_OutputIterator __x) : _M_iter(__x) 
# 77
{ } 
# 80
raw_storage_iterator &operator*() { return *this; } 
# 83
raw_storage_iterator &operator=(const _Tp &__element) 
# 84
{ 
# 85
std::_Construct(std::__addressof(*(_M_iter)), __element); 
# 86
return *this; 
# 87
} 
# 90
raw_storage_iterator &operator++() 
# 91
{ 
# 92
++(_M_iter); 
# 93
return *this; 
# 94
} 
# 97
raw_storage_iterator operator++(int) 
# 98
{ 
# 99
raw_storage_iterator __tmp = *this; 
# 100
++(_M_iter); 
# 101
return __tmp; 
# 102
} 
# 103
}; 
# 106
}
# 36 "/usr/include/c++/4.8.2/backward/auto_ptr.h" 3
namespace std __attribute((__visibility__("default"))) { 
# 47
template< class _Tp1> 
# 48
struct auto_ptr_ref { 
# 50
_Tp1 *_M_ptr; 
# 53
explicit auto_ptr_ref(_Tp1 *__p) : _M_ptr(__p) { } 
# 54
}; 
# 86
template< class _Tp> 
# 87
class auto_ptr { 
# 90
_Tp *_M_ptr; 
# 94
public: typedef _Tp element_type; 
# 103
explicit auto_ptr(element_type *__p = 0) throw() : _M_ptr(__p) { } 
# 112
auto_ptr(auto_ptr &__a) throw() : _M_ptr(__a.release()) { } 
# 124
template< class _Tp1> 
# 125
auto_ptr(std::auto_ptr< _Tp1>  &__a) throw() : _M_ptr((__a.release())) { } 
# 136
auto_ptr &operator=(auto_ptr &__a) throw() 
# 137
{ 
# 138
reset(__a.release()); 
# 139
return *this; 
# 140
} 
# 152
template< class _Tp1> auto_ptr &
# 154
operator=(std::auto_ptr< _Tp1>  &__a) throw() 
# 155
{ 
# 156
reset((__a.release())); 
# 157
return *this; 
# 158
} 
# 170
~auto_ptr() { delete (_M_ptr); } 
# 181
element_type &operator*() const throw() 
# 182
{ 
# 183
; 
# 184
return *(_M_ptr); 
# 185
} 
# 194
element_type *operator->() const throw() 
# 195
{ 
# 196
; 
# 197
return _M_ptr; 
# 198
} 
# 211
element_type *get() const throw() { return _M_ptr; } 
# 225
element_type *release() throw() 
# 226
{ 
# 227
element_type *__tmp = _M_ptr; 
# 228
(_M_ptr) = 0; 
# 229
return __tmp; 
# 230
} 
# 240
void reset(element_type *__p = 0) throw() 
# 241
{ 
# 242
if (__p != (_M_ptr)) 
# 243
{ 
# 244
delete (_M_ptr); 
# 245
(_M_ptr) = __p; 
# 246
}  
# 247
} 
# 260
auto_ptr(auto_ptr_ref< _Tp>  __ref) throw() : _M_ptr(((__ref._M_ptr))) 
# 261
{ } 
# 264
auto_ptr &operator=(auto_ptr_ref< _Tp>  __ref) throw() 
# 265
{ 
# 266
if ((__ref._M_ptr) != this->get()) 
# 267
{ 
# 268
delete (_M_ptr); 
# 269
(_M_ptr) = (__ref._M_ptr); 
# 270
}  
# 271
return *this; 
# 272
} 
# 274
template< class _Tp1> 
# 275
operator auto_ptr_ref< _Tp1> () throw() 
# 276
{ return ((auto_ptr_ref< _Tp1> )(this->release())); } 
# 278
template< class _Tp1> 
# 279
operator std::auto_ptr< _Tp1> () throw() 
# 280
{ return ((std::auto_ptr< _Tp1> )(this->release())); } 
# 281
}; 
# 286
template<> class auto_ptr< void>  { 
# 289
public: typedef void element_type; 
# 290
}; 
# 327
}
# 45 "/usr/local/cuda-8.0/include/thrust/detail/type_traits.h"
namespace thrust { 
# 49
template< class T> class device_reference; 
# 51
namespace detail { 
# 54
template< class _Tp, _Tp __v> 
# 55
struct integral_constant { 
# 57
static const _Tp value = __v; 
# 58
typedef _Tp value_type; 
# 59
typedef integral_constant type; 
# 60
}; 
# 63
typedef integral_constant< bool, true>  true_type; 
# 66
typedef integral_constant< bool, false>  false_type; 
# 69
template< class T> struct is_integral : public false_type { }; 
# 70
template<> struct is_integral< bool>  : public true_type { }; 
# 71
template<> struct is_integral< char>  : public true_type { }; 
# 72
template<> struct is_integral< signed char>  : public true_type { }; 
# 73
template<> struct is_integral< unsigned char>  : public true_type { }; 
# 74
template<> struct is_integral< short>  : public true_type { }; 
# 75
template<> struct is_integral< unsigned short>  : public true_type { }; 
# 76
template<> struct is_integral< int>  : public true_type { }; 
# 77
template<> struct is_integral< unsigned>  : public true_type { }; 
# 78
template<> struct is_integral< long>  : public true_type { }; 
# 79
template<> struct is_integral< unsigned long>  : public true_type { }; 
# 80
template<> struct is_integral< long long>  : public true_type { }; 
# 81
template<> struct is_integral< unsigned long long>  : public true_type { }; 
# 82
template<> struct is_integral< const bool>  : public true_type { }; 
# 83
template<> struct is_integral< const char>  : public true_type { }; 
# 84
template<> struct is_integral< const unsigned char>  : public true_type { }; 
# 85
template<> struct is_integral< const short>  : public true_type { }; 
# 86
template<> struct is_integral< const unsigned short>  : public true_type { }; 
# 87
template<> struct is_integral< const int>  : public true_type { }; 
# 88
template<> struct is_integral< const unsigned>  : public true_type { }; 
# 89
template<> struct is_integral< const long>  : public true_type { }; 
# 90
template<> struct is_integral< const unsigned long>  : public true_type { }; 
# 91
template<> struct is_integral< const long long>  : public true_type { }; 
# 92
template<> struct is_integral< const unsigned long long>  : public true_type { }; 
# 94
template< class T> struct is_floating_point : public false_type { }; 
# 95
template<> struct is_floating_point< float>  : public true_type { }; 
# 96
template<> struct is_floating_point< double>  : public true_type { }; 
# 97
template<> struct is_floating_point< long double>  : public true_type { }; 
# 99
template< class T> struct is_arithmetic : public is_integral< T>  { }; 
# 100
template<> struct is_arithmetic< float>  : public true_type { }; 
# 101
template<> struct is_arithmetic< double>  : public true_type { }; 
# 102
template<> struct is_arithmetic< const float>  : public true_type { }; 
# 103
template<> struct is_arithmetic< const double>  : public true_type { }; 
# 105
template< class T> struct is_pointer : public false_type { }; 
# 106
template< class T> struct is_pointer< T *>  : public true_type { }; 
# 108
template< class T> struct is_device_ptr : public false_type { }; 
# 110
template< class T> struct is_void : public false_type { }; 
# 111
template<> struct is_void< void>  : public true_type { }; 
# 112
template<> struct is_void< const void>  : public true_type { }; 
# 115
namespace tt_detail { 
# 119
}
# 121
template< class T> struct is_pod : public integral_constant< bool, ((is_void< T> ::value || is_pointer< T> ::value) || is_arithmetic< T> ::value) || __is_pod(T)>  { 
# 135
}; 
# 138
template< class T> struct has_trivial_constructor : public integral_constant< bool, is_pod< T> ::value || __has_trivial_constructor(T)>  { 
# 151
}; 
# 153
template< class T> struct has_trivial_copy_constructor : public integral_constant< bool, is_pod< T> ::value || __has_trivial_copy(T)>  { 
# 166
}; 
# 168
template< class T> struct has_trivial_destructor : public is_pod< T>  { }; 
# 170
template< class T> struct is_const : public false_type { }; 
# 171
template< class T> struct is_const< const T>  : public true_type { }; 
# 173
template< class T> struct is_volatile : public false_type { }; 
# 174
template< class T> struct is_volatile< volatile T>  : public true_type { }; 
# 176
template< class T> 
# 177
struct add_const { 
# 179
typedef const T type; 
# 180
}; 
# 182
template< class T> 
# 183
struct remove_const { 
# 185
typedef T type; 
# 186
}; 
# 188
template< class T> 
# 189
struct remove_const< const T>  { 
# 191
typedef T type; 
# 192
}; 
# 194
template< class T> 
# 195
struct add_volatile { 
# 197
typedef volatile T type; 
# 198
}; 
# 200
template< class T> 
# 201
struct remove_volatile { 
# 203
typedef T type; 
# 204
}; 
# 206
template< class T> 
# 207
struct remove_volatile< volatile T>  { 
# 209
typedef T type; 
# 210
}; 
# 212
template< class T> 
# 213
struct add_cv { 
# 215
typedef const volatile T type; 
# 216
}; 
# 218
template< class T> 
# 219
struct remove_cv { 
# 221
typedef typename remove_const< typename remove_volatile< T> ::type> ::type type; 
# 222
}; 
# 225
template< class T> struct is_reference : public false_type { }; 
# 226
template< class T> struct is_reference< T &>  : public true_type { }; 
# 228
template< class T> struct is_device_reference : public false_type { }; 
# 229
template< class T> struct is_device_reference< device_reference< T> >  : public true_type { }; 
# 233
template< class _Tp, bool  = is_void< _Tp> ::value || is_reference< _Tp> ::value> 
# 234
struct __add_reference_helper { 
# 235
typedef _Tp &type; }; 
# 237
template< class _Tp> 
# 238
struct __add_reference_helper< _Tp, true>  { 
# 239
typedef _Tp type; }; 
# 241
template< class _Tp> 
# 242
struct add_reference : public __add_reference_helper< _Tp>  { 
# 243
}; 
# 245
template< class T> 
# 246
struct remove_reference { 
# 248
typedef T type; 
# 249
}; 
# 251
template< class T> 
# 252
struct remove_reference< T &>  { 
# 254
typedef T type; 
# 255
}; 
# 257
template< class T1, class T2> 
# 258
struct is_same : public false_type { 
# 261
}; 
# 263
template< class T> 
# 264
struct is_same< T, T>  : public true_type { 
# 267
}; 
# 269
template< class T1, class T2> 
# 270
struct lazy_is_same : public is_same< typename T1::type, typename T2::type>  { 
# 273
}; 
# 275
template< class T1, class T2> 
# 276
struct is_different : public true_type { 
# 279
}; 
# 281
template< class T> 
# 282
struct is_different< T, T>  : public false_type { 
# 285
}; 
# 287
template< class T1, class T2> 
# 288
struct lazy_is_different : public is_different< typename T1::type, typename T2::type>  { 
# 291
}; 
# 293
namespace tt_detail { 
# 296
template< class T> 
# 297
struct is_int_or_cref { 
# 299
typedef typename remove_reference< T> ::type type_sans_ref; 
# 300
static const bool value = (is_integral< T> ::value || (is_integral< typename remove_reference< T> ::type> ::value && is_const< typename remove_reference< T> ::type> ::value && (!is_volatile< typename remove_reference< T> ::type> ::value))); 
# 304
}; 
# 311
template< class From, class To> 
# 312
struct is_convertible_sfinae { 
# 315
private: typedef char yes; 
# 316
typedef struct { char two_chars[2]; } no; 
# 318
static yes test(To) { return yes(); } 
# 319
static no test(...) { return no(); } 
# 320
static typename remove_reference< From> ::type &from() { typename remove_reference< From> ::type *ptr = (0); return *ptr; } 
# 323
public: static const bool value = (sizeof(test((from)())) == sizeof(yes)); 
# 324
}; 
# 331
template< class From, class To> 
# 332
struct is_convertible_needs_simple_test { 
# 334
static const bool from_is_void = (is_void< From> ::value); 
# 335
static const bool to_is_void = (is_void< To> ::value); 
# 336
static const bool from_is_float = (is_floating_point< typename remove_reference< From> ::type> ::value); 
# 337
static const bool to_is_int_or_cref = (is_int_or_cref< To> ::value); 
# 339
static const bool value = ((from_is_void || to_is_void) || (from_is_float && to_is_int_or_cref)); 
# 340
}; 
# 343
template< class From, class To, bool 
# 344
 = is_convertible_needs_simple_test< From, To> ::value> 
# 345
struct is_convertible { 
# 347
static const bool value = (is_void< To> ::value || (is_int_or_cref< To> ::value && (!is_void< From> ::value))); 
# 350
}; 
# 353
template< class From, class To> 
# 354
struct is_convertible< From, To, false>  { 
# 356
static const bool value = (is_convertible_sfinae< typename add_reference< From> ::type, To> ::value); 
# 358
}; 
# 361
}
# 363
template< class From, class To> 
# 364
struct is_convertible : public integral_constant< bool, tt_detail::is_convertible< From, To> ::value>  { 
# 367
}; 
# 370
template< class T1, class T2> 
# 371
struct is_one_convertible_to_the_other : public integral_constant< bool, is_convertible< T1, T2> ::value || is_convertible< T2, T1> ::value>  { 
# 376
}; 
# 381
template< class Condition1, class Condition2, class Condition3 = false_type, class 
# 382
Condition4 = false_type, class Condition5 = false_type, class Condition6 = false_type, class 
# 383
Condition7 = false_type, class Condition8 = false_type, class Condition9 = false_type, class 
# 384
Condition10 = false_type> 
# 385
struct or_ : public integral_constant< bool, ((((((((Condition1::value || Condition2::value) || Condition3::value) || Condition4::value) || Condition5::value) || Condition6::value) || Condition7::value) || Condition8::value) || Condition9::value) || Condition10::value>  { 
# 391
}; 
# 393
template< class Condition1, class Condition2, class Condition3 = true_type> 
# 394
struct and_ : public integral_constant< bool, Condition1::value && Condition2::value && Condition3::value>  { 
# 397
}; 
# 399
template< class Boolean> 
# 400
struct not_ : public integral_constant< bool, !Boolean::value>  { 
# 403
}; 
# 405
template< bool , class Then, class Else> 
# 406
struct eval_if { 
# 408
}; 
# 410
template< class Then, class Else> 
# 411
struct eval_if< true, Then, Else>  { 
# 413
typedef typename Then::type type; 
# 414
}; 
# 416
template< class Then, class Else> 
# 417
struct eval_if< false, Then, Else>  { 
# 419
typedef typename Else::type type; 
# 420
}; 
# 422
template< class T> 
# 425
struct identity_ { 
# 427
typedef T type; 
# 428
}; 
# 430
template< bool , class T = void> struct enable_if { }; 
# 431
template< class T> struct enable_if< true, T>  { typedef T type; }; 
# 433
template< bool , class T> struct lazy_enable_if { }; 
# 434
template< class T> struct lazy_enable_if< true, T>  { typedef typename T::type type; }; 
# 436
template< bool condition, class T = void> struct disable_if : public enable_if< !condition, T>  { }; 
# 437
template< bool condition, class T> struct lazy_disable_if : public lazy_enable_if< !condition, T>  { }; 
# 440
template< class T1, class T2, class T = void> 
# 441
struct enable_if_convertible : public enable_if< is_convertible< T1, T2> ::value, T>  { 
# 443
}; 
# 446
template< class T1, class T2, class T = void> 
# 447
struct disable_if_convertible : public disable_if< is_convertible< T1, T2> ::value, T>  { 
# 449
}; 
# 452
template< class T1, class T2, class Result = void> 
# 453
struct enable_if_different : public enable_if< is_different< T1, T2> ::value, Result>  { 
# 455
}; 
# 458
template< class T> 
# 459
struct is_numeric : public and_< is_convertible< int, T> , is_convertible< T, int> >  { 
# 465
}; 
# 468
template< class > struct is_reference_to_const : public false_type { }; 
# 469
template< class T> struct is_reference_to_const< const T &>  : public true_type { }; 
# 474
namespace tt_detail { 
# 477
template< class T> struct make_unsigned_simple; 
# 479
template<> struct make_unsigned_simple< char>  { typedef unsigned char type; }; 
# 480
template<> struct make_unsigned_simple< signed char>  { typedef signed char type; }; 
# 481
template<> struct make_unsigned_simple< unsigned char>  { typedef unsigned char type; }; 
# 482
template<> struct make_unsigned_simple< short>  { typedef unsigned short type; }; 
# 483
template<> struct make_unsigned_simple< unsigned short>  { typedef unsigned short type; }; 
# 484
template<> struct make_unsigned_simple< int>  { typedef unsigned type; }; 
# 485
template<> struct make_unsigned_simple< unsigned>  { typedef unsigned type; }; 
# 486
template<> struct make_unsigned_simple< long>  { typedef unsigned long type; }; 
# 487
template<> struct make_unsigned_simple< unsigned long>  { typedef unsigned long type; }; 
# 488
template<> struct make_unsigned_simple< long long>  { typedef unsigned long long type; }; 
# 489
template<> struct make_unsigned_simple< unsigned long long>  { typedef unsigned long long type; }; 
# 491
template< class T> 
# 492
struct make_unsigned_base { 
# 495
typedef typename remove_cv< T> ::type remove_cv_t; 
# 498
typedef typename make_unsigned_simple< typename remove_cv< T> ::type> ::type unsigned_remove_cv_t; 
# 518
typedef typename eval_if< is_const< T> ::value && is_volatile< T> ::value, add_cv< typename make_unsigned_simple< typename remove_cv< T> ::type> ::type> , eval_if< is_const< T> ::value, add_const< typename make_unsigned_simple< typename remove_cv< T> ::type> ::type> , eval_if< is_volatile< T> ::value, add_volatile< typename make_unsigned_simple< typename remove_cv< T> ::type> ::type> , identity_< typename make_unsigned_simple< typename remove_cv< T> ::type> ::type> > > > ::type type; 
# 519
}; 
# 521
}
# 523
template< class T> 
# 524
struct make_unsigned : public tt_detail::make_unsigned_base< T>  { 
# 526
}; 
# 528
struct largest_available_float { 
# 537
typedef double type; 
# 539
}; 
# 542
template< class T1, class T2> 
# 543
struct larger_type : public eval_if< (sizeof(T2) > sizeof(T1)), identity_< T2> , identity_< T1> >  { 
# 549
}; 
# 552
namespace is_base_of_ns { 
# 555
typedef char yes; 
# 556
typedef struct { char two_chars[2]; } no; 
# 558
template< class Base, class Derived> 
# 559
struct host { 
# 561
operator Base *() const; 
# 562
operator Derived *(); 
# 563
}; 
# 565
template< class Base, class Derived> 
# 566
struct impl { 
# 568
template< class T> static yes check(Derived *, T); 
# 569
static no check(Base *, int); 
# 571
static const bool value = (sizeof(check(host< Base, Derived> (), ((int)0))) == sizeof(yes)); 
# 572
}; 
# 574
}
# 577
template< class Base, class Derived> 
# 578
struct is_base_of : public integral_constant< bool, is_base_of_ns::impl< Base, Derived> ::value>  { 
# 583
}; 
# 585
template< class Base, class Derived, class Result = void> 
# 586
struct enable_if_base_of : public enable_if< is_base_of< Base, Derived> ::value, Result>  { 
# 591
}; 
# 594
namespace is_assignable_ns { 
# 597
template< class T1, class T2> 
# 598
class is_assignable { 
# 600
typedef char yes_type; 
# 601
typedef struct { char array[2]; } no_type; 
# 603
template< class T> static typename add_reference< T> ::type declval(); 
# 605
template< unsigned > struct helper { typedef void *type; }; 
# 607
template< class U1, class U2> static yes_type test(typename helper< sizeof((declval< U1> () = declval< U2> ()))> ::type); 
# 609
template< class , class > static no_type test(...); 
# 612
public: static const bool value = (sizeof(test< T1, T2> (0)) == (1)); 
# 613
}; 
# 615
}
# 618
template< class T1, class T2> 
# 619
struct is_assignable : public integral_constant< bool, is_assignable_ns::is_assignable< T1, T2> ::value>  { 
# 624
}; 
# 627
template< class T> 
# 628
struct is_copy_assignable : public is_assignable< typename add_reference< T> ::type, typename add_reference< typename add_const< T> ::type> ::type>  { 
# 633
}; 
# 636
template< class T1, class T2, class Enable = void> struct promoted_numerical_type; 
# 638
template< class T1, class T2> 
# 639
struct promoted_numerical_type< T1, T2, typename enable_if< and_< typename is_floating_point< T1> ::type, typename is_floating_point< T2> ::type> ::value> ::type>  { 
# 643
typedef larger_type< T1, T2>  type; 
# 644
}; 
# 646
template< class T1, class T2> 
# 647
struct promoted_numerical_type< T1, T2, typename enable_if< and_< typename is_integral< T1> ::type, typename is_floating_point< T2> ::type> ::value> ::type>  { 
# 651
typedef T2 type; 
# 652
}; 
# 654
template< class T1, class T2> 
# 655
struct promoted_numerical_type< T1, T2, typename enable_if< and_< typename is_floating_point< T1> ::type, typename is_integral< T2> ::type> ::value> ::type>  { 
# 659
typedef T1 type; 
# 660
}; 
# 662
}
# 664
}
# 28 "/usr/local/cuda-8.0/include/thrust/detail/type_traits/has_trivial_assign.h"
namespace thrust { 
# 31
namespace detail { 
# 34
template< class T> struct has_trivial_assign : public integral_constant< bool, (is_pod< T> ::value && (!is_const< T> ::value)) || __has_trivial_assign(T)>  { 
# 47
}; 
# 49
}
# 51
}
# 21 "/usr/local/cuda-8.0/include/thrust/detail/execution_policy.h"
namespace thrust { 
# 23
namespace detail { 
# 41
template< class DerivedPolicy> struct execution_policy_base { }; 
# 44
template< class DerivedPolicy> inline execution_policy_base< DerivedPolicy>  &
# 46
strip_const(const execution_policy_base< DerivedPolicy>  &x) 
# 47
{ 
# 48
return const_cast< execution_policy_base< DerivedPolicy>  &>(x); 
# 49
} 
# 52
template< class DerivedPolicy> inline DerivedPolicy &
# 54
derived_cast(execution_policy_base< DerivedPolicy>  &x) 
# 55
{ 
# 56
return static_cast< DerivedPolicy &>(x); 
# 57
} 
# 60
template< class DerivedPolicy> inline const DerivedPolicy &
# 62
derived_cast(const execution_policy_base< DerivedPolicy>  &x) 
# 63
{ 
# 64
return static_cast< const DerivedPolicy &>(x); 
# 65
} 
# 68
}
# 71
template< class DerivedPolicy> 
# 72
struct execution_policy : public detail::execution_policy_base< DerivedPolicy>  { 
# 74
}; 
# 77
}
# 22 "/usr/local/cuda-8.0/include/thrust/system/detail/sequential/execution_policy.h"
namespace thrust { 
# 24
namespace system { 
# 26
namespace detail { 
# 28
namespace sequential { 
# 39
struct tag; 
# 42
template< class > struct execution_policy; 
# 46
template<> struct execution_policy< tag>  : public thrust::execution_policy< tag>  { 
# 48
}; 
# 51
struct tag : public execution_policy< tag>  { 
# 53
tag() { } 
# 54
}; 
# 57
template< class Derived> 
# 58
struct execution_policy : public thrust::execution_policy< Derived>  { 
# 62
operator ::thrust::system::detail::sequential::tag() const 
# 63
{ 
# 64
return ::thrust::system::detail::sequential::tag(); 
# 65
} 
# 66
}; 
# 72
static const tag seq; 
# 76
}
# 77
}
# 78
}
# 79
}
# 22 "/usr/local/cuda-8.0/include/thrust/system/cpp/detail/execution_policy.h"
namespace thrust { 
# 24
namespace system { 
# 27
namespace cpp { 
# 29
namespace detail { 
# 39
struct tag; 
# 42
template< class > struct execution_policy; 
# 46
template<> struct execution_policy< tag>  : public system::detail::sequential::execution_policy< tag>  { 
# 48
}; 
# 52
struct tag : public execution_policy< tag>  { }; 
# 55
template< class Derived> 
# 56
struct execution_policy : public system::detail::sequential::execution_policy< Derived>  { 
# 60
operator ::thrust::system::cpp::detail::tag() const 
# 61
{ 
# 62
return ::thrust::system::cpp::detail::tag(); 
# 63
} 
# 64
}; 
# 66
}
# 69
using detail::execution_policy;
# 70
using detail::tag;
# 72
}
# 73
}
# 76
namespace cpp { 
# 79
using system::cpp::execution_policy;
# 80
using system::cpp::tag;
# 82
}
# 83
}
# 26 "/usr/local/cuda-8.0/include/thrust/iterator/detail/host_system_tag.h"
namespace thrust { 
# 29
typedef system::cpp::detail::tag host_system_tag; 
# 31
}
# 34
namespace thrust { 
# 37
__attribute((deprecated)) typedef host_system_tag host_space_tag; 
# 39
}
# 22 "/usr/local/cuda-8.0/include/thrust/iterator/detail/any_system_tag.h"
namespace thrust { 
# 25
struct any_system_tag : public execution_policy< any_system_tag>  { 
# 30
template< class T> operator T() const { return T(); } 
# 31
}; 
# 34
__attribute((deprecated)) typedef any_system_tag any_space_tag; 
# 36
}
# 24 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/execution_policy.h"
namespace thrust { 
# 26
namespace system { 
# 28
namespace cuda { 
# 31
namespace detail { 
# 41
struct tag; 
# 44
template< class > struct execution_policy; 
# 48
template<> struct execution_policy< tag>  : public thrust::execution_policy< tag>  { 
# 50
}; 
# 54
struct tag : public execution_policy< tag>  { }; 
# 57
template< class Derived> 
# 58
struct execution_policy : public thrust::execution_policy< Derived>  { 
# 62
operator ::thrust::system::cuda::detail::tag() const 
# 63
{ 
# 64
return ::thrust::system::cuda::detail::tag(); 
# 65
} 
# 66
}; 
# 69
template< class System1, class System2> 
# 70
struct cross_system : public thrust::execution_policy< cross_system< System1, System2> >  { 
# 74
cross_system(::thrust::execution_policy< System1>  &system1, ::thrust::execution_policy< System2>  &
# 75
system2) : system1(system1), system2(system2) 
# 77
{ } 
# 79
::thrust::execution_policy< System1>  &system1; 
# 80
::thrust::execution_policy< System2>  &system2; 
# 83
::thrust::system::cuda::detail::cross_system< System2, System1>  rotate() const 
# 84
{ 
# 85
return ::thrust::system::cuda::detail::cross_system< System2, System1> (system2, system1); 
# 86
} 
# 87
}; 
# 93
template< class System1, class System2> inline cross_system< System1, System2>  
# 95
select_system(const execution_policy< System1>  &system1, const cpp::detail::execution_policy< System2>  &system2) 
# 96
{ 
# 97
thrust::execution_policy< System1>  &non_const_system1 = const_cast< execution_policy< System1>  &>(system1); 
# 98
cpp::detail::execution_policy< System2>  &non_const_system2 = const_cast< cpp::detail::execution_policy< System2>  &>(system2); 
# 99
return cross_system< System1, System2> (non_const_system1, non_const_system2); 
# 100
} 
# 103
template< class System1, class System2> inline cross_system< System1, System2>  
# 105
select_system(const cpp::detail::execution_policy< System1>  &system1, execution_policy< System2>  &system2) 
# 106
{ 
# 107
cpp::detail::execution_policy< System1>  &non_const_system1 = const_cast< cpp::detail::execution_policy< System1>  &>(system1); 
# 108
thrust::execution_policy< System2>  &non_const_system2 = const_cast< execution_policy< System2>  &>(system2); 
# 109
return cross_system< System1, System2> (non_const_system1, non_const_system2); 
# 110
} 
# 113
}
# 116
using detail::execution_policy;
# 117
using detail::tag;
# 119
}
# 120
}
# 123
namespace cuda { 
# 126
using system::cuda::execution_policy;
# 127
using system::cuda::tag;
# 129
}
# 130
}
# 26 "/usr/local/cuda-8.0/include/thrust/iterator/detail/device_system_tag.h"
namespace thrust { 
# 29
typedef system::cuda::detail::tag device_system_tag; 
# 31
}
# 34
namespace thrust { 
# 37
__attribute((deprecated)) typedef device_system_tag device_space_tag; 
# 39
}
# 21 "/usr/local/cuda-8.0/include/thrust/iterator/detail/iterator_category_with_system_and_traversal.h"
namespace thrust { 
# 23
namespace detail { 
# 27
template< class Category, class System, class Traversal> 
# 28
struct iterator_category_with_system_and_traversal : public Category { 
# 31
}; 
# 35
template< class Category> struct iterator_category_to_system; 
# 37
template< class Category, class System, class Traversal> 
# 38
struct iterator_category_to_system< iterator_category_with_system_and_traversal< Category, System, Traversal> >  { 
# 40
typedef System type; 
# 41
}; 
# 45
template< class Category> struct iterator_category_to_traversal; 
# 47
template< class Category, class System, class Traversal> 
# 48
struct iterator_category_to_traversal< iterator_category_with_system_and_traversal< Category, System, Traversal> >  { 
# 50
typedef Traversal type; 
# 51
}; 
# 55
}
# 56
}
# 19 "/usr/local/cuda-8.0/include/thrust/iterator/detail/iterator_traversal_tags.h"
namespace thrust { 
# 23
struct no_traversal_tag { }; 
# 25
struct incrementable_traversal_tag : public no_traversal_tag { 
# 26
}; 
# 28
struct single_pass_traversal_tag : public incrementable_traversal_tag { 
# 29
}; 
# 31
struct forward_traversal_tag : public single_pass_traversal_tag { 
# 32
}; 
# 34
struct bidirectional_traversal_tag : public forward_traversal_tag { 
# 35
}; 
# 37
struct random_access_traversal_tag : public bidirectional_traversal_tag { 
# 38
}; 
# 40
}
# 42 "/usr/include/c++/4.8.2/bits/stringfwd.h" 3
namespace std __attribute((__visibility__("default"))) { 
# 52
template< class _CharT> struct char_traits; 
# 55
template< class _CharT, class _Traits = char_traits< _CharT> , class 
# 56
_Alloc = allocator< _CharT> > class basic_string; 
# 59
template<> struct char_traits< char> ; 
# 62
typedef basic_string< char>  string; 
# 65
template<> struct char_traits< wchar_t> ; 
# 68
typedef basic_string< wchar_t>  wstring; 
# 87
}
# 353 "/usr/lib/gcc/ppc64le-redhat-linux/4.8.5/include/stddef.h" 3
typedef unsigned wint_t; 
# 106 "/usr/include/wchar.h" 3
typedef __mbstate_t mbstate_t; 
# 132
extern "C" {
# 137
struct tm; 
# 147
extern wchar_t *wcscpy(wchar_t *__restrict__ __dest, const wchar_t *__restrict__ __src) throw(); 
# 150
extern wchar_t *wcsncpy(wchar_t *__restrict__ __dest, const wchar_t *__restrict__ __src, size_t __n) throw(); 
# 155
extern wchar_t *wcscat(wchar_t *__restrict__ __dest, const wchar_t *__restrict__ __src) throw(); 
# 158
extern wchar_t *wcsncat(wchar_t *__restrict__ __dest, const wchar_t *__restrict__ __src, size_t __n) throw(); 
# 163
extern int wcscmp(const wchar_t * __s1, const wchar_t * __s2) throw()
# 164
 __attribute((__pure__)); 
# 166
extern int wcsncmp(const wchar_t * __s1, const wchar_t * __s2, size_t __n) throw()
# 167
 __attribute((__pure__)); 
# 172
extern int wcscasecmp(const wchar_t * __s1, const wchar_t * __s2) throw(); 
# 175
extern int wcsncasecmp(const wchar_t * __s1, const wchar_t * __s2, size_t __n) throw(); 
# 182
extern int wcscasecmp_l(const wchar_t * __s1, const wchar_t * __s2, __locale_t __loc) throw(); 
# 185
extern int wcsncasecmp_l(const wchar_t * __s1, const wchar_t * __s2, size_t __n, __locale_t __loc) throw(); 
# 192
extern int wcscoll(const wchar_t * __s1, const wchar_t * __s2) throw(); 
# 196
extern size_t wcsxfrm(wchar_t *__restrict__ __s1, const wchar_t *__restrict__ __s2, size_t __n) throw(); 
# 206
extern int wcscoll_l(const wchar_t * __s1, const wchar_t * __s2, __locale_t __loc) throw(); 
# 212
extern size_t wcsxfrm_l(wchar_t * __s1, const wchar_t * __s2, size_t __n, __locale_t __loc) throw(); 
# 216
extern wchar_t *wcsdup(const wchar_t * __s) throw() __attribute((__malloc__)); 
# 222
extern "C++" wchar_t *wcschr(wchar_t * __wcs, wchar_t __wc) throw() __asm__("wcschr")
# 223
 __attribute((__pure__)); 
# 224
extern "C++" const wchar_t *wcschr(const wchar_t * __wcs, wchar_t __wc) throw() __asm__("wcschr")
# 225
 __attribute((__pure__)); 
# 232
extern "C++" wchar_t *wcsrchr(wchar_t * __wcs, wchar_t __wc) throw() __asm__("wcsrchr")
# 233
 __attribute((__pure__)); 
# 234
extern "C++" const wchar_t *wcsrchr(const wchar_t * __wcs, wchar_t __wc) throw() __asm__("wcsrchr")
# 235
 __attribute((__pure__)); 
# 245
extern wchar_t *wcschrnul(const wchar_t * __s, wchar_t __wc) throw()
# 246
 __attribute((__pure__)); 
# 252
extern size_t wcscspn(const wchar_t * __wcs, const wchar_t * __reject) throw()
# 253
 __attribute((__pure__)); 
# 256
extern size_t wcsspn(const wchar_t * __wcs, const wchar_t * __accept) throw()
# 257
 __attribute((__pure__)); 
# 260
extern "C++" wchar_t *wcspbrk(wchar_t * __wcs, const wchar_t * __accept) throw() __asm__("wcspbrk")
# 261
 __attribute((__pure__)); 
# 262
extern "C++" const wchar_t *wcspbrk(const wchar_t * __wcs, const wchar_t * __accept) throw() __asm__("wcspbrk")
# 264
 __attribute((__pure__)); 
# 271
extern "C++" wchar_t *wcsstr(wchar_t * __haystack, const wchar_t * __needle) throw() __asm__("wcsstr")
# 272
 __attribute((__pure__)); 
# 273
extern "C++" const wchar_t *wcsstr(const wchar_t * __haystack, const wchar_t * __needle) throw() __asm__("wcsstr")
# 275
 __attribute((__pure__)); 
# 282
extern wchar_t *wcstok(wchar_t *__restrict__ __s, const wchar_t *__restrict__ __delim, wchar_t **__restrict__ __ptr) throw(); 
# 287
extern size_t wcslen(const wchar_t * __s) throw() __attribute((__pure__)); 
# 293
extern "C++" wchar_t *wcswcs(wchar_t * __haystack, const wchar_t * __needle) throw() __asm__("wcswcs")
# 294
 __attribute((__pure__)); 
# 295
extern "C++" const wchar_t *wcswcs(const wchar_t * __haystack, const wchar_t * __needle) throw() __asm__("wcswcs")
# 297
 __attribute((__pure__)); 
# 306
extern size_t wcsnlen(const wchar_t * __s, size_t __maxlen) throw()
# 307
 __attribute((__pure__)); 
# 314
extern "C++" wchar_t *wmemchr(wchar_t * __s, wchar_t __c, size_t __n) throw() __asm__("wmemchr")
# 315
 __attribute((__pure__)); 
# 316
extern "C++" const wchar_t *wmemchr(const wchar_t * __s, wchar_t __c, size_t __n) throw() __asm__("wmemchr")
# 318
 __attribute((__pure__)); 
# 325
extern int wmemcmp(const wchar_t * __s1, const wchar_t * __s2, size_t __n) throw()
# 326
 __attribute((__pure__)); 
# 329
extern wchar_t *wmemcpy(wchar_t *__restrict__ __s1, const wchar_t *__restrict__ __s2, size_t __n) throw(); 
# 334
extern wchar_t *wmemmove(wchar_t * __s1, const wchar_t * __s2, size_t __n) throw(); 
# 338
extern wchar_t *wmemset(wchar_t * __s, wchar_t __c, size_t __n) throw(); 
# 344
extern wchar_t *wmempcpy(wchar_t *__restrict__ __s1, const wchar_t *__restrict__ __s2, size_t __n) throw(); 
# 353
extern __attribute((gnu_inline)) inline wint_t btowc(int __c) throw(); 
# 357
extern __attribute((gnu_inline)) inline int wctob(wint_t __c) throw(); 
# 361
extern int mbsinit(const mbstate_t * __ps) throw() __attribute((__pure__)); 
# 365
extern size_t mbrtowc(wchar_t *__restrict__ __pwc, const char *__restrict__ __s, size_t __n, mbstate_t *__restrict__ __p) throw(); 
# 370
extern size_t wcrtomb(char *__restrict__ __s, wchar_t __wc, mbstate_t *__restrict__ __ps) throw(); 
# 374
extern size_t __mbrlen(const char *__restrict__ __s, size_t __n, mbstate_t *__restrict__ __ps) throw(); 
# 376
extern __attribute((gnu_inline)) inline size_t mbrlen(const char *__restrict__ __s, size_t __n, mbstate_t *__restrict__ __ps) throw(); 
# 386
extern wint_t __btowc_alias(int __c) __asm__("btowc"); 
# 387
__attribute((__gnu_inline__)) extern inline wint_t
# 388
 __attribute((__leaf__)) btowc(int __c) throw() 
# 389
{ return ((0) && (__c >= ('\000')) && (__c <= ('\177'))) ? (wint_t)__c : __btowc_alias(__c); 
# 390
} 
# 392
extern int __wctob_alias(wint_t __c) __asm__("wctob"); 
# 393
__attribute((__gnu_inline__)) extern inline int
# 394
 __attribute((__leaf__)) wctob(wint_t __wc) throw() 
# 395
{ return ((0) && (__wc >= (L'\x0')) && (__wc <= (L'\x7f'))) ? (int)__wc : __wctob_alias(__wc); 
# 396
} 
# 398
__attribute((__gnu_inline__)) extern inline size_t
# 399
 __attribute((__leaf__)) mbrlen(const char *__restrict__ __s, size_t __n, mbstate_t *__restrict__ __ps) throw() 
# 401
{ return (__ps != (__null)) ? mbrtowc(__null, __s, __n, __ps) : __mbrlen(__s, __n, __null); 
# 402
} 
# 408
extern size_t mbsrtowcs(wchar_t *__restrict__ __dst, const char **__restrict__ __src, size_t __len, mbstate_t *__restrict__ __ps) throw(); 
# 414
extern size_t wcsrtombs(char *__restrict__ __dst, const wchar_t **__restrict__ __src, size_t __len, mbstate_t *__restrict__ __ps) throw(); 
# 423
extern size_t mbsnrtowcs(wchar_t *__restrict__ __dst, const char **__restrict__ __src, size_t __nmc, size_t __len, mbstate_t *__restrict__ __ps) throw(); 
# 429
extern size_t wcsnrtombs(char *__restrict__ __dst, const wchar_t **__restrict__ __src, size_t __nwc, size_t __len, mbstate_t *__restrict__ __ps) throw(); 
# 439
extern int wcwidth(wchar_t __c) throw(); 
# 443
extern int wcswidth(const wchar_t * __s, size_t __n) throw(); 
# 450
extern double wcstod(const wchar_t *__restrict__ __nptr, wchar_t **__restrict__ __endptr) throw(); 
# 457
extern float wcstof(const wchar_t *__restrict__ __nptr, wchar_t **__restrict__ __endptr) throw(); 
# 459
extern long double wcstold(const wchar_t *__restrict__ __nptr, wchar_t **__restrict__ __endptr) throw(); 
# 468
extern long wcstol(const wchar_t *__restrict__ __nptr, wchar_t **__restrict__ __endptr, int __base) throw(); 
# 473
extern unsigned long wcstoul(const wchar_t *__restrict__ __nptr, wchar_t **__restrict__ __endptr, int __base) throw(); 
# 483
__extension__ extern long long wcstoll(const wchar_t *__restrict__ __nptr, wchar_t **__restrict__ __endptr, int __base) throw(); 
# 490
__extension__ extern unsigned long long wcstoull(const wchar_t *__restrict__ __nptr, wchar_t **__restrict__ __endptr, int __base) throw(); 
# 500
__extension__ extern long long wcstoq(const wchar_t *__restrict__ __nptr, wchar_t **__restrict__ __endptr, int __base) throw(); 
# 507
__extension__ extern unsigned long long wcstouq(const wchar_t *__restrict__ __nptr, wchar_t **__restrict__ __endptr, int __base) throw(); 
# 530
extern long wcstol_l(const wchar_t *__restrict__ __nptr, wchar_t **__restrict__ __endptr, int __base, __locale_t __loc) throw(); 
# 534
extern unsigned long wcstoul_l(const wchar_t *__restrict__ __nptr, wchar_t **__restrict__ __endptr, int __base, __locale_t __loc) throw(); 
# 539
__extension__ extern long long wcstoll_l(const wchar_t *__restrict__ __nptr, wchar_t **__restrict__ __endptr, int __base, __locale_t __loc) throw(); 
# 544
__extension__ extern unsigned long long wcstoull_l(const wchar_t *__restrict__ __nptr, wchar_t **__restrict__ __endptr, int __base, __locale_t __loc) throw(); 
# 549
extern double wcstod_l(const wchar_t *__restrict__ __nptr, wchar_t **__restrict__ __endptr, __locale_t __loc) throw(); 
# 553
extern float wcstof_l(const wchar_t *__restrict__ __nptr, wchar_t **__restrict__ __endptr, __locale_t __loc) throw(); 
# 557
extern long double wcstold_l(const wchar_t *__restrict__ __nptr, wchar_t **__restrict__ __endptr, __locale_t __loc) throw(); 
# 566
extern wchar_t *wcpcpy(wchar_t *__restrict__ __dest, const wchar_t *__restrict__ __src) throw(); 
# 571
extern wchar_t *wcpncpy(wchar_t *__restrict__ __dest, const wchar_t *__restrict__ __src, size_t __n) throw(); 
# 580
extern __FILE *open_wmemstream(wchar_t ** __bufloc, size_t * __sizeloc) throw(); 
# 587
extern int fwide(__FILE * __fp, int __mode) throw(); 
# 594
extern int fwprintf(__FILE *__restrict__ __stream, const wchar_t *__restrict__ __format, ...); 
# 601
extern int wprintf(const wchar_t *__restrict__ __format, ...); 
# 604
extern int swprintf(wchar_t *__restrict__ __s, size_t __n, const wchar_t *__restrict__ __format, ...) throw(); 
# 612
extern int vfwprintf(__FILE *__restrict__ __s, const wchar_t *__restrict__ __format, __gnuc_va_list __arg); 
# 620
extern int vwprintf(const wchar_t *__restrict__ __format, __gnuc_va_list __arg); 
# 625
extern int vswprintf(wchar_t *__restrict__ __s, size_t __n, const wchar_t *__restrict__ __format, __gnuc_va_list __arg) throw(); 
# 635
extern int fwscanf(__FILE *__restrict__ __stream, const wchar_t *__restrict__ __format, ...); 
# 642
extern int wscanf(const wchar_t *__restrict__ __format, ...); 
# 645
extern int swscanf(const wchar_t *__restrict__ __s, const wchar_t *__restrict__ __format, ...) throw(); 
# 689
extern int vfwscanf(__FILE *__restrict__ __s, const wchar_t *__restrict__ __format, __gnuc_va_list __arg); 
# 697
extern int vwscanf(const wchar_t *__restrict__ __format, __gnuc_va_list __arg); 
# 701
extern int vswscanf(const wchar_t *__restrict__ __s, const wchar_t *__restrict__ __format, __gnuc_va_list __arg) throw(); 
# 745
extern wint_t fgetwc(__FILE * __stream); 
# 746
extern wint_t getwc(__FILE * __stream); 
# 752
extern wint_t getwchar(); 
# 759
extern wint_t fputwc(wchar_t __wc, __FILE * __stream); 
# 760
extern wint_t putwc(wchar_t __wc, __FILE * __stream); 
# 766
extern wint_t putwchar(wchar_t __wc); 
# 774
extern wchar_t *fgetws(wchar_t *__restrict__ __ws, int __n, __FILE *__restrict__ __stream); 
# 781
extern int fputws(const wchar_t *__restrict__ __ws, __FILE *__restrict__ __stream); 
# 789
extern wint_t ungetwc(wint_t __wc, __FILE * __stream); 
# 801
extern wint_t getwc_unlocked(__FILE * __stream); 
# 802
extern wint_t getwchar_unlocked(); 
# 810
extern wint_t fgetwc_unlocked(__FILE * __stream); 
# 818
extern wint_t fputwc_unlocked(wchar_t __wc, __FILE * __stream); 
# 827
extern wint_t putwc_unlocked(wchar_t __wc, __FILE * __stream); 
# 828
extern wint_t putwchar_unlocked(wchar_t __wc); 
# 837
extern wchar_t *fgetws_unlocked(wchar_t *__restrict__ __ws, int __n, __FILE *__restrict__ __stream); 
# 846
extern int fputws_unlocked(const wchar_t *__restrict__ __ws, __FILE *__restrict__ __stream); 
# 855
extern size_t wcsftime(wchar_t *__restrict__ __s, size_t __maxsize, const wchar_t *__restrict__ __format, const tm *__restrict__ __tp) throw(); 
# 865
extern size_t wcsftime_l(wchar_t *__restrict__ __s, size_t __maxsize, const wchar_t *__restrict__ __format, const tm *__restrict__ __tp, __locale_t __loc) throw(); 
# 891
}
# 62 "/usr/include/c++/4.8.2/cwchar" 3
namespace std { 
# 64
using ::mbstate_t;
# 65
}
# 135
namespace std __attribute((__visibility__("default"))) { 
# 139
using ::wint_t;
# 141
using ::btowc;
# 142
using ::fgetwc;
# 143
using ::fgetws;
# 144
using ::fputwc;
# 145
using ::fputws;
# 146
using ::fwide;
# 147
using ::fwprintf;
# 148
using ::fwscanf;
# 149
using ::getwc;
# 150
using ::getwchar;
# 151
using ::mbrlen;
# 152
using ::mbrtowc;
# 153
using ::mbsinit;
# 154
using ::mbsrtowcs;
# 155
using ::putwc;
# 156
using ::putwchar;
# 158
using ::swprintf;
# 160
using ::swscanf;
# 161
using ::ungetwc;
# 162
using ::vfwprintf;
# 164
using ::vfwscanf;
# 167
using ::vswprintf;
# 170
using ::vswscanf;
# 172
using ::vwprintf;
# 174
using ::vwscanf;
# 176
using ::wcrtomb;
# 177
using ::wcscat;
# 178
using ::wcscmp;
# 179
using ::wcscoll;
# 180
using ::wcscpy;
# 181
using ::wcscspn;
# 182
using ::wcsftime;
# 183
using ::wcslen;
# 184
using ::wcsncat;
# 185
using ::wcsncmp;
# 186
using ::wcsncpy;
# 187
using ::wcsrtombs;
# 188
using ::wcsspn;
# 189
using ::wcstod;
# 191
using ::wcstof;
# 193
using ::wcstok;
# 194
using ::wcstol;
# 195
using ::wcstoul;
# 196
using ::wcsxfrm;
# 197
using ::wctob;
# 198
using ::wmemcmp;
# 199
using ::wmemcpy;
# 200
using ::wmemmove;
# 201
using ::wmemset;
# 202
using ::wprintf;
# 203
using ::wscanf;
# 204
using ::wcschr;
# 205
using ::wcspbrk;
# 206
using ::wcsrchr;
# 207
using ::wcsstr;
# 208
using ::wmemchr;
# 233
}
# 241
namespace __gnu_cxx { 
# 248
using ::wcstold;
# 257
using ::wcstoll;
# 258
using ::wcstoull;
# 260
}
# 262
namespace std { 
# 264
using __gnu_cxx::wcstold;
# 265
using __gnu_cxx::wcstoll;
# 266
using __gnu_cxx::wcstoull;
# 267
}
# 68 "/usr/include/c++/4.8.2/bits/postypes.h" 3
namespace std __attribute((__visibility__("default"))) { 
# 88
typedef long streamoff; 
# 98
typedef ptrdiff_t streamsize; 
# 111
template< class _StateT> 
# 112
class fpos { 
# 115
streamoff _M_off; 
# 116
_StateT _M_state; 
# 123
public: fpos() : _M_off((0)), _M_state() 
# 124
{ } 
# 133
fpos(streamoff __off) : _M_off(__off), _M_state() 
# 134
{ } 
# 137
operator streamoff() const { return _M_off; } 
# 141
void state(_StateT __st) 
# 142
{ (_M_state) = __st; } 
# 146
_StateT state() const 
# 147
{ return _M_state; } 
# 154
fpos &operator+=(streamoff __off) 
# 155
{ 
# 156
(_M_off) += __off; 
# 157
return *this; 
# 158
} 
# 165
fpos &operator-=(streamoff __off) 
# 166
{ 
# 167
(_M_off) -= __off; 
# 168
return *this; 
# 169
} 
# 178
fpos operator+(streamoff __off) const 
# 179
{ 
# 180
fpos __pos(*this); 
# 181
__pos += __off; 
# 182
return __pos; 
# 183
} 
# 192
fpos operator-(streamoff __off) const 
# 193
{ 
# 194
fpos __pos(*this); 
# 195
__pos -= __off; 
# 196
return __pos; 
# 197
} 
# 205
streamoff operator-(const fpos &__other) const 
# 206
{ return (_M_off) - (__other._M_off); } 
# 207
}; 
# 214
template< class _StateT> inline bool 
# 216
operator==(const fpos< _StateT>  &__lhs, const fpos< _StateT>  &__rhs) 
# 217
{ return ((streamoff)__lhs) == ((streamoff)__rhs); } 
# 219
template< class _StateT> inline bool 
# 221
operator!=(const fpos< _StateT>  &__lhs, const fpos< _StateT>  &__rhs) 
# 222
{ return ((streamoff)__lhs) != ((streamoff)__rhs); } 
# 228
typedef fpos< __mbstate_t>  streampos; 
# 230
typedef fpos< __mbstate_t>  wstreampos; 
# 240
}
# 42 "/usr/include/c++/4.8.2/iosfwd" 3
namespace std __attribute((__visibility__("default"))) { 
# 74
class ios_base; 
# 76
template< class _CharT, class _Traits = char_traits< _CharT> > class basic_ios; 
# 79
template< class _CharT, class _Traits = char_traits< _CharT> > class basic_streambuf; 
# 82
template< class _CharT, class _Traits = char_traits< _CharT> > class basic_istream; 
# 85
template< class _CharT, class _Traits = char_traits< _CharT> > class basic_ostream; 
# 88
template< class _CharT, class _Traits = char_traits< _CharT> > class basic_iostream; 
# 91
template< class _CharT, class _Traits = char_traits< _CharT> , class 
# 92
_Alloc = allocator< _CharT> > class basic_stringbuf; 
# 95
template< class _CharT, class _Traits = char_traits< _CharT> , class 
# 96
_Alloc = allocator< _CharT> > class basic_istringstream; 
# 99
template< class _CharT, class _Traits = char_traits< _CharT> , class 
# 100
_Alloc = allocator< _CharT> > class basic_ostringstream; 
# 103
template< class _CharT, class _Traits = char_traits< _CharT> , class 
# 104
_Alloc = allocator< _CharT> > class basic_stringstream; 
# 107
template< class _CharT, class _Traits = char_traits< _CharT> > class basic_filebuf; 
# 110
template< class _CharT, class _Traits = char_traits< _CharT> > class basic_ifstream; 
# 113
template< class _CharT, class _Traits = char_traits< _CharT> > class basic_ofstream; 
# 116
template< class _CharT, class _Traits = char_traits< _CharT> > class basic_fstream; 
# 119
template< class _CharT, class _Traits = char_traits< _CharT> > class istreambuf_iterator; 
# 122
template< class _CharT, class _Traits = char_traits< _CharT> > class ostreambuf_iterator; 
# 127
typedef basic_ios< char>  ios; 
# 130
typedef basic_streambuf< char>  streambuf; 
# 133
typedef basic_istream< char>  istream; 
# 136
typedef basic_ostream< char>  ostream; 
# 139
typedef basic_iostream< char>  iostream; 
# 142
typedef basic_stringbuf< char>  stringbuf; 
# 145
typedef basic_istringstream< char>  istringstream; 
# 148
typedef basic_ostringstream< char>  ostringstream; 
# 151
typedef basic_stringstream< char>  stringstream; 
# 154
typedef basic_filebuf< char>  filebuf; 
# 157
typedef basic_ifstream< char>  ifstream; 
# 160
typedef basic_ofstream< char>  ofstream; 
# 163
typedef basic_fstream< char>  fstream; 
# 167
typedef basic_ios< wchar_t>  wios; 
# 170
typedef basic_streambuf< wchar_t>  wstreambuf; 
# 173
typedef basic_istream< wchar_t>  wistream; 
# 176
typedef basic_ostream< wchar_t>  wostream; 
# 179
typedef basic_iostream< wchar_t>  wiostream; 
# 182
typedef basic_stringbuf< wchar_t>  wstringbuf; 
# 185
typedef basic_istringstream< wchar_t>  wistringstream; 
# 188
typedef basic_ostringstream< wchar_t>  wostringstream; 
# 191
typedef basic_stringstream< wchar_t>  wstringstream; 
# 194
typedef basic_filebuf< wchar_t>  wfilebuf; 
# 197
typedef basic_ifstream< wchar_t>  wifstream; 
# 200
typedef basic_ofstream< wchar_t>  wofstream; 
# 203
typedef basic_fstream< wchar_t>  wfstream; 
# 208
}
# 43 "/usr/include/c++/4.8.2/bits/char_traits.h" 3
namespace __gnu_cxx __attribute((__visibility__("default"))) { 
# 57
template< class _CharT> 
# 58
struct _Char_types { 
# 60
typedef unsigned long int_type; 
# 61
typedef std::streampos pos_type; 
# 62
typedef std::streamoff off_type; 
# 63
typedef mbstate_t state_type; 
# 64
}; 
# 82
template< class _CharT> 
# 83
struct char_traits { 
# 85
typedef _CharT char_type; 
# 86
typedef typename _Char_types< _CharT> ::int_type int_type; 
# 87
typedef typename _Char_types< _CharT> ::pos_type pos_type; 
# 88
typedef typename _Char_types< _CharT> ::off_type off_type; 
# 89
typedef typename _Char_types< _CharT> ::state_type state_type; 
# 92
static void assign(char_type &__c1, const char_type &__c2) 
# 93
{ __c1 = __c2; } 
# 96
static bool eq(const char_type &__c1, const char_type &__c2) 
# 97
{ return __c1 == __c2; } 
# 100
static bool lt(const char_type &__c1, const char_type &__c2) 
# 101
{ return __c1 < __c2; } 
# 104
static int compare(const char_type * __s1, const char_type * __s2, std::size_t __n); 
# 107
static std::size_t length(const char_type * __s); 
# 110
static const char_type *find(const char_type * __s, std::size_t __n, const char_type & __a); 
# 113
static char_type *move(char_type * __s1, const char_type * __s2, std::size_t __n); 
# 116
static char_type *copy(char_type * __s1, const char_type * __s2, std::size_t __n); 
# 119
static char_type *assign(char_type * __s, std::size_t __n, char_type __a); 
# 122
static char_type to_char_type(const int_type &__c) 
# 123
{ return static_cast< char_type>(__c); } 
# 126
static int_type to_int_type(const char_type &__c) 
# 127
{ return static_cast< int_type>(__c); } 
# 130
static bool eq_int_type(const int_type &__c1, const int_type &__c2) 
# 131
{ return __c1 == __c2; } 
# 134
static int_type eof() 
# 135
{ return static_cast< int_type>(-1); } 
# 138
static int_type not_eof(const int_type &__c) 
# 139
{ return (!(eq_int_type)(__c, (eof)())) ? __c : (to_int_type)(char_type()); } 
# 140
}; 
# 142
template< class _CharT> int 
# 145
char_traits< _CharT> ::compare(const char_type *__s1, const char_type *__s2, std::size_t __n) 
# 146
{ 
# 147
for (std::size_t __i = (0); __i < __n; ++__i) { 
# 148
if ((lt)(__s1[__i], __s2[__i])) { 
# 149
return -1; } else { 
# 150
if ((lt)(__s2[__i], __s1[__i])) { 
# 151
return 1; }  }  }  
# 152
return 0; 
# 153
} 
# 155
template< class _CharT> std::size_t 
# 158
char_traits< _CharT> ::length(const char_type *__p) 
# 159
{ 
# 160
std::size_t __i = (0); 
# 161
while (!(eq)(__p[__i], char_type())) { 
# 162
++__i; }  
# 163
return __i; 
# 164
} 
# 166
template< class _CharT> const typename char_traits< _CharT> ::char_type *
# 169
char_traits< _CharT> ::find(const char_type *__s, std::size_t __n, const char_type &__a) 
# 170
{ 
# 171
for (std::size_t __i = (0); __i < __n; ++__i) { 
# 172
if ((eq)(__s[__i], __a)) { 
# 173
return __s + __i; }  }  
# 174
return 0; 
# 175
} 
# 177
template< class _CharT> typename char_traits< _CharT> ::char_type *
# 180
char_traits< _CharT> ::move(char_type *__s1, const char_type *__s2, std::size_t __n) 
# 181
{ 
# 182
return static_cast< _CharT *>(__builtin_memmove(__s1, __s2, __n * sizeof(char_type))); 
# 184
} 
# 186
template< class _CharT> typename char_traits< _CharT> ::char_type *
# 189
char_traits< _CharT> ::copy(char_type *__s1, const char_type *__s2, std::size_t __n) 
# 190
{ 
# 192
std::copy(__s2, __s2 + __n, __s1); 
# 193
return __s1; 
# 194
} 
# 196
template< class _CharT> typename char_traits< _CharT> ::char_type *
# 199
char_traits< _CharT> ::assign(char_type *__s, std::size_t __n, char_type __a) 
# 200
{ 
# 202
std::fill_n(__s, __n, __a); 
# 203
return __s; 
# 204
} 
# 207
}
# 209
namespace std __attribute((__visibility__("default"))) { 
# 226
template< class _CharT> 
# 227
struct char_traits : public __gnu_cxx::char_traits< _CharT>  { 
# 228
}; 
# 233
template<> struct char_traits< char>  { 
# 235
typedef char char_type; 
# 236
typedef int int_type; 
# 237
typedef streampos pos_type; 
# 238
typedef streamoff off_type; 
# 239
typedef mbstate_t state_type; 
# 242
static void assign(char_type &__c1, const char_type &__c2) 
# 243
{ __c1 = __c2; } 
# 246
static bool eq(const char_type &__c1, const char_type &__c2) 
# 247
{ return __c1 == __c2; } 
# 250
static bool lt(const char_type &__c1, const char_type &__c2) 
# 251
{ return __c1 < __c2; } 
# 254
static int compare(const char_type *__s1, const char_type *__s2, size_t __n) 
# 255
{ return __builtin_memcmp(__s1, __s2, __n); } 
# 258
static size_t length(const char_type *__s) 
# 259
{ return __builtin_strlen(__s); } 
# 262
static const char_type *find(const char_type *__s, size_t __n, const char_type &__a) 
# 263
{ return static_cast< const char_type *>(__builtin_memchr(__s, __a, __n)); } 
# 266
static char_type *move(char_type *__s1, const char_type *__s2, size_t __n) 
# 267
{ return static_cast< char_type *>(__builtin_memmove(__s1, __s2, __n)); } 
# 270
static char_type *copy(char_type *__s1, const char_type *__s2, size_t __n) 
# 271
{ return static_cast< char_type *>(__builtin_memcpy(__s1, __s2, __n)); } 
# 274
static char_type *assign(char_type *__s, size_t __n, char_type __a) 
# 275
{ return static_cast< char_type *>(__builtin_memset(__s, __a, __n)); } 
# 278
static char_type to_char_type(const int_type &__c) 
# 279
{ return static_cast< char_type>(__c); } 
# 284
static int_type to_int_type(const char_type &__c) 
# 285
{ return static_cast< int_type>(static_cast< unsigned char>(__c)); } 
# 288
static bool eq_int_type(const int_type &__c1, const int_type &__c2) 
# 289
{ return __c1 == __c2; } 
# 292
static int_type eof() 
# 293
{ return static_cast< int_type>(-1); } 
# 296
static int_type not_eof(const int_type &__c) 
# 297
{ return (__c == eof()) ? 0 : __c; } 
# 298
}; 
# 304
template<> struct char_traits< wchar_t>  { 
# 306
typedef wchar_t char_type; 
# 307
typedef wint_t int_type; 
# 308
typedef streamoff off_type; 
# 309
typedef wstreampos pos_type; 
# 310
typedef mbstate_t state_type; 
# 313
static void assign(char_type &__c1, const char_type &__c2) 
# 314
{ __c1 = __c2; } 
# 317
static bool eq(const char_type &__c1, const char_type &__c2) 
# 318
{ return __c1 == __c2; } 
# 321
static bool lt(const char_type &__c1, const char_type &__c2) 
# 322
{ return __c1 < __c2; } 
# 325
static int compare(const char_type *__s1, const char_type *__s2, size_t __n) 
# 326
{ return wmemcmp(__s1, __s2, __n); } 
# 329
static size_t length(const char_type *__s) 
# 330
{ return wcslen(__s); } 
# 333
static const char_type *find(const char_type *__s, size_t __n, const char_type &__a) 
# 334
{ return wmemchr(__s, __a, __n); } 
# 337
static char_type *move(char_type *__s1, const char_type *__s2, size_t __n) 
# 338
{ return wmemmove(__s1, __s2, __n); } 
# 341
static char_type *copy(char_type *__s1, const char_type *__s2, size_t __n) 
# 342
{ return wmemcpy(__s1, __s2, __n); } 
# 345
static char_type *assign(char_type *__s, size_t __n, char_type __a) 
# 346
{ return wmemset(__s, __a, __n); } 
# 349
static char_type to_char_type(const int_type &__c) 
# 350
{ return (char_type)__c; } 
# 353
static int_type to_int_type(const char_type &__c) 
# 354
{ return (int_type)__c; } 
# 357
static bool eq_int_type(const int_type &__c1, const int_type &__c2) 
# 358
{ return __c1 == __c2; } 
# 361
static int_type eof() 
# 362
{ return static_cast< int_type>(4294967295U); } 
# 365
static int_type not_eof(const int_type &__c) 
# 366
{ return eq_int_type(__c, eof()) ? 0 : __c; } 
# 367
}; 
# 371
}
# 32 "/usr/include/locale.h" 3
extern "C" {
# 54
struct lconv { 
# 58
char *decimal_point; 
# 59
char *thousands_sep; 
# 65
char *grouping; 
# 71
char *int_curr_symbol; 
# 72
char *currency_symbol; 
# 73
char *mon_decimal_point; 
# 74
char *mon_thousands_sep; 
# 75
char *mon_grouping; 
# 76
char *positive_sign; 
# 77
char *negative_sign; 
# 78
char int_frac_digits; 
# 79
char frac_digits; 
# 81
char p_cs_precedes; 
# 83
char p_sep_by_space; 
# 85
char n_cs_precedes; 
# 87
char n_sep_by_space; 
# 94
char p_sign_posn; 
# 95
char n_sign_posn; 
# 98
char int_p_cs_precedes; 
# 100
char int_p_sep_by_space; 
# 102
char int_n_cs_precedes; 
# 104
char int_n_sep_by_space; 
# 111
char int_p_sign_posn; 
# 112
char int_n_sign_posn; 
# 121
}; 
# 125
extern char *setlocale(int __category, const char * __locale) throw(); 
# 128
extern lconv *localeconv() throw(); 
# 152
extern __locale_t newlocale(int __category_mask, const char * __locale, __locale_t __base) throw(); 
# 187
extern __locale_t duplocale(__locale_t __dataset) throw(); 
# 191
extern void freelocale(__locale_t __dataset) throw(); 
# 198
extern __locale_t uselocale(__locale_t __dataset) throw(); 
# 206
}
# 51 "/usr/include/c++/4.8.2/clocale" 3
namespace std { 
# 53
using ::lconv;
# 54
using ::setlocale;
# 55
using ::localeconv;
# 56
}
# 48 "/usr/include/c++/4.8.2/ppc64le-redhat-linux/bits/c++locale.h" 3
namespace __gnu_cxx __attribute((__visibility__("default"))) { 
# 52
extern "C" __typeof__(uselocale) __uselocale; 
# 55
}
# 58
namespace std __attribute((__visibility__("default"))) { 
# 62
typedef __locale_t __c_locale; 
# 69
inline int __convert_from_v(const __c_locale &__cloc __attribute((__unused__)), char *
# 70
__out, const int 
# 71
__size __attribute((__unused__)), const char *
# 72
__fmt, ...) 
# 73
{ 
# 75
__c_locale __old = __gnu_cxx::__uselocale(__cloc); 
# 88
__builtin_va_list __args; 
# 89
__builtin_va_start(__args,__fmt); 
# 92
const int __ret = __builtin_vsnprintf(__out, __size, __fmt, __args); 
# 97
__builtin_va_end(__args); 
# 100
__gnu_cxx::__uselocale(__old); 
# 108
return __ret; 
# 109
} 
# 112
}
# 29 "/usr/include/ctype.h" 3
extern "C" {
# 48
enum { 
# 49
_ISupper = 256, 
# 50
_ISlower = 512, 
# 51
_ISalpha = 1024, 
# 52
_ISdigit = 2048, 
# 53
_ISxdigit = 4096, 
# 54
_ISspace = 8192, 
# 55
_ISprint = 16384, 
# 56
_ISgraph = 32768, 
# 57
_ISblank = 1, 
# 58
_IScntrl, 
# 59
_ISpunct = 4, 
# 60
_ISalnum = 8
# 61
}; 
# 80
extern const unsigned short **__ctype_b_loc() throw()
# 81
 __attribute((const)); 
# 82
extern const __int32_t **__ctype_tolower_loc() throw()
# 83
 __attribute((const)); 
# 84
extern const __int32_t **__ctype_toupper_loc() throw()
# 85
 __attribute((const)); 
# 111
extern int isalnum(int) throw(); 
# 112
extern int isalpha(int) throw(); 
# 113
extern int iscntrl(int) throw(); 
# 114
extern int isdigit(int) throw(); 
# 115
extern int islower(int) throw(); 
# 116
extern int isgraph(int) throw(); 
# 117
extern int isprint(int) throw(); 
# 118
extern int ispunct(int) throw(); 
# 119
extern int isspace(int) throw(); 
# 120
extern int isupper(int) throw(); 
# 121
extern int isxdigit(int) throw(); 
# 125
extern int tolower(int __c) throw(); 
# 128
extern int toupper(int __c) throw(); 
# 137
extern int isblank(int) throw(); 
# 144
extern int isctype(int __c, int __mask) throw(); 
# 151
extern int isascii(int __c) throw(); 
# 155
extern int toascii(int __c) throw(); 
# 159
extern int _toupper(int) throw(); 
# 160
extern int _tolower(int) throw(); 
# 272
extern int isalnum_l(int, __locale_t) throw(); 
# 273
extern int isalpha_l(int, __locale_t) throw(); 
# 274
extern int iscntrl_l(int, __locale_t) throw(); 
# 275
extern int isdigit_l(int, __locale_t) throw(); 
# 276
extern int islower_l(int, __locale_t) throw(); 
# 277
extern int isgraph_l(int, __locale_t) throw(); 
# 278
extern int isprint_l(int, __locale_t) throw(); 
# 279
extern int ispunct_l(int, __locale_t) throw(); 
# 280
extern int isspace_l(int, __locale_t) throw(); 
# 281
extern int isupper_l(int, __locale_t) throw(); 
# 282
extern int isxdigit_l(int, __locale_t) throw(); 
# 284
extern int isblank_l(int, __locale_t) throw(); 
# 288
extern int __tolower_l(int __c, __locale_t __l) throw(); 
# 289
extern int tolower_l(int __c, __locale_t __l) throw(); 
# 292
extern int __toupper_l(int __c, __locale_t __l) throw(); 
# 293
extern int toupper_l(int __c, __locale_t __l) throw(); 
# 348
}
# 62 "/usr/include/c++/4.8.2/cctype" 3
namespace std { 
# 64
using ::isalnum;
# 65
using ::isalpha;
# 66
using ::iscntrl;
# 67
using ::isdigit;
# 68
using ::isgraph;
# 69
using ::islower;
# 70
using ::isprint;
# 71
using ::ispunct;
# 72
using ::isspace;
# 73
using ::isupper;
# 74
using ::isxdigit;
# 75
using ::tolower;
# 76
using ::toupper;
# 77
}
# 44 "/usr/include/c++/4.8.2/bits/localefwd.h" 3
namespace std __attribute((__visibility__("default"))) { 
# 55
class locale; 
# 57
template< class _Facet> bool has_facet(const locale &) throw(); 
# 61
template< class _Facet> const _Facet &use_facet(const locale &); 
# 66
template< class _CharT> inline bool isspace(_CharT, const locale &); 
# 70
template< class _CharT> inline bool isprint(_CharT, const locale &); 
# 74
template< class _CharT> inline bool iscntrl(_CharT, const locale &); 
# 78
template< class _CharT> inline bool isupper(_CharT, const locale &); 
# 82
template< class _CharT> inline bool islower(_CharT, const locale &); 
# 86
template< class _CharT> inline bool isalpha(_CharT, const locale &); 
# 90
template< class _CharT> inline bool isdigit(_CharT, const locale &); 
# 94
template< class _CharT> inline bool ispunct(_CharT, const locale &); 
# 98
template< class _CharT> inline bool isxdigit(_CharT, const locale &); 
# 102
template< class _CharT> inline bool isalnum(_CharT, const locale &); 
# 106
template< class _CharT> inline bool isgraph(_CharT, const locale &); 
# 110
template< class _CharT> inline _CharT toupper(_CharT, const locale &); 
# 114
template< class _CharT> inline _CharT tolower(_CharT, const locale &); 
# 119
struct ctype_base; 
# 120
template< class _CharT> class ctype; 
# 122
template<> class ctype< char> ; 
# 124
template<> class ctype< wchar_t> ; 
# 126
template< class _CharT> class ctype_byname; 
# 130
class codecvt_base; 
# 131
template< class _InternT, class _ExternT, class _StateT> class codecvt; 
# 133
template<> class codecvt< char, char, __mbstate_t> ; 
# 135
template<> class codecvt< wchar_t, char, __mbstate_t> ; 
# 137
template< class _InternT, class _ExternT, class _StateT> class codecvt_byname; 
# 141
inline namespace __gnu_cxx_ldbl128 { 
# 142
template< class _CharT, class _InIter = istreambuf_iterator< _CharT> > class num_get; 
# 144
template< class _CharT, class _OutIter = ostreambuf_iterator< _CharT> > class num_put; 
# 146
}
# 147
template< class _CharT> class numpunct; 
# 148
template< class _CharT> class numpunct_byname; 
# 151
template< class _CharT> class collate; 
# 153
template< class _CharT> class collate_byname; 
# 157
class time_base; 
# 158
template< class _CharT, class _InIter = istreambuf_iterator< _CharT> > class time_get; 
# 160
template< class _CharT, class _InIter = istreambuf_iterator< _CharT> > class time_get_byname; 
# 162
template< class _CharT, class _OutIter = ostreambuf_iterator< _CharT> > class time_put; 
# 164
template< class _CharT, class _OutIter = ostreambuf_iterator< _CharT> > class time_put_byname; 
# 168
class money_base; 
# 169
inline namespace __gnu_cxx_ldbl128 { 
# 170
template< class _CharT, class _InIter = istreambuf_iterator< _CharT> > class money_get; 
# 172
template< class _CharT, class _OutIter = ostreambuf_iterator< _CharT> > class money_put; 
# 174
}
# 175
template< class _CharT, bool _Intl = false> class moneypunct; 
# 177
template< class _CharT, bool _Intl = false> class moneypunct_byname; 
# 181
class messages_base; 
# 182
template< class _CharT> class messages; 
# 184
template< class _CharT> class messages_byname; 
# 188
}
# 30 "/usr/include/c++/4.8.2/ppc64le-redhat-linux/bits/gthr.h" 3
#pragma GCC visibility push ( default )
# 73 "/usr/include/bits/sched.h" 3
struct sched_param { 
# 75
int __sched_priority; 
# 76
}; 
# 78
extern "C" {
# 82
extern int clone(int (* __fn)(void * __arg), void * __child_stack, int __flags, void * __arg, ...) throw(); 
# 86
extern int unshare(int __flags) throw(); 
# 89
extern int sched_getcpu() throw(); 
# 92
extern int setns(int __fd, int __nstype) throw(); 
# 96
}
# 104
struct __sched_param { 
# 106
int __sched_priority; 
# 107
}; 
# 119
typedef unsigned long __cpu_mask; 
# 129
typedef 
# 127
struct { 
# 128
__cpu_mask __bits[(1024) / ((8) * sizeof(__cpu_mask))]; 
# 129
} cpu_set_t; 
# 202
extern "C" {
# 204
extern int __sched_cpucount(size_t __setsize, const cpu_set_t * __setp) throw(); 
# 206
extern cpu_set_t *__sched_cpualloc(size_t __count) throw(); 
# 207
extern void __sched_cpufree(cpu_set_t * __set) throw(); 
# 209
}
# 47 "/usr/include/sched.h" 3
extern "C" {
# 50
extern int sched_setparam(__pid_t __pid, const sched_param * __param) throw(); 
# 54
extern int sched_getparam(__pid_t __pid, sched_param * __param) throw(); 
# 57
extern int sched_setscheduler(__pid_t __pid, int __policy, const sched_param * __param) throw(); 
# 61
extern int sched_getscheduler(__pid_t __pid) throw(); 
# 64
extern int sched_yield() throw(); 
# 67
extern int sched_get_priority_max(int __algorithm) throw(); 
# 70
extern int sched_get_priority_min(int __algorithm) throw(); 
# 73
extern int sched_rr_get_interval(__pid_t __pid, timespec * __t) throw(); 
# 117
extern int sched_setaffinity(__pid_t __pid, size_t __cpusetsize, const cpu_set_t * __cpuset) throw(); 
# 121
extern int sched_getaffinity(__pid_t __pid, size_t __cpusetsize, cpu_set_t * __cpuset) throw(); 
# 125
}
# 43 "/usr/include/bits/setjmp.h" 3
typedef long __jmp_buf[64] __attribute((__aligned__(16))); 
# 33 "/usr/include/pthread.h" 3
enum { 
# 34
PTHREAD_CREATE_JOINABLE, 
# 36
PTHREAD_CREATE_DETACHED
# 38
}; 
# 43
enum { 
# 44
PTHREAD_MUTEX_TIMED_NP, 
# 45
PTHREAD_MUTEX_RECURSIVE_NP, 
# 46
PTHREAD_MUTEX_ERRORCHECK_NP, 
# 47
PTHREAD_MUTEX_ADAPTIVE_NP, 
# 50
PTHREAD_MUTEX_NORMAL = 0, 
# 51
PTHREAD_MUTEX_RECURSIVE, 
# 52
PTHREAD_MUTEX_ERRORCHECK, 
# 53
PTHREAD_MUTEX_DEFAULT = 0, 
# 57
PTHREAD_MUTEX_FAST_NP = 0
# 59
}; 
# 65
enum { 
# 66
PTHREAD_MUTEX_STALLED, 
# 67
PTHREAD_MUTEX_STALLED_NP = 0, 
# 68
PTHREAD_MUTEX_ROBUST, 
# 69
PTHREAD_MUTEX_ROBUST_NP = 1
# 70
}; 
# 77
enum { 
# 78
PTHREAD_PRIO_NONE, 
# 79
PTHREAD_PRIO_INHERIT, 
# 80
PTHREAD_PRIO_PROTECT
# 81
}; 
# 114
enum { 
# 115
PTHREAD_RWLOCK_PREFER_READER_NP, 
# 116
PTHREAD_RWLOCK_PREFER_WRITER_NP, 
# 117
PTHREAD_RWLOCK_PREFER_WRITER_NONRECURSIVE_NP, 
# 118
PTHREAD_RWLOCK_DEFAULT_NP = 0
# 119
}; 
# 155
enum { 
# 156
PTHREAD_INHERIT_SCHED, 
# 158
PTHREAD_EXPLICIT_SCHED
# 160
}; 
# 165
enum { 
# 166
PTHREAD_SCOPE_SYSTEM, 
# 168
PTHREAD_SCOPE_PROCESS
# 170
}; 
# 175
enum { 
# 176
PTHREAD_PROCESS_PRIVATE, 
# 178
PTHREAD_PROCESS_SHARED
# 180
}; 
# 189
struct _pthread_cleanup_buffer { 
# 191
void (*__routine)(void *); 
# 192
void *__arg; 
# 193
int __canceltype; 
# 194
_pthread_cleanup_buffer *__prev; 
# 195
}; 
# 199
enum { 
# 200
PTHREAD_CANCEL_ENABLE, 
# 202
PTHREAD_CANCEL_DISABLE
# 204
}; 
# 206
enum { 
# 207
PTHREAD_CANCEL_DEFERRED, 
# 209
PTHREAD_CANCEL_ASYNCHRONOUS
# 211
}; 
# 227
extern "C" {
# 232
extern int pthread_create(pthread_t *__restrict__ __newthread, const pthread_attr_t *__restrict__ __attr, void *(* __start_routine)(void *), void *__restrict__ __arg) throw()
# 235
 __attribute((__nonnull__(1, 3))); 
# 241
extern void pthread_exit(void * __retval) __attribute((__noreturn__)); 
# 249
extern int pthread_join(pthread_t __th, void ** __thread_return); 
# 254
extern int pthread_tryjoin_np(pthread_t __th, void ** __thread_return) throw(); 
# 262
extern int pthread_timedjoin_np(pthread_t __th, void ** __thread_return, const timespec * __abstime); 
# 270
extern int pthread_detach(pthread_t __th) throw(); 
# 274
extern pthread_t pthread_self() throw() __attribute((const)); 
# 277
extern __attribute((gnu_inline)) inline int pthread_equal(pthread_t __thread1, pthread_t __thread2) throw()
# 278
 __attribute((const)); 
# 286
extern int pthread_attr_init(pthread_attr_t * __attr) throw() __attribute((__nonnull__(1))); 
# 289
extern int pthread_attr_destroy(pthread_attr_t * __attr) throw()
# 290
 __attribute((__nonnull__(1))); 
# 293
extern int pthread_attr_getdetachstate(const pthread_attr_t * __attr, int * __detachstate) throw()
# 295
 __attribute((__nonnull__(1, 2))); 
# 298
extern int pthread_attr_setdetachstate(pthread_attr_t * __attr, int __detachstate) throw()
# 300
 __attribute((__nonnull__(1))); 
# 304
extern int pthread_attr_getguardsize(const pthread_attr_t * __attr, size_t * __guardsize) throw()
# 306
 __attribute((__nonnull__(1, 2))); 
# 309
extern int pthread_attr_setguardsize(pthread_attr_t * __attr, size_t __guardsize) throw()
# 311
 __attribute((__nonnull__(1))); 
# 315
extern int pthread_attr_getschedparam(const pthread_attr_t *__restrict__ __attr, sched_param *__restrict__ __param) throw()
# 317
 __attribute((__nonnull__(1, 2))); 
# 320
extern int pthread_attr_setschedparam(pthread_attr_t *__restrict__ __attr, const sched_param *__restrict__ __param) throw()
# 322
 __attribute((__nonnull__(1, 2))); 
# 325
extern int pthread_attr_getschedpolicy(const pthread_attr_t *__restrict__ __attr, int *__restrict__ __policy) throw()
# 327
 __attribute((__nonnull__(1, 2))); 
# 330
extern int pthread_attr_setschedpolicy(pthread_attr_t * __attr, int __policy) throw()
# 331
 __attribute((__nonnull__(1))); 
# 334
extern int pthread_attr_getinheritsched(const pthread_attr_t *__restrict__ __attr, int *__restrict__ __inherit) throw()
# 336
 __attribute((__nonnull__(1, 2))); 
# 339
extern int pthread_attr_setinheritsched(pthread_attr_t * __attr, int __inherit) throw()
# 341
 __attribute((__nonnull__(1))); 
# 345
extern int pthread_attr_getscope(const pthread_attr_t *__restrict__ __attr, int *__restrict__ __scope) throw()
# 347
 __attribute((__nonnull__(1, 2))); 
# 350
extern int pthread_attr_setscope(pthread_attr_t * __attr, int __scope) throw()
# 351
 __attribute((__nonnull__(1))); 
# 354
extern int pthread_attr_getstackaddr(const pthread_attr_t *__restrict__ __attr, void **__restrict__ __stackaddr) throw()
# 356
 __attribute((__nonnull__(1, 2))) __attribute((__deprecated__)); 
# 362
extern int pthread_attr_setstackaddr(pthread_attr_t * __attr, void * __stackaddr) throw()
# 364
 __attribute((__nonnull__(1))) __attribute((__deprecated__)); 
# 367
extern int pthread_attr_getstacksize(const pthread_attr_t *__restrict__ __attr, size_t *__restrict__ __stacksize) throw()
# 369
 __attribute((__nonnull__(1, 2))); 
# 374
extern int pthread_attr_setstacksize(pthread_attr_t * __attr, size_t __stacksize) throw()
# 376
 __attribute((__nonnull__(1))); 
# 380
extern int pthread_attr_getstack(const pthread_attr_t *__restrict__ __attr, void **__restrict__ __stackaddr, size_t *__restrict__ __stacksize) throw()
# 383
 __attribute((__nonnull__(1, 2, 3))); 
# 388
extern int pthread_attr_setstack(pthread_attr_t * __attr, void * __stackaddr, size_t __stacksize) throw()
# 389
 __attribute((__nonnull__(1))); 
# 395
extern int pthread_attr_setaffinity_np(pthread_attr_t * __attr, size_t __cpusetsize, const cpu_set_t * __cpuset) throw()
# 398
 __attribute((__nonnull__(1, 3))); 
# 402
extern int pthread_attr_getaffinity_np(const pthread_attr_t * __attr, size_t __cpusetsize, cpu_set_t * __cpuset) throw()
# 405
 __attribute((__nonnull__(1, 3))); 
# 411
extern int pthread_getattr_np(pthread_t __th, pthread_attr_t * __attr) throw()
# 412
 __attribute((__nonnull__(2))); 
# 420
extern int pthread_setschedparam(pthread_t __target_thread, int __policy, const sched_param * __param) throw()
# 422
 __attribute((__nonnull__(3))); 
# 425
extern int pthread_getschedparam(pthread_t __target_thread, int *__restrict__ __policy, sched_param *__restrict__ __param) throw()
# 428
 __attribute((__nonnull__(2, 3))); 
# 431
extern int pthread_setschedprio(pthread_t __target_thread, int __prio) throw(); 
# 437
extern int pthread_getname_np(pthread_t __target_thread, char * __buf, size_t __buflen) throw()
# 439
 __attribute((__nonnull__(2))); 
# 442
extern int pthread_setname_np(pthread_t __target_thread, const char * __name) throw()
# 443
 __attribute((__nonnull__(2))); 
# 449
extern int pthread_getconcurrency() throw(); 
# 452
extern int pthread_setconcurrency(int __level) throw(); 
# 460
extern int pthread_yield() throw(); 
# 465
extern int pthread_setaffinity_np(pthread_t __th, size_t __cpusetsize, const cpu_set_t * __cpuset) throw()
# 467
 __attribute((__nonnull__(3))); 
# 470
extern int pthread_getaffinity_np(pthread_t __th, size_t __cpusetsize, cpu_set_t * __cpuset) throw()
# 472
 __attribute((__nonnull__(3))); 
# 485
extern int pthread_once(pthread_once_t * __once_control, void (* __init_routine)(void))
# 486
 __attribute((__nonnull__(1, 2))); 
# 497
extern int pthread_setcancelstate(int __state, int * __oldstate); 
# 501
extern int pthread_setcanceltype(int __type, int * __oldtype); 
# 504
extern int pthread_cancel(pthread_t __th); 
# 509
extern void pthread_testcancel(); 
# 522
typedef 
# 515
struct { 
# 517
struct { 
# 518
__jmp_buf __cancel_jmp_buf; 
# 519
int __mask_was_saved; 
# 520
} __cancel_jmp_buf[1]; 
# 521
void *__pad[4]; 
# 522
} __pthread_unwind_buf_t __attribute((__aligned__)); 
# 531
struct __pthread_cleanup_frame { 
# 533
void (*__cancel_routine)(void *); 
# 534
void *__cancel_arg; 
# 535
int __do_it; 
# 536
int __cancel_type; 
# 537
}; 
# 542
class __pthread_cleanup_class { 
# 544
void (*__cancel_routine)(void *); 
# 545
void *__cancel_arg; 
# 546
int __do_it; 
# 547
int __cancel_type; 
# 550
public: __pthread_cleanup_class(void (*__fct)(void *), void *__arg) : __cancel_routine(__fct), __cancel_arg(__arg), __do_it(1) 
# 551
{ } 
# 552
~__pthread_cleanup_class() { if (__do_it) { (__cancel_routine)(__cancel_arg); }  } 
# 553
void __setdoit(int __newval) { (__do_it) = __newval; } 
# 554
void __defer() { pthread_setcanceltype(PTHREAD_CANCEL_DEFERRED, &(__cancel_type)); 
# 555
} 
# 556
void __restore() const { pthread_setcanceltype(__cancel_type, 0); } 
# 557
}; 
# 733
struct __jmp_buf_tag; 
# 734
extern int __sigsetjmp(__jmp_buf_tag * __env, int __savemask) throw(); 
# 740
extern int pthread_mutex_init(pthread_mutex_t * __mutex, const pthread_mutexattr_t * __mutexattr) throw()
# 742
 __attribute((__nonnull__(1))); 
# 745
extern int pthread_mutex_destroy(pthread_mutex_t * __mutex) throw()
# 746
 __attribute((__nonnull__(1))); 
# 749
extern int pthread_mutex_trylock(pthread_mutex_t * __mutex) throw()
# 750
 __attribute((__nonnull__(1))); 
# 753
extern int pthread_mutex_lock(pthread_mutex_t * __mutex) throw()
# 754
 __attribute((__nonnull__(1))); 
# 758
extern int pthread_mutex_timedlock(pthread_mutex_t *__restrict__ __mutex, const timespec *__restrict__ __abstime) throw()
# 760
 __attribute((__nonnull__(1, 2))); 
# 764
extern int pthread_mutex_unlock(pthread_mutex_t * __mutex) throw()
# 765
 __attribute((__nonnull__(1))); 
# 769
extern int pthread_mutex_getprioceiling(const pthread_mutex_t *__restrict__ __mutex, int *__restrict__ __prioceiling) throw()
# 772
 __attribute((__nonnull__(1, 2))); 
# 776
extern int pthread_mutex_setprioceiling(pthread_mutex_t *__restrict__ __mutex, int __prioceiling, int *__restrict__ __old_ceiling) throw()
# 779
 __attribute((__nonnull__(1, 3))); 
# 784
extern int pthread_mutex_consistent(pthread_mutex_t * __mutex) throw()
# 785
 __attribute((__nonnull__(1))); 
# 787
extern int pthread_mutex_consistent_np(pthread_mutex_t * __mutex) throw()
# 788
 __attribute((__nonnull__(1))); 
# 797
extern int pthread_mutexattr_init(pthread_mutexattr_t * __attr) throw()
# 798
 __attribute((__nonnull__(1))); 
# 801
extern int pthread_mutexattr_destroy(pthread_mutexattr_t * __attr) throw()
# 802
 __attribute((__nonnull__(1))); 
# 805
extern int pthread_mutexattr_getpshared(const pthread_mutexattr_t *__restrict__ __attr, int *__restrict__ __pshared) throw()
# 808
 __attribute((__nonnull__(1, 2))); 
# 811
extern int pthread_mutexattr_setpshared(pthread_mutexattr_t * __attr, int __pshared) throw()
# 813
 __attribute((__nonnull__(1))); 
# 817
extern int pthread_mutexattr_gettype(const pthread_mutexattr_t *__restrict__ __attr, int *__restrict__ __kind) throw()
# 819
 __attribute((__nonnull__(1, 2))); 
# 824
extern int pthread_mutexattr_settype(pthread_mutexattr_t * __attr, int __kind) throw()
# 825
 __attribute((__nonnull__(1))); 
# 829
extern int pthread_mutexattr_getprotocol(const pthread_mutexattr_t *__restrict__ __attr, int *__restrict__ __protocol) throw()
# 832
 __attribute((__nonnull__(1, 2))); 
# 836
extern int pthread_mutexattr_setprotocol(pthread_mutexattr_t * __attr, int __protocol) throw()
# 838
 __attribute((__nonnull__(1))); 
# 841
extern int pthread_mutexattr_getprioceiling(const pthread_mutexattr_t *__restrict__ __attr, int *__restrict__ __prioceiling) throw()
# 844
 __attribute((__nonnull__(1, 2))); 
# 847
extern int pthread_mutexattr_setprioceiling(pthread_mutexattr_t * __attr, int __prioceiling) throw()
# 849
 __attribute((__nonnull__(1))); 
# 853
extern int pthread_mutexattr_getrobust(const pthread_mutexattr_t * __attr, int * __robustness) throw()
# 855
 __attribute((__nonnull__(1, 2))); 
# 857
extern int pthread_mutexattr_getrobust_np(const pthread_mutexattr_t * __attr, int * __robustness) throw()
# 859
 __attribute((__nonnull__(1, 2))); 
# 863
extern int pthread_mutexattr_setrobust(pthread_mutexattr_t * __attr, int __robustness) throw()
# 865
 __attribute((__nonnull__(1))); 
# 867
extern int pthread_mutexattr_setrobust_np(pthread_mutexattr_t * __attr, int __robustness) throw()
# 869
 __attribute((__nonnull__(1))); 
# 879
extern int pthread_rwlock_init(pthread_rwlock_t *__restrict__ __rwlock, const pthread_rwlockattr_t *__restrict__ __attr) throw()
# 881
 __attribute((__nonnull__(1))); 
# 884
extern int pthread_rwlock_destroy(pthread_rwlock_t * __rwlock) throw()
# 885
 __attribute((__nonnull__(1))); 
# 888
extern int pthread_rwlock_rdlock(pthread_rwlock_t * __rwlock) throw()
# 889
 __attribute((__nonnull__(1))); 
# 892
extern int pthread_rwlock_tryrdlock(pthread_rwlock_t * __rwlock) throw()
# 893
 __attribute((__nonnull__(1))); 
# 897
extern int pthread_rwlock_timedrdlock(pthread_rwlock_t *__restrict__ __rwlock, const timespec *__restrict__ __abstime) throw()
# 899
 __attribute((__nonnull__(1, 2))); 
# 903
extern int pthread_rwlock_wrlock(pthread_rwlock_t * __rwlock) throw()
# 904
 __attribute((__nonnull__(1))); 
# 907
extern int pthread_rwlock_trywrlock(pthread_rwlock_t * __rwlock) throw()
# 908
 __attribute((__nonnull__(1))); 
# 912
extern int pthread_rwlock_timedwrlock(pthread_rwlock_t *__restrict__ __rwlock, const timespec *__restrict__ __abstime) throw()
# 914
 __attribute((__nonnull__(1, 2))); 
# 918
extern int pthread_rwlock_unlock(pthread_rwlock_t * __rwlock) throw()
# 919
 __attribute((__nonnull__(1))); 
# 925
extern int pthread_rwlockattr_init(pthread_rwlockattr_t * __attr) throw()
# 926
 __attribute((__nonnull__(1))); 
# 929
extern int pthread_rwlockattr_destroy(pthread_rwlockattr_t * __attr) throw()
# 930
 __attribute((__nonnull__(1))); 
# 933
extern int pthread_rwlockattr_getpshared(const pthread_rwlockattr_t *__restrict__ __attr, int *__restrict__ __pshared) throw()
# 936
 __attribute((__nonnull__(1, 2))); 
# 939
extern int pthread_rwlockattr_setpshared(pthread_rwlockattr_t * __attr, int __pshared) throw()
# 941
 __attribute((__nonnull__(1))); 
# 944
extern int pthread_rwlockattr_getkind_np(const pthread_rwlockattr_t *__restrict__ __attr, int *__restrict__ __pref) throw()
# 947
 __attribute((__nonnull__(1, 2))); 
# 950
extern int pthread_rwlockattr_setkind_np(pthread_rwlockattr_t * __attr, int __pref) throw()
# 951
 __attribute((__nonnull__(1))); 
# 959
extern int pthread_cond_init(pthread_cond_t *__restrict__ __cond, const pthread_condattr_t *__restrict__ __cond_attr) throw()
# 961
 __attribute((__nonnull__(1))); 
# 964
extern int pthread_cond_destroy(pthread_cond_t * __cond) throw()
# 965
 __attribute((__nonnull__(1))); 
# 968
extern int pthread_cond_signal(pthread_cond_t * __cond) throw()
# 969
 __attribute((__nonnull__(1))); 
# 972
extern int pthread_cond_broadcast(pthread_cond_t * __cond) throw()
# 973
 __attribute((__nonnull__(1))); 
# 980
extern int pthread_cond_wait(pthread_cond_t *__restrict__ __cond, pthread_mutex_t *__restrict__ __mutex)
# 982
 __attribute((__nonnull__(1, 2))); 
# 991
extern int pthread_cond_timedwait(pthread_cond_t *__restrict__ __cond, pthread_mutex_t *__restrict__ __mutex, const timespec *__restrict__ __abstime)
# 994
 __attribute((__nonnull__(1, 2, 3))); 
# 999
extern int pthread_condattr_init(pthread_condattr_t * __attr) throw()
# 1000
 __attribute((__nonnull__(1))); 
# 1003
extern int pthread_condattr_destroy(pthread_condattr_t * __attr) throw()
# 1004
 __attribute((__nonnull__(1))); 
# 1007
extern int pthread_condattr_getpshared(const pthread_condattr_t *__restrict__ __attr, int *__restrict__ __pshared) throw()
# 1010
 __attribute((__nonnull__(1, 2))); 
# 1013
extern int pthread_condattr_setpshared(pthread_condattr_t * __attr, int __pshared) throw()
# 1014
 __attribute((__nonnull__(1))); 
# 1018
extern int pthread_condattr_getclock(const pthread_condattr_t *__restrict__ __attr, __clockid_t *__restrict__ __clock_id) throw()
# 1021
 __attribute((__nonnull__(1, 2))); 
# 1024
extern int pthread_condattr_setclock(pthread_condattr_t * __attr, __clockid_t __clock_id) throw()
# 1026
 __attribute((__nonnull__(1))); 
# 1035
extern int pthread_spin_init(pthread_spinlock_t * __lock, int __pshared) throw()
# 1036
 __attribute((__nonnull__(1))); 
# 1039
extern int pthread_spin_destroy(pthread_spinlock_t * __lock) throw()
# 1040
 __attribute((__nonnull__(1))); 
# 1043
extern int pthread_spin_lock(pthread_spinlock_t * __lock) throw()
# 1044
 __attribute((__nonnull__(1))); 
# 1047
extern int pthread_spin_trylock(pthread_spinlock_t * __lock) throw()
# 1048
 __attribute((__nonnull__(1))); 
# 1051
extern int pthread_spin_unlock(pthread_spinlock_t * __lock) throw()
# 1052
 __attribute((__nonnull__(1))); 
# 1059
extern int pthread_barrier_init(pthread_barrier_t *__restrict__ __barrier, const pthread_barrierattr_t *__restrict__ __attr, unsigned __count) throw()
# 1062
 __attribute((__nonnull__(1))); 
# 1065
extern int pthread_barrier_destroy(pthread_barrier_t * __barrier) throw()
# 1066
 __attribute((__nonnull__(1))); 
# 1069
extern int pthread_barrier_wait(pthread_barrier_t * __barrier) throw()
# 1070
 __attribute((__nonnull__(1))); 
# 1074
extern int pthread_barrierattr_init(pthread_barrierattr_t * __attr) throw()
# 1075
 __attribute((__nonnull__(1))); 
# 1078
extern int pthread_barrierattr_destroy(pthread_barrierattr_t * __attr) throw()
# 1079
 __attribute((__nonnull__(1))); 
# 1082
extern int pthread_barrierattr_getpshared(const pthread_barrierattr_t *__restrict__ __attr, int *__restrict__ __pshared) throw()
# 1085
 __attribute((__nonnull__(1, 2))); 
# 1088
extern int pthread_barrierattr_setpshared(pthread_barrierattr_t * __attr, int __pshared) throw()
# 1090
 __attribute((__nonnull__(1))); 
# 1102
extern int pthread_key_create(pthread_key_t * __key, void (* __destr_function)(void *)) throw()
# 1104
 __attribute((__nonnull__(1))); 
# 1107
extern int pthread_key_delete(pthread_key_t __key) throw(); 
# 1110
extern void *pthread_getspecific(pthread_key_t __key) throw(); 
# 1113
extern int pthread_setspecific(pthread_key_t __key, const void * __pointer) throw(); 
# 1119
extern int pthread_getcpuclockid(pthread_t __thread_id, __clockid_t * __clock_id) throw()
# 1121
 __attribute((__nonnull__(2))); 
# 1136
extern int pthread_atfork(void (* __prepare)(void), void (* __parent)(void), void (* __child)(void)) throw(); 
# 1143
__attribute((__gnu_inline__)) extern inline int
# 1144
 __attribute((__leaf__)) pthread_equal(pthread_t __thread1, pthread_t __thread2) throw() 
# 1145
{ 
# 1146
return __thread1 == __thread2; 
# 1147
} 
# 1150
}
# 47 "/usr/include/c++/4.8.2/ppc64le-redhat-linux/bits/gthr-default.h" 3
typedef pthread_t __gthread_t; 
# 48
typedef pthread_key_t __gthread_key_t; 
# 49
typedef pthread_once_t __gthread_once_t; 
# 50
typedef pthread_mutex_t __gthread_mutex_t; 
# 51
typedef pthread_mutex_t __gthread_recursive_mutex_t; 
# 52
typedef pthread_cond_t __gthread_cond_t; 
# 53
typedef timespec __gthread_time_t; 
# 101
static __typeof__(pthread_once) __gthrw_pthread_once __attribute((__weakref__("pthread_once"))); 
# 102
static __typeof__(pthread_getspecific) __gthrw_pthread_getspecific __attribute((__weakref__("pthread_getspecific"))); 
# 103
static __typeof__(pthread_setspecific) __gthrw_pthread_setspecific __attribute((__weakref__("pthread_setspecific"))); 
# 105
static __typeof__(pthread_create) __gthrw_pthread_create __attribute((__weakref__("pthread_create"))); 
# 106
static __typeof__(pthread_join) __gthrw_pthread_join __attribute((__weakref__("pthread_join"))); 
# 107
static __typeof__(pthread_equal) __gthrw_pthread_equal __attribute((__weakref__("pthread_equal"))); 
# 108
static __typeof__(pthread_self) __gthrw_pthread_self __attribute((__weakref__("pthread_self"))); 
# 109
static __typeof__(pthread_detach) __gthrw_pthread_detach __attribute((__weakref__("pthread_detach"))); 
# 111
static __typeof__(pthread_cancel) __gthrw_pthread_cancel __attribute((__weakref__("pthread_cancel"))); 
# 113
static __typeof__(sched_yield) __gthrw_sched_yield __attribute((__weakref__("sched_yield"))); 
# 115
static __typeof__(pthread_mutex_lock) __gthrw_pthread_mutex_lock __attribute((__weakref__("pthread_mutex_lock"))); 
# 116
static __typeof__(pthread_mutex_trylock) __gthrw_pthread_mutex_trylock __attribute((__weakref__("pthread_mutex_trylock"))); 
# 118
static __typeof__(pthread_mutex_timedlock) __gthrw_pthread_mutex_timedlock __attribute((__weakref__("pthread_mutex_timedlock"))); 
# 120
static __typeof__(pthread_mutex_unlock) __gthrw_pthread_mutex_unlock __attribute((__weakref__("pthread_mutex_unlock"))); 
# 121
static __typeof__(pthread_mutex_init) __gthrw_pthread_mutex_init __attribute((__weakref__("pthread_mutex_init"))); 
# 122
static __typeof__(pthread_mutex_destroy) __gthrw_pthread_mutex_destroy __attribute((__weakref__("pthread_mutex_destroy"))); 
# 124
static __typeof__(pthread_cond_init) __gthrw_pthread_cond_init __attribute((__weakref__("pthread_cond_init"))); 
# 125
static __typeof__(pthread_cond_broadcast) __gthrw_pthread_cond_broadcast __attribute((__weakref__("pthread_cond_broadcast"))); 
# 126
static __typeof__(pthread_cond_signal) __gthrw_pthread_cond_signal __attribute((__weakref__("pthread_cond_signal"))); 
# 127
static __typeof__(pthread_cond_wait) __gthrw_pthread_cond_wait __attribute((__weakref__("pthread_cond_wait"))); 
# 128
static __typeof__(pthread_cond_timedwait) __gthrw_pthread_cond_timedwait __attribute((__weakref__("pthread_cond_timedwait"))); 
# 129
static __typeof__(pthread_cond_destroy) __gthrw_pthread_cond_destroy __attribute((__weakref__("pthread_cond_destroy"))); 
# 131
static __typeof__(pthread_key_create) __gthrw_pthread_key_create __attribute((__weakref__("pthread_key_create"))); 
# 132
static __typeof__(pthread_key_delete) __gthrw_pthread_key_delete __attribute((__weakref__("pthread_key_delete"))); 
# 133
static __typeof__(pthread_mutexattr_init) __gthrw_pthread_mutexattr_init __attribute((__weakref__("pthread_mutexattr_init"))); 
# 134
static __typeof__(pthread_mutexattr_settype) __gthrw_pthread_mutexattr_settype __attribute((__weakref__("pthread_mutexattr_settype"))); 
# 135
static __typeof__(pthread_mutexattr_destroy) __gthrw_pthread_mutexattr_destroy __attribute((__weakref__("pthread_mutexattr_destroy"))); 
# 236
static __typeof__(pthread_key_create) __gthrw___pthread_key_create __attribute((__weakref__("__pthread_key_create"))); 
# 247
static inline int __gthread_active_p() 
# 248
{ 
# 249
static void *const __gthread_active_ptr = __extension__ ((void *)(&__gthrw___pthread_key_create)); 
# 251
return __gthread_active_ptr != (0); 
# 252
} 
# 659
static inline int __gthread_create(__gthread_t *__threadid, void *(*__func)(void *), void *
# 660
__args) 
# 661
{ 
# 662
return __gthrw_pthread_create(__threadid, __null, __func, __args); 
# 663
} 
# 666
static inline int __gthread_join(__gthread_t __threadid, void **__value_ptr) 
# 667
{ 
# 668
return __gthrw_pthread_join(__threadid, __value_ptr); 
# 669
} 
# 672
static inline int __gthread_detach(__gthread_t __threadid) 
# 673
{ 
# 674
return __gthrw_pthread_detach(__threadid); 
# 675
} 
# 678
static inline int __gthread_equal(__gthread_t __t1, __gthread_t __t2) 
# 679
{ 
# 680
return __gthrw_pthread_equal(__t1, __t2); 
# 681
} 
# 684
static inline __gthread_t __gthread_self() 
# 685
{ 
# 686
return __gthrw_pthread_self(); 
# 687
} 
# 690
static inline int __gthread_yield() 
# 691
{ 
# 692
return __gthrw_sched_yield(); 
# 693
} 
# 696
static inline int __gthread_once(__gthread_once_t *__once, void (*__func)(void)) 
# 697
{ 
# 698
if (__gthread_active_p()) { 
# 699
return __gthrw_pthread_once(__once, __func); } else { 
# 701
return -1; }  
# 702
} 
# 705
static inline int __gthread_key_create(__gthread_key_t *__key, void (*__dtor)(void *)) 
# 706
{ 
# 707
return __gthrw_pthread_key_create(__key, __dtor); 
# 708
} 
# 711
static inline int __gthread_key_delete(__gthread_key_t __key) 
# 712
{ 
# 713
return __gthrw_pthread_key_delete(__key); 
# 714
} 
# 717
static inline void *__gthread_getspecific(__gthread_key_t __key) 
# 718
{ 
# 719
return __gthrw_pthread_getspecific(__key); 
# 720
} 
# 723
static inline int __gthread_setspecific(__gthread_key_t __key, const void *__ptr) 
# 724
{ 
# 725
return __gthrw_pthread_setspecific(__key, __ptr); 
# 726
} 
# 729
static inline void __gthread_mutex_init_function(__gthread_mutex_t *__mutex) 
# 730
{ 
# 731
if (__gthread_active_p()) { 
# 732
__gthrw_pthread_mutex_init(__mutex, __null); }  
# 733
} 
# 736
static inline int __gthread_mutex_destroy(__gthread_mutex_t *__mutex) 
# 737
{ 
# 738
if (__gthread_active_p()) { 
# 739
return __gthrw_pthread_mutex_destroy(__mutex); } else { 
# 741
return 0; }  
# 742
} 
# 745
static inline int __gthread_mutex_lock(__gthread_mutex_t *__mutex) 
# 746
{ 
# 747
if (__gthread_active_p()) { 
# 748
return __gthrw_pthread_mutex_lock(__mutex); } else { 
# 750
return 0; }  
# 751
} 
# 754
static inline int __gthread_mutex_trylock(__gthread_mutex_t *__mutex) 
# 755
{ 
# 756
if (__gthread_active_p()) { 
# 757
return __gthrw_pthread_mutex_trylock(__mutex); } else { 
# 759
return 0; }  
# 760
} 
# 764
static inline int __gthread_mutex_timedlock(__gthread_mutex_t *__mutex, const __gthread_time_t *
# 765
__abs_timeout) 
# 766
{ 
# 767
if (__gthread_active_p()) { 
# 768
return __gthrw_pthread_mutex_timedlock(__mutex, __abs_timeout); } else { 
# 770
return 0; }  
# 771
} 
# 775
static inline int __gthread_mutex_unlock(__gthread_mutex_t *__mutex) 
# 776
{ 
# 777
if (__gthread_active_p()) { 
# 778
return __gthrw_pthread_mutex_unlock(__mutex); } else { 
# 780
return 0; }  
# 781
} 
# 808
static inline int __gthread_recursive_mutex_lock(__gthread_recursive_mutex_t *__mutex) 
# 809
{ 
# 810
return __gthread_mutex_lock(__mutex); 
# 811
} 
# 814
static inline int __gthread_recursive_mutex_trylock(__gthread_recursive_mutex_t *__mutex) 
# 815
{ 
# 816
return __gthread_mutex_trylock(__mutex); 
# 817
} 
# 821
static inline int __gthread_recursive_mutex_timedlock(__gthread_recursive_mutex_t *__mutex, const __gthread_time_t *
# 822
__abs_timeout) 
# 823
{ 
# 824
return __gthread_mutex_timedlock(__mutex, __abs_timeout); 
# 825
} 
# 829
static inline int __gthread_recursive_mutex_unlock(__gthread_recursive_mutex_t *__mutex) 
# 830
{ 
# 831
return __gthread_mutex_unlock(__mutex); 
# 832
} 
# 835
static inline int __gthread_recursive_mutex_destroy(__gthread_recursive_mutex_t *__mutex) 
# 836
{ 
# 837
return __gthread_mutex_destroy(__mutex); 
# 838
} 
# 850
static inline int __gthread_cond_broadcast(__gthread_cond_t *__cond) 
# 851
{ 
# 852
return __gthrw_pthread_cond_broadcast(__cond); 
# 853
} 
# 856
static inline int __gthread_cond_signal(__gthread_cond_t *__cond) 
# 857
{ 
# 858
return __gthrw_pthread_cond_signal(__cond); 
# 859
} 
# 862
static inline int __gthread_cond_wait(__gthread_cond_t *__cond, __gthread_mutex_t *__mutex) 
# 863
{ 
# 864
return __gthrw_pthread_cond_wait(__cond, __mutex); 
# 865
} 
# 868
static inline int __gthread_cond_timedwait(__gthread_cond_t *__cond, __gthread_mutex_t *__mutex, const __gthread_time_t *
# 869
__abs_timeout) 
# 870
{ 
# 871
return __gthrw_pthread_cond_timedwait(__cond, __mutex, __abs_timeout); 
# 872
} 
# 875
static inline int __gthread_cond_wait_recursive(__gthread_cond_t *__cond, __gthread_recursive_mutex_t *
# 876
__mutex) 
# 877
{ 
# 878
return __gthread_cond_wait(__cond, __mutex); 
# 879
} 
# 882
static inline int __gthread_cond_destroy(__gthread_cond_t *__cond) 
# 883
{ 
# 884
return __gthrw_pthread_cond_destroy(__cond); 
# 885
} 
# 151 "/usr/include/c++/4.8.2/ppc64le-redhat-linux/bits/gthr.h" 3
#pragma GCC visibility pop
# 28 "/usr/include/c++/4.8.2/ppc64le-redhat-linux/bits/atomic_word.h" 3
typedef int _Atomic_word; 
# 38 "/usr/include/c++/4.8.2/ext/atomicity.h" 3
namespace __gnu_cxx __attribute((__visibility__("default"))) { 
# 48
static inline _Atomic_word __exchange_and_add(volatile _Atomic_word *__mem, int __val) 
# 49
{ return __atomic_fetch_add(__mem, __val, 4); } 
# 52
static inline void __atomic_add(volatile _Atomic_word *__mem, int __val) 
# 53
{ __atomic_fetch_add(__mem, __val, 4); } 
# 65
static inline _Atomic_word __exchange_and_add_single(_Atomic_word *__mem, int __val) 
# 66
{ 
# 67
_Atomic_word __result = *__mem; 
# 68
(*__mem) += __val; 
# 69
return __result; 
# 70
} 
# 73
static inline void __atomic_add_single(_Atomic_word *__mem, int __val) 
# 74
{ (*__mem) += __val; } 
# 77
__attribute((__unused__)) static inline _Atomic_word 
# 78
__exchange_and_add_dispatch(_Atomic_word *__mem, int __val) 
# 79
{ 
# 81
if (__gthread_active_p()) { 
# 82
return __exchange_and_add(__mem, __val); } else { 
# 84
return __exchange_and_add_single(__mem, __val); }  
# 88
} 
# 91
__attribute((__unused__)) static inline void 
# 92
__atomic_add_dispatch(_Atomic_word *__mem, int __val) 
# 93
{ 
# 95
if (__gthread_active_p()) { 
# 96
__atomic_add(__mem, __val); } else { 
# 98
__atomic_add_single(__mem, __val); }  
# 102
} 
# 105
}
# 36 "/usr/include/c++/4.8.2/bits/cxxabi_forced.h" 3
#pragma GCC visibility push ( default )
# 39
namespace __cxxabiv1 { 
# 48
class __forced_unwind { 
# 50
virtual ~__forced_unwind() throw(); 
# 53
virtual void __pure_dummy() = 0; 
# 54
}; 
# 55
}
# 58
#pragma GCC visibility pop
# 38 "/usr/include/c++/4.8.2/bits/ostream_insert.h" 3
namespace std __attribute((__visibility__("default"))) { 
# 42
template< class _CharT, class _Traits> inline void 
# 44
__ostream_write(basic_ostream< _CharT, _Traits>  &__out, const _CharT *
# 45
__s, streamsize __n) 
# 46
{ 
# 47
typedef basic_ostream< _CharT, _Traits>  __ostream_type; 
# 48
typedef typename basic_ostream< _CharT, _Traits> ::ios_base __ios_base; 
# 50
const streamsize __put = ((__out.rdbuf())->sputn(__s, __n)); 
# 51
if (__put != __n) { 
# 52
(__out.setstate(__ios_base::badbit)); }  
# 53
} 
# 55
template< class _CharT, class _Traits> inline void 
# 57
__ostream_fill(basic_ostream< _CharT, _Traits>  &__out, streamsize __n) 
# 58
{ 
# 59
typedef basic_ostream< _CharT, _Traits>  __ostream_type; 
# 60
typedef typename basic_ostream< _CharT, _Traits> ::ios_base __ios_base; 
# 62
const _CharT __c = (__out.fill()); 
# 63
for (; __n > (0); --__n) 
# 64
{ 
# 65
const typename _Traits::int_type __put = ((__out.rdbuf())->sputc(__c)); 
# 66
if (_Traits::eq_int_type(__put, _Traits::eof())) 
# 67
{ 
# 68
(__out.setstate(__ios_base::badbit)); 
# 69
break; 
# 70
}  
# 71
}  
# 72
} 
# 74
template< class _CharT, class _Traits> basic_ostream< _CharT, _Traits>  &
# 76
__ostream_insert(basic_ostream< _CharT, _Traits>  &__out, const _CharT *
# 77
__s, streamsize __n) 
# 78
{ 
# 79
typedef basic_ostream< _CharT, _Traits>  __ostream_type; 
# 80
typedef typename basic_ostream< _CharT, _Traits> ::ios_base __ios_base; 
# 82
typename basic_ostream< _CharT, _Traits> ::sentry __cerb(__out); 
# 83
if (__cerb) 
# 84
{ 
# 85
try 
# 86
{ 
# 87
const streamsize __w = (__out.width()); 
# 88
if (__w > __n) 
# 89
{ 
# 90
const bool __left = ((__out.flags()) & __ios_base::adjustfield) == __ios_base::left; 
# 93
if (!__left) { 
# 94
__ostream_fill(__out, __w - __n); }  
# 95
if ((__out.good())) { 
# 96
__ostream_write(__out, __s, __n); }  
# 97
if (__left && (__out.good())) { 
# 98
__ostream_fill(__out, __w - __n); }  
# 99
} else { 
# 101
__ostream_write(__out, __s, __n); }  
# 102
(__out.width(0)); 
# 103
} 
# 104
catch (__cxxabiv1::__forced_unwind &) 
# 105
{ 
# 106
(__out._M_setstate(__ios_base::badbit)); 
# 107
throw; 
# 108
} 
# 109
catch (...) 
# 110
{ (__out._M_setstate(__ios_base::badbit)); }  
# 111
}  
# 112
return __out; 
# 113
} 
# 118
extern template basic_ostream< char>  &__ostream_insert(basic_ostream< char>  & __out, const char * __s, streamsize __n);
# 121
extern template basic_ostream< wchar_t>  &__ostream_insert(basic_ostream< wchar_t>  & __out, const wchar_t * __s, streamsize __n);
# 127
}
# 59 "/usr/include/c++/4.8.2/bits/stl_function.h" 3
namespace std __attribute((__visibility__("default"))) { 
# 100
template< class _Arg, class _Result> 
# 101
struct unary_function { 
# 104
typedef _Arg argument_type; 
# 107
typedef _Result result_type; 
# 108
}; 
# 113
template< class _Arg1, class _Arg2, class _Result> 
# 114
struct binary_function { 
# 117
typedef _Arg1 first_argument_type; 
# 120
typedef _Arg2 second_argument_type; 
# 123
typedef _Result result_type; 
# 124
}; 
# 139
template< class _Tp> 
# 140
struct plus : public binary_function< _Tp, _Tp, _Tp>  { 
# 143
_Tp operator()(const _Tp &__x, const _Tp &__y) const 
# 144
{ return __x + __y; } 
# 145
}; 
# 148
template< class _Tp> 
# 149
struct minus : public binary_function< _Tp, _Tp, _Tp>  { 
# 152
_Tp operator()(const _Tp &__x, const _Tp &__y) const 
# 153
{ return __x - __y; } 
# 154
}; 
# 157
template< class _Tp> 
# 158
struct multiplies : public binary_function< _Tp, _Tp, _Tp>  { 
# 161
_Tp operator()(const _Tp &__x, const _Tp &__y) const 
# 162
{ return __x * __y; } 
# 163
}; 
# 166
template< class _Tp> 
# 167
struct divides : public binary_function< _Tp, _Tp, _Tp>  { 
# 170
_Tp operator()(const _Tp &__x, const _Tp &__y) const 
# 171
{ return __x / __y; } 
# 172
}; 
# 175
template< class _Tp> 
# 176
struct modulus : public binary_function< _Tp, _Tp, _Tp>  { 
# 179
_Tp operator()(const _Tp &__x, const _Tp &__y) const 
# 180
{ return __x % __y; } 
# 181
}; 
# 184
template< class _Tp> 
# 185
struct negate : public unary_function< _Tp, _Tp>  { 
# 188
_Tp operator()(const _Tp &__x) const 
# 189
{ return -__x; } 
# 190
}; 
# 203
template< class _Tp> 
# 204
struct equal_to : public binary_function< _Tp, _Tp, bool>  { 
# 207
bool operator()(const _Tp &__x, const _Tp &__y) const 
# 208
{ return __x == __y; } 
# 209
}; 
# 212
template< class _Tp> 
# 213
struct not_equal_to : public binary_function< _Tp, _Tp, bool>  { 
# 216
bool operator()(const _Tp &__x, const _Tp &__y) const 
# 217
{ return __x != __y; } 
# 218
}; 
# 221
template< class _Tp> 
# 222
struct greater : public binary_function< _Tp, _Tp, bool>  { 
# 225
bool operator()(const _Tp &__x, const _Tp &__y) const 
# 226
{ return __x > __y; } 
# 227
}; 
# 230
template< class _Tp> 
# 231
struct less : public binary_function< _Tp, _Tp, bool>  { 
# 234
bool operator()(const _Tp &__x, const _Tp &__y) const 
# 235
{ return __x < __y; } 
# 236
}; 
# 239
template< class _Tp> 
# 240
struct greater_equal : public binary_function< _Tp, _Tp, bool>  { 
# 243
bool operator()(const _Tp &__x, const _Tp &__y) const 
# 244
{ return __x >= __y; } 
# 245
}; 
# 248
template< class _Tp> 
# 249
struct less_equal : public binary_function< _Tp, _Tp, bool>  { 
# 252
bool operator()(const _Tp &__x, const _Tp &__y) const 
# 253
{ return __x <= __y; } 
# 254
}; 
# 267
template< class _Tp> 
# 268
struct logical_and : public binary_function< _Tp, _Tp, bool>  { 
# 271
bool operator()(const _Tp &__x, const _Tp &__y) const 
# 272
{ return __x && __y; } 
# 273
}; 
# 276
template< class _Tp> 
# 277
struct logical_or : public binary_function< _Tp, _Tp, bool>  { 
# 280
bool operator()(const _Tp &__x, const _Tp &__y) const 
# 281
{ return __x || __y; } 
# 282
}; 
# 285
template< class _Tp> 
# 286
struct logical_not : public unary_function< _Tp, bool>  { 
# 289
bool operator()(const _Tp &__x) const 
# 290
{ return !__x; } 
# 291
}; 
# 296
template< class _Tp> 
# 297
struct bit_and : public binary_function< _Tp, _Tp, _Tp>  { 
# 300
_Tp operator()(const _Tp &__x, const _Tp &__y) const 
# 301
{ return __x & __y; } 
# 302
}; 
# 304
template< class _Tp> 
# 305
struct bit_or : public binary_function< _Tp, _Tp, _Tp>  { 
# 308
_Tp operator()(const _Tp &__x, const _Tp &__y) const 
# 309
{ return __x | __y; } 
# 310
}; 
# 312
template< class _Tp> 
# 313
struct bit_xor : public binary_function< _Tp, _Tp, _Tp>  { 
# 316
_Tp operator()(const _Tp &__x, const _Tp &__y) const 
# 317
{ return __x ^ __y; } 
# 318
}; 
# 350
template< class _Predicate> 
# 351
class unary_negate : public unary_function< typename _Predicate::argument_type, bool>  { 
# 355
protected: _Predicate _M_pred; 
# 359
public: explicit unary_negate(const _Predicate &__x) : _M_pred(__x) { } 
# 362
bool operator()(const typename _Predicate::argument_type &__x) const 
# 363
{ return !(_M_pred)(__x); } 
# 364
}; 
# 367
template< class _Predicate> inline unary_negate< _Predicate>  
# 369
not1(const _Predicate &__pred) 
# 370
{ return ((unary_negate< _Predicate> )(__pred)); } 
# 373
template< class _Predicate> 
# 374
class binary_negate : public binary_function< typename _Predicate::first_argument_type, typename _Predicate::second_argument_type, bool>  { 
# 379
protected: _Predicate _M_pred; 
# 383
public: explicit binary_negate(const _Predicate &__x) : _M_pred(__x) { } 
# 386
bool operator()(const typename _Predicate::first_argument_type &__x, const typename _Predicate::second_argument_type &
# 387
__y) const 
# 388
{ return !(_M_pred)(__x, __y); } 
# 389
}; 
# 392
template< class _Predicate> inline binary_negate< _Predicate>  
# 394
not2(const _Predicate &__pred) 
# 395
{ return ((binary_negate< _Predicate> )(__pred)); } 
# 421
template< class _Arg, class _Result> 
# 422
class pointer_to_unary_function : public unary_function< _Arg, _Result>  { 
# 425
protected: _Result (*_M_ptr)(_Arg); 
# 428
public: pointer_to_unary_function() { } 
# 431
explicit pointer_to_unary_function(_Result (*__x)(_Arg)) : _M_ptr(__x) 
# 432
{ } 
# 435
_Result operator()(_Arg __x) const 
# 436
{ return (_M_ptr)(__x); } 
# 437
}; 
# 440
template< class _Arg, class _Result> inline pointer_to_unary_function< _Arg, _Result>  
# 442
ptr_fun(_Result (*__x)(_Arg)) 
# 443
{ return ((pointer_to_unary_function< _Arg, _Result> )(__x)); } 
# 446
template< class _Arg1, class _Arg2, class _Result> 
# 447
class pointer_to_binary_function : public binary_function< _Arg1, _Arg2, _Result>  { 
# 451
protected: _Result (*_M_ptr)(_Arg1, _Arg2); 
# 454
public: pointer_to_binary_function() { } 
# 457
explicit pointer_to_binary_function(_Result (*__x)(_Arg1, _Arg2)) : _M_ptr(__x) 
# 458
{ } 
# 461
_Result operator()(_Arg1 __x, _Arg2 __y) const 
# 462
{ return (_M_ptr)(__x, __y); } 
# 463
}; 
# 466
template< class _Arg1, class _Arg2, class _Result> inline pointer_to_binary_function< _Arg1, _Arg2, _Result>  
# 468
ptr_fun(_Result (*__x)(_Arg1, _Arg2)) 
# 469
{ return ((pointer_to_binary_function< _Arg1, _Arg2, _Result> )(__x)); } 
# 472
template< class _Tp> 
# 473
struct _Identity : public unary_function< _Tp, _Tp>  { 
# 477
_Tp &operator()(_Tp &__x) const 
# 478
{ return __x; } 
# 481
const _Tp &operator()(const _Tp &__x) const 
# 482
{ return __x; } 
# 483
}; 
# 485
template< class _Pair> 
# 486
struct _Select1st : public unary_function< _Pair, typename _Pair::first_type>  { 
# 490
typename _Pair::first_type &operator()(_Pair &__x) const 
# 491
{ return __x.first; } 
# 494
const typename _Pair::first_type &operator()(const _Pair &__x) const 
# 495
{ return __x.first; } 
# 508
}; 
# 510
template< class _Pair> 
# 511
struct _Select2nd : public unary_function< _Pair, typename _Pair::second_type>  { 
# 515
typename _Pair::second_type &operator()(_Pair &__x) const 
# 516
{ return __x.second; } 
# 519
const typename _Pair::second_type &operator()(const _Pair &__x) const 
# 520
{ return __x.second; } 
# 521
}; 
# 541
template< class _Ret, class _Tp> 
# 542
class mem_fun_t : public unary_function< _Tp *, _Ret>  { 
# 546
public: explicit mem_fun_t(_Ret (_Tp::*__pf)(void)) : _M_f(__pf) 
# 547
{ } 
# 550
_Ret operator()(_Tp *__p) const 
# 551
{ return (__p->*(_M_f))(); } 
# 554
private: _Ret (_Tp::*_M_f)(void); 
# 555
}; 
# 559
template< class _Ret, class _Tp> 
# 560
class const_mem_fun_t : public unary_function< const _Tp *, _Ret>  { 
# 564
public: explicit const_mem_fun_t(_Ret (_Tp::*__pf)(void) const) : _M_f(__pf) 
# 565
{ } 
# 568
_Ret operator()(const _Tp *__p) const 
# 569
{ return (__p->*(_M_f))(); } 
# 572
private: _Ret (_Tp::*_M_f)(void) const; 
# 573
}; 
# 577
template< class _Ret, class _Tp> 
# 578
class mem_fun_ref_t : public unary_function< _Tp, _Ret>  { 
# 582
public: explicit mem_fun_ref_t(_Ret (_Tp::*__pf)(void)) : _M_f(__pf) 
# 583
{ } 
# 586
_Ret operator()(_Tp &__r) const 
# 587
{ return (__r.*(_M_f))(); } 
# 590
private: _Ret (_Tp::*_M_f)(void); 
# 591
}; 
# 595
template< class _Ret, class _Tp> 
# 596
class const_mem_fun_ref_t : public unary_function< _Tp, _Ret>  { 
# 600
public: explicit const_mem_fun_ref_t(_Ret (_Tp::*__pf)(void) const) : _M_f(__pf) 
# 601
{ } 
# 604
_Ret operator()(const _Tp &__r) const 
# 605
{ return (__r.*(_M_f))(); } 
# 608
private: _Ret (_Tp::*_M_f)(void) const; 
# 609
}; 
# 613
template< class _Ret, class _Tp, class _Arg> 
# 614
class mem_fun1_t : public binary_function< _Tp *, _Arg, _Ret>  { 
# 618
public: explicit mem_fun1_t(_Ret (_Tp::*__pf)(_Arg)) : _M_f(__pf) 
# 619
{ } 
# 622
_Ret operator()(_Tp *__p, _Arg __x) const 
# 623
{ return (__p->*(_M_f))(__x); } 
# 626
private: _Ret (_Tp::*_M_f)(_Arg); 
# 627
}; 
# 631
template< class _Ret, class _Tp, class _Arg> 
# 632
class const_mem_fun1_t : public binary_function< const _Tp *, _Arg, _Ret>  { 
# 636
public: explicit const_mem_fun1_t(_Ret (_Tp::*__pf)(_Arg) const) : _M_f(__pf) 
# 637
{ } 
# 640
_Ret operator()(const _Tp *__p, _Arg __x) const 
# 641
{ return (__p->*(_M_f))(__x); } 
# 644
private: _Ret (_Tp::*_M_f)(_Arg) const; 
# 645
}; 
# 649
template< class _Ret, class _Tp, class _Arg> 
# 650
class mem_fun1_ref_t : public binary_function< _Tp, _Arg, _Ret>  { 
# 654
public: explicit mem_fun1_ref_t(_Ret (_Tp::*__pf)(_Arg)) : _M_f(__pf) 
# 655
{ } 
# 658
_Ret operator()(_Tp &__r, _Arg __x) const 
# 659
{ return (__r.*(_M_f))(__x); } 
# 662
private: _Ret (_Tp::*_M_f)(_Arg); 
# 663
}; 
# 667
template< class _Ret, class _Tp, class _Arg> 
# 668
class const_mem_fun1_ref_t : public binary_function< _Tp, _Arg, _Ret>  { 
# 672
public: explicit const_mem_fun1_ref_t(_Ret (_Tp::*__pf)(_Arg) const) : _M_f(__pf) 
# 673
{ } 
# 676
_Ret operator()(const _Tp &__r, _Arg __x) const 
# 677
{ return (__r.*(_M_f))(__x); } 
# 680
private: _Ret (_Tp::*_M_f)(_Arg) const; 
# 681
}; 
# 685
template< class _Ret, class _Tp> inline mem_fun_t< _Ret, _Tp>  
# 687
mem_fun(_Ret (_Tp::*__f)(void)) 
# 688
{ return ((mem_fun_t< _Ret, _Tp> )(__f)); } 
# 690
template< class _Ret, class _Tp> inline const_mem_fun_t< _Ret, _Tp>  
# 692
mem_fun(_Ret (_Tp::*__f)(void) const) 
# 693
{ return ((const_mem_fun_t< _Ret, _Tp> )(__f)); } 
# 695
template< class _Ret, class _Tp> inline mem_fun_ref_t< _Ret, _Tp>  
# 697
mem_fun_ref(_Ret (_Tp::*__f)(void)) 
# 698
{ return ((mem_fun_ref_t< _Ret, _Tp> )(__f)); } 
# 700
template< class _Ret, class _Tp> inline const_mem_fun_ref_t< _Ret, _Tp>  
# 702
mem_fun_ref(_Ret (_Tp::*__f)(void) const) 
# 703
{ return ((const_mem_fun_ref_t< _Ret, _Tp> )(__f)); } 
# 705
template< class _Ret, class _Tp, class _Arg> inline mem_fun1_t< _Ret, _Tp, _Arg>  
# 707
mem_fun(_Ret (_Tp::*__f)(_Arg)) 
# 708
{ return ((mem_fun1_t< _Ret, _Tp, _Arg> )(__f)); } 
# 710
template< class _Ret, class _Tp, class _Arg> inline const_mem_fun1_t< _Ret, _Tp, _Arg>  
# 712
mem_fun(_Ret (_Tp::*__f)(_Arg) const) 
# 713
{ return ((const_mem_fun1_t< _Ret, _Tp, _Arg> )(__f)); } 
# 715
template< class _Ret, class _Tp, class _Arg> inline mem_fun1_ref_t< _Ret, _Tp, _Arg>  
# 717
mem_fun_ref(_Ret (_Tp::*__f)(_Arg)) 
# 718
{ return ((mem_fun1_ref_t< _Ret, _Tp, _Arg> )(__f)); } 
# 720
template< class _Ret, class _Tp, class _Arg> inline const_mem_fun1_ref_t< _Ret, _Tp, _Arg>  
# 722
mem_fun_ref(_Ret (_Tp::*__f)(_Arg) const) 
# 723
{ return ((const_mem_fun1_ref_t< _Ret, _Tp, _Arg> )(__f)); } 
# 728
}
# 59 "/usr/include/c++/4.8.2/backward/binders.h" 3
namespace std __attribute((__visibility__("default"))) { 
# 103
template< class _Operation> 
# 104
class binder1st : public unary_function< typename _Operation::second_argument_type, typename _Operation::result_type>  { 
# 109
protected: _Operation op; 
# 110
typename _Operation::first_argument_type value; 
# 113
public: binder1st(const _Operation &__x, const typename _Operation::first_argument_type &
# 114
__y) : op(__x), value(__y) 
# 115
{ } 
# 118
typename _Operation::result_type operator()(const typename _Operation::second_argument_type &__x) const 
# 119
{ return (op)(value, __x); } 
# 124
typename _Operation::result_type operator()(typename _Operation::second_argument_type &__x) const 
# 125
{ return (op)(value, __x); } 
# 126
}; 
# 129
template< class _Operation, class _Tp> inline binder1st< _Operation>  
# 131
bind1st(const _Operation &__fn, const _Tp &__x) 
# 132
{ 
# 133
typedef typename _Operation::first_argument_type _Arg1_type; 
# 134
return binder1st< _Operation> (__fn, (_Arg1_type)__x); 
# 135
} 
# 138
template< class _Operation> 
# 139
class binder2nd : public unary_function< typename _Operation::first_argument_type, typename _Operation::result_type>  { 
# 144
protected: _Operation op; 
# 145
typename _Operation::second_argument_type value; 
# 148
public: binder2nd(const _Operation &__x, const typename _Operation::second_argument_type &
# 149
__y) : op(__x), value(__y) 
# 150
{ } 
# 153
typename _Operation::result_type operator()(const typename _Operation::first_argument_type &__x) const 
# 154
{ return (op)(__x, value); } 
# 159
typename _Operation::result_type operator()(typename _Operation::first_argument_type &__x) const 
# 160
{ return (op)(__x, value); } 
# 161
}; 
# 164
template< class _Operation, class _Tp> inline binder2nd< _Operation>  
# 166
bind2nd(const _Operation &__fn, const _Tp &__x) 
# 167
{ 
# 168
typedef typename _Operation::second_argument_type _Arg2_type; 
# 169
return binder2nd< _Operation> (__fn, (_Arg2_type)__x); 
# 170
} 
# 174
}
# 45 "/usr/include/c++/4.8.2/bits/basic_string.h" 3
namespace std __attribute((__visibility__("default"))) { 
# 111
template< class _CharT, class _Traits, class _Alloc> 
# 112
class basic_string { 
# 114
typedef typename _Alloc::template rebind< _CharT> ::other _CharT_alloc_type; 
# 118
public: typedef _Traits traits_type; 
# 119
typedef typename _Traits::char_type value_type; 
# 120
typedef _Alloc allocator_type; 
# 121
typedef typename _Alloc::template rebind< _CharT> ::other::size_type size_type; 
# 122
typedef typename _Alloc::template rebind< _CharT> ::other::difference_type difference_type; 
# 123
typedef typename _Alloc::template rebind< _CharT> ::other::reference reference; 
# 124
typedef typename _Alloc::template rebind< _CharT> ::other::const_reference const_reference; 
# 125
typedef typename _Alloc::template rebind< _CharT> ::other::pointer pointer; 
# 126
typedef typename _Alloc::template rebind< _CharT> ::other::const_pointer const_pointer; 
# 127
typedef __gnu_cxx::__normal_iterator< typename _Alloc::template rebind< _CharT> ::other::pointer, basic_string>  iterator; 
# 129
typedef __gnu_cxx::__normal_iterator< typename _Alloc::template rebind< _CharT> ::other::const_pointer, basic_string>  const_iterator; 
# 130
typedef std::reverse_iterator< __gnu_cxx::__normal_iterator< typename _Alloc::template rebind< _CharT> ::other::const_pointer, basic_string> >  const_reverse_iterator; 
# 131
typedef std::reverse_iterator< __gnu_cxx::__normal_iterator< typename _Alloc::template rebind< _CharT> ::other::pointer, basic_string> >  reverse_iterator; 
# 148
private: struct _Rep_base { 
# 150
size_type _M_length; 
# 151
size_type _M_capacity; 
# 152
_Atomic_word _M_refcount; 
# 153
}; 
# 155
struct _Rep : public _Rep_base { 
# 158
typedef typename _Alloc::template rebind< char> ::other _Raw_bytes_alloc; 
# 173
static const typename ::std::basic_string< _CharT, _Traits, _Alloc> ::size_type _S_max_size; 
# 174
static const _CharT _S_terminal; 
# 178
static typename ::std::basic_string< _CharT, _Traits, _Alloc> ::size_type _S_empty_rep_storage[]; 
# 181
static _Rep &_S_empty_rep() 
# 182
{ 
# 186
void *__p = (reinterpret_cast< void *>(&_S_empty_rep_storage)); 
# 187
return *(reinterpret_cast< _Rep *>(__p)); 
# 188
} 
# 191
bool _M_is_leaked() const 
# 192
{ return (this->_M_refcount) < 0; } 
# 195
bool _M_is_shared() const 
# 196
{ return (this->_M_refcount) > 0; } 
# 199
void _M_set_leaked() 
# 200
{ (this->_M_refcount) = (-1); } 
# 203
void _M_set_sharable() 
# 204
{ (this->_M_refcount) = 0; } 
# 207
void _M_set_length_and_sharable(typename ::std::basic_string< _CharT, _Traits, _Alloc> ::size_type __n) 
# 208
{ 
# 210
if (__builtin_expect(this != (&(_S_empty_rep)()), false)) 
# 212
{ 
# 213
this->_M_set_sharable(); 
# 214
(this->_M_length) = __n; 
# 215
traits_type::assign(this->_M_refdata()[__n], _S_terminal); 
# 218
}  
# 219
} 
# 222
_CharT *_M_refdata() throw() 
# 223
{ return reinterpret_cast< _CharT *>(this + 1); } 
# 226
_CharT *_M_grab(const _Alloc &__alloc1, const _Alloc &__alloc2) 
# 227
{ 
# 228
return ((!_M_is_leaked()) && (__alloc1 == __alloc2)) ? _M_refcopy() : _M_clone(__alloc1); 
# 230
} 
# 234
static _Rep *_S_create(typename ::std::basic_string< _CharT, _Traits, _Alloc> ::size_type, typename ::std::basic_string< _CharT, _Traits, _Alloc> ::size_type, const _Alloc &); 
# 237
void _M_dispose(const _Alloc &__a) 
# 238
{ 
# 240
if (__builtin_expect(this != (&(_S_empty_rep)()), false)) 
# 242
{ 
# 244
; 
# 245
if (::__gnu_cxx::__exchange_and_add_dispatch(&(this->_M_refcount), -1) <= 0) 
# 247
{ 
# 248
; 
# 249
_M_destroy(__a); 
# 250
}  
# 251
}  
# 252
} 
# 255
void _M_destroy(const _Alloc &) throw(); 
# 258
_CharT *_M_refcopy() throw() 
# 259
{ 
# 261
if (__builtin_expect(this != (&(_S_empty_rep)()), false)) { 
# 263
::__gnu_cxx::__atomic_add_dispatch(&(this->_M_refcount), 1); }  
# 264
return _M_refdata(); 
# 265
} 
# 268
_CharT *_M_clone(const _Alloc &, typename ::std::basic_string< _CharT, _Traits, _Alloc> ::size_type __res = 0); 
# 269
}; 
# 272
struct _Alloc_hider : public _Alloc { 
# 274
_Alloc_hider(_CharT *__dat, const _Alloc &__a) : _Alloc(__a), _M_p(__dat) 
# 275
{ } 
# 277
_CharT *_M_p; 
# 278
}; 
# 285
public: static const size_type npos = (static_cast< size_type>(-1)); 
# 289
private: mutable _Alloc_hider _M_dataplus; 
# 292
_CharT *_M_data() const 
# 293
{ return (_M_dataplus)._M_p; } 
# 296
_CharT *_M_data(_CharT *__p) 
# 297
{ return ((_M_dataplus)._M_p) = __p; } 
# 300
_Rep *_M_rep() const 
# 301
{ return &((reinterpret_cast< _Rep *>(_M_data()))[-1]); } 
# 306
iterator _M_ibegin() const 
# 307
{ return ((iterator)(_M_data())); } 
# 310
iterator _M_iend() const 
# 311
{ return ((iterator)(_M_data() + this->size())); } 
# 314
void _M_leak() 
# 315
{ 
# 316
if (!(_M_rep()->_M_is_leaked())) { 
# 317
_M_leak_hard(); }  
# 318
} 
# 321
size_type _M_check(size_type __pos, const char *__s) const 
# 322
{ 
# 323
if (__pos > this->size()) { 
# 324
__throw_out_of_range(__s); }  
# 325
return __pos; 
# 326
} 
# 329
void _M_check_length(size_type __n1, size_type __n2, const char *__s) const 
# 330
{ 
# 331
if ((this->max_size() - (this->size() - __n1)) < __n2) { 
# 332
__throw_length_error(__s); }  
# 333
} 
# 337
size_type _M_limit(size_type __pos, size_type __off) const 
# 338
{ 
# 339
const bool __testoff = __off < (this->size() - __pos); 
# 340
return __testoff ? __off : (this->size() - __pos); 
# 341
} 
# 345
bool _M_disjunct(const _CharT *__s) const 
# 346
{ 
# 347
return less< const _CharT *> ()(__s, _M_data()) || less< const _CharT *> ()(_M_data() + this->size(), __s); 
# 349
} 
# 354
static void _M_copy(_CharT *__d, const _CharT *__s, size_type __n) 
# 355
{ 
# 356
if (__n == 1) { 
# 357
traits_type::assign(*__d, *__s); } else { 
# 359
traits_type::copy(__d, __s, __n); }  
# 360
} 
# 363
static void _M_move(_CharT *__d, const _CharT *__s, size_type __n) 
# 364
{ 
# 365
if (__n == 1) { 
# 366
traits_type::assign(*__d, *__s); } else { 
# 368
traits_type::move(__d, __s, __n); }  
# 369
} 
# 372
static void _M_assign(_CharT *__d, size_type __n, _CharT __c) 
# 373
{ 
# 374
if (__n == 1) { 
# 375
traits_type::assign(*__d, __c); } else { 
# 377
traits_type::assign(__d, __n, __c); }  
# 378
} 
# 382
template< class _Iterator> static void 
# 384
_S_copy_chars(_CharT *__p, _Iterator __k1, _Iterator __k2) 
# 385
{ 
# 386
for (; __k1 != __k2; (++__k1), (++__p)) { 
# 387
traits_type::assign(*__p, *__k1); }  
# 388
} 
# 391
static void _S_copy_chars(_CharT *__p, iterator __k1, iterator __k2) 
# 392
{ _S_copy_chars(__p, (__k1.base()), (__k2.base())); } 
# 395
static void _S_copy_chars(_CharT *__p, const_iterator __k1, const_iterator __k2) 
# 396
{ _S_copy_chars(__p, (__k1.base()), (__k2.base())); } 
# 399
static void _S_copy_chars(_CharT *__p, _CharT *__k1, _CharT *__k2) 
# 400
{ (_M_copy)(__p, __k1, __k2 - __k1); } 
# 403
static void _S_copy_chars(_CharT *__p, const _CharT *__k1, const _CharT *__k2) 
# 404
{ (_M_copy)(__p, __k1, __k2 - __k1); } 
# 407
static int _S_compare(size_type __n1, size_type __n2) 
# 408
{ 
# 409
const difference_type __d = (difference_type)(__n1 - __n2); 
# 411
if (__d > __gnu_cxx::__numeric_traits< int> ::__max) { 
# 412
return __gnu_cxx::__numeric_traits_integer< int> ::__max; } else { 
# 413
if (__d < __gnu_cxx::__numeric_traits< int> ::__min) { 
# 414
return __gnu_cxx::__numeric_traits_integer< int> ::__min; } else { 
# 416
return (int)__d; }  }  
# 417
} 
# 420
void _M_mutate(size_type __pos, size_type __len1, size_type __len2); 
# 423
void _M_leak_hard(); 
# 426
static _Rep &_S_empty_rep() 
# 427
{ return _Rep::_S_empty_rep(); } 
# 437
public: basic_string() : _M_dataplus(((_S_empty_rep)()._M_refdata()), _Alloc()) 
# 439
{ } 
# 448
explicit basic_string(const _Alloc & __a); 
# 455
basic_string(const basic_string & __str); 
# 462
basic_string(const basic_string & __str, size_type __pos, size_type __n = npos); 
# 471
basic_string(const basic_string & __str, size_type __pos, size_type __n, const _Alloc & __a); 
# 483
basic_string(const _CharT * __s, size_type __n, const _Alloc & __a = _Alloc()); 
# 490
basic_string(const _CharT * __s, const _Alloc & __a = _Alloc()); 
# 497
basic_string(size_type __n, _CharT __c, const _Alloc & __a = _Alloc()); 
# 531
template< class _InputIterator> basic_string(_InputIterator __beg, _InputIterator __end, const _Alloc & __a = _Alloc()); 
# 538
~basic_string() 
# 539
{ (_M_rep()->_M_dispose(this->get_allocator())); } 
# 546
basic_string &operator=(const basic_string &__str) 
# 547
{ return (this->assign(__str)); } 
# 554
basic_string &operator=(const _CharT *__s) 
# 555
{ return (this->assign(__s)); } 
# 565
basic_string &operator=(_CharT __c) 
# 566
{ 
# 567
(this->assign(1, __c)); 
# 568
return *this; 
# 569
} 
# 605
iterator begin() 
# 606
{ 
# 607
_M_leak(); 
# 608
return ((iterator)(_M_data())); 
# 609
} 
# 616
const_iterator begin() const 
# 617
{ return ((const_iterator)(_M_data())); } 
# 624
iterator end() 
# 625
{ 
# 626
_M_leak(); 
# 627
return ((iterator)(_M_data() + this->size())); 
# 628
} 
# 635
const_iterator end() const 
# 636
{ return ((const_iterator)(_M_data() + this->size())); } 
# 644
reverse_iterator rbegin() 
# 645
{ return ((reverse_iterator)(this->end())); } 
# 653
const_reverse_iterator rbegin() const 
# 654
{ return ((const_reverse_iterator)(this->end())); } 
# 662
reverse_iterator rend() 
# 663
{ return ((reverse_iterator)(this->begin())); } 
# 671
const_reverse_iterator rend() const 
# 672
{ return ((const_reverse_iterator)(this->begin())); } 
# 715
size_type size() const 
# 716
{ return _M_rep()->_M_length; } 
# 721
size_type length() const 
# 722
{ return _M_rep()->_M_length; } 
# 726
size_type max_size() const 
# 727
{ return _Rep::_S_max_size; } 
# 740
void resize(size_type __n, _CharT __c); 
# 753
void resize(size_type __n) 
# 754
{ (this->resize(__n, _CharT())); } 
# 776
size_type capacity() const 
# 777
{ return _M_rep()->_M_capacity; } 
# 797
void reserve(size_type __res_arg = 0); 
# 803
void clear() 
# 804
{ _M_mutate(0, this->size(), 0); } 
# 811
bool empty() const 
# 812
{ return this->size() == 0; } 
# 826
const_reference operator[](size_type __pos) const 
# 827
{ 
# 828
; 
# 829
return _M_data()[__pos]; 
# 830
} 
# 843
reference operator[](size_type __pos) 
# 844
{ 
# 846
; 
# 848
; 
# 849
_M_leak(); 
# 850
return _M_data()[__pos]; 
# 851
} 
# 864
const_reference at(size_type __n) const 
# 865
{ 
# 866
if (__n >= this->size()) { 
# 867
__throw_out_of_range("basic_string::at"); }  
# 868
return _M_data()[__n]; 
# 869
} 
# 883
reference at(size_type __n) 
# 884
{ 
# 885
if (__n >= size()) { 
# 886
__throw_out_of_range("basic_string::at"); }  
# 887
_M_leak(); 
# 888
return _M_data()[__n]; 
# 889
} 
# 932
basic_string &operator+=(const basic_string &__str) 
# 933
{ return (this->append(__str)); } 
# 941
basic_string &operator+=(const _CharT *__s) 
# 942
{ return (this->append(__s)); } 
# 950
basic_string &operator+=(_CharT __c) 
# 951
{ 
# 952
this->push_back(__c); 
# 953
return *this; 
# 954
} 
# 973
basic_string &append(const basic_string & __str); 
# 989
basic_string &append(const basic_string & __str, size_type __pos, size_type __n); 
# 998
basic_string &append(const _CharT * __s, size_type __n); 
# 1006
basic_string &append(const _CharT *__s) 
# 1007
{ 
# 1008
; 
# 1009
return (this->append(__s, traits_type::length(__s))); 
# 1010
} 
# 1021
basic_string &append(size_type __n, _CharT __c); 
# 1042
template< class _InputIterator> basic_string &
# 1044
append(_InputIterator __first, _InputIterator __last) 
# 1045
{ return (this->replace(_M_iend(), _M_iend(), __first, __last)); } 
# 1052
void push_back(_CharT __c) 
# 1053
{ 
# 1054
const size_type __len = 1 + this->size(); 
# 1055
if ((__len > this->capacity()) || (_M_rep()->_M_is_shared())) { 
# 1056
this->reserve(__len); }  
# 1057
traits_type::assign(_M_data()[this->size()], __c); 
# 1058
(_M_rep()->_M_set_length_and_sharable(__len)); 
# 1059
} 
# 1067
basic_string &assign(const basic_string & __str); 
# 1100
basic_string &assign(const basic_string &__str, size_type __pos, size_type __n) 
# 1101
{ return (this->assign((__str._M_data()) + __str._M_check(__pos, "basic_string::assign"), __str._M_limit(__pos, __n))); 
# 1103
} 
# 1116
basic_string &assign(const _CharT * __s, size_type __n); 
# 1128
basic_string &assign(const _CharT *__s) 
# 1129
{ 
# 1130
; 
# 1131
return (this->assign(__s, traits_type::length(__s))); 
# 1132
} 
# 1144
basic_string &assign(size_type __n, _CharT __c) 
# 1145
{ return _M_replace_aux((size_type)0, this->size(), __n, __c); } 
# 1155
template< class _InputIterator> basic_string &
# 1157
assign(_InputIterator __first, _InputIterator __last) 
# 1158
{ return (this->replace(_M_ibegin(), _M_iend(), __first, __last)); } 
# 1185
void insert(iterator __p, size_type __n, _CharT __c) 
# 1186
{ (this->replace(__p, __p, __n, __c)); } 
# 1200
template< class _InputIterator> void 
# 1202
insert(iterator __p, _InputIterator __beg, _InputIterator __end) 
# 1203
{ (this->replace(__p, __p, __beg, __end)); } 
# 1233
basic_string &insert(size_type __pos1, const basic_string &__str) 
# 1234
{ return (this->insert(__pos1, __str, (size_type)0, __str.size())); } 
# 1255
basic_string &insert(size_type __pos1, const basic_string &__str, size_type 
# 1256
__pos2, size_type __n) 
# 1257
{ return (this->insert(__pos1, (__str._M_data()) + __str._M_check(__pos2, "basic_string::insert"), __str._M_limit(__pos2, __n))); 
# 1259
} 
# 1278
basic_string &insert(size_type __pos, const _CharT * __s, size_type __n); 
# 1296
basic_string &insert(size_type __pos, const _CharT *__s) 
# 1297
{ 
# 1298
; 
# 1299
return (this->insert(__pos, __s, traits_type::length(__s))); 
# 1300
} 
# 1319
basic_string &insert(size_type __pos, size_type __n, _CharT __c) 
# 1320
{ return _M_replace_aux(_M_check(__pos, "basic_string::insert"), (size_type)0, __n, __c); 
# 1321
} 
# 1337
iterator insert(iterator __p, _CharT __c) 
# 1338
{ 
# 1339
; 
# 1340
const size_type __pos = __p - _M_ibegin(); 
# 1341
_M_replace_aux(__pos, (size_type)0, (size_type)1, __c); 
# 1342
(_M_rep()->_M_set_leaked()); 
# 1343
return ((iterator)(_M_data() + __pos)); 
# 1344
} 
# 1362
basic_string &erase(size_type __pos = 0, size_type __n = npos) 
# 1363
{ 
# 1364
_M_mutate(_M_check(__pos, "basic_string::erase"), _M_limit(__pos, __n), (size_type)0); 
# 1366
return *this; 
# 1367
} 
# 1378
iterator erase(iterator __position) 
# 1379
{ 
# 1381
; 
# 1382
const size_type __pos = __position - _M_ibegin(); 
# 1383
_M_mutate(__pos, (size_type)1, (size_type)0); 
# 1384
(_M_rep()->_M_set_leaked()); 
# 1385
return ((iterator)(_M_data() + __pos)); 
# 1386
} 
# 1398
iterator erase(iterator __first, iterator __last); 
# 1429
basic_string &replace(size_type __pos, size_type __n, const basic_string &__str) 
# 1430
{ return (this->replace(__pos, __n, (__str._M_data()), __str.size())); } 
# 1451
basic_string &replace(size_type __pos1, size_type __n1, const basic_string &__str, size_type 
# 1452
__pos2, size_type __n2) 
# 1453
{ return (this->replace(__pos1, __n1, (__str._M_data()) + __str._M_check(__pos2, "basic_string::replace"), __str._M_limit(__pos2, __n2))); 
# 1455
} 
# 1476
basic_string &replace(size_type __pos, size_type __n1, const _CharT * __s, size_type __n2); 
# 1496
basic_string &replace(size_type __pos, size_type __n1, const _CharT *__s) 
# 1497
{ 
# 1498
; 
# 1499
return (this->replace(__pos, __n1, __s, traits_type::length(__s))); 
# 1500
} 
# 1520
basic_string &replace(size_type __pos, size_type __n1, size_type __n2, _CharT __c) 
# 1521
{ return _M_replace_aux(_M_check(__pos, "basic_string::replace"), _M_limit(__pos, __n1), __n2, __c); 
# 1522
} 
# 1538
basic_string &replace(iterator __i1, iterator __i2, const basic_string &__str) 
# 1539
{ return (this->replace(__i1, __i2, (__str._M_data()), __str.size())); } 
# 1557
basic_string &replace(iterator __i1, iterator __i2, const _CharT *__s, size_type __n) 
# 1558
{ 
# 1560
; 
# 1561
return (this->replace(__i1 - _M_ibegin(), __i2 - __i1, __s, __n)); 
# 1562
} 
# 1578
basic_string &replace(iterator __i1, iterator __i2, const _CharT *__s) 
# 1579
{ 
# 1580
; 
# 1581
return (this->replace(__i1, __i2, __s, traits_type::length(__s))); 
# 1582
} 
# 1599
basic_string &replace(iterator __i1, iterator __i2, size_type __n, _CharT __c) 
# 1600
{ 
# 1602
; 
# 1603
return _M_replace_aux(__i1 - _M_ibegin(), __i2 - __i1, __n, __c); 
# 1604
} 
# 1621
template< class _InputIterator> basic_string &
# 1623
replace(iterator __i1, iterator __i2, _InputIterator 
# 1624
__k1, _InputIterator __k2) 
# 1625
{ 
# 1627
; 
# 1628
; 
# 1629
typedef typename __is_integer< _InputIterator> ::__type _Integral; 
# 1630
return _M_replace_dispatch(__i1, __i2, __k1, __k2, _Integral()); 
# 1631
} 
# 1636
basic_string &replace(iterator __i1, iterator __i2, _CharT *__k1, _CharT *__k2) 
# 1637
{ 
# 1639
; 
# 1640
; 
# 1641
return (this->replace(__i1 - _M_ibegin(), __i2 - __i1, __k1, __k2 - __k1)); 
# 1643
} 
# 1646
basic_string &replace(iterator __i1, iterator __i2, const _CharT *
# 1647
__k1, const _CharT *__k2) 
# 1648
{ 
# 1650
; 
# 1651
; 
# 1652
return (this->replace(__i1 - _M_ibegin(), __i2 - __i1, __k1, __k2 - __k1)); 
# 1654
} 
# 1657
basic_string &replace(iterator __i1, iterator __i2, iterator __k1, iterator __k2) 
# 1658
{ 
# 1660
; 
# 1661
; 
# 1662
return (this->replace(__i1 - _M_ibegin(), __i2 - __i1, (__k1.base()), __k2 - __k1)); 
# 1664
} 
# 1667
basic_string &replace(iterator __i1, iterator __i2, const_iterator 
# 1668
__k1, const_iterator __k2) 
# 1669
{ 
# 1671
; 
# 1672
; 
# 1673
return (this->replace(__i1 - _M_ibegin(), __i2 - __i1, (__k1.base()), __k2 - __k1)); 
# 1675
} 
# 1700
private: 
# 1698
template< class _Integer> basic_string &
# 1700
_M_replace_dispatch(iterator __i1, iterator __i2, _Integer __n, _Integer 
# 1701
__val, __true_type) 
# 1702
{ return _M_replace_aux(__i1 - _M_ibegin(), __i2 - __i1, __n, __val); } 
# 1704
template< class _InputIterator> basic_string &_M_replace_dispatch(iterator __i1, iterator __i2, _InputIterator __k1, _InputIterator __k2, __false_type); 
# 1710
basic_string &_M_replace_aux(size_type __pos1, size_type __n1, size_type __n2, _CharT __c); 
# 1714
basic_string &_M_replace_safe(size_type __pos1, size_type __n1, const _CharT * __s, size_type __n2); 
# 1719
template< class _InIterator> static _CharT *
# 1721
_S_construct_aux(_InIterator __beg, _InIterator __end, const _Alloc &
# 1722
__a, __false_type) 
# 1723
{ 
# 1724
typedef typename iterator_traits< _InIterator> ::iterator_category _Tag; 
# 1725
return _S_construct(__beg, __end, __a, _Tag()); 
# 1726
} 
# 1730
template< class _Integer> static _CharT *
# 1732
_S_construct_aux(_Integer __beg, _Integer __end, const _Alloc &
# 1733
__a, __true_type) 
# 1734
{ return (_S_construct_aux_2)(static_cast< size_type>(__beg), __end, __a); 
# 1735
} 
# 1738
static _CharT *_S_construct_aux_2(size_type __req, _CharT __c, const _Alloc &__a) 
# 1739
{ return _S_construct(__req, __c, __a); } 
# 1741
template< class _InIterator> static _CharT *
# 1743
_S_construct(_InIterator __beg, _InIterator __end, const _Alloc &__a) 
# 1744
{ 
# 1745
typedef typename __is_integer< _InIterator> ::__type _Integral; 
# 1746
return _S_construct_aux(__beg, __end, __a, _Integral()); 
# 1747
} 
# 1750
template< class _InIterator> static _CharT *_S_construct(_InIterator __beg, _InIterator __end, const _Alloc & __a, input_iterator_tag); 
# 1757
template< class _FwdIterator> static _CharT *_S_construct(_FwdIterator __beg, _FwdIterator __end, const _Alloc & __a, forward_iterator_tag); 
# 1763
static _CharT *_S_construct(size_type __req, _CharT __c, const _Alloc & __a); 
# 1780
public: size_type copy(_CharT * __s, size_type __n, size_type __pos = 0) const; 
# 1790
void swap(basic_string & __s); 
# 1800
const _CharT *c_str() const 
# 1801
{ return _M_data(); } 
# 1810
const _CharT *data() const 
# 1811
{ return _M_data(); } 
# 1817
allocator_type get_allocator() const 
# 1818
{ return _M_dataplus; } 
# 1833
size_type find(const _CharT * __s, size_type __pos, size_type __n) const; 
# 1846
size_type find(const basic_string &__str, size_type __pos = 0) const 
# 1848
{ return (this->find(__str.data(), __pos, __str.size())); } 
# 1861
size_type find(const _CharT *__s, size_type __pos = 0) const 
# 1862
{ 
# 1863
; 
# 1864
return (this->find(__s, __pos, traits_type::length(__s))); 
# 1865
} 
# 1878
size_type find(_CharT __c, size_type __pos = 0) const; 
# 1891
size_type rfind(const basic_string &__str, size_type __pos = npos) const 
# 1893
{ return (this->rfind(__str.data(), __pos, __str.size())); } 
# 1908
size_type rfind(const _CharT * __s, size_type __pos, size_type __n) const; 
# 1921
size_type rfind(const _CharT *__s, size_type __pos = npos) const 
# 1922
{ 
# 1923
; 
# 1924
return (this->rfind(__s, __pos, traits_type::length(__s))); 
# 1925
} 
# 1938
size_type rfind(_CharT __c, size_type __pos = npos) const; 
# 1952
size_type find_first_of(const basic_string &__str, size_type __pos = 0) const 
# 1954
{ return (this->find_first_of(__str.data(), __pos, __str.size())); } 
# 1969
size_type find_first_of(const _CharT * __s, size_type __pos, size_type __n) const; 
# 1982
size_type find_first_of(const _CharT *__s, size_type __pos = 0) const 
# 1983
{ 
# 1984
; 
# 1985
return (this->find_first_of(__s, __pos, traits_type::length(__s))); 
# 1986
} 
# 2001
size_type find_first_of(_CharT __c, size_type __pos = 0) const 
# 2002
{ return (this->find(__c, __pos)); } 
# 2016
size_type find_last_of(const basic_string &__str, size_type __pos = npos) const 
# 2018
{ return (this->find_last_of(__str.data(), __pos, __str.size())); } 
# 2033
size_type find_last_of(const _CharT * __s, size_type __pos, size_type __n) const; 
# 2046
size_type find_last_of(const _CharT *__s, size_type __pos = npos) const 
# 2047
{ 
# 2048
; 
# 2049
return (this->find_last_of(__s, __pos, traits_type::length(__s))); 
# 2050
} 
# 2065
size_type find_last_of(_CharT __c, size_type __pos = npos) const 
# 2066
{ return (this->rfind(__c, __pos)); } 
# 2079
size_type find_first_not_of(const basic_string &__str, size_type __pos = 0) const 
# 2081
{ return (this->find_first_not_of(__str.data(), __pos, __str.size())); } 
# 2096
size_type find_first_not_of(const _CharT * __s, size_type __pos, size_type __n) const; 
# 2110
size_type find_first_not_of(const _CharT *__s, size_type __pos = 0) const 
# 2111
{ 
# 2112
; 
# 2113
return (this->find_first_not_of(__s, __pos, traits_type::length(__s))); 
# 2114
} 
# 2127
size_type find_first_not_of(_CharT __c, size_type __pos = 0) const; 
# 2142
size_type find_last_not_of(const basic_string &__str, size_type __pos = npos) const 
# 2144
{ return (this->find_last_not_of(__str.data(), __pos, __str.size())); } 
# 2159
size_type find_last_not_of(const _CharT * __s, size_type __pos, size_type __n) const; 
# 2173
size_type find_last_not_of(const _CharT *__s, size_type __pos = npos) const 
# 2174
{ 
# 2175
; 
# 2176
return (this->find_last_not_of(__s, __pos, traits_type::length(__s))); 
# 2177
} 
# 2190
size_type find_last_not_of(_CharT __c, size_type __pos = npos) const; 
# 2206
basic_string substr(size_type __pos = 0, size_type __n = npos) const 
# 2207
{ return basic_string(*this, _M_check(__pos, "basic_string::substr"), __n); 
# 2208
} 
# 2225
int compare(const basic_string &__str) const 
# 2226
{ 
# 2227
const size_type __size = this->size(); 
# 2228
const size_type __osize = __str.size(); 
# 2229
const size_type __len = std::min(__size, __osize); 
# 2231
int __r = traits_type::compare(_M_data(), __str.data(), __len); 
# 2232
if (!__r) { 
# 2233
__r = (_S_compare)(__size, __osize); }  
# 2234
return __r; 
# 2235
} 
# 2257
int compare(size_type __pos, size_type __n, const basic_string & __str) const; 
# 2283
int compare(size_type __pos1, size_type __n1, const basic_string & __str, size_type __pos2, size_type __n2) const; 
# 2301
int compare(const _CharT * __s) const; 
# 2325
int compare(size_type __pos, size_type __n1, const _CharT * __s) const; 
# 2352
int compare(size_type __pos, size_type __n1, const _CharT * __s, size_type __n2) const; 
# 2354
}; 
# 2363
template< class _CharT, class _Traits, class _Alloc> basic_string< _CharT, _Traits, _Alloc>  
# 2365
operator+(const basic_string< _CharT, _Traits, _Alloc>  &__lhs, const basic_string< _CharT, _Traits, _Alloc>  &
# 2366
__rhs) 
# 2367
{ 
# 2368
basic_string< _CharT, _Traits, _Alloc>  __str(__lhs); 
# 2369
(__str.append(__rhs)); 
# 2370
return __str; 
# 2371
} 
# 2379
template< class _CharT, class _Traits, class _Alloc> basic_string< _CharT, _Traits, _Alloc>  operator+(const _CharT * __lhs, const basic_string< _CharT, _Traits, _Alloc>  & __rhs); 
# 2390
template< class _CharT, class _Traits, class _Alloc> basic_string< _CharT, _Traits, _Alloc>  operator+(_CharT __lhs, const basic_string< _CharT, _Traits, _Alloc>  & __rhs); 
# 2400
template< class _CharT, class _Traits, class _Alloc> inline basic_string< _CharT, _Traits, _Alloc>  
# 2402
operator+(const basic_string< _CharT, _Traits, _Alloc>  &__lhs, const _CharT *
# 2403
__rhs) 
# 2404
{ 
# 2405
basic_string< _CharT, _Traits, _Alloc>  __str(__lhs); 
# 2406
(__str.append(__rhs)); 
# 2407
return __str; 
# 2408
} 
# 2416
template< class _CharT, class _Traits, class _Alloc> inline basic_string< _CharT, _Traits, _Alloc>  
# 2418
operator+(const basic_string< _CharT, _Traits, _Alloc>  &__lhs, _CharT __rhs) 
# 2419
{ 
# 2420
typedef basic_string< _CharT, _Traits, _Alloc>  __string_type; 
# 2421
typedef typename basic_string< _CharT, _Traits, _Alloc> ::size_type __size_type; 
# 2422
__string_type __str(__lhs); 
# 2423
(__str.append((__size_type)1, __rhs)); 
# 2424
return __str; 
# 2425
} 
# 2484
template< class _CharT, class _Traits, class _Alloc> inline bool 
# 2486
operator==(const basic_string< _CharT, _Traits, _Alloc>  &__lhs, const basic_string< _CharT, _Traits, _Alloc>  &
# 2487
__rhs) 
# 2488
{ return (__lhs.compare(__rhs)) == 0; } 
# 2490
template< class _CharT> inline typename __gnu_cxx::__enable_if< __is_char< _CharT> ::__value, bool> ::__type 
# 2493
operator==(const basic_string< _CharT, char_traits< _CharT> , allocator< _CharT> >  &__lhs, const basic_string< _CharT, char_traits< _CharT> , allocator< _CharT> >  &
# 2494
__rhs) 
# 2495
{ return ((__lhs.size()) == (__rhs.size())) && (!std::char_traits< _CharT> ::compare((__lhs.data()), (__rhs.data()), (__lhs.size()))); 
# 2497
} 
# 2505
template< class _CharT, class _Traits, class _Alloc> inline bool 
# 2507
operator==(const _CharT *__lhs, const basic_string< _CharT, _Traits, _Alloc>  &
# 2508
__rhs) 
# 2509
{ return (__rhs.compare(__lhs)) == 0; } 
# 2517
template< class _CharT, class _Traits, class _Alloc> inline bool 
# 2519
operator==(const basic_string< _CharT, _Traits, _Alloc>  &__lhs, const _CharT *
# 2520
__rhs) 
# 2521
{ return (__lhs.compare(__rhs)) == 0; } 
# 2530
template< class _CharT, class _Traits, class _Alloc> inline bool 
# 2532
operator!=(const basic_string< _CharT, _Traits, _Alloc>  &__lhs, const basic_string< _CharT, _Traits, _Alloc>  &
# 2533
__rhs) 
# 2534
{ return !(__lhs == __rhs); } 
# 2542
template< class _CharT, class _Traits, class _Alloc> inline bool 
# 2544
operator!=(const _CharT *__lhs, const basic_string< _CharT, _Traits, _Alloc>  &
# 2545
__rhs) 
# 2546
{ return !(__lhs == __rhs); } 
# 2554
template< class _CharT, class _Traits, class _Alloc> inline bool 
# 2556
operator!=(const basic_string< _CharT, _Traits, _Alloc>  &__lhs, const _CharT *
# 2557
__rhs) 
# 2558
{ return !(__lhs == __rhs); } 
# 2567
template< class _CharT, class _Traits, class _Alloc> inline bool 
# 2569
operator<(const basic_string< _CharT, _Traits, _Alloc>  &__lhs, const basic_string< _CharT, _Traits, _Alloc>  &
# 2570
__rhs) 
# 2571
{ return (__lhs.compare(__rhs)) < 0; } 
# 2579
template< class _CharT, class _Traits, class _Alloc> inline bool 
# 2581
operator<(const basic_string< _CharT, _Traits, _Alloc>  &__lhs, const _CharT *
# 2582
__rhs) 
# 2583
{ return (__lhs.compare(__rhs)) < 0; } 
# 2591
template< class _CharT, class _Traits, class _Alloc> inline bool 
# 2593
operator<(const _CharT *__lhs, const basic_string< _CharT, _Traits, _Alloc>  &
# 2594
__rhs) 
# 2595
{ return (__rhs.compare(__lhs)) > 0; } 
# 2604
template< class _CharT, class _Traits, class _Alloc> inline bool 
# 2606
operator>(const basic_string< _CharT, _Traits, _Alloc>  &__lhs, const basic_string< _CharT, _Traits, _Alloc>  &
# 2607
__rhs) 
# 2608
{ return (__lhs.compare(__rhs)) > 0; } 
# 2616
template< class _CharT, class _Traits, class _Alloc> inline bool 
# 2618
operator>(const basic_string< _CharT, _Traits, _Alloc>  &__lhs, const _CharT *
# 2619
__rhs) 
# 2620
{ return (__lhs.compare(__rhs)) > 0; } 
# 2628
template< class _CharT, class _Traits, class _Alloc> inline bool 
# 2630
operator>(const _CharT *__lhs, const basic_string< _CharT, _Traits, _Alloc>  &
# 2631
__rhs) 
# 2632
{ return (__rhs.compare(__lhs)) < 0; } 
# 2641
template< class _CharT, class _Traits, class _Alloc> inline bool 
# 2643
operator<=(const basic_string< _CharT, _Traits, _Alloc>  &__lhs, const basic_string< _CharT, _Traits, _Alloc>  &
# 2644
__rhs) 
# 2645
{ return (__lhs.compare(__rhs)) <= 0; } 
# 2653
template< class _CharT, class _Traits, class _Alloc> inline bool 
# 2655
operator<=(const basic_string< _CharT, _Traits, _Alloc>  &__lhs, const _CharT *
# 2656
__rhs) 
# 2657
{ return (__lhs.compare(__rhs)) <= 0; } 
# 2665
template< class _CharT, class _Traits, class _Alloc> inline bool 
# 2667
operator<=(const _CharT *__lhs, const basic_string< _CharT, _Traits, _Alloc>  &
# 2668
__rhs) 
# 2669
{ return (__rhs.compare(__lhs)) >= 0; } 
# 2678
template< class _CharT, class _Traits, class _Alloc> inline bool 
# 2680
operator>=(const basic_string< _CharT, _Traits, _Alloc>  &__lhs, const basic_string< _CharT, _Traits, _Alloc>  &
# 2681
__rhs) 
# 2682
{ return (__lhs.compare(__rhs)) >= 0; } 
# 2690
template< class _CharT, class _Traits, class _Alloc> inline bool 
# 2692
operator>=(const basic_string< _CharT, _Traits, _Alloc>  &__lhs, const _CharT *
# 2693
__rhs) 
# 2694
{ return (__lhs.compare(__rhs)) >= 0; } 
# 2702
template< class _CharT, class _Traits, class _Alloc> inline bool 
# 2704
operator>=(const _CharT *__lhs, const basic_string< _CharT, _Traits, _Alloc>  &
# 2705
__rhs) 
# 2706
{ return (__rhs.compare(__lhs)) <= 0; } 
# 2715
template< class _CharT, class _Traits, class _Alloc> inline void 
# 2717
swap(basic_string< _CharT, _Traits, _Alloc>  &__lhs, basic_string< _CharT, _Traits, _Alloc>  &
# 2718
__rhs) 
# 2719
{ (__lhs.swap(__rhs)); } 
# 2733
template< class _CharT, class _Traits, class _Alloc> basic_istream< _CharT, _Traits>  &operator>>(basic_istream< _CharT, _Traits>  & __is, basic_string< _CharT, _Traits, _Alloc>  & __str); 
# 2740
template<> basic_istream< char>  &operator>>(basic_istream< char>  & __is, basic_string< char, char_traits< char> , allocator< char> >  & __str); 
# 2751
template< class _CharT, class _Traits, class _Alloc> inline basic_ostream< _CharT, _Traits>  &
# 2753
operator<<(basic_ostream< _CharT, _Traits>  &__os, const basic_string< _CharT, _Traits, _Alloc>  &
# 2754
__str) 
# 2755
{ 
# 2758
return __ostream_insert(__os, (__str.data()), (__str.size())); 
# 2759
} 
# 2774
template< class _CharT, class _Traits, class _Alloc> basic_istream< _CharT, _Traits>  &getline(basic_istream< _CharT, _Traits>  & __is, basic_string< _CharT, _Traits, _Alloc>  & __str, _CharT __delim); 
# 2791
template< class _CharT, class _Traits, class _Alloc> inline basic_istream< _CharT, _Traits>  &
# 2793
getline(basic_istream< _CharT, _Traits>  &__is, basic_string< _CharT, _Traits, _Alloc>  &
# 2794
__str) 
# 2795
{ return getline(__is, __str, (__is.widen('\n'))); } 
# 2799
template<> basic_istream< char>  &getline(basic_istream< char>  & __in, basic_string< char, char_traits< char> , allocator< char> >  & __str, char __delim); 
# 2805
template<> basic_istream< wchar_t>  &getline(basic_istream< wchar_t>  & __in, basic_string< wchar_t, char_traits< wchar_t> , allocator< wchar_t> >  & __str, wchar_t __delim); 
# 2810
}
# 44 "/usr/include/c++/4.8.2/bits/basic_string.tcc" 3
namespace std __attribute((__visibility__("default"))) { 
# 48
template< class _CharT, class _Traits, class _Alloc> const typename basic_string< _CharT, _Traits, _Alloc> ::size_type 
# 51
basic_string< _CharT, _Traits, _Alloc> ::_Rep::_S_max_size = (((npos - sizeof(typename ::std::basic_string< _CharT, _Traits, _Alloc> ::_Rep_base)) / sizeof(_CharT)) - 1) / 4; 
# 53
template< class _CharT, class _Traits, class _Alloc> const _CharT 
# 56
basic_string< _CharT, _Traits, _Alloc> ::_Rep::_S_terminal = (_CharT()); 
# 58
template< class _CharT, class _Traits, class _Alloc> const typename basic_string< _CharT, _Traits, _Alloc> ::size_type 
# 60
basic_string< _CharT, _Traits, _Alloc> ::npos; 
# 64
template< class _CharT, class _Traits, class _Alloc> typename basic_string< _CharT, _Traits, _Alloc> ::size_type 
# 66
basic_string< _CharT, _Traits, _Alloc> ::_Rep::_S_empty_rep_storage[(((sizeof(typename ::std::basic_string< _CharT, _Traits, _Alloc> ::_Rep_base) + sizeof(_CharT)) + sizeof(typename ::std::basic_string< _CharT, _Traits, _Alloc> ::size_type)) - (1)) / sizeof(typename ::std::basic_string< _CharT, _Traits, _Alloc> ::size_type)]; 
# 74
template< class _CharT, class _Traits, class _Alloc> 
# 75
template< class _InIterator> _CharT *
# 78
basic_string< _CharT, _Traits, _Alloc> ::_S_construct(_InIterator __beg, _InIterator __end, const _Alloc &__a, input_iterator_tag) 
# 80
{ 
# 82
if ((__beg == __end) && (__a == _Alloc())) { 
# 83
return ((_S_empty_rep)()._M_refdata()); }  
# 86
_CharT __buf[128]; 
# 87
size_type __len = (0); 
# 88
while ((__beg != __end) && (__len < (sizeof(__buf) / sizeof(_CharT)))) 
# 89
{ 
# 90
(__buf[__len++]) = (*__beg); 
# 91
++__beg; 
# 92
}  
# 93
_Rep *__r = _Rep::_S_create(__len, (size_type)0, __a); 
# 94
(_M_copy)((__r->_M_refdata()), __buf, __len); 
# 95
try 
# 96
{ 
# 97
while (__beg != __end) 
# 98
{ 
# 99
if (__len == (__r->_M_capacity)) 
# 100
{ 
# 102
_Rep *__another = _Rep::_S_create(__len + 1, __len, __a); 
# 103
(_M_copy)((__another->_M_refdata()), (__r->_M_refdata()), __len); 
# 104
(__r->_M_destroy(__a)); 
# 105
__r = __another; 
# 106
}  
# 107
((__r->_M_refdata())[__len++]) = (*__beg); 
# 108
++__beg; 
# 109
}  
# 110
} 
# 111
catch (...) 
# 112
{ 
# 113
(__r->_M_destroy(__a)); 
# 114
throw; 
# 115
}  
# 116
(__r->_M_set_length_and_sharable(__len)); 
# 117
return (__r->_M_refdata()); 
# 118
} 
# 120
template< class _CharT, class _Traits, class _Alloc> 
# 121
template< class _InIterator> _CharT *
# 124
basic_string< _CharT, _Traits, _Alloc> ::_S_construct(_InIterator __beg, _InIterator __end, const _Alloc &__a, forward_iterator_tag) 
# 126
{ 
# 128
if ((__beg == __end) && (__a == _Alloc())) { 
# 129
return ((_S_empty_rep)()._M_refdata()); }  
# 132
if (__gnu_cxx::__is_null_pointer(__beg) && (__beg != __end)) { 
# 133
__throw_logic_error("basic_string::_S_construct null not valid"); }  
# 135
const size_type __dnew = static_cast< size_type>(std::distance(__beg, __end)); 
# 138
_Rep *__r = _Rep::_S_create(__dnew, (size_type)0, __a); 
# 139
try 
# 140
{ _S_copy_chars((__r->_M_refdata()), __beg, __end); } 
# 141
catch (...) 
# 142
{ 
# 143
(__r->_M_destroy(__a)); 
# 144
throw; 
# 145
}  
# 146
(__r->_M_set_length_and_sharable(__dnew)); 
# 147
return (__r->_M_refdata()); 
# 148
} 
# 150
template< class _CharT, class _Traits, class _Alloc> _CharT *
# 153
basic_string< _CharT, _Traits, _Alloc> ::_S_construct(size_type __n, _CharT __c, const _Alloc &__a) 
# 154
{ 
# 156
if ((__n == 0) && (__a == _Alloc())) { 
# 157
return ((_S_empty_rep)()._M_refdata()); }  
# 160
_Rep *__r = _Rep::_S_create(__n, (size_type)0, __a); 
# 161
if (__n) { 
# 162
(_M_assign)((__r->_M_refdata()), __n, __c); }  
# 164
(__r->_M_set_length_and_sharable(__n)); 
# 165
return (__r->_M_refdata()); 
# 166
} 
# 168
template< class _CharT, class _Traits, class _Alloc> 
# 170
basic_string< _CharT, _Traits, _Alloc> ::basic_string(const basic_string &__str) : _M_dataplus((__str._M_rep()->_M_grab((_Alloc)__str.get_allocator(), __str.get_allocator())), __str.get_allocator()) 
# 174
{ } 
# 176
template< class _CharT, class _Traits, class _Alloc> 
# 178
basic_string< _CharT, _Traits, _Alloc> ::basic_string(const _Alloc &__a) : _M_dataplus(_S_construct(size_type(), _CharT(), __a), __a) 
# 180
{ } 
# 182
template< class _CharT, class _Traits, class _Alloc> 
# 184
basic_string< _CharT, _Traits, _Alloc> ::basic_string(const basic_string &__str, size_type __pos, size_type __n) : _M_dataplus(_S_construct((__str._M_data()) + __str._M_check(__pos, "basic_string::basic_string"), ((__str._M_data()) + __str._M_limit(__pos, __n)) + __pos, _Alloc()), _Alloc()) 
# 190
{ } 
# 192
template< class _CharT, class _Traits, class _Alloc> 
# 194
basic_string< _CharT, _Traits, _Alloc> ::basic_string(const basic_string &__str, size_type __pos, size_type 
# 195
__n, const _Alloc &__a) : _M_dataplus(_S_construct((__str._M_data()) + __str._M_check(__pos, "basic_string::basic_string"), ((__str._M_data()) + __str._M_limit(__pos, __n)) + __pos, __a), __a) 
# 201
{ } 
# 204
template< class _CharT, class _Traits, class _Alloc> 
# 206
basic_string< _CharT, _Traits, _Alloc> ::basic_string(const _CharT *__s, size_type __n, const _Alloc &__a) : _M_dataplus(_S_construct(__s, __s + __n, __a), __a) 
# 208
{ } 
# 211
template< class _CharT, class _Traits, class _Alloc> 
# 213
basic_string< _CharT, _Traits, _Alloc> ::basic_string(const _CharT *__s, const _Alloc &__a) : _M_dataplus(_S_construct(__s, (__s) ? __s + traits_type::length(__s) : (__s + npos), __a), __a) 
# 216
{ } 
# 218
template< class _CharT, class _Traits, class _Alloc> 
# 220
basic_string< _CharT, _Traits, _Alloc> ::basic_string(size_type __n, _CharT __c, const _Alloc &__a) : _M_dataplus(_S_construct(__n, __c, __a), __a) 
# 222
{ } 
# 225
template< class _CharT, class _Traits, class _Alloc> 
# 226
template< class _InputIterator> 
# 228
basic_string< _CharT, _Traits, _Alloc> ::basic_string(_InputIterator __beg, _InputIterator __end, const _Alloc &__a) : _M_dataplus(_S_construct(__beg, __end, __a), __a) 
# 230
{ } 
# 240
template< class _CharT, class _Traits, class _Alloc> basic_string< _CharT, _Traits, _Alloc>  &
# 243
basic_string< _CharT, _Traits, _Alloc> ::assign(const basic_string &__str) 
# 244
{ 
# 245
if (_M_rep() != __str._M_rep()) 
# 246
{ 
# 248
const allocator_type __a = this->get_allocator(); 
# 249
_CharT *__tmp = (__str._M_rep()->_M_grab(__a, __str.get_allocator())); 
# 250
(_M_rep()->_M_dispose(__a)); 
# 251
_M_data(__tmp); 
# 252
}  
# 253
return *this; 
# 254
} 
# 256
template< class _CharT, class _Traits, class _Alloc> basic_string< _CharT, _Traits, _Alloc>  &
# 259
basic_string< _CharT, _Traits, _Alloc> ::assign(const _CharT *__s, size_type __n) 
# 260
{ 
# 261
; 
# 262
_M_check_length(this->size(), __n, "basic_string::assign"); 
# 263
if (_M_disjunct(__s) || (_M_rep()->_M_is_shared())) { 
# 264
return _M_replace_safe((size_type)0, this->size(), __s, __n); } else 
# 266
{ 
# 268
const size_type __pos = __s - _M_data(); 
# 269
if (__pos >= __n) { 
# 270
(_M_copy)(_M_data(), __s, __n); } else { 
# 271
if (__pos) { 
# 272
(_M_move)(_M_data(), __s, __n); }  }  
# 273
(_M_rep()->_M_set_length_and_sharable(__n)); 
# 274
return *this; 
# 275
}  
# 276
} 
# 278
template< class _CharT, class _Traits, class _Alloc> basic_string< _CharT, _Traits, _Alloc>  &
# 281
basic_string< _CharT, _Traits, _Alloc> ::append(size_type __n, _CharT __c) 
# 282
{ 
# 283
if (__n) 
# 284
{ 
# 285
_M_check_length((size_type)0, __n, "basic_string::append"); 
# 286
const size_type __len = __n + this->size(); 
# 287
if ((__len > this->capacity()) || (_M_rep()->_M_is_shared())) { 
# 288
this->reserve(__len); }  
# 289
(_M_assign)(_M_data() + this->size(), __n, __c); 
# 290
(_M_rep()->_M_set_length_and_sharable(__len)); 
# 291
}  
# 292
return *this; 
# 293
} 
# 295
template< class _CharT, class _Traits, class _Alloc> basic_string< _CharT, _Traits, _Alloc>  &
# 298
basic_string< _CharT, _Traits, _Alloc> ::append(const _CharT *__s, size_type __n) 
# 299
{ 
# 300
; 
# 301
if (__n) 
# 302
{ 
# 303
_M_check_length((size_type)0, __n, "basic_string::append"); 
# 304
const size_type __len = __n + this->size(); 
# 305
if ((__len > this->capacity()) || (_M_rep()->_M_is_shared())) 
# 306
{ 
# 307
if (_M_disjunct(__s)) { 
# 308
this->reserve(__len); } else 
# 310
{ 
# 311
const size_type __off = __s - _M_data(); 
# 312
this->reserve(__len); 
# 313
__s = (_M_data() + __off); 
# 314
}  
# 315
}  
# 316
(_M_copy)(_M_data() + this->size(), __s, __n); 
# 317
(_M_rep()->_M_set_length_and_sharable(__len)); 
# 318
}  
# 319
return *this; 
# 320
} 
# 322
template< class _CharT, class _Traits, class _Alloc> basic_string< _CharT, _Traits, _Alloc>  &
# 325
basic_string< _CharT, _Traits, _Alloc> ::append(const basic_string &__str) 
# 326
{ 
# 327
const size_type __size = __str.size(); 
# 328
if (__size) 
# 329
{ 
# 330
const size_type __len = __size + this->size(); 
# 331
if ((__len > this->capacity()) || (_M_rep()->_M_is_shared())) { 
# 332
this->reserve(__len); }  
# 333
(_M_copy)(_M_data() + this->size(), (__str._M_data()), __size); 
# 334
(_M_rep()->_M_set_length_and_sharable(__len)); 
# 335
}  
# 336
return *this; 
# 337
} 
# 339
template< class _CharT, class _Traits, class _Alloc> basic_string< _CharT, _Traits, _Alloc>  &
# 342
basic_string< _CharT, _Traits, _Alloc> ::append(const basic_string &__str, size_type __pos, size_type __n) 
# 343
{ 
# 344
__str._M_check(__pos, "basic_string::append"); 
# 345
__n = __str._M_limit(__pos, __n); 
# 346
if (__n) 
# 347
{ 
# 348
const size_type __len = __n + this->size(); 
# 349
if ((__len > this->capacity()) || (_M_rep()->_M_is_shared())) { 
# 350
this->reserve(__len); }  
# 351
(_M_copy)(_M_data() + this->size(), (__str._M_data()) + __pos, __n); 
# 352
(_M_rep()->_M_set_length_and_sharable(__len)); 
# 353
}  
# 354
return *this; 
# 355
} 
# 357
template< class _CharT, class _Traits, class _Alloc> basic_string< _CharT, _Traits, _Alloc>  &
# 360
basic_string< _CharT, _Traits, _Alloc> ::insert(size_type __pos, const _CharT *__s, size_type __n) 
# 361
{ 
# 362
; 
# 363
_M_check(__pos, "basic_string::insert"); 
# 364
_M_check_length((size_type)0, __n, "basic_string::insert"); 
# 365
if (_M_disjunct(__s) || (_M_rep()->_M_is_shared())) { 
# 366
return _M_replace_safe(__pos, (size_type)0, __s, __n); } else 
# 368
{ 
# 370
const size_type __off = __s - _M_data(); 
# 371
_M_mutate(__pos, 0, __n); 
# 372
__s = (_M_data() + __off); 
# 373
_CharT *__p = _M_data() + __pos; 
# 374
if ((__s + __n) <= __p) { 
# 375
(_M_copy)(__p, __s, __n); } else { 
# 376
if (__s >= __p) { 
# 377
(_M_copy)(__p, __s + __n, __n); } else 
# 379
{ 
# 380
const size_type __nleft = __p - __s; 
# 381
(_M_copy)(__p, __s, __nleft); 
# 382
(_M_copy)(__p + __nleft, __p + __n, __n - __nleft); 
# 383
}  }  
# 384
return *this; 
# 385
}  
# 386
} 
# 388
template< class _CharT, class _Traits, class _Alloc> typename basic_string< _CharT, _Traits, _Alloc> ::iterator 
# 391
basic_string< _CharT, _Traits, _Alloc> ::erase(iterator __first, iterator __last) 
# 392
{ 
# 394
; 
# 399
const size_type __size = __last - __first; 
# 400
if (__size) 
# 401
{ 
# 402
const size_type __pos = __first - _M_ibegin(); 
# 403
_M_mutate(__pos, __size, (size_type)0); 
# 404
(_M_rep()->_M_set_leaked()); 
# 405
return ((iterator)(_M_data() + __pos)); 
# 406
} else { 
# 408
return __first; }  
# 409
} 
# 411
template< class _CharT, class _Traits, class _Alloc> basic_string< _CharT, _Traits, _Alloc>  &
# 414
basic_string< _CharT, _Traits, _Alloc> ::replace(size_type __pos, size_type __n1, const _CharT *__s, size_type 
# 415
__n2) 
# 416
{ 
# 417
; 
# 418
_M_check(__pos, "basic_string::replace"); 
# 419
__n1 = _M_limit(__pos, __n1); 
# 420
_M_check_length(__n1, __n2, "basic_string::replace"); 
# 421
bool __left; 
# 422
if (_M_disjunct(__s) || (_M_rep()->_M_is_shared())) { 
# 423
return _M_replace_safe(__pos, __n1, __s, __n2); } else { 
# 424
if ((__left = ((__s + __n2) <= (_M_data() + __pos))) || (((_M_data() + __pos) + __n1) <= __s)) 
# 426
{ 
# 428
size_type __off = __s - _M_data(); 
# 429
__left ? __off : (__off += (__n2 - __n1)); 
# 430
_M_mutate(__pos, __n1, __n2); 
# 431
(_M_copy)(_M_data() + __pos, _M_data() + __off, __n2); 
# 432
return *this; 
# 433
} else 
# 435
{ 
# 437
const basic_string __tmp(__s, __n2); 
# 438
return _M_replace_safe(__pos, __n1, (__tmp._M_data()), __n2); 
# 439
}  }  
# 440
} 
# 442
template< class _CharT, class _Traits, class _Alloc> void 
# 445
basic_string< _CharT, _Traits, _Alloc> ::_Rep::_M_destroy(const _Alloc &__a) throw() 
# 446
{ 
# 447
const typename ::std::basic_string< _CharT, _Traits, _Alloc> ::size_type __size = sizeof(typename ::std::basic_string< _CharT, _Traits, _Alloc> ::_Rep_base) + (((this->_M_capacity) + 1) * sizeof(_CharT)); 
# 449
(((_Raw_bytes_alloc)__a).deallocate(reinterpret_cast< char *>(this), __size)); 
# 450
} 
# 452
template< class _CharT, class _Traits, class _Alloc> void 
# 455
basic_string< _CharT, _Traits, _Alloc> ::_M_leak_hard() 
# 456
{ 
# 458
if (_M_rep() == (&(_S_empty_rep)())) { 
# 459
return; }  
# 461
if ((_M_rep()->_M_is_shared())) { 
# 462
_M_mutate(0, 0, 0); }  
# 463
(_M_rep()->_M_set_leaked()); 
# 464
} 
# 466
template< class _CharT, class _Traits, class _Alloc> void 
# 469
basic_string< _CharT, _Traits, _Alloc> ::_M_mutate(size_type __pos, size_type __len1, size_type __len2) 
# 470
{ 
# 471
const size_type __old_size = this->size(); 
# 472
const size_type __new_size = (__old_size + __len2) - __len1; 
# 473
const size_type __how_much = (__old_size - __pos) - __len1; 
# 475
if ((__new_size > this->capacity()) || (_M_rep()->_M_is_shared())) 
# 476
{ 
# 478
const allocator_type __a = get_allocator(); 
# 479
_Rep *__r = _Rep::_S_create(__new_size, this->capacity(), __a); 
# 481
if (__pos) { 
# 482
(_M_copy)((__r->_M_refdata()), _M_data(), __pos); }  
# 483
if (__how_much) { 
# 484
(_M_copy)(((__r->_M_refdata()) + __pos) + __len2, (_M_data() + __pos) + __len1, __how_much); }  
# 487
(_M_rep()->_M_dispose(__a)); 
# 488
_M_data((__r->_M_refdata())); 
# 489
} else { 
# 490
if (__how_much && (__len1 != __len2)) 
# 491
{ 
# 493
(_M_move)((_M_data() + __pos) + __len2, (_M_data() + __pos) + __len1, __how_much); 
# 495
}  }  
# 496
(_M_rep()->_M_set_length_and_sharable(__new_size)); 
# 497
} 
# 499
template< class _CharT, class _Traits, class _Alloc> void 
# 502
basic_string< _CharT, _Traits, _Alloc> ::reserve(size_type __res) 
# 503
{ 
# 504
if ((__res != this->capacity()) || (_M_rep()->_M_is_shared())) 
# 505
{ 
# 507
if (__res < this->size()) { 
# 508
__res = this->size(); }  
# 509
const allocator_type __a = get_allocator(); 
# 510
_CharT *__tmp = (_M_rep()->_M_clone(__a, __res - this->size())); 
# 511
(_M_rep()->_M_dispose(__a)); 
# 512
_M_data(__tmp); 
# 513
}  
# 514
} 
# 516
template< class _CharT, class _Traits, class _Alloc> void 
# 519
basic_string< _CharT, _Traits, _Alloc> ::swap(basic_string &__s) 
# 520
{ 
# 521
if ((_M_rep()->_M_is_leaked())) { 
# 522
(_M_rep()->_M_set_sharable()); }  
# 523
if ((__s._M_rep()->_M_is_leaked())) { 
# 524
(__s._M_rep()->_M_set_sharable()); }  
# 525
if (this->get_allocator() == __s.get_allocator()) 
# 526
{ 
# 527
_CharT *__tmp = _M_data(); 
# 528
_M_data((__s._M_data())); 
# 529
(__s._M_data(__tmp)); 
# 530
} else 
# 533
{ 
# 534
const basic_string __tmp1(_M_ibegin(), _M_iend(), __s.get_allocator()); 
# 536
const basic_string __tmp2(__s._M_ibegin(), __s._M_iend(), this->get_allocator()); 
# 538
(*this) = __tmp2; 
# 539
__s = __tmp1; 
# 540
}  
# 541
} 
# 543
template< class _CharT, class _Traits, class _Alloc> typename basic_string< _CharT, _Traits, _Alloc> ::_Rep *
# 546
basic_string< _CharT, _Traits, _Alloc> ::_Rep::_S_create(typename ::std::basic_string< _CharT, _Traits, _Alloc> ::size_type __capacity, typename ::std::basic_string< _CharT, _Traits, _Alloc> ::size_type __old_capacity, const _Alloc &
# 547
__alloc) 
# 548
{ 
# 551
if (__capacity > _S_max_size) { 
# 552
__throw_length_error("basic_string::_S_create"); }  
# 577
const typename ::std::basic_string< _CharT, _Traits, _Alloc> ::size_type __pagesize = (4096); 
# 578
const typename ::std::basic_string< _CharT, _Traits, _Alloc> ::size_type __malloc_header_size = ((4) * sizeof(void *)); 
# 586
if ((__capacity > __old_capacity) && (__capacity < (2 * __old_capacity))) { 
# 587
__capacity = (2 * __old_capacity); }  
# 592
typename ::std::basic_string< _CharT, _Traits, _Alloc> ::size_type __size = ((__capacity + 1) * sizeof(_CharT)) + sizeof(_Rep); 
# 594
const typename ::std::basic_string< _CharT, _Traits, _Alloc> ::size_type __adj_size = __size + __malloc_header_size; 
# 595
if ((__adj_size > __pagesize) && (__capacity > __old_capacity)) 
# 596
{ 
# 597
const typename ::std::basic_string< _CharT, _Traits, _Alloc> ::size_type __extra = __pagesize - (__adj_size % __pagesize); 
# 598
__capacity += (__extra / sizeof(_CharT)); 
# 600
if (__capacity > _S_max_size) { 
# 601
__capacity = _S_max_size; }  
# 602
__size = (((__capacity + 1) * sizeof(_CharT)) + sizeof(_Rep)); 
# 603
}  
# 607
void *__place = (((_Raw_bytes_alloc)__alloc).allocate(__size)); 
# 608
_Rep *__p = new (__place) _Rep; 
# 609
(__p->_M_capacity) = __capacity; 
# 617
__p->_M_set_sharable(); 
# 618
return __p; 
# 619
} 
# 621
template< class _CharT, class _Traits, class _Alloc> _CharT *
# 624
basic_string< _CharT, _Traits, _Alloc> ::_Rep::_M_clone(const _Alloc &__alloc, typename ::std::basic_string< _CharT, _Traits, _Alloc> ::size_type __res) 
# 625
{ 
# 627
const typename ::std::basic_string< _CharT, _Traits, _Alloc> ::size_type __requested_cap = (this->_M_length) + __res; 
# 628
_Rep *__r = (_S_create)(__requested_cap, (this->_M_capacity), __alloc); 
# 630
if (this->_M_length) { 
# 631
(::std::basic_string< _CharT, _Traits, _Alloc> ::_M_copy)(__r->_M_refdata(), _M_refdata(), (this->_M_length)); }  
# 633
__r->_M_set_length_and_sharable((this->_M_length)); 
# 634
return __r->_M_refdata(); 
# 635
} 
# 637
template< class _CharT, class _Traits, class _Alloc> void 
# 640
basic_string< _CharT, _Traits, _Alloc> ::resize(size_type __n, _CharT __c) 
# 641
{ 
# 642
const size_type __size = this->size(); 
# 643
_M_check_length(__size, __n, "basic_string::resize"); 
# 644
if (__size < __n) { 
# 645
(this->append(__n - __size, __c)); } else { 
# 646
if (__n < __size) { 
# 647
(this->erase(__n)); }  }  
# 649
} 
# 651
template< class _CharT, class _Traits, class _Alloc> 
# 652
template< class _InputIterator> basic_string< _CharT, _Traits, _Alloc>  &
# 655
basic_string< _CharT, _Traits, _Alloc> ::_M_replace_dispatch(iterator __i1, iterator __i2, _InputIterator __k1, _InputIterator 
# 656
__k2, __false_type) 
# 657
{ 
# 658
const basic_string __s(__k1, __k2); 
# 659
const size_type __n1 = __i2 - __i1; 
# 660
_M_check_length(__n1, __s.size(), "basic_string::_M_replace_dispatch"); 
# 661
return _M_replace_safe(__i1 - _M_ibegin(), __n1, (__s._M_data()), __s.size()); 
# 663
} 
# 665
template< class _CharT, class _Traits, class _Alloc> basic_string< _CharT, _Traits, _Alloc>  &
# 668
basic_string< _CharT, _Traits, _Alloc> ::_M_replace_aux(size_type __pos1, size_type __n1, size_type __n2, _CharT 
# 669
__c) 
# 670
{ 
# 671
_M_check_length(__n1, __n2, "basic_string::_M_replace_aux"); 
# 672
_M_mutate(__pos1, __n1, __n2); 
# 673
if (__n2) { 
# 674
(_M_assign)(_M_data() + __pos1, __n2, __c); }  
# 675
return *this; 
# 676
} 
# 678
template< class _CharT, class _Traits, class _Alloc> basic_string< _CharT, _Traits, _Alloc>  &
# 681
basic_string< _CharT, _Traits, _Alloc> ::_M_replace_safe(size_type __pos1, size_type __n1, const _CharT *__s, size_type 
# 682
__n2) 
# 683
{ 
# 684
_M_mutate(__pos1, __n1, __n2); 
# 685
if (__n2) { 
# 686
(_M_copy)(_M_data() + __pos1, __s, __n2); }  
# 687
return *this; 
# 688
} 
# 690
template< class _CharT, class _Traits, class _Alloc> basic_string< _CharT, _Traits, _Alloc>  
# 692
operator+(const _CharT *__lhs, const basic_string< _CharT, _Traits, _Alloc>  &
# 693
__rhs) 
# 694
{ 
# 695
; 
# 696
typedef basic_string< _CharT, _Traits, _Alloc>  __string_type; 
# 697
typedef typename basic_string< _CharT, _Traits, _Alloc> ::size_type __size_type; 
# 698
const __size_type __len = _Traits::length(__lhs); 
# 699
__string_type __str; 
# 700
(__str.reserve(__len + (__rhs.size()))); 
# 701
(__str.append(__lhs, __len)); 
# 702
(__str.append(__rhs)); 
# 703
return __str; 
# 704
} 
# 706
template< class _CharT, class _Traits, class _Alloc> basic_string< _CharT, _Traits, _Alloc>  
# 708
operator+(_CharT __lhs, const basic_string< _CharT, _Traits, _Alloc>  &__rhs) 
# 709
{ 
# 710
typedef basic_string< _CharT, _Traits, _Alloc>  __string_type; 
# 711
typedef typename basic_string< _CharT, _Traits, _Alloc> ::size_type __size_type; 
# 712
__string_type __str; 
# 713
const __size_type __len = (__rhs.size()); 
# 714
(__str.reserve(__len + 1)); 
# 715
(__str.append((__size_type)1, __lhs)); 
# 716
(__str.append(__rhs)); 
# 717
return __str; 
# 718
} 
# 720
template< class _CharT, class _Traits, class _Alloc> typename basic_string< _CharT, _Traits, _Alloc> ::size_type 
# 723
basic_string< _CharT, _Traits, _Alloc> ::copy(_CharT *__s, size_type __n, size_type __pos) const 
# 724
{ 
# 725
_M_check(__pos, "basic_string::copy"); 
# 726
__n = _M_limit(__pos, __n); 
# 727
; 
# 728
if (__n) { 
# 729
(_M_copy)(__s, _M_data() + __pos, __n); }  
# 731
return __n; 
# 732
} 
# 734
template< class _CharT, class _Traits, class _Alloc> typename basic_string< _CharT, _Traits, _Alloc> ::size_type 
# 737
basic_string< _CharT, _Traits, _Alloc> ::find(const _CharT *__s, size_type __pos, size_type __n) const 
# 738
{ 
# 739
; 
# 740
const size_type __size = this->size(); 
# 741
const _CharT *__data = _M_data(); 
# 743
if (__n == 0) { 
# 744
return (__pos <= __size) ? __pos : npos; }  
# 746
if (__n <= __size) 
# 747
{ 
# 748
for (; __pos <= (__size - __n); ++__pos) { 
# 749
if (traits_type::eq(__data[__pos], __s[0]) && (traits_type::compare((__data + __pos) + 1, __s + 1, __n - 1) == 0)) { 
# 752
return __pos; }  }  
# 753
}  
# 754
return npos; 
# 755
} 
# 757
template< class _CharT, class _Traits, class _Alloc> typename basic_string< _CharT, _Traits, _Alloc> ::size_type 
# 760
basic_string< _CharT, _Traits, _Alloc> ::find(_CharT __c, size_type __pos) const 
# 761
{ 
# 762
size_type __ret = npos; 
# 763
const size_type __size = this->size(); 
# 764
if (__pos < __size) 
# 765
{ 
# 766
const _CharT *__data = _M_data(); 
# 767
const size_type __n = __size - __pos; 
# 768
const _CharT *__p = traits_type::find(__data + __pos, __n, __c); 
# 769
if (__p) { 
# 770
__ret = (__p - __data); }  
# 771
}  
# 772
return __ret; 
# 773
} 
# 775
template< class _CharT, class _Traits, class _Alloc> typename basic_string< _CharT, _Traits, _Alloc> ::size_type 
# 778
basic_string< _CharT, _Traits, _Alloc> ::rfind(const _CharT *__s, size_type __pos, size_type __n) const 
# 779
{ 
# 780
; 
# 781
const size_type __size = this->size(); 
# 782
if (__n <= __size) 
# 783
{ 
# 784
__pos = std::min((size_type)(__size - __n), __pos); 
# 785
const _CharT *__data = _M_data(); 
# 786
do 
# 787
{ 
# 788
if (traits_type::compare(__data + __pos, __s, __n) == 0) { 
# 789
return __pos; }  
# 790
} 
# 791
while ((__pos--) > 0); 
# 792
}  
# 793
return npos; 
# 794
} 
# 796
template< class _CharT, class _Traits, class _Alloc> typename basic_string< _CharT, _Traits, _Alloc> ::size_type 
# 799
basic_string< _CharT, _Traits, _Alloc> ::rfind(_CharT __c, size_type __pos) const 
# 800
{ 
# 801
size_type __size = this->size(); 
# 802
if (__size) 
# 803
{ 
# 804
if ((--__size) > __pos) { 
# 805
__size = __pos; }  
# 806
for (++__size; (__size--) > 0;) { 
# 807
if (traits_type::eq(_M_data()[__size], __c)) { 
# 808
return __size; }  }  
# 809
}  
# 810
return npos; 
# 811
} 
# 813
template< class _CharT, class _Traits, class _Alloc> typename basic_string< _CharT, _Traits, _Alloc> ::size_type 
# 816
basic_string< _CharT, _Traits, _Alloc> ::find_first_of(const _CharT *__s, size_type __pos, size_type __n) const 
# 817
{ 
# 818
; 
# 819
for (; __n && (__pos < this->size()); ++__pos) 
# 820
{ 
# 821
const _CharT *__p = traits_type::find(__s, __n, _M_data()[__pos]); 
# 822
if (__p) { 
# 823
return __pos; }  
# 824
}  
# 825
return npos; 
# 826
} 
# 828
template< class _CharT, class _Traits, class _Alloc> typename basic_string< _CharT, _Traits, _Alloc> ::size_type 
# 831
basic_string< _CharT, _Traits, _Alloc> ::find_last_of(const _CharT *__s, size_type __pos, size_type __n) const 
# 832
{ 
# 833
; 
# 834
size_type __size = this->size(); 
# 835
if (__size && __n) 
# 836
{ 
# 837
if ((--__size) > __pos) { 
# 838
__size = __pos; }  
# 839
do 
# 840
{ 
# 841
if (traits_type::find(__s, __n, _M_data()[__size])) { 
# 842
return __size; }  
# 843
} 
# 844
while ((__size--) != 0); 
# 845
}  
# 846
return npos; 
# 847
} 
# 849
template< class _CharT, class _Traits, class _Alloc> typename basic_string< _CharT, _Traits, _Alloc> ::size_type 
# 852
basic_string< _CharT, _Traits, _Alloc> ::find_first_not_of(const _CharT *__s, size_type __pos, size_type __n) const 
# 853
{ 
# 854
; 
# 855
for (; __pos < this->size(); ++__pos) { 
# 856
if (!traits_type::find(__s, __n, _M_data()[__pos])) { 
# 857
return __pos; }  }  
# 858
return npos; 
# 859
} 
# 861
template< class _CharT, class _Traits, class _Alloc> typename basic_string< _CharT, _Traits, _Alloc> ::size_type 
# 864
basic_string< _CharT, _Traits, _Alloc> ::find_first_not_of(_CharT __c, size_type __pos) const 
# 865
{ 
# 866
for (; __pos < this->size(); ++__pos) { 
# 867
if (!traits_type::eq(_M_data()[__pos], __c)) { 
# 868
return __pos; }  }  
# 869
return npos; 
# 870
} 
# 872
template< class _CharT, class _Traits, class _Alloc> typename basic_string< _CharT, _Traits, _Alloc> ::size_type 
# 875
basic_string< _CharT, _Traits, _Alloc> ::find_last_not_of(const _CharT *__s, size_type __pos, size_type __n) const 
# 876
{ 
# 877
; 
# 878
size_type __size = this->size(); 
# 879
if (__size) 
# 880
{ 
# 881
if ((--__size) > __pos) { 
# 882
__size = __pos; }  
# 883
do 
# 884
{ 
# 885
if (!traits_type::find(__s, __n, _M_data()[__size])) { 
# 886
return __size; }  
# 887
} 
# 888
while (__size--); 
# 889
}  
# 890
return npos; 
# 891
} 
# 893
template< class _CharT, class _Traits, class _Alloc> typename basic_string< _CharT, _Traits, _Alloc> ::size_type 
# 896
basic_string< _CharT, _Traits, _Alloc> ::find_last_not_of(_CharT __c, size_type __pos) const 
# 897
{ 
# 898
size_type __size = this->size(); 
# 899
if (__size) 
# 900
{ 
# 901
if ((--__size) > __pos) { 
# 902
__size = __pos; }  
# 903
do 
# 904
{ 
# 905
if (!traits_type::eq(_M_data()[__size], __c)) { 
# 906
return __size; }  
# 907
} 
# 908
while (__size--); 
# 909
}  
# 910
return npos; 
# 911
} 
# 913
template< class _CharT, class _Traits, class _Alloc> int 
# 916
basic_string< _CharT, _Traits, _Alloc> ::compare(size_type __pos, size_type __n, const basic_string &__str) const 
# 917
{ 
# 918
_M_check(__pos, "basic_string::compare"); 
# 919
__n = _M_limit(__pos, __n); 
# 920
const size_type __osize = __str.size(); 
# 921
const size_type __len = std::min(__n, __osize); 
# 922
int __r = traits_type::compare(_M_data() + __pos, __str.data(), __len); 
# 923
if (!__r) { 
# 924
__r = (_S_compare)(__n, __osize); }  
# 925
return __r; 
# 926
} 
# 928
template< class _CharT, class _Traits, class _Alloc> int 
# 931
basic_string< _CharT, _Traits, _Alloc> ::compare(size_type __pos1, size_type __n1, const basic_string &__str, size_type 
# 932
__pos2, size_type __n2) const 
# 933
{ 
# 934
_M_check(__pos1, "basic_string::compare"); 
# 935
__str._M_check(__pos2, "basic_string::compare"); 
# 936
__n1 = _M_limit(__pos1, __n1); 
# 937
__n2 = __str._M_limit(__pos2, __n2); 
# 938
const size_type __len = std::min(__n1, __n2); 
# 939
int __r = traits_type::compare(_M_data() + __pos1, __str.data() + __pos2, __len); 
# 941
if (!__r) { 
# 942
__r = (_S_compare)(__n1, __n2); }  
# 943
return __r; 
# 944
} 
# 946
template< class _CharT, class _Traits, class _Alloc> int 
# 949
basic_string< _CharT, _Traits, _Alloc> ::compare(const _CharT *__s) const 
# 950
{ 
# 951
; 
# 952
const size_type __size = this->size(); 
# 953
const size_type __osize = traits_type::length(__s); 
# 954
const size_type __len = std::min(__size, __osize); 
# 955
int __r = traits_type::compare(_M_data(), __s, __len); 
# 956
if (!__r) { 
# 957
__r = (_S_compare)(__size, __osize); }  
# 958
return __r; 
# 959
} 
# 961
template< class _CharT, class _Traits, class _Alloc> int 
# 964
basic_string< _CharT, _Traits, _Alloc> ::compare(size_type __pos, size_type __n1, const _CharT *__s) const 
# 965
{ 
# 966
; 
# 967
_M_check(__pos, "basic_string::compare"); 
# 968
__n1 = _M_limit(__pos, __n1); 
# 969
const size_type __osize = traits_type::length(__s); 
# 970
const size_type __len = std::min(__n1, __osize); 
# 971
int __r = traits_type::compare(_M_data() + __pos, __s, __len); 
# 972
if (!__r) { 
# 973
__r = (_S_compare)(__n1, __osize); }  
# 974
return __r; 
# 975
} 
# 977
template< class _CharT, class _Traits, class _Alloc> int 
# 980
basic_string< _CharT, _Traits, _Alloc> ::compare(size_type __pos, size_type __n1, const _CharT *__s, size_type 
# 981
__n2) const 
# 982
{ 
# 983
; 
# 984
_M_check(__pos, "basic_string::compare"); 
# 985
__n1 = _M_limit(__pos, __n1); 
# 986
const size_type __len = std::min(__n1, __n2); 
# 987
int __r = traits_type::compare(_M_data() + __pos, __s, __len); 
# 988
if (!__r) { 
# 989
__r = (_S_compare)(__n1, __n2); }  
# 990
return __r; 
# 991
} 
# 994
template< class _CharT, class _Traits, class _Alloc> basic_istream< _CharT, _Traits>  &
# 996
operator>>(basic_istream< _CharT, _Traits>  &__in, basic_string< _CharT, _Traits, _Alloc>  &
# 997
__str) 
# 998
{ 
# 999
typedef basic_istream< _CharT, _Traits>  __istream_type; 
# 1000
typedef basic_string< _CharT, _Traits, _Alloc>  __string_type; 
# 1001
typedef typename basic_istream< _CharT, _Traits> ::ios_base __ios_base; 
# 1002
typedef typename basic_istream< _CharT, _Traits> ::int_type __int_type; 
# 1003
typedef typename basic_string< _CharT, _Traits, _Alloc> ::size_type __size_type; 
# 1004
typedef ctype< _CharT>  __ctype_type; 
# 1005
typedef typename ctype< _CharT> ::ctype_base __ctype_base; 
# 1007
__size_type __extracted = (0); 
# 1008
typename basic_istream< _CharT, _Traits> ::ios_base::iostate __err = (__ios_base::goodbit); 
# 1009
typename basic_istream< _CharT, _Traits> ::sentry __cerb(__in, false); 
# 1010
if (__cerb) 
# 1011
{ 
# 1012
try 
# 1013
{ 
# 1015
(__str.erase()); 
# 1016
_CharT __buf[128]; 
# 1017
__size_type __len = (0); 
# 1018
const streamsize __w = (__in.width()); 
# 1019
const __size_type __n = (__w > (0)) ? static_cast< __size_type>(__w) : (__str.max_size()); 
# 1021
const __ctype_type &__ct = use_facet< ctype< _CharT> > ((__in.getloc())); 
# 1022
const __int_type __eof = _Traits::eof(); 
# 1023
__int_type __c = ((__in.rdbuf())->sgetc()); 
# 1025
while ((__extracted < __n) && (!_Traits::eq_int_type(__c, __eof)) && (!(__ct.is(__ctype_base::space, _Traits::to_char_type(__c))))) 
# 1029
{ 
# 1030
if (__len == (sizeof(__buf) / sizeof(_CharT))) 
# 1031
{ 
# 1032
(__str.append(__buf, sizeof(__buf) / sizeof(_CharT))); 
# 1033
__len = 0; 
# 1034
}  
# 1035
(__buf[__len++]) = _Traits::to_char_type(__c); 
# 1036
++__extracted; 
# 1037
__c = ((__in.rdbuf())->snextc()); 
# 1038
}  
# 1039
(__str.append(__buf, __len)); 
# 1041
if (_Traits::eq_int_type(__c, __eof)) { 
# 1042
__err |= __ios_base::eofbit; }  
# 1043
(__in.width(0)); 
# 1044
} 
# 1045
catch (__cxxabiv1::__forced_unwind &) 
# 1046
{ 
# 1047
(__in._M_setstate(__ios_base::badbit)); 
# 1048
throw; 
# 1049
} 
# 1050
catch (...) 
# 1051
{ 
# 1055
(__in._M_setstate(__ios_base::badbit)); 
# 1056
}  
# 1057
}  
# 1059
if (!__extracted) { 
# 1060
__err |= __ios_base::failbit; }  
# 1061
if (__err) { 
# 1062
(__in.setstate(__err)); }  
# 1063
return __in; 
# 1064
} 
# 1066
template< class _CharT, class _Traits, class _Alloc> basic_istream< _CharT, _Traits>  &
# 1068
getline(basic_istream< _CharT, _Traits>  &__in, basic_string< _CharT, _Traits, _Alloc>  &
# 1069
__str, _CharT __delim) 
# 1070
{ 
# 1071
typedef basic_istream< _CharT, _Traits>  __istream_type; 
# 1072
typedef basic_string< _CharT, _Traits, _Alloc>  __string_type; 
# 1073
typedef typename basic_istream< _CharT, _Traits> ::ios_base __ios_base; 
# 1074
typedef typename basic_istream< _CharT, _Traits> ::int_type __int_type; 
# 1075
typedef typename basic_string< _CharT, _Traits, _Alloc> ::size_type __size_type; 
# 1077
__size_type __extracted = (0); 
# 1078
const __size_type __n = (__str.max_size()); 
# 1079
typename basic_istream< _CharT, _Traits> ::ios_base::iostate __err = (__ios_base::goodbit); 
# 1080
typename basic_istream< _CharT, _Traits> ::sentry __cerb(__in, true); 
# 1081
if (__cerb) 
# 1082
{ 
# 1083
try 
# 1084
{ 
# 1085
(__str.erase()); 
# 1086
const __int_type __idelim = _Traits::to_int_type(__delim); 
# 1087
const __int_type __eof = _Traits::eof(); 
# 1088
__int_type __c = ((__in.rdbuf())->sgetc()); 
# 1090
while ((__extracted < __n) && (!_Traits::eq_int_type(__c, __eof)) && (!_Traits::eq_int_type(__c, __idelim))) 
# 1093
{ 
# 1094
__str += _Traits::to_char_type(__c); 
# 1095
++__extracted; 
# 1096
__c = ((__in.rdbuf())->snextc()); 
# 1097
}  
# 1099
if (_Traits::eq_int_type(__c, __eof)) { 
# 1100
__err |= __ios_base::eofbit; } else { 
# 1101
if (_Traits::eq_int_type(__c, __idelim)) 
# 1102
{ 
# 1103
++__extracted; 
# 1104
((__in.rdbuf())->sbumpc()); 
# 1105
} else { 
# 1107
__err |= __ios_base::failbit; }  }  
# 1108
} 
# 1109
catch (__cxxabiv1::__forced_unwind &) 
# 1110
{ 
# 1111
(__in._M_setstate(__ios_base::badbit)); 
# 1112
throw; 
# 1113
} 
# 1114
catch (...) 
# 1115
{ 
# 1119
(__in._M_setstate(__ios_base::badbit)); 
# 1120
}  
# 1121
}  
# 1122
if (!__extracted) { 
# 1123
__err |= __ios_base::failbit; }  
# 1124
if (__err) { 
# 1125
(__in.setstate(__err)); }  
# 1126
return __in; 
# 1127
} 
# 1132
extern template class basic_string< char, char_traits< char> , allocator< char> > ;
# 1133
extern template basic_istream< char>  &operator>>(basic_istream< char>  & __is, basic_string< char, char_traits< char> , allocator< char> >  & __str);
# 1136
extern template basic_ostream< char>  &operator<<(basic_ostream< char>  & __os, const basic_string< char, char_traits< char> , allocator< char> >  & __str);
# 1139
extern template basic_istream< char>  &getline(basic_istream< char>  & __is, basic_string< char, char_traits< char> , allocator< char> >  & __str, char __delim);
# 1142
extern template basic_istream< char>  &getline(basic_istream< char>  & __is, basic_string< char, char_traits< char> , allocator< char> >  & __str);
# 1147
extern template class basic_string< wchar_t, char_traits< wchar_t> , allocator< wchar_t> > ;
# 1148
extern template basic_istream< wchar_t>  &operator>>(basic_istream< wchar_t>  & __is, basic_string< wchar_t, char_traits< wchar_t> , allocator< wchar_t> >  & __str);
# 1151
extern template basic_ostream< wchar_t>  &operator<<(basic_ostream< wchar_t>  & __os, const basic_string< wchar_t, char_traits< wchar_t> , allocator< wchar_t> >  & __str);
# 1154
extern template basic_istream< wchar_t>  &getline(basic_istream< wchar_t>  & __is, basic_string< wchar_t, char_traits< wchar_t> , allocator< wchar_t> >  & __str, wchar_t __delim);
# 1157
extern template basic_istream< wchar_t>  &getline(basic_istream< wchar_t>  & __is, basic_string< wchar_t, char_traits< wchar_t> , allocator< wchar_t> >  & __str);
# 1164
}
# 43 "/usr/include/c++/4.8.2/bits/locale_classes.h" 3
namespace std __attribute((__visibility__("default"))) { 
# 62
class locale { 
# 67
public: typedef int category; 
# 70
class facet; 
# 71
class id; 
# 72
class _Impl; 
# 74
friend class facet; 
# 75
friend class _Impl; 
# 77
template< class _Facet> friend bool has_facet(const locale &) throw(); 
# 81
template< class _Facet> friend const _Facet &use_facet(const locale &); 
# 85
template< class _Cache> friend struct __use_cache; 
# 98
static const category none = 0; 
# 99
static const category ctype = (1L << 0); 
# 100
static const category numeric = (1L << 1); 
# 101
static const category collate = (1L << 2); 
# 102
static const category time = (1L << 3); 
# 103
static const category monetary = (1L << 4); 
# 104
static const category messages = (1L << 5); 
# 105
static const category all = (((((ctype | numeric) | collate) | time) | monetary) | messages); 
# 117
locale() throw(); 
# 126
locale(const locale & __other) throw(); 
# 137
explicit locale(const char * __s); 
# 151
locale(const locale & __base, const char * __s, category __cat); 
# 164
locale(const locale & __base, const locale & __add, category __cat); 
# 177
template< class _Facet> locale(const locale & __other, _Facet * __f); 
# 181
~locale() throw(); 
# 192
const locale &operator=(const locale & __other) throw(); 
# 206
template< class _Facet> locale combine(const locale & __other) const; 
# 216
string name() const; 
# 226
bool operator==(const locale & __other) const throw(); 
# 235
bool operator!=(const locale &__other) const throw() 
# 236
{ return !this->operator==(__other); } 
# 253
template< class _Char, class _Traits, class _Alloc> bool operator()(const basic_string< _Char, _Traits, _Alloc>  & __s1, const basic_string< _Char, _Traits, _Alloc>  & __s2) const; 
# 270
static locale global(const locale & __loc); 
# 276
static const locale &classic(); 
# 280
private: _Impl *_M_impl; 
# 283
static _Impl *_S_classic; 
# 286
static _Impl *_S_global; 
# 292
static const char *const *const _S_categories; 
# 304
enum { _S_categories_size = 12}; 
# 307
static __gthread_once_t _S_once; 
# 311
explicit locale(_Impl *) throw(); 
# 314
static void _S_initialize(); 
# 317
static void _S_initialize_once() throw(); 
# 320
static category _S_normalize_category(category); 
# 323
void _M_coalesce(const locale & __base, const locale & __add, category __cat); 
# 324
}; 
# 338
class locale::facet { 
# 341
friend class locale; 
# 342
friend class _Impl; 
# 344
mutable _Atomic_word _M_refcount; 
# 347
static __c_locale _S_c_locale; 
# 350
static const char _S_c_name[2]; 
# 353
static __gthread_once_t _S_once; 
# 357
static void _S_initialize_once(); 
# 370
protected: explicit facet(size_t __refs = 0) throw() : _M_refcount((__refs) ? 1 : 0) 
# 371
{ } 
# 375
virtual ~facet(); 
# 378
static void _S_create_c_locale(__c_locale & __cloc, const char * __s, __c_locale __old = 0); 
# 382
static __c_locale _S_clone_c_locale(__c_locale & __cloc) throw(); 
# 385
static void _S_destroy_c_locale(__c_locale & __cloc); 
# 388
static __c_locale _S_lc_ctype_c_locale(__c_locale __cloc, const char * __s); 
# 393
static __c_locale _S_get_c_locale(); 
# 395
__attribute((const)) static const char *
# 396
_S_get_c_name() throw(); 
# 400
private: void _M_add_reference() const throw() 
# 401
{ __gnu_cxx::__atomic_add_dispatch(&(_M_refcount), 1); } 
# 404
void _M_remove_reference() const throw() 
# 405
{ 
# 407
; 
# 408
if (__gnu_cxx::__exchange_and_add_dispatch(&(_M_refcount), -1) == 1) 
# 409
{ 
# 410
; 
# 411
try 
# 412
{ delete this; } 
# 413
catch (...) 
# 414
{ }  
# 415
}  
# 416
} 
# 418
facet(const facet &); 
# 421
facet &operator=(const facet &); 
# 422
}; 
# 436
class locale::id { 
# 439
friend class locale; 
# 440
friend class _Impl; 
# 442
template< class _Facet> friend const _Facet &use_facet(const locale &); 
# 446
template< class _Facet> friend bool has_facet(const locale &) throw(); 
# 453
mutable size_t _M_index; 
# 456
static _Atomic_word _S_refcount; 
# 459
void operator=(const id &); 
# 461
id(const id &); 
# 467
public: id() { } 
# 470
size_t _M_id() const throw(); 
# 471
}; 
# 475
class locale::_Impl { 
# 479
friend class locale; 
# 480
friend class facet; 
# 482
template< class _Facet> friend bool has_facet(const locale &) throw(); 
# 486
template< class _Facet> friend const _Facet &use_facet(const locale &); 
# 490
template< class _Cache> friend struct __use_cache; 
# 495
_Atomic_word _M_refcount; 
# 496
const facet **_M_facets; 
# 497
size_t _M_facets_size; 
# 498
const facet **_M_caches; 
# 499
char **_M_names; 
# 500
static const id *const _S_id_ctype[]; 
# 501
static const id *const _S_id_numeric[]; 
# 502
static const id *const _S_id_collate[]; 
# 503
static const id *const _S_id_time[]; 
# 504
static const id *const _S_id_monetary[]; 
# 505
static const id *const _S_id_messages[]; 
# 506
static const id *const *const _S_facet_categories[]; 
# 509
void _M_add_reference() throw() 
# 510
{ __gnu_cxx::__atomic_add_dispatch(&(_M_refcount), 1); } 
# 513
void _M_remove_reference() throw() 
# 514
{ 
# 516
; 
# 517
if (__gnu_cxx::__exchange_and_add_dispatch(&(_M_refcount), -1) == 1) 
# 518
{ 
# 519
; 
# 520
try 
# 521
{ delete this; } 
# 522
catch (...) 
# 523
{ }  
# 524
}  
# 525
} 
# 527
_Impl(const _Impl &, size_t); 
# 528
_Impl(const char *, size_t); 
# 529
_Impl(size_t) throw(); 
# 531
~_Impl() throw(); 
# 533
_Impl(const _Impl &); 
# 536
void operator=(const _Impl &); 
# 539
bool _M_check_same_name() 
# 540
{ 
# 541
bool __ret = true; 
# 542
if ((_M_names)[1]) { 
# 544
for (size_t __i = (0); __ret && (__i < ((_S_categories_size) - 1)); ++__i) { 
# 545
__ret = (__builtin_strcmp((_M_names)[__i], (_M_names)[__i + (1)]) == 0); }  }  
# 546
return __ret; 
# 547
} 
# 550
void _M_replace_categories(const _Impl *, category); 
# 553
void _M_replace_category(const _Impl *, const id *const *); 
# 556
void _M_replace_facet(const _Impl *, const id *); 
# 559
void _M_install_facet(const id *, const facet *); 
# 561
template< class _Facet> void 
# 563
_M_init_facet(_Facet *__facet) 
# 564
{ this->_M_install_facet(&_Facet::id, __facet); } 
# 567
void _M_install_cache(const facet *, size_t); 
# 568
}; 
# 583
template< class _CharT> 
# 584
class collate : public locale::facet { 
# 590
public: typedef _CharT char_type; 
# 591
typedef basic_string< _CharT, char_traits< _CharT> , allocator< _CharT> >  string_type; 
# 597
protected: __c_locale _M_c_locale_collate; 
# 601
public: static locale::id id; 
# 611
explicit collate(size_t __refs = 0) : locale::facet(__refs), _M_c_locale_collate(_S_get_c_locale()) 
# 613
{ } 
# 625
explicit collate(__c_locale __cloc, size_t __refs = 0) : locale::facet(__refs), _M_c_locale_collate(_S_clone_c_locale(__cloc)) 
# 627
{ } 
# 642
int compare(const _CharT *__lo1, const _CharT *__hi1, const _CharT *
# 643
__lo2, const _CharT *__hi2) const 
# 644
{ return this->do_compare(__lo1, __hi1, __lo2, __hi2); } 
# 661
string_type transform(const _CharT *__lo, const _CharT *__hi) const 
# 662
{ return this->do_transform(__lo, __hi); } 
# 675
long hash(const _CharT *__lo, const _CharT *__hi) const 
# 676
{ return this->do_hash(__lo, __hi); } 
# 680
int _M_compare(const _CharT *, const _CharT *) const throw(); 
# 683
size_t _M_transform(_CharT *, const _CharT *, size_t) const throw(); 
# 688
protected: virtual ~collate() 
# 689
{ _S_destroy_c_locale(_M_c_locale_collate); } 
# 704
virtual int do_compare(const _CharT * __lo1, const _CharT * __hi1, const _CharT * __lo2, const _CharT * __hi2) const; 
# 718
virtual string_type do_transform(const _CharT * __lo, const _CharT * __hi) const; 
# 731
virtual long do_hash(const _CharT * __lo, const _CharT * __hi) const; 
# 732
}; 
# 734
template< class _CharT> locale::id 
# 735
collate< _CharT> ::id; 
# 740
template<> int collate< char> ::_M_compare(const char *, const char *) const throw(); 
# 744
template<> size_t collate< char> ::_M_transform(char *, const char *, size_t) const throw(); 
# 749
template<> int collate< wchar_t> ::_M_compare(const wchar_t *, const wchar_t *) const throw(); 
# 753
template<> size_t collate< wchar_t> ::_M_transform(wchar_t *, const wchar_t *, size_t) const throw(); 
# 757
template< class _CharT> 
# 758
class collate_byname : public collate< _CharT>  { 
# 763
public: typedef _CharT char_type; 
# 764
typedef basic_string< _CharT, char_traits< _CharT> , allocator< _CharT> >  string_type; 
# 768
explicit collate_byname(const char *__s, ::std::size_t __refs = 0) : ::std::collate< _CharT> (__refs) 
# 770
{ 
# 771
if ((__builtin_strcmp(__s, "C") != 0) && (__builtin_strcmp(__s, "POSIX") != 0)) 
# 773
{ 
# 774
(this->_S_destroy_c_locale((this->_M_c_locale_collate))); 
# 775
(this->_S_create_c_locale((this->_M_c_locale_collate), __s)); 
# 776
}  
# 777
} 
# 781
protected: virtual ~collate_byname() { } 
# 782
}; 
# 785
}
# 39 "/usr/include/c++/4.8.2/bits/locale_classes.tcc" 3
namespace std __attribute((__visibility__("default"))) { 
# 43
template< class _Facet> 
# 45
locale::locale(const locale &__other, _Facet *__f) 
# 46
{ 
# 47
(_M_impl) = (new _Impl(*(__other._M_impl), 1)); 
# 49
try 
# 50
{ (_M_impl)->_M_install_facet(&_Facet::id, __f); } 
# 51
catch (...) 
# 52
{ 
# 53
(_M_impl)->_M_remove_reference(); 
# 54
throw; 
# 55
}  
# 56
delete [] (((_M_impl)->_M_names)[0]); 
# 57
(((_M_impl)->_M_names)[0]) = (0); 
# 58
} 
# 60
template< class _Facet> locale 
# 63
locale::combine(const locale &__other) const 
# 64
{ 
# 65
_Impl *__tmp = new _Impl(*(_M_impl), 1); 
# 66
try 
# 67
{ 
# 68
__tmp->_M_replace_facet(__other._M_impl, &_Facet::id); 
# 69
} 
# 70
catch (...) 
# 71
{ 
# 72
__tmp->_M_remove_reference(); 
# 73
throw; 
# 74
}  
# 75
return ((locale)(__tmp)); 
# 76
} 
# 78
template< class _CharT, class _Traits, class _Alloc> bool 
# 81
locale::operator()(const basic_string< _CharT, _Traits, _Alloc>  &__s1, const basic_string< _CharT, _Traits, _Alloc>  &
# 82
__s2) const 
# 83
{ 
# 84
typedef std::collate< _CharT>  __collate_type; 
# 85
const __collate_type &__collate = use_facet< std::collate< _CharT> > (*this); 
# 86
return (__collate.compare((__s1.data()), (__s1.data()) + (__s1.length()), (__s2.data()), (__s2.data()) + (__s2.length()))) < 0; 
# 88
} 
# 102
template< class _Facet> bool 
# 104
has_facet(const locale &__loc) throw() 
# 105
{ 
# 106
const size_t __i = (_Facet::id._M_id)(); 
# 107
const locale::facet **__facets = (__loc._M_impl)->_M_facets; 
# 108
return (__i < ((__loc._M_impl)->_M_facets_size)) && (dynamic_cast< const _Facet *>(__facets[__i])); 
# 114
} 
# 130
template< class _Facet> const _Facet &
# 132
use_facet(const locale &__loc) 
# 133
{ 
# 134
const size_t __i = (_Facet::id._M_id)(); 
# 135
const locale::facet **__facets = (__loc._M_impl)->_M_facets; 
# 136
if ((__i >= ((__loc._M_impl)->_M_facets_size)) || (!(__facets[__i]))) { 
# 137
__throw_bad_cast(); }  
# 139
return dynamic_cast< const _Facet &>(*(__facets[__i])); 
# 143
} 
# 147
template< class _CharT> int 
# 149
collate< _CharT> ::_M_compare(const _CharT *, const _CharT *) const throw() 
# 150
{ return 0; } 
# 153
template< class _CharT> size_t 
# 155
collate< _CharT> ::_M_transform(_CharT *, const _CharT *, size_t) const throw() 
# 156
{ return 0; } 
# 158
template< class _CharT> int 
# 161
collate< _CharT> ::do_compare(const _CharT *__lo1, const _CharT *__hi1, const _CharT *
# 162
__lo2, const _CharT *__hi2) const 
# 163
{ 
# 166
const string_type __one(__lo1, __hi1); 
# 167
const string_type __two(__lo2, __hi2); 
# 169
const _CharT *__p = (__one.c_str()); 
# 170
const _CharT *__pend = (__one.data()) + (__one.length()); 
# 171
const _CharT *__q = (__two.c_str()); 
# 172
const _CharT *__qend = (__two.data()) + (__two.length()); 
# 177
for (; ;) 
# 178
{ 
# 179
const int __res = _M_compare(__p, __q); 
# 180
if (__res) { 
# 181
return __res; }  
# 183
__p += char_traits< _CharT> ::length(__p); 
# 184
__q += char_traits< _CharT> ::length(__q); 
# 185
if ((__p == __pend) && (__q == __qend)) { 
# 186
return 0; } else { 
# 187
if (__p == __pend) { 
# 188
return -1; } else { 
# 189
if (__q == __qend) { 
# 190
return 1; }  }  }  
# 192
__p++; 
# 193
__q++; 
# 194
}  
# 195
} 
# 197
template< class _CharT> typename collate< _CharT> ::string_type 
# 200
collate< _CharT> ::do_transform(const _CharT *__lo, const _CharT *__hi) const 
# 201
{ 
# 202
string_type __ret; 
# 205
const string_type __str(__lo, __hi); 
# 207
const _CharT *__p = (__str.c_str()); 
# 208
const _CharT *__pend = (__str.data()) + (__str.length()); 
# 210
size_t __len = (__hi - __lo) * 2; 
# 212
_CharT *__c = new _CharT [__len]; 
# 214
try 
# 215
{ 
# 219
for (; ;) 
# 220
{ 
# 222
size_t __res = _M_transform(__c, __p, __len); 
# 225
if (__res >= __len) 
# 226
{ 
# 227
__len = (__res + (1)); 
# 228
(delete [] __c), (__c = 0); 
# 229
__c = (new _CharT [__len]); 
# 230
__res = _M_transform(__c, __p, __len); 
# 231
}  
# 233
(__ret.append(__c, __res)); 
# 234
__p += char_traits< _CharT> ::length(__p); 
# 235
if (__p == __pend) { 
# 236
break; }  
# 238
__p++; 
# 239
(__ret.push_back(_CharT())); 
# 240
}  
# 241
} 
# 242
catch (...) 
# 243
{ 
# 244
delete [] __c; 
# 245
throw; 
# 246
}  
# 248
delete [] __c; 
# 250
return __ret; 
# 251
} 
# 253
template< class _CharT> long 
# 256
collate< _CharT> ::do_hash(const _CharT *__lo, const _CharT *__hi) const 
# 257
{ 
# 258
unsigned long __val = (0); 
# 259
for (; __lo < __hi; ++__lo) { 
# 260
__val = ((*__lo) + ((__val << 7) | (__val >> (__gnu_cxx::__numeric_traits_integer< unsigned long> ::__digits - 7)))); }  
# 264
return static_cast< long>(__val); 
# 265
} 
# 270
extern template class collate< char> ;
# 271
extern template class collate_byname< char> ;
# 273
extern template const collate< char>  &use_facet< collate< char> > (const locale &);
# 277
extern template bool has_facet< collate< char> > (const locale &) throw();
# 282
extern template class collate< wchar_t> ;
# 283
extern template class collate_byname< wchar_t> ;
# 285
extern template const collate< wchar_t>  &use_facet< collate< wchar_t> > (const locale &);
# 289
extern template bool has_facet< collate< wchar_t> > (const locale &) throw();
# 296
}
# 43 "/usr/include/c++/4.8.2/bits/ios_base.h" 3
namespace std __attribute((__visibility__("default"))) { 
# 51
enum _Ios_Fmtflags { 
# 53
_S_boolalpha = 1, 
# 54
_S_dec, 
# 55
_S_fixed = 4, 
# 56
_S_hex = 8, 
# 57
_S_internal = 16, 
# 58
_S_left = 32, 
# 59
_S_oct = 64, 
# 60
_S_right = 128, 
# 61
_S_scientific = 256, 
# 62
_S_showbase = 512, 
# 63
_S_showpoint = 1024, 
# 64
_S_showpos = 2048, 
# 65
_S_skipws = 4096, 
# 66
_S_unitbuf = 8192, 
# 67
_S_uppercase = 16384, 
# 68
_S_adjustfield = 176, 
# 69
_S_basefield = 74, 
# 70
_S_floatfield = 260, 
# 71
_S_ios_fmtflags_end = 65536
# 72
}; 
# 75
inline _Ios_Fmtflags operator&(_Ios_Fmtflags __a, _Ios_Fmtflags __b) 
# 76
{ return (_Ios_Fmtflags)((static_cast< int>(__a)) & (static_cast< int>(__b))); } 
# 79
inline _Ios_Fmtflags operator|(_Ios_Fmtflags __a, _Ios_Fmtflags __b) 
# 80
{ return (_Ios_Fmtflags)((static_cast< int>(__a)) | (static_cast< int>(__b))); } 
# 83
inline _Ios_Fmtflags operator^(_Ios_Fmtflags __a, _Ios_Fmtflags __b) 
# 84
{ return (_Ios_Fmtflags)((static_cast< int>(__a)) ^ (static_cast< int>(__b))); } 
# 87
inline _Ios_Fmtflags operator~(_Ios_Fmtflags __a) 
# 88
{ return (_Ios_Fmtflags)(~(static_cast< int>(__a))); } 
# 91
inline const _Ios_Fmtflags &operator|=(_Ios_Fmtflags &__a, _Ios_Fmtflags __b) 
# 92
{ return __a = ((__a | __b)); } 
# 95
inline const _Ios_Fmtflags &operator&=(_Ios_Fmtflags &__a, _Ios_Fmtflags __b) 
# 96
{ return __a = ((__a & __b)); } 
# 99
inline const _Ios_Fmtflags &operator^=(_Ios_Fmtflags &__a, _Ios_Fmtflags __b) 
# 100
{ return __a = ((__a ^ __b)); } 
# 103
enum _Ios_Openmode { 
# 105
_S_app = 1, 
# 106
_S_ate, 
# 107
_S_bin = 4, 
# 108
_S_in = 8, 
# 109
_S_out = 16, 
# 110
_S_trunc = 32, 
# 111
_S_ios_openmode_end = 65536
# 112
}; 
# 115
inline _Ios_Openmode operator&(_Ios_Openmode __a, _Ios_Openmode __b) 
# 116
{ return (_Ios_Openmode)((static_cast< int>(__a)) & (static_cast< int>(__b))); } 
# 119
inline _Ios_Openmode operator|(_Ios_Openmode __a, _Ios_Openmode __b) 
# 120
{ return (_Ios_Openmode)((static_cast< int>(__a)) | (static_cast< int>(__b))); } 
# 123
inline _Ios_Openmode operator^(_Ios_Openmode __a, _Ios_Openmode __b) 
# 124
{ return (_Ios_Openmode)((static_cast< int>(__a)) ^ (static_cast< int>(__b))); } 
# 127
inline _Ios_Openmode operator~(_Ios_Openmode __a) 
# 128
{ return (_Ios_Openmode)(~(static_cast< int>(__a))); } 
# 131
inline const _Ios_Openmode &operator|=(_Ios_Openmode &__a, _Ios_Openmode __b) 
# 132
{ return __a = ((__a | __b)); } 
# 135
inline const _Ios_Openmode &operator&=(_Ios_Openmode &__a, _Ios_Openmode __b) 
# 136
{ return __a = ((__a & __b)); } 
# 139
inline const _Ios_Openmode &operator^=(_Ios_Openmode &__a, _Ios_Openmode __b) 
# 140
{ return __a = ((__a ^ __b)); } 
# 143
enum _Ios_Iostate { 
# 145
_S_goodbit, 
# 146
_S_badbit, 
# 147
_S_eofbit, 
# 148
_S_failbit = 4, 
# 149
_S_ios_iostate_end = 65536
# 150
}; 
# 153
inline _Ios_Iostate operator&(_Ios_Iostate __a, _Ios_Iostate __b) 
# 154
{ return (_Ios_Iostate)((static_cast< int>(__a)) & (static_cast< int>(__b))); } 
# 157
inline _Ios_Iostate operator|(_Ios_Iostate __a, _Ios_Iostate __b) 
# 158
{ return (_Ios_Iostate)((static_cast< int>(__a)) | (static_cast< int>(__b))); } 
# 161
inline _Ios_Iostate operator^(_Ios_Iostate __a, _Ios_Iostate __b) 
# 162
{ return (_Ios_Iostate)((static_cast< int>(__a)) ^ (static_cast< int>(__b))); } 
# 165
inline _Ios_Iostate operator~(_Ios_Iostate __a) 
# 166
{ return (_Ios_Iostate)(~(static_cast< int>(__a))); } 
# 169
inline const _Ios_Iostate &operator|=(_Ios_Iostate &__a, _Ios_Iostate __b) 
# 170
{ return __a = ((__a | __b)); } 
# 173
inline const _Ios_Iostate &operator&=(_Ios_Iostate &__a, _Ios_Iostate __b) 
# 174
{ return __a = ((__a & __b)); } 
# 177
inline const _Ios_Iostate &operator^=(_Ios_Iostate &__a, _Ios_Iostate __b) 
# 178
{ return __a = ((__a ^ __b)); } 
# 181
enum _Ios_Seekdir { 
# 183
_S_beg, 
# 184
_S_cur, 
# 185
_S_end, 
# 186
_S_ios_seekdir_end = 65536
# 187
}; 
# 199
class ios_base { 
# 209
public: class failure : public exception { 
# 215
public: explicit failure(const string & __str) throw(); 
# 220
virtual ~failure() throw(); 
# 223
virtual const char *what() const throw(); 
# 226
private: string _M_msg; 
# 227
}; 
# 255
typedef _Ios_Fmtflags fmtflags; 
# 258
static const fmtflags boolalpha = _S_boolalpha; 
# 261
static const fmtflags dec = _S_dec; 
# 264
static const fmtflags fixed = _S_fixed; 
# 267
static const fmtflags hex = _S_hex; 
# 272
static const fmtflags internal = _S_internal; 
# 276
static const fmtflags left = _S_left; 
# 279
static const fmtflags oct = _S_oct; 
# 283
static const fmtflags right = _S_right; 
# 286
static const fmtflags scientific = _S_scientific; 
# 290
static const fmtflags showbase = _S_showbase; 
# 294
static const fmtflags showpoint = _S_showpoint; 
# 297
static const fmtflags showpos = _S_showpos; 
# 300
static const fmtflags skipws = _S_skipws; 
# 303
static const fmtflags unitbuf = _S_unitbuf; 
# 307
static const fmtflags uppercase = _S_uppercase; 
# 310
static const fmtflags adjustfield = _S_adjustfield; 
# 313
static const fmtflags basefield = _S_basefield; 
# 316
static const fmtflags floatfield = _S_floatfield; 
# 330
typedef _Ios_Iostate iostate; 
# 334
static const iostate badbit = _S_badbit; 
# 337
static const iostate eofbit = _S_eofbit; 
# 342
static const iostate failbit = _S_failbit; 
# 345
static const iostate goodbit = _S_goodbit; 
# 361
typedef _Ios_Openmode openmode; 
# 364
static const openmode app = _S_app; 
# 367
static const openmode ate = _S_ate; 
# 372
static const openmode binary = _S_bin; 
# 375
static const openmode in = _S_in; 
# 378
static const openmode out = _S_out; 
# 381
static const openmode trunc = _S_trunc; 
# 393
typedef _Ios_Seekdir seekdir; 
# 396
static const seekdir beg = _S_beg; 
# 399
static const seekdir cur = _S_cur; 
# 402
static const seekdir end = _S_end; 
# 405
typedef int io_state; 
# 406
typedef int open_mode; 
# 407
typedef int seek_dir; 
# 409
typedef std::streampos streampos; 
# 410
typedef std::streamoff streamoff; 
# 419
enum event { 
# 421
erase_event, 
# 422
imbue_event, 
# 423
copyfmt_event
# 424
}; 
# 436
typedef void (*event_callback)(event __e, ios_base & __b, int __i); 
# 449
void register_callback(event_callback __fn, int __index); 
# 452
protected: streamsize _M_precision; 
# 453
streamsize _M_width; 
# 454
fmtflags _M_flags; 
# 455
iostate _M_exception; 
# 456
iostate _M_streambuf_state; 
# 460
struct _Callback_list { 
# 463
_Callback_list *_M_next; 
# 464
event_callback _M_fn; 
# 465
int _M_index; 
# 466
_Atomic_word _M_refcount; 
# 468
_Callback_list(event_callback __fn, int __index, _Callback_list *
# 469
__cb) : _M_next(__cb), _M_fn(__fn), _M_index(__index), _M_refcount(0) 
# 470
{ } 
# 473
void _M_add_reference() { __gnu_cxx::__atomic_add_dispatch(&(_M_refcount), 1); } 
# 477
int _M_remove_reference() 
# 478
{ 
# 480
; 
# 481
int __res = __gnu_cxx::__exchange_and_add_dispatch(&(_M_refcount), -1); 
# 482
if (__res == 0) 
# 483
{ 
# 484
; 
# 485
}  
# 486
return __res; 
# 487
} 
# 488
}; 
# 490
_Callback_list *_M_callbacks; 
# 493
void _M_call_callbacks(event __ev) throw(); 
# 496
void _M_dispose_callbacks() throw(); 
# 499
struct _Words { 
# 501
void *_M_pword; 
# 502
long _M_iword; 
# 503
_Words() : _M_pword((0)), _M_iword((0)) { } 
# 504
}; 
# 507
_Words _M_word_zero; 
# 511
enum { _S_local_word_size = 8}; 
# 512
_Words _M_local_word[_S_local_word_size]; 
# 515
int _M_word_size; 
# 516
_Words *_M_word; 
# 519
_Words &_M_grow_words(int __index, bool __iword); 
# 522
locale _M_ios_locale; 
# 525
void _M_init() throw(); 
# 533
public: class Init { 
# 535
friend class ios_base; 
# 537
public: Init(); 
# 538
~Init(); 
# 541
private: static _Atomic_word _S_refcount; 
# 542
static bool _S_synced_with_stdio; 
# 543
}; 
# 551
fmtflags flags() const 
# 552
{ return _M_flags; } 
# 562
fmtflags flags(fmtflags __fmtfl) 
# 563
{ 
# 564
fmtflags __old = _M_flags; 
# 565
(_M_flags) = __fmtfl; 
# 566
return __old; 
# 567
} 
# 578
fmtflags setf(fmtflags __fmtfl) 
# 579
{ 
# 580
fmtflags __old = _M_flags; 
# 581
((_M_flags) |= __fmtfl); 
# 582
return __old; 
# 583
} 
# 595
fmtflags setf(fmtflags __fmtfl, fmtflags __mask) 
# 596
{ 
# 597
fmtflags __old = _M_flags; 
# 598
((_M_flags) &= ((~__mask))); 
# 599
((_M_flags) |= ((__fmtfl & __mask))); 
# 600
return __old; 
# 601
} 
# 610
void unsetf(fmtflags __mask) 
# 611
{ ((_M_flags) &= ((~__mask))); } 
# 621
streamsize precision() const 
# 622
{ return _M_precision; } 
# 630
streamsize precision(streamsize __prec) 
# 631
{ 
# 632
streamsize __old = _M_precision; 
# 633
(_M_precision) = __prec; 
# 634
return __old; 
# 635
} 
# 644
streamsize width() const 
# 645
{ return _M_width; } 
# 653
streamsize width(streamsize __wide) 
# 654
{ 
# 655
streamsize __old = _M_width; 
# 656
(_M_width) = __wide; 
# 657
return __old; 
# 658
} 
# 672
static bool sync_with_stdio(bool __sync = true); 
# 684
locale imbue(const locale & __loc) throw(); 
# 695
locale getloc() const 
# 696
{ return _M_ios_locale; } 
# 706
const locale &_M_getloc() const 
# 707
{ return _M_ios_locale; } 
# 725
static int xalloc() throw(); 
# 741
long &iword(int __ix) 
# 742
{ 
# 743
_Words &__word = (__ix < (_M_word_size)) ? (_M_word)[__ix] : this->_M_grow_words(__ix, true); 
# 745
return __word._M_iword; 
# 746
} 
# 762
void *&pword(int __ix) 
# 763
{ 
# 764
_Words &__word = (__ix < (_M_word_size)) ? (_M_word)[__ix] : this->_M_grow_words(__ix, false); 
# 766
return __word._M_pword; 
# 767
} 
# 778
virtual ~ios_base(); 
# 781
protected: ios_base() throw(); 
# 786
private: ios_base(const ios_base &); 
# 789
ios_base &operator=(const ios_base &); 
# 790
}; 
# 795
inline ios_base &boolalpha(ios_base &__base) 
# 796
{ 
# 797
__base.setf(ios_base::boolalpha); 
# 798
return __base; 
# 799
} 
# 803
inline ios_base &noboolalpha(ios_base &__base) 
# 804
{ 
# 805
__base.unsetf(ios_base::boolalpha); 
# 806
return __base; 
# 807
} 
# 811
inline ios_base &showbase(ios_base &__base) 
# 812
{ 
# 813
__base.setf(ios_base::showbase); 
# 814
return __base; 
# 815
} 
# 819
inline ios_base &noshowbase(ios_base &__base) 
# 820
{ 
# 821
__base.unsetf(ios_base::showbase); 
# 822
return __base; 
# 823
} 
# 827
inline ios_base &showpoint(ios_base &__base) 
# 828
{ 
# 829
__base.setf(ios_base::showpoint); 
# 830
return __base; 
# 831
} 
# 835
inline ios_base &noshowpoint(ios_base &__base) 
# 836
{ 
# 837
__base.unsetf(ios_base::showpoint); 
# 838
return __base; 
# 839
} 
# 843
inline ios_base &showpos(ios_base &__base) 
# 844
{ 
# 845
__base.setf(ios_base::showpos); 
# 846
return __base; 
# 847
} 
# 851
inline ios_base &noshowpos(ios_base &__base) 
# 852
{ 
# 853
__base.unsetf(ios_base::showpos); 
# 854
return __base; 
# 855
} 
# 859
inline ios_base &skipws(ios_base &__base) 
# 860
{ 
# 861
__base.setf(ios_base::skipws); 
# 862
return __base; 
# 863
} 
# 867
inline ios_base &noskipws(ios_base &__base) 
# 868
{ 
# 869
__base.unsetf(ios_base::skipws); 
# 870
return __base; 
# 871
} 
# 875
inline ios_base &uppercase(ios_base &__base) 
# 876
{ 
# 877
__base.setf(ios_base::uppercase); 
# 878
return __base; 
# 879
} 
# 883
inline ios_base &nouppercase(ios_base &__base) 
# 884
{ 
# 885
__base.unsetf(ios_base::uppercase); 
# 886
return __base; 
# 887
} 
# 891
inline ios_base &unitbuf(ios_base &__base) 
# 892
{ 
# 893
__base.setf(ios_base::unitbuf); 
# 894
return __base; 
# 895
} 
# 899
inline ios_base &nounitbuf(ios_base &__base) 
# 900
{ 
# 901
__base.unsetf(ios_base::unitbuf); 
# 902
return __base; 
# 903
} 
# 908
inline ios_base &internal(ios_base &__base) 
# 909
{ 
# 910
__base.setf(ios_base::internal, ios_base::adjustfield); 
# 911
return __base; 
# 912
} 
# 916
inline ios_base &left(ios_base &__base) 
# 917
{ 
# 918
__base.setf(ios_base::left, ios_base::adjustfield); 
# 919
return __base; 
# 920
} 
# 924
inline ios_base &right(ios_base &__base) 
# 925
{ 
# 926
__base.setf(ios_base::right, ios_base::adjustfield); 
# 927
return __base; 
# 928
} 
# 933
inline ios_base &dec(ios_base &__base) 
# 934
{ 
# 935
__base.setf(ios_base::dec, ios_base::basefield); 
# 936
return __base; 
# 937
} 
# 941
inline ios_base &hex(ios_base &__base) 
# 942
{ 
# 943
__base.setf(ios_base::hex, ios_base::basefield); 
# 944
return __base; 
# 945
} 
# 949
inline ios_base &oct(ios_base &__base) 
# 950
{ 
# 951
__base.setf(ios_base::oct, ios_base::basefield); 
# 952
return __base; 
# 953
} 
# 958
inline ios_base &fixed(ios_base &__base) 
# 959
{ 
# 960
__base.setf(ios_base::fixed, ios_base::floatfield); 
# 961
return __base; 
# 962
} 
# 966
inline ios_base &scientific(ios_base &__base) 
# 967
{ 
# 968
__base.setf(ios_base::scientific, ios_base::floatfield); 
# 969
return __base; 
# 970
} 
# 973
}
# 45 "/usr/include/c++/4.8.2/streambuf" 3
namespace std __attribute((__visibility__("default"))) { 
# 49
template< class _CharT, class _Traits> streamsize __copy_streambufs_eof(basic_streambuf< _CharT, _Traits>  *, basic_streambuf< _CharT, _Traits>  *, bool &); 
# 119
template< class _CharT, class _Traits> 
# 120
class basic_streambuf { 
# 129
public: typedef _CharT char_type; 
# 130
typedef _Traits traits_type; 
# 131
typedef typename _Traits::int_type int_type; 
# 132
typedef typename _Traits::pos_type pos_type; 
# 133
typedef typename _Traits::off_type off_type; 
# 138
typedef basic_streambuf __streambuf_type; 
# 141
friend class basic_ios< _CharT, _Traits> ; 
# 142
friend class basic_istream< _CharT, _Traits> ; 
# 143
friend class basic_ostream< _CharT, _Traits> ; 
# 144
friend class istreambuf_iterator< _CharT, _Traits> ; 
# 145
friend class ostreambuf_iterator< _CharT, _Traits> ; 
# 148
friend streamsize __copy_streambufs_eof<> (basic_streambuf *, basic_streambuf *, bool &); 
# 150
template< bool _IsMove, class _CharT2> friend typename __gnu_cxx::__enable_if< __is_char< _CharT2> ::__value, _CharT2 *> ::__type __copy_move_a2(istreambuf_iterator< _CharT2> , istreambuf_iterator< _CharT2> , _CharT2 *); 
# 156
template< class _CharT2> friend typename __gnu_cxx::__enable_if< __is_char< _CharT2> ::__value, istreambuf_iterator< _CharT2> > ::__type find(istreambuf_iterator< _CharT2> , istreambuf_iterator< _CharT2> , const _CharT2 &); 
# 162
template< class _CharT2, class _Traits2> friend basic_istream< _CharT2, _Traits2>  &operator>>(basic_istream< _CharT2, _Traits2>  &, _CharT2 *); 
# 166
template< class _CharT2, class _Traits2, class _Alloc> friend basic_istream< _CharT2, _Traits2>  &operator>>(basic_istream< _CharT2, _Traits2>  &, basic_string< _CharT2, _Traits2, _Alloc>  &); 
# 171
template< class _CharT2, class _Traits2, class _Alloc> friend basic_istream< _CharT2, _Traits2>  &getline(basic_istream< _CharT2, _Traits2>  &, basic_string< _CharT2, _Traits2, _Alloc>  &, _CharT2); 
# 184
protected: char_type *_M_in_beg; 
# 185
char_type *_M_in_cur; 
# 186
char_type *_M_in_end; 
# 187
char_type *_M_out_beg; 
# 188
char_type *_M_out_cur; 
# 189
char_type *_M_out_end; 
# 192
locale _M_buf_locale; 
# 197
public: virtual ~basic_streambuf() 
# 198
{ } 
# 209
locale pubimbue(const locale &__loc) 
# 210
{ 
# 211
locale __tmp(this->getloc()); 
# 212
this->imbue(__loc); 
# 213
((_M_buf_locale) = __loc); 
# 214
return __tmp; 
# 215
} 
# 226
locale getloc() const 
# 227
{ return _M_buf_locale; } 
# 239
basic_streambuf *pubsetbuf(char_type *__s, streamsize __n) 
# 240
{ return this->setbuf(__s, __n); } 
# 251
pos_type pubseekoff(off_type __off, ios_base::seekdir __way, ios_base::openmode 
# 252
__mode = (ios_base::in | ios_base::out)) 
# 253
{ return this->seekoff(__off, __way, __mode); } 
# 263
pos_type pubseekpos(pos_type __sp, ios_base::openmode 
# 264
__mode = (ios_base::in | ios_base::out)) 
# 265
{ return this->seekpos(__sp, __mode); } 
# 271
int pubsync() { return this->sync(); } 
# 284
streamsize in_avail() 
# 285
{ 
# 286
const streamsize __ret = this->egptr() - this->gptr(); 
# 287
return (__ret) ? __ret : this->showmanyc(); 
# 288
} 
# 298
int_type snextc() 
# 299
{ 
# 300
int_type __ret = traits_type::eof(); 
# 301
if (__builtin_expect(!traits_type::eq_int_type(this->sbumpc(), __ret), true)) { 
# 303
__ret = this->sgetc(); }  
# 304
return __ret; 
# 305
} 
# 316
int_type sbumpc() 
# 317
{ 
# 318
int_type __ret; 
# 319
if (__builtin_expect(this->gptr() < this->egptr(), true)) 
# 320
{ 
# 321
__ret = traits_type::to_int_type(*this->gptr()); 
# 322
this->gbump(1); 
# 323
} else { 
# 325
__ret = this->uflow(); }  
# 326
return __ret; 
# 327
} 
# 338
int_type sgetc() 
# 339
{ 
# 340
int_type __ret; 
# 341
if (__builtin_expect(this->gptr() < this->egptr(), true)) { 
# 342
__ret = traits_type::to_int_type(*this->gptr()); } else { 
# 344
__ret = this->underflow(); }  
# 345
return __ret; 
# 346
} 
# 357
streamsize sgetn(char_type *__s, streamsize __n) 
# 358
{ return this->xsgetn(__s, __n); } 
# 372
int_type sputbackc(char_type __c) 
# 373
{ 
# 374
int_type __ret; 
# 375
const bool __testpos = this->eback() < this->gptr(); 
# 376
if (__builtin_expect((!__testpos) || (!traits_type::eq(__c, this->gptr()[-1])), false)) { 
# 378
__ret = this->pbackfail(traits_type::to_int_type(__c)); } else 
# 380
{ 
# 381
this->gbump(-1); 
# 382
__ret = traits_type::to_int_type(*this->gptr()); 
# 383
}  
# 384
return __ret; 
# 385
} 
# 397
int_type sungetc() 
# 398
{ 
# 399
int_type __ret; 
# 400
if (__builtin_expect(this->eback() < this->gptr(), true)) 
# 401
{ 
# 402
this->gbump(-1); 
# 403
__ret = traits_type::to_int_type(*this->gptr()); 
# 404
} else { 
# 406
__ret = this->pbackfail(); }  
# 407
return __ret; 
# 408
} 
# 424
int_type sputc(char_type __c) 
# 425
{ 
# 426
int_type __ret; 
# 427
if (__builtin_expect(this->pptr() < this->epptr(), true)) 
# 428
{ 
# 429
(*this->pptr()) = __c; 
# 430
this->pbump(1); 
# 431
__ret = traits_type::to_int_type(__c); 
# 432
} else { 
# 434
__ret = this->overflow(traits_type::to_int_type(__c)); }  
# 435
return __ret; 
# 436
} 
# 450
streamsize sputn(const char_type *__s, streamsize __n) 
# 451
{ return this->xsputn(__s, __n); } 
# 463
protected: basic_streambuf() : _M_in_beg((0)), _M_in_cur((0)), _M_in_end((0)), _M_out_beg((0)), _M_out_cur((0)), _M_out_end((0)), _M_buf_locale(locale()) 
# 467
{ } 
# 482
char_type *eback() const { return _M_in_beg; } 
# 485
char_type *gptr() const { return _M_in_cur; } 
# 488
char_type *egptr() const { return _M_in_end; } 
# 498
void gbump(int __n) { (_M_in_cur) += __n; } 
# 509
void setg(char_type *__gbeg, char_type *__gnext, char_type *__gend) 
# 510
{ 
# 511
(_M_in_beg) = __gbeg; 
# 512
(_M_in_cur) = __gnext; 
# 513
(_M_in_end) = __gend; 
# 514
} 
# 529
char_type *pbase() const { return _M_out_beg; } 
# 532
char_type *pptr() const { return _M_out_cur; } 
# 535
char_type *epptr() const { return _M_out_end; } 
# 545
void pbump(int __n) { (_M_out_cur) += __n; } 
# 555
void setp(char_type *__pbeg, char_type *__pend) 
# 556
{ 
# 557
(_M_out_beg) = ((_M_out_cur) = __pbeg); 
# 558
(_M_out_end) = __pend; 
# 559
} 
# 576
virtual void imbue(const locale &__loc) 
# 577
{ } 
# 591
virtual basic_streambuf *setbuf(char_type *, streamsize) 
# 592
{ return this; } 
# 602
virtual pos_type seekoff(off_type, ios_base::seekdir, ios_base::openmode = (ios_base::in | ios_base::out)) 
# 604
{ return (pos_type)((off_type)(-1)); } 
# 614
virtual pos_type seekpos(pos_type, ios_base::openmode = (ios_base::in | ios_base::out)) 
# 616
{ return (pos_type)((off_type)(-1)); } 
# 627
virtual int sync() { return 0; } 
# 649
virtual streamsize showmanyc() { return 0; } 
# 665
virtual streamsize xsgetn(char_type * __s, streamsize __n); 
# 687
virtual int_type underflow() 
# 688
{ return traits_type::eof(); } 
# 700
virtual int_type uflow() 
# 701
{ 
# 702
int_type __ret = traits_type::eof(); 
# 703
const bool __testeof = traits_type::eq_int_type(this->underflow(), __ret); 
# 705
if (!__testeof) 
# 706
{ 
# 707
__ret = traits_type::to_int_type(*this->gptr()); 
# 708
this->gbump(1); 
# 709
}  
# 710
return __ret; 
# 711
} 
# 724
virtual int_type pbackfail(int_type __c = traits_type::eof()) 
# 725
{ return traits_type::eof(); } 
# 742
virtual streamsize xsputn(const char_type * __s, streamsize __n); 
# 768
virtual int_type overflow(int_type __c = traits_type::eof()) 
# 769
{ return traits_type::eof(); } 
# 783
public: void stossc() 
# 784
{ 
# 785
if (this->gptr() < this->egptr()) { 
# 786
this->gbump(1); } else { 
# 788
this->uflow(); }  
# 789
} 
# 794
void __safe_gbump(streamsize __n) { (_M_in_cur) += __n; } 
# 797
void __safe_pbump(streamsize __n) { (_M_out_cur) += __n; } 
# 802
private: basic_streambuf(const basic_streambuf &__sb) : _M_in_beg(__sb._M_in_beg), _M_in_cur(__sb._M_in_cur), _M_in_end(__sb._M_in_end), _M_out_beg(__sb._M_out_beg), _M_out_cur(__sb._M_out_cur), _M_out_end(__sb._M_out_end), _M_buf_locale(__sb._M_buf_locale) 
# 807
{ } 
# 810
basic_streambuf &operator=(const basic_streambuf &__sb) 
# 811
{ 
# 812
(_M_in_beg) = (__sb._M_in_beg); 
# 813
(_M_in_cur) = (__sb._M_in_cur); 
# 814
(_M_in_end) = (__sb._M_in_end); 
# 815
(_M_out_beg) = (__sb._M_out_beg); 
# 816
(_M_out_cur) = (__sb._M_out_cur); 
# 817
(_M_out_end) = (__sb._M_out_end); 
# 818
((_M_buf_locale) = (__sb._M_buf_locale)); 
# 819
return *this; 
# 820
} 
# 821
}; 
# 826
template<> streamsize __copy_streambufs_eof(basic_streambuf< char, char_traits< char> >  * __sbin, basic_streambuf< char, char_traits< char> >  * __sbout, bool & __ineof); 
# 831
template<> streamsize __copy_streambufs_eof(basic_streambuf< wchar_t, char_traits< wchar_t> >  * __sbin, basic_streambuf< wchar_t, char_traits< wchar_t> >  * __sbout, bool & __ineof); 
# 836
}
# 39 "/usr/include/c++/4.8.2/bits/streambuf.tcc" 3
namespace std __attribute((__visibility__("default"))) { 
# 43
template< class _CharT, class _Traits> streamsize 
# 46
basic_streambuf< _CharT, _Traits> ::xsgetn(char_type *__s, streamsize __n) 
# 47
{ 
# 48
streamsize __ret = (0); 
# 49
while (__ret < __n) 
# 50
{ 
# 51
const streamsize __buf_len = this->egptr() - this->gptr(); 
# 52
if (__buf_len) 
# 53
{ 
# 54
const streamsize __remaining = __n - __ret; 
# 55
const streamsize __len = std::min(__buf_len, __remaining); 
# 56
traits_type::copy(__s, this->gptr(), __len); 
# 57
__ret += __len; 
# 58
__s += __len; 
# 59
this->__safe_gbump(__len); 
# 60
}  
# 62
if (__ret < __n) 
# 63
{ 
# 64
const int_type __c = this->uflow(); 
# 65
if (!traits_type::eq_int_type(__c, traits_type::eof())) 
# 66
{ 
# 67
traits_type::assign(*(__s++), traits_type::to_char_type(__c)); 
# 68
++__ret; 
# 69
} else { 
# 71
break; }  
# 72
}  
# 73
}  
# 74
return __ret; 
# 75
} 
# 77
template< class _CharT, class _Traits> streamsize 
# 80
basic_streambuf< _CharT, _Traits> ::xsputn(const char_type *__s, streamsize __n) 
# 81
{ 
# 82
streamsize __ret = (0); 
# 83
while (__ret < __n) 
# 84
{ 
# 85
const streamsize __buf_len = this->epptr() - this->pptr(); 
# 86
if (__buf_len) 
# 87
{ 
# 88
const streamsize __remaining = __n - __ret; 
# 89
const streamsize __len = std::min(__buf_len, __remaining); 
# 90
traits_type::copy(this->pptr(), __s, __len); 
# 91
__ret += __len; 
# 92
__s += __len; 
# 93
this->__safe_pbump(__len); 
# 94
}  
# 96
if (__ret < __n) 
# 97
{ 
# 98
int_type __c = this->overflow(traits_type::to_int_type(*__s)); 
# 99
if (!traits_type::eq_int_type(__c, traits_type::eof())) 
# 100
{ 
# 101
++__ret; 
# 102
++__s; 
# 103
} else { 
# 105
break; }  
# 106
}  
# 107
}  
# 108
return __ret; 
# 109
} 
# 114
template< class _CharT, class _Traits> streamsize 
# 116
__copy_streambufs_eof(basic_streambuf< _CharT, _Traits>  *__sbin, basic_streambuf< _CharT, _Traits>  *
# 117
__sbout, bool &
# 118
__ineof) 
# 119
{ 
# 120
streamsize __ret = (0); 
# 121
__ineof = true; 
# 122
typename _Traits::int_type __c = (__sbin->sgetc()); 
# 123
while (!_Traits::eq_int_type(__c, _Traits::eof())) 
# 124
{ 
# 125
__c = (__sbout->sputc(_Traits::to_char_type(__c))); 
# 126
if (_Traits::eq_int_type(__c, _Traits::eof())) 
# 127
{ 
# 128
__ineof = false; 
# 129
break; 
# 130
}  
# 131
++__ret; 
# 132
__c = (__sbin->snextc()); 
# 133
}  
# 134
return __ret; 
# 135
} 
# 137
template< class _CharT, class _Traits> inline streamsize 
# 139
__copy_streambufs(basic_streambuf< _CharT, _Traits>  *__sbin, basic_streambuf< _CharT, _Traits>  *
# 140
__sbout) 
# 141
{ 
# 142
bool __ineof; 
# 143
return __copy_streambufs_eof(__sbin, __sbout, __ineof); 
# 144
} 
# 149
extern template class basic_streambuf< char, char_traits< char> > ;
# 150
extern template streamsize __copy_streambufs(basic_streambuf< char, char_traits< char> >  * __sbin, basic_streambuf< char, char_traits< char> >  * __sbout);
# 154
extern template streamsize __copy_streambufs_eof< char, char_traits< char> > (basic_streambuf< char, char_traits< char> >  *, basic_streambuf< char, char_traits< char> >  *, bool &);
# 160
extern template class basic_streambuf< wchar_t, char_traits< wchar_t> > ;
# 161
extern template streamsize __copy_streambufs(basic_streambuf< wchar_t, char_traits< wchar_t> >  * __sbin, basic_streambuf< wchar_t, char_traits< wchar_t> >  * __sbout);
# 165
extern template streamsize __copy_streambufs_eof< wchar_t, char_traits< wchar_t> > (basic_streambuf< wchar_t, char_traits< wchar_t> >  *, basic_streambuf< wchar_t, char_traits< wchar_t> >  *, bool &);
# 173
}
# 52 "/usr/include/wctype.h" 3
typedef unsigned long wctype_t; 
# 72
enum { 
# 73
__ISwupper, 
# 74
__ISwlower, 
# 75
__ISwalpha, 
# 76
__ISwdigit, 
# 77
__ISwxdigit, 
# 78
__ISwspace, 
# 79
__ISwprint, 
# 80
__ISwgraph, 
# 81
__ISwblank, 
# 82
__ISwcntrl, 
# 83
__ISwpunct, 
# 84
__ISwalnum, 
# 86
_ISwupper = 16777216, 
# 87
_ISwlower = 33554432, 
# 88
_ISwalpha = 67108864, 
# 89
_ISwdigit = 134217728, 
# 90
_ISwxdigit = 268435456, 
# 91
_ISwspace = 536870912, 
# 92
_ISwprint = 1073741824, 
# 93
_ISwgraph = (-2147483647-1), 
# 94
_ISwblank = 65536, 
# 95
_ISwcntrl = 131072, 
# 96
_ISwpunct = 262144, 
# 97
_ISwalnum = 524288
# 98
}; 
# 102
extern "C" {
# 111
extern int iswalnum(wint_t __wc) throw(); 
# 117
extern int iswalpha(wint_t __wc) throw(); 
# 120
extern int iswcntrl(wint_t __wc) throw(); 
# 124
extern int iswdigit(wint_t __wc) throw(); 
# 128
extern int iswgraph(wint_t __wc) throw(); 
# 133
extern int iswlower(wint_t __wc) throw(); 
# 136
extern int iswprint(wint_t __wc) throw(); 
# 141
extern int iswpunct(wint_t __wc) throw(); 
# 146
extern int iswspace(wint_t __wc) throw(); 
# 151
extern int iswupper(wint_t __wc) throw(); 
# 156
extern int iswxdigit(wint_t __wc) throw(); 
# 162
extern int iswblank(wint_t __wc) throw(); 
# 171
extern wctype_t wctype(const char * __property) throw(); 
# 175
extern int iswctype(wint_t __wc, wctype_t __desc) throw(); 
# 186
typedef const __int32_t *wctrans_t; 
# 194
extern wint_t towlower(wint_t __wc) throw(); 
# 197
extern wint_t towupper(wint_t __wc) throw(); 
# 200
}
# 213
extern "C" {
# 218
extern wctrans_t wctrans(const char * __property) throw(); 
# 221
extern wint_t towctrans(wint_t __wc, wctrans_t __desc) throw(); 
# 230
extern int iswalnum_l(wint_t __wc, __locale_t __locale) throw(); 
# 236
extern int iswalpha_l(wint_t __wc, __locale_t __locale) throw(); 
# 239
extern int iswcntrl_l(wint_t __wc, __locale_t __locale) throw(); 
# 243
extern int iswdigit_l(wint_t __wc, __locale_t __locale) throw(); 
# 247
extern int iswgraph_l(wint_t __wc, __locale_t __locale) throw(); 
# 252
extern int iswlower_l(wint_t __wc, __locale_t __locale) throw(); 
# 255
extern int iswprint_l(wint_t __wc, __locale_t __locale) throw(); 
# 260
extern int iswpunct_l(wint_t __wc, __locale_t __locale) throw(); 
# 265
extern int iswspace_l(wint_t __wc, __locale_t __locale) throw(); 
# 270
extern int iswupper_l(wint_t __wc, __locale_t __locale) throw(); 
# 275
extern int iswxdigit_l(wint_t __wc, __locale_t __locale) throw(); 
# 280
extern int iswblank_l(wint_t __wc, __locale_t __locale) throw(); 
# 284
extern wctype_t wctype_l(const char * __property, __locale_t __locale) throw(); 
# 289
extern int iswctype_l(wint_t __wc, wctype_t __desc, __locale_t __locale) throw(); 
# 298
extern wint_t towlower_l(wint_t __wc, __locale_t __locale) throw(); 
# 301
extern wint_t towupper_l(wint_t __wc, __locale_t __locale) throw(); 
# 305
extern wctrans_t wctrans_l(const char * __property, __locale_t __locale) throw(); 
# 309
extern wint_t towctrans_l(wint_t __wc, wctrans_t __desc, __locale_t __locale) throw(); 
# 314
}
# 80 "/usr/include/c++/4.8.2/cwctype" 3
namespace std { 
# 82
using ::wctrans_t;
# 83
using ::wctype_t;
# 86
using ::iswalnum;
# 87
using ::iswalpha;
# 89
using ::iswblank;
# 91
using ::iswcntrl;
# 92
using ::iswctype;
# 93
using ::iswdigit;
# 94
using ::iswgraph;
# 95
using ::iswlower;
# 96
using ::iswprint;
# 97
using ::iswpunct;
# 98
using ::iswspace;
# 99
using ::iswupper;
# 100
using ::iswxdigit;
# 101
using ::towctrans;
# 102
using ::towlower;
# 103
using ::towupper;
# 104
using ::wctrans;
# 105
using ::wctype;
# 106
}
# 36 "/usr/include/c++/4.8.2/ppc64le-redhat-linux/bits/ctype_base.h" 3
namespace std __attribute((__visibility__("default"))) { 
# 41
struct ctype_base { 
# 44
typedef const int *__to_type; 
# 48
typedef unsigned short mask; 
# 49
static const mask upper = (_ISupper); 
# 50
static const mask lower = (_ISlower); 
# 51
static const mask alpha = (_ISalpha); 
# 52
static const mask digit = (_ISdigit); 
# 53
static const mask xdigit = (_ISxdigit); 
# 54
static const mask space = (_ISspace); 
# 55
static const mask print = (_ISprint); 
# 56
static const mask graph = (((_ISalpha) | (_ISdigit)) | (_ISpunct)); 
# 57
static const mask cntrl = (_IScntrl); 
# 58
static const mask punct = (_ISpunct); 
# 59
static const mask alnum = ((_ISalpha) | (_ISdigit)); 
# 60
}; 
# 63
}
# 38 "/usr/include/c++/4.8.2/bits/streambuf_iterator.h" 3
namespace std __attribute((__visibility__("default"))) { 
# 49
template< class _CharT, class _Traits> 
# 50
class istreambuf_iterator : public iterator< input_iterator_tag, _CharT, typename _Traits::off_type, _CharT *, _CharT &>  { 
# 64
public: typedef _CharT char_type; 
# 65
typedef _Traits traits_type; 
# 66
typedef typename _Traits::int_type int_type; 
# 67
typedef basic_streambuf< _CharT, _Traits>  streambuf_type; 
# 68
typedef basic_istream< _CharT, _Traits>  istream_type; 
# 71
template< class _CharT2> friend typename ::__gnu_cxx::__enable_if< __is_char< _CharT2> ::__value, ostreambuf_iterator< _CharT2> > ::__type copy(::std::istreambuf_iterator< _CharT2> , ::std::istreambuf_iterator< _CharT2> , ostreambuf_iterator< _CharT2> ); 
# 77
template< bool _IsMove, class _CharT2> friend typename ::__gnu_cxx::__enable_if< __is_char< _CharT2> ::__value, _CharT2 *> ::__type __copy_move_a2(::std::istreambuf_iterator< _CharT2> , ::std::istreambuf_iterator< _CharT2> , _CharT2 *); 
# 83
template< class _CharT2> friend typename ::__gnu_cxx::__enable_if< __is_char< _CharT2> ::__value, ::std::istreambuf_iterator< _CharT2> > ::__type find(::std::istreambuf_iterator< _CharT2> , ::std::istreambuf_iterator< _CharT2> , const _CharT2 &); 
# 97
private: mutable streambuf_type *_M_sbuf; 
# 98
mutable int_type _M_c; 
# 102
public: istreambuf_iterator() throw() : _M_sbuf((0)), _M_c(traits_type::eof()) 
# 103
{ } 
# 112
istreambuf_iterator(istream_type &__s) throw() : _M_sbuf((__s.rdbuf())), _M_c(traits_type::eof()) 
# 113
{ } 
# 116
istreambuf_iterator(streambuf_type *__s) throw() : _M_sbuf(__s), _M_c(traits_type::eof()) 
# 117
{ } 
# 123
char_type operator*() const 
# 124
{ 
# 132
return traits_type::to_char_type(_M_get()); 
# 133
} 
# 137
istreambuf_iterator &operator++() 
# 138
{ 
# 141
; 
# 142
if (_M_sbuf) 
# 143
{ 
# 144
((_M_sbuf)->sbumpc()); 
# 145
(_M_c) = traits_type::eof(); 
# 146
}  
# 147
return *this; 
# 148
} 
# 152
istreambuf_iterator operator++(int) 
# 153
{ 
# 156
; 
# 158
istreambuf_iterator __old = *this; 
# 159
if (_M_sbuf) 
# 160
{ 
# 161
(__old._M_c) = ((_M_sbuf)->sbumpc()); 
# 162
(_M_c) = traits_type::eof(); 
# 163
}  
# 164
return __old; 
# 165
} 
# 172
bool equal(const istreambuf_iterator &__b) const 
# 173
{ return _M_at_eof() == __b._M_at_eof(); } 
# 177
private: int_type _M_get() const 
# 178
{ 
# 179
const int_type __eof = traits_type::eof(); 
# 180
int_type __ret = __eof; 
# 181
if (_M_sbuf) 
# 182
{ 
# 183
if (!traits_type::eq_int_type(_M_c, __eof)) { 
# 184
__ret = (_M_c); } else { 
# 185
if (!traits_type::eq_int_type(__ret = ((_M_sbuf)->sgetc()), __eof)) { 
# 187
(_M_c) = __ret; } else { 
# 189
(_M_sbuf) = 0; }  }  
# 190
}  
# 191
return __ret; 
# 192
} 
# 195
bool _M_at_eof() const 
# 196
{ 
# 197
const int_type __eof = traits_type::eof(); 
# 198
return traits_type::eq_int_type(_M_get(), __eof); 
# 199
} 
# 200
}; 
# 202
template< class _CharT, class _Traits> inline bool 
# 204
operator==(const istreambuf_iterator< _CharT, _Traits>  &__a, const istreambuf_iterator< _CharT, _Traits>  &
# 205
__b) 
# 206
{ return (__a.equal(__b)); } 
# 208
template< class _CharT, class _Traits> inline bool 
# 210
operator!=(const istreambuf_iterator< _CharT, _Traits>  &__a, const istreambuf_iterator< _CharT, _Traits>  &
# 211
__b) 
# 212
{ return !(__a.equal(__b)); } 
# 215
template< class _CharT, class _Traits> 
# 216
class ostreambuf_iterator : public iterator< output_iterator_tag, void, void, void, void>  { 
# 223
public: typedef _CharT char_type; 
# 224
typedef _Traits traits_type; 
# 225
typedef basic_streambuf< _CharT, _Traits>  streambuf_type; 
# 226
typedef basic_ostream< _CharT, _Traits>  ostream_type; 
# 229
template< class _CharT2> friend typename __gnu_cxx::__enable_if< __is_char< _CharT2> ::__value, std::ostreambuf_iterator< _CharT2> > ::__type copy(istreambuf_iterator< _CharT2, char_traits< _CharT2> > , istreambuf_iterator< _CharT2, char_traits< _CharT2> > , std::ostreambuf_iterator< _CharT2> ); 
# 236
private: streambuf_type *_M_sbuf; 
# 237
bool _M_failed; 
# 241
public: ostreambuf_iterator(ostream_type &__s) throw() : _M_sbuf((__s.rdbuf())), _M_failed(!(_M_sbuf)) 
# 242
{ } 
# 245
ostreambuf_iterator(streambuf_type *__s) throw() : _M_sbuf(__s), _M_failed(!(_M_sbuf)) 
# 246
{ } 
# 250
ostreambuf_iterator &operator=(_CharT __c) 
# 251
{ 
# 252
if ((!(_M_failed)) && _Traits::eq_int_type(((_M_sbuf)->sputc(__c)), _Traits::eof())) { 
# 254
(_M_failed) = true; }  
# 255
return *this; 
# 256
} 
# 260
ostreambuf_iterator &operator*() 
# 261
{ return *this; } 
# 265
ostreambuf_iterator &operator++(int) 
# 266
{ return *this; } 
# 270
ostreambuf_iterator &operator++() 
# 271
{ return *this; } 
# 275
bool failed() const throw() 
# 276
{ return _M_failed; } 
# 279
ostreambuf_iterator &_M_put(const _CharT *__ws, streamsize __len) 
# 280
{ 
# 281
if ((__builtin_expect(!(_M_failed), true)) && (__builtin_expect(((this->_M_sbuf)->sputn(__ws, __len)) != __len, false))) { 
# 284
(_M_failed) = true; }  
# 285
return *this; 
# 286
} 
# 287
}; 
# 290
template< class _CharT> typename __gnu_cxx::__enable_if< __is_char< _CharT> ::__value, ostreambuf_iterator< _CharT, char_traits< _CharT> > > ::__type 
# 293
copy(istreambuf_iterator< _CharT, char_traits< _CharT> >  __first, istreambuf_iterator< _CharT, char_traits< _CharT> >  
# 294
__last, ostreambuf_iterator< _CharT, char_traits< _CharT> >  
# 295
__result) 
# 296
{ 
# 297
if ((__first._M_sbuf) && (!(__last._M_sbuf)) && (!(__result._M_failed))) 
# 298
{ 
# 299
bool __ineof; 
# 300
__copy_streambufs_eof((__first._M_sbuf), (__result._M_sbuf), __ineof); 
# 301
if (!__ineof) { 
# 302
(__result._M_failed) = true; }  
# 303
}  
# 304
return __result; 
# 305
} 
# 307
template< bool _IsMove, class _CharT> typename __gnu_cxx::__enable_if< __is_char< _CharT> ::__value, ostreambuf_iterator< _CharT, char_traits< _CharT> > > ::__type 
# 310
__copy_move_a2(_CharT *__first, _CharT *__last, ostreambuf_iterator< _CharT, char_traits< _CharT> >  
# 311
__result) 
# 312
{ 
# 313
const streamsize __num = __last - __first; 
# 314
if (__num > (0)) { 
# 315
(__result._M_put(__first, __num)); }  
# 316
return __result; 
# 317
} 
# 319
template< bool _IsMove, class _CharT> typename __gnu_cxx::__enable_if< __is_char< _CharT> ::__value, ostreambuf_iterator< _CharT, char_traits< _CharT> > > ::__type 
# 322
__copy_move_a2(const _CharT *__first, const _CharT *__last, ostreambuf_iterator< _CharT, char_traits< _CharT> >  
# 323
__result) 
# 324
{ 
# 325
const streamsize __num = __last - __first; 
# 326
if (__num > (0)) { 
# 327
(__result._M_put(__first, __num)); }  
# 328
return __result; 
# 329
} 
# 331
template< bool _IsMove, class _CharT> typename __gnu_cxx::__enable_if< __is_char< _CharT> ::__value, _CharT *> ::__type 
# 334
__copy_move_a2(istreambuf_iterator< _CharT, char_traits< _CharT> >  __first, istreambuf_iterator< _CharT, char_traits< _CharT> >  
# 335
__last, _CharT *__result) 
# 336
{ 
# 337
typedef istreambuf_iterator< _CharT, char_traits< _CharT> >  __is_iterator_type; 
# 338
typedef typename istreambuf_iterator< _CharT, char_traits< _CharT> > ::traits_type traits_type; 
# 339
typedef typename istreambuf_iterator< _CharT, char_traits< _CharT> > ::streambuf_type streambuf_type; 
# 340
typedef typename istreambuf_iterator< _CharT, char_traits< _CharT> > ::traits_type::int_type int_type; 
# 342
if ((__first._M_sbuf) && (!(__last._M_sbuf))) 
# 343
{ 
# 344
streambuf_type *__sb = ((__first._M_sbuf)); 
# 345
int_type __c = (__sb->sgetc()); 
# 346
while (!traits_type::eq_int_type(__c, traits_type::eof())) 
# 347
{ 
# 348
const streamsize __n = (__sb->egptr()) - (__sb->gptr()); 
# 349
if (__n > (1)) 
# 350
{ 
# 351
traits_type::copy(__result, (__sb->gptr()), __n); 
# 352
(__sb->__safe_gbump(__n)); 
# 353
__result += __n; 
# 354
__c = (__sb->underflow()); 
# 355
} else 
# 357
{ 
# 358
(*(__result++)) = traits_type::to_char_type(__c); 
# 359
__c = (__sb->snextc()); 
# 360
}  
# 361
}  
# 362
}  
# 363
return __result; 
# 364
} 
# 366
template< class _CharT> typename __gnu_cxx::__enable_if< __is_char< _CharT> ::__value, istreambuf_iterator< _CharT, char_traits< _CharT> > > ::__type 
# 369
find(istreambuf_iterator< _CharT, char_traits< _CharT> >  __first, istreambuf_iterator< _CharT, char_traits< _CharT> >  
# 370
__last, const _CharT &__val) 
# 371
{ 
# 372
typedef istreambuf_iterator< _CharT, char_traits< _CharT> >  __is_iterator_type; 
# 373
typedef typename istreambuf_iterator< _CharT, char_traits< _CharT> > ::traits_type traits_type; 
# 374
typedef typename istreambuf_iterator< _CharT, char_traits< _CharT> > ::streambuf_type streambuf_type; 
# 375
typedef typename istreambuf_iterator< _CharT, char_traits< _CharT> > ::traits_type::int_type int_type; 
# 377
if ((__first._M_sbuf) && (!(__last._M_sbuf))) 
# 378
{ 
# 379
const int_type __ival = traits_type::to_int_type(__val); 
# 380
streambuf_type *__sb = ((__first._M_sbuf)); 
# 381
int_type __c = (__sb->sgetc()); 
# 382
while ((!traits_type::eq_int_type(__c, traits_type::eof())) && (!traits_type::eq_int_type(__c, __ival))) 
# 384
{ 
# 385
streamsize __n = (__sb->egptr()) - (__sb->gptr()); 
# 386
if (__n > (1)) 
# 387
{ 
# 388
const _CharT *__p = traits_type::find((__sb->gptr()), __n, __val); 
# 390
if (__p) { 
# 391
__n = (__p - (__sb->gptr())); }  
# 392
(__sb->__safe_gbump(__n)); 
# 393
__c = (__sb->sgetc()); 
# 394
} else { 
# 396
__c = (__sb->snextc()); }  
# 397
}  
# 399
if (!traits_type::eq_int_type(__c, traits_type::eof())) { 
# 400
(__first._M_c) = __c; } else { 
# 402
(__first._M_sbuf) = 0; }  
# 403
}  
# 404
return __first; 
# 405
} 
# 410
}
# 50 "/usr/include/c++/4.8.2/bits/locale_facets.h" 3
namespace std __attribute((__visibility__("default"))) { 
# 64
template< class _Tp> void __convert_to_v(const char *, _Tp &, ios_base::iostate &, const __c_locale &) throw(); 
# 72
template<> void __convert_to_v(const char *, float &, ios_base::iostate &, const __c_locale &) throw(); 
# 77
template<> void __convert_to_v(const char *, double &, ios_base::iostate &, const __c_locale &) throw(); 
# 82
template<> void __convert_to_v(const char *, long double &, ios_base::iostate &, const __c_locale &) throw(); 
# 87
template< class _CharT, class _Traits> 
# 88
struct __pad { 
# 91
static void _S_pad(ios_base & __io, _CharT __fill, _CharT * __news, const _CharT * __olds, streamsize __newlen, streamsize __oldlen); 
# 93
}; 
# 100
template< class _CharT> _CharT *__add_grouping(_CharT * __s, _CharT __sep, const char * __gbeg, size_t __gsize, const _CharT * __first, const _CharT * __last); 
# 109
template< class _CharT> inline ostreambuf_iterator< _CharT, char_traits< _CharT> >  
# 112
__write(ostreambuf_iterator< _CharT, char_traits< _CharT> >  __s, const _CharT *__ws, int __len) 
# 113
{ 
# 114
(__s._M_put(__ws, __len)); 
# 115
return __s; 
# 116
} 
# 119
template< class _CharT, class _OutIter> inline _OutIter 
# 122
__write(_OutIter __s, const _CharT *__ws, int __len) 
# 123
{ 
# 124
for (int __j = 0; __j < __len; (__j++), (++__s)) { 
# 125
(*__s) = (__ws[__j]); }  
# 126
return __s; 
# 127
} 
# 142
template< class _CharT> 
# 143
class __ctype_abstract_base : public locale::facet, public ctype_base { 
# 148
public: typedef _CharT char_type; 
# 162
bool is(mask __m, char_type __c) const 
# 163
{ return (this->do_is(__m, __c)); } 
# 179
const char_type *is(const char_type *__lo, const char_type *__hi, mask *__vec) const 
# 180
{ return (this->do_is(__lo, __hi, __vec)); } 
# 195
const char_type *scan_is(mask __m, const char_type *__lo, const char_type *__hi) const 
# 196
{ return this->do_scan_is(__m, __lo, __hi); } 
# 211
const char_type *scan_not(mask __m, const char_type *__lo, const char_type *__hi) const 
# 212
{ return this->do_scan_not(__m, __lo, __hi); } 
# 225
char_type toupper(char_type __c) const 
# 226
{ return (this->do_toupper(__c)); } 
# 240
const char_type *toupper(char_type *__lo, const char_type *__hi) const 
# 241
{ return (this->do_toupper(__lo, __hi)); } 
# 254
char_type tolower(char_type __c) const 
# 255
{ return (this->do_tolower(__c)); } 
# 269
const char_type *tolower(char_type *__lo, const char_type *__hi) const 
# 270
{ return (this->do_tolower(__lo, __hi)); } 
# 286
char_type widen(char __c) const 
# 287
{ return (this->do_widen(__c)); } 
# 305
const char *widen(const char *__lo, const char *__hi, char_type *__to) const 
# 306
{ return (this->do_widen(__lo, __hi, __to)); } 
# 324
char narrow(char_type __c, char __dfault) const 
# 325
{ return (this->do_narrow(__c, __dfault)); } 
# 346
const char_type *narrow(const char_type *__lo, const char_type *__hi, char 
# 347
__dfault, char *__to) const 
# 348
{ return (this->do_narrow(__lo, __hi, __dfault, __to)); } 
# 352
protected: explicit __ctype_abstract_base(size_t __refs = 0) : locale::facet(__refs) { } 
# 355
virtual ~__ctype_abstract_base() { } 
# 371
virtual bool do_is(mask __m, char_type __c) const = 0; 
# 390
virtual const char_type *do_is(const char_type * __lo, const char_type * __hi, mask * __vec) const = 0; 
# 409
virtual const char_type *do_scan_is(mask __m, const char_type * __lo, const char_type * __hi) const = 0; 
# 428
virtual const char_type *do_scan_not(mask __m, const char_type * __lo, const char_type * __hi) const = 0; 
# 446
virtual char_type do_toupper(char_type __c) const = 0; 
# 463
virtual const char_type *do_toupper(char_type * __lo, const char_type * __hi) const = 0; 
# 479
virtual char_type do_tolower(char_type __c) const = 0; 
# 496
virtual const char_type *do_tolower(char_type * __lo, const char_type * __hi) const = 0; 
# 515
virtual char_type do_widen(char __c) const = 0; 
# 536
virtual const char *do_widen(const char * __lo, const char * __hi, char_type * __to) const = 0; 
# 557
virtual char do_narrow(char_type __c, char __dfault) const = 0; 
# 582
virtual const char_type *do_narrow(const char_type * __lo, const char_type * __hi, char __dfault, char * __to) const = 0; 
# 584
}; 
# 604
template< class _CharT> 
# 605
class ctype : public __ctype_abstract_base< _CharT>  { 
# 609
public: typedef _CharT char_type; 
# 610
typedef typename ::std::__ctype_abstract_base< _CharT> ::mask mask; 
# 613
static ::std::locale::id id; 
# 616
explicit ctype(::std::size_t __refs = 0) : ::std::__ctype_abstract_base< _CharT> (__refs) { } 
# 620
protected: virtual ~ctype(); 
# 623
virtual bool do_is(mask __m, char_type __c) const; 
# 626
virtual const char_type *do_is(const char_type * __lo, const char_type * __hi, mask * __vec) const; 
# 629
virtual const char_type *do_scan_is(mask __m, const char_type * __lo, const char_type * __hi) const; 
# 632
virtual const char_type *do_scan_not(mask __m, const char_type * __lo, const char_type * __hi) const; 
# 636
virtual char_type do_toupper(char_type __c) const; 
# 639
virtual const char_type *do_toupper(char_type * __lo, const char_type * __hi) const; 
# 642
virtual char_type do_tolower(char_type __c) const; 
# 645
virtual const char_type *do_tolower(char_type * __lo, const char_type * __hi) const; 
# 648
virtual char_type do_widen(char __c) const; 
# 651
virtual const char *do_widen(const char * __lo, const char * __hi, char_type * __dest) const; 
# 654
virtual char do_narrow(char_type, char __dfault) const; 
# 657
virtual const char_type *do_narrow(const char_type * __lo, const char_type * __hi, char __dfault, char * __to) const; 
# 659
}; 
# 661
template< class _CharT> locale::id 
# 662
ctype< _CharT> ::id; 
# 674
template<> class ctype< char>  : public locale::facet, public ctype_base { 
# 679
public: typedef char char_type; 
# 683
protected: __c_locale _M_c_locale_ctype; 
# 684
bool _M_del; 
# 685
__to_type _M_toupper; 
# 686
__to_type _M_tolower; 
# 687
const mask *_M_table; 
# 688
mutable char _M_widen_ok; 
# 689
mutable char _M_widen[1 + (static_cast< unsigned char>(-1))]; 
# 690
mutable char _M_narrow[1 + (static_cast< unsigned char>(-1))]; 
# 691
mutable char _M_narrow_ok; 
# 696
public: static locale::id id; 
# 698
static const size_t table_size = (1 + (static_cast< unsigned char>(-1))); 
# 711
explicit ctype(const mask * __table = 0, bool __del = false, size_t __refs = 0); 
# 724
explicit ctype(__c_locale __cloc, const mask * __table = 0, bool __del = false, size_t __refs = 0); 
# 737
inline bool is(mask __m, char __c) const; 
# 752
inline const char *is(const char * __lo, const char * __hi, mask * __vec) const; 
# 766
inline const char *scan_is(mask __m, const char * __lo, const char * __hi) const; 
# 780
inline const char *scan_not(mask __m, const char * __lo, const char * __hi) const; 
# 795
char_type toupper(char_type __c) const 
# 796
{ return this->do_toupper(__c); } 
# 812
const char_type *toupper(char_type *__lo, const char_type *__hi) const 
# 813
{ return this->do_toupper(__lo, __hi); } 
# 828
char_type tolower(char_type __c) const 
# 829
{ return this->do_tolower(__c); } 
# 845
const char_type *tolower(char_type *__lo, const char_type *__hi) const 
# 846
{ return this->do_tolower(__lo, __hi); } 
# 865
char_type widen(char __c) const 
# 866
{ 
# 867
if (_M_widen_ok) { 
# 868
return (_M_widen)[static_cast< unsigned char>(__c)]; }  
# 869
this->_M_widen_init(); 
# 870
return this->do_widen(__c); 
# 871
} 
# 892
const char *widen(const char *__lo, const char *__hi, char_type *__to) const 
# 893
{ 
# 894
if ((_M_widen_ok) == 1) 
# 895
{ 
# 896
__builtin_memcpy(__to, __lo, __hi - __lo); 
# 897
return __hi; 
# 898
}  
# 899
if (!(_M_widen_ok)) { 
# 900
this->_M_widen_init(); }  
# 901
return this->do_widen(__lo, __hi, __to); 
# 902
} 
# 923
char narrow(char_type __c, char __dfault) const 
# 924
{ 
# 925
if ((_M_narrow)[static_cast< unsigned char>(__c)]) { 
# 926
return (_M_narrow)[static_cast< unsigned char>(__c)]; }  
# 927
const char __t = this->do_narrow(__c, __dfault); 
# 928
if (__t != __dfault) { 
# 929
((_M_narrow)[static_cast< unsigned char>(__c)]) = __t; }  
# 930
return __t; 
# 931
} 
# 956
const char_type *narrow(const char_type *__lo, const char_type *__hi, char 
# 957
__dfault, char *__to) const 
# 958
{ 
# 959
if (__builtin_expect((_M_narrow_ok) == 1, true)) 
# 960
{ 
# 961
__builtin_memcpy(__to, __lo, __hi - __lo); 
# 962
return __hi; 
# 963
}  
# 964
if (!(_M_narrow_ok)) { 
# 965
this->_M_narrow_init(); }  
# 966
return this->do_narrow(__lo, __hi, __dfault, __to); 
# 967
} 
# 974
const mask *table() const throw() 
# 975
{ return _M_table; } 
# 979
static const mask *classic_table() throw(); 
# 989
protected: virtual ~ctype(); 
# 1005
virtual char_type do_toupper(char_type __c) const; 
# 1022
virtual const char_type *do_toupper(char_type * __lo, const char_type * __hi) const; 
# 1038
virtual char_type do_tolower(char_type __c) const; 
# 1055
virtual const char_type *do_tolower(char_type * __lo, const char_type * __hi) const; 
# 1075
virtual char_type do_widen(char __c) const 
# 1076
{ return __c; } 
# 1098
virtual const char *do_widen(const char *__lo, const char *__hi, char_type *__to) const 
# 1099
{ 
# 1100
__builtin_memcpy(__to, __lo, __hi - __lo); 
# 1101
return __hi; 
# 1102
} 
# 1124
virtual char do_narrow(char_type __c, char __dfault) const 
# 1125
{ return __c; } 
# 1150
virtual const char_type *do_narrow(const char_type *__lo, const char_type *__hi, char 
# 1151
__dfault, char *__to) const 
# 1152
{ 
# 1153
__builtin_memcpy(__to, __lo, __hi - __lo); 
# 1154
return __hi; 
# 1155
} 
# 1158
private: void _M_narrow_init() const; 
# 1159
void _M_widen_init() const; 
# 1160
}; 
# 1175
template<> class ctype< wchar_t>  : public __ctype_abstract_base< wchar_t>  { 
# 1180
public: typedef wchar_t char_type; 
# 1181
typedef wctype_t __wmask_type; 
# 1184
protected: __c_locale _M_c_locale_ctype; 
# 1187
bool _M_narrow_ok; 
# 1188
char _M_narrow[128]; 
# 1189
wint_t _M_widen[1 + (static_cast< unsigned char>(-1))]; 
# 1192
mask _M_bit[16]; 
# 1193
__wmask_type _M_wmask[16]; 
# 1198
public: static locale::id id; 
# 1208
explicit ctype(size_t __refs = 0); 
# 1219
explicit ctype(__c_locale __cloc, size_t __refs = 0); 
# 1223
protected: __wmask_type _M_convert_to_wmask(const mask __m) const throw(); 
# 1227
virtual ~ctype(); 
# 1243
virtual bool do_is(mask __m, char_type __c) const; 
# 1262
virtual const char_type *do_is(const char_type * __lo, const char_type * __hi, mask * __vec) const; 
# 1280
virtual const char_type *do_scan_is(mask __m, const char_type * __lo, const char_type * __hi) const; 
# 1298
virtual const char_type *do_scan_not(mask __m, const char_type * __lo, const char_type * __hi) const; 
# 1315
virtual char_type do_toupper(char_type __c) const; 
# 1332
virtual const char_type *do_toupper(char_type * __lo, const char_type * __hi) const; 
# 1348
virtual char_type do_tolower(char_type __c) const; 
# 1365
virtual const char_type *do_tolower(char_type * __lo, const char_type * __hi) const; 
# 1385
virtual char_type do_widen(char __c) const; 
# 1407
virtual const char *do_widen(const char * __lo, const char * __hi, char_type * __to) const; 
# 1430
virtual char do_narrow(char_type __c, char __dfault) const; 
# 1456
virtual const char_type *do_narrow(const char_type * __lo, const char_type * __hi, char __dfault, char * __to) const; 
# 1461
void _M_initialize_ctype() throw(); 
# 1462
}; 
# 1466
template< class _CharT> 
# 1467
class ctype_byname : public ctype< _CharT>  { 
# 1470
public: typedef typename ::std::ctype< _CharT> ::mask mask; 
# 1473
explicit ctype_byname(const char * __s, ::std::size_t __refs = 0); 
# 1477
protected: virtual ~ctype_byname() { } 
# 1478
}; 
# 1482
template<> class ctype_byname< char>  : public ctype< char>  { 
# 1486
public: explicit ctype_byname(const char * __s, size_t __refs = 0); 
# 1490
protected: virtual ~ctype_byname(); 
# 1491
}; 
# 1495
template<> class ctype_byname< wchar_t>  : public ctype< wchar_t>  { 
# 1499
public: explicit ctype_byname(const char * __s, size_t __refs = 0); 
# 1503
protected: virtual ~ctype_byname(); 
# 1504
}; 
# 1508
}
# 37 "/usr/include/c++/4.8.2/ppc64le-redhat-linux/bits/ctype_inline.h" 3
namespace std __attribute((__visibility__("default"))) { 
# 43
inline bool ctype< char> ::is(mask __m, char __c) const 
# 44
{ return ((_M_table)[static_cast< unsigned char>(__c)]) & __m; } 
# 48
inline const char *ctype< char> ::is(const char *__low, const char *__high, mask *__vec) const 
# 49
{ 
# 50
while (__low < __high) { 
# 51
(*(__vec++)) = ((_M_table)[static_cast< unsigned char>(*(__low++))]); }  
# 52
return __high; 
# 53
} 
# 57
inline const char *ctype< char> ::scan_is(mask __m, const char *__low, const char *__high) const 
# 58
{ 
# 59
while ((__low < __high) && (!(((_M_table)[static_cast< unsigned char>(*__low)]) & __m))) { 
# 61
++__low; }  
# 62
return __low; 
# 63
} 
# 67
inline const char *ctype< char> ::scan_not(mask __m, const char *__low, const char *__high) const 
# 68
{ 
# 69
while ((__low < __high) && ((((_M_table)[static_cast< unsigned char>(*__low)]) & __m) != 0)) { 
# 71
++__low; }  
# 72
return __low; 
# 73
} 
# 76
}
# 1513 "/usr/include/c++/4.8.2/bits/locale_facets.h" 3
namespace std __attribute((__visibility__("default"))) { 
# 1518
class __num_base { 
# 1524
public: enum { 
# 1525
_S_ominus, 
# 1526
_S_oplus, 
# 1527
_S_ox, 
# 1528
_S_oX, 
# 1529
_S_odigits, 
# 1530
_S_odigits_end = 20, 
# 1531
_S_oudigits = 20, 
# 1532
_S_oudigits_end = 36, 
# 1533
_S_oe = 18, 
# 1534
_S_oE = 34, 
# 1535
_S_oend = 36
# 1536
}; 
# 1543
static const char *_S_atoms_out; 
# 1547
static const char *_S_atoms_in; 
# 1550
enum { 
# 1551
_S_iminus, 
# 1552
_S_iplus, 
# 1553
_S_ix, 
# 1554
_S_iX, 
# 1555
_S_izero, 
# 1556
_S_ie = 18, 
# 1557
_S_iE = 24, 
# 1558
_S_iend = 26
# 1559
}; 
# 1564
static void _S_format_float(const ios_base & __io, char * __fptr, char __mod) throw(); 
# 1565
}; 
# 1567
template< class _CharT> 
# 1568
struct __numpunct_cache : public locale::facet { 
# 1570
const char *_M_grouping; 
# 1571
size_t _M_grouping_size; 
# 1572
bool _M_use_grouping; 
# 1573
const _CharT *_M_truename; 
# 1574
size_t _M_truename_size; 
# 1575
const _CharT *_M_falsename; 
# 1576
size_t _M_falsename_size; 
# 1577
_CharT _M_decimal_point; 
# 1578
_CharT _M_thousands_sep; 
# 1584
_CharT _M_atoms_out[__num_base::_S_oend]; 
# 1590
_CharT _M_atoms_in[__num_base::_S_iend]; 
# 1592
bool _M_allocated; 
# 1594
__numpunct_cache(size_t __refs = 0) : locale::facet(__refs), _M_grouping((0)), _M_grouping_size((0)), _M_use_grouping(false), _M_truename((0)), _M_truename_size((0)), _M_falsename((0)), _M_falsename_size((0)), _M_decimal_point(_CharT()), _M_thousands_sep(_CharT()), _M_allocated(false) 
# 1600
{ } 
# 1602
virtual ~__numpunct_cache(); 
# 1605
void _M_cache(const locale & __loc); 
# 1609
private: __numpunct_cache &operator=(const __numpunct_cache &); 
# 1612
explicit __numpunct_cache(const __numpunct_cache &); 
# 1613
}; 
# 1615
template< class _CharT> 
# 1616
__numpunct_cache< _CharT> ::~__numpunct_cache() 
# 1617
{ 
# 1618
if (_M_allocated) 
# 1619
{ 
# 1620
delete [] (_M_grouping); 
# 1621
delete [] (_M_truename); 
# 1622
delete [] (_M_falsename); 
# 1623
}  
# 1624
} 
# 1640
template< class _CharT> 
# 1641
class numpunct : public locale::facet { 
# 1647
public: typedef _CharT char_type; 
# 1648
typedef basic_string< _CharT, char_traits< _CharT> , allocator< _CharT> >  string_type; 
# 1650
typedef __numpunct_cache< _CharT>  __cache_type; 
# 1653
protected: __cache_type *_M_data; 
# 1657
public: static locale::id id; 
# 1665
explicit numpunct(size_t __refs = 0) : locale::facet(__refs), _M_data((0)) 
# 1667
{ _M_initialize_numpunct(); } 
# 1679
explicit numpunct(__cache_type *__cache, size_t __refs = 0) : locale::facet(__refs), _M_data(__cache) 
# 1681
{ _M_initialize_numpunct(); } 
# 1693
explicit numpunct(__c_locale __cloc, size_t __refs = 0) : locale::facet(__refs), _M_data((0)) 
# 1695
{ _M_initialize_numpunct(__cloc); } 
# 1707
char_type decimal_point() const 
# 1708
{ return this->do_decimal_point(); } 
# 1720
char_type thousands_sep() const 
# 1721
{ return this->do_thousands_sep(); } 
# 1751
string grouping() const 
# 1752
{ return this->do_grouping(); } 
# 1764
string_type truename() const 
# 1765
{ return this->do_truename(); } 
# 1777
string_type falsename() const 
# 1778
{ return this->do_falsename(); } 
# 1783
protected: virtual ~numpunct(); 
# 1794
virtual char_type do_decimal_point() const 
# 1795
{ return (_M_data)->_M_decimal_point; } 
# 1806
virtual char_type do_thousands_sep() const 
# 1807
{ return (_M_data)->_M_thousands_sep; } 
# 1819
virtual string do_grouping() const 
# 1820
{ return ((_M_data)->_M_grouping); } 
# 1832
virtual string_type do_truename() const 
# 1833
{ return ((_M_data)->_M_truename); } 
# 1845
virtual string_type do_falsename() const 
# 1846
{ return ((_M_data)->_M_falsename); } 
# 1850
void _M_initialize_numpunct(__c_locale __cloc = 0); 
# 1851
}; 
# 1853
template< class _CharT> locale::id 
# 1854
numpunct< _CharT> ::id; 
# 1857
template<> numpunct< char> ::~numpunct(); 
# 1861
template<> void numpunct< char> ::_M_initialize_numpunct(__c_locale __cloc); 
# 1865
template<> numpunct< wchar_t> ::~numpunct(); 
# 1869
template<> void numpunct< wchar_t> ::_M_initialize_numpunct(__c_locale __cloc); 
# 1873
template< class _CharT> 
# 1874
class numpunct_byname : public numpunct< _CharT>  { 
# 1877
public: typedef _CharT char_type; 
# 1878
typedef basic_string< _CharT, char_traits< _CharT> , allocator< _CharT> >  string_type; 
# 1881
explicit numpunct_byname(const char *__s, ::std::size_t __refs = 0) : ::std::numpunct< _CharT> (__refs) 
# 1883
{ 
# 1884
if ((__builtin_strcmp(__s, "C") != 0) && (__builtin_strcmp(__s, "POSIX") != 0)) 
# 1886
{ 
# 1887
::std::__c_locale __tmp; 
# 1888
(this->_S_create_c_locale(__tmp, __s)); 
# 1889
(this->_M_initialize_numpunct(__tmp)); 
# 1890
(this->_S_destroy_c_locale(__tmp)); 
# 1891
}  
# 1892
} 
# 1896
protected: virtual ~numpunct_byname() { } 
# 1897
}; 
# 1899
inline namespace __gnu_cxx_ldbl128 { 
# 1914
template< class _CharT, class _InIter> 
# 1915
class num_get : public locale::facet { 
# 1921
public: typedef _CharT char_type; 
# 1922
typedef _InIter iter_type; 
# 1926
static locale::id id; 
# 1936
explicit num_get(size_t __refs = 0) : locale::facet(__refs) { } 
# 1962
iter_type get(iter_type __in, iter_type __end, ios_base &__io, ios_base::iostate &
# 1963
__err, bool &__v) const 
# 1964
{ return (this->do_get(__in, __end, __io, __err, __v)); } 
# 1999
iter_type get(iter_type __in, iter_type __end, ios_base &__io, ios_base::iostate &
# 2000
__err, long &__v) const 
# 2001
{ return (this->do_get(__in, __end, __io, __err, __v)); } 
# 2004
iter_type get(iter_type __in, iter_type __end, ios_base &__io, ios_base::iostate &
# 2005
__err, unsigned short &__v) const 
# 2006
{ return (this->do_get(__in, __end, __io, __err, __v)); } 
# 2009
iter_type get(iter_type __in, iter_type __end, ios_base &__io, ios_base::iostate &
# 2010
__err, unsigned &__v) const 
# 2011
{ return (this->do_get(__in, __end, __io, __err, __v)); } 
# 2014
iter_type get(iter_type __in, iter_type __end, ios_base &__io, ios_base::iostate &
# 2015
__err, unsigned long &__v) const 
# 2016
{ return (this->do_get(__in, __end, __io, __err, __v)); } 
# 2020
iter_type get(iter_type __in, iter_type __end, ios_base &__io, ios_base::iostate &
# 2021
__err, long long &__v) const 
# 2022
{ return (this->do_get(__in, __end, __io, __err, __v)); } 
# 2025
iter_type get(iter_type __in, iter_type __end, ios_base &__io, ios_base::iostate &
# 2026
__err, unsigned long long &__v) const 
# 2027
{ return (this->do_get(__in, __end, __io, __err, __v)); } 
# 2059
iter_type get(iter_type __in, iter_type __end, ios_base &__io, ios_base::iostate &
# 2060
__err, float &__v) const 
# 2061
{ return (this->do_get(__in, __end, __io, __err, __v)); } 
# 2064
iter_type get(iter_type __in, iter_type __end, ios_base &__io, ios_base::iostate &
# 2065
__err, double &__v) const 
# 2066
{ return (this->do_get(__in, __end, __io, __err, __v)); } 
# 2069
iter_type get(iter_type __in, iter_type __end, ios_base &__io, ios_base::iostate &
# 2070
__err, long double &__v) const 
# 2071
{ return (this->do_get(__in, __end, __io, __err, __v)); } 
# 2102
iter_type get(iter_type __in, iter_type __end, ios_base &__io, ios_base::iostate &
# 2103
__err, void *&__v) const 
# 2104
{ return (this->do_get(__in, __end, __io, __err, __v)); } 
# 2108
protected: virtual ~num_get() { } 
# 2111
iter_type _M_extract_float(iter_type, iter_type, ios_base &, ios_base::iostate &, string &) const; 
# 2114
template< class _ValueT> iter_type _M_extract_int(iter_type, iter_type, ios_base &, ios_base::iostate &, _ValueT &) const; 
# 2119
template< class _CharT2> typename __gnu_cxx::__enable_if< __is_char< _CharT2> ::__value, int> ::__type 
# 2121
_M_find(const _CharT2 *, size_t __len, _CharT2 __c) const 
# 2122
{ 
# 2123
int __ret = (-1); 
# 2124
if (__len <= (10)) 
# 2125
{ 
# 2126
if ((__c >= ((_CharT2)'0')) && (__c < ((_CharT2)(((_CharT2)'0') + __len)))) { 
# 2127
__ret = (__c - ((_CharT2)'0')); }  
# 2128
} else 
# 2130
{ 
# 2131
if ((__c >= ((_CharT2)'0')) && (__c <= ((_CharT2)'9'))) { 
# 2132
__ret = (__c - ((_CharT2)'0')); } else { 
# 2133
if ((__c >= ((_CharT2)'a')) && (__c <= ((_CharT2)'f'))) { 
# 2134
__ret = (10 + (__c - ((_CharT2)'a'))); } else { 
# 2135
if ((__c >= ((_CharT2)'A')) && (__c <= ((_CharT2)'F'))) { 
# 2136
__ret = (10 + (__c - ((_CharT2)'A'))); }  }  }  
# 2137
}  
# 2138
return __ret; 
# 2139
} 
# 2141
template< class _CharT2> typename __gnu_cxx::__enable_if< !__is_char< _CharT2> ::__value, int> ::__type 
# 2144
_M_find(const _CharT2 *__zero, size_t __len, _CharT2 __c) const 
# 2145
{ 
# 2146
int __ret = (-1); 
# 2147
const char_type *__q = char_traits< _CharT2> ::find(__zero, __len, __c); 
# 2148
if (__q) 
# 2149
{ 
# 2150
__ret = (__q - __zero); 
# 2151
if (__ret > 15) { 
# 2152
__ret -= 6; }  
# 2153
}  
# 2154
return __ret; 
# 2155
} 
# 2173
virtual iter_type do_get(iter_type, iter_type, ios_base &, ios_base::iostate &, bool &) const; 
# 2176
virtual iter_type do_get(iter_type __beg, iter_type __end, ios_base &__io, ios_base::iostate &
# 2177
__err, long &__v) const 
# 2178
{ return _M_extract_int(__beg, __end, __io, __err, __v); } 
# 2181
virtual iter_type do_get(iter_type __beg, iter_type __end, ios_base &__io, ios_base::iostate &
# 2182
__err, unsigned short &__v) const 
# 2183
{ return _M_extract_int(__beg, __end, __io, __err, __v); } 
# 2186
virtual iter_type do_get(iter_type __beg, iter_type __end, ios_base &__io, ios_base::iostate &
# 2187
__err, unsigned &__v) const 
# 2188
{ return _M_extract_int(__beg, __end, __io, __err, __v); } 
# 2191
virtual iter_type do_get(iter_type __beg, iter_type __end, ios_base &__io, ios_base::iostate &
# 2192
__err, unsigned long &__v) const 
# 2193
{ return _M_extract_int(__beg, __end, __io, __err, __v); } 
# 2197
virtual iter_type do_get(iter_type __beg, iter_type __end, ios_base &__io, ios_base::iostate &
# 2198
__err, long long &__v) const 
# 2199
{ return _M_extract_int(__beg, __end, __io, __err, __v); } 
# 2202
virtual iter_type do_get(iter_type __beg, iter_type __end, ios_base &__io, ios_base::iostate &
# 2203
__err, unsigned long long &__v) const 
# 2204
{ return _M_extract_int(__beg, __end, __io, __err, __v); } 
# 2208
virtual iter_type do_get(iter_type, iter_type, ios_base &, ios_base::iostate &, float &) const; 
# 2211
virtual iter_type do_get(iter_type, iter_type, ios_base &, ios_base::iostate &, double &) const; 
# 2217
virtual iter_type __do_get(iter_type, iter_type, ios_base &, ios_base::iostate &, double &) const; 
# 2226
virtual iter_type do_get(iter_type, iter_type, ios_base &, ios_base::iostate &, void *&) const; 
# 2231
virtual iter_type do_get(iter_type, iter_type, ios_base &, ios_base::iostate &, long double &) const; 
# 2235
}; 
# 2237
template< class _CharT, class _InIter> locale::id 
# 2238
num_get< _CharT, _InIter> ::id; 
# 2253
template< class _CharT, class _OutIter> 
# 2254
class num_put : public locale::facet { 
# 2260
public: typedef _CharT char_type; 
# 2261
typedef _OutIter iter_type; 
# 2265
static locale::id id; 
# 2275
explicit num_put(size_t __refs = 0) : locale::facet(__refs) { } 
# 2293
iter_type put(iter_type __s, ios_base &__io, char_type __fill, bool __v) const 
# 2294
{ return (this->do_put(__s, __io, __fill, __v)); } 
# 2335
iter_type put(iter_type __s, ios_base &__io, char_type __fill, long __v) const 
# 2336
{ return (this->do_put(__s, __io, __fill, __v)); } 
# 2339
iter_type put(iter_type __s, ios_base &__io, char_type __fill, unsigned long 
# 2340
__v) const 
# 2341
{ return (this->do_put(__s, __io, __fill, __v)); } 
# 2345
iter_type put(iter_type __s, ios_base &__io, char_type __fill, long long __v) const 
# 2346
{ return (this->do_put(__s, __io, __fill, __v)); } 
# 2349
iter_type put(iter_type __s, ios_base &__io, char_type __fill, unsigned long long 
# 2350
__v) const 
# 2351
{ return (this->do_put(__s, __io, __fill, __v)); } 
# 2398
iter_type put(iter_type __s, ios_base &__io, char_type __fill, double __v) const 
# 2399
{ return (this->do_put(__s, __io, __fill, __v)); } 
# 2402
iter_type put(iter_type __s, ios_base &__io, char_type __fill, long double 
# 2403
__v) const 
# 2404
{ return (this->do_put(__s, __io, __fill, __v)); } 
# 2423
iter_type put(iter_type __s, ios_base &__io, char_type __fill, const void *
# 2424
__v) const 
# 2425
{ return (this->do_put(__s, __io, __fill, __v)); } 
# 2428
protected: template< class _ValueT> iter_type _M_insert_float(iter_type, ios_base & __io, char_type __fill, char __mod, _ValueT __v) const; 
# 2434
void _M_group_float(const char * __grouping, size_t __grouping_size, char_type __sep, const char_type * __p, char_type * __new, char_type * __cs, int & __len) const; 
# 2438
template< class _ValueT> iter_type _M_insert_int(iter_type, ios_base & __io, char_type __fill, _ValueT __v) const; 
# 2444
void _M_group_int(const char * __grouping, size_t __grouping_size, char_type __sep, ios_base & __io, char_type * __new, char_type * __cs, int & __len) const; 
# 2449
void _M_pad(char_type __fill, streamsize __w, ios_base & __io, char_type * __new, const char_type * __cs, int & __len) const; 
# 2454
virtual ~num_put() { } 
# 2471
virtual iter_type do_put(iter_type __s, ios_base & __io, char_type __fill, bool __v) const; 
# 2474
virtual iter_type do_put(iter_type __s, ios_base &__io, char_type __fill, long __v) const 
# 2475
{ return _M_insert_int(__s, __io, __fill, __v); } 
# 2478
virtual iter_type do_put(iter_type __s, ios_base &__io, char_type __fill, unsigned long 
# 2479
__v) const 
# 2480
{ return _M_insert_int(__s, __io, __fill, __v); } 
# 2484
virtual iter_type do_put(iter_type __s, ios_base &__io, char_type __fill, long long 
# 2485
__v) const 
# 2486
{ return _M_insert_int(__s, __io, __fill, __v); } 
# 2489
virtual iter_type do_put(iter_type __s, ios_base &__io, char_type __fill, unsigned long long 
# 2490
__v) const 
# 2491
{ return _M_insert_int(__s, __io, __fill, __v); } 
# 2495
virtual iter_type do_put(iter_type, ios_base &, char_type, double) const; 
# 2500
virtual iter_type __do_put(iter_type, ios_base &, char_type, double) const; 
# 2507
virtual iter_type do_put(iter_type, ios_base &, char_type, const void *) const; 
# 2512
virtual iter_type do_put(iter_type, ios_base &, char_type, long double) const; 
# 2515
}; 
# 2517
template< class _CharT, class _OutIter> locale::id 
# 2518
num_put< _CharT, _OutIter> ::id; 
# 2520
}
# 2528
template< class _CharT> inline bool 
# 2530
isspace(_CharT __c, const locale &__loc) 
# 2531
{ return (use_facet< ctype< _CharT> > (__loc).is(ctype_base::space, __c)); } 
# 2534
template< class _CharT> inline bool 
# 2536
isprint(_CharT __c, const locale &__loc) 
# 2537
{ return (use_facet< ctype< _CharT> > (__loc).is(ctype_base::print, __c)); } 
# 2540
template< class _CharT> inline bool 
# 2542
iscntrl(_CharT __c, const locale &__loc) 
# 2543
{ return (use_facet< ctype< _CharT> > (__loc).is(ctype_base::cntrl, __c)); } 
# 2546
template< class _CharT> inline bool 
# 2548
isupper(_CharT __c, const locale &__loc) 
# 2549
{ return (use_facet< ctype< _CharT> > (__loc).is(ctype_base::upper, __c)); } 
# 2552
template< class _CharT> inline bool 
# 2554
islower(_CharT __c, const locale &__loc) 
# 2555
{ return (use_facet< ctype< _CharT> > (__loc).is(ctype_base::lower, __c)); } 
# 2558
template< class _CharT> inline bool 
# 2560
isalpha(_CharT __c, const locale &__loc) 
# 2561
{ return (use_facet< ctype< _CharT> > (__loc).is(ctype_base::alpha, __c)); } 
# 2564
template< class _CharT> inline bool 
# 2566
isdigit(_CharT __c, const locale &__loc) 
# 2567
{ return (use_facet< ctype< _CharT> > (__loc).is(ctype_base::digit, __c)); } 
# 2570
template< class _CharT> inline bool 
# 2572
ispunct(_CharT __c, const locale &__loc) 
# 2573
{ return (use_facet< ctype< _CharT> > (__loc).is(ctype_base::punct, __c)); } 
# 2576
template< class _CharT> inline bool 
# 2578
isxdigit(_CharT __c, const locale &__loc) 
# 2579
{ return (use_facet< ctype< _CharT> > (__loc).is(ctype_base::xdigit, __c)); } 
# 2582
template< class _CharT> inline bool 
# 2584
isalnum(_CharT __c, const locale &__loc) 
# 2585
{ return (use_facet< ctype< _CharT> > (__loc).is(ctype_base::alnum, __c)); } 
# 2588
template< class _CharT> inline bool 
# 2590
isgraph(_CharT __c, const locale &__loc) 
# 2591
{ return (use_facet< ctype< _CharT> > (__loc).is(ctype_base::graph, __c)); } 
# 2594
template< class _CharT> inline _CharT 
# 2596
toupper(_CharT __c, const locale &__loc) 
# 2597
{ return (use_facet< ctype< _CharT> > (__loc).toupper(__c)); } 
# 2600
template< class _CharT> inline _CharT 
# 2602
tolower(_CharT __c, const locale &__loc) 
# 2603
{ return (use_facet< ctype< _CharT> > (__loc).tolower(__c)); } 
# 2606
}
# 35 "/usr/include/c++/4.8.2/bits/locale_facets.tcc" 3
namespace std __attribute((__visibility__("default"))) { 
# 41
template< class _Facet> 
# 42
struct __use_cache { 
# 45
const _Facet *operator()(const locale & __loc) const; 
# 46
}; 
# 49
template< class _CharT> 
# 50
struct __use_cache< __numpunct_cache< _CharT> >  { 
# 53
const __numpunct_cache< _CharT>  *operator()(const locale &__loc) const 
# 54
{ 
# 55
const size_t __i = (numpunct< _CharT> ::id._M_id)(); 
# 56
const locale::facet **__caches = (__loc._M_impl)->_M_caches; 
# 57
if (!(__caches[__i])) 
# 58
{ 
# 59
__numpunct_cache< _CharT>  *__tmp = (0); 
# 60
try 
# 61
{ 
# 62
__tmp = (new __numpunct_cache< _CharT> ); 
# 63
(__tmp->_M_cache(__loc)); 
# 64
} 
# 65
catch (...) 
# 66
{ 
# 67
delete __tmp; 
# 68
throw; 
# 69
}  
# 70
(__loc._M_impl)->_M_install_cache(__tmp, __i); 
# 71
}  
# 72
return static_cast< const __numpunct_cache< _CharT>  *>(__caches[__i]); 
# 73
} 
# 74
}; 
# 76
template< class _CharT> void 
# 78
__numpunct_cache< _CharT> ::_M_cache(const locale &__loc) 
# 79
{ 
# 80
(_M_allocated) = true; 
# 82
const numpunct< _CharT>  &__np = use_facet< numpunct< _CharT> > (__loc); 
# 84
char *__grouping = (0); 
# 85
_CharT *__truename = (0); 
# 86
_CharT *__falsename = (0); 
# 87
try 
# 88
{ 
# 89
(_M_grouping_size) = ((__np.grouping()).size()); 
# 90
__grouping = (new char [_M_grouping_size]); 
# 91
((__np.grouping()).copy(__grouping, _M_grouping_size)); 
# 92
(_M_grouping) = __grouping; 
# 93
(_M_use_grouping) = ((_M_grouping_size) && ((static_cast< signed char>((_M_grouping)[0])) > 0) && (((_M_grouping)[0]) != __gnu_cxx::__numeric_traits_integer< char> ::__max)); 
# 98
(_M_truename_size) = ((__np.truename()).size()); 
# 99
__truename = (new _CharT [_M_truename_size]); 
# 100
((__np.truename()).copy(__truename, _M_truename_size)); 
# 101
(_M_truename) = __truename; 
# 103
(_M_falsename_size) = ((__np.falsename()).size()); 
# 104
__falsename = (new _CharT [_M_falsename_size]); 
# 105
((__np.falsename()).copy(__falsename, _M_falsename_size)); 
# 106
(_M_falsename) = __falsename; 
# 108
(_M_decimal_point) = (__np.decimal_point()); 
# 109
(_M_thousands_sep) = (__np.thousands_sep()); 
# 111
const ctype< _CharT>  &__ct = use_facet< ctype< _CharT> > (__loc); 
# 112
(__ct.widen(__num_base::_S_atoms_out, __num_base::_S_atoms_out + __num_base::_S_oend, _M_atoms_out)); 
# 115
(__ct.widen(__num_base::_S_atoms_in, __num_base::_S_atoms_in + __num_base::_S_iend, _M_atoms_in)); 
# 118
} 
# 119
catch (...) 
# 120
{ 
# 121
delete [] __grouping; 
# 122
delete [] __truename; 
# 123
delete [] __falsename; 
# 124
throw; 
# 125
}  
# 126
} 
# 136
__attribute((__pure__)) bool 
# 137
__verify_grouping(const char * __grouping, size_t __grouping_size, const string & __grouping_tmp) throw(); 
# 140
inline namespace __gnu_cxx_ldbl128 { 
# 142
template< class _CharT, class _InIter> _InIter 
# 145
num_get< _CharT, _InIter> ::_M_extract_float(_InIter __beg, _InIter __end, ios_base &__io, ios_base::iostate &
# 146
__err, string &__xtrc) const 
# 147
{ 
# 148
typedef char_traits< _CharT>  __traits_type; 
# 149
typedef __numpunct_cache< _CharT>  __cache_type; 
# 150
__use_cache< __numpunct_cache< _CharT> >  __uc; 
# 151
const locale &__loc = __io._M_getloc(); 
# 152
const __cache_type *__lc = __uc(__loc); 
# 153
const _CharT *__lit = ((__lc->_M_atoms_in)); 
# 154
char_type __c = (char_type()); 
# 157
bool __testeof = __beg == __end; 
# 160
if (!__testeof) 
# 161
{ 
# 162
__c = (*__beg); 
# 163
const bool __plus = __c == (__lit[__num_base::_S_iplus]); 
# 164
if ((__plus || (__c == (__lit[__num_base::_S_iminus]))) && (!((__lc->_M_use_grouping) && (__c == (__lc->_M_thousands_sep)))) && (!(__c == (__lc->_M_decimal_point)))) 
# 167
{ 
# 168
(__xtrc += (__plus ? '+' : '-')); 
# 169
if ((++__beg) != __end) { 
# 170
__c = (*__beg); } else { 
# 172
__testeof = true; }  
# 173
}  
# 174
}  
# 177
bool __found_mantissa = false; 
# 178
int __sep_pos = 0; 
# 179
while (!__testeof) 
# 180
{ 
# 181
if (((__lc->_M_use_grouping) && (__c == (__lc->_M_thousands_sep))) || (__c == (__lc->_M_decimal_point))) { 
# 183
break; } else { 
# 184
if (__c == (__lit[__num_base::_S_izero])) 
# 185
{ 
# 186
if (!__found_mantissa) 
# 187
{ 
# 188
(__xtrc += ('0')); 
# 189
__found_mantissa = true; 
# 190
}  
# 191
++__sep_pos; 
# 193
if ((++__beg) != __end) { 
# 194
__c = (*__beg); } else { 
# 196
__testeof = true; }  
# 197
} else { 
# 199
break; }  }  
# 200
}  
# 203
bool __found_dec = false; 
# 204
bool __found_sci = false; 
# 205
string __found_grouping; 
# 206
if (__lc->_M_use_grouping) { 
# 207
__found_grouping.reserve(32); }  
# 208
const char_type *__lit_zero = __lit + __num_base::_S_izero; 
# 210
if (!(__lc->_M_allocated)) { 
# 212
while (!__testeof) { 
# 213
{ 
# 214
const int __digit = _M_find(__lit_zero, 10, __c); 
# 215
if (__digit != (-1)) 
# 216
{ 
# 217
(__xtrc += (('0') + __digit)); 
# 218
__found_mantissa = true; 
# 219
} else { 
# 220
if ((__c == (__lc->_M_decimal_point)) && (!__found_dec) && (!__found_sci)) 
# 222
{ 
# 223
(__xtrc += ('.')); 
# 224
__found_dec = true; 
# 225
} else { 
# 226
if (((__c == (__lit[__num_base::_S_ie])) || (__c == (__lit[__num_base::_S_iE]))) && (!__found_sci) && __found_mantissa) 
# 229
{ 
# 231
(__xtrc += ('e')); 
# 232
__found_sci = true; 
# 235
if ((++__beg) != __end) 
# 236
{ 
# 237
__c = (*__beg); 
# 238
const bool __plus = __c == (__lit[__num_base::_S_iplus]); 
# 239
if (__plus || (__c == (__lit[__num_base::_S_iminus]))) { 
# 240
(__xtrc += (__plus ? '+' : '-')); } else { 
# 242
continue; }  
# 243
} else 
# 245
{ 
# 246
__testeof = true; 
# 247
break; 
# 248
}  
# 249
} else { 
# 251
break; }  }  }  
# 253
if ((++__beg) != __end) { 
# 254
__c = (*__beg); } else { 
# 256
__testeof = true; }  
# 257
} }  } else { 
# 259
while (!__testeof) { 
# 260
{ 
# 263
if ((__lc->_M_use_grouping) && (__c == (__lc->_M_thousands_sep))) 
# 264
{ 
# 265
if ((!__found_dec) && (!__found_sci)) 
# 266
{ 
# 269
if (__sep_pos) 
# 270
{ 
# 271
(__found_grouping += (static_cast< char>(__sep_pos))); 
# 272
__sep_pos = 0; 
# 273
} else 
# 275
{ 
# 278
__xtrc.clear(); 
# 279
break; 
# 280
}  
# 281
} else { 
# 283
break; }  
# 284
} else { 
# 285
if (__c == (__lc->_M_decimal_point)) 
# 286
{ 
# 287
if ((!__found_dec) && (!__found_sci)) 
# 288
{ 
# 292
if (__found_grouping.size()) { 
# 293
(__found_grouping += (static_cast< char>(__sep_pos))); }  
# 294
(__xtrc += ('.')); 
# 295
__found_dec = true; 
# 296
} else { 
# 298
break; }  
# 299
} else 
# 301
{ 
# 302
const char_type *__q = __traits_type::find(__lit_zero, 10, __c); 
# 304
if (__q) 
# 305
{ 
# 306
__xtrc += ('0' + (__q - __lit_zero)); 
# 307
__found_mantissa = true; 
# 308
++__sep_pos; 
# 309
} else { 
# 310
if (((__c == (__lit[__num_base::_S_ie])) || (__c == (__lit[__num_base::_S_iE]))) && (!__found_sci) && __found_mantissa) 
# 313
{ 
# 315
if ((__found_grouping.size()) && (!__found_dec)) { 
# 316
(__found_grouping += (static_cast< char>(__sep_pos))); }  
# 317
(__xtrc += ('e')); 
# 318
__found_sci = true; 
# 321
if ((++__beg) != __end) 
# 322
{ 
# 323
__c = (*__beg); 
# 324
const bool __plus = __c == (__lit[__num_base::_S_iplus]); 
# 325
if ((__plus || (__c == (__lit[__num_base::_S_iminus]))) && (!((__lc->_M_use_grouping) && (__c == (__lc->_M_thousands_sep)))) && (!(__c == (__lc->_M_decimal_point)))) { 
# 329
(__xtrc += (__plus ? '+' : '-')); } else { 
# 331
continue; }  
# 332
} else 
# 334
{ 
# 335
__testeof = true; 
# 336
break; 
# 337
}  
# 338
} else { 
# 340
break; }  }  
# 341
}  }  
# 343
if ((++__beg) != __end) { 
# 344
__c = (*__beg); } else { 
# 346
__testeof = true; }  
# 347
} }  }  
# 351
if (__found_grouping.size()) 
# 352
{ 
# 354
if ((!__found_dec) && (!__found_sci)) { 
# 355
(__found_grouping += (static_cast< char>(__sep_pos))); }  
# 357
if (!std::__verify_grouping((__lc->_M_grouping), (__lc->_M_grouping_size), __found_grouping)) { 
# 360
__err = ios_base::failbit; }  
# 361
}  
# 363
return __beg; 
# 364
} 
# 366
template< class _CharT, class _InIter> 
# 367
template< class _ValueT> _InIter 
# 370
num_get< _CharT, _InIter> ::_M_extract_int(_InIter __beg, _InIter __end, ios_base &__io, ios_base::iostate &
# 371
__err, _ValueT &__v) const 
# 372
{ 
# 373
typedef char_traits< _CharT>  __traits_type; 
# 374
using __gnu_cxx::__add_unsigned;
# 375
typedef typename __gnu_cxx::__add_unsigned< _ValueT> ::__type __unsigned_type; 
# 376
typedef __numpunct_cache< _CharT>  __cache_type; 
# 377
__use_cache< __numpunct_cache< _CharT> >  __uc; 
# 378
const locale &__loc = __io._M_getloc(); 
# 379
const __cache_type *__lc = __uc(__loc); 
# 380
const _CharT *__lit = ((__lc->_M_atoms_in)); 
# 381
char_type __c = (char_type()); 
# 384
const ios_base::fmtflags __basefield = ((__io.flags()) & ios_base::basefield); 
# 386
const bool __oct = __basefield == ios_base::oct; 
# 387
int __base = __oct ? 8 : ((__basefield == ios_base::hex) ? 16 : 10); 
# 390
bool __testeof = __beg == __end; 
# 393
bool __negative = false; 
# 394
if (!__testeof) 
# 395
{ 
# 396
__c = (*__beg); 
# 397
__negative = (__c == (__lit[__num_base::_S_iminus])); 
# 398
if ((__negative || (__c == (__lit[__num_base::_S_iplus]))) && (!((__lc->_M_use_grouping) && (__c == (__lc->_M_thousands_sep)))) && (!(__c == (__lc->_M_decimal_point)))) 
# 401
{ 
# 402
if ((++__beg) != __end) { 
# 403
__c = (*__beg); } else { 
# 405
__testeof = true; }  
# 406
}  
# 407
}  
# 411
bool __found_zero = false; 
# 412
int __sep_pos = 0; 
# 413
while (!__testeof) 
# 414
{ 
# 415
if (((__lc->_M_use_grouping) && (__c == (__lc->_M_thousands_sep))) || (__c == (__lc->_M_decimal_point))) { 
# 417
break; } else { 
# 418
if ((__c == (__lit[__num_base::_S_izero])) && ((!__found_zero) || (__base == 10))) 
# 420
{ 
# 421
__found_zero = true; 
# 422
++__sep_pos; 
# 423
if (__basefield == 0) { 
# 424
__base = 8; }  
# 425
if (__base == 8) { 
# 426
__sep_pos = 0; }  
# 427
} else { 
# 428
if (__found_zero && ((__c == (__lit[__num_base::_S_ix])) || (__c == (__lit[__num_base::_S_iX])))) 
# 431
{ 
# 432
if (__basefield == 0) { 
# 433
__base = 16; }  
# 434
if (__base == 16) 
# 435
{ 
# 436
__found_zero = false; 
# 437
__sep_pos = 0; 
# 438
} else { 
# 440
break; }  
# 441
} else { 
# 443
break; }  }  }  
# 445
if ((++__beg) != __end) 
# 446
{ 
# 447
__c = (*__beg); 
# 448
if (!__found_zero) { 
# 449
break; }  
# 450
} else { 
# 452
__testeof = true; }  
# 453
}  
# 457
const size_t __len = (__base == 16) ? (__num_base::_S_iend) - (__num_base::_S_izero) : __base; 
# 461
string __found_grouping; 
# 462
if (__lc->_M_use_grouping) { 
# 463
__found_grouping.reserve(32); }  
# 464
bool __testfail = false; 
# 465
bool __testoverflow = false; 
# 466
const __unsigned_type __max = (__negative && __gnu_cxx::__numeric_traits< _ValueT> ::__is_signed) ? -__gnu_cxx::__numeric_traits< _ValueT> ::__min : __gnu_cxx::__numeric_traits< _ValueT> ::__max; 
# 470
const __unsigned_type __smax = __max / __base; 
# 471
__unsigned_type __result = (0); 
# 472
int __digit = 0; 
# 473
const char_type *__lit_zero = __lit + __num_base::_S_izero; 
# 475
if (!(__lc->_M_allocated)) { 
# 477
while (!__testeof) 
# 478
{ 
# 479
__digit = _M_find(__lit_zero, __len, __c); 
# 480
if (__digit == (-1)) { 
# 481
break; }  
# 483
if (__result > __smax) { 
# 484
__testoverflow = true; } else 
# 486
{ 
# 487
__result *= __base; 
# 488
__testoverflow |= (__result > (__max - __digit)); 
# 489
__result += __digit; 
# 490
++__sep_pos; 
# 491
}  
# 493
if ((++__beg) != __end) { 
# 494
__c = (*__beg); } else { 
# 496
__testeof = true; }  
# 497
}  } else { 
# 499
while (!__testeof) 
# 500
{ 
# 503
if ((__lc->_M_use_grouping) && (__c == (__lc->_M_thousands_sep))) 
# 504
{ 
# 507
if (__sep_pos) 
# 508
{ 
# 509
(__found_grouping += (static_cast< char>(__sep_pos))); 
# 510
__sep_pos = 0; 
# 511
} else 
# 513
{ 
# 514
__testfail = true; 
# 515
break; 
# 516
}  
# 517
} else { 
# 518
if (__c == (__lc->_M_decimal_point)) { 
# 519
break; } else 
# 521
{ 
# 522
const char_type *__q = __traits_type::find(__lit_zero, __len, __c); 
# 524
if (!__q) { 
# 525
break; }  
# 527
__digit = (__q - __lit_zero); 
# 528
if (__digit > 15) { 
# 529
__digit -= 6; }  
# 530
if (__result > __smax) { 
# 531
__testoverflow = true; } else 
# 533
{ 
# 534
__result *= __base; 
# 535
__testoverflow |= (__result > (__max - __digit)); 
# 536
__result += __digit; 
# 537
++__sep_pos; 
# 538
}  
# 539
}  }  
# 541
if ((++__beg) != __end) { 
# 542
__c = (*__beg); } else { 
# 544
__testeof = true; }  
# 545
}  }  
# 549
if (__found_grouping.size()) 
# 550
{ 
# 552
(__found_grouping += (static_cast< char>(__sep_pos))); 
# 554
if (!std::__verify_grouping((__lc->_M_grouping), (__lc->_M_grouping_size), __found_grouping)) { 
# 557
__err = ios_base::failbit; }  
# 558
}  
# 562
if (((!__sep_pos) && (!__found_zero) && (!(__found_grouping.size()))) || __testfail) 
# 564
{ 
# 565
__v = 0; 
# 566
__err = ios_base::failbit; 
# 567
} else { 
# 568
if (__testoverflow) 
# 569
{ 
# 570
if (__negative && __gnu_cxx::__numeric_traits< _ValueT> ::__is_signed) { 
# 572
__v = __gnu_cxx::__numeric_traits< _ValueT> ::__min; } else { 
# 574
__v = __gnu_cxx::__numeric_traits< _ValueT> ::__max; }  
# 575
__err = ios_base::failbit; 
# 576
} else { 
# 578
__v = (__negative ? -__result : __result); }  }  
# 580
if (__testeof) { 
# 581
(__err |= ios_base::eofbit); }  
# 582
return __beg; 
# 583
} 
# 587
template< class _CharT, class _InIter> _InIter 
# 590
num_get< _CharT, _InIter> ::do_get(iter_type __beg, iter_type __end, ios_base &__io, ios_base::iostate &
# 591
__err, bool &__v) const 
# 592
{ 
# 593
if (!(((__io.flags()) & ios_base::boolalpha))) 
# 594
{ 
# 598
long __l = (-1); 
# 599
__beg = _M_extract_int(__beg, __end, __io, __err, __l); 
# 600
if ((__l == (0)) || (__l == (1))) { 
# 601
__v = ((bool)__l); } else 
# 603
{ 
# 606
__v = true; 
# 607
__err = ios_base::failbit; 
# 608
if (__beg == __end) { 
# 609
(__err |= ios_base::eofbit); }  
# 610
}  
# 611
} else 
# 613
{ 
# 615
typedef __numpunct_cache< _CharT>  __cache_type; 
# 616
__use_cache< __numpunct_cache< _CharT> >  __uc; 
# 617
const locale &__loc = __io._M_getloc(); 
# 618
const __cache_type *__lc = __uc(__loc); 
# 620
bool __testf = true; 
# 621
bool __testt = true; 
# 622
bool __donef = (__lc->_M_falsename_size) == 0; 
# 623
bool __donet = (__lc->_M_truename_size) == 0; 
# 624
bool __testeof = false; 
# 625
size_t __n = (0); 
# 626
while ((!__donef) || (!__donet)) 
# 627
{ 
# 628
if (__beg == __end) 
# 629
{ 
# 630
__testeof = true; 
# 631
break; 
# 632
}  
# 634
const char_type __c = *__beg; 
# 636
if (!__donef) { 
# 637
__testf = (__c == ((__lc->_M_falsename)[__n])); }  
# 639
if ((!__testf) && __donet) { 
# 640
break; }  
# 642
if (!__donet) { 
# 643
__testt = (__c == ((__lc->_M_truename)[__n])); }  
# 645
if ((!__testt) && __donef) { 
# 646
break; }  
# 648
if ((!__testt) && (!__testf)) { 
# 649
break; }  
# 651
++__n; 
# 652
++__beg; 
# 654
__donef = ((!__testf) || (__n >= (__lc->_M_falsename_size))); 
# 655
__donet = ((!__testt) || (__n >= (__lc->_M_truename_size))); 
# 656
}  
# 657
if (__testf && (__n == (__lc->_M_falsename_size)) && __n) 
# 658
{ 
# 659
__v = false; 
# 660
if (__testt && (__n == (__lc->_M_truename_size))) { 
# 661
__err = ios_base::failbit; } else { 
# 663
__err = (__testeof ? ios_base::eofbit : ios_base::goodbit); }  
# 664
} else { 
# 665
if (__testt && (__n == (__lc->_M_truename_size)) && __n) 
# 666
{ 
# 667
__v = true; 
# 668
__err = (__testeof ? ios_base::eofbit : ios_base::goodbit); 
# 669
} else 
# 671
{ 
# 674
__v = false; 
# 675
__err = ios_base::failbit; 
# 676
if (__testeof) { 
# 677
(__err |= ios_base::eofbit); }  
# 678
}  }  
# 679
}  
# 680
return __beg; 
# 681
} 
# 683
template< class _CharT, class _InIter> _InIter 
# 686
num_get< _CharT, _InIter> ::do_get(iter_type __beg, iter_type __end, ios_base &__io, ios_base::iostate &
# 687
__err, float &__v) const 
# 688
{ 
# 689
string __xtrc; 
# 690
__xtrc.reserve(32); 
# 691
__beg = _M_extract_float(__beg, __end, __io, __err, __xtrc); 
# 692
std::__convert_to_v(__xtrc.c_str(), __v, __err, _S_get_c_locale()); 
# 693
if (__beg == __end) { 
# 694
(__err |= ios_base::eofbit); }  
# 695
return __beg; 
# 696
} 
# 698
template< class _CharT, class _InIter> _InIter 
# 701
num_get< _CharT, _InIter> ::do_get(iter_type __beg, iter_type __end, ios_base &__io, ios_base::iostate &
# 702
__err, double &__v) const 
# 703
{ 
# 704
string __xtrc; 
# 705
__xtrc.reserve(32); 
# 706
__beg = _M_extract_float(__beg, __end, __io, __err, __xtrc); 
# 707
std::__convert_to_v(__xtrc.c_str(), __v, __err, _S_get_c_locale()); 
# 708
if (__beg == __end) { 
# 709
(__err |= ios_base::eofbit); }  
# 710
return __beg; 
# 711
} 
# 714
template< class _CharT, class _InIter> _InIter 
# 717
num_get< _CharT, _InIter> ::__do_get(iter_type __beg, iter_type __end, ios_base &__io, ios_base::iostate &
# 718
__err, double &__v) const 
# 719
{ 
# 720
string __xtrc; 
# 721
__xtrc.reserve(32); 
# 722
__beg = _M_extract_float(__beg, __end, __io, __err, __xtrc); 
# 723
std::__convert_to_v(__xtrc.c_str(), __v, __err, _S_get_c_locale()); 
# 724
if (__beg == __end) { 
# 725
(__err |= ios_base::eofbit); }  
# 726
return __beg; 
# 727
} 
# 730
template< class _CharT, class _InIter> _InIter 
# 733
num_get< _CharT, _InIter> ::do_get(iter_type __beg, iter_type __end, ios_base &__io, ios_base::iostate &
# 734
__err, long double &__v) const 
# 735
{ 
# 736
string __xtrc; 
# 737
__xtrc.reserve(32); 
# 738
__beg = _M_extract_float(__beg, __end, __io, __err, __xtrc); 
# 739
std::__convert_to_v(__xtrc.c_str(), __v, __err, _S_get_c_locale()); 
# 740
if (__beg == __end) { 
# 741
(__err |= ios_base::eofbit); }  
# 742
return __beg; 
# 743
} 
# 745
template< class _CharT, class _InIter> _InIter 
# 748
num_get< _CharT, _InIter> ::do_get(iter_type __beg, iter_type __end, ios_base &__io, ios_base::iostate &
# 749
__err, void *&__v) const 
# 750
{ 
# 752
typedef ios_base::fmtflags fmtflags; 
# 753
const fmtflags __fmt = __io.flags(); 
# 754
__io.flags((((__fmt & ((~ios_base::basefield)))) | ios_base::hex)); 
# 758
typedef __gnu_cxx::__conditional_type< true, unsigned long, unsigned long long> ::__type _UIntPtrType; 
# 760
_UIntPtrType __ul; 
# 761
__beg = _M_extract_int(__beg, __end, __io, __err, __ul); 
# 764
__io.flags(__fmt); 
# 766
__v = (reinterpret_cast< void *>(__ul)); 
# 767
return __beg; 
# 768
} 
# 772
template< class _CharT, class _OutIter> void 
# 775
num_put< _CharT, _OutIter> ::_M_pad(_CharT __fill, streamsize __w, ios_base &__io, _CharT *
# 776
__new, const _CharT *__cs, int &__len) const 
# 777
{ 
# 780
__pad< _CharT, char_traits< _CharT> > ::_S_pad(__io, __fill, __new, __cs, __w, __len); 
# 782
__len = (static_cast< int>(__w)); 
# 783
} 
# 785
}
# 787
template< class _CharT, class _ValueT> int 
# 789
__int_to_char(_CharT *__bufend, _ValueT __v, const _CharT *__lit, ios_base::fmtflags 
# 790
__flags, bool __dec) 
# 791
{ 
# 792
_CharT *__buf = __bufend; 
# 793
if (__builtin_expect(__dec, true)) 
# 794
{ 
# 796
do 
# 797
{ 
# 798
(*(--__buf)) = (__lit[(__v % 10) + __num_base::_S_odigits]); 
# 799
__v /= 10; 
# 800
} 
# 801
while (__v != 0); 
# 802
} else { 
# 803
if (((__flags & ios_base::basefield)) == ios_base::oct) 
# 804
{ 
# 806
do 
# 807
{ 
# 808
(*(--__buf)) = (__lit[(__v & 7) + __num_base::_S_odigits]); 
# 809
__v >>= 3; 
# 810
} 
# 811
while (__v != 0); 
# 812
} else 
# 814
{ 
# 816
const bool __uppercase = (__flags & ios_base::uppercase); 
# 817
const int __case_offset = __uppercase ? __num_base::_S_oudigits : __num_base::_S_odigits; 
# 819
do 
# 820
{ 
# 821
(*(--__buf)) = (__lit[(__v & 15) + __case_offset]); 
# 822
__v >>= 4; 
# 823
} 
# 824
while (__v != 0); 
# 825
}  }  
# 826
return __bufend - __buf; 
# 827
} 
# 829
inline namespace __gnu_cxx_ldbl128 { 
# 831
template< class _CharT, class _OutIter> void 
# 834
num_put< _CharT, _OutIter> ::_M_group_int(const char *__grouping, size_t __grouping_size, _CharT __sep, ios_base &, _CharT *
# 835
__new, _CharT *__cs, int &__len) const 
# 836
{ 
# 837
_CharT *__p = std::__add_grouping(__new, __sep, __grouping, __grouping_size, __cs, __cs + __len); 
# 839
__len = (__p - __new); 
# 840
} 
# 842
template< class _CharT, class _OutIter> 
# 843
template< class _ValueT> _OutIter 
# 846
num_put< _CharT, _OutIter> ::_M_insert_int(_OutIter __s, ios_base &__io, _CharT __fill, _ValueT 
# 847
__v) const 
# 848
{ 
# 849
using __gnu_cxx::__add_unsigned;
# 850
typedef typename __gnu_cxx::__add_unsigned< _ValueT> ::__type __unsigned_type; 
# 851
typedef __numpunct_cache< _CharT>  __cache_type; 
# 852
__use_cache< __numpunct_cache< _CharT> >  __uc; 
# 853
const locale &__loc = __io._M_getloc(); 
# 854
const __cache_type *__lc = __uc(__loc); 
# 855
const _CharT *__lit = ((__lc->_M_atoms_out)); 
# 856
const ios_base::fmtflags __flags = __io.flags(); 
# 859
const int __ilen = ((5) * sizeof(_ValueT)); 
# 860
_CharT *__cs = static_cast< _CharT *>(__builtin_alloca(sizeof(_CharT) * __ilen)); 
# 865
const ios_base::fmtflags __basefield = (__flags & ios_base::basefield); 
# 866
const bool __dec = (__basefield != ios_base::oct) && (__basefield != ios_base::hex); 
# 868
const __unsigned_type __u = ((__v > 0) || (!__dec)) ? (__unsigned_type)__v : (-((__unsigned_type)__v)); 
# 871
int __len = __int_to_char(__cs + __ilen, __u, __lit, __flags, __dec); 
# 872
__cs += (__ilen - __len); 
# 875
if (__lc->_M_use_grouping) 
# 876
{ 
# 879
_CharT *__cs2 = static_cast< _CharT *>(__builtin_alloca((sizeof(_CharT) * (__len + 1)) * (2))); 
# 882
_M_group_int((__lc->_M_grouping), (__lc->_M_grouping_size), (__lc->_M_thousands_sep), __io, __cs2 + 2, __cs, __len); 
# 884
__cs = (__cs2 + 2); 
# 885
}  
# 888
if (__builtin_expect(__dec, true)) 
# 889
{ 
# 891
if (__v >= 0) 
# 892
{ 
# 893
if (((bool)((__flags & ios_base::showpos))) && __gnu_cxx::__numeric_traits< _ValueT> ::__is_signed) { 
# 895
((*(--__cs)) = (__lit[__num_base::_S_oplus])), (++__len); }  
# 896
} else { 
# 898
((*(--__cs)) = (__lit[__num_base::_S_ominus])), (++__len); }  
# 899
} else { 
# 900
if (((bool)((__flags & ios_base::showbase))) && __v) 
# 901
{ 
# 902
if (__basefield == ios_base::oct) { 
# 903
((*(--__cs)) = (__lit[__num_base::_S_odigits])), (++__len); } else 
# 905
{ 
# 907
const bool __uppercase = (__flags & ios_base::uppercase); 
# 908
(*(--__cs)) = (__lit[(__num_base::_S_ox) + __uppercase]); 
# 910
(*(--__cs)) = (__lit[__num_base::_S_odigits]); 
# 911
__len += 2; 
# 912
}  
# 913
}  }  
# 916
const streamsize __w = __io.width(); 
# 917
if (__w > (static_cast< streamsize>(__len))) 
# 918
{ 
# 919
_CharT *__cs3 = static_cast< _CharT *>(__builtin_alloca(sizeof(_CharT) * __w)); 
# 921
_M_pad(__fill, __w, __io, __cs3, __cs, __len); 
# 922
__cs = __cs3; 
# 923
}  
# 924
__io.width(0); 
# 928
return std::__write(__s, __cs, __len); 
# 929
} 
# 931
template< class _CharT, class _OutIter> void 
# 934
num_put< _CharT, _OutIter> ::_M_group_float(const char *__grouping, size_t __grouping_size, _CharT 
# 935
__sep, const _CharT *__p, _CharT *__new, _CharT *
# 936
__cs, int &__len) const 
# 937
{ 
# 941
const int __declen = (__p) ? __p - __cs : __len; 
# 942
_CharT *__p2 = std::__add_grouping(__new, __sep, __grouping, __grouping_size, __cs, __cs + __declen); 
# 947
int __newlen = __p2 - __new; 
# 948
if (__p) 
# 949
{ 
# 950
char_traits< _CharT> ::copy(__p2, __p, __len - __declen); 
# 951
__newlen += (__len - __declen); 
# 952
}  
# 953
__len = __newlen; 
# 954
} 
# 966
template< class _CharT, class _OutIter> 
# 967
template< class _ValueT> _OutIter 
# 970
num_put< _CharT, _OutIter> ::_M_insert_float(_OutIter __s, ios_base &__io, _CharT __fill, char __mod, _ValueT 
# 971
__v) const 
# 972
{ 
# 973
typedef __numpunct_cache< _CharT>  __cache_type; 
# 974
__use_cache< __numpunct_cache< _CharT> >  __uc; 
# 975
const locale &__loc = __io._M_getloc(); 
# 976
const __cache_type *__lc = __uc(__loc); 
# 979
const streamsize __prec = (__io.precision() < (0)) ? 6 : __io.precision(); 
# 981
const int __max_digits = (__gnu_cxx::__numeric_traits< _ValueT> ::__digits10); 
# 985
int __len; 
# 987
char __fbuf[16]; 
# 988
__num_base::_S_format_float(__io, __fbuf, __mod); 
# 993
int __cs_size = (__max_digits * 3); 
# 994
char *__cs = static_cast< char *>(__builtin_alloca(__cs_size)); 
# 995
__len = std::__convert_from_v(_S_get_c_locale(), __cs, __cs_size, __fbuf, __prec, __v); 
# 999
if (__len >= __cs_size) 
# 1000
{ 
# 1001
__cs_size = (__len + 1); 
# 1002
__cs = (static_cast< char *>(__builtin_alloca(__cs_size))); 
# 1003
__len = std::__convert_from_v(_S_get_c_locale(), __cs, __cs_size, __fbuf, __prec, __v); 
# 1005
}  
# 1027
const ctype< _CharT>  &__ctype = use_facet< ctype< _CharT> > (__loc); 
# 1029
_CharT *__ws = static_cast< _CharT *>(__builtin_alloca(sizeof(_CharT) * __len)); 
# 1031
(__ctype.widen(__cs, __cs + __len, __ws)); 
# 1034
_CharT *__wp = (0); 
# 1035
const char *__p = char_traits< char> ::find(__cs, __len, '.'); 
# 1036
if (__p) 
# 1037
{ 
# 1038
__wp = (__ws + (__p - __cs)); 
# 1039
(*__wp) = (__lc->_M_decimal_point); 
# 1040
}  
# 1045
if ((__lc->_M_use_grouping) && ((__wp || (__len < 3)) || (((__cs[1]) <= ('9')) && ((__cs[2]) <= ('9')) && ((__cs[1]) >= ('0')) && ((__cs[2]) >= ('0'))))) 
# 1048
{ 
# 1051
_CharT *__ws2 = static_cast< _CharT *>(__builtin_alloca((sizeof(_CharT) * __len) * (2))); 
# 1054
streamsize __off = (0); 
# 1055
if (((__cs[0]) == ('-')) || ((__cs[0]) == ('+'))) 
# 1056
{ 
# 1057
__off = (1); 
# 1058
(__ws2[0]) = (__ws[0]); 
# 1059
__len -= 1; 
# 1060
}  
# 1062
_M_group_float((__lc->_M_grouping), (__lc->_M_grouping_size), (__lc->_M_thousands_sep), __wp, __ws2 + __off, __ws + __off, __len); 
# 1065
__len += __off; 
# 1067
__ws = __ws2; 
# 1068
}  
# 1071
const streamsize __w = __io.width(); 
# 1072
if (__w > (static_cast< streamsize>(__len))) 
# 1073
{ 
# 1074
_CharT *__ws3 = static_cast< _CharT *>(__builtin_alloca(sizeof(_CharT) * __w)); 
# 1076
_M_pad(__fill, __w, __io, __ws3, __ws, __len); 
# 1077
__ws = __ws3; 
# 1078
}  
# 1079
__io.width(0); 
# 1083
return std::__write(__s, __ws, __len); 
# 1084
} 
# 1086
template< class _CharT, class _OutIter> _OutIter 
# 1089
num_put< _CharT, _OutIter> ::do_put(iter_type __s, ios_base &__io, char_type __fill, bool __v) const 
# 1090
{ 
# 1091
const ios_base::fmtflags __flags = __io.flags(); 
# 1092
if (((__flags & ios_base::boolalpha)) == 0) 
# 1093
{ 
# 1094
const long __l = __v; 
# 1095
__s = _M_insert_int(__s, __io, __fill, __l); 
# 1096
} else 
# 1098
{ 
# 1099
typedef __numpunct_cache< _CharT>  __cache_type; 
# 1100
__use_cache< __numpunct_cache< _CharT> >  __uc; 
# 1101
const locale &__loc = __io._M_getloc(); 
# 1102
const __cache_type *__lc = __uc(__loc); 
# 1104
const _CharT *__name = __v ? __lc->_M_truename : (__lc->_M_falsename); 
# 1106
int __len = __v ? __lc->_M_truename_size : (__lc->_M_falsename_size); 
# 1109
const streamsize __w = __io.width(); 
# 1110
if (__w > (static_cast< streamsize>(__len))) 
# 1111
{ 
# 1112
const streamsize __plen = __w - __len; 
# 1113
_CharT *__ps = static_cast< _CharT *>(__builtin_alloca(sizeof(_CharT) * __plen)); 
# 1117
char_traits< _CharT> ::assign(__ps, __plen, __fill); 
# 1118
__io.width(0); 
# 1120
if (((__flags & ios_base::adjustfield)) == ios_base::left) 
# 1121
{ 
# 1122
__s = std::__write(__s, __name, __len); 
# 1123
__s = std::__write(__s, __ps, __plen); 
# 1124
} else 
# 1126
{ 
# 1127
__s = std::__write(__s, __ps, __plen); 
# 1128
__s = std::__write(__s, __name, __len); 
# 1129
}  
# 1130
return __s; 
# 1131
}  
# 1132
__io.width(0); 
# 1133
__s = std::__write(__s, __name, __len); 
# 1134
}  
# 1135
return __s; 
# 1136
} 
# 1138
template< class _CharT, class _OutIter> _OutIter 
# 1141
num_put< _CharT, _OutIter> ::do_put(iter_type __s, ios_base &__io, char_type __fill, double __v) const 
# 1142
{ return _M_insert_float(__s, __io, __fill, ((char)0), __v); } 
# 1145
template< class _CharT, class _OutIter> _OutIter 
# 1148
num_put< _CharT, _OutIter> ::__do_put(iter_type __s, ios_base &__io, char_type __fill, double __v) const 
# 1149
{ return _M_insert_float(__s, __io, __fill, ((char)0), __v); } 
# 1152
template< class _CharT, class _OutIter> _OutIter 
# 1155
num_put< _CharT, _OutIter> ::do_put(iter_type __s, ios_base &__io, char_type __fill, long double 
# 1156
__v) const 
# 1157
{ return _M_insert_float(__s, __io, __fill, 'L', __v); } 
# 1159
template< class _CharT, class _OutIter> _OutIter 
# 1162
num_put< _CharT, _OutIter> ::do_put(iter_type __s, ios_base &__io, char_type __fill, const void *
# 1163
__v) const 
# 1164
{ 
# 1165
const ios_base::fmtflags __flags = __io.flags(); 
# 1166
const ios_base::fmtflags __fmt = (~((ios_base::basefield | ios_base::uppercase))); 
# 1168
__io.flags((((__flags & __fmt)) | ((ios_base::hex | ios_base::showbase)))); 
# 1172
typedef __gnu_cxx::__conditional_type< true, unsigned long, unsigned long long> ::__type _UIntPtrType; 
# 1174
__s = _M_insert_int(__s, __io, __fill, reinterpret_cast< _UIntPtrType>(__v)); 
# 1176
__io.flags(__flags); 
# 1177
return __s; 
# 1178
} 
# 1180
}
# 1189
template< class _CharT, class _Traits> void 
# 1191
__pad< _CharT, _Traits> ::_S_pad(ios_base &__io, _CharT __fill, _CharT *
# 1192
__news, const _CharT *__olds, streamsize 
# 1193
__newlen, streamsize __oldlen) 
# 1194
{ 
# 1195
const size_t __plen = static_cast< size_t>(__newlen - __oldlen); 
# 1196
const ios_base::fmtflags __adjust = ((__io.flags()) & ios_base::adjustfield); 
# 1199
if (__adjust == ios_base::left) 
# 1200
{ 
# 1201
_Traits::copy(__news, __olds, __oldlen); 
# 1202
_Traits::assign(__news + __oldlen, __plen, __fill); 
# 1203
return; 
# 1204
}  
# 1206
size_t __mod = (0); 
# 1207
if (__adjust == ios_base::internal) 
# 1208
{ 
# 1212
const locale &__loc = __io._M_getloc(); 
# 1213
const ctype< _CharT>  &__ctype = use_facet< ctype< _CharT> > (__loc); 
# 1215
if (((__ctype.widen('-')) == (__olds[0])) || ((__ctype.widen('+')) == (__olds[0]))) 
# 1217
{ 
# 1218
(__news[0]) = (__olds[0]); 
# 1219
__mod = (1); 
# 1220
++__news; 
# 1221
} else { 
# 1222
if (((__ctype.widen('0')) == (__olds[0])) && (__oldlen > (1)) && (((__ctype.widen('x')) == (__olds[1])) || ((__ctype.widen('X')) == (__olds[1])))) 
# 1226
{ 
# 1227
(__news[0]) = (__olds[0]); 
# 1228
(__news[1]) = (__olds[1]); 
# 1229
__mod = (2); 
# 1230
__news += 2; 
# 1231
}  }  
# 1233
}  
# 1234
_Traits::assign(__news, __plen, __fill); 
# 1235
_Traits::copy(__news + __plen, __olds + __mod, __oldlen - __mod); 
# 1236
} 
# 1238
template< class _CharT> _CharT *
# 1240
__add_grouping(_CharT *__s, _CharT __sep, const char *
# 1241
__gbeg, size_t __gsize, const _CharT *
# 1242
__first, const _CharT *__last) 
# 1243
{ 
# 1244
size_t __idx = (0); 
# 1245
size_t __ctr = (0); 
# 1247
while (((__last - __first) > (__gbeg[__idx])) && ((static_cast< signed char>(__gbeg[__idx])) > 0) && ((__gbeg[__idx]) != __gnu_cxx::__numeric_traits_integer< char> ::__max)) 
# 1250
{ 
# 1251
__last -= (__gbeg[__idx]); 
# 1252
(__idx < (__gsize - (1))) ? ++__idx : (++__ctr); 
# 1253
}  
# 1255
while (__first != __last) { 
# 1256
(*(__s++)) = (*(__first++)); }  
# 1258
while (__ctr--) 
# 1259
{ 
# 1260
(*(__s++)) = __sep; 
# 1261
for (char __i = __gbeg[__idx]; __i > 0; --__i) { 
# 1262
(*(__s++)) = (*(__first++)); }  
# 1263
}  
# 1265
while (__idx--) 
# 1266
{ 
# 1267
(*(__s++)) = __sep; 
# 1268
for (char __i = __gbeg[__idx]; __i > 0; --__i) { 
# 1269
(*(__s++)) = (*(__first++)); }  
# 1270
}  
# 1272
return __s; 
# 1273
} 
# 1278
extern template class numpunct< char> ;
# 1279
extern template class numpunct_byname< char> ;
# 1280
extern template class __gnu_cxx_ldbl128::num_get< char, istreambuf_iterator< char, char_traits< char> > > ;
# 1281
extern template class __gnu_cxx_ldbl128::num_put< char, ostreambuf_iterator< char, char_traits< char> > > ;
# 1284
extern template const ctype< char>  &use_facet< ctype< char> > (const locale &);
# 1288
extern template const numpunct< char>  &use_facet< numpunct< char> > (const locale &);
# 1292
extern template const __gnu_cxx_ldbl128::num_put< char, ostreambuf_iterator< char, char_traits< char> > >  &use_facet< __gnu_cxx_ldbl128::num_put< char, ostreambuf_iterator< char, char_traits< char> > > > (const locale &);
# 1296
extern template const __gnu_cxx_ldbl128::num_get< char, istreambuf_iterator< char, char_traits< char> > >  &use_facet< __gnu_cxx_ldbl128::num_get< char, istreambuf_iterator< char, char_traits< char> > > > (const locale &);
# 1300
extern template bool has_facet< ctype< char> > (const locale &) throw();
# 1304
extern template bool has_facet< numpunct< char> > (const locale &) throw();
# 1308
extern template bool has_facet< __gnu_cxx_ldbl128::num_put< char, ostreambuf_iterator< char, char_traits< char> > > > (const locale &) throw();
# 1312
extern template bool has_facet< __gnu_cxx_ldbl128::num_get< char, istreambuf_iterator< char, char_traits< char> > > > (const locale &) throw();
# 1317
extern template class numpunct< wchar_t> ;
# 1318
extern template class numpunct_byname< wchar_t> ;
# 1319
extern template class __gnu_cxx_ldbl128::num_get< wchar_t, istreambuf_iterator< wchar_t, char_traits< wchar_t> > > ;
# 1320
extern template class __gnu_cxx_ldbl128::num_put< wchar_t, ostreambuf_iterator< wchar_t, char_traits< wchar_t> > > ;
# 1323
extern template const ctype< wchar_t>  &use_facet< ctype< wchar_t> > (const locale &);
# 1327
extern template const numpunct< wchar_t>  &use_facet< numpunct< wchar_t> > (const locale &);
# 1331
extern template const __gnu_cxx_ldbl128::num_put< wchar_t, ostreambuf_iterator< wchar_t, char_traits< wchar_t> > >  &use_facet< __gnu_cxx_ldbl128::num_put< wchar_t, ostreambuf_iterator< wchar_t, char_traits< wchar_t> > > > (const locale &);
# 1335
extern template const __gnu_cxx_ldbl128::num_get< wchar_t, istreambuf_iterator< wchar_t, char_traits< wchar_t> > >  &use_facet< __gnu_cxx_ldbl128::num_get< wchar_t, istreambuf_iterator< wchar_t, char_traits< wchar_t> > > > (const locale &);
# 1339
extern template bool has_facet< ctype< wchar_t> > (const locale &) throw();
# 1343
extern template bool has_facet< numpunct< wchar_t> > (const locale &) throw();
# 1347
extern template bool has_facet< __gnu_cxx_ldbl128::num_put< wchar_t, ostreambuf_iterator< wchar_t, char_traits< wchar_t> > > > (const locale &) throw();
# 1351
extern template bool has_facet< __gnu_cxx_ldbl128::num_get< wchar_t, istreambuf_iterator< wchar_t, char_traits< wchar_t> > > > (const locale &) throw();
# 1358
}
# 40 "/usr/include/c++/4.8.2/bits/basic_ios.h" 3
namespace std __attribute((__visibility__("default"))) { 
# 44
template< class _Facet> inline const _Facet &
# 46
__check_facet(const _Facet *__f) 
# 47
{ 
# 48
if (!__f) { 
# 49
__throw_bad_cast(); }  
# 50
return *__f; 
# 51
} 
# 65
template< class _CharT, class _Traits> 
# 66
class basic_ios : public ios_base { 
# 75
public: typedef _CharT char_type; 
# 76
typedef typename _Traits::int_type int_type; 
# 77
typedef typename _Traits::pos_type pos_type; 
# 78
typedef typename _Traits::off_type off_type; 
# 79
typedef _Traits traits_type; 
# 86
typedef ctype< _CharT>  __ctype_type; 
# 88
typedef __gnu_cxx_ldbl128::num_put< _CharT, ostreambuf_iterator< _CharT, _Traits> >  __num_put_type; 
# 90
typedef __gnu_cxx_ldbl128::num_get< _CharT, istreambuf_iterator< _CharT, _Traits> >  __num_get_type; 
# 95
protected: basic_ostream< _CharT, _Traits>  *_M_tie; 
# 96
mutable char_type _M_fill; 
# 97
mutable bool _M_fill_init; 
# 98
basic_streambuf< _CharT, _Traits>  *_M_streambuf; 
# 101
const __ctype_type *_M_ctype; 
# 103
const __num_put_type *_M_num_put; 
# 105
const __num_get_type *_M_num_get; 
# 115
public: operator void *() const 
# 116
{ return this->fail() ? 0 : (const_cast< basic_ios *>(this)); } 
# 119
bool operator!() const 
# 120
{ return this->fail(); } 
# 131
iostate rdstate() const 
# 132
{ return ios_base::_M_streambuf_state; } 
# 142
void clear(iostate __state = goodbit); 
# 151
void setstate(iostate __state) 
# 152
{ this->clear(((this->rdstate()) | __state)); } 
# 158
void _M_setstate(iostate __state) 
# 159
{ 
# 162
((ios_base::_M_streambuf_state) |= __state); 
# 163
if (((this->exceptions()) & __state)) { 
# 164
throw; }  
# 165
} 
# 174
bool good() const 
# 175
{ return (this->rdstate()) == 0; } 
# 184
bool eof() const 
# 185
{ return (((this->rdstate()) & eofbit)) != 0; } 
# 195
bool fail() const 
# 196
{ return (((this->rdstate()) & ((badbit | failbit)))) != 0; } 
# 205
bool bad() const 
# 206
{ return (((this->rdstate()) & badbit)) != 0; } 
# 216
iostate exceptions() const 
# 217
{ return ios_base::_M_exception; } 
# 251
void exceptions(iostate __except) 
# 252
{ 
# 253
(ios_base::_M_exception) = __except; 
# 254
this->clear(ios_base::_M_streambuf_state); 
# 255
} 
# 264
explicit basic_ios(basic_streambuf< _CharT, _Traits>  *__sb) : ios_base(), _M_tie((0)), _M_fill(), _M_fill_init(false), _M_streambuf((0)), _M_ctype((0)), _M_num_put((0)), _M_num_get((0)) 
# 267
{ this->init(__sb); } 
# 276
virtual ~basic_ios() { } 
# 289
basic_ostream< _CharT, _Traits>  *tie() const 
# 290
{ return _M_tie; } 
# 301
basic_ostream< _CharT, _Traits>  *tie(basic_ostream< _CharT, _Traits>  *__tiestr) 
# 302
{ 
# 303
basic_ostream< _CharT, _Traits>  *__old = _M_tie; 
# 304
(_M_tie) = __tiestr; 
# 305
return __old; 
# 306
} 
# 315
basic_streambuf< _CharT, _Traits>  *rdbuf() const 
# 316
{ return _M_streambuf; } 
# 341
basic_streambuf< _CharT, _Traits>  *rdbuf(basic_streambuf< _CharT, _Traits>  * __sb); 
# 355
basic_ios &copyfmt(const basic_ios & __rhs); 
# 364
char_type fill() const 
# 365
{ 
# 366
if (!(_M_fill_init)) 
# 367
{ 
# 368
(_M_fill) = this->widen(' '); 
# 369
(_M_fill_init) = true; 
# 370
}  
# 371
return _M_fill; 
# 372
} 
# 384
char_type fill(char_type __ch) 
# 385
{ 
# 386
char_type __old = (this->fill()); 
# 387
(_M_fill) = __ch; 
# 388
return __old; 
# 389
} 
# 404
locale imbue(const locale & __loc); 
# 424
char narrow(char_type __c, char __dfault) const 
# 425
{ return (__check_facet(_M_ctype).narrow(__c, __dfault)); } 
# 443
char_type widen(char __c) const 
# 444
{ return (__check_facet(_M_ctype).widen(__c)); } 
# 454
protected: basic_ios() : ios_base(), _M_tie((0)), _M_fill(char_type()), _M_fill_init(false), _M_streambuf((0)), _M_ctype((0)), _M_num_put((0)), _M_num_get((0)) 
# 457
{ } 
# 466
void init(basic_streambuf< _CharT, _Traits>  * __sb); 
# 469
void _M_cache_locale(const locale & __loc); 
# 470
}; 
# 473
}
# 35 "/usr/include/c++/4.8.2/bits/basic_ios.tcc" 3
namespace std __attribute((__visibility__("default"))) { 
# 39
template< class _CharT, class _Traits> void 
# 41
basic_ios< _CharT, _Traits> ::clear(iostate __state) 
# 42
{ 
# 43
if ((this->rdbuf())) { 
# 44
(ios_base::_M_streambuf_state) = __state; } else { 
# 46
(ios_base::_M_streambuf_state) = ((__state | badbit)); }  
# 47
if (((this->exceptions()) & (this->rdstate()))) { 
# 48
__throw_ios_failure("basic_ios::clear"); }  
# 49
} 
# 51
template< class _CharT, class _Traits> basic_streambuf< _CharT, _Traits>  *
# 53
basic_ios< _CharT, _Traits> ::rdbuf(basic_streambuf< _CharT, _Traits>  *__sb) 
# 54
{ 
# 55
basic_streambuf< _CharT, _Traits>  *__old = _M_streambuf; 
# 56
(_M_streambuf) = __sb; 
# 57
this->clear(); 
# 58
return __old; 
# 59
} 
# 61
template< class _CharT, class _Traits> basic_ios< _CharT, _Traits>  &
# 63
basic_ios< _CharT, _Traits> ::copyfmt(const basic_ios &__rhs) 
# 64
{ 
# 67
if (this != (&__rhs)) 
# 68
{ 
# 73
_Words *__words = ((__rhs.ios_base::_M_word_size) <= (_S_local_word_size)) ? ios_base::_M_local_word : (new _Words [__rhs.ios_base::_M_word_size]); 
# 77
_Callback_list *__cb = __rhs.ios_base::_M_callbacks; 
# 78
if (__cb) { 
# 79
__cb->_M_add_reference(); }  
# 80
this->ios_base::_M_call_callbacks(erase_event); 
# 81
if ((ios_base::_M_word) != (ios_base::_M_local_word)) 
# 82
{ 
# 83
delete [] (ios_base::_M_word); 
# 84
(ios_base::_M_word) = (0); 
# 85
}  
# 86
this->ios_base::_M_dispose_callbacks(); 
# 89
(ios_base::_M_callbacks) = __cb; 
# 90
for (int __i = 0; __i < (__rhs.ios_base::_M_word_size); ++__i) { 
# 91
(__words[__i]) = ((__rhs.ios_base::_M_word)[__i]); }  
# 92
(ios_base::_M_word) = __words; 
# 93
(ios_base::_M_word_size) = (__rhs.ios_base::_M_word_size); 
# 95
this->flags(__rhs.flags()); 
# 96
this->width(__rhs.width()); 
# 97
this->precision(__rhs.precision()); 
# 98
(this->tie((__rhs.tie()))); 
# 99
(this->fill((__rhs.fill()))); 
# 100
((ios_base::_M_ios_locale) = (__rhs.getloc())); 
# 101
_M_cache_locale(ios_base::_M_ios_locale); 
# 103
this->ios_base::_M_call_callbacks(copyfmt_event); 
# 106
this->exceptions(__rhs.exceptions()); 
# 107
}  
# 108
return *this; 
# 109
} 
# 112
template< class _CharT, class _Traits> locale 
# 114
basic_ios< _CharT, _Traits> ::imbue(const locale &__loc) 
# 115
{ 
# 116
locale __old(this->getloc()); 
# 117
this->ios_base::imbue(__loc); 
# 118
_M_cache_locale(__loc); 
# 119
if ((this->rdbuf()) != 0) { 
# 120
((this->rdbuf())->pubimbue(__loc)); }  
# 121
return __old; 
# 122
} 
# 124
template< class _CharT, class _Traits> void 
# 126
basic_ios< _CharT, _Traits> ::init(basic_streambuf< _CharT, _Traits>  *__sb) 
# 127
{ 
# 129
this->ios_base::_M_init(); 
# 132
_M_cache_locale(ios_base::_M_ios_locale); 
# 146
(_M_fill) = _CharT(); 
# 147
(_M_fill_init) = false; 
# 149
(_M_tie) = 0; 
# 150
(ios_base::_M_exception) = goodbit; 
# 151
(_M_streambuf) = __sb; 
# 152
(ios_base::_M_streambuf_state) = ((__sb) ? goodbit : badbit); 
# 153
} 
# 155
template< class _CharT, class _Traits> void 
# 157
basic_ios< _CharT, _Traits> ::_M_cache_locale(const locale &__loc) 
# 158
{ 
# 159
if (__builtin_expect(has_facet< __ctype_type> (__loc), true)) { 
# 160
(_M_ctype) = (&use_facet< __ctype_type> (__loc)); } else { 
# 162
(_M_ctype) = 0; }  
# 164
if (__builtin_expect(has_facet< __num_put_type> (__loc), true)) { 
# 165
(_M_num_put) = (&use_facet< __num_put_type> (__loc)); } else { 
# 167
(_M_num_put) = 0; }  
# 169
if (__builtin_expect(has_facet< __num_get_type> (__loc), true)) { 
# 170
(_M_num_get) = (&use_facet< __num_get_type> (__loc)); } else { 
# 172
(_M_num_get) = 0; }  
# 173
} 
# 178
extern template class basic_ios< char, char_traits< char> > ;
# 181
extern template class basic_ios< wchar_t, char_traits< wchar_t> > ;
# 186
}
# 41 "/usr/include/c++/4.8.2/ostream" 3
namespace std __attribute((__visibility__("default"))) { 
# 57
template< class _CharT, class _Traits> 
# 58
class basic_ostream : virtual public basic_ios< _CharT, _Traits>  { 
# 62
public: typedef _CharT char_type; 
# 63
typedef typename _Traits::int_type int_type; 
# 64
typedef typename _Traits::pos_type pos_type; 
# 65
typedef typename _Traits::off_type off_type; 
# 66
typedef _Traits traits_type; 
# 69
typedef basic_streambuf< _CharT, _Traits>  __streambuf_type; 
# 70
typedef ::std::basic_ios< _CharT, _Traits>  __ios_type; 
# 71
typedef basic_ostream __ostream_type; 
# 73
typedef ::std::__gnu_cxx_ldbl128::num_put< _CharT, ostreambuf_iterator< _CharT, _Traits> >  __num_put_type; 
# 74
typedef ctype< _CharT>  __ctype_type; 
# 84
explicit basic_ostream(__streambuf_type *__sb) 
# 85
{ (this->init(__sb)); } 
# 93
virtual ~basic_ostream() { } 
# 96
class sentry; 
# 97
friend class sentry; 
# 108
__ostream_type &operator<<(__ostream_type &(*__pf)(__ostream_type &)) 
# 109
{ 
# 113
return __pf(*this); 
# 114
} 
# 117
__ostream_type &operator<<(__ios_type &(*__pf)(__ios_type &)) 
# 118
{ 
# 122
__pf(*this); 
# 123
return *this; 
# 124
} 
# 127
__ostream_type &operator<<(::std::ios_base &(*__pf)(::std::ios_base &)) 
# 128
{ 
# 132
__pf(*this); 
# 133
return *this; 
# 134
} 
# 166
__ostream_type &operator<<(long __n) 
# 167
{ return _M_insert(__n); } 
# 170
__ostream_type &operator<<(unsigned long __n) 
# 171
{ return _M_insert(__n); } 
# 174
__ostream_type &operator<<(bool __n) 
# 175
{ return _M_insert(__n); } 
# 178
__ostream_type &operator<<(short __n); 
# 181
__ostream_type &operator<<(unsigned short __n) 
# 182
{ 
# 185
return _M_insert(static_cast< unsigned long>(__n)); 
# 186
} 
# 189
__ostream_type &operator<<(int __n); 
# 192
__ostream_type &operator<<(unsigned __n) 
# 193
{ 
# 196
return _M_insert(static_cast< unsigned long>(__n)); 
# 197
} 
# 201
__ostream_type &operator<<(long long __n) 
# 202
{ return _M_insert(__n); } 
# 205
__ostream_type &operator<<(unsigned long long __n) 
# 206
{ return _M_insert(__n); } 
# 220
__ostream_type &operator<<(double __f) 
# 221
{ return _M_insert(__f); } 
# 224
__ostream_type &operator<<(float __f) 
# 225
{ 
# 228
return _M_insert(static_cast< double>(__f)); 
# 229
} 
# 232
__ostream_type &operator<<(long double __f) 
# 233
{ return _M_insert(__f); } 
# 245
__ostream_type &operator<<(const void *__p) 
# 246
{ return _M_insert(__p); } 
# 270
__ostream_type &operator<<(__streambuf_type * __sb); 
# 303
__ostream_type &put(char_type __c); 
# 311
void _M_write(const char_type *__s, ::std::streamsize __n) 
# 312
{ 
# 313
const ::std::streamsize __put = ((this->rdbuf())->sputn(__s, __n)); 
# 314
if (__put != __n) { 
# 315
(this->setstate(ios_base::badbit)); }  
# 316
} 
# 335
__ostream_type &write(const char_type * __s, ::std::streamsize __n); 
# 348
__ostream_type &flush(); 
# 358
pos_type tellp(); 
# 369
__ostream_type &seekp(pos_type); 
# 381
__ostream_type &seekp(off_type, ::std::ios_base::seekdir); 
# 384
protected: basic_ostream() 
# 385
{ (this->init(0)); } 
# 387
template< class _ValueT> __ostream_type &_M_insert(_ValueT __v); 
# 390
}; 
# 399
template< class _CharT, class _Traits> 
# 400
class basic_ostream< _CharT, _Traits> ::sentry { 
# 403
bool _M_ok; 
# 404
basic_ostream &_M_os; 
# 419
public: explicit sentry(basic_ostream & __os); 
# 428
~sentry() 
# 429
{ 
# 431
if (((bool)(((_M_os).flags()) & ios_base::unitbuf)) && (!uncaught_exception())) 
# 432
{ 
# 434
if (((_M_os).rdbuf()) && ((((_M_os).rdbuf())->pubsync()) == (-1))) { 
# 435
((_M_os).setstate(ios_base::badbit)); }  
# 436
}  
# 437
} 
# 449
operator bool() const 
# 450
{ return _M_ok; } 
# 451
}; 
# 469
template< class _CharT, class _Traits> inline basic_ostream< _CharT, _Traits>  &
# 471
operator<<(basic_ostream< _CharT, _Traits>  &__out, _CharT __c) 
# 472
{ return __ostream_insert(__out, &__c, 1); } 
# 474
template< class _CharT, class _Traits> inline basic_ostream< _CharT, _Traits>  &
# 476
operator<<(basic_ostream< _CharT, _Traits>  &__out, char __c) 
# 477
{ return __out << (__out.widen(__c)); } 
# 480
template< class _Traits> inline basic_ostream< char, _Traits>  &
# 482
operator<<(basic_ostream< char, _Traits>  &__out, char __c) 
# 483
{ return __ostream_insert(__out, &__c, 1); } 
# 486
template< class _Traits> inline basic_ostream< char, _Traits>  &
# 488
operator<<(basic_ostream< char, _Traits>  &__out, signed char __c) 
# 489
{ return __out << (static_cast< char>(__c)); } 
# 491
template< class _Traits> inline basic_ostream< char, _Traits>  &
# 493
operator<<(basic_ostream< char, _Traits>  &__out, unsigned char __c) 
# 494
{ return __out << (static_cast< char>(__c)); } 
# 511
template< class _CharT, class _Traits> inline basic_ostream< _CharT, _Traits>  &
# 513
operator<<(basic_ostream< _CharT, _Traits>  &__out, const _CharT *__s) 
# 514
{ 
# 515
if (!__s) { 
# 516
(__out.setstate(ios_base::badbit)); } else { 
# 518
__ostream_insert(__out, __s, static_cast< streamsize>(_Traits::length(__s))); }  
# 520
return __out; 
# 521
} 
# 523
template< class _CharT, class _Traits> basic_ostream< _CharT, _Traits>  &operator<<(basic_ostream< _CharT, _Traits>  & __out, const char * __s); 
# 528
template< class _Traits> inline basic_ostream< char, _Traits>  &
# 530
operator<<(basic_ostream< char, _Traits>  &__out, const char *__s) 
# 531
{ 
# 532
if (!__s) { 
# 533
(__out.setstate(ios_base::badbit)); } else { 
# 535
__ostream_insert(__out, __s, static_cast< streamsize>(_Traits::length(__s))); }  
# 537
return __out; 
# 538
} 
# 541
template< class _Traits> inline basic_ostream< char, _Traits>  &
# 543
operator<<(basic_ostream< char, _Traits>  &__out, const signed char *__s) 
# 544
{ return __out << (reinterpret_cast< const char *>(__s)); } 
# 546
template< class _Traits> inline basic_ostream< char, _Traits>  &
# 548
operator<<(basic_ostream< char, _Traits>  &__out, const unsigned char *__s) 
# 549
{ return __out << (reinterpret_cast< const char *>(__s)); } 
# 562
template< class _CharT, class _Traits> inline basic_ostream< _CharT, _Traits>  &
# 564
endl(basic_ostream< _CharT, _Traits>  &__os) 
# 565
{ return flush((__os.put((__os.widen('\n'))))); } 
# 574
template< class _CharT, class _Traits> inline basic_ostream< _CharT, _Traits>  &
# 576
ends(basic_ostream< _CharT, _Traits>  &__os) 
# 577
{ return (__os.put(_CharT())); } 
# 584
template< class _CharT, class _Traits> inline basic_ostream< _CharT, _Traits>  &
# 586
flush(basic_ostream< _CharT, _Traits>  &__os) 
# 587
{ return (__os.flush()); } 
# 610
}
# 41 "/usr/include/c++/4.8.2/bits/ostream.tcc" 3
namespace std __attribute((__visibility__("default"))) { 
# 45
template< class _CharT, class _Traits> 
# 47
basic_ostream< _CharT, _Traits> ::sentry::sentry(basic_ostream &__os) : _M_ok(false), _M_os(__os) 
# 49
{ 
# 51
if ((__os.tie()) && (__os.good())) { 
# 52
((__os.tie())->flush()); }  
# 54
if ((__os.good())) { 
# 55
(_M_ok) = true; } else { 
# 57
(__os.setstate(ios_base::failbit)); }  
# 58
} 
# 60
template< class _CharT, class _Traits> 
# 61
template< class _ValueT> basic_ostream< _CharT, _Traits>  &
# 64
basic_ostream< _CharT, _Traits> ::_M_insert(_ValueT __v) 
# 65
{ 
# 66
sentry __cerb(*this); 
# 67
if (__cerb) 
# 68
{ 
# 69
::std::ios_base::iostate __err = ::std::ios_base::goodbit; 
# 70
try 
# 71
{ 
# 72
const __num_put_type &__np = __check_facet((this->_M_num_put)); 
# 73
if (((__np.put(*this, *this, (this->fill()), __v)).failed())) { 
# 74
(__err |= ::std::ios_base::badbit); }  
# 75
} 
# 76
catch (::__cxxabiv1::__forced_unwind &) 
# 77
{ 
# 78
(this->_M_setstate(ios_base::badbit)); 
# 79
throw; 
# 80
} 
# 81
catch (...) 
# 82
{ (this->_M_setstate(ios_base::badbit)); }  
# 83
if (__err) { 
# 84
(this->setstate(__err)); }  
# 85
}  
# 86
return *this; 
# 87
} 
# 89
template< class _CharT, class _Traits> basic_ostream< _CharT, _Traits>  &
# 92
basic_ostream< _CharT, _Traits> ::operator<<(short __n) 
# 93
{ 
# 96
const ::std::ios_base::fmtflags __fmt = (this->flags()) & ios_base::basefield; 
# 97
if ((__fmt == ::std::ios_base::oct) || (__fmt == ::std::ios_base::hex)) { 
# 98
return _M_insert(static_cast< long>(static_cast< unsigned short>(__n))); } else { 
# 100
return _M_insert(static_cast< long>(__n)); }  
# 101
} 
# 103
template< class _CharT, class _Traits> basic_ostream< _CharT, _Traits>  &
# 106
basic_ostream< _CharT, _Traits> ::operator<<(int __n) 
# 107
{ 
# 110
const ::std::ios_base::fmtflags __fmt = (this->flags()) & ios_base::basefield; 
# 111
if ((__fmt == ::std::ios_base::oct) || (__fmt == ::std::ios_base::hex)) { 
# 112
return _M_insert(static_cast< long>(static_cast< unsigned>(__n))); } else { 
# 114
return _M_insert(static_cast< long>(__n)); }  
# 115
} 
# 117
template< class _CharT, class _Traits> basic_ostream< _CharT, _Traits>  &
# 120
basic_ostream< _CharT, _Traits> ::operator<<(__streambuf_type *__sbin) 
# 121
{ 
# 122
::std::ios_base::iostate __err = ::std::ios_base::goodbit; 
# 123
sentry __cerb(*this); 
# 124
if (__cerb && __sbin) 
# 125
{ 
# 126
try 
# 127
{ 
# 128
if (!__copy_streambufs(__sbin, (this->rdbuf()))) { 
# 129
(__err |= ::std::ios_base::failbit); }  
# 130
} 
# 131
catch (::__cxxabiv1::__forced_unwind &) 
# 132
{ 
# 133
(this->_M_setstate(ios_base::badbit)); 
# 134
throw; 
# 135
} 
# 136
catch (...) 
# 137
{ (this->_M_setstate(ios_base::failbit)); }  
# 138
} else { 
# 139
if (!__sbin) { 
# 140
(__err |= ::std::ios_base::badbit); }  }  
# 141
if (__err) { 
# 142
(this->setstate(__err)); }  
# 143
return *this; 
# 144
} 
# 146
template< class _CharT, class _Traits> basic_ostream< _CharT, _Traits>  &
# 149
basic_ostream< _CharT, _Traits> ::put(char_type __c) 
# 150
{ 
# 157
sentry __cerb(*this); 
# 158
if (__cerb) 
# 159
{ 
# 160
::std::ios_base::iostate __err = ::std::ios_base::goodbit; 
# 161
try 
# 162
{ 
# 163
const int_type __put = ((this->rdbuf())->sputc(__c)); 
# 164
if (traits_type::eq_int_type(__put, traits_type::eof())) { 
# 165
(__err |= ::std::ios_base::badbit); }  
# 166
} 
# 167
catch (::__cxxabiv1::__forced_unwind &) 
# 168
{ 
# 169
(this->_M_setstate(ios_base::badbit)); 
# 170
throw; 
# 171
} 
# 172
catch (...) 
# 173
{ (this->_M_setstate(ios_base::badbit)); }  
# 174
if (__err) { 
# 175
(this->setstate(__err)); }  
# 176
}  
# 177
return *this; 
# 178
} 
# 180
template< class _CharT, class _Traits> basic_ostream< _CharT, _Traits>  &
# 183
basic_ostream< _CharT, _Traits> ::write(const _CharT *__s, ::std::streamsize __n) 
# 184
{ 
# 192
sentry __cerb(*this); 
# 193
if (__cerb) 
# 194
{ 
# 195
try 
# 196
{ _M_write(__s, __n); } 
# 197
catch (::__cxxabiv1::__forced_unwind &) 
# 198
{ 
# 199
(this->_M_setstate(ios_base::badbit)); 
# 200
throw; 
# 201
} 
# 202
catch (...) 
# 203
{ (this->_M_setstate(ios_base::badbit)); }  
# 204
}  
# 205
return *this; 
# 206
} 
# 208
template< class _CharT, class _Traits> typename basic_ostream< _CharT, _Traits> ::__ostream_type &
# 211
basic_ostream< _CharT, _Traits> ::flush() 
# 212
{ 
# 216
::std::ios_base::iostate __err = ::std::ios_base::goodbit; 
# 217
try 
# 218
{ 
# 219
if ((this->rdbuf()) && (((this->rdbuf())->pubsync()) == (-1))) { 
# 220
(__err |= ::std::ios_base::badbit); }  
# 221
} 
# 222
catch (::__cxxabiv1::__forced_unwind &) 
# 223
{ 
# 224
(this->_M_setstate(ios_base::badbit)); 
# 225
throw; 
# 226
} 
# 227
catch (...) 
# 228
{ (this->_M_setstate(ios_base::badbit)); }  
# 229
if (__err) { 
# 230
(this->setstate(__err)); }  
# 231
return *this; 
# 232
} 
# 234
template< class _CharT, class _Traits> typename basic_ostream< _CharT, _Traits> ::pos_type 
# 237
basic_ostream< _CharT, _Traits> ::tellp() 
# 238
{ 
# 239
pos_type __ret = ((pos_type)(-1)); 
# 240
try 
# 241
{ 
# 242
if (!(this->fail())) { 
# 243
__ret = ((this->rdbuf())->pubseekoff(0, ios_base::cur, ios_base::out)); }  
# 244
} 
# 245
catch (::__cxxabiv1::__forced_unwind &) 
# 246
{ 
# 247
(this->_M_setstate(ios_base::badbit)); 
# 248
throw; 
# 249
} 
# 250
catch (...) 
# 251
{ (this->_M_setstate(ios_base::badbit)); }  
# 252
return __ret; 
# 253
} 
# 255
template< class _CharT, class _Traits> basic_ostream< _CharT, _Traits>  &
# 258
basic_ostream< _CharT, _Traits> ::seekp(pos_type __pos) 
# 259
{ 
# 260
::std::ios_base::iostate __err = ::std::ios_base::goodbit; 
# 261
try 
# 262
{ 
# 263
if (!(this->fail())) 
# 264
{ 
# 267
const pos_type __p = ((this->rdbuf())->pubseekpos(__pos, ios_base::out)); 
# 271
if (__p == ((pos_type)((off_type)(-1)))) { 
# 272
(__err |= ::std::ios_base::failbit); }  
# 273
}  
# 274
} 
# 275
catch (::__cxxabiv1::__forced_unwind &) 
# 276
{ 
# 277
(this->_M_setstate(ios_base::badbit)); 
# 278
throw; 
# 279
} 
# 280
catch (...) 
# 281
{ (this->_M_setstate(ios_base::badbit)); }  
# 282
if (__err) { 
# 283
(this->setstate(__err)); }  
# 284
return *this; 
# 285
} 
# 287
template< class _CharT, class _Traits> basic_ostream< _CharT, _Traits>  &
# 290
basic_ostream< _CharT, _Traits> ::seekp(off_type __off, ::std::ios_base::seekdir __dir) 
# 291
{ 
# 292
::std::ios_base::iostate __err = ::std::ios_base::goodbit; 
# 293
try 
# 294
{ 
# 295
if (!(this->fail())) 
# 296
{ 
# 299
const pos_type __p = ((this->rdbuf())->pubseekoff(__off, __dir, ios_base::out)); 
# 303
if (__p == ((pos_type)((off_type)(-1)))) { 
# 304
(__err |= ::std::ios_base::failbit); }  
# 305
}  
# 306
} 
# 307
catch (::__cxxabiv1::__forced_unwind &) 
# 308
{ 
# 309
(this->_M_setstate(ios_base::badbit)); 
# 310
throw; 
# 311
} 
# 312
catch (...) 
# 313
{ (this->_M_setstate(ios_base::badbit)); }  
# 314
if (__err) { 
# 315
(this->setstate(__err)); }  
# 316
return *this; 
# 317
} 
# 319
template< class _CharT, class _Traits> basic_ostream< _CharT, _Traits>  &
# 321
operator<<(basic_ostream< _CharT, _Traits>  &__out, const char *__s) 
# 322
{ 
# 323
if (!__s) { 
# 324
(__out.setstate(ios_base::badbit)); } else 
# 326
{ 
# 329
const size_t __clen = char_traits< char> ::length(__s); 
# 330
try 
# 331
{ 
# 332
struct __ptr_guard { 
# 334
_CharT *__p; 
# 335
__ptr_guard(_CharT *__ip) : __p(__ip) { } 
# 336
~__ptr_guard() { delete [] (__p); } 
# 337
_CharT *__get() { return __p; } 
# 338
} __pg(new _CharT [__clen]); 
# 340
_CharT *__ws = __pg.__get(); 
# 341
for (size_t __i = (0); __i < __clen; ++__i) { 
# 342
(__ws[__i]) = (__out.widen(__s[__i])); }  
# 343
__ostream_insert(__out, __ws, __clen); 
# 344
} 
# 345
catch (__cxxabiv1::__forced_unwind &) 
# 346
{ 
# 347
(__out._M_setstate(ios_base::badbit)); 
# 348
throw; 
# 349
} 
# 350
catch (...) 
# 351
{ (__out._M_setstate(ios_base::badbit)); }  
# 352
}  
# 353
return __out; 
# 354
} 
# 359
extern template class basic_ostream< char, char_traits< char> > ;
# 360
extern template basic_ostream< char, char_traits< char> >  &endl(basic_ostream< char, char_traits< char> >  & __os);
# 361
extern template basic_ostream< char, char_traits< char> >  &ends(basic_ostream< char, char_traits< char> >  & __os);
# 362
extern template basic_ostream< char, char_traits< char> >  &flush(basic_ostream< char, char_traits< char> >  & __os);
# 363
extern template basic_ostream< char, char_traits< char> >  &operator<<(basic_ostream< char, char_traits< char> >  & __out, char __c);
# 364
extern template basic_ostream< char, char_traits< char> >  &operator<<(basic_ostream< char, char_traits< char> >  & __out, unsigned char __c);
# 365
extern template basic_ostream< char, char_traits< char> >  &operator<<(basic_ostream< char, char_traits< char> >  & __out, signed char __c);
# 366
extern template basic_ostream< char, char_traits< char> >  &operator<<(basic_ostream< char, char_traits< char> >  & __out, const char * __s);
# 367
extern template basic_ostream< char, char_traits< char> >  &operator<<(basic_ostream< char, char_traits< char> >  & __out, const unsigned char * __s);
# 368
extern template basic_ostream< char, char_traits< char> >  &operator<<(basic_ostream< char, char_traits< char> >  & __out, const signed char * __s);
# 370
extern template basic_ostream< char, char_traits< char> > ::__ostream_type &basic_ostream< char, char_traits< char> > ::_M_insert(long __v);
# 371
extern template basic_ostream< char, char_traits< char> > ::__ostream_type &basic_ostream< char, char_traits< char> > ::_M_insert(unsigned long __v);
# 372
extern template basic_ostream< char, char_traits< char> > ::__ostream_type &basic_ostream< char, char_traits< char> > ::_M_insert(bool __v);
# 374
extern template basic_ostream< char, char_traits< char> > ::__ostream_type &basic_ostream< char, char_traits< char> > ::_M_insert(long long __v);
# 375
extern template basic_ostream< char, char_traits< char> > ::__ostream_type &basic_ostream< char, char_traits< char> > ::_M_insert(unsigned long long __v);
# 377
extern template basic_ostream< char, char_traits< char> > ::__ostream_type &basic_ostream< char, char_traits< char> > ::_M_insert(double __v);
# 378
extern template basic_ostream< char, char_traits< char> > ::__ostream_type &basic_ostream< char, char_traits< char> > ::_M_insert(long double __v);
# 379
extern template basic_ostream< char, char_traits< char> > ::__ostream_type &basic_ostream< char, char_traits< char> > ::_M_insert(const void * __v);
# 382
extern template class basic_ostream< wchar_t, char_traits< wchar_t> > ;
# 383
extern template basic_ostream< wchar_t, char_traits< wchar_t> >  &endl(basic_ostream< wchar_t, char_traits< wchar_t> >  & __os);
# 384
extern template basic_ostream< wchar_t, char_traits< wchar_t> >  &ends(basic_ostream< wchar_t, char_traits< wchar_t> >  & __os);
# 385
extern template basic_ostream< wchar_t, char_traits< wchar_t> >  &flush(basic_ostream< wchar_t, char_traits< wchar_t> >  & __os);
# 386
extern template basic_ostream< wchar_t, char_traits< wchar_t> >  &operator<<(basic_ostream< wchar_t, char_traits< wchar_t> >  & __out, wchar_t __c);
# 387
extern template basic_ostream< wchar_t, char_traits< wchar_t> >  &operator<<(basic_ostream< wchar_t, char_traits< wchar_t> >  & __out, char __c);
# 388
extern template basic_ostream< wchar_t, char_traits< wchar_t> >  &operator<<(basic_ostream< wchar_t, char_traits< wchar_t> >  & __out, const wchar_t * __s);
# 389
extern template basic_ostream< wchar_t, char_traits< wchar_t> >  &operator<<(basic_ostream< wchar_t, char_traits< wchar_t> >  & __out, const char * __s);
# 391
extern template basic_ostream< wchar_t, char_traits< wchar_t> > ::__ostream_type &basic_ostream< wchar_t, char_traits< wchar_t> > ::_M_insert(long __v);
# 392
extern template basic_ostream< wchar_t, char_traits< wchar_t> > ::__ostream_type &basic_ostream< wchar_t, char_traits< wchar_t> > ::_M_insert(unsigned long __v);
# 393
extern template basic_ostream< wchar_t, char_traits< wchar_t> > ::__ostream_type &basic_ostream< wchar_t, char_traits< wchar_t> > ::_M_insert(bool __v);
# 395
extern template basic_ostream< wchar_t, char_traits< wchar_t> > ::__ostream_type &basic_ostream< wchar_t, char_traits< wchar_t> > ::_M_insert(long long __v);
# 396
extern template basic_ostream< wchar_t, char_traits< wchar_t> > ::__ostream_type &basic_ostream< wchar_t, char_traits< wchar_t> > ::_M_insert(unsigned long long __v);
# 398
extern template basic_ostream< wchar_t, char_traits< wchar_t> > ::__ostream_type &basic_ostream< wchar_t, char_traits< wchar_t> > ::_M_insert(double __v);
# 399
extern template basic_ostream< wchar_t, char_traits< wchar_t> > ::__ostream_type &basic_ostream< wchar_t, char_traits< wchar_t> > ::_M_insert(long double __v);
# 400
extern template basic_ostream< wchar_t, char_traits< wchar_t> > ::__ostream_type &basic_ostream< wchar_t, char_traits< wchar_t> > ::_M_insert(const void * __v);
# 405
}
# 41 "/usr/include/c++/4.8.2/istream" 3
namespace std __attribute((__visibility__("default"))) { 
# 57
template< class _CharT, class _Traits> 
# 58
class basic_istream : virtual public basic_ios< _CharT, _Traits>  { 
# 62
public: typedef _CharT char_type; 
# 63
typedef typename _Traits::int_type int_type; 
# 64
typedef typename _Traits::pos_type pos_type; 
# 65
typedef typename _Traits::off_type off_type; 
# 66
typedef _Traits traits_type; 
# 69
typedef basic_streambuf< _CharT, _Traits>  __streambuf_type; 
# 70
typedef ::std::basic_ios< _CharT, _Traits>  __ios_type; 
# 71
typedef basic_istream __istream_type; 
# 73
typedef ::std::__gnu_cxx_ldbl128::num_get< _CharT, istreambuf_iterator< _CharT, _Traits> >  __num_get_type; 
# 74
typedef ctype< _CharT>  __ctype_type; 
# 82
protected: ::std::streamsize _M_gcount; 
# 93
public: explicit basic_istream(__streambuf_type *__sb) : _M_gcount(((::std::streamsize)0)) 
# 95
{ (this->init(__sb)); } 
# 103
virtual ~basic_istream() 
# 104
{ (_M_gcount) = ((::std::streamsize)0); } 
# 107
class sentry; 
# 108
friend class sentry; 
# 120
__istream_type &operator>>(__istream_type &(*__pf)(__istream_type &)) 
# 121
{ return __pf(*this); } 
# 124
__istream_type &operator>>(__ios_type &(*__pf)(__ios_type &)) 
# 125
{ 
# 126
__pf(*this); 
# 127
return *this; 
# 128
} 
# 131
__istream_type &operator>>(::std::ios_base &(*__pf)(::std::ios_base &)) 
# 132
{ 
# 133
__pf(*this); 
# 134
return *this; 
# 135
} 
# 168
__istream_type &operator>>(bool &__n) 
# 169
{ return _M_extract(__n); } 
# 172
__istream_type &operator>>(short & __n); 
# 175
__istream_type &operator>>(unsigned short &__n) 
# 176
{ return _M_extract(__n); } 
# 179
__istream_type &operator>>(int & __n); 
# 182
__istream_type &operator>>(unsigned &__n) 
# 183
{ return _M_extract(__n); } 
# 186
__istream_type &operator>>(long &__n) 
# 187
{ return _M_extract(__n); } 
# 190
__istream_type &operator>>(unsigned long &__n) 
# 191
{ return _M_extract(__n); } 
# 195
__istream_type &operator>>(long long &__n) 
# 196
{ return _M_extract(__n); } 
# 199
__istream_type &operator>>(unsigned long long &__n) 
# 200
{ return _M_extract(__n); } 
# 214
__istream_type &operator>>(float &__f) 
# 215
{ return _M_extract(__f); } 
# 218
__istream_type &operator>>(double &__f) 
# 219
{ return _M_extract(__f); } 
# 222
__istream_type &operator>>(long double &__f) 
# 223
{ return _M_extract(__f); } 
# 235
__istream_type &operator>>(void *&__p) 
# 236
{ return _M_extract(__p); } 
# 259
__istream_type &operator>>(__streambuf_type * __sb); 
# 269
::std::streamsize gcount() const 
# 270
{ return _M_gcount; } 
# 302
int_type get(); 
# 316
__istream_type &get(char_type & __c); 
# 343
__istream_type &get(char_type * __s, ::std::streamsize __n, char_type __delim); 
# 354
__istream_type &get(char_type *__s, ::std::streamsize __n) 
# 355
{ return (this->get(__s, __n, (this->widen('\n')))); } 
# 377
__istream_type &get(__streambuf_type & __sb, char_type __delim); 
# 387
__istream_type &get(__streambuf_type &__sb) 
# 388
{ return (this->get(__sb, (this->widen('\n')))); } 
# 416
__istream_type &getline(char_type * __s, ::std::streamsize __n, char_type __delim); 
# 427
__istream_type &getline(char_type *__s, ::std::streamsize __n) 
# 428
{ return (this->getline(__s, __n, (this->widen('\n')))); } 
# 451
__istream_type &ignore(::std::streamsize __n, int_type __delim); 
# 454
__istream_type &ignore(::std::streamsize __n); 
# 457
__istream_type &ignore(); 
# 468
int_type peek(); 
# 486
__istream_type &read(char_type * __s, ::std::streamsize __n); 
# 505
::std::streamsize readsome(char_type * __s, ::std::streamsize __n); 
# 522
__istream_type &putback(char_type __c); 
# 538
__istream_type &unget(); 
# 556
int sync(); 
# 571
pos_type tellg(); 
# 586
__istream_type &seekg(pos_type); 
# 602
__istream_type &seekg(off_type, ::std::ios_base::seekdir); 
# 606
protected: basic_istream() : _M_gcount(((::std::streamsize)0)) 
# 608
{ (this->init(0)); } 
# 610
template< class _ValueT> __istream_type &_M_extract(_ValueT & __v); 
# 613
}; 
# 619
template<> basic_istream< char, char_traits< char> >  &basic_istream< char, char_traits< char> > ::getline(char_type * __s, streamsize __n, char_type __delim); 
# 624
template<> basic_istream< char, char_traits< char> >  &basic_istream< char, char_traits< char> > ::ignore(streamsize __n); 
# 629
template<> basic_istream< char, char_traits< char> >  &basic_istream< char, char_traits< char> > ::ignore(streamsize __n, int_type __delim); 
# 635
template<> basic_istream< wchar_t, char_traits< wchar_t> >  &basic_istream< wchar_t, char_traits< wchar_t> > ::getline(char_type * __s, streamsize __n, char_type __delim); 
# 640
template<> basic_istream< wchar_t, char_traits< wchar_t> >  &basic_istream< wchar_t, char_traits< wchar_t> > ::ignore(streamsize __n); 
# 645
template<> basic_istream< wchar_t, char_traits< wchar_t> >  &basic_istream< wchar_t, char_traits< wchar_t> > ::ignore(streamsize __n, int_type __delim); 
# 656
template< class _CharT, class _Traits> 
# 657
class basic_istream< _CharT, _Traits> ::sentry { 
# 660
bool _M_ok; 
# 664
public: typedef _Traits traits_type; 
# 665
typedef basic_streambuf< _CharT, _Traits>  __streambuf_type; 
# 666
typedef basic_istream __istream_type; 
# 667
typedef typename ::std::basic_istream< _CharT, _Traits> ::__ctype_type __ctype_type; 
# 668
typedef typename _Traits::int_type __int_type; 
# 693
explicit sentry(basic_istream & __is, bool __noskipws = false); 
# 705
operator bool() const 
# 706
{ return _M_ok; } 
# 707
}; 
# 721
template< class _CharT, class _Traits> basic_istream< _CharT, _Traits>  &operator>>(basic_istream< _CharT, _Traits>  & __in, _CharT & __c); 
# 725
template< class _Traits> inline basic_istream< char, _Traits>  &
# 727
operator>>(basic_istream< char, _Traits>  &__in, unsigned char &__c) 
# 728
{ return __in >> (reinterpret_cast< char &>(__c)); } 
# 730
template< class _Traits> inline basic_istream< char, _Traits>  &
# 732
operator>>(basic_istream< char, _Traits>  &__in, signed char &__c) 
# 733
{ return __in >> (reinterpret_cast< char &>(__c)); } 
# 763
template< class _CharT, class _Traits> basic_istream< _CharT, _Traits>  &operator>>(basic_istream< _CharT, _Traits>  & __in, _CharT * __s); 
# 770
template<> basic_istream< char, char_traits< char> >  &operator>>(basic_istream< char, char_traits< char> >  & __in, char * __s); 
# 772
template< class _Traits> inline basic_istream< char, _Traits>  &
# 774
operator>>(basic_istream< char, _Traits>  &__in, unsigned char *__s) 
# 775
{ return __in >> (reinterpret_cast< char *>(__s)); } 
# 777
template< class _Traits> inline basic_istream< char, _Traits>  &
# 779
operator>>(basic_istream< char, _Traits>  &__in, signed char *__s) 
# 780
{ return __in >> (reinterpret_cast< char *>(__s)); } 
# 794
template< class _CharT, class _Traits> 
# 795
class basic_iostream : public basic_istream< _CharT, _Traits> , public basic_ostream< _CharT, _Traits>  { 
# 803
public: typedef _CharT char_type; 
# 804
typedef typename _Traits::int_type int_type; 
# 805
typedef typename _Traits::pos_type pos_type; 
# 806
typedef typename _Traits::off_type off_type; 
# 807
typedef _Traits traits_type; 
# 810
typedef ::std::basic_istream< _CharT, _Traits>  __istream_type; 
# 811
typedef ::std::basic_ostream< _CharT, _Traits>  __ostream_type; 
# 820
explicit basic_iostream(basic_streambuf< _CharT, _Traits>  *__sb) : __istream_type(__sb), __ostream_type(__sb) 
# 821
{ } 
# 827
virtual ~basic_iostream() { } 
# 830
protected: basic_iostream() : __istream_type(), __ostream_type() 
# 831
{ } 
# 832
}; 
# 854
template< class _CharT, class _Traits> basic_istream< _CharT, _Traits>  &ws(basic_istream< _CharT, _Traits>  & __is); 
# 880
}
# 41 "/usr/include/c++/4.8.2/bits/istream.tcc" 3
namespace std __attribute((__visibility__("default"))) { 
# 45
template< class _CharT, class _Traits> 
# 47
basic_istream< _CharT, _Traits> ::sentry::sentry(basic_istream &__in, bool __noskip) : _M_ok(false) 
# 48
{ 
# 49
::std::ios_base::iostate __err = ::std::ios_base::goodbit; 
# 50
if ((__in.good())) 
# 51
{ 
# 52
if ((__in.tie())) { 
# 53
((__in.tie())->flush()); }  
# 54
if ((!__noskip) && ((bool)((__in.flags()) & ios_base::skipws))) 
# 55
{ 
# 56
const __int_type __eof = traits_type::eof(); 
# 57
__streambuf_type *__sb = (__in.rdbuf()); 
# 58
__int_type __c = (__sb->sgetc()); 
# 60
const __ctype_type &__ct = __check_facet((__in._M_ctype)); 
# 61
while ((!traits_type::eq_int_type(__c, __eof)) && (__ct.is(ctype_base::space, traits_type::to_char_type(__c)))) { 
# 64
__c = (__sb->snextc()); }  
# 69
if (traits_type::eq_int_type(__c, __eof)) { 
# 70
(__err |= ::std::ios_base::eofbit); }  
# 71
}  
# 72
}  
# 74
if ((__in.good()) && (__err == ::std::ios_base::goodbit)) { 
# 75
(_M_ok) = true; } else 
# 77
{ 
# 78
(__err |= ::std::ios_base::failbit); 
# 79
(__in.setstate(__err)); 
# 80
}  
# 81
} 
# 83
template< class _CharT, class _Traits> 
# 84
template< class _ValueT> basic_istream< _CharT, _Traits>  &
# 87
basic_istream< _CharT, _Traits> ::_M_extract(_ValueT &__v) 
# 88
{ 
# 89
sentry __cerb(*this, false); 
# 90
if (__cerb) 
# 91
{ 
# 92
::std::ios_base::iostate __err = ::std::ios_base::goodbit; 
# 93
try 
# 94
{ 
# 95
const __num_get_type &__ng = __check_facet((this->_M_num_get)); 
# 96
(__ng.get(*this, 0, *this, __err, __v)); 
# 97
} 
# 98
catch (::__cxxabiv1::__forced_unwind &) 
# 99
{ 
# 100
(this->_M_setstate(ios_base::badbit)); 
# 101
throw; 
# 102
} 
# 103
catch (...) 
# 104
{ (this->_M_setstate(ios_base::badbit)); }  
# 105
if (__err) { 
# 106
(this->setstate(__err)); }  
# 107
}  
# 108
return *this; 
# 109
} 
# 111
template< class _CharT, class _Traits> basic_istream< _CharT, _Traits>  &
# 114
basic_istream< _CharT, _Traits> ::operator>>(short &__n) 
# 115
{ 
# 118
sentry __cerb(*this, false); 
# 119
if (__cerb) 
# 120
{ 
# 121
::std::ios_base::iostate __err = ::std::ios_base::goodbit; 
# 122
try 
# 123
{ 
# 124
long __l; 
# 125
const __num_get_type &__ng = __check_facet((this->_M_num_get)); 
# 126
(__ng.get(*this, 0, *this, __err, __l)); 
# 130
if (__l < ::__gnu_cxx::__numeric_traits_integer< short> ::__min) 
# 131
{ 
# 132
(__err |= ::std::ios_base::failbit); 
# 133
__n = ::__gnu_cxx::__numeric_traits_integer< short> ::__min; 
# 134
} else { 
# 135
if (__l > ::__gnu_cxx::__numeric_traits_integer< short> ::__max) 
# 136
{ 
# 137
(__err |= ::std::ios_base::failbit); 
# 138
__n = ::__gnu_cxx::__numeric_traits_integer< short> ::__max; 
# 139
} else { 
# 141
__n = ((short)__l); }  }  
# 142
} 
# 143
catch (::__cxxabiv1::__forced_unwind &) 
# 144
{ 
# 145
(this->_M_setstate(ios_base::badbit)); 
# 146
throw; 
# 147
} 
# 148
catch (...) 
# 149
{ (this->_M_setstate(ios_base::badbit)); }  
# 150
if (__err) { 
# 151
(this->setstate(__err)); }  
# 152
}  
# 153
return *this; 
# 154
} 
# 156
template< class _CharT, class _Traits> basic_istream< _CharT, _Traits>  &
# 159
basic_istream< _CharT, _Traits> ::operator>>(int &__n) 
# 160
{ 
# 163
sentry __cerb(*this, false); 
# 164
if (__cerb) 
# 165
{ 
# 166
::std::ios_base::iostate __err = ::std::ios_base::goodbit; 
# 167
try 
# 168
{ 
# 169
long __l; 
# 170
const __num_get_type &__ng = __check_facet((this->_M_num_get)); 
# 171
(__ng.get(*this, 0, *this, __err, __l)); 
# 175
if (__l < ::__gnu_cxx::__numeric_traits_integer< int> ::__min) 
# 176
{ 
# 177
(__err |= ::std::ios_base::failbit); 
# 178
__n = ::__gnu_cxx::__numeric_traits_integer< int> ::__min; 
# 179
} else { 
# 180
if (__l > ::__gnu_cxx::__numeric_traits_integer< int> ::__max) 
# 181
{ 
# 182
(__err |= ::std::ios_base::failbit); 
# 183
__n = ::__gnu_cxx::__numeric_traits_integer< int> ::__max; 
# 184
} else { 
# 186
__n = ((int)__l); }  }  
# 187
} 
# 188
catch (::__cxxabiv1::__forced_unwind &) 
# 189
{ 
# 190
(this->_M_setstate(ios_base::badbit)); 
# 191
throw; 
# 192
} 
# 193
catch (...) 
# 194
{ (this->_M_setstate(ios_base::badbit)); }  
# 195
if (__err) { 
# 196
(this->setstate(__err)); }  
# 197
}  
# 198
return *this; 
# 199
} 
# 201
template< class _CharT, class _Traits> basic_istream< _CharT, _Traits>  &
# 204
basic_istream< _CharT, _Traits> ::operator>>(__streambuf_type *__sbout) 
# 205
{ 
# 206
::std::ios_base::iostate __err = ::std::ios_base::goodbit; 
# 207
sentry __cerb(*this, false); 
# 208
if (__cerb && __sbout) 
# 209
{ 
# 210
try 
# 211
{ 
# 212
bool __ineof; 
# 213
if (!__copy_streambufs_eof((this->rdbuf()), __sbout, __ineof)) { 
# 214
(__err |= ::std::ios_base::failbit); }  
# 215
if (__ineof) { 
# 216
(__err |= ::std::ios_base::eofbit); }  
# 217
} 
# 218
catch (::__cxxabiv1::__forced_unwind &) 
# 219
{ 
# 220
(this->_M_setstate(ios_base::failbit)); 
# 221
throw; 
# 222
} 
# 223
catch (...) 
# 224
{ (this->_M_setstate(ios_base::failbit)); }  
# 225
} else { 
# 226
if (!__sbout) { 
# 227
(__err |= ::std::ios_base::failbit); }  }  
# 228
if (__err) { 
# 229
(this->setstate(__err)); }  
# 230
return *this; 
# 231
} 
# 233
template< class _CharT, class _Traits> typename basic_istream< _CharT, _Traits> ::int_type 
# 236
basic_istream< _CharT, _Traits> ::get() 
# 237
{ 
# 238
const int_type __eof = traits_type::eof(); 
# 239
int_type __c = __eof; 
# 240
(_M_gcount) = (0); 
# 241
::std::ios_base::iostate __err = ::std::ios_base::goodbit; 
# 242
sentry __cerb(*this, true); 
# 243
if (__cerb) 
# 244
{ 
# 245
try 
# 246
{ 
# 247
__c = ((this->rdbuf())->sbumpc()); 
# 249
if (!traits_type::eq_int_type(__c, __eof)) { 
# 250
(_M_gcount) = (1); } else { 
# 252
(__err |= ::std::ios_base::eofbit); }  
# 253
} 
# 254
catch (::__cxxabiv1::__forced_unwind &) 
# 255
{ 
# 256
(this->_M_setstate(ios_base::badbit)); 
# 257
throw; 
# 258
} 
# 259
catch (...) 
# 260
{ (this->_M_setstate(ios_base::badbit)); }  
# 261
}  
# 262
if (!(_M_gcount)) { 
# 263
(__err |= ::std::ios_base::failbit); }  
# 264
if (__err) { 
# 265
(this->setstate(__err)); }  
# 266
return __c; 
# 267
} 
# 269
template< class _CharT, class _Traits> basic_istream< _CharT, _Traits>  &
# 272
basic_istream< _CharT, _Traits> ::get(char_type &__c) 
# 273
{ 
# 274
(_M_gcount) = (0); 
# 275
::std::ios_base::iostate __err = ::std::ios_base::goodbit; 
# 276
sentry __cerb(*this, true); 
# 277
if (__cerb) 
# 278
{ 
# 279
try 
# 280
{ 
# 281
const int_type __cb = ((this->rdbuf())->sbumpc()); 
# 283
if (!traits_type::eq_int_type(__cb, traits_type::eof())) 
# 284
{ 
# 285
(_M_gcount) = (1); 
# 286
__c = traits_type::to_char_type(__cb); 
# 287
} else { 
# 289
(__err |= ::std::ios_base::eofbit); }  
# 290
} 
# 291
catch (::__cxxabiv1::__forced_unwind &) 
# 292
{ 
# 293
(this->_M_setstate(ios_base::badbit)); 
# 294
throw; 
# 295
} 
# 296
catch (...) 
# 297
{ (this->_M_setstate(ios_base::badbit)); }  
# 298
}  
# 299
if (!(_M_gcount)) { 
# 300
(__err |= ::std::ios_base::failbit); }  
# 301
if (__err) { 
# 302
(this->setstate(__err)); }  
# 303
return *this; 
# 304
} 
# 306
template< class _CharT, class _Traits> basic_istream< _CharT, _Traits>  &
# 309
basic_istream< _CharT, _Traits> ::get(char_type *__s, ::std::streamsize __n, char_type __delim) 
# 310
{ 
# 311
(_M_gcount) = (0); 
# 312
::std::ios_base::iostate __err = ::std::ios_base::goodbit; 
# 313
sentry __cerb(*this, true); 
# 314
if (__cerb) 
# 315
{ 
# 316
try 
# 317
{ 
# 318
const int_type __idelim = traits_type::to_int_type(__delim); 
# 319
const int_type __eof = traits_type::eof(); 
# 320
__streambuf_type *__sb = (this->rdbuf()); 
# 321
int_type __c = (__sb->sgetc()); 
# 323
while ((((_M_gcount) + (1)) < __n) && (!traits_type::eq_int_type(__c, __eof)) && (!traits_type::eq_int_type(__c, __idelim))) 
# 326
{ 
# 327
(*(__s++)) = traits_type::to_char_type(__c); 
# 328
++(_M_gcount); 
# 329
__c = (__sb->snextc()); 
# 330
}  
# 331
if (traits_type::eq_int_type(__c, __eof)) { 
# 332
(__err |= ::std::ios_base::eofbit); }  
# 333
} 
# 334
catch (::__cxxabiv1::__forced_unwind &) 
# 335
{ 
# 336
(this->_M_setstate(ios_base::badbit)); 
# 337
throw; 
# 338
} 
# 339
catch (...) 
# 340
{ (this->_M_setstate(ios_base::badbit)); }  
# 341
}  
# 344
if (__n > (0)) { 
# 345
(*__s) = char_type(); }  
# 346
if (!(_M_gcount)) { 
# 347
(__err |= ::std::ios_base::failbit); }  
# 348
if (__err) { 
# 349
(this->setstate(__err)); }  
# 350
return *this; 
# 351
} 
# 353
template< class _CharT, class _Traits> basic_istream< _CharT, _Traits>  &
# 356
basic_istream< _CharT, _Traits> ::get(__streambuf_type &__sb, char_type __delim) 
# 357
{ 
# 358
(_M_gcount) = (0); 
# 359
::std::ios_base::iostate __err = ::std::ios_base::goodbit; 
# 360
sentry __cerb(*this, true); 
# 361
if (__cerb) 
# 362
{ 
# 363
try 
# 364
{ 
# 365
const int_type __idelim = traits_type::to_int_type(__delim); 
# 366
const int_type __eof = traits_type::eof(); 
# 367
__streambuf_type *__this_sb = (this->rdbuf()); 
# 368
int_type __c = (__this_sb->sgetc()); 
# 369
char_type __c2 = traits_type::to_char_type(__c); 
# 371
while ((!traits_type::eq_int_type(__c, __eof)) && (!traits_type::eq_int_type(__c, __idelim)) && (!traits_type::eq_int_type((__sb.sputc(__c2)), __eof))) 
# 374
{ 
# 375
++(_M_gcount); 
# 376
__c = (__this_sb->snextc()); 
# 377
__c2 = traits_type::to_char_type(__c); 
# 378
}  
# 379
if (traits_type::eq_int_type(__c, __eof)) { 
# 380
(__err |= ::std::ios_base::eofbit); }  
# 381
} 
# 382
catch (::__cxxabiv1::__forced_unwind &) 
# 383
{ 
# 384
(this->_M_setstate(ios_base::badbit)); 
# 385
throw; 
# 386
} 
# 387
catch (...) 
# 388
{ (this->_M_setstate(ios_base::badbit)); }  
# 389
}  
# 390
if (!(_M_gcount)) { 
# 391
(__err |= ::std::ios_base::failbit); }  
# 392
if (__err) { 
# 393
(this->setstate(__err)); }  
# 394
return *this; 
# 395
} 
# 397
template< class _CharT, class _Traits> basic_istream< _CharT, _Traits>  &
# 400
basic_istream< _CharT, _Traits> ::getline(char_type *__s, ::std::streamsize __n, char_type __delim) 
# 401
{ 
# 402
(_M_gcount) = (0); 
# 403
::std::ios_base::iostate __err = ::std::ios_base::goodbit; 
# 404
sentry __cerb(*this, true); 
# 405
if (__cerb) 
# 406
{ 
# 407
try 
# 408
{ 
# 409
const int_type __idelim = traits_type::to_int_type(__delim); 
# 410
const int_type __eof = traits_type::eof(); 
# 411
__streambuf_type *__sb = (this->rdbuf()); 
# 412
int_type __c = (__sb->sgetc()); 
# 414
while ((((_M_gcount) + (1)) < __n) && (!traits_type::eq_int_type(__c, __eof)) && (!traits_type::eq_int_type(__c, __idelim))) 
# 417
{ 
# 418
(*(__s++)) = traits_type::to_char_type(__c); 
# 419
__c = (__sb->snextc()); 
# 420
++(_M_gcount); 
# 421
}  
# 422
if (traits_type::eq_int_type(__c, __eof)) { 
# 423
(__err |= ::std::ios_base::eofbit); } else 
# 425
{ 
# 426
if (traits_type::eq_int_type(__c, __idelim)) 
# 427
{ 
# 428
(__sb->sbumpc()); 
# 429
++(_M_gcount); 
# 430
} else { 
# 432
(__err |= ::std::ios_base::failbit); }  
# 433
}  
# 434
} 
# 435
catch (::__cxxabiv1::__forced_unwind &) 
# 436
{ 
# 437
(this->_M_setstate(ios_base::badbit)); 
# 438
throw; 
# 439
} 
# 440
catch (...) 
# 441
{ (this->_M_setstate(ios_base::badbit)); }  
# 442
}  
# 445
if (__n > (0)) { 
# 446
(*__s) = char_type(); }  
# 447
if (!(_M_gcount)) { 
# 448
(__err |= ::std::ios_base::failbit); }  
# 449
if (__err) { 
# 450
(this->setstate(__err)); }  
# 451
return *this; 
# 452
} 
# 457
template< class _CharT, class _Traits> typename basic_istream< _CharT, _Traits> ::__istream_type &
# 460
basic_istream< _CharT, _Traits> ::ignore() 
# 461
{ 
# 462
(_M_gcount) = (0); 
# 463
sentry __cerb(*this, true); 
# 464
if (__cerb) 
# 465
{ 
# 466
::std::ios_base::iostate __err = ::std::ios_base::goodbit; 
# 467
try 
# 468
{ 
# 469
const int_type __eof = traits_type::eof(); 
# 470
__streambuf_type *__sb = (this->rdbuf()); 
# 472
if (traits_type::eq_int_type((__sb->sbumpc()), __eof)) { 
# 473
(__err |= ::std::ios_base::eofbit); } else { 
# 475
(_M_gcount) = (1); }  
# 476
} 
# 477
catch (::__cxxabiv1::__forced_unwind &) 
# 478
{ 
# 479
(this->_M_setstate(ios_base::badbit)); 
# 480
throw; 
# 481
} 
# 482
catch (...) 
# 483
{ (this->_M_setstate(ios_base::badbit)); }  
# 484
if (__err) { 
# 485
(this->setstate(__err)); }  
# 486
}  
# 487
return *this; 
# 488
} 
# 490
template< class _CharT, class _Traits> basic_istream< _CharT, _Traits>  &
# 493
basic_istream< _CharT, _Traits> ::ignore(::std::streamsize __n) 
# 494
{ 
# 495
(_M_gcount) = (0); 
# 496
sentry __cerb(*this, true); 
# 497
if (__cerb && (__n > (0))) 
# 498
{ 
# 499
::std::ios_base::iostate __err = ::std::ios_base::goodbit; 
# 500
try 
# 501
{ 
# 502
const int_type __eof = traits_type::eof(); 
# 503
__streambuf_type *__sb = (this->rdbuf()); 
# 504
int_type __c = (__sb->sgetc()); 
# 513
bool __large_ignore = false; 
# 514
while (true) 
# 515
{ 
# 516
while (((_M_gcount) < __n) && (!traits_type::eq_int_type(__c, __eof))) 
# 518
{ 
# 519
++(_M_gcount); 
# 520
__c = (__sb->snextc()); 
# 521
}  
# 522
if ((__n == ::__gnu_cxx::__numeric_traits_integer< long> ::__max) && (!traits_type::eq_int_type(__c, __eof))) 
# 524
{ 
# 525
(_M_gcount) = ::__gnu_cxx::__numeric_traits_integer< long> ::__min; 
# 527
__large_ignore = true; 
# 528
} else { 
# 530
break; }  
# 531
}  
# 533
if (__large_ignore) { 
# 534
(_M_gcount) = ::__gnu_cxx::__numeric_traits_integer< long> ::__max; }  
# 536
if (traits_type::eq_int_type(__c, __eof)) { 
# 537
(__err |= ::std::ios_base::eofbit); }  
# 538
} 
# 539
catch (::__cxxabiv1::__forced_unwind &) 
# 540
{ 
# 541
(this->_M_setstate(ios_base::badbit)); 
# 542
throw; 
# 543
} 
# 544
catch (...) 
# 545
{ (this->_M_setstate(ios_base::badbit)); }  
# 546
if (__err) { 
# 547
(this->setstate(__err)); }  
# 548
}  
# 549
return *this; 
# 550
} 
# 552
template< class _CharT, class _Traits> basic_istream< _CharT, _Traits>  &
# 555
basic_istream< _CharT, _Traits> ::ignore(::std::streamsize __n, int_type __delim) 
# 556
{ 
# 557
(_M_gcount) = (0); 
# 558
sentry __cerb(*this, true); 
# 559
if (__cerb && (__n > (0))) 
# 560
{ 
# 561
::std::ios_base::iostate __err = ::std::ios_base::goodbit; 
# 562
try 
# 563
{ 
# 564
const int_type __eof = traits_type::eof(); 
# 565
__streambuf_type *__sb = (this->rdbuf()); 
# 566
int_type __c = (__sb->sgetc()); 
# 569
bool __large_ignore = false; 
# 570
while (true) 
# 571
{ 
# 572
while (((_M_gcount) < __n) && (!traits_type::eq_int_type(__c, __eof)) && (!traits_type::eq_int_type(__c, __delim))) 
# 575
{ 
# 576
++(_M_gcount); 
# 577
__c = (__sb->snextc()); 
# 578
}  
# 579
if ((__n == ::__gnu_cxx::__numeric_traits_integer< long> ::__max) && (!traits_type::eq_int_type(__c, __eof)) && (!traits_type::eq_int_type(__c, __delim))) 
# 582
{ 
# 583
(_M_gcount) = ::__gnu_cxx::__numeric_traits_integer< long> ::__min; 
# 585
__large_ignore = true; 
# 586
} else { 
# 588
break; }  
# 589
}  
# 591
if (__large_ignore) { 
# 592
(_M_gcount) = ::__gnu_cxx::__numeric_traits_integer< long> ::__max; }  
# 594
if (traits_type::eq_int_type(__c, __eof)) { 
# 595
(__err |= ::std::ios_base::eofbit); } else { 
# 596
if (traits_type::eq_int_type(__c, __delim)) 
# 597
{ 
# 598
if ((_M_gcount) < ::__gnu_cxx::__numeric_traits_integer< long> ::__max) { 
# 600
++(_M_gcount); }  
# 601
(__sb->sbumpc()); 
# 602
}  }  
# 603
} 
# 604
catch (::__cxxabiv1::__forced_unwind &) 
# 605
{ 
# 606
(this->_M_setstate(ios_base::badbit)); 
# 607
throw; 
# 608
} 
# 609
catch (...) 
# 610
{ (this->_M_setstate(ios_base::badbit)); }  
# 611
if (__err) { 
# 612
(this->setstate(__err)); }  
# 613
}  
# 614
return *this; 
# 615
} 
# 617
template< class _CharT, class _Traits> typename basic_istream< _CharT, _Traits> ::int_type 
# 620
basic_istream< _CharT, _Traits> ::peek() 
# 621
{ 
# 622
int_type __c = traits_type::eof(); 
# 623
(_M_gcount) = (0); 
# 624
sentry __cerb(*this, true); 
# 625
if (__cerb) 
# 626
{ 
# 627
::std::ios_base::iostate __err = ::std::ios_base::goodbit; 
# 628
try 
# 629
{ 
# 630
__c = ((this->rdbuf())->sgetc()); 
# 631
if (traits_type::eq_int_type(__c, traits_type::eof())) { 
# 632
(__err |= ::std::ios_base::eofbit); }  
# 633
} 
# 634
catch (::__cxxabiv1::__forced_unwind &) 
# 635
{ 
# 636
(this->_M_setstate(ios_base::badbit)); 
# 637
throw; 
# 638
} 
# 639
catch (...) 
# 640
{ (this->_M_setstate(ios_base::badbit)); }  
# 641
if (__err) { 
# 642
(this->setstate(__err)); }  
# 643
}  
# 644
return __c; 
# 645
} 
# 647
template< class _CharT, class _Traits> basic_istream< _CharT, _Traits>  &
# 650
basic_istream< _CharT, _Traits> ::read(char_type *__s, ::std::streamsize __n) 
# 651
{ 
# 652
(_M_gcount) = (0); 
# 653
sentry __cerb(*this, true); 
# 654
if (__cerb) 
# 655
{ 
# 656
::std::ios_base::iostate __err = ::std::ios_base::goodbit; 
# 657
try 
# 658
{ 
# 659
(_M_gcount) = ((this->rdbuf())->sgetn(__s, __n)); 
# 660
if ((_M_gcount) != __n) { 
# 661
(__err |= ((::std::ios_base::eofbit | ::std::ios_base::failbit))); }  
# 662
} 
# 663
catch (::__cxxabiv1::__forced_unwind &) 
# 664
{ 
# 665
(this->_M_setstate(ios_base::badbit)); 
# 666
throw; 
# 667
} 
# 668
catch (...) 
# 669
{ (this->_M_setstate(ios_base::badbit)); }  
# 670
if (__err) { 
# 671
(this->setstate(__err)); }  
# 672
}  
# 673
return *this; 
# 674
} 
# 676
template< class _CharT, class _Traits> streamsize 
# 679
basic_istream< _CharT, _Traits> ::readsome(char_type *__s, ::std::streamsize __n) 
# 680
{ 
# 681
(_M_gcount) = (0); 
# 682
sentry __cerb(*this, true); 
# 683
if (__cerb) 
# 684
{ 
# 685
::std::ios_base::iostate __err = ::std::ios_base::goodbit; 
# 686
try 
# 687
{ 
# 689
const ::std::streamsize __num = ((this->rdbuf())->in_avail()); 
# 690
if (__num > (0)) { 
# 691
(_M_gcount) = ((this->rdbuf())->sgetn(__s, std::min(__num, __n))); } else { 
# 692
if (__num == (-1)) { 
# 693
(__err |= ::std::ios_base::eofbit); }  }  
# 694
} 
# 695
catch (::__cxxabiv1::__forced_unwind &) 
# 696
{ 
# 697
(this->_M_setstate(ios_base::badbit)); 
# 698
throw; 
# 699
} 
# 700
catch (...) 
# 701
{ (this->_M_setstate(ios_base::badbit)); }  
# 702
if (__err) { 
# 703
(this->setstate(__err)); }  
# 704
}  
# 705
return _M_gcount; 
# 706
} 
# 708
template< class _CharT, class _Traits> basic_istream< _CharT, _Traits>  &
# 711
basic_istream< _CharT, _Traits> ::putback(char_type __c) 
# 712
{ 
# 715
(_M_gcount) = (0); 
# 717
(this->clear((this->rdstate()) & ((~::std::ios_base::eofbit)))); 
# 718
sentry __cerb(*this, true); 
# 719
if (__cerb) 
# 720
{ 
# 721
::std::ios_base::iostate __err = ::std::ios_base::goodbit; 
# 722
try 
# 723
{ 
# 724
const int_type __eof = traits_type::eof(); 
# 725
__streambuf_type *__sb = (this->rdbuf()); 
# 726
if ((!__sb) || traits_type::eq_int_type((__sb->sputbackc(__c)), __eof)) { 
# 728
(__err |= ::std::ios_base::badbit); }  
# 729
} 
# 730
catch (::__cxxabiv1::__forced_unwind &) 
# 731
{ 
# 732
(this->_M_setstate(ios_base::badbit)); 
# 733
throw; 
# 734
} 
# 735
catch (...) 
# 736
{ (this->_M_setstate(ios_base::badbit)); }  
# 737
if (__err) { 
# 738
(this->setstate(__err)); }  
# 739
}  
# 740
return *this; 
# 741
} 
# 743
template< class _CharT, class _Traits> typename basic_istream< _CharT, _Traits> ::__istream_type &
# 746
basic_istream< _CharT, _Traits> ::unget() 
# 747
{ 
# 750
(_M_gcount) = (0); 
# 752
(this->clear((this->rdstate()) & ((~::std::ios_base::eofbit)))); 
# 753
sentry __cerb(*this, true); 
# 754
if (__cerb) 
# 755
{ 
# 756
::std::ios_base::iostate __err = ::std::ios_base::goodbit; 
# 757
try 
# 758
{ 
# 759
const int_type __eof = traits_type::eof(); 
# 760
__streambuf_type *__sb = (this->rdbuf()); 
# 761
if ((!__sb) || traits_type::eq_int_type((__sb->sungetc()), __eof)) { 
# 763
(__err |= ::std::ios_base::badbit); }  
# 764
} 
# 765
catch (::__cxxabiv1::__forced_unwind &) 
# 766
{ 
# 767
(this->_M_setstate(ios_base::badbit)); 
# 768
throw; 
# 769
} 
# 770
catch (...) 
# 771
{ (this->_M_setstate(ios_base::badbit)); }  
# 772
if (__err) { 
# 773
(this->setstate(__err)); }  
# 774
}  
# 775
return *this; 
# 776
} 
# 778
template< class _CharT, class _Traits> int 
# 781
basic_istream< _CharT, _Traits> ::sync() 
# 782
{ 
# 785
int __ret = (-1); 
# 786
sentry __cerb(*this, true); 
# 787
if (__cerb) 
# 788
{ 
# 789
::std::ios_base::iostate __err = ::std::ios_base::goodbit; 
# 790
try 
# 791
{ 
# 792
__streambuf_type *__sb = (this->rdbuf()); 
# 793
if (__sb) 
# 794
{ 
# 795
if ((__sb->pubsync()) == (-1)) { 
# 796
(__err |= ::std::ios_base::badbit); } else { 
# 798
__ret = 0; }  
# 799
}  
# 800
} 
# 801
catch (::__cxxabiv1::__forced_unwind &) 
# 802
{ 
# 803
(this->_M_setstate(ios_base::badbit)); 
# 804
throw; 
# 805
} 
# 806
catch (...) 
# 807
{ (this->_M_setstate(ios_base::badbit)); }  
# 808
if (__err) { 
# 809
(this->setstate(__err)); }  
# 810
}  
# 811
return __ret; 
# 812
} 
# 814
template< class _CharT, class _Traits> typename basic_istream< _CharT, _Traits> ::pos_type 
# 817
basic_istream< _CharT, _Traits> ::tellg() 
# 818
{ 
# 821
pos_type __ret = ((pos_type)(-1)); 
# 822
sentry __cerb(*this, true); 
# 823
if (__cerb) 
# 824
{ 
# 825
try 
# 826
{ 
# 827
if (!(this->fail())) { 
# 828
__ret = ((this->rdbuf())->pubseekoff(0, ios_base::cur, ios_base::in)); }  
# 830
} 
# 831
catch (::__cxxabiv1::__forced_unwind &) 
# 832
{ 
# 833
(this->_M_setstate(ios_base::badbit)); 
# 834
throw; 
# 835
} 
# 836
catch (...) 
# 837
{ (this->_M_setstate(ios_base::badbit)); }  
# 838
}  
# 839
return __ret; 
# 840
} 
# 842
template< class _CharT, class _Traits> basic_istream< _CharT, _Traits>  &
# 845
basic_istream< _CharT, _Traits> ::seekg(pos_type __pos) 
# 846
{ 
# 850
(this->clear((this->rdstate()) & ((~::std::ios_base::eofbit)))); 
# 851
sentry __cerb(*this, true); 
# 852
if (__cerb) 
# 853
{ 
# 854
::std::ios_base::iostate __err = ::std::ios_base::goodbit; 
# 855
try 
# 856
{ 
# 857
if (!(this->fail())) 
# 858
{ 
# 860
const pos_type __p = ((this->rdbuf())->pubseekpos(__pos, ios_base::in)); 
# 864
if (__p == ((pos_type)((off_type)(-1)))) { 
# 865
(__err |= ::std::ios_base::failbit); }  
# 866
}  
# 867
} 
# 868
catch (::__cxxabiv1::__forced_unwind &) 
# 869
{ 
# 870
(this->_M_setstate(ios_base::badbit)); 
# 871
throw; 
# 872
} 
# 873
catch (...) 
# 874
{ (this->_M_setstate(ios_base::badbit)); }  
# 875
if (__err) { 
# 876
(this->setstate(__err)); }  
# 877
}  
# 878
return *this; 
# 879
} 
# 881
template< class _CharT, class _Traits> basic_istream< _CharT, _Traits>  &
# 884
basic_istream< _CharT, _Traits> ::seekg(off_type __off, ::std::ios_base::seekdir __dir) 
# 885
{ 
# 889
(this->clear((this->rdstate()) & ((~::std::ios_base::eofbit)))); 
# 890
sentry __cerb(*this, true); 
# 891
if (__cerb) 
# 892
{ 
# 893
::std::ios_base::iostate __err = ::std::ios_base::goodbit; 
# 894
try 
# 895
{ 
# 896
if (!(this->fail())) 
# 897
{ 
# 899
const pos_type __p = ((this->rdbuf())->pubseekoff(__off, __dir, ios_base::in)); 
# 903
if (__p == ((pos_type)((off_type)(-1)))) { 
# 904
(__err |= ::std::ios_base::failbit); }  
# 905
}  
# 906
} 
# 907
catch (::__cxxabiv1::__forced_unwind &) 
# 908
{ 
# 909
(this->_M_setstate(ios_base::badbit)); 
# 910
throw; 
# 911
} 
# 912
catch (...) 
# 913
{ (this->_M_setstate(ios_base::badbit)); }  
# 914
if (__err) { 
# 915
(this->setstate(__err)); }  
# 916
}  
# 917
return *this; 
# 918
} 
# 921
template< class _CharT, class _Traits> basic_istream< _CharT, _Traits>  &
# 923
operator>>(basic_istream< _CharT, _Traits>  &__in, _CharT &__c) 
# 924
{ 
# 925
typedef basic_istream< _CharT, _Traits>  __istream_type; 
# 926
typedef typename basic_istream< _CharT, _Traits> ::int_type __int_type; 
# 928
typename basic_istream< _CharT, _Traits> ::sentry __cerb(__in, false); 
# 929
if (__cerb) 
# 930
{ 
# 931
ios_base::iostate __err = ios_base::goodbit; 
# 932
try 
# 933
{ 
# 934
const __int_type __cb = ((__in.rdbuf())->sbumpc()); 
# 935
if (!_Traits::eq_int_type(__cb, _Traits::eof())) { 
# 936
__c = _Traits::to_char_type(__cb); } else { 
# 938
(__err |= ((ios_base::eofbit | ios_base::failbit))); }  
# 939
} 
# 940
catch (__cxxabiv1::__forced_unwind &) 
# 941
{ 
# 942
(__in._M_setstate(ios_base::badbit)); 
# 943
throw; 
# 944
} 
# 945
catch (...) 
# 946
{ (__in._M_setstate(ios_base::badbit)); }  
# 947
if (__err) { 
# 948
(__in.setstate(__err)); }  
# 949
}  
# 950
return __in; 
# 951
} 
# 953
template< class _CharT, class _Traits> basic_istream< _CharT, _Traits>  &
# 955
operator>>(basic_istream< _CharT, _Traits>  &__in, _CharT *__s) 
# 956
{ 
# 957
typedef basic_istream< _CharT, _Traits>  __istream_type; 
# 958
typedef basic_streambuf< _CharT, _Traits>  __streambuf_type; 
# 959
typedef typename _Traits::int_type int_type; 
# 960
typedef _CharT char_type; 
# 961
typedef ctype< _CharT>  __ctype_type; 
# 963
streamsize __extracted = (0); 
# 964
ios_base::iostate __err = ios_base::goodbit; 
# 965
typename basic_istream< _CharT, _Traits> ::sentry __cerb(__in, false); 
# 966
if (__cerb) 
# 967
{ 
# 968
try 
# 969
{ 
# 971
streamsize __num = (__in.width()); 
# 972
if (__num <= (0)) { 
# 973
__num = __gnu_cxx::__numeric_traits_integer< long> ::__max; }  
# 975
const __ctype_type &__ct = use_facet< ctype< _CharT> > ((__in.getloc())); 
# 977
const int_type __eof = _Traits::eof(); 
# 978
__streambuf_type *__sb = (__in.rdbuf()); 
# 979
int_type __c = (__sb->sgetc()); 
# 981
while ((__extracted < (__num - (1))) && (!_Traits::eq_int_type(__c, __eof)) && (!(__ct.is(ctype_base::space, _Traits::to_char_type(__c))))) 
# 985
{ 
# 986
(*(__s++)) = _Traits::to_char_type(__c); 
# 987
++__extracted; 
# 988
__c = (__sb->snextc()); 
# 989
}  
# 990
if (_Traits::eq_int_type(__c, __eof)) { 
# 991
(__err |= ios_base::eofbit); }  
# 995
(*__s) = char_type(); 
# 996
(__in.width(0)); 
# 997
} 
# 998
catch (__cxxabiv1::__forced_unwind &) 
# 999
{ 
# 1000
(__in._M_setstate(ios_base::badbit)); 
# 1001
throw; 
# 1002
} 
# 1003
catch (...) 
# 1004
{ (__in._M_setstate(ios_base::badbit)); }  
# 1005
}  
# 1006
if (!__extracted) { 
# 1007
(__err |= ios_base::failbit); }  
# 1008
if (__err) { 
# 1009
(__in.setstate(__err)); }  
# 1010
return __in; 
# 1011
} 
# 1014
template< class _CharT, class _Traits> basic_istream< _CharT, _Traits>  &
# 1016
ws(basic_istream< _CharT, _Traits>  &__in) 
# 1017
{ 
# 1018
typedef basic_istream< _CharT, _Traits>  __istream_type; 
# 1019
typedef basic_streambuf< _CharT, _Traits>  __streambuf_type; 
# 1020
typedef typename basic_istream< _CharT, _Traits> ::int_type __int_type; 
# 1021
typedef ctype< _CharT>  __ctype_type; 
# 1023
const __ctype_type &__ct = use_facet< ctype< _CharT> > ((__in.getloc())); 
# 1024
const __int_type __eof = _Traits::eof(); 
# 1025
__streambuf_type *__sb = (__in.rdbuf()); 
# 1026
__int_type __c = (__sb->sgetc()); 
# 1028
while ((!_Traits::eq_int_type(__c, __eof)) && (__ct.is(ctype_base::space, _Traits::to_char_type(__c)))) { 
# 1030
__c = (__sb->snextc()); }  
# 1032
if (_Traits::eq_int_type(__c, __eof)) { 
# 1033
(__in.setstate(ios_base::eofbit)); }  
# 1034
return __in; 
# 1035
} 
# 1040
extern template class basic_istream< char, char_traits< char> > ;
# 1041
extern template basic_istream< char, char_traits< char> >  &ws(basic_istream< char, char_traits< char> >  & __is);
# 1042
extern template basic_istream< char, char_traits< char> >  &operator>>(basic_istream< char, char_traits< char> >  & __in, char & __c);
# 1043
extern template basic_istream< char, char_traits< char> >  &operator>>(basic_istream< char, char_traits< char> >  &, char *);
# 1044
extern template basic_istream< char, char_traits< char> >  &operator>>(basic_istream< char, char_traits< char> >  & __in, unsigned char & __c);
# 1045
extern template basic_istream< char, char_traits< char> >  &operator>>(basic_istream< char, char_traits< char> >  & __in, signed char & __c);
# 1046
extern template basic_istream< char, char_traits< char> >  &operator>>(basic_istream< char, char_traits< char> >  & __in, unsigned char * __s);
# 1047
extern template basic_istream< char, char_traits< char> >  &operator>>(basic_istream< char, char_traits< char> >  & __in, signed char * __s);
# 1049
extern template basic_istream< char, char_traits< char> > ::__istream_type &basic_istream< char, char_traits< char> > ::_M_extract(unsigned short & __v);
# 1050
extern template basic_istream< char, char_traits< char> > ::__istream_type &basic_istream< char, char_traits< char> > ::_M_extract(unsigned & __v);
# 1051
extern template basic_istream< char, char_traits< char> > ::__istream_type &basic_istream< char, char_traits< char> > ::_M_extract(long & __v);
# 1052
extern template basic_istream< char, char_traits< char> > ::__istream_type &basic_istream< char, char_traits< char> > ::_M_extract(unsigned long & __v);
# 1053
extern template basic_istream< char, char_traits< char> > ::__istream_type &basic_istream< char, char_traits< char> > ::_M_extract(bool & __v);
# 1055
extern template basic_istream< char, char_traits< char> > ::__istream_type &basic_istream< char, char_traits< char> > ::_M_extract(long long & __v);
# 1056
extern template basic_istream< char, char_traits< char> > ::__istream_type &basic_istream< char, char_traits< char> > ::_M_extract(unsigned long long & __v);
# 1058
extern template basic_istream< char, char_traits< char> > ::__istream_type &basic_istream< char, char_traits< char> > ::_M_extract(float & __v);
# 1059
extern template basic_istream< char, char_traits< char> > ::__istream_type &basic_istream< char, char_traits< char> > ::_M_extract(double & __v);
# 1060
extern template basic_istream< char, char_traits< char> > ::__istream_type &basic_istream< char, char_traits< char> > ::_M_extract(long double & __v);
# 1061
extern template basic_istream< char, char_traits< char> > ::__istream_type &basic_istream< char, char_traits< char> > ::_M_extract(void *& __v);
# 1063
extern template class basic_iostream< char, char_traits< char> > ;
# 1066
extern template class basic_istream< wchar_t, char_traits< wchar_t> > ;
# 1067
extern template basic_istream< wchar_t, char_traits< wchar_t> >  &ws(basic_istream< wchar_t, char_traits< wchar_t> >  & __is);
# 1068
extern template basic_istream< wchar_t, char_traits< wchar_t> >  &operator>>(basic_istream< wchar_t, char_traits< wchar_t> >  & __in, wchar_t & __c);
# 1069
extern template basic_istream< wchar_t, char_traits< wchar_t> >  &operator>>(basic_istream< wchar_t, char_traits< wchar_t> >  &, wchar_t *);
# 1071
extern template basic_istream< wchar_t, char_traits< wchar_t> > ::__istream_type &basic_istream< wchar_t, char_traits< wchar_t> > ::_M_extract(unsigned short & __v);
# 1072
extern template basic_istream< wchar_t, char_traits< wchar_t> > ::__istream_type &basic_istream< wchar_t, char_traits< wchar_t> > ::_M_extract(unsigned & __v);
# 1073
extern template basic_istream< wchar_t, char_traits< wchar_t> > ::__istream_type &basic_istream< wchar_t, char_traits< wchar_t> > ::_M_extract(long & __v);
# 1074
extern template basic_istream< wchar_t, char_traits< wchar_t> > ::__istream_type &basic_istream< wchar_t, char_traits< wchar_t> > ::_M_extract(unsigned long & __v);
# 1075
extern template basic_istream< wchar_t, char_traits< wchar_t> > ::__istream_type &basic_istream< wchar_t, char_traits< wchar_t> > ::_M_extract(bool & __v);
# 1077
extern template basic_istream< wchar_t, char_traits< wchar_t> > ::__istream_type &basic_istream< wchar_t, char_traits< wchar_t> > ::_M_extract(long long & __v);
# 1078
extern template basic_istream< wchar_t, char_traits< wchar_t> > ::__istream_type &basic_istream< wchar_t, char_traits< wchar_t> > ::_M_extract(unsigned long long & __v);
# 1080
extern template basic_istream< wchar_t, char_traits< wchar_t> > ::__istream_type &basic_istream< wchar_t, char_traits< wchar_t> > ::_M_extract(float & __v);
# 1081
extern template basic_istream< wchar_t, char_traits< wchar_t> > ::__istream_type &basic_istream< wchar_t, char_traits< wchar_t> > ::_M_extract(double & __v);
# 1082
extern template basic_istream< wchar_t, char_traits< wchar_t> > ::__istream_type &basic_istream< wchar_t, char_traits< wchar_t> > ::_M_extract(long double & __v);
# 1083
extern template basic_istream< wchar_t, char_traits< wchar_t> > ::__istream_type &basic_istream< wchar_t, char_traits< wchar_t> > ::_M_extract(void *& __v);
# 1085
extern template class basic_iostream< wchar_t, char_traits< wchar_t> > ;
# 1090
}
# 37 "/usr/include/c++/4.8.2/bits/stream_iterator.h" 3
namespace std __attribute((__visibility__("default"))) { 
# 47
template< class _Tp, class _CharT = char, class 
# 48
_Traits = char_traits< _CharT> , class _Dist = ptrdiff_t> 
# 49
class istream_iterator : public iterator< input_iterator_tag, _Tp, _Dist, const _Tp *, const _Tp &>  { 
# 53
public: typedef _CharT char_type; 
# 54
typedef _Traits traits_type; 
# 55
typedef basic_istream< _CharT, _Traits>  istream_type; 
# 58
private: istream_type *_M_stream; 
# 59
_Tp _M_value; 
# 60
bool _M_ok; 
# 64
public: istream_iterator() : _M_stream((0)), _M_value(), _M_ok(false) 
# 65
{ } 
# 68
istream_iterator(istream_type &__s) : _M_stream((&__s)) 
# 70
{ _M_read(); } 
# 72
istream_iterator(const istream_iterator &__obj) : _M_stream(__obj._M_stream), _M_value(__obj._M_value), _M_ok(__obj._M_ok) 
# 75
{ } 
# 78
const _Tp &operator*() const 
# 79
{ 
# 82
; 
# 83
return _M_value; 
# 84
} 
# 87
const _Tp *operator->() const { return &operator*(); } 
# 90
istream_iterator &operator++() 
# 91
{ 
# 94
; 
# 95
_M_read(); 
# 96
return *this; 
# 97
} 
# 100
istream_iterator operator++(int) 
# 101
{ 
# 104
; 
# 105
istream_iterator __tmp = *this; 
# 106
_M_read(); 
# 107
return __tmp; 
# 108
} 
# 111
bool _M_equal(const istream_iterator &__x) const 
# 112
{ return ((_M_ok) == (__x._M_ok)) && ((!(_M_ok)) || ((_M_stream) == (__x._M_stream))); } 
# 116
private: void _M_read() 
# 117
{ 
# 118
(_M_ok) = (((_M_stream) && (*(_M_stream))) ? true : false); 
# 119
if (_M_ok) 
# 120
{ 
# 121
(*(_M_stream)) >> (_M_value); 
# 122
(_M_ok) = ((*(_M_stream)) ? true : false); 
# 123
}  
# 124
} 
# 125
}; 
# 128
template< class _Tp, class _CharT, class _Traits, class _Dist> inline bool 
# 130
operator==(const istream_iterator< _Tp, _CharT, _Traits, _Dist>  &__x, const istream_iterator< _Tp, _CharT, _Traits, _Dist>  &
# 131
__y) 
# 132
{ return (__x._M_equal(__y)); } 
# 135
template< class _Tp, class _CharT, class _Traits, class _Dist> inline bool 
# 137
operator!=(const istream_iterator< _Tp, _CharT, _Traits, _Dist>  &__x, const istream_iterator< _Tp, _CharT, _Traits, _Dist>  &
# 138
__y) 
# 139
{ return !(__x._M_equal(__y)); } 
# 152
template< class _Tp, class _CharT = char, class 
# 153
_Traits = char_traits< _CharT> > 
# 154
class ostream_iterator : public iterator< output_iterator_tag, void, void, void, void>  { 
# 160
public: typedef _CharT char_type; 
# 161
typedef _Traits traits_type; 
# 162
typedef basic_ostream< _CharT, _Traits>  ostream_type; 
# 166
private: ostream_type *_M_stream; 
# 167
const _CharT *_M_string; 
# 171
public: ostream_iterator(ostream_type &__s) : _M_stream((&__s)), _M_string((0)) { } 
# 183
ostream_iterator(ostream_type &__s, const _CharT *__c) : _M_stream((&__s)), _M_string(__c) 
# 184
{ } 
# 187
ostream_iterator(const ostream_iterator &__obj) : _M_stream(__obj._M_stream), _M_string(__obj._M_string) 
# 188
{ } 
# 193
ostream_iterator &operator=(const _Tp &__value) 
# 194
{ 
# 197
; 
# 198
(*(_M_stream)) << __value; 
# 199
if (_M_string) { (*(_M_stream)) << (_M_string); }  
# 200
return *this; 
# 201
} 
# 204
ostream_iterator &operator*() 
# 205
{ return *this; } 
# 208
ostream_iterator &operator++() 
# 209
{ return *this; } 
# 212
ostream_iterator &operator++(int) 
# 213
{ return *this; } 
# 214
}; 
# 219
}
# 42 "/usr/local/cuda-8.0/include/thrust/iterator/iterator_categories.h"
namespace thrust { 
# 64
struct input_device_iterator_tag : public detail::iterator_category_with_system_and_traversal< std::input_iterator_tag, system::cuda::detail::tag, single_pass_traversal_tag>  { 
# 70
}; 
# 83
struct output_device_iterator_tag : public detail::iterator_category_with_system_and_traversal< std::output_iterator_tag, system::cuda::detail::tag, single_pass_traversal_tag>  { 
# 89
}; 
# 102
struct forward_device_iterator_tag : public detail::iterator_category_with_system_and_traversal< std::forward_iterator_tag, system::cuda::detail::tag, forward_traversal_tag>  { 
# 108
}; 
# 121
struct bidirectional_device_iterator_tag : public detail::iterator_category_with_system_and_traversal< std::bidirectional_iterator_tag, system::cuda::detail::tag, bidirectional_traversal_tag>  { 
# 127
}; 
# 140
struct random_access_device_iterator_tag : public detail::iterator_category_with_system_and_traversal< std::random_access_iterator_tag, system::cuda::detail::tag, random_access_traversal_tag>  { 
# 146
}; 
# 160
typedef std::input_iterator_tag input_host_iterator_tag; 
# 174
typedef std::output_iterator_tag output_host_iterator_tag; 
# 188
typedef std::forward_iterator_tag forward_host_iterator_tag; 
# 202
typedef std::bidirectional_iterator_tag bidirectional_host_iterator_tag; 
# 216
typedef std::random_access_iterator_tag random_access_host_iterator_tag; 
# 221
}
# 24 "/usr/local/cuda-8.0/include/thrust/iterator/detail/universal_categories.h"
namespace thrust { 
# 29
struct input_universal_iterator_tag { 
# 31
operator input_host_iterator_tag() { return input_host_iterator_tag(); } 
# 33
operator input_device_iterator_tag() { return input_device_iterator_tag(); } 
# 34
}; 
# 36
struct output_universal_iterator_tag { 
# 38
operator output_host_iterator_tag() { return output_host_iterator_tag(); } 
# 40
operator output_device_iterator_tag() { return output_device_iterator_tag(); } 
# 41
}; 
# 43
struct forward_universal_iterator_tag : public input_universal_iterator_tag { 
# 46
operator forward_host_iterator_tag() { return forward_host_iterator_tag(); } 
# 48
operator forward_device_iterator_tag() { return forward_device_iterator_tag(); } 
# 49
}; 
# 51
struct bidirectional_universal_iterator_tag : public forward_universal_iterator_tag { 
# 54
operator bidirectional_host_iterator_tag() { return bidirectional_host_iterator_tag(); } 
# 56
operator bidirectional_device_iterator_tag() { return bidirectional_device_iterator_tag(); } 
# 57
}; 
# 60
namespace detail { 
# 64
template< class T> 
# 65
struct one_degree_of_separation : public T { 
# 68
}; 
# 70
}
# 73
struct random_access_universal_iterator_tag { 
# 76
operator random_access_host_iterator_tag() { return random_access_host_iterator_tag(); } 
# 78
operator random_access_device_iterator_tag() { return random_access_device_iterator_tag(); } 
# 81
operator detail::one_degree_of_separation< bidirectional_universal_iterator_tag> () { return detail::one_degree_of_separation< bidirectional_universal_iterator_tag> (); } 
# 83
}; 
# 86
}
# 23 "/usr/local/cuda-8.0/include/thrust/iterator/detail/is_iterator_category.h"
namespace thrust { 
# 26
namespace detail { 
# 29
template< class T> 
# 30
struct is_host_iterator_category : public or_< is_convertible< T, std::input_iterator_tag> , is_convertible< T, std::output_iterator_tag> >  { 
# 36
}; 
# 38
template< class T> 
# 39
struct is_device_iterator_category : public or_< is_convertible< T, input_device_iterator_tag> , is_convertible< T, output_device_iterator_tag> >  { 
# 45
}; 
# 48
template< class T> 
# 49
struct is_iterator_category : public or_< is_host_iterator_category< T> , is_device_iterator_category< T> >  { 
# 55
}; 
# 57
}
# 59
}
# 27 "/usr/local/cuda-8.0/include/thrust/iterator/detail/iterator_category_to_system.h"
namespace thrust { 
# 30
namespace detail { 
# 34
template< class > struct is_iterator_system; 
# 36
template< class > struct device_iterator_category_to_backend_system; 
# 40
template< class Category> 
# 41
struct iterator_category_to_system : public eval_if< or_< is_convertible< Category, std::input_iterator_tag> , is_convertible< Category, std::output_iterator_tag> > ::value, identity_< system::cpp::detail::tag> , eval_if< or_< is_convertible< Category, input_device_iterator_tag> , is_convertible< Category, output_device_iterator_tag> > ::value, identity_< system::cuda::detail::tag> , identity_< void> > >  { 
# 65
}; 
# 68
template< class CategoryOrTraversal> 
# 69
struct iterator_category_or_traversal_to_system : public eval_if< is_iterator_system< CategoryOrTraversal> ::value, identity_< CategoryOrTraversal> , iterator_category_to_system< CategoryOrTraversal> >  { 
# 76
}; 
# 78
}
# 79
}
# 25 "/usr/local/cuda-8.0/include/thrust/iterator/detail/iterator_category_to_traversal.h"
namespace thrust { 
# 28
namespace detail { 
# 32
template< class > struct is_iterator_system; 
# 33
template< class > struct is_iterator_traversal; 
# 36
using namespace detail;
# 38
template< class Category> 
# 39
struct host_system_category_to_traversal : public eval_if< is_convertible< Category, std::random_access_iterator_tag> ::value, identity_< random_access_traversal_tag> , eval_if< is_convertible< Category, std::bidirectional_iterator_tag> ::value, identity_< bidirectional_traversal_tag> , eval_if< is_convertible< Category, std::forward_iterator_tag> ::value, identity_< forward_traversal_tag> , eval_if< is_convertible< Category, std::input_iterator_tag> ::value, identity_< single_pass_traversal_tag> , eval_if< is_convertible< Category, std::output_iterator_tag> ::value, identity_< incrementable_traversal_tag> , void> > > > >  { 
# 62
}; 
# 66
template< class Category> 
# 67
struct device_system_category_to_traversal : public eval_if< is_convertible< Category, random_access_device_iterator_tag> ::value, identity_< random_access_traversal_tag> , eval_if< is_convertible< Category, bidirectional_device_iterator_tag> ::value, identity_< bidirectional_traversal_tag> , eval_if< is_convertible< Category, forward_device_iterator_tag> ::value, identity_< forward_traversal_tag> , eval_if< is_convertible< Category, input_device_iterator_tag> ::value, identity_< single_pass_traversal_tag> , eval_if< is_convertible< Category, output_device_iterator_tag> ::value, identity_< incrementable_traversal_tag> , void> > > > >  { 
# 90
}; 
# 93
template< class Category> 
# 94
struct category_to_traversal : public eval_if< or_< is_convertible< Category, std::input_iterator_tag> , is_convertible< Category, std::output_iterator_tag> > ::value, host_system_category_to_traversal< Category> , eval_if< or_< is_convertible< Category, input_device_iterator_tag> , is_convertible< Category, output_device_iterator_tag> > ::value, device_system_category_to_traversal< Category> , void> >  { 
# 117
}; 
# 120
template< class CategoryOrTraversal> 
# 121
struct iterator_category_to_traversal : public eval_if< is_iterator_traversal< CategoryOrTraversal> ::value, identity_< CategoryOrTraversal> , category_to_traversal< CategoryOrTraversal> >  { 
# 128
}; 
# 131
}
# 133
}
# 30 "/usr/local/cuda-8.0/include/thrust/iterator/detail/iterator_facade_category.h"
namespace thrust { 
# 33
namespace detail { 
# 81
template< class System, class Traversal, class ValueParam, class Reference> struct iterator_facade_default_category; 
# 95
template< class Traversal, class ValueParam, class Reference> 
# 96
struct iterator_facade_default_category_std : public eval_if< is_convertible< Traversal, forward_traversal_tag> ::value, eval_if< is_convertible< Traversal, random_access_traversal_tag> ::value, identity_< std::random_access_iterator_tag> , eval_if< is_convertible< Traversal, bidirectional_traversal_tag> ::value, identity_< std::bidirectional_iterator_tag> , identity_< std::forward_iterator_tag> > > , eval_if< is_convertible< Traversal, single_pass_traversal_tag> ::value, identity_< std::input_iterator_tag> , identity_< Traversal> > >  { 
# 115
}; 
# 119
template< class Traversal, class ValueParam, class Reference> 
# 120
struct iterator_facade_default_category_host : public eval_if< is_convertible< Traversal, forward_traversal_tag> ::value, eval_if< is_convertible< Traversal, random_access_traversal_tag> ::value, identity_< std::random_access_iterator_tag> , eval_if< is_convertible< Traversal, bidirectional_traversal_tag> ::value, identity_< std::bidirectional_iterator_tag> , identity_< std::forward_iterator_tag> > > , eval_if< is_convertible< Traversal, single_pass_traversal_tag> ::value, identity_< std::input_iterator_tag> , identity_< Traversal> > >  { 
# 139
}; 
# 143
template< class Traversal, class ValueParam, class Reference> 
# 144
struct iterator_facade_default_category_device : public eval_if< is_convertible< Traversal, forward_traversal_tag> ::value, eval_if< is_convertible< Traversal, random_access_traversal_tag> ::value, identity_< random_access_device_iterator_tag> , eval_if< is_convertible< Traversal, bidirectional_traversal_tag> ::value, identity_< bidirectional_device_iterator_tag> , identity_< forward_device_iterator_tag> > > , eval_if< is_convertible< Traversal, single_pass_traversal_tag> ::value, identity_< input_device_iterator_tag> , identity_< Traversal> > >  { 
# 163
}; 
# 167
template< class Traversal, class ValueParam, class Reference> 
# 168
struct iterator_facade_default_category_any { 
# 174
typedef iterator_category_with_system_and_traversal< typename iterator_facade_default_category_std< Traversal, ValueParam, Reference> ::type, any_system_tag, Traversal>  type; 
# 175
}; 
# 178
template< class System, class Traversal, class ValueParam, class Reference> 
# 179
struct iterator_facade_default_category : public eval_if< is_convertible< System, any_system_tag> ::value, iterator_facade_default_category_any< Traversal, ValueParam, Reference> , eval_if< is_convertible< System, system::cpp::detail::tag> ::value, iterator_facade_default_category_host< Traversal, ValueParam, Reference> , eval_if< is_convertible< System, system::cuda::detail::tag> ::value, iterator_facade_default_category_device< Traversal, ValueParam, Reference> , identity_< iterator_category_with_system_and_traversal< typename iterator_facade_default_category_std< Traversal, ValueParam, Reference> ::type, System, Traversal> > > > >  { 
# 207
}; 
# 210
template< class System, class Traversal, class ValueParam, class Reference> 
# 211
struct iterator_facade_category_impl { 
# 215
typedef typename iterator_facade_default_category< System, Traversal, ValueParam, Reference> ::type category; 
# 232
typedef typename eval_if< and_< is_same< Traversal, typename iterator_category_to_traversal< typename iterator_facade_default_category< System, Traversal, ValueParam, Reference> ::type> ::type> , is_same< System, typename iterator_category_to_system< typename iterator_facade_default_category< System, Traversal, ValueParam, Reference> ::type> ::type> > ::value, identity_< typename iterator_facade_default_category< System, Traversal, ValueParam, Reference> ::type> , identity_< iterator_category_with_system_and_traversal< typename iterator_facade_default_category< System, Traversal, ValueParam, Reference> ::type, System, Traversal> > > ::type type; 
# 233
}; 
# 236
template< class CategoryOrSystem, class 
# 237
CategoryOrTraversal, class 
# 238
ValueParam, class 
# 239
Reference> 
# 240
struct iterator_facade_category { 
# 247
typedef typename eval_if< is_iterator_category< CategoryOrTraversal> ::value, identity_< CategoryOrTraversal> , iterator_facade_category_impl< CategoryOrSystem, CategoryOrTraversal, ValueParam, Reference> > ::type type; 
# 248
}; 
# 251
}
# 252
}
# 22 "/usr/local/cuda-8.0/include/thrust/iterator/detail/distance_from_result.h"
namespace thrust { 
# 25
namespace detail { 
# 30
template< class IteratorFacade1, class IteratorFacade2> 
# 31
struct distance_from_result : public eval_if< is_convertible< IteratorFacade2, IteratorFacade1> ::value, identity_< typename IteratorFacade1::difference_type> , identity_< typename IteratorFacade2::difference_type> >  { 
# 37
}; 
# 39
}
# 41
}
# 40 "/usr/local/cuda-8.0/include/thrust/iterator/iterator_facade.h"
namespace thrust { 
# 55
template< class Derived, class Value, class System, class Traversal, class Reference, class Difference> class iterator_facade; 
# 61
class iterator_core_access { 
# 67
template< class Derived, class Value, class System, class Traversal, class Reference, class Difference> friend class iterator_facade; 
# 70
template< class Derived1, class Value1, class System1, class Traversal1, class Reference1, class Difference1, class 
# 71
Derived2, class Value2, class System2, class Traversal2, class Reference2, class Difference2> friend inline bool 
# 70
operator==(const iterator_facade< Derived1, Value1, System1, Traversal1, Reference1, Difference1>  & lhs, const iterator_facade< Derived2, Value2, System2, Traversal2, Reference2, Difference2>  & rhs); 
# 77
template< class Derived1, class Value1, class System1, class Traversal1, class Reference1, class Difference1, class 
# 78
Derived2, class Value2, class System2, class Traversal2, class Reference2, class Difference2> friend inline bool 
# 77
operator!=(const iterator_facade< Derived1, Value1, System1, Traversal1, Reference1, Difference1>  & lhs, const iterator_facade< Derived2, Value2, System2, Traversal2, Reference2, Difference2>  & rhs); 
# 84
template< class Derived1, class Value1, class System1, class Traversal1, class Reference1, class Difference1, class 
# 85
Derived2, class Value2, class System2, class Traversal2, class Reference2, class Difference2> friend inline bool 
# 84
operator<(const iterator_facade< Derived1, Value1, System1, Traversal1, Reference1, Difference1>  & lhs, const iterator_facade< Derived2, Value2, System2, Traversal2, Reference2, Difference2>  & rhs); 
# 91
template< class Derived1, class Value1, class System1, class Traversal1, class Reference1, class Difference1, class 
# 92
Derived2, class Value2, class System2, class Traversal2, class Reference2, class Difference2> friend inline bool 
# 91
operator>(const iterator_facade< Derived1, Value1, System1, Traversal1, Reference1, Difference1>  & lhs, const iterator_facade< Derived2, Value2, System2, Traversal2, Reference2, Difference2>  & rhs); 
# 98
template< class Derived1, class Value1, class System1, class Traversal1, class Reference1, class Difference1, class 
# 99
Derived2, class Value2, class System2, class Traversal2, class Reference2, class Difference2> friend inline bool 
# 98
operator<=(const iterator_facade< Derived1, Value1, System1, Traversal1, Reference1, Difference1>  & lhs, const iterator_facade< Derived2, Value2, System2, Traversal2, Reference2, Difference2>  & rhs); 
# 105
template< class Derived1, class Value1, class System1, class Traversal1, class Reference1, class Difference1, class 
# 106
Derived2, class Value2, class System2, class Traversal2, class Reference2, class Difference2> friend inline bool 
# 105
operator>=(const iterator_facade< Derived1, Value1, System1, Traversal1, Reference1, Difference1>  & lhs, const iterator_facade< Derived2, Value2, System2, Traversal2, Reference2, Difference2>  & rhs); 
# 113
template< class Derived1, class Value1, class System1, class Traversal1, class Reference1, class Difference1, class 
# 114
Derived2, class Value2, class System2, class Traversal2, class Reference2, class Difference2> friend inline typename detail::distance_from_result< iterator_facade< Derived1, Value1, System1, Traversal1, Reference1, Difference1> , iterator_facade< Derived2, Value2, System2, Traversal2, Reference2, Difference2> > ::type 
# 113
operator-(const iterator_facade< Derived1, Value1, System1, Traversal1, Reference1, Difference1>  & lhs, const iterator_facade< Derived2, Value2, System2, Traversal2, Reference2, Difference2>  & rhs); 
# 124
template< class Facade> static typename Facade::reference 
# 126
dereference(const Facade &f) 
# 127
{ 
# 128
return (f.dereference()); 
# 129
} 
# 131
template< class Facade> static void 
# 133
increment(Facade &f) 
# 134
{ 
# 135
(f.increment()); 
# 136
} 
# 138
template< class Facade> static void 
# 140
decrement(Facade &f) 
# 141
{ 
# 142
(f.decrement()); 
# 143
} 
# 145
template< class Facade1, class Facade2> static bool 
# 147
equal(const Facade1 &f1, const Facade2 &f2) 
# 148
{ 
# 149
return (f1.equal(f2)); 
# 150
} 
# 167
template< class Facade> static void 
# 169
advance(Facade &f, typename Facade::difference_type n) 
# 170
{ 
# 171
(f.advance(n)); 
# 172
} 
# 176
template< class Facade1, class Facade2> static typename Facade1::difference_type 
# 179
distance_from(const Facade1 &f1, const Facade2 &f2, detail::true_type) 
# 180
{ 
# 181
return -(f1.distance_to(f2)); 
# 182
} 
# 186
template< class Facade1, class Facade2> static typename Facade2::difference_type 
# 189
distance_from(const Facade1 &f1, const Facade2 &f2, detail::false_type) 
# 190
{ 
# 191
return (f2.distance_to(f1)); 
# 192
} 
# 194
template< class Facade1, class Facade2> static typename detail::distance_from_result< Facade1, Facade2> ::type 
# 197
distance_from(const Facade1 &f1, const Facade2 &f2) 
# 198
{ 
# 201
return distance_from(f1, f2, typename detail::is_convertible< Facade2, Facade1> ::type()); 
# 203
} 
# 208
template< class Derived, class Value, class System, class Traversal, class Reference, class Difference> static Derived &
# 210
derived(iterator_facade< Derived, Value, System, Traversal, Reference, Difference>  &facade) 
# 211
{ 
# 212
return *(static_cast< Derived *>(&facade)); 
# 213
} 
# 215
template< class Derived, class Value, class System, class Traversal, class Reference, class Difference> static const Derived &
# 217
derived(const iterator_facade< Derived, Value, System, Traversal, Reference, Difference>  &facade) 
# 218
{ 
# 219
return *(static_cast< const Derived *>(&facade)); 
# 220
} 
# 224
}; 
# 246
template< class Derived, class 
# 247
Value, class 
# 248
System, class 
# 249
Traversal, class 
# 250
Reference, class 
# 251
Difference = std::ptrdiff_t> 
# 252
class iterator_facade { 
# 262
Derived &derived() 
# 263
{ 
# 264
return *(static_cast< Derived *>(this)); 
# 265
} 
# 268
const Derived &derived() const 
# 269
{ 
# 270
return *(static_cast< const Derived *>(this)); 
# 271
} 
# 278
public: typedef typename detail::remove_const< Value> ::type value_type; 
# 282
typedef Reference reference; 
# 291
typedef void pointer; 
# 296
typedef Difference difference_type; 
# 302
typedef typename detail::iterator_facade_category< System, Traversal, Value, Reference> ::type iterator_category; 
# 308
reference operator*() const 
# 309
{ 
# 310
return iterator_core_access::dereference(this->derived()); 
# 311
} 
# 326
reference operator[](difference_type n) const 
# 327
{ 
# 328
return *(this->derived() + n); 
# 329
} 
# 335
Derived &operator++() 
# 336
{ 
# 337
iterator_core_access::increment(this->derived()); 
# 338
return this->derived(); 
# 339
} 
# 345
Derived operator++(int) 
# 346
{ 
# 347
Derived tmp(this->derived()); 
# 348
++(*this); 
# 349
return tmp; 
# 350
} 
# 356
Derived &operator--() 
# 357
{ 
# 358
iterator_core_access::decrement(this->derived()); 
# 359
return this->derived(); 
# 360
} 
# 366
Derived operator--(int) 
# 367
{ 
# 368
Derived tmp(this->derived()); 
# 369
--(*this); 
# 370
return tmp; 
# 371
} 
# 378
Derived &operator+=(difference_type n) 
# 379
{ 
# 380
iterator_core_access::advance(this->derived(), n); 
# 381
return this->derived(); 
# 382
} 
# 389
Derived &operator-=(difference_type n) 
# 390
{ 
# 391
iterator_core_access::advance(this->derived(), -n); 
# 392
return this->derived(); 
# 393
} 
# 400
Derived operator-(difference_type n) const 
# 401
{ 
# 402
Derived result(this->derived()); 
# 403
return result -= n; 
# 404
} 
# 405
}; 
# 411
template< class Derived1, class Value1, class System1, class Traversal1, class Reference1, class Difference1, class 
# 412
Derived2, class Value2, class System2, class Traversal2, class Reference2, class Difference2> inline bool 
# 417
operator==(const iterator_facade< Derived1, Value1, System1, Traversal1, Reference1, Difference1>  &lhs, const iterator_facade< Derived2, Value2, System2, Traversal2, Reference2, Difference2>  &
# 418
rhs) 
# 419
{ 
# 420
return iterator_core_access::equal(*(static_cast< const Derived1 *>(&lhs)), *(static_cast< const Derived2 *>(&rhs))); 
# 423
} 
# 425
template< class Derived1, class Value1, class System1, class Traversal1, class Reference1, class Difference1, class 
# 426
Derived2, class Value2, class System2, class Traversal2, class Reference2, class Difference2> inline bool 
# 431
operator!=(const iterator_facade< Derived1, Value1, System1, Traversal1, Reference1, Difference1>  &lhs, const iterator_facade< Derived2, Value2, System2, Traversal2, Reference2, Difference2>  &
# 432
rhs) 
# 433
{ 
# 434
return !iterator_core_access::equal(*(static_cast< const Derived1 *>(&lhs)), *(static_cast< const Derived2 *>(&rhs))); 
# 437
} 
# 439
template< class Derived1, class Value1, class System1, class Traversal1, class Reference1, class Difference1, class 
# 440
Derived2, class Value2, class System2, class Traversal2, class Reference2, class Difference2> inline bool 
# 445
operator<(const iterator_facade< Derived1, Value1, System1, Traversal1, Reference1, Difference1>  &lhs, const iterator_facade< Derived2, Value2, System2, Traversal2, Reference2, Difference2>  &
# 446
rhs) 
# 447
{ 
# 448
return 0 > iterator_core_access::distance_from(*(static_cast< const Derived1 *>(&lhs)), *(static_cast< const Derived2 *>(&rhs))); 
# 451
} 
# 453
template< class Derived1, class Value1, class System1, class Traversal1, class Reference1, class Difference1, class 
# 454
Derived2, class Value2, class System2, class Traversal2, class Reference2, class Difference2> inline bool 
# 459
operator>(const iterator_facade< Derived1, Value1, System1, Traversal1, Reference1, Difference1>  &lhs, const iterator_facade< Derived2, Value2, System2, Traversal2, Reference2, Difference2>  &
# 460
rhs) 
# 461
{ 
# 462
return 0 < iterator_core_access::distance_from(*(static_cast< const Derived1 *>(&lhs)), *(static_cast< const Derived2 *>(&rhs))); 
# 465
} 
# 467
template< class Derived1, class Value1, class System1, class Traversal1, class Reference1, class Difference1, class 
# 468
Derived2, class Value2, class System2, class Traversal2, class Reference2, class Difference2> inline bool 
# 473
operator<=(const iterator_facade< Derived1, Value1, System1, Traversal1, Reference1, Difference1>  &lhs, const iterator_facade< Derived2, Value2, System2, Traversal2, Reference2, Difference2>  &
# 474
rhs) 
# 475
{ 
# 476
return 0 >= iterator_core_access::distance_from(*(static_cast< const Derived1 *>(&lhs)), *(static_cast< const Derived2 *>(&rhs))); 
# 479
} 
# 481
template< class Derived1, class Value1, class System1, class Traversal1, class Reference1, class Difference1, class 
# 482
Derived2, class Value2, class System2, class Traversal2, class Reference2, class Difference2> inline bool 
# 487
operator>=(const iterator_facade< Derived1, Value1, System1, Traversal1, Reference1, Difference1>  &lhs, const iterator_facade< Derived2, Value2, System2, Traversal2, Reference2, Difference2>  &
# 488
rhs) 
# 489
{ 
# 490
return 0 <= iterator_core_access::distance_from(*(static_cast< const Derived1 *>(&lhs)), *(static_cast< const Derived2 *>(&rhs))); 
# 493
} 
# 496
template< class Derived1, class Value1, class System1, class Traversal1, class Reference1, class Difference1, class 
# 497
Derived2, class Value2, class System2, class Traversal2, class Reference2, class Difference2> inline typename detail::distance_from_result< iterator_facade< Derived1, Value1, System1, Traversal1, Reference1, Difference1> , iterator_facade< Derived2, Value2, System2, Traversal2, Reference2, Difference2> > ::type 
# 506
operator-(const iterator_facade< Derived1, Value1, System1, Traversal1, Reference1, Difference1>  &lhs, const iterator_facade< Derived2, Value2, System2, Traversal2, Reference2, Difference2>  &
# 507
rhs) 
# 508
{ 
# 509
return iterator_core_access::distance_from(*(static_cast< const Derived1 *>(&lhs)), *(static_cast< const Derived2 *>(&rhs))); 
# 512
} 
# 515
template< class Derived, class Value, class System, class Traversal, class Reference, class Difference> inline Derived 
# 517
operator+(const iterator_facade< Derived, Value, System, Traversal, Reference, Difference>  &i, typename Derived::difference_type 
# 518
n) 
# 519
{ 
# 520
Derived tmp(static_cast< const Derived &>(i)); 
# 521
return tmp += n; 
# 522
} 
# 524
template< class Derived, class Value, class System, class Traversal, class Reference, class Difference> inline Derived 
# 526
operator+(typename Derived::difference_type n, const iterator_facade< Derived, Value, System, Traversal, Reference, Difference>  &
# 527
i) 
# 528
{ 
# 529
Derived tmp(static_cast< const Derived &>(i)); 
# 530
return tmp += n; 
# 531
} 
# 542
}
# 21 "/usr/local/cuda-8.0/include/thrust/detail/use_default.h"
namespace thrust { 
# 24
struct use_default { }; 
# 26
}
# 36 "/usr/local/cuda-8.0/include/thrust/iterator/iterator_traits.h"
namespace thrust { 
# 42
template< class T> 
# 43
struct iterator_traits { 
# 45
typedef typename T::difference_type difference_type; 
# 46
typedef typename T::value_type value_type; 
# 47
typedef typename T::pointer pointer; 
# 48
typedef typename T::reference reference; 
# 49
typedef typename T::iterator_category iterator_category; 
# 50
}; 
# 53
template< class T> 
# 54
struct iterator_traits< T *>  { 
# 56
typedef std::ptrdiff_t difference_type; 
# 57
typedef T value_type; 
# 58
typedef T *pointer; 
# 59
typedef T &reference; 
# 60
typedef std::random_access_iterator_tag iterator_category; 
# 61
}; 
# 63
template< class T> 
# 64
struct iterator_traits< const T *>  { 
# 66
typedef std::ptrdiff_t difference_type; 
# 67
typedef T value_type; 
# 68
typedef const T *pointer; 
# 69
typedef const T &reference; 
# 70
typedef std::random_access_iterator_tag iterator_category; 
# 71
}; 
# 73
template< class Iterator> struct iterator_value; 
# 75
template< class Iterator> struct iterator_pointer; 
# 77
template< class Iterator> struct iterator_reference; 
# 79
template< class Iterator> struct iterator_difference; 
# 81
template< class Iterator> struct iterator_traversal; 
# 83
template< class Iterator> struct iterator_system; 
# 86
template< class Iterator> 
# 87
struct __attribute((deprecated)) iterator_space { 
# 89
__attribute((deprecated)) typedef typename iterator_system< Iterator> ::type type; 
# 90
}; 
# 93
}
# 26 "/usr/local/cuda-8.0/include/thrust/iterator/detail/iterator_traits.inl"
namespace thrust { 
# 29
template< class Iterator> 
# 30
struct iterator_value { 
# 32
typedef typename iterator_traits< Iterator> ::value_type type; 
# 33
}; 
# 36
template< class Iterator> 
# 37
struct iterator_pointer { 
# 39
typedef typename iterator_traits< Iterator> ::pointer type; 
# 40
}; 
# 43
template< class Iterator> 
# 44
struct iterator_reference { 
# 46
typedef typename iterator_traits< Iterator> ::reference type; 
# 47
}; 
# 50
template< class Iterator> 
# 51
struct iterator_difference { 
# 53
typedef typename iterator_traits< Iterator> ::difference_type type; 
# 54
}; 
# 57
template< class Iterator> 
# 58
struct iterator_system : public detail::iterator_category_to_system< typename iterator_traits< Iterator> ::iterator_category>  { 
# 63
}; 
# 67
template<> struct iterator_system< void *>  { 
# 69
typedef detail::eval_if< detail::integral_constant< bool, true> ::value, detail::identity_< system::cpp::detail::tag> , detail::eval_if< detail::integral_constant< bool, false> ::value, detail::identity_< system::cuda::detail::tag> , detail::identity_< void> > > ::type type; 
# 70
}; 
# 73
template<> struct iterator_system< const void *>  { 
# 75
typedef detail::eval_if< true, detail::identity_< system::cpp::detail::tag> , detail::eval_if< false, detail::identity_< system::cuda::detail::tag> , detail::identity_< void> > > ::type type; 
# 76
}; 
# 79
template< class Iterator> 
# 80
struct iterator_traversal : public detail::iterator_category_to_traversal< typename iterator_traits< Iterator> ::iterator_category>  { 
# 85
}; 
# 87
namespace detail { 
# 90
template< class T> 
# 91
struct is_iterator_traversal : public is_convertible< T, incrementable_traversal_tag>  { 
# 94
}; 
# 97
template< class T> 
# 98
struct is_iterator_system : public or_< is_convertible< T, any_system_tag> , or_< is_convertible< T, system::cpp::detail::tag> , is_convertible< T, system::cuda::detail::tag> > >  { 
# 107
}; 
# 110
}
# 111
}
# 24 "/usr/local/cuda-8.0/include/thrust/iterator/detail/iterator_adaptor_base.h"
namespace thrust { 
# 29
template< class Derived, class 
# 30
Base, class 
# 31
Value, class 
# 32
System, class 
# 33
Traversal, class 
# 34
Reference, class 
# 35
Difference> class iterator_adaptor; 
# 40
namespace detail { 
# 46
template< class T, class DefaultNullaryFn> 
# 47
struct ia_dflt_help : public eval_if< is_same< T, use_default> ::value, DefaultNullaryFn, identity_< T> >  { 
# 54
}; 
# 59
template< class Derived, class 
# 60
Base, class 
# 61
Value, class 
# 62
System, class 
# 63
Traversal, class 
# 64
Reference, class 
# 65
Difference> 
# 67
struct iterator_adaptor_base { 
# 72
typedef typename ia_dflt_help< Value, iterator_value< Base> > ::type value; 
# 77
typedef typename ia_dflt_help< System, iterator_system< Base> > ::type system; 
# 82
typedef typename ia_dflt_help< Traversal, iterator_traversal< Base> > ::type traversal; 
# 91
typedef typename ia_dflt_help< Reference, eval_if< is_same< Value, use_default> ::value, iterator_reference< Base> , add_reference< Value> > > ::type reference; 
# 96
typedef typename ia_dflt_help< Difference, iterator_difference< Base> > ::type difference; 
# 105
typedef iterator_facade< Derived, typename ia_dflt_help< Value, iterator_value< Base> > ::type, typename ia_dflt_help< System, iterator_system< Base> > ::type, typename ia_dflt_help< Traversal, iterator_traversal< Base> > ::type, typename ia_dflt_help< Reference, eval_if< is_same< Value, use_default> ::value, iterator_reference< Base> , add_reference< Value> > > ::type, typename ia_dflt_help< Difference, iterator_difference< Base> > ::type>  type; 
# 106
}; 
# 109
}
# 110
}
# 40 "/usr/local/cuda-8.0/include/thrust/iterator/iterator_adaptor.h"
namespace thrust { 
# 114
template< class Derived, class 
# 115
Base, class 
# 116
Value = use_default, class 
# 117
System = use_default, class 
# 118
Traversal = use_default, class 
# 119
Reference = use_default, class 
# 120
Difference = use_default> 
# 121
class iterator_adaptor : public detail::iterator_adaptor_base< Derived, Base, Value, System, Traversal, Reference, Difference> ::type { 
# 129
friend class iterator_core_access; 
# 134
protected: typedef typename ::thrust::detail::iterator_adaptor_base< Derived, Base, Value, System, Traversal, Reference, Difference> ::type super_t; 
# 143
public: iterator_adaptor() { } 
# 148
explicit iterator_adaptor(const Base &iter) : m_iterator(iter) 
# 150
{ } 
# 154
typedef Base base_type; 
# 158
typedef typename ::thrust::detail::iterator_adaptor_base< Derived, Base, Value, System, Traversal, Reference, Difference> ::type::reference reference; 
# 160
typedef typename ::thrust::detail::iterator_adaptor_base< Derived, Base, Value, System, Traversal, Reference, Difference> ::type::difference_type difference_type; 
# 167
const Base &base() const 
# 168
{ return m_iterator; } 
# 174
protected: const Base &base_reference() const 
# 175
{ return m_iterator; } 
# 180
Base &base_reference() 
# 181
{ return m_iterator; } 
# 189
private: reference dereference() const 
# 190
{ return *(m_iterator); } 
# 193
template< class OtherDerived, class OtherIterator, class V, class S, class T, class R, class D> bool 
# 195
equal(const ::thrust::iterator_adaptor< OtherDerived, OtherIterator, V, S, T, R, D>  &x) const 
# 196
{ return (m_iterator) == (x.base()); } 
# 200
void advance(difference_type n) 
# 201
{ 
# 203
(m_iterator) += n; 
# 204
} 
# 208
void increment() 
# 209
{ ++(m_iterator); } 
# 213
void decrement() 
# 214
{ 
# 216
--(m_iterator); 
# 217
} 
# 220
template< class OtherDerived, class OtherIterator, class V, class S, class T, class R, class D> difference_type 
# 222
distance_to(const ::thrust::iterator_adaptor< OtherDerived, OtherIterator, V, S, T, R, D>  &y) const 
# 223
{ return (y.base()) - (m_iterator); } 
# 226
Base m_iterator; 
# 230
}; 
# 238
}
# 22 "/usr/local/cuda-8.0/include/thrust/detail/type_traits/is_metafunction_defined.h"
namespace thrust { 
# 25
namespace detail { 
# 28
template< class T> struct is_metafunction_defined { typedef char yes_type; typedef int no_type; template< class S> static yes_type test(typename S::type *); template< class S> static no_type test(...); static const bool value = (sizeof(test< T> (0)) == sizeof(yes_type)); typedef integral_constant< bool, value>  type; }; 
# 30
template< class Metafunction> 
# 31
struct enable_if_defined : public lazy_enable_if< is_metafunction_defined< Metafunction> ::value, Metafunction>  { 
# 36
}; 
# 38
}
# 40
}
# 26 "/usr/local/cuda-8.0/include/thrust/detail/type_traits/pointer_traits.h"
namespace thrust { 
# 28
namespace detail { 
# 31
template< class Ptr> struct pointer_element; 
# 33
template< template< class >  class Ptr, class Arg> 
# 34
struct pointer_element< Ptr< Arg> >  { 
# 36
typedef Arg type; 
# 37
}; 
# 39
template< template< class , class >  class Ptr, class Arg1, class Arg2> 
# 40
struct pointer_element< Ptr< Arg1, Arg2> >  { 
# 42
typedef Arg1 type; 
# 43
}; 
# 45
template< template< class , class , class >  class Ptr, class Arg1, class Arg2, class Arg3> 
# 46
struct pointer_element< Ptr< Arg1, Arg2, Arg3> >  { 
# 48
typedef Arg1 type; 
# 49
}; 
# 51
template< template< class , class , class , class >  class Ptr, class Arg1, class Arg2, class Arg3, class Arg4> 
# 52
struct pointer_element< Ptr< Arg1, Arg2, Arg3, Arg4> >  { 
# 54
typedef Arg1 type; 
# 55
}; 
# 57
template< template< class , class , class , class , class >  class Ptr, class Arg1, class Arg2, class Arg3, class Arg4, class Arg5> 
# 58
struct pointer_element< Ptr< Arg1, Arg2, Arg3, Arg4, Arg5> >  { 
# 60
typedef Arg1 type; 
# 61
}; 
# 63
template< class T> 
# 64
struct pointer_element< T *>  { 
# 66
typedef T type; 
# 67
}; 
# 69
template< class Ptr> 
# 70
struct pointer_difference { 
# 72
typedef typename Ptr::difference_type type; 
# 73
}; 
# 75
template< class T> 
# 76
struct pointer_difference< T *>  { 
# 78
typedef std::ptrdiff_t type; 
# 79
}; 
# 81
template< class Ptr, class T> struct rebind_pointer; 
# 83
template< class T, class U> 
# 84
struct rebind_pointer< T *, U>  { 
# 86
typedef U *type; 
# 87
}; 
# 89
template< template< class >  class Ptr, class Arg, class T> 
# 90
struct rebind_pointer< Ptr< Arg> , T>  { 
# 92
typedef Ptr< T>  type; 
# 93
}; 
# 95
template< template< class , class >  class Ptr, class Arg1, class Arg2, class T> 
# 96
struct rebind_pointer< Ptr< Arg1, Arg2> , T>  { 
# 98
typedef Ptr< T, Arg2>  type; 
# 99
}; 
# 101
template< template< class , class , class >  class Ptr, class Arg1, class Arg2, class Arg3, class T> 
# 102
struct rebind_pointer< Ptr< Arg1, Arg2, Arg3> , T>  { 
# 104
typedef Ptr< T, Arg2, Arg3>  type; 
# 105
}; 
# 107
template< template< class , class , class , class >  class Ptr, class Arg1, class Arg2, class Arg3, class Arg4, class T> 
# 108
struct rebind_pointer< Ptr< Arg1, Arg2, Arg3, Arg4> , T>  { 
# 110
typedef Ptr< T, Arg2, Arg3, Arg4>  type; 
# 111
}; 
# 114
template< class T> struct has_raw_pointer { typedef char yes_type; typedef int no_type; template< class S> static yes_type test(typename S::raw_pointer *); template< class S> static no_type test(...); static const bool value = (sizeof(test< T> (0)) == sizeof(yes_type)); typedef integral_constant< bool, value>  type; }; 
# 116
namespace pointer_traits_detail { 
# 119
template< class Ptr, class Enable = void> struct pointer_raw_pointer_impl { }; 
# 121
template< class T> 
# 122
struct pointer_raw_pointer_impl< T *, void>  { 
# 124
typedef T *type; 
# 125
}; 
# 127
template< class Ptr> 
# 128
struct pointer_raw_pointer_impl< Ptr, typename enable_if< has_raw_pointer< Ptr> ::value> ::type>  { 
# 130
typedef typename Ptr::raw_pointer type; 
# 131
}; 
# 133
}
# 135
template< class T> 
# 136
struct pointer_raw_pointer : public pointer_traits_detail::pointer_raw_pointer_impl< T>  { 
# 138
}; 
# 140
namespace pointer_traits_detail { 
# 143
template< class Void> 
# 144
struct capture_address { 
# 146
template< class T> 
# 148
capture_address(T &r) : m_addr((&r)) 
# 150
{ } 
# 153
Void *operator&() const 
# 154
{ 
# 155
return m_addr; 
# 156
} 
# 158
Void *m_addr; 
# 159
}; 
# 162
template< class T> 
# 163
struct pointer_to_param : public eval_if< is_void< T> ::value, identity_< capture_address< T> > , add_reference< T> >  { 
# 169
}; 
# 171
}
# 173
template< class Ptr> 
# 174
struct pointer_traits { 
# 176
typedef Ptr pointer; 
# 177
typedef typename pointer_element< Ptr> ::type element_type; 
# 178
typedef typename pointer_difference< Ptr> ::type difference_type; 
# 180
template< class U> 
# 181
struct rebind { 
# 183
typedef typename rebind_pointer< Ptr, U> ::type other; 
# 184
}; 
# 187
static pointer pointer_to(typename pointer_traits_detail::pointer_to_param< typename pointer_element< Ptr> ::type> ::type r) 
# 188
{ 
# 192
return (pointer)(&r); 
# 193
} 
# 196
typedef typename pointer_raw_pointer< Ptr> ::type raw_pointer; 
# 199
static raw_pointer get(pointer ptr) 
# 200
{ 
# 201
return (ptr.get()); 
# 202
} 
# 203
}; 
# 205
template< class T> 
# 206
struct pointer_traits< T *>  { 
# 208
typedef T *pointer; 
# 209
typedef T element_type; 
# 210
typedef typename pointer_difference< T *> ::type difference_type; 
# 212
template< class U> 
# 213
struct rebind { 
# 215
typedef U *other; 
# 216
}; 
# 219
static pointer pointer_to(typename pointer_traits_detail::pointer_to_param< T> ::type r) 
# 220
{ 
# 221
return &r; 
# 222
} 
# 225
typedef typename pointer_raw_pointer< T *> ::type raw_pointer; 
# 228
static raw_pointer get(pointer ptr) 
# 229
{ 
# 230
return ptr; 
# 231
} 
# 232
}; 
# 234
template< class FromPtr, class ToPtr> 
# 235
struct is_pointer_convertible : public and_< is_convertible< typename pointer_element< FromPtr> ::type *, typename pointer_element< ToPtr> ::type *> , is_convertible< typename iterator_system< FromPtr> ::type, typename iterator_system< ToPtr> ::type> >  { 
# 246
}; 
# 250
template< class T> 
# 251
struct is_thrust_pointer : public is_metafunction_defined< pointer_raw_pointer< T> >  { 
# 253
}; 
# 256
template< class FromPtr, class ToPtr> 
# 257
struct lazy_is_pointer_convertible : public eval_if< is_thrust_pointer< FromPtr> ::value && is_thrust_pointer< ToPtr> ::value, is_pointer_convertible< FromPtr, ToPtr> , identity_< integral_constant< bool, false> > >  { 
# 263
}; 
# 265
template< class FromPtr, class ToPtr, class T = void> 
# 266
struct enable_if_pointer_is_convertible : public enable_if< lazy_is_pointer_convertible< FromPtr, ToPtr> ::type::value, T>  { 
# 271
}; 
# 274
}
# 275
}
# 24 "/usr/local/cuda-8.0/include/thrust/iterator/detail/is_trivial_iterator.h"
namespace __gnu_cxx { 
# 27
template< class Iterator, class Container> class __normal_iterator; 
# 29
}
# 42
namespace thrust { 
# 44
namespace detail { 
# 48
template< class T> 
# 49
struct is_gnu_normal_iterator : public false_type { 
# 51
}; 
# 55
template< class Iterator, class Container> 
# 56
struct is_gnu_normal_iterator< __gnu_cxx::__normal_iterator< Iterator, Container> >  : public true_type { 
# 58
}; 
# 79
template< class T> 
# 80
struct is_trivial_iterator : public integral_constant< bool, (is_pointer< T> ::value | is_thrust_pointer< T> ::value) | is_gnu_normal_iterator< T> ::value>  { 
# 92
}; 
# 94
}
# 95
}
# 29 "/usr/local/cuda-8.0/include/thrust/iterator/detail/normal_iterator.h"
namespace thrust { 
# 31
namespace detail { 
# 35
template< class Pointer> 
# 36
class normal_iterator : public iterator_adaptor< normal_iterator< Pointer> , Pointer>  { 
# 42
typedef ::thrust::iterator_adaptor< ::thrust::detail::normal_iterator< Pointer> , Pointer>  super_t; 
# 46
public: normal_iterator() { } 
# 49
normal_iterator(Pointer p) : super_t(p) 
# 50
{ } 
# 52
template< class OtherPointer> 
# 54
normal_iterator(const ::thrust::detail::normal_iterator< OtherPointer>  &other, typename enable_if_convertible< OtherPointer, Pointer> ::type * = 0) : super_t((other.base())) 
# 59
{ } 
# 61
}; 
# 64
template< class Pointer> inline normal_iterator< Pointer>  
# 65
make_normal_iterator(Pointer ptr) 
# 66
{ 
# 67
return ((normal_iterator< Pointer> )(ptr)); 
# 68
} 
# 71
template< class T> struct is_trivial_iterator< normal_iterator< T> >  : public true_type { }; 
# 74
}
# 75
}
# 22 "/usr/local/cuda-8.0/include/thrust/iterator/detail/reverse_iterator_base.h"
namespace thrust { 
# 25
template< class > class reverse_iterator; 
# 27
namespace detail { 
# 30
template< class BidirectionalIterator> 
# 31
struct reverse_iterator_base { 
# 36
typedef iterator_adaptor< reverse_iterator< BidirectionalIterator> , BidirectionalIterator>  type; 
# 37
}; 
# 39
}
# 41
}
# 40 "/usr/local/cuda-8.0/include/thrust/iterator/reverse_iterator.h"
namespace thrust { 
# 144
template< class BidirectionalIterator> 
# 145
class reverse_iterator : public detail::reverse_iterator_base< BidirectionalIterator> ::type { 
# 153
typedef typename ::thrust::detail::reverse_iterator_base< BidirectionalIterator> ::type super_t; 
# 155
friend class iterator_core_access; 
# 163
public: reverse_iterator() { } 
# 171
explicit reverse_iterator(BidirectionalIterator x); 
# 178
template< class OtherBidirectionalIterator> reverse_iterator(const ::thrust::reverse_iterator< OtherBidirectionalIterator>  & r, typename ::thrust::detail::enable_if< ::thrust::detail::is_convertible< OtherBidirectionalIterator, BidirectionalIterator> ::value> ::type * = 0); 
# 198
private: typename ::thrust::detail::reverse_iterator_base< BidirectionalIterator> ::type::reference dereference() const; 
# 201
void increment(); 
# 204
void decrement(); 
# 207
void advance(typename ::thrust::detail::reverse_iterator_base< BidirectionalIterator> ::type::difference_type n); 
# 209
template< class OtherBidirectionalIterator> typename ::thrust::detail::reverse_iterator_base< BidirectionalIterator> ::type::difference_type distance_to(const ::thrust::reverse_iterator< OtherBidirectionalIterator>  & y) const; 
# 215
}; 
# 224
template< class BidirectionalIterator> reverse_iterator< BidirectionalIterator>  make_reverse_iterator(BidirectionalIterator x); 
# 235
}
# 20 "/usr/local/cuda-8.0/include/thrust/iterator/detail/reverse_iterator.inl"
namespace thrust { 
# 23
namespace detail { 
# 27
template< class Iterator> Iterator 
# 29
prior(Iterator x) 
# 30
{ 
# 31
return --x; 
# 32
} 
# 34
}
# 36
template< class BidirectionalIterator> 
# 38
reverse_iterator< BidirectionalIterator> ::reverse_iterator(BidirectionalIterator x) : super_t(x) 
# 40
{ 
# 41
} 
# 43
template< class BidirectionalIterator> 
# 44
template< class OtherBidirectionalIterator> 
# 46
reverse_iterator< BidirectionalIterator> ::reverse_iterator(const ::thrust::reverse_iterator< OtherBidirectionalIterator>  &r, typename ::thrust::detail::enable_if< ::thrust::detail::is_convertible< OtherBidirectionalIterator, BidirectionalIterator> ::value> ::type *) : super_t((r.base())) 
# 58
{ 
# 59
} 
# 61
template< class BidirectionalIterator> typename detail::reverse_iterator_base< BidirectionalIterator> ::type::reference 
# 64
reverse_iterator< BidirectionalIterator> ::dereference() const 
# 65
{ 
# 66
return *::thrust::detail::prior((this->base())); 
# 67
} 
# 69
template< class BidirectionalIterator> void 
# 71
reverse_iterator< BidirectionalIterator> ::increment() 
# 72
{ 
# 73
--(this->base_reference()); 
# 74
} 
# 76
template< class BidirectionalIterator> void 
# 78
reverse_iterator< BidirectionalIterator> ::decrement() 
# 79
{ 
# 80
++(this->base_reference()); 
# 81
} 
# 83
template< class BidirectionalIterator> void 
# 85
reverse_iterator< BidirectionalIterator> ::advance(typename ::thrust::detail::reverse_iterator_base< BidirectionalIterator> ::type::difference_type n) 
# 86
{ 
# 87
(this->base_reference()) += (-n); 
# 88
} 
# 90
template< class BidirectionalIterator> 
# 91
template< class OtherBidirectionalIterator> typename detail::reverse_iterator_base< BidirectionalIterator> ::type::difference_type 
# 94
reverse_iterator< BidirectionalIterator> ::distance_to(const ::thrust::reverse_iterator< OtherBidirectionalIterator>  &y) const 
# 95
{ 
# 96
return (this->base_reference()) - (y.base()); 
# 97
} 
# 99
template< class BidirectionalIterator> reverse_iterator< BidirectionalIterator>  
# 101
make_reverse_iterator(BidirectionalIterator x) 
# 102
{ 
# 103
return ((reverse_iterator< BidirectionalIterator> )(x)); 
# 104
} 
# 107
}
# 25 "/usr/local/cuda-8.0/include/thrust/detail/allocator/allocator_traits.h"
namespace thrust { 
# 27
namespace detail { 
# 32
template< class Alloc> struct allocator_system; 
# 35
namespace allocator_traits_detail { 
# 38
template< class T> struct has_value_type { typedef char yes_type; typedef int no_type; template< class S> static yes_type test(typename S::value_type *); template< class S> static no_type test(...); static const bool value = (sizeof(test< T> (0)) == sizeof(yes_type)); typedef integral_constant< bool, value>  type; }; 
# 39
template< class T> struct has_pointer { typedef char yes_type; typedef int no_type; template< class S> static yes_type test(typename S::pointer *); template< class S> static no_type test(...); static const bool value = (sizeof(test< T> (0)) == sizeof(yes_type)); typedef integral_constant< bool, value>  type; }; 
# 40
template< class T> struct has_const_pointer { typedef char yes_type; typedef int no_type; template< class S> static yes_type test(typename S::const_pointer *); template< class S> static no_type test(...); static const bool value = (sizeof(test< T> (0)) == sizeof(yes_type)); typedef integral_constant< bool, value>  type; }; 
# 41
template< class T> struct has_reference { typedef char yes_type; typedef int no_type; template< class S> static yes_type test(typename S::reference *); template< class S> static no_type test(...); static const bool value = (sizeof(test< T> (0)) == sizeof(yes_type)); typedef integral_constant< bool, value>  type; }; 
# 42
template< class T> struct has_const_reference { typedef char yes_type; typedef int no_type; template< class S> static yes_type test(typename S::const_reference *); template< class S> static no_type test(...); static const bool value = (sizeof(test< T> (0)) == sizeof(yes_type)); typedef integral_constant< bool, value>  type; }; 
# 43
template< class T> struct has_void_pointer { typedef char yes_type; typedef int no_type; template< class S> static yes_type test(typename S::void_pointer *); template< class S> static no_type test(...); static const bool value = (sizeof(test< T> (0)) == sizeof(yes_type)); typedef integral_constant< bool, value>  type; }; 
# 44
template< class T> struct has_const_void_pointer { typedef char yes_type; typedef int no_type; template< class S> static yes_type test(typename S::const_void_pointer *); template< class S> static no_type test(...); static const bool value = (sizeof(test< T> (0)) == sizeof(yes_type)); typedef integral_constant< bool, value>  type; }; 
# 45
template< class T> struct has_difference_type { typedef char yes_type; typedef int no_type; template< class S> static yes_type test(typename S::difference_type *); template< class S> static no_type test(...); static const bool value = (sizeof(test< T> (0)) == sizeof(yes_type)); typedef integral_constant< bool, value>  type; }; 
# 46
template< class T> struct has_size_type { typedef char yes_type; typedef int no_type; template< class S> static yes_type test(typename S::size_type *); template< class S> static no_type test(...); static const bool value = (sizeof(test< T> (0)) == sizeof(yes_type)); typedef integral_constant< bool, value>  type; }; 
# 47
template< class T> struct has_propagate_on_container_copy_assignment { typedef char yes_type; typedef int no_type; template< class S> static yes_type test(typename S::propagate_on_container_copy_assignment *); template< class S> static no_type test(...); static const bool value = (sizeof(test< T> (0)) == sizeof(yes_type)); typedef integral_constant< bool, value>  type; }; 
# 48
template< class T> struct has_propagate_on_container_move_assignment { typedef char yes_type; typedef int no_type; template< class S> static yes_type test(typename S::propagate_on_container_move_assignment *); template< class S> static no_type test(...); static const bool value = (sizeof(test< T> (0)) == sizeof(yes_type)); typedef integral_constant< bool, value>  type; }; 
# 49
template< class T> struct has_propagate_on_container_swap { typedef char yes_type; typedef int no_type; template< class S> static yes_type test(typename S::propagate_on_container_swap *); template< class S> static no_type test(...); static const bool value = (sizeof(test< T> (0)) == sizeof(yes_type)); typedef integral_constant< bool, value>  type; }; 
# 50
template< class T> struct has_system_type { typedef char yes_type; typedef int no_type; template< class S> static yes_type test(typename S::system_type *); template< class S> static no_type test(...); static const bool value = (sizeof(test< T> (0)) == sizeof(yes_type)); typedef integral_constant< bool, value>  type; }; 
# 51
template< class T, class Signature> class has_member_system_impl; template< class T, class Result> class has_member_system_impl< T, Result (void)>  { class yes { char m; }; class no { yes m[2]; }; struct base_mixin { Result system(); }; struct base : public T, public base_mixin { }; template< class U, U t> class helper { }; template< class U> static no deduce(U *, helper< Result (base_mixin::*)(void), &U::system>  * = 0); static yes deduce(...); public: static const bool value = (sizeof(yes) == sizeof(deduce(static_cast< base *>(0)))); typedef integral_constant< bool, value>  type; }; template< class T, class Result, class Arg> class has_member_system_impl< T, Result (Arg)>  { class yes { char m; }; class no { yes m[2]; }; struct base_mixin { Result system(Arg); }; struct base : public T, public base_mixin { }; template< class U, U t> class helper { }; template< class U> static no deduce(U *, helper< Result (base_mixin::*)(Arg), &U::system>  * = 0); static yes deduce(...); public: static const bool value = (sizeof(yes) == sizeof(deduce(static_cast< base *>(0)))); typedef integral_constant< bool, value>  type; }; template< class T, class Result, class Arg1, class Arg2> class has_member_system_impl< T, Result (Arg1, Arg2)>  { class yes { char m; }; class no { yes m[2]; }; struct base_mixin { Result system(Arg1, Arg2); }; struct base : public T, public base_mixin { }; template< class U, U t> class helper { }; template< class U> static no deduce(U *, helper< Result (base_mixin::*)(Arg1, Arg2), &U::system>  * = 0); static yes deduce(...); public: static const bool value = (sizeof(yes) == sizeof(deduce(static_cast< base *>(0)))); typedef integral_constant< bool, value>  type; }; template< class T, class Result, class Arg1, class Arg2, class Arg3> class has_member_system_impl< T, Result (Arg1, Arg2, Arg3)>  { class yes { char m; }; class no { yes m[2]; }; struct base_mixin { Result system(Arg1, Arg2, Arg3); }; struct base : public T, public base_mixin { }; template< class U, U t> class helper { }; template< class U> static no deduce(U *, helper< Result (base_mixin::*)(Arg1, Arg2, Arg3), &U::system>  * = 0); static yes deduce(...); public: static const bool value = (sizeof(yes) == sizeof(deduce(static_cast< base *>(0)))); typedef integral_constant< bool, value>  type; }; template< class T, class Result, class Arg1, class Arg2, class Arg3, class Arg4> class has_member_system_impl< T, Result (Arg1, Arg2, Arg3, Arg4)>  { class yes { char m; }; class no { yes m[2]; }; struct base_mixin { Result system(Arg1, Arg2, Arg3, Arg4); }; struct base : public T, public base_mixin { }; template< class U, U t> class helper { }; template< class U> static no deduce(U *, helper< Result (base_mixin::*)(Arg1, Arg2, Arg3, Arg4), &U::system>  * = 0); static yes deduce(...); public: static const bool value = (sizeof(yes) == sizeof(deduce(static_cast< base *>(0)))); typedef integral_constant< bool, value>  type; }; 
# 54
template< class T> 
# 55
struct nested_pointer { 
# 57
typedef typename T::pointer type; 
# 58
}; 
# 60
template< class T> 
# 61
struct nested_const_pointer { 
# 63
typedef typename T::const_pointer type; 
# 64
}; 
# 66
template< class T> 
# 67
struct nested_reference { 
# 69
typedef typename T::reference type; 
# 70
}; 
# 72
template< class T> 
# 73
struct nested_const_reference { 
# 75
typedef typename T::const_reference type; 
# 76
}; 
# 78
template< class T> 
# 79
struct nested_void_pointer { 
# 81
typedef typename T::void_pointer type; 
# 82
}; 
# 84
template< class T> 
# 85
struct nested_const_void_pointer { 
# 87
typedef typename T::const_void_pointer type; 
# 88
}; 
# 90
template< class T> 
# 91
struct nested_difference_type { 
# 93
typedef typename T::difference_type type; 
# 94
}; 
# 96
template< class T> 
# 97
struct nested_size_type { 
# 99
typedef typename T::size_type type; 
# 100
}; 
# 102
template< class T> 
# 103
struct nested_propagate_on_container_copy_assignment { 
# 105
typedef typename T::propagate_on_container_copy_assignment type; 
# 106
}; 
# 108
template< class T> 
# 109
struct nested_propagate_on_container_move_assignment { 
# 111
typedef typename T::propagate_on_container_move_assignment type; 
# 112
}; 
# 114
template< class T> 
# 115
struct nested_propagate_on_container_swap { 
# 117
typedef typename T::propagate_on_container_swap type; 
# 118
}; 
# 120
template< class T> 
# 121
struct nested_system_type { 
# 123
typedef typename T::system_type type; 
# 124
}; 
# 126
template< class Alloc> 
# 127
class has_member_system { 
# 129
typedef typename allocator_system< Alloc> ::type system_type; 
# 132
public: typedef typename has_member_system_impl< Alloc, typename allocator_system< Alloc> ::type &(void)> ::type type; 
# 133
static const bool value = (type::value); 
# 134
}; 
# 137
}
# 140
template< class Alloc> 
# 141
struct allocator_traits { 
# 143
typedef Alloc allocator_type; 
# 145
typedef typename Alloc::value_type value_type; 
# 151
typedef typename eval_if< allocator_traits_detail::has_pointer< Alloc> ::value, allocator_traits_detail::nested_pointer< Alloc> , identity_< typename Alloc::value_type *> > ::type pointer; 
# 155
private: 
# 154
template< class T> 
# 155
struct rebind_pointer { 
# 157
typedef typename pointer_traits< typename eval_if< allocator_traits_detail::has_pointer< Alloc> ::value, allocator_traits_detail::nested_pointer< Alloc> , identity_< typename Alloc::value_type *> > ::type> ::template rebind< T> ::other type; 
# 158
}; 
# 166
public: typedef typename eval_if< allocator_traits_detail::has_const_pointer< Alloc> ::value, allocator_traits_detail::nested_const_pointer< Alloc> , rebind_pointer< const typename Alloc::value_type> > ::type const_pointer; 
# 172
typedef typename eval_if< allocator_traits_detail::has_void_pointer< Alloc> ::value, allocator_traits_detail::nested_void_pointer< Alloc> , rebind_pointer< void> > ::type void_pointer; 
# 178
typedef typename eval_if< allocator_traits_detail::has_const_void_pointer< Alloc> ::value, allocator_traits_detail::nested_const_void_pointer< Alloc> , rebind_pointer< const void> > ::type const_void_pointer; 
# 184
typedef typename eval_if< allocator_traits_detail::has_difference_type< Alloc> ::value, allocator_traits_detail::nested_difference_type< Alloc> , pointer_difference< typename eval_if< allocator_traits_detail::has_pointer< Alloc> ::value, allocator_traits_detail::nested_pointer< Alloc> , identity_< typename Alloc::value_type *> > ::type> > ::type difference_type; 
# 190
typedef typename eval_if< allocator_traits_detail::has_size_type< Alloc> ::value, allocator_traits_detail::nested_size_type< Alloc> , make_unsigned< typename eval_if< allocator_traits_detail::has_difference_type< Alloc> ::value, allocator_traits_detail::nested_difference_type< Alloc> , pointer_difference< typename eval_if< allocator_traits_detail::has_pointer< Alloc> ::value, allocator_traits_detail::nested_pointer< Alloc> , identity_< typename Alloc::value_type *> > ::type> > ::type> > ::type size_type; 
# 196
typedef typename eval_if< allocator_traits_detail::has_propagate_on_container_copy_assignment< Alloc> ::value, allocator_traits_detail::nested_propagate_on_container_copy_assignment< Alloc> , identity_< integral_constant< bool, false> > > ::type propagate_on_container_copy_assignment; 
# 202
typedef typename eval_if< allocator_traits_detail::has_propagate_on_container_move_assignment< Alloc> ::value, allocator_traits_detail::nested_propagate_on_container_move_assignment< Alloc> , identity_< integral_constant< bool, false> > > ::type propagate_on_container_move_assignment; 
# 208
typedef typename eval_if< allocator_traits_detail::has_propagate_on_container_swap< Alloc> ::value, allocator_traits_detail::nested_propagate_on_container_swap< Alloc> , identity_< integral_constant< bool, false> > > ::type propagate_on_container_swap; 
# 214
typedef typename eval_if< allocator_traits_detail::has_system_type< Alloc> ::value, allocator_traits_detail::nested_system_type< Alloc> , iterator_system< typename eval_if< allocator_traits_detail::has_pointer< Alloc> ::value, allocator_traits_detail::nested_pointer< Alloc> , identity_< typename Alloc::value_type *> > ::type> > ::type system_type; 
# 220
static inline pointer allocate(allocator_type & a, size_type n); 
# 223
static inline pointer allocate(allocator_type & a, size_type n, const_void_pointer hint); 
# 226
static inline void deallocate(allocator_type & a, pointer p, size_type n); 
# 230
template< class T> static inline void construct(allocator_type & a, T * p); 
# 233
template< class T, class Arg1> static inline void construct(allocator_type & a, T * p, const Arg1 & arg1); 
# 236
template< class T> static inline void destroy(allocator_type & a, T * p); 
# 240
static inline size_type max_size(const allocator_type & a); 
# 241
}; 
# 247
template< class T> 
# 248
struct is_allocator : public allocator_traits_detail::has_value_type< T>  { 
# 250
}; 
# 254
template< class Alloc> 
# 255
struct allocator_system { 
# 264
typedef typename eval_if< allocator_traits_detail::has_system_type< Alloc> ::value, allocator_traits_detail::nested_system_type< Alloc> , iterator_system< typename allocator_traits< Alloc> ::pointer> > ::type type; 
# 271
typedef typename eval_if< allocator_traits_detail::has_member_system< Alloc> ::value, add_reference< typename eval_if< allocator_traits_detail::has_system_type< Alloc> ::value, allocator_traits_detail::nested_system_type< Alloc> , iterator_system< typename allocator_traits< Alloc> ::pointer> > ::type> , identity_< typename eval_if< allocator_traits_detail::has_system_type< Alloc> ::value, allocator_traits_detail::nested_system_type< Alloc> , iterator_system< typename allocator_traits< Alloc> ::pointer> > ::type> > ::type get_result_type; 
# 274
static inline get_result_type get(Alloc & a); 
# 275
}; 
# 278
}
# 279
}
# 25 "/usr/local/cuda-8.0/include/thrust/detail/type_traits/is_call_possible.h"
namespace thrust { 
# 27
namespace detail { 
# 29
namespace is_call_possible_detail { 
# 32
template< class T> class void_exp_result { }; 
# 34
template< class T, class U> const U &operator,(const U &, void_exp_result< T> ); 
# 37
template< class T, class U> U &operator,(U &, void_exp_result< T> ); 
# 40
template< class src_type, class dest_type> 
# 41
struct clone_constness { 
# 43
typedef dest_type type; 
# 44
}; 
# 46
template< class src_type, class dest_type> 
# 47
struct clone_constness< const src_type, dest_type>  { 
# 49
typedef const dest_type type; 
# 50
}; 
# 52
}
# 53
}
# 54
}
# 147 "/usr/include/c++/4.8.2/limits" 3
namespace std __attribute((__visibility__("default"))) { 
# 156
enum float_round_style { 
# 158
round_indeterminate = (-1), 
# 159
round_toward_zero = 0, 
# 160
round_to_nearest, 
# 161
round_toward_infinity, 
# 162
round_toward_neg_infinity
# 163
}; 
# 171
enum float_denorm_style { 
# 174
denorm_indeterminate = (-1), 
# 176
denorm_absent = 0, 
# 178
denorm_present
# 179
}; 
# 191
struct __numeric_limits_base { 
# 195
static const bool is_specialized = false; 
# 200
static const int digits = 0; 
# 203
static const int digits10 = 0; 
# 212
static const bool is_signed = false; 
# 215
static const bool is_integer = false; 
# 220
static const bool is_exact = false; 
# 224
static const int radix = 0; 
# 228
static const int min_exponent = 0; 
# 232
static const int min_exponent10 = 0; 
# 237
static const int max_exponent = 0; 
# 241
static const int max_exponent10 = 0; 
# 244
static const bool has_infinity = false; 
# 248
static const bool has_quiet_NaN = false; 
# 252
static const bool has_signaling_NaN = false; 
# 255
static const float_denorm_style has_denorm = denorm_absent; 
# 259
static const bool has_denorm_loss = false; 
# 263
static const bool is_iec559 = false; 
# 268
static const bool is_bounded = false; 
# 277
static const bool is_modulo = false; 
# 280
static const bool traps = false; 
# 283
static const bool tinyness_before = false; 
# 288
static const float_round_style round_style = round_toward_zero; 
# 290
}; 
# 303
template< class _Tp> 
# 304
struct numeric_limits : public __numeric_limits_base { 
# 309
static _Tp min() throw() { return _Tp(); } 
# 313
static _Tp max() throw() { return _Tp(); } 
# 325
static _Tp epsilon() throw() { return _Tp(); } 
# 329
static _Tp round_error() throw() { return _Tp(); } 
# 333
static _Tp infinity() throw() { return _Tp(); } 
# 338
static _Tp quiet_NaN() throw() { return _Tp(); } 
# 343
static _Tp signaling_NaN() throw() { return _Tp(); } 
# 349
static _Tp denorm_min() throw() { return _Tp(); } 
# 350
}; 
# 371
template<> struct numeric_limits< bool>  { 
# 373
static const bool is_specialized = true; 
# 376
static bool min() throw() { return false; } 
# 379
static bool max() throw() { return true; } 
# 385
static const int digits = 1; 
# 386
static const int digits10 = 0; 
# 390
static const bool is_signed = false; 
# 391
static const bool is_integer = true; 
# 392
static const bool is_exact = true; 
# 393
static const int radix = 2; 
# 396
static bool epsilon() throw() { return false; } 
# 399
static bool round_error() throw() { return false; } 
# 401
static const int min_exponent = 0; 
# 402
static const int min_exponent10 = 0; 
# 403
static const int max_exponent = 0; 
# 404
static const int max_exponent10 = 0; 
# 406
static const bool has_infinity = false; 
# 407
static const bool has_quiet_NaN = false; 
# 408
static const bool has_signaling_NaN = false; 
# 409
static const float_denorm_style has_denorm = denorm_absent; 
# 411
static const bool has_denorm_loss = false; 
# 414
static bool infinity() throw() { return false; } 
# 417
static bool quiet_NaN() throw() { return false; } 
# 420
static bool signaling_NaN() throw() { return false; } 
# 423
static bool denorm_min() throw() { return false; } 
# 425
static const bool is_iec559 = false; 
# 426
static const bool is_bounded = true; 
# 427
static const bool is_modulo = false; 
# 432
static const bool traps = false; 
# 433
static const bool tinyness_before = false; 
# 434
static const float_round_style round_style = round_toward_zero; 
# 436
}; 
# 440
template<> struct numeric_limits< char>  { 
# 442
static const bool is_specialized = true; 
# 445
static char min() throw() { return (((char)(-1)) < 0) ? (-((((char)(-1)) < 0) ? (((((char)1) << (((sizeof(char) * (8)) - (((char)(-1)) < 0)) - (1))) - 1) << 1) + 1 : (~((char)0)))) - 1 : ((char)0); } 
# 448
static char max() throw() { return (((char)(-1)) < 0) ? (((((char)1) << (((sizeof(char) * (8)) - (((char)(-1)) < 0)) - (1))) - 1) << 1) + 1 : (~((char)0)); } 
# 455
static const int digits = ((sizeof(char) * (8)) - (((char)(-1)) < 0)); 
# 456
static const int digits10 = ((((sizeof(char) * (8)) - (((char)(-1)) < 0)) * (643L)) / (2136)); 
# 460
static const bool is_signed = (((char)(-1)) < 0); 
# 461
static const bool is_integer = true; 
# 462
static const bool is_exact = true; 
# 463
static const int radix = 2; 
# 466
static char epsilon() throw() { return 0; } 
# 469
static char round_error() throw() { return 0; } 
# 471
static const int min_exponent = 0; 
# 472
static const int min_exponent10 = 0; 
# 473
static const int max_exponent = 0; 
# 474
static const int max_exponent10 = 0; 
# 476
static const bool has_infinity = false; 
# 477
static const bool has_quiet_NaN = false; 
# 478
static const bool has_signaling_NaN = false; 
# 479
static const float_denorm_style has_denorm = denorm_absent; 
# 481
static const bool has_denorm_loss = false; 
# 484
static char infinity() throw() { return ((char)0); } 
# 487
static char quiet_NaN() throw() { return ((char)0); } 
# 490
static char signaling_NaN() throw() { return ((char)0); } 
# 493
static char denorm_min() throw() { return static_cast< char>(0); } 
# 495
static const bool is_iec559 = false; 
# 496
static const bool is_bounded = true; 
# 497
static const bool is_modulo = (!is_signed); 
# 499
static const bool traps = false; 
# 500
static const bool tinyness_before = false; 
# 501
static const float_round_style round_style = round_toward_zero; 
# 503
}; 
# 507
template<> struct numeric_limits< signed char>  { 
# 509
static const bool is_specialized = true; 
# 512
static signed char min() throw() { return (-127) - 1; } 
# 515
static signed char max() throw() { return 127; } 
# 522
static const int digits = ((sizeof(signed char) * (8)) - (((signed char)(-1)) < 0)); 
# 523
static const int digits10 = ((((sizeof(signed char) * (8)) - (((signed char)(-1)) < 0)) * (643L)) / (2136)); 
# 528
static const bool is_signed = true; 
# 529
static const bool is_integer = true; 
# 530
static const bool is_exact = true; 
# 531
static const int radix = 2; 
# 534
static signed char epsilon() throw() { return 0; } 
# 537
static signed char round_error() throw() { return 0; } 
# 539
static const int min_exponent = 0; 
# 540
static const int min_exponent10 = 0; 
# 541
static const int max_exponent = 0; 
# 542
static const int max_exponent10 = 0; 
# 544
static const bool has_infinity = false; 
# 545
static const bool has_quiet_NaN = false; 
# 546
static const bool has_signaling_NaN = false; 
# 547
static const float_denorm_style has_denorm = denorm_absent; 
# 549
static const bool has_denorm_loss = false; 
# 552
static signed char infinity() throw() { return static_cast< signed char>(0); } 
# 555
static signed char quiet_NaN() throw() { return static_cast< signed char>(0); } 
# 558
static signed char signaling_NaN() throw() 
# 559
{ return static_cast< signed char>(0); } 
# 562
static signed char denorm_min() throw() 
# 563
{ return static_cast< signed char>(0); } 
# 565
static const bool is_iec559 = false; 
# 566
static const bool is_bounded = true; 
# 567
static const bool is_modulo = false; 
# 569
static const bool traps = false; 
# 570
static const bool tinyness_before = false; 
# 571
static const float_round_style round_style = round_toward_zero; 
# 573
}; 
# 577
template<> struct numeric_limits< unsigned char>  { 
# 579
static const bool is_specialized = true; 
# 582
static unsigned char min() throw() { return 0; } 
# 585
static unsigned char max() throw() { return ((127) * 2U) + (1); } 
# 592
static const int digits = ((sizeof(unsigned char) * (8)) - (((unsigned char)(-1)) < 0)); 
# 594
static const int digits10 = ((((sizeof(unsigned char) * (8)) - (((unsigned char)(-1)) < 0)) * (643L)) / (2136)); 
# 599
static const bool is_signed = false; 
# 600
static const bool is_integer = true; 
# 601
static const bool is_exact = true; 
# 602
static const int radix = 2; 
# 605
static unsigned char epsilon() throw() { return 0; } 
# 608
static unsigned char round_error() throw() { return 0; } 
# 610
static const int min_exponent = 0; 
# 611
static const int min_exponent10 = 0; 
# 612
static const int max_exponent = 0; 
# 613
static const int max_exponent10 = 0; 
# 615
static const bool has_infinity = false; 
# 616
static const bool has_quiet_NaN = false; 
# 617
static const bool has_signaling_NaN = false; 
# 618
static const float_denorm_style has_denorm = denorm_absent; 
# 620
static const bool has_denorm_loss = false; 
# 623
static unsigned char infinity() throw() 
# 624
{ return static_cast< unsigned char>(0); } 
# 627
static unsigned char quiet_NaN() throw() 
# 628
{ return static_cast< unsigned char>(0); } 
# 631
static unsigned char signaling_NaN() throw() 
# 632
{ return static_cast< unsigned char>(0); } 
# 635
static unsigned char denorm_min() throw() 
# 636
{ return static_cast< unsigned char>(0); } 
# 638
static const bool is_iec559 = false; 
# 639
static const bool is_bounded = true; 
# 640
static const bool is_modulo = true; 
# 642
static const bool traps = false; 
# 643
static const bool tinyness_before = false; 
# 644
static const float_round_style round_style = round_toward_zero; 
# 646
}; 
# 650
template<> struct numeric_limits< wchar_t>  { 
# 652
static const bool is_specialized = true; 
# 655
static wchar_t min() throw() { return (((wchar_t)(-1)) < 0) ? (-((((wchar_t)(-1)) < 0) ? (((((wchar_t)1) << (((sizeof(wchar_t) * (8)) - (((wchar_t)(-1)) < 0)) - (1))) - 1) << 1) + 1 : (~((wchar_t)0)))) - 1 : ((wchar_t)0); } 
# 658
static wchar_t max() throw() { return (((wchar_t)(-1)) < 0) ? (((((wchar_t)1) << (((sizeof(wchar_t) * (8)) - (((wchar_t)(-1)) < 0)) - (1))) - 1) << 1) + 1 : (~((wchar_t)0)); } 
# 665
static const int digits = ((sizeof(wchar_t) * (8)) - (((wchar_t)(-1)) < 0)); 
# 666
static const int digits10 = ((((sizeof(wchar_t) * (8)) - (((wchar_t)(-1)) < 0)) * (643L)) / (2136)); 
# 671
static const bool is_signed = (((wchar_t)(-1)) < 0); 
# 672
static const bool is_integer = true; 
# 673
static const bool is_exact = true; 
# 674
static const int radix = 2; 
# 677
static wchar_t epsilon() throw() { return 0; } 
# 680
static wchar_t round_error() throw() { return 0; } 
# 682
static const int min_exponent = 0; 
# 683
static const int min_exponent10 = 0; 
# 684
static const int max_exponent = 0; 
# 685
static const int max_exponent10 = 0; 
# 687
static const bool has_infinity = false; 
# 688
static const bool has_quiet_NaN = false; 
# 689
static const bool has_signaling_NaN = false; 
# 690
static const float_denorm_style has_denorm = denorm_absent; 
# 692
static const bool has_denorm_loss = false; 
# 695
static wchar_t infinity() throw() { return ((wchar_t)0); } 
# 698
static wchar_t quiet_NaN() throw() { return ((wchar_t)0); } 
# 701
static wchar_t signaling_NaN() throw() { return ((wchar_t)0); } 
# 704
static wchar_t denorm_min() throw() { return ((wchar_t)0); } 
# 706
static const bool is_iec559 = false; 
# 707
static const bool is_bounded = true; 
# 708
static const bool is_modulo = (!is_signed); 
# 710
static const bool traps = false; 
# 711
static const bool tinyness_before = false; 
# 712
static const float_round_style round_style = round_toward_zero; 
# 714
}; 
# 842
template<> struct numeric_limits< short>  { 
# 844
static const bool is_specialized = true; 
# 847
static short min() throw() { return (-32767) - 1; } 
# 850
static short max() throw() { return 32767; } 
# 857
static const int digits = ((sizeof(short) * (8)) - (((short)(-1)) < 0)); 
# 858
static const int digits10 = ((((sizeof(short) * (8)) - (((short)(-1)) < 0)) * (643L)) / (2136)); 
# 862
static const bool is_signed = true; 
# 863
static const bool is_integer = true; 
# 864
static const bool is_exact = true; 
# 865
static const int radix = 2; 
# 868
static short epsilon() throw() { return 0; } 
# 871
static short round_error() throw() { return 0; } 
# 873
static const int min_exponent = 0; 
# 874
static const int min_exponent10 = 0; 
# 875
static const int max_exponent = 0; 
# 876
static const int max_exponent10 = 0; 
# 878
static const bool has_infinity = false; 
# 879
static const bool has_quiet_NaN = false; 
# 880
static const bool has_signaling_NaN = false; 
# 881
static const float_denorm_style has_denorm = denorm_absent; 
# 883
static const bool has_denorm_loss = false; 
# 886
static short infinity() throw() { return ((short)0); } 
# 889
static short quiet_NaN() throw() { return ((short)0); } 
# 892
static short signaling_NaN() throw() { return ((short)0); } 
# 895
static short denorm_min() throw() { return ((short)0); } 
# 897
static const bool is_iec559 = false; 
# 898
static const bool is_bounded = true; 
# 899
static const bool is_modulo = false; 
# 901
static const bool traps = false; 
# 902
static const bool tinyness_before = false; 
# 903
static const float_round_style round_style = round_toward_zero; 
# 905
}; 
# 909
template<> struct numeric_limits< unsigned short>  { 
# 911
static const bool is_specialized = true; 
# 914
static unsigned short min() throw() { return 0; } 
# 917
static unsigned short max() throw() { return ((32767) * 2U) + (1); } 
# 924
static const int digits = ((sizeof(unsigned short) * (8)) - (((unsigned short)(-1)) < 0)); 
# 926
static const int digits10 = ((((sizeof(unsigned short) * (8)) - (((unsigned short)(-1)) < 0)) * (643L)) / (2136)); 
# 931
static const bool is_signed = false; 
# 932
static const bool is_integer = true; 
# 933
static const bool is_exact = true; 
# 934
static const int radix = 2; 
# 937
static unsigned short epsilon() throw() { return 0; } 
# 940
static unsigned short round_error() throw() { return 0; } 
# 942
static const int min_exponent = 0; 
# 943
static const int min_exponent10 = 0; 
# 944
static const int max_exponent = 0; 
# 945
static const int max_exponent10 = 0; 
# 947
static const bool has_infinity = false; 
# 948
static const bool has_quiet_NaN = false; 
# 949
static const bool has_signaling_NaN = false; 
# 950
static const float_denorm_style has_denorm = denorm_absent; 
# 952
static const bool has_denorm_loss = false; 
# 955
static unsigned short infinity() throw() 
# 956
{ return static_cast< unsigned short>(0); } 
# 959
static unsigned short quiet_NaN() throw() 
# 960
{ return static_cast< unsigned short>(0); } 
# 963
static unsigned short signaling_NaN() throw() 
# 964
{ return static_cast< unsigned short>(0); } 
# 967
static unsigned short denorm_min() throw() 
# 968
{ return static_cast< unsigned short>(0); } 
# 970
static const bool is_iec559 = false; 
# 971
static const bool is_bounded = true; 
# 972
static const bool is_modulo = true; 
# 974
static const bool traps = false; 
# 975
static const bool tinyness_before = false; 
# 976
static const float_round_style round_style = round_toward_zero; 
# 978
}; 
# 982
template<> struct numeric_limits< int>  { 
# 984
static const bool is_specialized = true; 
# 987
static int min() throw() { return (-2147483647) - 1; } 
# 990
static int max() throw() { return 2147483647; } 
# 997
static const int digits = ((sizeof(int) * (8)) - (((int)(-1)) < 0)); 
# 998
static const int digits10 = ((((sizeof(int) * (8)) - (((int)(-1)) < 0)) * (643L)) / (2136)); 
# 1002
static const bool is_signed = true; 
# 1003
static const bool is_integer = true; 
# 1004
static const bool is_exact = true; 
# 1005
static const int radix = 2; 
# 1008
static int epsilon() throw() { return 0; } 
# 1011
static int round_error() throw() { return 0; } 
# 1013
static const int min_exponent = 0; 
# 1014
static const int min_exponent10 = 0; 
# 1015
static const int max_exponent = 0; 
# 1016
static const int max_exponent10 = 0; 
# 1018
static const bool has_infinity = false; 
# 1019
static const bool has_quiet_NaN = false; 
# 1020
static const bool has_signaling_NaN = false; 
# 1021
static const float_denorm_style has_denorm = denorm_absent; 
# 1023
static const bool has_denorm_loss = false; 
# 1026
static int infinity() throw() { return static_cast< int>(0); } 
# 1029
static int quiet_NaN() throw() { return static_cast< int>(0); } 
# 1032
static int signaling_NaN() throw() { return static_cast< int>(0); } 
# 1035
static int denorm_min() throw() { return static_cast< int>(0); } 
# 1037
static const bool is_iec559 = false; 
# 1038
static const bool is_bounded = true; 
# 1039
static const bool is_modulo = false; 
# 1041
static const bool traps = false; 
# 1042
static const bool tinyness_before = false; 
# 1043
static const float_round_style round_style = round_toward_zero; 
# 1045
}; 
# 1049
template<> struct numeric_limits< unsigned>  { 
# 1051
static const bool is_specialized = true; 
# 1054
static unsigned min() throw() { return 0; } 
# 1057
static unsigned max() throw() { return ((2147483647) * 2U) + (1); } 
# 1064
static const int digits = ((sizeof(unsigned) * (8)) - (((unsigned)(-1)) < (0))); 
# 1066
static const int digits10 = ((((sizeof(unsigned) * (8)) - (((unsigned)(-1)) < (0))) * (643L)) / (2136)); 
# 1071
static const bool is_signed = false; 
# 1072
static const bool is_integer = true; 
# 1073
static const bool is_exact = true; 
# 1074
static const int radix = 2; 
# 1077
static unsigned epsilon() throw() { return 0; } 
# 1080
static unsigned round_error() throw() { return 0; } 
# 1082
static const int min_exponent = 0; 
# 1083
static const int min_exponent10 = 0; 
# 1084
static const int max_exponent = 0; 
# 1085
static const int max_exponent10 = 0; 
# 1087
static const bool has_infinity = false; 
# 1088
static const bool has_quiet_NaN = false; 
# 1089
static const bool has_signaling_NaN = false; 
# 1090
static const float_denorm_style has_denorm = denorm_absent; 
# 1092
static const bool has_denorm_loss = false; 
# 1095
static unsigned infinity() throw() { return static_cast< unsigned>(0); } 
# 1098
static unsigned quiet_NaN() throw() 
# 1099
{ return static_cast< unsigned>(0); } 
# 1102
static unsigned signaling_NaN() throw() 
# 1103
{ return static_cast< unsigned>(0); } 
# 1106
static unsigned denorm_min() throw() 
# 1107
{ return static_cast< unsigned>(0); } 
# 1109
static const bool is_iec559 = false; 
# 1110
static const bool is_bounded = true; 
# 1111
static const bool is_modulo = true; 
# 1113
static const bool traps = false; 
# 1114
static const bool tinyness_before = false; 
# 1115
static const float_round_style round_style = round_toward_zero; 
# 1117
}; 
# 1121
template<> struct numeric_limits< long>  { 
# 1123
static const bool is_specialized = true; 
# 1126
static long min() throw() { return (-9223372036854775807L) - (1); } 
# 1129
static long max() throw() { return 9223372036854775807L; } 
# 1136
static const int digits = ((sizeof(long) * (8)) - (((long)(-1)) < (0))); 
# 1137
static const int digits10 = ((((sizeof(long) * (8)) - (((long)(-1)) < (0))) * (643L)) / (2136)); 
# 1141
static const bool is_signed = true; 
# 1142
static const bool is_integer = true; 
# 1143
static const bool is_exact = true; 
# 1144
static const int radix = 2; 
# 1147
static long epsilon() throw() { return 0; } 
# 1150
static long round_error() throw() { return 0; } 
# 1152
static const int min_exponent = 0; 
# 1153
static const int min_exponent10 = 0; 
# 1154
static const int max_exponent = 0; 
# 1155
static const int max_exponent10 = 0; 
# 1157
static const bool has_infinity = false; 
# 1158
static const bool has_quiet_NaN = false; 
# 1159
static const bool has_signaling_NaN = false; 
# 1160
static const float_denorm_style has_denorm = denorm_absent; 
# 1162
static const bool has_denorm_loss = false; 
# 1165
static long infinity() throw() { return static_cast< long>(0); } 
# 1168
static long quiet_NaN() throw() { return static_cast< long>(0); } 
# 1171
static long signaling_NaN() throw() { return static_cast< long>(0); } 
# 1174
static long denorm_min() throw() { return static_cast< long>(0); } 
# 1176
static const bool is_iec559 = false; 
# 1177
static const bool is_bounded = true; 
# 1178
static const bool is_modulo = false; 
# 1180
static const bool traps = false; 
# 1181
static const bool tinyness_before = false; 
# 1182
static const float_round_style round_style = round_toward_zero; 
# 1184
}; 
# 1188
template<> struct numeric_limits< unsigned long>  { 
# 1190
static const bool is_specialized = true; 
# 1193
static unsigned long min() throw() { return 0; } 
# 1196
static unsigned long max() throw() { return ((9223372036854775807L) * 2UL) + (1); } 
# 1203
static const int digits = ((sizeof(unsigned long) * (8)) - (((unsigned long)(-1)) < (0))); 
# 1205
static const int digits10 = ((((sizeof(unsigned long) * (8)) - (((unsigned long)(-1)) < (0))) * (643L)) / (2136)); 
# 1210
static const bool is_signed = false; 
# 1211
static const bool is_integer = true; 
# 1212
static const bool is_exact = true; 
# 1213
static const int radix = 2; 
# 1216
static unsigned long epsilon() throw() { return 0; } 
# 1219
static unsigned long round_error() throw() { return 0; } 
# 1221
static const int min_exponent = 0; 
# 1222
static const int min_exponent10 = 0; 
# 1223
static const int max_exponent = 0; 
# 1224
static const int max_exponent10 = 0; 
# 1226
static const bool has_infinity = false; 
# 1227
static const bool has_quiet_NaN = false; 
# 1228
static const bool has_signaling_NaN = false; 
# 1229
static const float_denorm_style has_denorm = denorm_absent; 
# 1231
static const bool has_denorm_loss = false; 
# 1234
static unsigned long infinity() throw() 
# 1235
{ return static_cast< unsigned long>(0); } 
# 1238
static unsigned long quiet_NaN() throw() 
# 1239
{ return static_cast< unsigned long>(0); } 
# 1242
static unsigned long signaling_NaN() throw() 
# 1243
{ return static_cast< unsigned long>(0); } 
# 1246
static unsigned long denorm_min() throw() 
# 1247
{ return static_cast< unsigned long>(0); } 
# 1249
static const bool is_iec559 = false; 
# 1250
static const bool is_bounded = true; 
# 1251
static const bool is_modulo = true; 
# 1253
static const bool traps = false; 
# 1254
static const bool tinyness_before = false; 
# 1255
static const float_round_style round_style = round_toward_zero; 
# 1257
}; 
# 1261
template<> struct numeric_limits< long long>  { 
# 1263
static const bool is_specialized = true; 
# 1266
static long long min() throw() { return (-9223372036854775807LL) - (1); } 
# 1269
static long long max() throw() { return 9223372036854775807LL; } 
# 1276
static const int digits = ((sizeof(long long) * (8)) - (((long long)(-1)) < (0))); 
# 1278
static const int digits10 = ((((sizeof(long long) * (8)) - (((long long)(-1)) < (0))) * (643L)) / (2136)); 
# 1283
static const bool is_signed = true; 
# 1284
static const bool is_integer = true; 
# 1285
static const bool is_exact = true; 
# 1286
static const int radix = 2; 
# 1289
static long long epsilon() throw() { return 0; } 
# 1292
static long long round_error() throw() { return 0; } 
# 1294
static const int min_exponent = 0; 
# 1295
static const int min_exponent10 = 0; 
# 1296
static const int max_exponent = 0; 
# 1297
static const int max_exponent10 = 0; 
# 1299
static const bool has_infinity = false; 
# 1300
static const bool has_quiet_NaN = false; 
# 1301
static const bool has_signaling_NaN = false; 
# 1302
static const float_denorm_style has_denorm = denorm_absent; 
# 1304
static const bool has_denorm_loss = false; 
# 1307
static long long infinity() throw() { return static_cast< long long>(0); } 
# 1310
static long long quiet_NaN() throw() { return static_cast< long long>(0); } 
# 1313
static long long signaling_NaN() throw() 
# 1314
{ return static_cast< long long>(0); } 
# 1317
static long long denorm_min() throw() { return static_cast< long long>(0); } 
# 1319
static const bool is_iec559 = false; 
# 1320
static const bool is_bounded = true; 
# 1321
static const bool is_modulo = false; 
# 1323
static const bool traps = false; 
# 1324
static const bool tinyness_before = false; 
# 1325
static const float_round_style round_style = round_toward_zero; 
# 1327
}; 
# 1331
template<> struct numeric_limits< unsigned long long>  { 
# 1333
static const bool is_specialized = true; 
# 1336
static unsigned long long min() throw() { return 0; } 
# 1339
static unsigned long long max() throw() { return ((9223372036854775807LL) * 2ULL) + (1); } 
# 1346
static const int digits = ((sizeof(unsigned long long) * (8)) - (((unsigned long long)(-1)) < (0))); 
# 1348
static const int digits10 = ((((sizeof(unsigned long long) * (8)) - (((unsigned long long)(-1)) < (0))) * (643L)) / (2136)); 
# 1353
static const bool is_signed = false; 
# 1354
static const bool is_integer = true; 
# 1355
static const bool is_exact = true; 
# 1356
static const int radix = 2; 
# 1359
static unsigned long long epsilon() throw() { return 0; } 
# 1362
static unsigned long long round_error() throw() { return 0; } 
# 1364
static const int min_exponent = 0; 
# 1365
static const int min_exponent10 = 0; 
# 1366
static const int max_exponent = 0; 
# 1367
static const int max_exponent10 = 0; 
# 1369
static const bool has_infinity = false; 
# 1370
static const bool has_quiet_NaN = false; 
# 1371
static const bool has_signaling_NaN = false; 
# 1372
static const float_denorm_style has_denorm = denorm_absent; 
# 1374
static const bool has_denorm_loss = false; 
# 1377
static unsigned long long infinity() throw() 
# 1378
{ return static_cast< unsigned long long>(0); } 
# 1381
static unsigned long long quiet_NaN() throw() 
# 1382
{ return static_cast< unsigned long long>(0); } 
# 1385
static unsigned long long signaling_NaN() throw() 
# 1386
{ return static_cast< unsigned long long>(0); } 
# 1389
static unsigned long long denorm_min() throw() 
# 1390
{ return static_cast< unsigned long long>(0); } 
# 1392
static const bool is_iec559 = false; 
# 1393
static const bool is_bounded = true; 
# 1394
static const bool is_modulo = true; 
# 1396
static const bool traps = false; 
# 1397
static const bool tinyness_before = false; 
# 1398
static const float_round_style round_style = round_toward_zero; 
# 1400
}; 
# 1405
template<> struct numeric_limits< __int128_t>  { 
# 1407
static const bool is_specialized = true; 
# 1410
static __int128_t min() throw() { return (((__int128_t)(-1)) < (0)) ? (-((((__int128_t)(-1)) < (0)) ? (((((__int128_t)1) << (((sizeof(__int128_t) * (8)) - (((__int128_t)(-1)) < (0))) - (1))) - (1)) << 1) + (1) : (~((__int128_t)0)))) - (1) : ((__int128_t)0); } 
# 1413
static __int128_t max() throw() { return (((__int128_t)(-1)) < (0)) ? (((((__int128_t)1) << (((sizeof(__int128_t) * (8)) - (((__int128_t)(-1)) < (0))) - (1))) - (1)) << 1) + (1) : (~((__int128_t)0)); } 
# 1420
static const int digits = ((sizeof(__int128_t) * (8)) - (((__int128_t)(-1)) < (0))); 
# 1422
static const int digits10 = ((((sizeof(__int128_t) * (8)) - (((__int128_t)(-1)) < (0))) * (643L)) / (2136)); 
# 1427
static const bool is_signed = true; 
# 1428
static const bool is_integer = true; 
# 1429
static const bool is_exact = true; 
# 1430
static const int radix = 2; 
# 1433
static __int128_t epsilon() throw() { return 0; } 
# 1436
static __int128_t round_error() throw() { return 0; } 
# 1438
static const int min_exponent = 0; 
# 1439
static const int min_exponent10 = 0; 
# 1440
static const int max_exponent = 0; 
# 1441
static const int max_exponent10 = 0; 
# 1443
static const bool has_infinity = false; 
# 1444
static const bool has_quiet_NaN = false; 
# 1445
static const bool has_signaling_NaN = false; 
# 1446
static const float_denorm_style has_denorm = denorm_absent; 
# 1448
static const bool has_denorm_loss = false; 
# 1451
static __int128_t infinity() throw() 
# 1452
{ return static_cast< __int128_t>(0); } 
# 1455
static __int128_t quiet_NaN() throw() 
# 1456
{ return static_cast< __int128_t>(0); } 
# 1459
static __int128_t signaling_NaN() throw() 
# 1460
{ return static_cast< __int128_t>(0); } 
# 1463
static __int128_t denorm_min() throw() 
# 1464
{ return static_cast< __int128_t>(0); } 
# 1466
static const bool is_iec559 = false; 
# 1467
static const bool is_bounded = true; 
# 1468
static const bool is_modulo = false; 
# 1470
static const bool traps = false; 
# 1472
static const bool tinyness_before = false; 
# 1473
static const float_round_style round_style = round_toward_zero; 
# 1475
}; 
# 1479
template<> struct numeric_limits< __uint128_t>  { 
# 1481
static const bool is_specialized = true; 
# 1484
static __uint128_t min() throw() { return 0; } 
# 1487
static __uint128_t max() throw() { return (((__uint128_t)(-1)) < (0)) ? (((((__uint128_t)1) << (((sizeof(__uint128_t) * (8)) - (((__uint128_t)(-1)) < (0))) - (1))) - (1)) << 1) + (1) : (~((__uint128_t)0)); } 
# 1494
static const int digits = ((sizeof(__uint128_t) * (8)) - (((__uint128_t)(-1)) < (0))); 
# 1496
static const int digits10 = ((((sizeof(__uint128_t) * (8)) - (((__uint128_t)(-1)) < (0))) * (643L)) / (2136)); 
# 1501
static const bool is_signed = false; 
# 1502
static const bool is_integer = true; 
# 1503
static const bool is_exact = true; 
# 1504
static const int radix = 2; 
# 1507
static __uint128_t epsilon() throw() { return 0; } 
# 1510
static __uint128_t round_error() throw() { return 0; } 
# 1512
static const int min_exponent = 0; 
# 1513
static const int min_exponent10 = 0; 
# 1514
static const int max_exponent = 0; 
# 1515
static const int max_exponent10 = 0; 
# 1517
static const bool has_infinity = false; 
# 1518
static const bool has_quiet_NaN = false; 
# 1519
static const bool has_signaling_NaN = false; 
# 1520
static const float_denorm_style has_denorm = denorm_absent; 
# 1522
static const bool has_denorm_loss = false; 
# 1525
static __uint128_t infinity() throw() 
# 1526
{ return static_cast< __uint128_t>(0); } 
# 1529
static __uint128_t quiet_NaN() throw() 
# 1530
{ return static_cast< __uint128_t>(0); } 
# 1533
static __uint128_t signaling_NaN() throw() 
# 1534
{ return static_cast< __uint128_t>(0); } 
# 1537
static __uint128_t denorm_min() throw() 
# 1538
{ return static_cast< __uint128_t>(0); } 
# 1540
static const bool is_iec559 = false; 
# 1541
static const bool is_bounded = true; 
# 1542
static const bool is_modulo = true; 
# 1544
static const bool traps = false; 
# 1545
static const bool tinyness_before = false; 
# 1546
static const float_round_style round_style = round_toward_zero; 
# 1548
}; 
# 1553
template<> struct numeric_limits< float>  { 
# 1555
static const bool is_specialized = true; 
# 1558
static float min() throw() { return (1.175494351e-38F); } 
# 1561
static float max() throw() { return (3.402823466e+38F); } 
# 1568
static const int digits = 24; 
# 1569
static const int digits10 = 6; 
# 1574
static const bool is_signed = true; 
# 1575
static const bool is_integer = false; 
# 1576
static const bool is_exact = false; 
# 1577
static const int radix = 2; 
# 1580
static float epsilon() throw() { return (1.192092896e-07F); } 
# 1583
static float round_error() throw() { return (0.5F); } 
# 1585
static const int min_exponent = (-125); 
# 1586
static const int min_exponent10 = (-37); 
# 1587
static const int max_exponent = 128; 
# 1588
static const int max_exponent10 = 38; 
# 1590
static const bool has_infinity = (1); 
# 1591
static const bool has_quiet_NaN = (1); 
# 1592
static const bool has_signaling_NaN = has_quiet_NaN; 
# 1593
static const float_denorm_style has_denorm = (((bool)1) ? denorm_present : denorm_absent); 
# 1595
static const bool has_denorm_loss = false; 
# 1599
static float infinity() throw() { return __builtin_huge_valf(); } 
# 1602
static float quiet_NaN() throw() { return __builtin_nanf(""); } 
# 1605
static float signaling_NaN() throw() { return __builtin_nansf(""); } 
# 1608
static float denorm_min() throw() { return (1.401298464e-45F); } 
# 1610
static const bool is_iec559 = (has_infinity && has_quiet_NaN && (has_denorm == (denorm_present))); 
# 1612
static const bool is_bounded = true; 
# 1613
static const bool is_modulo = false; 
# 1615
static const bool traps = false; 
# 1616
static const bool tinyness_before = false; 
# 1618
static const float_round_style round_style = round_to_nearest; 
# 1620
}; 
# 1628
template<> struct numeric_limits< double>  { 
# 1630
static const bool is_specialized = true; 
# 1633
static double min() throw() { return (double)(2.225073858507201383e-308L); } 
# 1636
static double max() throw() { return (double)(1.797693134862315708e+308L); } 
# 1643
static const int digits = 53; 
# 1644
static const int digits10 = 15; 
# 1649
static const bool is_signed = true; 
# 1650
static const bool is_integer = false; 
# 1651
static const bool is_exact = false; 
# 1652
static const int radix = 2; 
# 1655
static double epsilon() throw() { return (double)(2.220446049250313081e-16L); } 
# 1658
static double round_error() throw() { return (0.5); } 
# 1660
static const int min_exponent = (-1021); 
# 1661
static const int min_exponent10 = (-307); 
# 1662
static const int max_exponent = 1024; 
# 1663
static const int max_exponent10 = 308; 
# 1665
static const bool has_infinity = (1); 
# 1666
static const bool has_quiet_NaN = (1); 
# 1667
static const bool has_signaling_NaN = has_quiet_NaN; 
# 1668
static const float_denorm_style has_denorm = (((bool)1) ? denorm_present : denorm_absent); 
# 1670
static const bool has_denorm_loss = false; 
# 1674
static double infinity() throw() { return __builtin_huge_val(); } 
# 1677
static double quiet_NaN() throw() { return __builtin_nan(""); } 
# 1680
static double signaling_NaN() throw() { return __builtin_nans(""); } 
# 1683
static double denorm_min() throw() { return (double)(4.940656458412465442e-324L); } 
# 1685
static const bool is_iec559 = (has_infinity && has_quiet_NaN && (has_denorm == (denorm_present))); 
# 1687
static const bool is_bounded = true; 
# 1688
static const bool is_modulo = false; 
# 1690
static const bool traps = false; 
# 1691
static const bool tinyness_before = false; 
# 1693
static const float_round_style round_style = round_to_nearest; 
# 1695
}; 
# 1703
template<> struct numeric_limits< long double>  { 
# 1705
static const bool is_specialized = true; 
# 1708
static long double min() throw() { return (2.004168360008972778e-292L); } 
# 1711
static long double max() throw() { return (1.797693134862315708e+308L); } 
# 1718
static const int digits = 106; 
# 1719
static const int digits10 = 31; 
# 1724
static const bool is_signed = true; 
# 1725
static const bool is_integer = false; 
# 1726
static const bool is_exact = false; 
# 1727
static const int radix = 2; 
# 1730
static long double epsilon() throw() { return (4.940656458412465442e-324L); } 
# 1733
static long double round_error() throw() { return (0.5L); } 
# 1735
static const int min_exponent = (-968); 
# 1736
static const int min_exponent10 = (-291); 
# 1737
static const int max_exponent = 1024; 
# 1738
static const int max_exponent10 = 308; 
# 1740
static const bool has_infinity = (1); 
# 1741
static const bool has_quiet_NaN = (1); 
# 1742
static const bool has_signaling_NaN = has_quiet_NaN; 
# 1743
static const float_denorm_style has_denorm = (((bool)1) ? denorm_present : denorm_absent); 
# 1745
static const bool has_denorm_loss = false; 
# 1749
static long double infinity() throw() { return __builtin_huge_vall(); } 
# 1752
static long double quiet_NaN() throw() { return __builtin_nanl(""); } 
# 1755
static long double signaling_NaN() throw() { return __builtin_nansl(""); } 
# 1758
static long double denorm_min() throw() { return (4.940656458412465442e-324L); } 
# 1760
static const bool is_iec559 = (has_infinity && has_quiet_NaN && (has_denorm == (denorm_present))); 
# 1762
static const bool is_bounded = true; 
# 1763
static const bool is_modulo = false; 
# 1765
static const bool traps = false; 
# 1766
static const bool tinyness_before = false; 
# 1768
static const float_round_style round_style = round_to_nearest; 
# 1770
}; 
# 1777
}
# 23 "/usr/local/cuda-8.0/include/thrust/detail/integer_traits.h"
namespace thrust { 
# 26
namespace detail { 
# 29
template< class T> 
# 30
class integer_traits { 
# 33
public: static const bool is_integral = false; 
# 34
}; 
# 36
template< class T, T min_val, T max_val> 
# 37
class integer_traits_base { 
# 40
public: static const bool is_integral = true; 
# 41
static const T const_min = min_val; 
# 42
static const T const_max = max_val; 
# 43
}; 
# 47
template<> class integer_traits< bool>  : public std::numeric_limits< bool> , public integer_traits_base< bool, false, true>  { 
# 50
}; 
# 54
template<> class integer_traits< char>  : public std::numeric_limits< char> , public integer_traits_base< char, '\000', '\377'>  { 
# 57
}; 
# 61
template<> class integer_traits< signed char>  : public std::numeric_limits< signed char> , public integer_traits_base< signed char, (signed char)'\200', (signed char)'\177'>  { 
# 64
}; 
# 68
template<> class integer_traits< unsigned char>  : public std::numeric_limits< unsigned char> , public integer_traits_base< unsigned char, (unsigned char)'\000', (unsigned char)'\377'>  { 
# 71
}; 
# 75
template<> class integer_traits< short>  : public std::numeric_limits< short> , public integer_traits_base< short, (short)(-32767-1), (short)32767>  { 
# 78
}; 
# 82
template<> class integer_traits< unsigned short>  : public std::numeric_limits< unsigned short> , public integer_traits_base< unsigned short, (unsigned short)0U, (unsigned short)65535U>  { 
# 85
}; 
# 89
template<> class integer_traits< int>  : public std::numeric_limits< int> , public integer_traits_base< int, -2147483647-1, 2147483647>  { 
# 92
}; 
# 96
template<> class integer_traits< unsigned>  : public std::numeric_limits< unsigned> , public integer_traits_base< unsigned, 0U, 4294967295U>  { 
# 99
}; 
# 103
template<> class integer_traits< long>  : public std::numeric_limits< long> , public integer_traits_base< long, -9223372036854775807L-1, 9223372036854775807L>  { 
# 106
}; 
# 110
template<> class integer_traits< unsigned long>  : public std::numeric_limits< unsigned long> , public integer_traits_base< unsigned long, 0UL, 18446744073709551615UL>  { 
# 113
}; 
# 117
template<> class integer_traits< long long>  : public std::numeric_limits< long long> , public integer_traits_base< long long, -9223372036854775807LL-1, 9223372036854775807LL>  { 
# 120
}; 
# 124
template<> class integer_traits< unsigned long long>  : public std::numeric_limits< unsigned long long> , public integer_traits_base< unsigned long long, 0ULL, 18446744073709551615ULL>  { 
# 127
}; 
# 129
}
# 131
}
# 23 "/usr/local/cuda-8.0/include/thrust/detail/allocator/allocator_traits.inl"
namespace thrust { 
# 25
namespace detail { 
# 27
namespace allocator_traits_detail { 
# 30
template< class T, class Signature> class has_member_allocate_with_hint_impl_has_member; template< class T, class Result> class has_member_allocate_with_hint_impl_has_member< T, Result (void)>  { class yes { char m; }; class no { yes m[2]; }; struct base_mixin { Result allocate(); }; struct base : public T, public base_mixin { }; template< class U, U t> class helper { }; template< class U> static no deduce(U *, helper< Result (base_mixin::*)(void), &U::allocate>  * = 0); static yes deduce(...); public: static const bool value = (sizeof(yes) == sizeof(deduce(static_cast< base *>(0)))); typedef integral_constant< bool, value>  type; }; template< class T, class Result, class Arg> class has_member_allocate_with_hint_impl_has_member< T, Result (Arg)>  { class yes { char m; }; class no { yes m[2]; }; struct base_mixin { Result allocate(Arg); }; struct base : public T, public base_mixin { }; template< class U, U t> class helper { }; template< class U> static no deduce(U *, helper< Result (base_mixin::*)(Arg), &U::allocate>  * = 0); static yes deduce(...); public: static const bool value = (sizeof(yes) == sizeof(deduce(static_cast< base *>(0)))); typedef integral_constant< bool, value>  type; }; template< class T, class Result, class Arg1, class Arg2> class has_member_allocate_with_hint_impl_has_member< T, Result (Arg1, Arg2)>  { class yes { char m; }; class no { yes m[2]; }; struct base_mixin { Result allocate(Arg1, Arg2); }; struct base : public T, public base_mixin { }; template< class U, U t> class helper { }; template< class U> static no deduce(U *, helper< Result (base_mixin::*)(Arg1, Arg2), &U::allocate>  * = 0); static yes deduce(...); public: static const bool value = (sizeof(yes) == sizeof(deduce(static_cast< base *>(0)))); typedef integral_constant< bool, value>  type; }; template< class T, class Result, class Arg1, class Arg2, class Arg3> class has_member_allocate_with_hint_impl_has_member< T, Result (Arg1, Arg2, Arg3)>  { class yes { char m; }; class no { yes m[2]; }; struct base_mixin { Result allocate(Arg1, Arg2, Arg3); }; struct base : public T, public base_mixin { }; template< class U, U t> class helper { }; template< class U> static no deduce(U *, helper< Result (base_mixin::*)(Arg1, Arg2, Arg3), &U::allocate>  * = 0); static yes deduce(...); public: static const bool value = (sizeof(yes) == sizeof(deduce(static_cast< base *>(0)))); typedef integral_constant< bool, value>  type; }; template< class T, class Result, class Arg1, class Arg2, class Arg3, class Arg4> class has_member_allocate_with_hint_impl_has_member< T, Result (Arg1, Arg2, Arg3, Arg4)>  { class yes { char m; }; class no { yes m[2]; }; struct base_mixin { Result allocate(Arg1, Arg2, Arg3, Arg4); }; struct base : public T, public base_mixin { }; template< class U, U t> class helper { }; template< class U> static no deduce(U *, helper< Result (base_mixin::*)(Arg1, Arg2, Arg3, Arg4), &U::allocate>  * = 0); static yes deduce(...); public: static const bool value = (sizeof(yes) == sizeof(deduce(static_cast< base *>(0)))); typedef integral_constant< bool, value>  type; }; template< class T, class Signature> struct has_member_allocate_with_hint_impl { private: struct yes { }; struct no { yes m[2]; }; struct derived : public T { using T::allocate;typename ::thrust::detail::allocator_traits_detail::has_member_allocate_with_hint_impl< T, Signature> ::no allocate(...) const; }; typedef typename is_call_possible_detail::clone_constness< T, derived> ::type derived_type; template< class U, class Result> struct return_value_check { static yes deduce(Result); static no deduce(...); static no deduce(no); static no deduce(is_call_possible_detail::void_exp_result< T> ); }; template< class U> struct return_value_check< U, void>  { static yes deduce(...); static no deduce(no); }; template< bool has_the_member_of_interest, class F> struct impl { static const bool value = false; }; template< class Result, class Arg> struct impl< true, Result (Arg)>  { static typename add_reference< typename is_call_possible_detail::clone_constness< T, derived> ::type> ::type test_me; static typename add_reference< Arg> ::type arg; static const bool value = (sizeof(return_value_check< T, Result> ::deduce(((test_me.allocate(arg)), (is_call_possible_detail::void_exp_result< T> ())))) == sizeof(yes)); }; template< class Result, class Arg1, class Arg2> struct impl< true, Result (Arg1, Arg2)>  { static typename add_reference< typename is_call_possible_detail::clone_constness< T, derived> ::type> ::type test_me; static typename add_reference< Arg1> ::type arg1; static typename add_reference< Arg2> ::type arg2; static const bool value = (sizeof(return_value_check< T, Result> ::deduce(((test_me.allocate(arg1, arg2)), (is_call_possible_detail::void_exp_result< T> ())))) == sizeof(yes)); }; template< class Result, class Arg1, class Arg2, class Arg3> struct impl< true, Result (Arg1, Arg2, Arg3)>  { static typename add_reference< typename is_call_possible_detail::clone_constness< T, derived> ::type> ::type test_me; static typename add_reference< Arg1> ::type arg1; static typename add_reference< Arg2> ::type arg2; static typename add_reference< Arg3> ::type arg3; static const bool value = (sizeof(return_value_check< T, Result> ::deduce(((test_me.allocate(arg1, arg2, arg3)), (is_call_possible_detail::void_exp_result< T> ())))) == sizeof(yes)); }; template< class Result, class Arg1, class Arg2, class Arg3, class Arg4> struct impl< true, Result (Arg1, Arg2, Arg3, Arg4)>  { static typename add_reference< typename is_call_possible_detail::clone_constness< T, derived> ::type> ::type test_me; static typename add_reference< Arg1> ::type arg1; static typename add_reference< Arg2> ::type arg2; static typename add_reference< Arg3> ::type arg3; static typename add_reference< Arg4> ::type arg4; static const bool value = (sizeof(return_value_check< T, Result> ::deduce(((test_me.allocate(arg1, arg2, arg3, arg4)), (is_call_possible_detail::void_exp_result< T> ())))) == sizeof(yes)); }; public: static const bool value = (impl< has_member_allocate_with_hint_impl_has_member< T, Signature> ::value, Signature> ::value); typedef integral_constant< bool, value>  type; }; 
# 32
template< class Alloc> 
# 33
class has_member_allocate_with_hint { 
# 35
typedef typename allocator_traits< Alloc> ::pointer pointer; 
# 36
typedef typename allocator_traits< Alloc> ::size_type size_type; 
# 37
typedef typename allocator_traits< Alloc> ::const_void_pointer const_void_pointer; 
# 40
public: typedef typename has_member_allocate_with_hint_impl< Alloc, typename allocator_traits< Alloc> ::pointer (typename allocator_traits< Alloc> ::size_type, typename allocator_traits< Alloc> ::const_void_pointer)> ::type type; 
# 41
static const bool value = (type::value); 
# 42
}; 
# 44
template< class Alloc> typename enable_if< has_member_allocate_with_hint< Alloc> ::value, typename allocator_traits< Alloc> ::pointer> ::type 
# 50
allocate(Alloc &a, typename allocator_traits< Alloc> ::size_type n, typename allocator_traits< Alloc> ::const_void_pointer hint) 
# 51
{ 
# 52
return (a.allocate(n, hint)); 
# 53
} 
# 55
template< class Alloc> typename disable_if< has_member_allocate_with_hint< Alloc> ::value, typename allocator_traits< Alloc> ::pointer> ::type 
# 61
allocate(Alloc &a, typename allocator_traits< Alloc> ::size_type n, typename allocator_traits< Alloc> ::const_void_pointer) 
# 62
{ 
# 63
return (a.allocate(n)); 
# 64
} 
# 67
template< class T, class Signature> class has_member_construct1_impl_has_member; template< class T, class Result> class has_member_construct1_impl_has_member< T, Result (void)>  { class yes { char m; }; class no { yes m[2]; }; struct base_mixin { Result construct(); }; struct base : public T, public base_mixin { }; template< class U, U t> class helper { }; template< class U> static no deduce(U *, helper< Result (base_mixin::*)(void), &U::construct>  * = 0); static yes deduce(...); public: static const bool value = (sizeof(yes) == sizeof(deduce(static_cast< base *>(0)))); typedef integral_constant< bool, value>  type; }; template< class T, class Result, class Arg> class has_member_construct1_impl_has_member< T, Result (Arg)>  { class yes { char m; }; class no { yes m[2]; }; struct base_mixin { Result construct(Arg); }; struct base : public T, public base_mixin { }; template< class U, U t> class helper { }; template< class U> static no deduce(U *, helper< Result (base_mixin::*)(Arg), &U::construct>  * = 0); static yes deduce(...); public: static const bool value = (sizeof(yes) == sizeof(deduce(static_cast< base *>(0)))); typedef integral_constant< bool, value>  type; }; template< class T, class Result, class Arg1, class Arg2> class has_member_construct1_impl_has_member< T, Result (Arg1, Arg2)>  { class yes { char m; }; class no { yes m[2]; }; struct base_mixin { Result construct(Arg1, Arg2); }; struct base : public T, public base_mixin { }; template< class U, U t> class helper { }; template< class U> static no deduce(U *, helper< Result (base_mixin::*)(Arg1, Arg2), &U::construct>  * = 0); static yes deduce(...); public: static const bool value = (sizeof(yes) == sizeof(deduce(static_cast< base *>(0)))); typedef integral_constant< bool, value>  type; }; template< class T, class Result, class Arg1, class Arg2, class Arg3> class has_member_construct1_impl_has_member< T, Result (Arg1, Arg2, Arg3)>  { class yes { char m; }; class no { yes m[2]; }; struct base_mixin { Result construct(Arg1, Arg2, Arg3); }; struct base : public T, public base_mixin { }; template< class U, U t> class helper { }; template< class U> static no deduce(U *, helper< Result (base_mixin::*)(Arg1, Arg2, Arg3), &U::construct>  * = 0); static yes deduce(...); public: static const bool value = (sizeof(yes) == sizeof(deduce(static_cast< base *>(0)))); typedef integral_constant< bool, value>  type; }; template< class T, class Result, class Arg1, class Arg2, class Arg3, class Arg4> class has_member_construct1_impl_has_member< T, Result (Arg1, Arg2, Arg3, Arg4)>  { class yes { char m; }; class no { yes m[2]; }; struct base_mixin { Result construct(Arg1, Arg2, Arg3, Arg4); }; struct base : public T, public base_mixin { }; template< class U, U t> class helper { }; template< class U> static no deduce(U *, helper< Result (base_mixin::*)(Arg1, Arg2, Arg3, Arg4), &U::construct>  * = 0); static yes deduce(...); public: static const bool value = (sizeof(yes) == sizeof(deduce(static_cast< base *>(0)))); typedef integral_constant< bool, value>  type; }; template< class T, class Signature> struct has_member_construct1_impl { private: struct yes { }; struct no { yes m[2]; }; struct derived : public T { using T::construct;typename ::thrust::detail::allocator_traits_detail::has_member_construct1_impl< T, Signature> ::no construct(...) const; }; typedef typename is_call_possible_detail::clone_constness< T, derived> ::type derived_type; template< class U, class Result> struct return_value_check { static yes deduce(Result); static no deduce(...); static no deduce(no); static no deduce(is_call_possible_detail::void_exp_result< T> ); }; template< class U> struct return_value_check< U, void>  { static yes deduce(...); static no deduce(no); }; template< bool has_the_member_of_interest, class F> struct impl { static const bool value = false; }; template< class Result, class Arg> struct impl< true, Result (Arg)>  { static typename add_reference< typename is_call_possible_detail::clone_constness< T, derived> ::type> ::type test_me; static typename add_reference< Arg> ::type arg; static const bool value = (sizeof(return_value_check< T, Result> ::deduce(((test_me.construct(arg)), (is_call_possible_detail::void_exp_result< T> ())))) == sizeof(yes)); }; template< class Result, class Arg1, class Arg2> struct impl< true, Result (Arg1, Arg2)>  { static typename add_reference< typename is_call_possible_detail::clone_constness< T, derived> ::type> ::type test_me; static typename add_reference< Arg1> ::type arg1; static typename add_reference< Arg2> ::type arg2; static const bool value = (sizeof(return_value_check< T, Result> ::deduce(((test_me.construct(arg1, arg2)), (is_call_possible_detail::void_exp_result< T> ())))) == sizeof(yes)); }; template< class Result, class Arg1, class Arg2, class Arg3> struct impl< true, Result (Arg1, Arg2, Arg3)>  { static typename add_reference< typename is_call_possible_detail::clone_constness< T, derived> ::type> ::type test_me; static typename add_reference< Arg1> ::type arg1; static typename add_reference< Arg2> ::type arg2; static typename add_reference< Arg3> ::type arg3; static const bool value = (sizeof(return_value_check< T, Result> ::deduce(((test_me.construct(arg1, arg2, arg3)), (is_call_possible_detail::void_exp_result< T> ())))) == sizeof(yes)); }; template< class Result, class Arg1, class Arg2, class Arg3, class Arg4> struct impl< true, Result (Arg1, Arg2, Arg3, Arg4)>  { static typename add_reference< typename is_call_possible_detail::clone_constness< T, derived> ::type> ::type test_me; static typename add_reference< Arg1> ::type arg1; static typename add_reference< Arg2> ::type arg2; static typename add_reference< Arg3> ::type arg3; static typename add_reference< Arg4> ::type arg4; static const bool value = (sizeof(return_value_check< T, Result> ::deduce(((test_me.construct(arg1, arg2, arg3, arg4)), (is_call_possible_detail::void_exp_result< T> ())))) == sizeof(yes)); }; public: static const bool value = (impl< has_member_construct1_impl_has_member< T, Signature> ::value, Signature> ::value); typedef integral_constant< bool, value>  type; }; 
# 69
template< class Alloc, class T> 
# 70
struct has_member_construct1 : public has_member_construct1_impl< Alloc, void (T *)>  { 
# 72
}; 
# 75
template< class Alloc, class T> inline typename enable_if< has_member_construct1< Alloc, T> ::value> ::type 
# 80
construct(Alloc &a, T *p) 
# 81
{ 
# 82
(a.construct(p)); 
# 83
} 
# 85
template< class Alloc, class T> inline typename disable_if< has_member_construct1< Alloc, T> ::value> ::type 
# 90
construct(Alloc &a, T *p) 
# 91
{ 
# 92
::new (static_cast< void *>(p)) (T)(); 
# 93
} 
# 96
template< class T, class Signature> class has_member_construct2_impl_has_member; template< class T, class Result> class has_member_construct2_impl_has_member< T, Result (void)>  { class yes { char m; }; class no { yes m[2]; }; struct base_mixin { Result construct(); }; struct base : public T, public base_mixin { }; template< class U, U t> class helper { }; template< class U> static no deduce(U *, helper< Result (base_mixin::*)(void), &U::construct>  * = 0); static yes deduce(...); public: static const bool value = (sizeof(yes) == sizeof(deduce(static_cast< base *>(0)))); typedef integral_constant< bool, value>  type; }; template< class T, class Result, class Arg> class has_member_construct2_impl_has_member< T, Result (Arg)>  { class yes { char m; }; class no { yes m[2]; }; struct base_mixin { Result construct(Arg); }; struct base : public T, public base_mixin { }; template< class U, U t> class helper { }; template< class U> static no deduce(U *, helper< Result (base_mixin::*)(Arg), &U::construct>  * = 0); static yes deduce(...); public: static const bool value = (sizeof(yes) == sizeof(deduce(static_cast< base *>(0)))); typedef integral_constant< bool, value>  type; }; template< class T, class Result, class Arg1, class Arg2> class has_member_construct2_impl_has_member< T, Result (Arg1, Arg2)>  { class yes { char m; }; class no { yes m[2]; }; struct base_mixin { Result construct(Arg1, Arg2); }; struct base : public T, public base_mixin { }; template< class U, U t> class helper { }; template< class U> static no deduce(U *, helper< Result (base_mixin::*)(Arg1, Arg2), &U::construct>  * = 0); static yes deduce(...); public: static const bool value = (sizeof(yes) == sizeof(deduce(static_cast< base *>(0)))); typedef integral_constant< bool, value>  type; }; template< class T, class Result, class Arg1, class Arg2, class Arg3> class has_member_construct2_impl_has_member< T, Result (Arg1, Arg2, Arg3)>  { class yes { char m; }; class no { yes m[2]; }; struct base_mixin { Result construct(Arg1, Arg2, Arg3); }; struct base : public T, public base_mixin { }; template< class U, U t> class helper { }; template< class U> static no deduce(U *, helper< Result (base_mixin::*)(Arg1, Arg2, Arg3), &U::construct>  * = 0); static yes deduce(...); public: static const bool value = (sizeof(yes) == sizeof(deduce(static_cast< base *>(0)))); typedef integral_constant< bool, value>  type; }; template< class T, class Result, class Arg1, class Arg2, class Arg3, class Arg4> class has_member_construct2_impl_has_member< T, Result (Arg1, Arg2, Arg3, Arg4)>  { class yes { char m; }; class no { yes m[2]; }; struct base_mixin { Result construct(Arg1, Arg2, Arg3, Arg4); }; struct base : public T, public base_mixin { }; template< class U, U t> class helper { }; template< class U> static no deduce(U *, helper< Result (base_mixin::*)(Arg1, Arg2, Arg3, Arg4), &U::construct>  * = 0); static yes deduce(...); public: static const bool value = (sizeof(yes) == sizeof(deduce(static_cast< base *>(0)))); typedef integral_constant< bool, value>  type; }; template< class T, class Signature> struct has_member_construct2_impl { private: struct yes { }; struct no { yes m[2]; }; struct derived : public T { using T::construct;typename ::thrust::detail::allocator_traits_detail::has_member_construct2_impl< T, Signature> ::no construct(...) const; }; typedef typename is_call_possible_detail::clone_constness< T, derived> ::type derived_type; template< class U, class Result> struct return_value_check { static yes deduce(Result); static no deduce(...); static no deduce(no); static no deduce(is_call_possible_detail::void_exp_result< T> ); }; template< class U> struct return_value_check< U, void>  { static yes deduce(...); static no deduce(no); }; template< bool has_the_member_of_interest, class F> struct impl { static const bool value = false; }; template< class Result, class Arg> struct impl< true, Result (Arg)>  { static typename add_reference< typename is_call_possible_detail::clone_constness< T, derived> ::type> ::type test_me; static typename add_reference< Arg> ::type arg; static const bool value = (sizeof(return_value_check< T, Result> ::deduce(((test_me.construct(arg)), (is_call_possible_detail::void_exp_result< T> ())))) == sizeof(yes)); }; template< class Result, class Arg1, class Arg2> struct impl< true, Result (Arg1, Arg2)>  { static typename add_reference< typename is_call_possible_detail::clone_constness< T, derived> ::type> ::type test_me; static typename add_reference< Arg1> ::type arg1; static typename add_reference< Arg2> ::type arg2; static const bool value = (sizeof(return_value_check< T, Result> ::deduce(((test_me.construct(arg1, arg2)), (is_call_possible_detail::void_exp_result< T> ())))) == sizeof(yes)); }; template< class Result, class Arg1, class Arg2, class Arg3> struct impl< true, Result (Arg1, Arg2, Arg3)>  { static typename add_reference< typename is_call_possible_detail::clone_constness< T, derived> ::type> ::type test_me; static typename add_reference< Arg1> ::type arg1; static typename add_reference< Arg2> ::type arg2; static typename add_reference< Arg3> ::type arg3; static const bool value = (sizeof(return_value_check< T, Result> ::deduce(((test_me.construct(arg1, arg2, arg3)), (is_call_possible_detail::void_exp_result< T> ())))) == sizeof(yes)); }; template< class Result, class Arg1, class Arg2, class Arg3, class Arg4> struct impl< true, Result (Arg1, Arg2, Arg3, Arg4)>  { static typename add_reference< typename is_call_possible_detail::clone_constness< T, derived> ::type> ::type test_me; static typename add_reference< Arg1> ::type arg1; static typename add_reference< Arg2> ::type arg2; static typename add_reference< Arg3> ::type arg3; static typename add_reference< Arg4> ::type arg4; static const bool value = (sizeof(return_value_check< T, Result> ::deduce(((test_me.construct(arg1, arg2, arg3, arg4)), (is_call_possible_detail::void_exp_result< T> ())))) == sizeof(yes)); }; public: static const bool value = (impl< has_member_construct2_impl_has_member< T, Signature> ::value, Signature> ::value); typedef integral_constant< bool, value>  type; }; 
# 98
template< class Alloc, class T, class Arg1> 
# 99
struct has_member_construct2 : public has_member_construct2_impl< Alloc, void (T *, const Arg1 &)>  { 
# 101
}; 
# 103
template< class Alloc, class T, class Arg1> inline typename enable_if< has_member_construct2< Alloc, T, Arg1> ::value> ::type 
# 108
construct(Alloc &a, T *p, const Arg1 &arg1) 
# 109
{ 
# 110
(a.construct(p, arg1)); 
# 111
} 
# 113
template< class Alloc, class T, class Arg1> inline typename disable_if< has_member_construct2< Alloc, T, Arg1> ::value> ::type 
# 118
construct(Alloc &, T *p, const Arg1 &arg1) 
# 119
{ 
# 120
::new (static_cast< void *>(p)) (T)(arg1); 
# 121
} 
# 124
template< class T, class Signature> class has_member_destroy_impl_has_member; template< class T, class Result> class has_member_destroy_impl_has_member< T, Result (void)>  { class yes { char m; }; class no { yes m[2]; }; struct base_mixin { Result destroy(); }; struct base : public T, public base_mixin { }; template< class U, U t> class helper { }; template< class U> static no deduce(U *, helper< Result (base_mixin::*)(void), &U::destroy>  * = 0); static yes deduce(...); public: static const bool value = (sizeof(yes) == sizeof(deduce(static_cast< base *>(0)))); typedef integral_constant< bool, value>  type; }; template< class T, class Result, class Arg> class has_member_destroy_impl_has_member< T, Result (Arg)>  { class yes { char m; }; class no { yes m[2]; }; struct base_mixin { Result destroy(Arg); }; struct base : public T, public base_mixin { }; template< class U, U t> class helper { }; template< class U> static no deduce(U *, helper< Result (base_mixin::*)(Arg), &U::destroy>  * = 0); static yes deduce(...); public: static const bool value = (sizeof(yes) == sizeof(deduce(static_cast< base *>(0)))); typedef integral_constant< bool, value>  type; }; template< class T, class Result, class Arg1, class Arg2> class has_member_destroy_impl_has_member< T, Result (Arg1, Arg2)>  { class yes { char m; }; class no { yes m[2]; }; struct base_mixin { Result destroy(Arg1, Arg2); }; struct base : public T, public base_mixin { }; template< class U, U t> class helper { }; template< class U> static no deduce(U *, helper< Result (base_mixin::*)(Arg1, Arg2), &U::destroy>  * = 0); static yes deduce(...); public: static const bool value = (sizeof(yes) == sizeof(deduce(static_cast< base *>(0)))); typedef integral_constant< bool, value>  type; }; template< class T, class Result, class Arg1, class Arg2, class Arg3> class has_member_destroy_impl_has_member< T, Result (Arg1, Arg2, Arg3)>  { class yes { char m; }; class no { yes m[2]; }; struct base_mixin { Result destroy(Arg1, Arg2, Arg3); }; struct base : public T, public base_mixin { }; template< class U, U t> class helper { }; template< class U> static no deduce(U *, helper< Result (base_mixin::*)(Arg1, Arg2, Arg3), &U::destroy>  * = 0); static yes deduce(...); public: static const bool value = (sizeof(yes) == sizeof(deduce(static_cast< base *>(0)))); typedef integral_constant< bool, value>  type; }; template< class T, class Result, class Arg1, class Arg2, class Arg3, class Arg4> class has_member_destroy_impl_has_member< T, Result (Arg1, Arg2, Arg3, Arg4)>  { class yes { char m; }; class no { yes m[2]; }; struct base_mixin { Result destroy(Arg1, Arg2, Arg3, Arg4); }; struct base : public T, public base_mixin { }; template< class U, U t> class helper { }; template< class U> static no deduce(U *, helper< Result (base_mixin::*)(Arg1, Arg2, Arg3, Arg4), &U::destroy>  * = 0); static yes deduce(...); public: static const bool value = (sizeof(yes) == sizeof(deduce(static_cast< base *>(0)))); typedef integral_constant< bool, value>  type; }; template< class T, class Signature> struct has_member_destroy_impl { private: struct yes { }; struct no { yes m[2]; }; struct derived : public T { using T::destroy;typename ::thrust::detail::allocator_traits_detail::has_member_destroy_impl< T, Signature> ::no destroy(...) const; }; typedef typename is_call_possible_detail::clone_constness< T, derived> ::type derived_type; template< class U, class Result> struct return_value_check { static yes deduce(Result); static no deduce(...); static no deduce(no); static no deduce(is_call_possible_detail::void_exp_result< T> ); }; template< class U> struct return_value_check< U, void>  { static yes deduce(...); static no deduce(no); }; template< bool has_the_member_of_interest, class F> struct impl { static const bool value = false; }; template< class Result, class Arg> struct impl< true, Result (Arg)>  { static typename add_reference< typename is_call_possible_detail::clone_constness< T, derived> ::type> ::type test_me; static typename add_reference< Arg> ::type arg; static const bool value = (sizeof(return_value_check< T, Result> ::deduce(((test_me.destroy(arg)), (is_call_possible_detail::void_exp_result< T> ())))) == sizeof(yes)); }; template< class Result, class Arg1, class Arg2> struct impl< true, Result (Arg1, Arg2)>  { static typename add_reference< typename is_call_possible_detail::clone_constness< T, derived> ::type> ::type test_me; static typename add_reference< Arg1> ::type arg1; static typename add_reference< Arg2> ::type arg2; static const bool value = (sizeof(return_value_check< T, Result> ::deduce(((test_me.destroy(arg1, arg2)), (is_call_possible_detail::void_exp_result< T> ())))) == sizeof(yes)); }; template< class Result, class Arg1, class Arg2, class Arg3> struct impl< true, Result (Arg1, Arg2, Arg3)>  { static typename add_reference< typename is_call_possible_detail::clone_constness< T, derived> ::type> ::type test_me; static typename add_reference< Arg1> ::type arg1; static typename add_reference< Arg2> ::type arg2; static typename add_reference< Arg3> ::type arg3; static const bool value = (sizeof(return_value_check< T, Result> ::deduce(((test_me.destroy(arg1, arg2, arg3)), (is_call_possible_detail::void_exp_result< T> ())))) == sizeof(yes)); }; template< class Result, class Arg1, class Arg2, class Arg3, class Arg4> struct impl< true, Result (Arg1, Arg2, Arg3, Arg4)>  { static typename add_reference< typename is_call_possible_detail::clone_constness< T, derived> ::type> ::type test_me; static typename add_reference< Arg1> ::type arg1; static typename add_reference< Arg2> ::type arg2; static typename add_reference< Arg3> ::type arg3; static typename add_reference< Arg4> ::type arg4; static const bool value = (sizeof(return_value_check< T, Result> ::deduce(((test_me.destroy(arg1, arg2, arg3, arg4)), (is_call_possible_detail::void_exp_result< T> ())))) == sizeof(yes)); }; public: static const bool value = (impl< has_member_destroy_impl_has_member< T, Signature> ::value, Signature> ::value); typedef integral_constant< bool, value>  type; }; 
# 126
template< class Alloc, class T> 
# 127
struct has_member_destroy : public has_member_destroy_impl< Alloc, void (T *)>  { 
# 129
}; 
# 131
template< class Alloc, class T> inline typename enable_if< has_member_destroy< Alloc, T> ::value> ::type 
# 136
destroy(Alloc &a, T *p) 
# 137
{ 
# 138
(a.destroy(p)); 
# 139
} 
# 141
template< class Alloc, class T> inline typename disable_if< has_member_destroy< Alloc, T> ::value> ::type 
# 146
destroy(Alloc &, T *p) 
# 147
{ 
# 148
(p->~T()); 
# 149
} 
# 152
template< class T, class Signature> class has_member_max_size_impl_has_member; template< class T, class Result> class has_member_max_size_impl_has_member< T, Result (void)>  { class yes { char m; }; class no { yes m[2]; }; struct base_mixin { Result max_size(); }; struct base : public T, public base_mixin { }; template< class U, U t> class helper { }; template< class U> static no deduce(U *, helper< Result (base_mixin::*)(void), &U::max_size>  * = 0); static yes deduce(...); public: static const bool value = (sizeof(yes) == sizeof(deduce(static_cast< base *>(0)))); typedef integral_constant< bool, value>  type; }; template< class T, class Result, class Arg> class has_member_max_size_impl_has_member< T, Result (Arg)>  { class yes { char m; }; class no { yes m[2]; }; struct base_mixin { Result max_size(Arg); }; struct base : public T, public base_mixin { }; template< class U, U t> class helper { }; template< class U> static no deduce(U *, helper< Result (base_mixin::*)(Arg), &U::max_size>  * = 0); static yes deduce(...); public: static const bool value = (sizeof(yes) == sizeof(deduce(static_cast< base *>(0)))); typedef integral_constant< bool, value>  type; }; template< class T, class Result, class Arg1, class Arg2> class has_member_max_size_impl_has_member< T, Result (Arg1, Arg2)>  { class yes { char m; }; class no { yes m[2]; }; struct base_mixin { Result max_size(Arg1, Arg2); }; struct base : public T, public base_mixin { }; template< class U, U t> class helper { }; template< class U> static no deduce(U *, helper< Result (base_mixin::*)(Arg1, Arg2), &U::max_size>  * = 0); static yes deduce(...); public: static const bool value = (sizeof(yes) == sizeof(deduce(static_cast< base *>(0)))); typedef integral_constant< bool, value>  type; }; template< class T, class Result, class Arg1, class Arg2, class Arg3> class has_member_max_size_impl_has_member< T, Result (Arg1, Arg2, Arg3)>  { class yes { char m; }; class no { yes m[2]; }; struct base_mixin { Result max_size(Arg1, Arg2, Arg3); }; struct base : public T, public base_mixin { }; template< class U, U t> class helper { }; template< class U> static no deduce(U *, helper< Result (base_mixin::*)(Arg1, Arg2, Arg3), &U::max_size>  * = 0); static yes deduce(...); public: static const bool value = (sizeof(yes) == sizeof(deduce(static_cast< base *>(0)))); typedef integral_constant< bool, value>  type; }; template< class T, class Result, class Arg1, class Arg2, class Arg3, class Arg4> class has_member_max_size_impl_has_member< T, Result (Arg1, Arg2, Arg3, Arg4)>  { class yes { char m; }; class no { yes m[2]; }; struct base_mixin { Result max_size(Arg1, Arg2, Arg3, Arg4); }; struct base : public T, public base_mixin { }; template< class U, U t> class helper { }; template< class U> static no deduce(U *, helper< Result (base_mixin::*)(Arg1, Arg2, Arg3, Arg4), &U::max_size>  * = 0); static yes deduce(...); public: static const bool value = (sizeof(yes) == sizeof(deduce(static_cast< base *>(0)))); typedef integral_constant< bool, value>  type; }; template< class T, class Signature> struct has_member_max_size_impl { private: struct yes { }; struct no { yes m[2]; }; struct derived : public T { using T::max_size;typename ::thrust::detail::allocator_traits_detail::has_member_max_size_impl< T, Signature> ::no max_size(...) const; }; typedef typename is_call_possible_detail::clone_constness< T, derived> ::type derived_type; template< class U, class Result> struct return_value_check { static yes deduce(Result); static no deduce(...); static no deduce(no); static no deduce(is_call_possible_detail::void_exp_result< T> ); }; template< class U> struct return_value_check< U, void>  { static yes deduce(...); static no deduce(no); }; template< bool has_the_member_of_interest, class F> struct impl { static const bool value = false; }; template< class Result, class Arg> struct impl< true, Result (Arg)>  { static typename add_reference< typename is_call_possible_detail::clone_constness< T, derived> ::type> ::type test_me; static typename add_reference< Arg> ::type arg; static const bool value = (sizeof(return_value_check< T, Result> ::deduce(((test_me.max_size(arg)), (is_call_possible_detail::void_exp_result< T> ())))) == sizeof(yes)); }; template< class Result, class Arg1, class Arg2> struct impl< true, Result (Arg1, Arg2)>  { static typename add_reference< typename is_call_possible_detail::clone_constness< T, derived> ::type> ::type test_me; static typename add_reference< Arg1> ::type arg1; static typename add_reference< Arg2> ::type arg2; static const bool value = (sizeof(return_value_check< T, Result> ::deduce(((test_me.max_size(arg1, arg2)), (is_call_possible_detail::void_exp_result< T> ())))) == sizeof(yes)); }; template< class Result, class Arg1, class Arg2, class Arg3> struct impl< true, Result (Arg1, Arg2, Arg3)>  { static typename add_reference< typename is_call_possible_detail::clone_constness< T, derived> ::type> ::type test_me; static typename add_reference< Arg1> ::type arg1; static typename add_reference< Arg2> ::type arg2; static typename add_reference< Arg3> ::type arg3; static const bool value = (sizeof(return_value_check< T, Result> ::deduce(((test_me.max_size(arg1, arg2, arg3)), (is_call_possible_detail::void_exp_result< T> ())))) == sizeof(yes)); }; template< class Result, class Arg1, class Arg2, class Arg3, class Arg4> struct impl< true, Result (Arg1, Arg2, Arg3, Arg4)>  { static typename add_reference< typename is_call_possible_detail::clone_constness< T, derived> ::type> ::type test_me; static typename add_reference< Arg1> ::type arg1; static typename add_reference< Arg2> ::type arg2; static typename add_reference< Arg3> ::type arg3; static typename add_reference< Arg4> ::type arg4; static const bool value = (sizeof(return_value_check< T, Result> ::deduce(((test_me.max_size(arg1, arg2, arg3, arg4)), (is_call_possible_detail::void_exp_result< T> ())))) == sizeof(yes)); }; public: static const bool value = (impl< has_member_max_size_impl_has_member< T, Signature> ::value, Signature> ::value); typedef integral_constant< bool, value>  type; }; 
# 154
template< class Alloc> 
# 155
class has_member_max_size { 
# 157
typedef typename allocator_traits< Alloc> ::size_type size_type; 
# 160
public: typedef typename has_member_max_size_impl< Alloc, typename allocator_traits< Alloc> ::size_type (void)> ::type type; 
# 161
static const bool value = (type::value); 
# 162
}; 
# 164
template< class Alloc> typename enable_if< has_member_max_size< Alloc> ::value, typename allocator_traits< Alloc> ::size_type> ::type 
# 170
max_size(const Alloc &a) 
# 171
{ 
# 172
return (a.max_size()); 
# 173
} 
# 175
template< class Alloc> typename disable_if< has_member_max_size< Alloc> ::value, typename allocator_traits< Alloc> ::size_type> ::type 
# 181
max_size(const Alloc &) 
# 182
{ 
# 183
typedef typename allocator_traits< Alloc> ::size_type size_type; 
# 184
return thrust::detail::integer_traits< typename allocator_traits< Alloc> ::size_type> ::const_max; 
# 185
} 
# 187
template< class Alloc> typename enable_if< has_member_system< Alloc> ::value, typename allocator_system< Alloc> ::type &> ::type 
# 193
system(Alloc &a) 
# 194
{ 
# 196
return (a.system()); 
# 197
} 
# 199
template< class Alloc> typename disable_if< has_member_system< Alloc> ::value, typename allocator_system< Alloc> ::type> ::type 
# 205
system(Alloc &) 
# 206
{ 
# 208
typename allocator_system< Alloc> ::type result; 
# 209
return result; 
# 210
} 
# 213
}
# 216
template< class Alloc> inline typename allocator_traits< Alloc> ::pointer 
# 220
allocator_traits< Alloc> ::allocate(Alloc &a, size_type n) 
# 221
{ 
# 222
struct workaround_warnings { 
# 227
static pointer allocate(Alloc &a, size_type n) 
# 228
{ 
# 229
return (a.allocate(n)); 
# 230
} 
# 231
}; 
# 233
return (workaround_warnings::allocate)(a, n); 
# 234
} 
# 236
template< class Alloc> inline typename allocator_traits< Alloc> ::pointer 
# 240
allocator_traits< Alloc> ::allocate(Alloc &a, size_type n, const_void_pointer hint) 
# 241
{ 
# 242
return allocator_traits_detail::allocate(a, n, hint); 
# 243
} 
# 245
template< class Alloc> inline void 
# 248
allocator_traits< Alloc> ::deallocate(Alloc &a, pointer p, size_type n) 
# 249
{ 
# 250
struct workaround_warnings { 
# 254
static void deallocate(Alloc &a, pointer p, size_type n) 
# 255
{ 
# 256
return (a.deallocate(p, n)); 
# 257
} 
# 258
}; 
# 260
return (workaround_warnings::deallocate)(a, p, n); 
# 261
} 
# 263
template< class Alloc> 
# 264
template< class T> inline void 
# 267
allocator_traits< Alloc> ::construct(allocator_type &a, T *p) 
# 268
{ 
# 269
return allocator_traits_detail::construct(a, p); 
# 270
} 
# 272
template< class Alloc> 
# 273
template< class T, class Arg1> inline void 
# 276
allocator_traits< Alloc> ::construct(allocator_type &a, T *p, const Arg1 &arg1) 
# 277
{ 
# 278
return allocator_traits_detail::construct(a, p, arg1); 
# 279
} 
# 281
template< class Alloc> 
# 282
template< class T> inline void 
# 285
allocator_traits< Alloc> ::destroy(allocator_type &a, T *p) 
# 286
{ 
# 287
return allocator_traits_detail::destroy(a, p); 
# 288
} 
# 290
template< class Alloc> inline typename allocator_traits< Alloc> ::size_type 
# 294
allocator_traits< Alloc> ::max_size(const allocator_type &a) 
# 295
{ 
# 296
return allocator_traits_detail::max_size(a); 
# 297
} 
# 299
template< class Alloc> inline typename allocator_system< Alloc> ::get_result_type 
# 303
allocator_system< Alloc> ::get(Alloc &a) 
# 304
{ 
# 305
return allocator_traits_detail::system(a); 
# 306
} 
# 309
}
# 310
}
# 23 "/usr/local/cuda-8.0/include/thrust/detail/contiguous_storage.h"
namespace thrust { 
# 26
namespace detail { 
# 30
template< class T, class Alloc> 
# 31
class contiguous_storage { 
# 34
typedef allocator_traits< Alloc>  alloc_traits; 
# 37
public: typedef Alloc allocator_type; 
# 38
typedef T value_type; 
# 39
typedef typename allocator_traits< Alloc> ::pointer pointer; 
# 40
typedef typename allocator_traits< Alloc> ::const_pointer const_pointer; 
# 41
typedef typename allocator_traits< Alloc> ::size_type size_type; 
# 42
typedef typename allocator_traits< Alloc> ::difference_type difference_type; 
# 49
typedef typename Alloc::reference reference; 
# 50
typedef typename Alloc::const_reference const_reference; 
# 52
typedef normal_iterator< typename allocator_traits< Alloc> ::pointer>  iterator; 
# 53
typedef normal_iterator< typename allocator_traits< Alloc> ::const_pointer>  const_iterator; 
# 57
explicit contiguous_storage(const allocator_type & alloc = allocator_type()); 
# 61
explicit contiguous_storage(size_type n, const allocator_type & alloc = allocator_type()); 
# 65
~contiguous_storage(); 
# 68
size_type size() const; 
# 71
size_type max_size() const; 
# 74
iterator begin(); 
# 77
const_iterator begin() const; 
# 80
iterator end(); 
# 83
const_iterator end() const; 
# 86
reference operator[](size_type n); 
# 89
const_reference operator[](size_type n) const; 
# 92
allocator_type get_allocator() const; 
# 96
void allocate(size_type n); 
# 99
void deallocate(); 
# 102
void swap(contiguous_storage & x); 
# 105
void default_construct_n(iterator first, size_type n); 
# 108
void uninitialized_fill_n(iterator first, size_type n, const value_type & value); 
# 110
template< class InputIterator> iterator uninitialized_copy(InputIterator first, InputIterator last, iterator result); 
# 114
template< class System, class InputIterator> iterator uninitialized_copy(execution_policy< System>  & from_system, InputIterator first, InputIterator last, iterator result); 
# 121
template< class InputIterator, class Size> iterator uninitialized_copy_n(InputIterator first, Size n, iterator result); 
# 125
template< class System, class InputIterator, class Size> iterator uninitialized_copy_n(execution_policy< System>  & from_system, InputIterator first, Size n, iterator result); 
# 133
void destroy(iterator first, iterator last); 
# 137
private: allocator_type m_allocator; 
# 139
iterator m_begin; 
# 141
size_type m_size; 
# 144
contiguous_storage &operator=(const contiguous_storage & x); 
# 145
}; 
# 147
}
# 149
template< class T, class Alloc> void swap(detail::contiguous_storage< T, Alloc>  & lhs, detail::contiguous_storage< T, Alloc>  & rhs); 
# 153
}
# 22 "/usr/local/cuda-8.0/include/thrust/detail/swap.h"
namespace thrust { 
# 26
template< class Assignable1, class Assignable2> inline void 
# 28
swap(Assignable1 &a, Assignable2 &b) 
# 29
{ 
# 30
Assignable1 temp = a; 
# 31
a = b; 
# 32
b = temp; 
# 33
} 
# 35
}
# 22 "/usr/local/cuda-8.0/include/thrust/detail/allocator/copy_construct_range.h"
namespace thrust { 
# 24
namespace detail { 
# 27
template< class System, class Allocator, class InputIterator, class Pointer> Pointer copy_construct_range(execution_policy< System>  & from_system, Allocator & a, InputIterator first, InputIterator last, Pointer result); 
# 35
template< class System, class Allocator, class InputIterator, class Size, class Pointer> Pointer copy_construct_range_n(execution_policy< System>  & from_system, Allocator & a, InputIterator first, Size n, Pointer result); 
# 43
}
# 44
}
# 22 "/usr/local/cuda-8.0/include/thrust/detail/copy.h"
namespace thrust { 
# 25
template< class System, class 
# 26
InputIterator, class 
# 27
OutputIterator> OutputIterator 
# 25
copy(const detail::execution_policy_base< System>  & system, InputIterator first, InputIterator last, OutputIterator result); 
# 34
template< class System, class 
# 35
InputIterator, class 
# 36
Size, class 
# 37
OutputIterator> OutputIterator 
# 34
copy_n(const detail::execution_policy_base< System>  & system, InputIterator first, Size n, OutputIterator result); 
# 44
template< class InputIterator, class 
# 45
OutputIterator> OutputIterator 
# 44
copy(InputIterator first, InputIterator last, OutputIterator result); 
# 50
template< class InputIterator, class 
# 51
Size, class 
# 52
OutputIterator> OutputIterator 
# 50
copy_n(InputIterator first, Size n, OutputIterator result); 
# 58
namespace detail { 
# 62
template< class FromSystem, class 
# 63
ToSystem, class 
# 64
InputIterator, class 
# 65
OutputIterator> OutputIterator 
# 62
two_system_copy(const execution_policy< FromSystem>  & from_system, const execution_policy< ToSystem>  & two_system, InputIterator first, InputIterator last, OutputIterator result); 
# 74
template< class FromSystem, class 
# 75
ToSystem, class 
# 76
InputIterator, class 
# 77
Size, class 
# 78
OutputIterator> OutputIterator 
# 74
two_system_copy_n(const execution_policy< FromSystem>  & from_system, const execution_policy< ToSystem>  & two_system, InputIterator first, Size n, OutputIterator result); 
# 87
}
# 88
}
# 21 "/usr/local/cuda-8.0/include/thrust/detail/type_traits/minimum_type.h"
namespace thrust { 
# 24
namespace detail { 
# 27
namespace minimum_type_detail { 
# 34
template< class T1, class T2, bool GreaterEqual, bool LessEqual> struct minimum_type_impl { }; 
# 36
template< class T1, class T2> 
# 37
struct minimum_type_impl< T1, T2, true, false>  { 
# 39
typedef T2 type; 
# 40
}; 
# 42
template< class T1, class T2> 
# 43
struct minimum_type_impl< T1, T2, false, true>  { 
# 45
typedef T1 type; 
# 46
}; 
# 48
template< class T1, class T2> 
# 49
struct minimum_type_impl< T1, T2, true, true>  { 
# 51
typedef T1 type; 
# 52
}; 
# 54
template< class T1, class T2> 
# 55
struct primitive_minimum_type : public minimum_type_impl< T1, T2, is_convertible< T1, T2> ::value, is_convertible< T2, T1> ::value>  { 
# 63
}; 
# 67
template< class T> 
# 68
struct primitive_minimum_type< T, T>  { 
# 70
typedef T type; 
# 71
}; 
# 74
struct any_conversion { 
# 76
template< class T> operator T(); 
# 77
}; 
# 79
}
# 81
template< class T1, class 
# 82
T2 = minimum_type_detail::any_conversion, class 
# 83
T3 = minimum_type_detail::any_conversion, class 
# 84
T4 = minimum_type_detail::any_conversion, class 
# 85
T5 = minimum_type_detail::any_conversion, class 
# 86
T6 = minimum_type_detail::any_conversion, class 
# 87
T7 = minimum_type_detail::any_conversion, class 
# 88
T8 = minimum_type_detail::any_conversion, class 
# 89
T9 = minimum_type_detail::any_conversion, class 
# 90
T10 = minimum_type_detail::any_conversion, class 
# 91
T11 = minimum_type_detail::any_conversion, class 
# 92
T12 = minimum_type_detail::any_conversion, class 
# 93
T13 = minimum_type_detail::any_conversion, class 
# 94
T14 = minimum_type_detail::any_conversion, class 
# 95
T15 = minimum_type_detail::any_conversion, class 
# 96
T16 = minimum_type_detail::any_conversion> struct minimum_type; 
# 100
template< class T1, class T2> 
# 101
struct minimum_type< T1, T2, minimum_type_detail::any_conversion, minimum_type_detail::any_conversion, minimum_type_detail::any_conversion, minimum_type_detail::any_conversion, minimum_type_detail::any_conversion, minimum_type_detail::any_conversion, minimum_type_detail::any_conversion, minimum_type_detail::any_conversion, minimum_type_detail::any_conversion, minimum_type_detail::any_conversion, minimum_type_detail::any_conversion, minimum_type_detail::any_conversion, minimum_type_detail::any_conversion, minimum_type_detail::any_conversion>  : public minimum_type_detail::primitive_minimum_type< T1, T2>  { 
# 103
}; 
# 105
template< class T1, class T2> 
# 106
struct lazy_minimum_type : public minimum_type< typename T1::type, typename T2::type>  { 
# 111
}; 
# 114
template< class T1, class T2, class T3, class T4, class 
# 115
T5, class T6, class T7, class T8, class 
# 116
T9, class T10, class T11, class T12, class 
# 117
T13, class T14, class T15, class T16> 
# 118
struct minimum_type : public lazy_minimum_type< lazy_minimum_type< lazy_minimum_type< minimum_type< T1, T2> , minimum_type< T3, T4> > , lazy_minimum_type< minimum_type< T5, T6> , minimum_type< T7, T8> > > , lazy_minimum_type< lazy_minimum_type< minimum_type< T9, T10> , minimum_type< T11, T12> > , lazy_minimum_type< minimum_type< T13, T14> , minimum_type< T15, T16> > > >  { 
# 157
}; 
# 159
}
# 161
}
# 24 "/usr/local/cuda-8.0/include/thrust/iterator/detail/minimum_system.h"
namespace thrust { 
# 26
namespace detail { 
# 30
template< class T1, class 
# 31
T2 = void, class 
# 32
T3 = void, class 
# 33
T4 = void, class 
# 34
T5 = void, class 
# 35
T6 = void, class 
# 36
T7 = void, class 
# 37
T8 = void, class 
# 38
T9 = void, class 
# 39
T10 = void, class 
# 40
T11 = void, class 
# 41
T12 = void, class 
# 42
T13 = void, class 
# 43
T14 = void, class 
# 44
T15 = void, class 
# 45
T16 = void> 
# 46
struct unrelated_systems { }; 
# 51
template< class T1, class 
# 52
T2 = minimum_type_detail::any_conversion, class 
# 53
T3 = minimum_type_detail::any_conversion, class 
# 54
T4 = minimum_type_detail::any_conversion, class 
# 55
T5 = minimum_type_detail::any_conversion, class 
# 56
T6 = minimum_type_detail::any_conversion, class 
# 57
T7 = minimum_type_detail::any_conversion, class 
# 58
T8 = minimum_type_detail::any_conversion, class 
# 59
T9 = minimum_type_detail::any_conversion, class 
# 60
T10 = minimum_type_detail::any_conversion, class 
# 61
T11 = minimum_type_detail::any_conversion, class 
# 62
T12 = minimum_type_detail::any_conversion, class 
# 63
T13 = minimum_type_detail::any_conversion, class 
# 64
T14 = minimum_type_detail::any_conversion, class 
# 65
T15 = minimum_type_detail::any_conversion, class 
# 66
T16 = minimum_type_detail::any_conversion> 
# 67
struct minimum_system : public eval_if< is_metafunction_defined< minimum_type< T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16> > ::value, minimum_type< T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16> , identity_< unrelated_systems< T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16> > >  { 
# 77
}; 
# 80
}
# 81
}
# 26 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/type_traits.h"
namespace thrust { 
# 30
struct any_system_tag; 
# 32
namespace system { 
# 34
namespace detail { 
# 38
namespace generic_type_traits_ns { 
# 41
typedef char yes; 
# 42
typedef char (&no)[2]; 
# 44
struct any_conversion { 
# 46
template< class T> any_conversion(const T &); 
# 49
any_conversion(const any_system_tag &); 
# 50
}; 
# 52
namespace select_system_exists_ns { 
# 54
no select_system(const any_conversion &); 
# 55
no select_system(const any_conversion &, const any_conversion &); 
# 56
no select_system(const any_conversion &, const any_conversion &, const any_conversion &); 
# 57
no select_system(const any_conversion &, const any_conversion &, const any_conversion &, const any_conversion &); 
# 58
no select_system(const any_conversion &, const any_conversion &, const any_conversion &, const any_conversion &, const any_conversion &); 
# 59
no select_system(const any_conversion &, const any_conversion &, const any_conversion &, const any_conversion &, const any_conversion &, const any_conversion &); 
# 61
template< class T> yes check(const T &); 
# 63
no check(no); 
# 65
template< class Tag> 
# 66
struct select_system1_exists { 
# 68
static Tag &tag; 
# 70
static const bool value = (sizeof(check(select_system(tag))) == sizeof(yes)); 
# 71
}; 
# 73
template< class Tag1, class Tag2> 
# 74
struct select_system2_exists { 
# 76
static Tag1 &tag1; 
# 77
static Tag2 &tag2; 
# 79
static const bool value = (sizeof(check(select_system(tag1, tag2))) == sizeof(yes)); 
# 80
}; 
# 82
template< class Tag1, class Tag2, class Tag3> 
# 83
struct select_system3_exists { 
# 85
static Tag1 &tag1; 
# 86
static Tag2 &tag2; 
# 87
static Tag3 &tag3; 
# 89
static const bool value = (sizeof(check(select_system(tag1, tag2, tag3))) == sizeof(yes)); 
# 90
}; 
# 92
template< class Tag1, class Tag2, class Tag3, class Tag4> 
# 93
struct select_system4_exists { 
# 95
static Tag1 &tag1; 
# 96
static Tag2 &tag2; 
# 97
static Tag3 &tag3; 
# 98
static Tag4 &tag4; 
# 100
static const bool value = (sizeof(check(select_system(tag1, tag2, tag3, tag4))) == sizeof(yes)); 
# 101
}; 
# 103
template< class Tag1, class Tag2, class Tag3, class Tag4, class Tag5> 
# 104
struct select_system5_exists { 
# 106
static Tag1 &tag1; 
# 107
static Tag2 &tag2; 
# 108
static Tag3 &tag3; 
# 109
static Tag4 &tag4; 
# 110
static Tag5 &tag5; 
# 112
static const bool value = (sizeof(check(select_system(tag1, tag2, tag3, tag4, tag5))) == sizeof(yes)); 
# 113
}; 
# 115
template< class Tag1, class Tag2, class Tag3, class Tag4, class Tag5, class Tag6> 
# 116
struct select_system6_exists { 
# 118
static Tag1 &tag1; 
# 119
static Tag2 &tag2; 
# 120
static Tag3 &tag3; 
# 121
static Tag4 &tag4; 
# 122
static Tag5 &tag5; 
# 123
static Tag6 &tag6; 
# 125
static const bool value = (sizeof(check(select_system(tag1, tag2, tag3, tag4, tag5, tag6))) == sizeof(yes)); 
# 126
}; 
# 127
}
# 129
}
# 131
namespace generic { 
# 134
template< class Tag> 
# 135
struct select_system1_exists : public generic_type_traits_ns::select_system_exists_ns::select_system1_exists< Tag>  { 
# 137
}; 
# 139
template< class Tag1, class Tag2> 
# 140
struct select_system2_exists : public generic_type_traits_ns::select_system_exists_ns::select_system2_exists< Tag1, Tag2>  { 
# 142
}; 
# 144
template< class Tag1, class Tag2, class Tag3> 
# 145
struct select_system3_exists : public generic_type_traits_ns::select_system_exists_ns::select_system3_exists< Tag1, Tag2, Tag3>  { 
# 147
}; 
# 149
template< class Tag1, class Tag2, class Tag3, class Tag4> 
# 150
struct select_system4_exists : public generic_type_traits_ns::select_system_exists_ns::select_system4_exists< Tag1, Tag2, Tag3, Tag4>  { 
# 152
}; 
# 154
template< class Tag1, class Tag2, class Tag3, class Tag4, class Tag5> 
# 155
struct select_system5_exists : public generic_type_traits_ns::select_system_exists_ns::select_system5_exists< Tag1, Tag2, Tag3, Tag4, Tag5>  { 
# 157
}; 
# 159
template< class Tag1, class Tag2, class Tag3, class Tag4, class Tag5, class Tag6> 
# 160
struct select_system6_exists : public generic_type_traits_ns::select_system_exists_ns::select_system6_exists< Tag1, Tag2, Tag3, Tag4, Tag5, Tag6>  { 
# 162
}; 
# 164
}
# 165
}
# 166
}
# 167
}
# 27 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/select_system.h"
namespace thrust { 
# 29
namespace system { 
# 31
namespace detail { 
# 33
namespace generic { 
# 35
namespace select_system_detail { 
# 40
template< class System> System &
# 42
min_system(execution_policy< System>  &system1, execution_policy< System>  &) 
# 44
{ 
# 45
return thrust::detail::derived_cast(system1); 
# 46
} 
# 50
template< class System1, class System2> typename thrust::detail::enable_if< thrust::detail::is_same< System1, typename thrust::detail::minimum_system< System1, System2> ::type> ::value, System1 &> ::type 
# 59
min_system(execution_policy< System1>  &system1, execution_policy< System2>  &) 
# 60
{ 
# 61
return thrust::detail::derived_cast(system1); 
# 62
} 
# 66
template< class System1, class System2> typename thrust::detail::enable_if< thrust::detail::is_same< System2, typename thrust::detail::minimum_system< System1, System2> ::type> ::value, System2 &> ::type 
# 75
min_system(execution_policy< System1>  &, execution_policy< System2>  &system2) 
# 76
{ 
# 77
return thrust::detail::derived_cast(system2); 
# 78
} 
# 81
}
# 84
template< class System> typename thrust::detail::disable_if< select_system1_exists< System> ::value, System &> ::type 
# 90
select_system(execution_policy< System>  &system) 
# 91
{ 
# 92
return thrust::detail::derived_cast(system); 
# 93
} 
# 96
template< class System1, class System2> typename thrust::detail::enable_if_defined< thrust::detail::minimum_system< System1, System2> > ::type &
# 101
select_system(execution_policy< System1>  &system1, execution_policy< System2>  &
# 102
system2) 
# 103
{ 
# 104
return select_system_detail::min_system(system1, system2); 
# 105
} 
# 108
template< class System1, class System2, class System3> typename thrust::detail::lazy_disable_if< select_system3_exists< System1, System2, System3> ::value, thrust::detail::minimum_system< System1, System2, System3> > ::type &
# 114
select_system(execution_policy< System1>  &system1, execution_policy< System2>  &
# 115
system2, execution_policy< System3>  &
# 116
system3) 
# 117
{ 
# 118
return select_system(select_system(system1, system2), system3); 
# 119
} 
# 122
template< class System1, class System2, class System3, class System4> typename thrust::detail::lazy_disable_if< select_system4_exists< System1, System2, System3, System4> ::value, thrust::detail::minimum_system< System1, System2, System3, System4> > ::type &
# 128
select_system(execution_policy< System1>  &system1, execution_policy< System2>  &
# 129
system2, execution_policy< System3>  &
# 130
system3, execution_policy< System4>  &
# 131
system4) 
# 132
{ 
# 133
return select_system(select_system(system1, system2, system3), system4); 
# 134
} 
# 137
template< class System1, class System2, class System3, class System4, class System5> typename thrust::detail::lazy_disable_if< select_system5_exists< System1, System2, System3, System4, System5> ::value, thrust::detail::minimum_system< System1, System2, System3, System4, System5> > ::type &
# 143
select_system(execution_policy< System1>  &system1, execution_policy< System2>  &
# 144
system2, execution_policy< System3>  &
# 145
system3, execution_policy< System4>  &
# 146
system4, execution_policy< System5>  &
# 147
system5) 
# 148
{ 
# 149
return select_system(select_system(system1, system2, system3, system4), system5); 
# 150
} 
# 153
template< class System1, class System2, class System3, class System4, class System5, class System6> typename thrust::detail::lazy_disable_if< select_system6_exists< System1, System2, System3, System4, System5, System6> ::value, thrust::detail::minimum_system< System1, System2, System3, System4, System5, System6> > ::type &
# 159
select_system(execution_policy< System1>  &system1, execution_policy< System2>  &
# 160
system2, execution_policy< System3>  &
# 161
system3, execution_policy< System4>  &
# 162
system4, execution_policy< System5>  &
# 163
system5, execution_policy< System6>  &
# 164
system6) 
# 165
{ 
# 166
return select_system(select_system(system1, system2, system3, system4, system5), system6); 
# 167
} 
# 172
inline device_system_tag select_system(any_system_tag) 
# 173
{ 
# 174
return device_system_tag(); 
# 175
} 
# 178
}
# 179
}
# 180
}
# 181
}
# 26 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/tag.h"
namespace thrust { 
# 28
namespace system { 
# 30
namespace detail { 
# 32
namespace generic { 
# 37
struct tag { 
# 39
template< class T> 
# 41
tag(const T &) { } 
# 42
}; 
# 44
}
# 45
}
# 46
}
# 47
}
# 22 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/copy.h"
namespace thrust { 
# 24
namespace system { 
# 26
namespace detail { 
# 28
namespace generic { 
# 32
template< class DerivedPolicy, class 
# 33
InputIterator, class 
# 34
OutputIterator> OutputIterator 
# 32
copy(execution_policy< DerivedPolicy>  & exec, InputIterator first, InputIterator last, OutputIterator result); 
# 42
template< class DerivedPolicy, class 
# 43
InputIterator, class 
# 44
Size, class 
# 45
OutputIterator> OutputIterator 
# 42
copy_n(execution_policy< DerivedPolicy>  & exec, InputIterator first, Size n, OutputIterator result); 
# 53
}
# 54
}
# 55
}
# 56
}
# 20 "/usr/local/cuda-8.0/include/thrust/detail/tuple.inl"
namespace thrust { 
# 24
struct null_type { }; 
# 28
inline bool operator==(const null_type &, const null_type &) { return true; } 
# 31
inline bool operator>=(const null_type &, const null_type &) { return true; } 
# 34
inline bool operator<=(const null_type &, const null_type &) { return true; } 
# 37
inline bool operator!=(const null_type &, const null_type &) { return false; } 
# 40
inline bool operator<(const null_type &, const null_type &) { return false; } 
# 43
inline bool operator>(const null_type &, const null_type &) { return false; } 
# 46
template< class 
# 47
T0 = null_type, class T1 = null_type, class T2 = null_type, class 
# 48
T3 = null_type, class T4 = null_type, class T5 = null_type, class 
# 49
T6 = null_type, class T7 = null_type, class T8 = null_type, class 
# 50
T9 = null_type> class tuple; 
# 54
template< int i, class T> struct tuple_element; 
# 57
template< class T> 
# 58
struct tuple_element< 0, T>  { 
# 60
typedef typename T::head_type type; 
# 61
}; 
# 63
template< int N, class T> 
# 64
struct tuple_element< N, const T>  { 
# 67
private: typedef typename T::tail_type Next; 
# 68
typedef typename thrust::tuple_element< N - 1, typename T::tail_type> ::type unqualified_type; 
# 71
public: typedef typename detail::add_const< typename thrust::tuple_element< N - 1, typename T::tail_type> ::type> ::type type; 
# 72
}; 
# 74
template< class T> 
# 75
struct tuple_element< 0, const T>  { 
# 77
typedef typename detail::add_const< typename T::head_type> ::type type; 
# 78
}; 
# 83
template< class T> struct tuple_size; 
# 87
template<> struct tuple_size< tuple<> >  { 
# 89
static const int value = 0; 
# 90
}; 
# 93
template<> struct tuple_size< null_type>  { 
# 95
static const int value = 0; 
# 96
}; 
# 101
namespace detail { 
# 104
template< class HT, class TT> struct cons; 
# 106
}
# 110
template< class T> struct access_traits { 
# 112
typedef const T &const_type; 
# 113
typedef T &non_const_type; 
# 115
typedef const typename detail::remove_cv< T> ::type &parameter_type; 
# 122
}; 
# 124
template< class T> struct access_traits< T &>  { 
# 126
typedef T &const_type; 
# 127
typedef T &non_const_type; 
# 129
typedef T &parameter_type; 
# 130
}; 
# 133
template< int N, class HT, class TT> inline typename access_traits< typename tuple_element< N, detail::cons< HT, TT> > ::type> ::non_const_type get(detail::cons< HT, TT>  & c); 
# 142
template< int N, class HT, class TT> inline typename access_traits< typename tuple_element< N, detail::cons< HT, TT> > ::type> ::const_type get(const detail::cons< HT, TT>  & c); 
# 151
namespace detail { 
# 156
template< class T> class generate_error; 
# 162
template< int N> 
# 163
struct get_class { 
# 165
template< class RET, class HT, class TT> static RET 
# 167
get(const cons< HT, TT>  &t) 
# 168
{ 
# 171
return detail::get_class< N - 1> ::template get< RET> ((t.tail)); 
# 175
} 
# 177
template< class RET, class HT, class TT> static RET 
# 179
get(cons< HT, TT>  &t) 
# 180
{ 
# 183
return detail::get_class< N - 1> ::template get< RET> ((t.tail)); 
# 187
} 
# 188
}; 
# 191
template<> struct get_class< 0>  { 
# 193
template< class RET, class HT, class TT> static RET 
# 195
get(const cons< HT, TT>  &t) 
# 196
{ 
# 197
return t.head; 
# 198
} 
# 200
template< class RET, class HT, class TT> static RET 
# 202
get(cons< HT, TT>  &t) 
# 203
{ 
# 204
return t.head; 
# 205
} 
# 206
}; 
# 209
template< bool If, class Then, class Else> struct IF { 
# 211
typedef Then RET; 
# 212
}; 
# 214
template< class Then, class Else> struct IF< false, Then, Else>  { 
# 216
typedef Else RET; 
# 217
}; 
# 225
template< class T> class non_storeable_type { 
# 228
non_storeable_type(); 
# 229
}; 
# 231
template< class T> struct wrap_non_storeable_type { 
# 238
typedef T type; 
# 239
}; 
# 241
template<> struct wrap_non_storeable_type< void>  { 
# 243
typedef non_storeable_type< void>  type; 
# 244
}; 
# 247
template< class HT, class TT> 
# 248
struct cons { 
# 250
typedef HT head_type; 
# 251
typedef TT tail_type; 
# 254
typedef typename wrap_non_storeable_type< HT> ::type stored_head_type; 
# 256
stored_head_type head; 
# 257
tail_type tail; 
# 261
typename access_traits< typename wrap_non_storeable_type< HT> ::type> ::non_const_type get_head() { return head; } 
# 265
typename access_traits< TT> ::non_const_type get_tail() { return tail; } 
# 269
typename access_traits< typename wrap_non_storeable_type< HT> ::type> ::const_type get_head() const { return head; } 
# 273
typename access_traits< TT> ::const_type get_tail() const { return tail; } 
# 276
cons() : head(), tail() { } 
# 285
cons(typename access_traits< typename wrap_non_storeable_type< HT> ::type> ::parameter_type h, const tail_type &
# 286
t) : head(h), tail(t) 
# 287
{ } 
# 289
template< class T1, class T2, class T3, class T4, class T5, class 
# 290
T6, class T7, class T8, class T9, class T10> 
# 292
cons(T1 &t1, T2 &t2, T3 &t3, T4 &t4, T5 &t5, T6 &
# 293
t6, T7 &t7, T8 &t8, T9 &t9, T10 &t10) : head(t1), tail(t2, t3, t4, t5, t6, t7, t8, t9, t10, static_cast< const null_type &>(null_type())) 
# 296
{ } 
# 298
template< class T2, class T3, class T4, class T5, class 
# 299
T6, class T7, class T8, class T9, class T10> 
# 301
cons(const null_type &, T2 &t2, T3 &t3, T4 &t4, T5 &t5, T6 &
# 302
t6, T7 &t7, T8 &t8, T9 &t9, T10 &t10) : head(), tail(t2, t3, t4, t5, t6, t7, t8, t9, t10, static_cast< const null_type &>(null_type())) 
# 305
{ } 
# 308
template< class HT2, class TT2> 
# 310
cons(const detail::cons< HT2, TT2>  &u) : head((u.head)), tail((u.tail)) { } 
# 312
template< class HT2, class TT2> cons &
# 314
operator=(const detail::cons< HT2, TT2>  &u) { 
# 315
(head) = (u.head); (tail) = (u.tail); return *this; 
# 316
} 
# 321
cons &operator=(const cons &u) { 
# 322
(head) = (u.head); (tail) = (u.tail); return *this; 
# 323
} 
# 334
template< int N> typename access_traits< typename tuple_element< N, cons> ::type> ::non_const_type 
# 339
get() { 
# 340
return thrust::get< N> (*this); 
# 341
} 
# 343
template< int N> typename access_traits< typename tuple_element< N, cons> ::type> ::const_type 
# 348
get() const { 
# 349
return thrust::get< N> (*this); 
# 350
} 
# 353
void swap(cons &c) 
# 354
{ 
# 355
using thrust::swap;
# 357
swap(head, c.head); 
# 358
((tail).swap(c.tail)); 
# 359
} 
# 360
}; 
# 362
template< class HT> 
# 363
struct cons< HT, null_type>  { 
# 365
typedef HT head_type; 
# 366
typedef null_type tail_type; 
# 367
typedef detail::cons< HT, null_type>  self_type; 
# 370
typedef typename wrap_non_storeable_type< HT> ::type stored_head_type; 
# 371
stored_head_type head; 
# 375
typename access_traits< typename wrap_non_storeable_type< HT> ::type> ::non_const_type get_head() { return head; } 
# 378
null_type get_tail() { return null_type(); } 
# 382
typename access_traits< typename wrap_non_storeable_type< HT> ::type> ::const_type get_head() const { return head; } 
# 385
null_type get_tail() const { return null_type(); } 
# 388
cons() : head() { } 
# 391
cons(typename access_traits< typename wrap_non_storeable_type< HT> ::type> ::parameter_type h, const null_type & = null_type()) : head(h) 
# 393
{ } 
# 395
template< class T1> 
# 397
cons(T1 &t1, const null_type &, const null_type &, const null_type &, const null_type &, const null_type &, const null_type &, const null_type &, const null_type &, const null_type &) : head(t1) 
# 400
{ } 
# 403
cons(const null_type &, const null_type &, const null_type &, const null_type &, const null_type &, const null_type &, const null_type &, const null_type &, const null_type &, const null_type &) : head() 
# 407
{ } 
# 409
template< class HT2> 
# 411
cons(const detail::cons< HT2, null_type>  &u) : head((u.head)) { } 
# 413
template< class HT2> detail::cons< HT, null_type>  &
# 415
operator=(const detail::cons< HT2, null_type>  &u) 
# 416
{ 
# 417
(head) = (u.head); 
# 418
return *this; 
# 419
} 
# 424
detail::cons< HT, null_type>  &operator=(const detail::cons< HT, null_type>  &u) { (head) = (u.head); return *this; } 
# 426
template< int N> typename access_traits< typename tuple_element< N, detail::cons< HT, null_type> > ::type> ::non_const_type 
# 433
get() 
# 434
{ 
# 435
return thrust::get< N> (*this); 
# 436
} 
# 438
template< int N> typename access_traits< typename tuple_element< N, detail::cons< HT, null_type> > ::type> ::const_type 
# 445
get() const 
# 446
{ 
# 447
return thrust::get< N> (*this); 
# 448
} 
# 451
void swap(detail::cons< HT, null_type>  &c) 
# 452
{ 
# 453
using thrust::swap;
# 455
swap(head, c.head); 
# 456
} 
# 457
}; 
# 459
template< class T0, class T1, class T2, class T3, class T4, class 
# 460
T5, class T6, class T7, class T8, class T9> 
# 461
struct map_tuple_to_cons { 
# 466
typedef cons< T0, typename detail::map_tuple_to_cons< T1, T2, T3, T4, T5, T6, T7, T8, T9, null_type> ::type>  type; 
# 467
}; 
# 471
template<> struct map_tuple_to_cons< null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type>  { 
# 473
typedef null_type type; 
# 474
}; 
# 492
template< class T> 
# 493
struct make_tuple_traits { 
# 494
typedef T type; 
# 502
}; 
# 516
template< class T> 
# 517
struct make_tuple_traits< T &>  { 
# 520
typedef typename generate_error< T &> ::do_not_use_with_reference_type error; 
# 521
}; 
# 527
template< class T, int n> struct make_tuple_traits< T [n]>  { 
# 528
typedef const T (&type)[n]; 
# 529
}; 
# 531
template< class T, int n> 
# 532
struct make_tuple_traits< const T [n]>  { 
# 533
typedef const T (&type)[n]; 
# 534
}; 
# 536
template< class T, int n> struct make_tuple_traits< volatile T [n]>  { 
# 537
typedef const volatile T (&type)[n]; 
# 538
}; 
# 540
template< class T, int n> 
# 541
struct make_tuple_traits< const volatile T [n]>  { 
# 542
typedef const volatile T (&type)[n]; 
# 543
}; 
# 559
template< class 
# 560
T0 = null_type, class T1 = null_type, class T2 = null_type, class 
# 561
T3 = null_type, class T4 = null_type, class T5 = null_type, class 
# 562
T6 = null_type, class T7 = null_type, class T8 = null_type, class 
# 563
T9 = null_type> 
# 565
struct make_tuple_mapper { 
# 576
typedef tuple< typename make_tuple_traits< T0> ::type, typename make_tuple_traits< T1> ::type, typename make_tuple_traits< T2> ::type, typename make_tuple_traits< T3> ::type, typename make_tuple_traits< T4> ::type, typename make_tuple_traits< T5> ::type, typename make_tuple_traits< T6> ::type, typename make_tuple_traits< T7> ::type, typename make_tuple_traits< T8> ::type, typename make_tuple_traits< T9> ::type>  type; 
# 577
}; 
# 579
}
# 582
template< int N, class HT, class TT> inline typename access_traits< typename tuple_element< N, detail::cons< HT, TT> > ::type> ::non_const_type 
# 587
get(detail::cons< HT, TT>  &c) 
# 588
{ 
# 594
return detail::get_class< N> ::template get< typename access_traits< typename tuple_element< N, detail::cons< HT, TT> > ::type> ::non_const_type, HT, TT> (c); 
# 601
} 
# 607
template< int N, class HT, class TT> inline typename access_traits< typename tuple_element< N, detail::cons< HT, TT> > ::type> ::const_type 
# 612
get(const detail::cons< HT, TT>  &c) 
# 613
{ 
# 619
return detail::get_class< N> ::template get< typename access_traits< typename tuple_element< N, detail::cons< HT, TT> > ::type> ::const_type, HT, TT> (c); 
# 626
} 
# 629
template< class T0> inline typename detail::make_tuple_mapper< T0> ::type 
# 632
make_tuple(const T0 &t0) 
# 633
{ 
# 634
typedef typename detail::make_tuple_mapper< T0> ::type t; 
# 635
return (t)t0; 
# 636
} 
# 638
template< class T0, class T1> inline typename detail::make_tuple_mapper< T0, T1> ::type 
# 641
make_tuple(const T0 &t0, const T1 &t1) 
# 642
{ 
# 643
typedef typename detail::make_tuple_mapper< T0, T1> ::type t; 
# 644
return t(t0, t1); 
# 645
} 
# 647
template< class T0, class T1, class T2> inline typename detail::make_tuple_mapper< T0, T1, T2> ::type 
# 650
make_tuple(const T0 &t0, const T1 &t1, const T2 &t2) 
# 651
{ 
# 652
typedef typename detail::make_tuple_mapper< T0, T1, T2> ::type t; 
# 653
return t(t0, t1, t2); 
# 654
} 
# 656
template< class T0, class T1, class T2, class T3> inline typename detail::make_tuple_mapper< T0, T1, T2, T3> ::type 
# 659
make_tuple(const T0 &t0, const T1 &t1, const T2 &t2, const T3 &t3) 
# 660
{ 
# 661
typedef typename detail::make_tuple_mapper< T0, T1, T2, T3> ::type t; 
# 662
return t(t0, t1, t2, t3); 
# 663
} 
# 665
template< class T0, class T1, class T2, class T3, class T4> inline typename detail::make_tuple_mapper< T0, T1, T2, T3, T4> ::type 
# 668
make_tuple(const T0 &t0, const T1 &t1, const T2 &t2, const T3 &t3, const T4 &t4) 
# 669
{ 
# 670
typedef typename detail::make_tuple_mapper< T0, T1, T2, T3, T4> ::type t; 
# 671
return t(t0, t1, t2, t3, t4); 
# 672
} 
# 674
template< class T0, class T1, class T2, class T3, class T4, class T5> inline typename detail::make_tuple_mapper< T0, T1, T2, T3, T4, T5> ::type 
# 677
make_tuple(const T0 &t0, const T1 &t1, const T2 &t2, const T3 &t3, const T4 &t4, const T5 &t5) 
# 678
{ 
# 679
typedef typename detail::make_tuple_mapper< T0, T1, T2, T3, T4, T5> ::type t; 
# 680
return t(t0, t1, t2, t3, t4, t5); 
# 681
} 
# 683
template< class T0, class T1, class T2, class T3, class T4, class T5, class T6> inline typename detail::make_tuple_mapper< T0, T1, T2, T3, T4, T5, T6> ::type 
# 686
make_tuple(const T0 &t0, const T1 &t1, const T2 &t2, const T3 &t3, const T4 &t4, const T5 &t5, const T6 &t6) 
# 687
{ 
# 688
typedef typename detail::make_tuple_mapper< T0, T1, T2, T3, T4, T5, T6> ::type t; 
# 689
return t(t0, t1, t2, t3, t4, t5, t6); 
# 690
} 
# 692
template< class T0, class T1, class T2, class T3, class T4, class T5, class T6, class T7> inline typename detail::make_tuple_mapper< T0, T1, T2, T3, T4, T5, T6, T7> ::type 
# 695
make_tuple(const T0 &t0, const T1 &t1, const T2 &t2, const T3 &t3, const T4 &t4, const T5 &t5, const T6 &t6, const T7 &t7) 
# 696
{ 
# 697
typedef typename detail::make_tuple_mapper< T0, T1, T2, T3, T4, T5, T6, T7> ::type t; 
# 698
return t(t0, t1, t2, t3, t4, t5, t6, t7); 
# 699
} 
# 701
template< class T0, class T1, class T2, class T3, class T4, class T5, class T6, class T7, class T8> inline typename detail::make_tuple_mapper< T0, T1, T2, T3, T4, T5, T6, T7, T8> ::type 
# 704
make_tuple(const T0 &t0, const T1 &t1, const T2 &t2, const T3 &t3, const T4 &t4, const T5 &t5, const T6 &t6, const T7 &t7, const T8 &t8) 
# 705
{ 
# 706
typedef typename detail::make_tuple_mapper< T0, T1, T2, T3, T4, T5, T6, T7, T8> ::type t; 
# 707
return t(t0, t1, t2, t3, t4, t5, t6, t7, t8); 
# 708
} 
# 710
template< class T0, class T1, class T2, class T3, class T4, class T5, class T6, class T7, class T8, class T9> inline typename detail::make_tuple_mapper< T0, T1, T2, T3, T4, T5, T6, T7, T8, T9> ::type 
# 713
make_tuple(const T0 &t0, const T1 &t1, const T2 &t2, const T3 &t3, const T4 &t4, const T5 &t5, const T6 &t6, const T7 &t7, const T8 &t8, const T9 &t9) 
# 714
{ 
# 715
typedef typename detail::make_tuple_mapper< T0, T1, T2, T3, T4, T5, T6, T7, T8, T9> ::type t; 
# 716
return t(t0, t1, t2, t3, t4, t5, t6, t7, t8, t9); 
# 717
} 
# 720
template< class T0> inline tuple< T0 &>  
# 722
tie(T0 &t0) 
# 723
{ 
# 724
return ((tuple< T0 &> )(t0)); 
# 725
} 
# 727
template< class T0, class T1> inline tuple< T0 &, T1 &>  
# 729
tie(T0 &t0, T1 &t1) 
# 730
{ 
# 731
return tuple< T0 &, T1 &> (t0, t1); 
# 732
} 
# 734
template< class T0, class T1, class T2> inline tuple< T0 &, T1 &, T2 &>  
# 736
tie(T0 &t0, T1 &t1, T2 &t2) 
# 737
{ 
# 738
return tuple< T0 &, T1 &, T2 &> (t0, t1, t2); 
# 739
} 
# 741
template< class T0, class T1, class T2, class T3> inline tuple< T0 &, T1 &, T2 &, T3 &>  
# 743
tie(T0 &t0, T1 &t1, T2 &t2, T3 &t3) 
# 744
{ 
# 745
return tuple< T0 &, T1 &, T2 &, T3 &> (t0, t1, t2, t3); 
# 746
} 
# 748
template< class T0, class T1, class T2, class T3, class T4> inline tuple< T0 &, T1 &, T2 &, T3 &, T4 &>  
# 750
tie(T0 &t0, T1 &t1, T2 &t2, T3 &t3, T4 &t4) 
# 751
{ 
# 752
return tuple< T0 &, T1 &, T2 &, T3 &, T4 &> (t0, t1, t2, t3, t4); 
# 753
} 
# 755
template< class T0, class T1, class T2, class T3, class T4, class T5> inline tuple< T0 &, T1 &, T2 &, T3 &, T4 &, T5 &>  
# 757
tie(T0 &t0, T1 &t1, T2 &t2, T3 &t3, T4 &t4, T5 &t5) 
# 758
{ 
# 759
return tuple< T0 &, T1 &, T2 &, T3 &, T4 &, T5 &> (t0, t1, t2, t3, t4, t5); 
# 760
} 
# 762
template< class T0, class T1, class T2, class T3, class T4, class T5, class T6> inline tuple< T0 &, T1 &, T2 &, T3 &, T4 &, T5 &, T6 &>  
# 764
tie(T0 &t0, T1 &t1, T2 &t2, T3 &t3, T4 &t4, T5 &t5, T6 &t6) 
# 765
{ 
# 766
return tuple< T0 &, T1 &, T2 &, T3 &, T4 &, T5 &, T6 &> (t0, t1, t2, t3, t4, t5, t6); 
# 767
} 
# 769
template< class T0, class T1, class T2, class T3, class T4, class T5, class T6, class T7> inline tuple< T0 &, T1 &, T2 &, T3 &, T4 &, T5 &, T6 &, T7 &>  
# 771
tie(T0 &t0, T1 &t1, T2 &t2, T3 &t3, T4 &t4, T5 &t5, T6 &t6, T7 &t7) 
# 772
{ 
# 773
return tuple< T0 &, T1 &, T2 &, T3 &, T4 &, T5 &, T6 &, T7 &> (t0, t1, t2, t3, t4, t5, t6, t7); 
# 774
} 
# 776
template< class T0, class T1, class T2, class T3, class T4, class T5, class T6, class T7, class T8> inline tuple< T0 &, T1 &, T2 &, T3 &, T4 &, T5 &, T6 &, T7 &, T8 &>  
# 778
tie(T0 &t0, T1 &t1, T2 &t2, T3 &t3, T4 &t4, T5 &t5, T6 &t6, T7 &t7, T8 &t8) 
# 779
{ 
# 780
return tuple< T0 &, T1 &, T2 &, T3 &, T4 &, T5 &, T6 &, T7 &, T8 &> (t0, t1, t2, t3, t4, t5, t6, t7, t8); 
# 781
} 
# 783
template< class T0, class T1, class T2, class T3, class T4, class T5, class T6, class T7, class T8, class T9> inline tuple< T0 &, T1 &, T2 &, T3 &, T4 &, T5 &, T6 &, T7 &, T8 &, T9 &>  
# 785
tie(T0 &t0, T1 &t1, T2 &t2, T3 &t3, T4 &t4, T5 &t5, T6 &t6, T7 &t7, T8 &t8, T9 &t9) 
# 786
{ 
# 787
return tuple< T0 &, T1 &, T2 &, T3 &, T4 &, T5 &, T6 &, T7 &, T8 &, T9 &> (t0, t1, t2, t3, t4, t5, t6, t7, t8, t9); 
# 788
} 
# 790
template< class 
# 791
T0, class T1, class T2, class T3, class T4, class T5, class T6, class T7, class T8, class T9, class 
# 792
U0, class U1, class U2, class U3, class U4, class U5, class U6, class U7, class U8, class U9> inline void 
# 795
swap(tuple< T0, T1, T2, T3, T4, T5, T6, T7, T8, T9>  &x, tuple< U0, U1, U2, U3, U4, U5, U6, U7, U8, U9>  &
# 796
y) 
# 797
{ 
# 798
return (x.swap(y)); 
# 799
} 
# 803
namespace detail { 
# 806
template< class T1, class T2> inline bool 
# 808
eq(const T1 &lhs, const T2 &rhs) { 
# 809
return ((lhs.get_head()) == (rhs.get_head())) && eq((lhs.get_tail()), (rhs.get_tail())); 
# 811
} 
# 813
template<> inline bool eq< null_type, null_type> (const null_type &, const null_type &) { return true; } 
# 815
template< class T1, class T2> inline bool 
# 817
neq(const T1 &lhs, const T2 &rhs) { 
# 818
return ((lhs.get_head()) != (rhs.get_head())) || neq((lhs.get_tail()), (rhs.get_tail())); 
# 820
} 
# 823
template<> inline bool neq< null_type, null_type> (const null_type &, const null_type &) { return false; } 
# 825
template< class T1, class T2> inline bool 
# 827
lt(const T1 &lhs, const T2 &rhs) { 
# 828
return ((lhs.get_head()) < (rhs.get_head())) || ((!((rhs.get_head()) < (lhs.get_head()))) && lt((lhs.get_tail()), (rhs.get_tail()))); 
# 831
} 
# 834
template<> inline bool lt< null_type, null_type> (const null_type &, const null_type &) { return false; } 
# 836
template< class T1, class T2> inline bool 
# 838
gt(const T1 &lhs, const T2 &rhs) { 
# 839
return ((lhs.get_head()) > (rhs.get_head())) || ((!((rhs.get_head()) > (lhs.get_head()))) && gt((lhs.get_tail()), (rhs.get_tail()))); 
# 842
} 
# 845
template<> inline bool gt< null_type, null_type> (const null_type &, const null_type &) { return false; } 
# 847
template< class T1, class T2> inline bool 
# 849
lte(const T1 &lhs, const T2 &rhs) { 
# 850
return ((lhs.get_head()) <= (rhs.get_head())) && ((!((rhs.get_head()) <= (lhs.get_head()))) || lte((lhs.get_tail()), (rhs.get_tail()))); 
# 853
} 
# 856
template<> inline bool lte< null_type, null_type> (const null_type &, const null_type &) { return true; } 
# 858
template< class T1, class T2> inline bool 
# 860
gte(const T1 &lhs, const T2 &rhs) { 
# 861
return ((lhs.get_head()) >= (rhs.get_head())) && ((!((rhs.get_head()) >= (lhs.get_head()))) || gte((lhs.get_tail()), (rhs.get_tail()))); 
# 864
} 
# 867
template<> inline bool gte< null_type, null_type> (const null_type &, const null_type &) { return true; } 
# 869
}
# 875
template< class T1, class T2, class S1, class S2> inline bool 
# 877
operator==(const detail::cons< T1, T2>  &lhs, const detail::cons< S1, S2>  &rhs) 
# 878
{ 
# 883
return detail::eq(lhs, rhs); 
# 884
} 
# 888
template< class T1, class T2, class S1, class S2> inline bool 
# 890
operator!=(const detail::cons< T1, T2>  &lhs, const detail::cons< S1, S2>  &rhs) 
# 891
{ 
# 896
return detail::neq(lhs, rhs); 
# 897
} 
# 900
template< class T1, class T2, class S1, class S2> inline bool 
# 902
operator<(const detail::cons< T1, T2>  &lhs, const detail::cons< S1, S2>  &rhs) 
# 903
{ 
# 908
return detail::lt(lhs, rhs); 
# 909
} 
# 912
template< class T1, class T2, class S1, class S2> inline bool 
# 914
operator>(const detail::cons< T1, T2>  &lhs, const detail::cons< S1, S2>  &rhs) 
# 915
{ 
# 920
return detail::gt(lhs, rhs); 
# 921
} 
# 924
template< class T1, class T2, class S1, class S2> inline bool 
# 926
operator<=(const detail::cons< T1, T2>  &lhs, const detail::cons< S1, S2>  &rhs) 
# 927
{ 
# 932
return detail::lte(lhs, rhs); 
# 933
} 
# 936
template< class T1, class T2, class S1, class S2> inline bool 
# 938
operator>=(const detail::cons< T1, T2>  &lhs, const detail::cons< S1, S2>  &rhs) 
# 939
{ 
# 944
return detail::gte(lhs, rhs); 
# 945
} 
# 947
}
# 67 "/usr/include/c++/4.8.2/bits/stl_relops.h" 3
namespace std __attribute((__visibility__("default"))) { 
# 69
namespace rel_ops { 
# 85
template< class _Tp> inline bool 
# 87
operator!=(const _Tp &__x, const _Tp &__y) 
# 88
{ return !(__x == __y); } 
# 98
template< class _Tp> inline bool 
# 100
operator>(const _Tp &__x, const _Tp &__y) 
# 101
{ return __y < __x; } 
# 111
template< class _Tp> inline bool 
# 113
operator<=(const _Tp &__x, const _Tp &__y) 
# 114
{ return !(__y < __x); } 
# 124
template< class _Tp> inline bool 
# 126
operator>=(const _Tp &__x, const _Tp &__y) 
# 127
{ return !(__x < __y); } 
# 130
}
# 132
}
# 26 "/usr/local/cuda-8.0/include/thrust/pair.h"
namespace thrust { 
# 48
template< class T1, class T2> 
# 49
struct pair { 
# 53
typedef T1 first_type; 
# 57
typedef T2 second_type; 
# 61
first_type first; 
# 65
second_type second; 
# 71
pair(); 
# 79
inline pair(const T1 & x, const T2 & y); 
# 90
template< class U1, class U2> inline pair(const thrust::pair< U1, U2>  & p); 
# 103
template< class U1, class U2> inline pair(const std::pair< U1, U2>  & p); 
# 112
inline void swap(pair & p); 
# 113
}; 
# 125
template< class T1, class T2> inline bool operator==(const pair< T1, T2>  & x, const pair< T1, T2>  & y); 
# 139
template< class T1, class T2> inline bool operator<(const pair< T1, T2>  & x, const pair< T1, T2>  & y); 
# 153
template< class T1, class T2> inline bool operator!=(const pair< T1, T2>  & x, const pair< T1, T2>  & y); 
# 167
template< class T1, class T2> inline bool operator>(const pair< T1, T2>  & x, const pair< T1, T2>  & y); 
# 181
template< class T1, class T2> inline bool operator<=(const pair< T1, T2>  & x, const pair< T1, T2>  & y); 
# 195
template< class T1, class T2> inline bool operator>=(const pair< T1, T2>  & x, const pair< T1, T2>  & y); 
# 205
template< class T1, class T2> inline void swap(pair< T1, T2>  & x, pair< T1, T2>  & y); 
# 219
template< class T1, class T2> inline pair< T1, T2>  make_pair(T1 x, T2 y); 
# 231
template< int N, class T> struct tuple_element; 
# 240
template< class Pair> struct tuple_size; 
# 280
}
# 20 "/usr/local/cuda-8.0/include/thrust/detail/pair.inl"
namespace thrust { 
# 23
template< class T1, class T2> 
# 25
pair< T1, T2> ::pair() : first(), second() 
# 27
{ 
# 28
; 
# 29
} 
# 32
template< class T1, class T2> inline 
# 34
pair< T1, T2> ::pair(const T1 &x, const T2 &y) : first(x), second(y) 
# 36
{ 
# 37
; 
# 38
} 
# 41
template< class T1, class T2> 
# 42
template< class U1, class U2> inline 
# 44
pair< T1, T2> ::pair(const thrust::pair< U1, U2>  &p) : first((p.first)), second((p.second)) 
# 46
{ 
# 47
; 
# 48
} 
# 51
template< class T1, class T2> 
# 52
template< class U1, class U2> inline 
# 54
pair< T1, T2> ::pair(const std::pair< U1, U2>  &p) : first((p.first)), second((p.second)) 
# 56
{ 
# 57
; 
# 58
} 
# 61
template< class T1, class T2> inline void 
# 64
pair< T1, T2> ::swap(pair &p) 
# 65
{ 
# 66
using thrust::swap;
# 68
swap(first, p.first); 
# 69
swap(second, p.second); 
# 70
} 
# 73
template< class T1, class T2> inline bool 
# 75
operator==(const pair< T1, T2>  &x, const pair< T1, T2>  &y) 
# 76
{ 
# 77
return ((x.first) == (y.first)) && ((x.second) == (y.second)); 
# 78
} 
# 81
template< class T1, class T2> inline bool 
# 83
operator<(const pair< T1, T2>  &x, const pair< T1, T2>  &y) 
# 84
{ 
# 85
return ((x.first) < (y.first)) || ((!((y.first) < (x.first))) && ((x.second) < (y.second))); 
# 86
} 
# 89
template< class T1, class T2> inline bool 
# 91
operator!=(const pair< T1, T2>  &x, const pair< T1, T2>  &y) 
# 92
{ 
# 93
return !(x == y); 
# 94
} 
# 97
template< class T1, class T2> inline bool 
# 99
operator>(const pair< T1, T2>  &x, const pair< T1, T2>  &y) 
# 100
{ 
# 101
return y < x; 
# 102
} 
# 105
template< class T1, class T2> inline bool 
# 107
operator<=(const pair< T1, T2>  &x, const pair< T1, T2>  &y) 
# 108
{ 
# 109
return !(y < x); 
# 110
} 
# 113
template< class T1, class T2> inline bool 
# 115
operator>=(const pair< T1, T2>  &x, const pair< T1, T2>  &y) 
# 116
{ 
# 117
return !(x < y); 
# 118
} 
# 121
template< class T1, class T2> inline void 
# 123
swap(pair< T1, T2>  &x, pair< T1, T2>  &y) 
# 124
{ 
# 125
return (x.swap(y)); 
# 126
} 
# 129
template< class T1, class T2> inline pair< T1, T2>  
# 131
make_pair(T1 x, T2 y) 
# 132
{ 
# 133
return pair< T1, T2> (x, y); 
# 134
} 
# 138
template< class T1, class T2> 
# 139
struct tuple_element< 0, pair< T1, T2> >  { 
# 141
typedef T1 type; 
# 142
}; 
# 144
template< class T1, class T2> 
# 145
struct tuple_element< 1, pair< T1, T2> >  { 
# 147
typedef T2 type; 
# 148
}; 
# 152
template< class T1, class T2> 
# 153
struct tuple_size< pair< T1, T2> >  { 
# 155
static const unsigned value = (2); 
# 156
}; 
# 160
namespace detail { 
# 164
template< int N, class Pair> struct pair_get { }; 
# 166
template< class Pair> 
# 167
struct pair_get< 0, Pair>  { 
# 171
const typename tuple_element< 0, Pair> ::type &operator()(const Pair &p) const 
# 172
{ 
# 173
return p.first; 
# 174
} 
# 178
typename tuple_element< 0, Pair> ::type &operator()(Pair &p) const 
# 179
{ 
# 180
return p.first; 
# 181
} 
# 182
}; 
# 185
template< class Pair> 
# 186
struct pair_get< 1, Pair>  { 
# 190
const typename tuple_element< 1, Pair> ::type &operator()(const Pair &p) const 
# 191
{ 
# 192
return p.second; 
# 193
} 
# 197
typename tuple_element< 1, Pair> ::type &operator()(Pair &p) const 
# 198
{ 
# 199
return p.second; 
# 200
} 
# 201
}; 
# 203
}
# 207
template< unsigned N, class T1, class T2> inline typename tuple_element< N, pair< T1, T2> > ::type &
# 210
get(pair< T1, T2>  &p) 
# 211
{ 
# 212
return detail::pair_get< N, pair< T1, T2> > ()(p); 
# 213
} 
# 215
template< unsigned N, class T1, class T2> inline const typename tuple_element< N, pair< T1, T2> > ::type &
# 218
get(const pair< T1, T2>  &p) 
# 219
{ 
# 220
return detail::pair_get< N, pair< T1, T2> > ()(p); 
# 221
} 
# 224
}
# 37 "/usr/local/cuda-8.0/include/thrust/tuple.h"
namespace thrust { 
# 51
struct null_type; 
# 65
template< int N, class T> 
# 66
struct tuple_element { 
# 69
private: typedef typename T::tail_type Next; 
# 74
public: typedef typename thrust::tuple_element< N - 1, typename T::tail_type> ::type type; 
# 75
}; 
# 85
template< class T> 
# 86
struct tuple_size { 
# 90
static const int value = (1 + tuple_size< typename T::tail_type> ::value); 
# 91
}; 
# 118
template< int N, class HT, class TT> inline typename access_traits< typename tuple_element< N, detail::cons< HT, TT> > ::type> ::non_const_type get(detail::cons< HT, TT>  & t); 
# 149
template< int N, class HT, class TT> inline typename access_traits< typename tuple_element< N, detail::cons< HT, TT> > ::type> ::const_type get(const detail::cons< HT, TT>  & t); 
# 195
template< class T0, class T1, class T2, class T3, class T4, class 
# 196
T5, class T6, class T7, class T8, class T9> 
# 197
class tuple : public detail::map_tuple_to_cons< T0, T1, T2, T3, T4, T5, T6, T7, T8, T9> ::type { 
# 204
typedef typename ::thrust::detail::map_tuple_to_cons< T0, T1, T2, T3, T4, T5, T6, T7, T8, T9> ::type inherited; 
# 213
public: tuple() { } 
# 220
tuple(typename access_traits< T0> ::parameter_type t0) : inherited(t0, static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type())) 
# 230
{ } 
# 239
tuple(typename access_traits< T0> ::parameter_type t0, typename access_traits< T1> ::parameter_type 
# 240
t1) : inherited(t0, t1, static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type())) 
# 249
{ } 
# 255
tuple(typename access_traits< T0> ::parameter_type t0, typename access_traits< T1> ::parameter_type 
# 256
t1, typename access_traits< T2> ::parameter_type 
# 257
t2) : inherited(t0, t1, t2, static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type())) 
# 265
{ } 
# 268
tuple(typename access_traits< T0> ::parameter_type t0, typename access_traits< T1> ::parameter_type 
# 269
t1, typename access_traits< T2> ::parameter_type 
# 270
t2, typename access_traits< T3> ::parameter_type 
# 271
t3) : inherited(t0, t1, t2, t3, static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type())) 
# 278
{ } 
# 281
tuple(typename access_traits< T0> ::parameter_type t0, typename access_traits< T1> ::parameter_type 
# 282
t1, typename access_traits< T2> ::parameter_type 
# 283
t2, typename access_traits< T3> ::parameter_type 
# 284
t3, typename access_traits< T4> ::parameter_type 
# 285
t4) : inherited(t0, t1, t2, t3, t4, static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type())) 
# 291
{ } 
# 294
tuple(typename access_traits< T0> ::parameter_type t0, typename access_traits< T1> ::parameter_type 
# 295
t1, typename access_traits< T2> ::parameter_type 
# 296
t2, typename access_traits< T3> ::parameter_type 
# 297
t3, typename access_traits< T4> ::parameter_type 
# 298
t4, typename access_traits< T5> ::parameter_type 
# 299
t5) : inherited(t0, t1, t2, t3, t4, t5, static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type())) 
# 304
{ } 
# 307
tuple(typename access_traits< T0> ::parameter_type t0, typename access_traits< T1> ::parameter_type 
# 308
t1, typename access_traits< T2> ::parameter_type 
# 309
t2, typename access_traits< T3> ::parameter_type 
# 310
t3, typename access_traits< T4> ::parameter_type 
# 311
t4, typename access_traits< T5> ::parameter_type 
# 312
t5, typename access_traits< T6> ::parameter_type 
# 313
t6) : inherited(t0, t1, t2, t3, t4, t5, t6, static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type())) 
# 317
{ } 
# 320
tuple(typename access_traits< T0> ::parameter_type t0, typename access_traits< T1> ::parameter_type 
# 321
t1, typename access_traits< T2> ::parameter_type 
# 322
t2, typename access_traits< T3> ::parameter_type 
# 323
t3, typename access_traits< T4> ::parameter_type 
# 324
t4, typename access_traits< T5> ::parameter_type 
# 325
t5, typename access_traits< T6> ::parameter_type 
# 326
t6, typename access_traits< T7> ::parameter_type 
# 327
t7) : inherited(t0, t1, t2, t3, t4, t5, t6, t7, static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type())) 
# 330
{ } 
# 333
tuple(typename access_traits< T0> ::parameter_type t0, typename access_traits< T1> ::parameter_type 
# 334
t1, typename access_traits< T2> ::parameter_type 
# 335
t2, typename access_traits< T3> ::parameter_type 
# 336
t3, typename access_traits< T4> ::parameter_type 
# 337
t4, typename access_traits< T5> ::parameter_type 
# 338
t5, typename access_traits< T6> ::parameter_type 
# 339
t6, typename access_traits< T7> ::parameter_type 
# 340
t7, typename access_traits< T8> ::parameter_type 
# 341
t8) : inherited(t0, t1, t2, t3, t4, t5, t6, t7, t8, static_cast< const ::thrust::null_type &>(::thrust::null_type())) 
# 343
{ } 
# 346
tuple(typename access_traits< T0> ::parameter_type t0, typename access_traits< T1> ::parameter_type 
# 347
t1, typename access_traits< T2> ::parameter_type 
# 348
t2, typename access_traits< T3> ::parameter_type 
# 349
t3, typename access_traits< T4> ::parameter_type 
# 350
t4, typename access_traits< T5> ::parameter_type 
# 351
t5, typename access_traits< T6> ::parameter_type 
# 352
t6, typename access_traits< T7> ::parameter_type 
# 353
t7, typename access_traits< T8> ::parameter_type 
# 354
t8, typename access_traits< T9> ::parameter_type 
# 355
t9) : inherited(t0, t1, t2, t3, t4, t5, t6, t7, t8, t9) 
# 356
{ } 
# 359
template< class U1, class U2> 
# 361
tuple(const ::thrust::detail::cons< U1, U2>  &p) : inherited(p) { } 
# 363
template< class U1, class U2> tuple &
# 365
operator=(const ::thrust::detail::cons< U1, U2>  &k) 
# 366
{ 
# 367
::thrust::detail::map_tuple_to_cons< T0, T1, T2, T3, T4, T5, T6, T7, T8, T9> ::type::operator=(k); 
# 368
return *this; 
# 369
} 
# 377
template< class U1, class U2> tuple &
# 379
operator=(const pair< U1, U2>  &k) { 
# 381
(this->head) = (k.first); 
# 382
((this->tail).head) = (k.second); 
# 383
return *this; 
# 384
} 
# 391
void swap(tuple &t) 
# 392
{ 
# 393
inherited::swap(t); 
# 394
} 
# 395
}; 
# 401
template<> class tuple< null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type>  : public null_type { 
# 405
public: typedef null_type inherited; 
# 406
}; 
# 418
template< class T0> inline typename detail::make_tuple_mapper< T0> ::type make_tuple(const T0 & t0); 
# 434
template< class T0, class T1> inline typename detail::make_tuple_mapper< T0, T1> ::type make_tuple(const T0 & t0, const T1 & t1); 
# 445
template< class T0> inline tuple< T0 &, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type>  tie(T0 & t0); 
# 460
template< class T0, class T1> inline tuple< T0 &, T1 &, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type>  tie(T0 & t0, T1 & t1); 
# 469
template< class 
# 470
T0, class T1, class T2, class T3, class T4, class T5, class T6, class T7, class T8, class T9, class 
# 471
U0, class U1, class U2, class U3, class U4, class U5, class U6, class U7, class U8, class U9> inline void 
# 469
swap(tuple< T0, T1, T2, T3, T4, T5, T6, T7, T8, T9>  & x, tuple< U0, U1, U2, U3, U4, U5, U6, U7, U8, U9>  & y); 
# 482
template< class T0, class T1, class T2> inline typename detail::make_tuple_mapper< T0, T1, T2> ::type make_tuple(const T0 & t0, const T1 & t1, const T2 & t2); 
# 487
template< class T0, class T1, class T2, class T3> inline typename detail::make_tuple_mapper< T0, T1, T2, T3> ::type make_tuple(const T0 & t0, const T1 & t1, const T2 & t2, const T3 & t3); 
# 492
template< class T0, class T1, class T2, class T3, class T4> inline typename detail::make_tuple_mapper< T0, T1, T2, T3, T4> ::type make_tuple(const T0 & t0, const T1 & t1, const T2 & t2, const T3 & t3, const T4 & t4); 
# 497
template< class T0, class T1, class T2, class T3, class T4, class T5> inline typename detail::make_tuple_mapper< T0, T1, T2, T3, T4, T5> ::type make_tuple(const T0 & t0, const T1 & t1, const T2 & t2, const T3 & t3, const T4 & t4, const T5 & t5); 
# 502
template< class T0, class T1, class T2, class T3, class T4, class T5, class T6> inline typename detail::make_tuple_mapper< T0, T1, T2, T3, T4, T5, T6> ::type make_tuple(const T0 & t0, const T1 & t1, const T2 & t2, const T3 & t3, const T4 & t4, const T5 & t5, const T6 & t6); 
# 507
template< class T0, class T1, class T2, class T3, class T4, class T5, class T6, class T7> inline typename detail::make_tuple_mapper< T0, T1, T2, T3, T4, T5, T6, T7> ::type make_tuple(const T0 & t0, const T1 & t1, const T2 & t2, const T3 & t3, const T4 & t4, const T5 & t5, const T6 & t6, const T7 & t7); 
# 512
template< class T0, class T1, class T2, class T3, class T4, class T5, class T6, class T7, class T8> inline typename detail::make_tuple_mapper< T0, T1, T2, T3, T4, T5, T6, T7, T8> ::type make_tuple(const T0 & t0, const T1 & t1, const T2 & t2, const T3 & t3, const T4 & t4, const T5 & t5, const T6 & t6, const T7 & t7, const T8 & t8); 
# 517
template< class T0, class T1, class T2, class T3, class T4, class T5, class T6, class T7, class T8, class T9> inline typename detail::make_tuple_mapper< T0, T1, T2, T3, T4, T5, T6, T7, T8, T9> ::type make_tuple(const T0 & t0, const T1 & t1, const T2 & t2, const T3 & t3, const T4 & t4, const T5 & t5, const T6 & t6, const T7 & t7, const T8 & t8, const T9 & t9); 
# 522
template< class T0, class T1, class T2> inline tuple< T0 &, T1 &, T2 &, null_type, null_type, null_type, null_type, null_type, null_type, null_type>  tie(T0 & t0, T1 & t1, T2 & t2); 
# 526
template< class T0, class T1, class T2, class T3> inline tuple< T0 &, T1 &, T2 &, T3 &, null_type, null_type, null_type, null_type, null_type, null_type>  tie(T0 & t0, T1 & t1, T2 & t2, T3 & t3); 
# 530
template< class T0, class T1, class T2, class T3, class T4> inline tuple< T0 &, T1 &, T2 &, T3 &, T4 &, null_type, null_type, null_type, null_type, null_type>  tie(T0 & t0, T1 & t1, T2 & t2, T3 & t3, T4 & t4); 
# 534
template< class T0, class T1, class T2, class T3, class T4, class T5> inline tuple< T0 &, T1 &, T2 &, T3 &, T4 &, T5 &, null_type, null_type, null_type, null_type>  tie(T0 & t0, T1 & t1, T2 & t2, T3 & t3, T4 & t4, T5 & t5); 
# 538
template< class T0, class T1, class T2, class T3, class T4, class T5, class T6> inline tuple< T0 &, T1 &, T2 &, T3 &, T4 &, T5 &, T6 &, null_type, null_type, null_type>  tie(T0 & t0, T1 & t1, T2 & t2, T3 & t3, T4 & t4, T5 & t5, T6 & t6); 
# 542
template< class T0, class T1, class T2, class T3, class T4, class T5, class T6, class T7> inline tuple< T0 &, T1 &, T2 &, T3 &, T4 &, T5 &, T6 &, T7 &, null_type, null_type>  tie(T0 & t0, T1 & t1, T2 & t2, T3 & t3, T4 & t4, T5 & t5, T6 & t6, T7 & t7); 
# 546
template< class T0, class T1, class T2, class T3, class T4, class T5, class T6, class T7, class T8> inline tuple< T0 &, T1 &, T2 &, T3 &, T4 &, T5 &, T6 &, T7 &, T8 &, null_type>  tie(T0 & t0, T1 & t1, T2 & t2, T3 & t3, T4 & t4, T5 & t5, T6 & t6, T7 & t7, T8 & t8); 
# 550
template< class T0, class T1, class T2, class T3, class T4, class T5, class T6, class T7, class T8, class T9> inline tuple< T0 &, T1 &, T2 &, T3 &, T4 &, T5 &, T6 &, T7 &, T8 &, T9 &>  tie(T0 & t0, T1 & t1, T2 & t2, T3 & t3, T4 & t4, T5 & t5, T6 & t6, T7 & t7, T8 & t8, T9 & t9); 
# 556
inline bool operator==(const null_type &, const null_type &); 
# 559
inline bool operator>=(const null_type &, const null_type &); 
# 562
inline bool operator<=(const null_type &, const null_type &); 
# 565
inline bool operator!=(const null_type &, const null_type &); 
# 568
inline bool operator<(const null_type &, const null_type &); 
# 571
inline bool operator>(const null_type &, const null_type &); 
# 582
}
# 31 "/usr/local/cuda-8.0/include/thrust/detail/functional/value.h"
namespace thrust { 
# 33
namespace detail { 
# 35
namespace functional { 
# 39
template< class Eval> struct actor; 
# 42
template< class T> 
# 43
class value { 
# 48
public: 
# 47
template< class Env> 
# 48
struct result { 
# 50
typedef T type; 
# 51
}; 
# 54
value(const T &arg) : m_val(arg) 
# 56
{ } 
# 58
template< class Env> T 
# 60
eval(const Env &) const 
# 61
{ 
# 62
return m_val; 
# 63
} 
# 66
private: T m_val; 
# 67
}; 
# 69
template< class T> actor< value< T> >  
# 71
val(const T &x) 
# 72
{ 
# 73
return ((value< T> )(x)); 
# 74
} 
# 77
}
# 78
}
# 79
}
# 31 "/usr/local/cuda-8.0/include/thrust/detail/functional/composite.h"
namespace thrust { 
# 33
namespace detail { 
# 35
namespace functional { 
# 39
template< class Eval0, class 
# 40
Eval1 = null_type, class 
# 41
Eval2 = null_type, class 
# 42
Eval3 = null_type, class 
# 43
Eval4 = null_type, class 
# 44
Eval5 = null_type, class 
# 45
Eval6 = null_type, class 
# 46
Eval7 = null_type, class 
# 47
Eval8 = null_type, class 
# 48
Eval9 = null_type, class 
# 49
Eval10 = null_type> class composite; 
# 52
template< class Eval0, class Eval1> 
# 53
class composite< Eval0, Eval1, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type>  { 
# 68
public: 
# 67
template< class Env> 
# 68
struct result { 
# 74
typedef typename Eval0::template result< tuple< typename Eval1::template result< Env> ::type, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type> > ::type type; 
# 75
}; 
# 78
composite(const Eval0 &e0, const Eval1 &e1) : m_eval0(e0), m_eval1(e1) 
# 81
{ } 
# 83
template< class Env> typename result< Env> ::type 
# 86
eval(const Env &x) const 
# 87
{ 
# 88
typename Eval1::template result< Env> ::type result1 = ((m_eval1).eval(x)); 
# 89
return ((m_eval0).eval(thrust::tie(result1))); 
# 90
} 
# 93
private: Eval0 m_eval0; 
# 94
Eval1 m_eval1; 
# 95
}; 
# 97
template< class Eval0, class Eval1, class Eval2> 
# 98
class composite< Eval0, Eval1, Eval2, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type>  { 
# 113
public: 
# 112
template< class Env> 
# 113
struct result { 
# 120
typedef typename Eval0::template result< tuple< typename Eval1::template result< Env> ::type, typename Eval2::template result< Env> ::type, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type> > ::type type; 
# 121
}; 
# 124
composite(const Eval0 &e0, const Eval1 &e1, const Eval2 &e2) : m_eval0(e0), m_eval1(e1), m_eval2(e2) 
# 128
{ } 
# 130
template< class Env> typename result< Env> ::type 
# 133
eval(const Env &x) const 
# 134
{ 
# 135
typename Eval1::template result< Env> ::type result1 = ((m_eval1).eval(x)); 
# 136
typename Eval2::template result< Env> ::type result2 = ((m_eval2).eval(x)); 
# 137
return ((m_eval0).eval(thrust::tie(result1, result2))); 
# 138
} 
# 141
private: Eval0 m_eval0; 
# 142
Eval1 m_eval1; 
# 143
Eval2 m_eval2; 
# 144
}; 
# 146
template< class Eval0, class Eval1> actor< composite< Eval0, Eval1> >  
# 148
compose(const Eval0 &e0, const Eval1 &e1) 
# 149
{ 
# 150
return ((actor< composite< Eval0, Eval1> > )(composite< Eval0, Eval1> (e0, e1))); 
# 151
} 
# 153
template< class Eval0, class Eval1, class Eval2> actor< composite< Eval0, Eval1, Eval2> >  
# 155
compose(const Eval0 &e0, const Eval1 &e1, const Eval2 &e2) 
# 156
{ 
# 157
return ((actor< composite< Eval0, Eval1, Eval2> > )(composite< Eval0, Eval1, Eval2> (e0, e1, e2))); 
# 158
} 
# 160
}
# 161
}
# 162
}
# 23 "/usr/local/cuda-8.0/include/thrust/detail/functional/operators/operator_adaptors.h"
namespace thrust { 
# 25
namespace detail { 
# 27
namespace functional { 
# 32
template< template< class >  class UnaryOperator> 
# 33
struct unary_operator { 
# 35
template< class Env> 
# 36
struct argument : public eval_if< tuple_size< Env> ::value == 0, identity_< null_type> , tuple_element< 0, Env> >  { 
# 43
}; 
# 45
template< class Env> 
# 46
struct operator_type { 
# 52
typedef UnaryOperator< typename remove_reference< typename argument< Env> ::type> ::type>  type; 
# 53
}; 
# 55
template< class Env> 
# 56
struct result { 
# 58
typedef typename operator_type< Env> ::type op_type; 
# 59
typedef typename operator_type< Env> ::type::result_type type; 
# 60
}; 
# 62
template< class Env> typename result< Env> ::type 
# 64
eval(const Env &e) const 
# 65
{ 
# 66
typename operator_type< Env> ::type op; 
# 67
return op(thrust::get< 0> (e)); 
# 68
} 
# 69
}; 
# 73
template< template< class >  class BinaryOperator> 
# 74
struct binary_operator { 
# 76
template< class Env> 
# 77
struct first_argument : public eval_if< tuple_size< Env> ::value == 0, identity_< null_type> , tuple_element< 0, Env> >  { 
# 84
}; 
# 86
template< class Env> 
# 87
struct operator_type { 
# 93
typedef BinaryOperator< typename remove_reference< typename first_argument< Env> ::type> ::type>  type; 
# 94
}; 
# 96
template< class Env> 
# 97
struct result { 
# 99
typedef typename operator_type< Env> ::type op_type; 
# 100
typedef typename operator_type< Env> ::type::result_type type; 
# 101
}; 
# 103
template< class Env> typename result< Env> ::type 
# 105
eval(const Env &e) const 
# 106
{ 
# 107
typename operator_type< Env> ::type op; 
# 108
return op(thrust::get< 0> (e), thrust::get< 1> (e)); 
# 109
} 
# 110
}; 
# 112
}
# 113
}
# 114
}
# 25 "/usr/local/cuda-8.0/include/thrust/detail/functional/operators/assignment_operator.h"
namespace thrust { 
# 29
template< class , class , class > struct binary_function; 
# 31
namespace detail { 
# 33
namespace functional { 
# 37
template< class > struct as_actor; 
# 40
template< class T> 
# 41
struct assign : public binary_function< T &, T, T &>  { 
# 44
T &operator()(T &lhs, const T &rhs) const { return lhs = rhs; } 
# 45
}; 
# 47
template< class Eval, class T> 
# 48
struct assign_result { 
# 56
typedef actor< composite< binary_operator< assign> , actor< Eval> , typename as_actor< T> ::type> >  type; 
# 57
}; 
# 59
template< class Eval, class T> typename assign_result< Eval, T> ::type 
# 62
do_assign(const actor< Eval>  &_1, const T &_2) 
# 63
{ 
# 64
return compose(binary_operator< assign> (), _1, as_actor< T> ::convert(_2)); 
# 67
} 
# 69
}
# 70
}
# 71
}
# 22 "/usr/local/cuda-8.0/include/thrust/detail/type_traits/function_traits.h"
namespace thrust { 
# 26
template< class T> struct plus; 
# 27
template< class T> struct multiplies; 
# 28
template< class T> struct minimum; 
# 29
template< class T> struct maximum; 
# 30
template< class T> struct logical_or; 
# 31
template< class T> struct logical_and; 
# 32
template< class T> struct bit_or; 
# 33
template< class T> struct bit_and; 
# 34
template< class T> struct bit_xor; 
# 36
namespace detail { 
# 42
template< class T> struct has_result_type { typedef char yes_type; typedef int no_type; template< class S> static yes_type test(typename S::result_type *); template< class S> static no_type test(...); static const bool value = (sizeof(test< T> (0)) == sizeof(yes_type)); typedef integral_constant< bool, value>  type; }; 
# 44
template< class T> struct has_argument_type { typedef char yes_type; typedef int no_type; template< class S> static yes_type test(typename S::argument_type *); template< class S> static no_type test(...); static const bool value = (sizeof(test< T> (0)) == sizeof(yes_type)); typedef integral_constant< bool, value>  type; }; 
# 46
template< class T> struct has_first_argument_type { typedef char yes_type; typedef int no_type; template< class S> static yes_type test(typename S::first_argument_type *); template< class S> static no_type test(...); static const bool value = (sizeof(test< T> (0)) == sizeof(yes_type)); typedef integral_constant< bool, value>  type; }; 
# 48
template< class T> struct has_second_argument_type { typedef char yes_type; typedef int no_type; template< class S> static yes_type test(typename S::second_argument_type *); template< class S> static no_type test(...); static const bool value = (sizeof(test< T> (0)) == sizeof(yes_type)); typedef integral_constant< bool, value>  type; }; 
# 51
template< class AdaptableBinaryFunction> 
# 52
struct result_type { 
# 54
typedef typename AdaptableBinaryFunction::result_type type; 
# 55
}; 
# 58
template< class T> 
# 59
struct is_adaptable_unary_function : public and_< has_result_type< T> , has_argument_type< T> >  { 
# 64
}; 
# 67
template< class T> 
# 68
struct is_adaptable_binary_function : public and_< has_result_type< T> , and_< has_first_argument_type< T> , has_second_argument_type< T> > >  { 
# 76
}; 
# 79
template< class BinaryFunction> 
# 80
struct is_commutative : public false_type { 
# 82
}; 
# 84
template< class T> struct is_commutative< plus< T> >  : public is_arithmetic< T>  { }; 
# 85
template< class T> struct is_commutative< multiplies< T> >  : public is_arithmetic< T>  { }; 
# 86
template< class T> struct is_commutative< minimum< T> >  : public is_arithmetic< T>  { }; 
# 87
template< class T> struct is_commutative< maximum< T> >  : public is_arithmetic< T>  { }; 
# 88
template< class T> struct is_commutative< logical_or< T> >  : public is_arithmetic< T>  { }; 
# 89
template< class T> struct is_commutative< logical_and< T> >  : public is_arithmetic< T>  { }; 
# 90
template< class T> struct is_commutative< bit_or< T> >  : public is_arithmetic< T>  { }; 
# 91
template< class T> struct is_commutative< bit_and< T> >  : public is_arithmetic< T>  { }; 
# 92
template< class T> struct is_commutative< bit_xor< T> >  : public is_arithmetic< T>  { }; 
# 94
}
# 95
}
# 23 "/usr/local/cuda-8.0/include/thrust/detail/type_traits/result_of_adaptable_function.h"
namespace thrust { 
# 25
namespace detail { 
# 33
template< class Signature, class Enable = void> struct result_of_adaptable_function; 
# 38
template< class Functor, class Arg1> 
# 39
struct result_of_adaptable_function< Functor (Arg1), typename enable_if< has_result_type< Functor> ::value> ::type>  { 
# 44
typedef typename Functor::result_type type; 
# 45
}; 
# 48
template< class Functor, class Arg1, class Arg2> 
# 49
struct result_of_adaptable_function< Functor (Arg1, Arg2), typename enable_if< has_result_type< Functor> ::value> ::type>  { 
# 54
typedef typename Functor::result_type type; 
# 55
}; 
# 58
}
# 59
}
# 35 "/usr/local/cuda-8.0/include/thrust/detail/functional/actor.h"
namespace thrust { 
# 37
namespace detail { 
# 39
namespace functional { 
# 42
template< class Action, class Env> 
# 43
struct apply_actor { 
# 45
typedef typename Action::template result< Env> ::type type; 
# 46
}; 
# 48
template< class Eval> 
# 49
struct actor : public Eval { 
# 52
typedef Eval eval_type; 
# 55
actor(); 
# 58
actor(const Eval & base); 
# 62
typename apply_actor< Eval, ::thrust::null_type> ::type operator()() const; 
# 64
template< class T0> typename apply_actor< Eval, tuple< T0 &, ::thrust::null_type, ::thrust::null_type, ::thrust::null_type, ::thrust::null_type, ::thrust::null_type, ::thrust::null_type, ::thrust::null_type, ::thrust::null_type, ::thrust::null_type> > ::type operator()(T0 & _0) const; 
# 69
template< class T0, class T1> typename apply_actor< Eval, tuple< T0 &, T1 &, ::thrust::null_type, ::thrust::null_type, ::thrust::null_type, ::thrust::null_type, ::thrust::null_type, ::thrust::null_type, ::thrust::null_type, ::thrust::null_type> > ::type operator()(T0 & _0, T1 & _1) const; 
# 74
template< class T0, class T1, class T2> typename apply_actor< Eval, tuple< T0 &, T1 &, T2 &, ::thrust::null_type, ::thrust::null_type, ::thrust::null_type, ::thrust::null_type, ::thrust::null_type, ::thrust::null_type, ::thrust::null_type> > ::type operator()(T0 & _0, T1 & _1, T2 & _2) const; 
# 79
template< class T0, class T1, class T2, class T3> typename apply_actor< Eval, tuple< T0 &, T1 &, T2 &, T3 &, ::thrust::null_type, ::thrust::null_type, ::thrust::null_type, ::thrust::null_type, ::thrust::null_type, ::thrust::null_type> > ::type operator()(T0 & _0, T1 & _1, T2 & _2, T3 & _3) const; 
# 84
template< class T0, class T1, class T2, class T3, class T4> typename apply_actor< Eval, tuple< T0 &, T1 &, T2 &, T3 &, T4 &, ::thrust::null_type, ::thrust::null_type, ::thrust::null_type, ::thrust::null_type, ::thrust::null_type> > ::type operator()(T0 & _0, T1 & _1, T2 & _2, T3 & _3, T4 & _4) const; 
# 89
template< class T0, class T1, class T2, class T3, class T4, class T5> typename apply_actor< Eval, tuple< T0 &, T1 &, T2 &, T3 &, T4 &, T5 &, ::thrust::null_type, ::thrust::null_type, ::thrust::null_type, ::thrust::null_type> > ::type operator()(T0 & _0, T1 & _1, T2 & _2, T3 & _3, T4 & _4, T5 & _5) const; 
# 94
template< class T0, class T1, class T2, class T3, class T4, class T5, class T6> typename apply_actor< Eval, tuple< T0 &, T1 &, T2 &, T3 &, T4 &, T5 &, T6 &, ::thrust::null_type, ::thrust::null_type, ::thrust::null_type> > ::type operator()(T0 & _0, T1 & _1, T2 & _2, T3 & _3, T4 & _4, T5 & _5, T6 & _6) const; 
# 99
template< class T0, class T1, class T2, class T3, class T4, class T5, class T6, class T7> typename apply_actor< Eval, tuple< T0 &, T1 &, T2 &, T3 &, T4 &, T5 &, T6 &, T7 &, ::thrust::null_type, ::thrust::null_type> > ::type operator()(T0 & _0, T1 & _1, T2 & _2, T3 & _3, T4 & _4, T5 & _5, T6 & _6, T7 & _7) const; 
# 104
template< class T0, class T1, class T2, class T3, class T4, class T5, class T6, class T7, class T8> typename apply_actor< Eval, tuple< T0 &, T1 &, T2 &, T3 &, T4 &, T5 &, T6 &, T7 &, T8 &, ::thrust::null_type> > ::type operator()(T0 & _0, T1 & _1, T2 & _2, T3 & _3, T4 & _4, T5 & _5, T6 & _6, T7 & _7, T8 & _8) const; 
# 109
template< class T0, class T1, class T2, class T3, class T4, class T5, class T6, class T7, class T8, class T9> typename apply_actor< Eval, tuple< T0 &, T1 &, T2 &, T3 &, T4 &, T5 &, T6 &, T7 &, T8 &, T9 &> > ::type operator()(T0 & _0, T1 & _1, T2 & _2, T3 & _3, T4 & _4, T5 & _5, T6 & _6, T7 & _7, T8 & _8, T9 & _9) const; 
# 114
template< class T> typename assign_result< Eval, T> ::type operator=(const T & _1) const; 
# 118
}; 
# 121
template< class T> 
# 122
struct as_actor { 
# 124
typedef value< T>  type; 
# 126
static type convert(const T &x) 
# 127
{ 
# 128
return val(x); 
# 129
} 
# 130
}; 
# 133
template< class Eval> 
# 134
struct as_actor< actor< Eval> >  { 
# 136
typedef actor< Eval>  type; 
# 138
static const type &convert(const actor< Eval>  &x) 
# 139
{ 
# 140
return x; 
# 141
} 
# 142
}; 
# 144
template< class T> typename as_actor< T> ::type 
# 147
make_actor(const T &x) 
# 148
{ 
# 149
return as_actor< T> ::convert(x); 
# 150
} 
# 152
}
# 155
template< class Eval> 
# 156
struct result_of_adaptable_function< functional::actor< Eval>  (void), void>  { 
# 163
typedef typename functional::apply_actor< functional::actor< Eval> , null_type> ::type type; 
# 164
}; 
# 166
template< class Eval, class Arg1> 
# 167
struct result_of_adaptable_function< functional::actor< Eval>  (Arg1), void>  { 
# 174
typedef typename functional::apply_actor< functional::actor< Eval> , tuple< Arg1, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type> > ::type type; 
# 175
}; 
# 177
template< class Eval, class Arg1, class Arg2> 
# 178
struct result_of_adaptable_function< functional::actor< Eval>  (Arg1, Arg2), void>  { 
# 185
typedef typename functional::apply_actor< functional::actor< Eval> , tuple< Arg1, Arg2, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type> > ::type type; 
# 186
}; 
# 188
}
# 189
}
# 31 "/usr/local/cuda-8.0/include/thrust/detail/functional/actor.inl"
namespace thrust { 
# 34
namespace detail { 
# 36
namespace functional { 
# 39
template< class Eval> 
# 41
actor< Eval> ::actor() : eval_type() 
# 43
{ } 
# 45
template< class Eval> 
# 47
actor< Eval> ::actor(const Eval &base) : eval_type(base) 
# 49
{ } 
# 51
template< class Eval> typename apply_actor< Eval, null_type> ::type 
# 57
actor< Eval> ::operator()() const 
# 58
{ 
# 59
return eval_type::eval(::thrust::null_type()); 
# 60
} 
# 62
template< class Eval> 
# 63
template< class T0> typename apply_actor< Eval, tuple< T0 &, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type> > ::type 
# 69
actor< Eval> ::operator()(T0 &_0) const 
# 70
{ 
# 71
return eval_type::eval(::thrust::tie(_0)); 
# 72
} 
# 74
template< class Eval> 
# 75
template< class T0, class T1> typename apply_actor< Eval, tuple< T0 &, T1 &, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type> > ::type 
# 81
actor< Eval> ::operator()(T0 &_0, T1 &_1) const 
# 82
{ 
# 83
return eval_type::eval(::thrust::tie(_0, _1)); 
# 84
} 
# 86
template< class Eval> 
# 87
template< class T0, class T1, class T2> typename apply_actor< Eval, tuple< T0 &, T1 &, T2 &, null_type, null_type, null_type, null_type, null_type, null_type, null_type> > ::type 
# 93
actor< Eval> ::operator()(T0 &_0, T1 &_1, T2 &_2) const 
# 94
{ 
# 95
return eval_type::eval(::thrust::tie(_0, _1, _2)); 
# 96
} 
# 98
template< class Eval> 
# 99
template< class T0, class T1, class T2, class T3> typename apply_actor< Eval, tuple< T0 &, T1 &, T2 &, T3 &, null_type, null_type, null_type, null_type, null_type, null_type> > ::type 
# 105
actor< Eval> ::operator()(T0 &_0, T1 &_1, T2 &_2, T3 &_3) const 
# 106
{ 
# 107
return eval_type::eval(::thrust::tie(_0, _1, _2, _3)); 
# 108
} 
# 110
template< class Eval> 
# 111
template< class T0, class T1, class T2, class T3, class T4> typename apply_actor< Eval, tuple< T0 &, T1 &, T2 &, T3 &, T4 &, null_type, null_type, null_type, null_type, null_type> > ::type 
# 117
actor< Eval> ::operator()(T0 &_0, T1 &_1, T2 &_2, T3 &_3, T4 &_4) const 
# 118
{ 
# 119
return eval_type::eval(::thrust::tie(_0, _1, _2, _3, _4)); 
# 120
} 
# 122
template< class Eval> 
# 123
template< class T0, class T1, class T2, class T3, class T4, class T5> typename apply_actor< Eval, tuple< T0 &, T1 &, T2 &, T3 &, T4 &, T5 &, null_type, null_type, null_type, null_type> > ::type 
# 129
actor< Eval> ::operator()(T0 &_0, T1 &_1, T2 &_2, T3 &_3, T4 &_4, T5 &_5) const 
# 130
{ 
# 131
return eval_type::eval(::thrust::tie(_0, _1, _2, _3, _4, _5)); 
# 132
} 
# 134
template< class Eval> 
# 135
template< class T0, class T1, class T2, class T3, class T4, class T5, class T6> typename apply_actor< Eval, tuple< T0 &, T1 &, T2 &, T3 &, T4 &, T5 &, T6 &, null_type, null_type, null_type> > ::type 
# 141
actor< Eval> ::operator()(T0 &_0, T1 &_1, T2 &_2, T3 &_3, T4 &_4, T5 &_5, T6 &_6) const 
# 142
{ 
# 143
return eval_type::eval(::thrust::tie(_0, _1, _2, _3, _4, _5, _6)); 
# 144
} 
# 146
template< class Eval> 
# 147
template< class T0, class T1, class T2, class T3, class T4, class T5, class T6, class T7> typename apply_actor< Eval, tuple< T0 &, T1 &, T2 &, T3 &, T4 &, T5 &, T6 &, T7 &, null_type, null_type> > ::type 
# 153
actor< Eval> ::operator()(T0 &_0, T1 &_1, T2 &_2, T3 &_3, T4 &_4, T5 &_5, T6 &_6, T7 &_7) const 
# 154
{ 
# 155
return eval_type::eval(::thrust::tie(_0, _1, _2, _3, _4, _5, _6, _7)); 
# 156
} 
# 158
template< class Eval> 
# 159
template< class T0, class T1, class T2, class T3, class T4, class T5, class T6, class T7, class T8> typename apply_actor< Eval, tuple< T0 &, T1 &, T2 &, T3 &, T4 &, T5 &, T6 &, T7 &, T8 &, null_type> > ::type 
# 165
actor< Eval> ::operator()(T0 &_0, T1 &_1, T2 &_2, T3 &_3, T4 &_4, T5 &_5, T6 &_6, T7 &_7, T8 &_8) const 
# 166
{ 
# 167
return eval_type::eval(::thrust::tie(_0, _1, _2, _3, _4, _5, _6, _7, _8)); 
# 168
} 
# 170
template< class Eval> 
# 171
template< class T0, class T1, class T2, class T3, class T4, class T5, class T6, class T7, class T8, class T9> typename apply_actor< Eval, tuple< T0 &, T1 &, T2 &, T3 &, T4 &, T5 &, T6 &, T7 &, T8 &, T9 &> > ::type 
# 177
actor< Eval> ::operator()(T0 &_0, T1 &_1, T2 &_2, T3 &_3, T4 &_4, T5 &_5, T6 &_6, T7 &_7, T8 &_8, T9 &_9) const 
# 178
{ 
# 179
return eval_type::eval(::thrust::tie(_0, _1, _2, _3, _4, _5, _6, _7, _8, _9)); 
# 180
} 
# 182
template< class Eval> 
# 183
template< class T> typename assign_result< Eval, T> ::type 
# 186
actor< Eval> ::operator=(const T &_1) const 
# 187
{ 
# 188
return do_assign(*this, _1); 
# 189
} 
# 191
}
# 192
}
# 193
}
# 31 "/usr/local/cuda-8.0/include/thrust/detail/functional/argument.h"
namespace thrust { 
# 33
namespace detail { 
# 35
namespace functional { 
# 38
template< unsigned i, class Env> 
# 39
struct argument_helper { 
# 41
typedef typename tuple_element< i, Env> ::type type; 
# 42
}; 
# 44
template< unsigned i> 
# 45
struct argument_helper< i, null_type>  { 
# 47
typedef null_type type; 
# 48
}; 
# 51
template< unsigned i> 
# 52
class argument { 
# 56
public: 
# 55
template< class Env> 
# 56
struct result : public argument_helper< i, Env>  { 
# 59
}; 
# 62
argument() { } 
# 64
template< class Env> typename result< Env> ::type 
# 66
eval(const Env &e) const 
# 67
{ 
# 68
return thrust::get< i> (e); 
# 69
} 
# 70
}; 
# 72
}
# 73
}
# 74
}
# 23 "/usr/local/cuda-8.0/include/thrust/detail/functional/placeholder.h"
namespace thrust { 
# 25
namespace detail { 
# 27
namespace functional { 
# 30
template< unsigned i> 
# 31
struct placeholder { 
# 33
typedef actor< argument< i> >  type; 
# 34
}; 
# 36
}
# 37
}
# 38
}
# 28 "/usr/local/cuda-8.0/include/thrust/functional.h"
namespace thrust { 
# 34
template< class Operation> struct unary_traits; 
# 36
template< class Operation> struct binary_traits; 
# 68
template< class Argument, class 
# 69
Result> 
# 70
struct unary_function { 
# 75
typedef Argument argument_type; 
# 80
typedef Result result_type; 
# 81
}; 
# 108
template< class Argument1, class 
# 109
Argument2, class 
# 110
Result> 
# 111
struct binary_function { 
# 116
typedef Argument1 first_argument_type; 
# 121
typedef Argument2 second_argument_type; 
# 126
typedef Result result_type; 
# 127
}; 
# 175
template< class T> 
# 176
struct plus { 
# 181
typedef T first_argument_type; 
# 186
typedef T second_argument_type; 
# 191
typedef T result_type; 
# 195
T operator()(const T &lhs, const T &rhs) const { return lhs + rhs; } 
# 196
}; 
# 231
template< class T> 
# 232
struct minus { 
# 237
typedef T first_argument_type; 
# 242
typedef T second_argument_type; 
# 247
typedef T result_type; 
# 251
T operator()(const T &lhs, const T &rhs) const { return lhs - rhs; } 
# 252
}; 
# 287
template< class T> 
# 288
struct multiplies { 
# 293
typedef T first_argument_type; 
# 298
typedef T second_argument_type; 
# 303
typedef T result_type; 
# 307
T operator()(const T &lhs, const T &rhs) const { return lhs * rhs; } 
# 308
}; 
# 343
template< class T> 
# 344
struct divides { 
# 349
typedef T first_argument_type; 
# 354
typedef T second_argument_type; 
# 359
typedef T result_type; 
# 363
T operator()(const T &lhs, const T &rhs) const { return lhs / rhs; } 
# 364
}; 
# 399
template< class T> 
# 400
struct modulus { 
# 405
typedef T first_argument_type; 
# 410
typedef T second_argument_type; 
# 415
typedef T result_type; 
# 419
T operator()(const T &lhs, const T &rhs) const { return lhs % rhs; } 
# 420
}; 
# 452
template< class T> 
# 453
struct negate { 
# 458
typedef T argument_type; 
# 463
typedef T result_type; 
# 467
T operator()(const T &x) const { return -x; } 
# 468
}; 
# 489
template< class T> 
# 490
struct equal_to { 
# 495
typedef T first_argument_type; 
# 500
typedef T second_argument_type; 
# 505
typedef bool result_type; 
# 509
bool operator()(const T &lhs, const T &rhs) const { return lhs == rhs; } 
# 510
}; 
# 523
template< class T> 
# 524
struct not_equal_to { 
# 529
typedef T first_argument_type; 
# 534
typedef T second_argument_type; 
# 539
typedef bool result_type; 
# 543
bool operator()(const T &lhs, const T &rhs) const { return lhs != rhs; } 
# 544
}; 
# 557
template< class T> 
# 558
struct greater { 
# 563
typedef T first_argument_type; 
# 568
typedef T second_argument_type; 
# 573
typedef bool result_type; 
# 577
bool operator()(const T &lhs, const T &rhs) const { return lhs > rhs; } 
# 578
}; 
# 591
template< class T> 
# 592
struct less { 
# 597
typedef T first_argument_type; 
# 602
typedef T second_argument_type; 
# 607
typedef bool result_type; 
# 611
bool operator()(const T &lhs, const T &rhs) const { return lhs < rhs; } 
# 612
}; 
# 625
template< class T> 
# 626
struct greater_equal { 
# 631
typedef T first_argument_type; 
# 636
typedef T second_argument_type; 
# 641
typedef bool result_type; 
# 645
bool operator()(const T &lhs, const T &rhs) const { return lhs >= rhs; } 
# 646
}; 
# 659
template< class T> 
# 660
struct less_equal { 
# 665
typedef T first_argument_type; 
# 670
typedef T second_argument_type; 
# 675
typedef bool result_type; 
# 679
bool operator()(const T &lhs, const T &rhs) const { return lhs <= rhs; } 
# 680
}; 
# 702
template< class T> 
# 703
struct logical_and { 
# 708
typedef T first_argument_type; 
# 713
typedef T second_argument_type; 
# 718
typedef bool result_type; 
# 722
bool operator()(const T &lhs, const T &rhs) const { return lhs && rhs; } 
# 723
}; 
# 736
template< class T> 
# 737
struct logical_or { 
# 742
typedef T first_argument_type; 
# 747
typedef T second_argument_type; 
# 752
typedef bool result_type; 
# 756
bool operator()(const T &lhs, const T &rhs) const { return lhs || rhs; } 
# 757
}; 
# 784
template< class T> 
# 785
struct logical_not { 
# 790
typedef T first_argument_type; 
# 795
typedef T second_argument_type; 
# 800
typedef bool result_type; 
# 804
bool operator()(const T &x) const { return !x; } 
# 805
}; 
# 847
template< class T> 
# 848
struct bit_and { 
# 853
typedef T first_argument_type; 
# 858
typedef T second_argument_type; 
# 863
typedef T result_type; 
# 867
T operator()(const T &lhs, const T &rhs) const { return lhs & rhs; } 
# 868
}; 
# 902
template< class T> 
# 903
struct bit_or { 
# 908
typedef T first_argument_type; 
# 913
typedef T second_argument_type; 
# 918
typedef T result_type; 
# 922
T operator()(const T &lhs, const T &rhs) const { return lhs | rhs; } 
# 923
}; 
# 957
template< class T> 
# 958
struct bit_xor { 
# 963
typedef T first_argument_type; 
# 968
typedef T second_argument_type; 
# 973
typedef T result_type; 
# 977
T operator()(const T &lhs, const T &rhs) const { return lhs ^ rhs; } 
# 978
}; 
# 1008
template< class T> 
# 1009
struct identity { 
# 1014
typedef T argument_type; 
# 1019
typedef T result_type; 
# 1023
const T &operator()(const T &x) const { return x; } 
# 1024
}; 
# 1050
template< class T> 
# 1051
struct maximum { 
# 1056
typedef T first_argument_type; 
# 1061
typedef T second_argument_type; 
# 1066
typedef T result_type; 
# 1070
T operator()(const T &lhs, const T &rhs) const { return (lhs < rhs) ? rhs : lhs; } 
# 1071
}; 
# 1097
template< class T> 
# 1098
struct minimum { 
# 1103
typedef T first_argument_type; 
# 1108
typedef T second_argument_type; 
# 1113
typedef T result_type; 
# 1117
T operator()(const T &lhs, const T &rhs) const { return (lhs < rhs) ? lhs : rhs; } 
# 1118
}; 
# 1138
template< class T1, class T2> 
# 1139
struct project1st { 
# 1144
typedef T1 first_argument_type; 
# 1149
typedef T2 second_argument_type; 
# 1154
typedef T1 result_type; 
# 1158
const T1 &operator()(const T1 &lhs, const T2 &rhs) const { return lhs; } 
# 1159
}; 
# 1179
template< class T1, class T2> 
# 1180
struct project2nd { 
# 1185
typedef T1 first_argument_type; 
# 1190
typedef T2 second_argument_type; 
# 1195
typedef T2 result_type; 
# 1199
const T2 &operator()(const T1 &lhs, const T2 &rhs) const { return rhs; } 
# 1200
}; 
# 1223
template< class Predicate> 
# 1224
struct unary_negate : public unary_function< typename Predicate::argument_type, bool>  { 
# 1231
explicit unary_negate(Predicate p) : pred(p) { } 
# 1236
bool operator()(const typename Predicate::argument_type &x) { return !(pred)(x); } 
# 1240
Predicate pred; 
# 1243
}; 
# 1261
template< class Predicate> unary_negate< Predicate>  not1(const Predicate & pred); 
# 1275
template< class Predicate> 
# 1276
struct binary_negate : public binary_function< typename Predicate::first_argument_type, typename Predicate::second_argument_type, bool>  { 
# 1285
explicit binary_negate(Predicate p) : pred(p) { } 
# 1290
bool operator()(const typename Predicate::first_argument_type &x, const typename Predicate::second_argument_type &y) 
# 1291
{ 
# 1292
return !(pred)(x, y); 
# 1293
} 
# 1297
Predicate pred; 
# 1300
}; 
# 1318
template< class BinaryPredicate> binary_negate< BinaryPredicate>  not2(const BinaryPredicate & pred); 
# 1374
namespace placeholders { 
# 1383
static const detail::functional::placeholder< 0U> ::type _1; 
# 1392
static const detail::functional::placeholder< 1U> ::type _2; 
# 1401
static const detail::functional::placeholder< 2U> ::type _3; 
# 1410
static const detail::functional::placeholder< 3U> ::type _4; 
# 1419
static const detail::functional::placeholder< 4U> ::type _5; 
# 1428
static const detail::functional::placeholder< 5U> ::type _6; 
# 1437
static const detail::functional::placeholder< 6U> ::type _7; 
# 1446
static const detail::functional::placeholder< 7U> ::type _8; 
# 1455
static const detail::functional::placeholder< 8U> ::type _9; 
# 1464
static const detail::functional::placeholder< 9U> ::type _10; 
# 1468
}
# 1475
}
# 19 "/usr/local/cuda-8.0/include/thrust/detail/functional.inl"
namespace thrust { 
# 22
namespace detail { 
# 25
template< class Operation> struct unary_traits_imp; 
# 28
template< class Operation> 
# 29
struct unary_traits_imp< Operation *>  { 
# 31
typedef Operation function_type; 
# 32
typedef const function_type &param_type; 
# 33
typedef typename Operation::result_type result_type; 
# 34
typedef typename Operation::argument_type argument_type; 
# 35
}; 
# 37
template< class Result, class Argument> 
# 38
struct unary_traits_imp< Result (*)(Argument)>  { 
# 40
typedef Result (*function_type)(Argument); 
# 41
typedef Result (*param_type)(Argument); 
# 42
typedef Result result_type; 
# 43
typedef Argument argument_type; 
# 44
}; 
# 46
template< class Operation> struct binary_traits_imp; 
# 49
template< class Operation> 
# 50
struct binary_traits_imp< Operation *>  { 
# 52
typedef Operation function_type; 
# 53
typedef const function_type &param_type; 
# 54
typedef typename Operation::result_type result_type; 
# 55
typedef typename Operation::first_argument_type first_argument_type; 
# 56
typedef typename Operation::second_argument_type second_argument_type; 
# 57
}; 
# 59
template< class Result, class Argument1, class Argument2> 
# 60
struct binary_traits_imp< Result (*)(Argument1, Argument2)>  { 
# 62
typedef Result (*function_type)(Argument1, Argument2); 
# 63
typedef Result (*param_type)(Argument1, Argument2); 
# 64
typedef Result result_type; 
# 65
typedef Argument1 first_argument_type; 
# 66
typedef Argument2 second_argument_type; 
# 67
}; 
# 69
}
# 71
template< class Operation> 
# 72
struct unary_traits { 
# 74
typedef typename detail::unary_traits_imp< Operation *> ::function_type function_type; 
# 75
typedef typename detail::unary_traits_imp< Operation *> ::param_type param_type; 
# 76
typedef typename detail::unary_traits_imp< Operation *> ::result_type result_type; 
# 77
typedef typename detail::unary_traits_imp< Operation *> ::argument_type argument_type; 
# 78
}; 
# 80
template< class Result, class Argument> 
# 81
struct unary_traits< Result (*)(Argument)>  { 
# 83
typedef Result (*function_type)(Argument); 
# 84
typedef Result (*param_type)(Argument); 
# 85
typedef Result result_type; 
# 86
typedef Argument argument_type; 
# 87
}; 
# 89
template< class Operation> 
# 90
struct binary_traits { 
# 92
typedef typename detail::binary_traits_imp< Operation *> ::function_type function_type; 
# 93
typedef typename detail::binary_traits_imp< Operation *> ::param_type param_type; 
# 94
typedef typename detail::binary_traits_imp< Operation *> ::result_type result_type; 
# 95
typedef typename detail::binary_traits_imp< Operation *> ::first_argument_type first_argument_type; 
# 96
typedef typename detail::binary_traits_imp< Operation *> ::second_argument_type second_argument_type; 
# 97
}; 
# 99
template< class Result, class Argument1, class Argument2> 
# 100
struct binary_traits< Result (*)(Argument1, Argument2)>  { 
# 102
typedef Result (*function_type)(Argument1, Argument2); 
# 103
typedef Result (*param_type)(Argument1, Argument2); 
# 104
typedef Result result_type; 
# 105
typedef Argument1 first_argument_type; 
# 106
typedef Argument2 second_argument_type; 
# 107
}; 
# 109
template< class Predicate> unary_negate< Predicate>  
# 110
not1(const Predicate &pred) 
# 111
{ 
# 112
return ((unary_negate< Predicate> )(pred)); 
# 113
} 
# 115
template< class BinaryPredicate> binary_negate< BinaryPredicate>  
# 116
not2(const BinaryPredicate &pred) 
# 117
{ 
# 118
return ((binary_negate< BinaryPredicate> )(pred)); 
# 119
} 
# 121
}
# 25 "/usr/local/cuda-8.0/include/thrust/detail/functional/operators/arithmetic_operators.h"
namespace thrust { 
# 27
namespace detail { 
# 29
namespace functional { 
# 32
template< class Eval> actor< composite< unary_operator< negate> , actor< Eval> > >  
# 41
operator-(const actor< Eval>  &_1) 
# 42
{ 
# 43
return compose(unary_operator< negate> (), _1); 
# 44
} 
# 47
template< class T> 
# 48
struct unary_plus : public unary_function< T, T>  { 
# 51
T operator()(const T &x) const { return +x; } 
# 52
}; 
# 54
template< class Eval> actor< composite< unary_operator< unary_plus> , actor< Eval> > >  
# 62
operator+(const actor< Eval>  &_1) 
# 63
{ 
# 64
return compose(unary_operator< unary_plus> (), _1); 
# 65
} 
# 67
template< class T1, class T2> actor< composite< binary_operator< plus> , actor< T1> , typename as_actor< T2> ::type> >  
# 76
operator+(const actor< T1>  &_1, const T2 &_2) 
# 77
{ 
# 78
return compose(binary_operator< plus> (), make_actor(_1), make_actor(_2)); 
# 81
} 
# 83
template< class T1, class T2> actor< composite< binary_operator< plus> , typename as_actor< T1> ::type, actor< T2> > >  
# 92
operator+(const T1 &_1, const actor< T2>  &_2) 
# 93
{ 
# 94
return compose(binary_operator< plus> (), make_actor(_1), make_actor(_2)); 
# 97
} 
# 99
template< class T1, class T2> actor< composite< binary_operator< plus> , actor< T1> , actor< T2> > >  
# 108
operator+(const actor< T1>  &_1, const actor< T2>  &_2) 
# 109
{ 
# 110
return compose(binary_operator< plus> (), make_actor(_1), make_actor(_2)); 
# 113
} 
# 115
template< class T1, class T2> actor< composite< binary_operator< minus> , typename as_actor< T1> ::type, actor< T2> > >  
# 124
operator-(const T1 &_1, const actor< T2>  &_2) 
# 125
{ 
# 126
return compose(binary_operator< minus> (), make_actor(_1), make_actor(_2)); 
# 129
} 
# 131
template< class T1, class T2> actor< composite< binary_operator< minus> , actor< T1> , typename as_actor< T2> ::type> >  
# 140
operator-(const actor< T1>  &_1, const T2 &_2) 
# 141
{ 
# 142
return compose(binary_operator< minus> (), make_actor(_1), make_actor(_2)); 
# 145
} 
# 147
template< class T1, class T2> actor< composite< binary_operator< minus> , actor< T1> , actor< T2> > >  
# 156
operator-(const actor< T1>  &_1, const actor< T2>  &_2) 
# 157
{ 
# 158
return compose(binary_operator< minus> (), make_actor(_1), make_actor(_2)); 
# 161
} 
# 163
template< class T1, class T2> actor< composite< binary_operator< multiplies> , typename as_actor< T1> ::type, actor< T2> > >  
# 172
operator*(const T1 &_1, const actor< T2>  &_2) 
# 173
{ 
# 174
return compose(binary_operator< multiplies> (), make_actor(_1), make_actor(_2)); 
# 177
} 
# 179
template< class T1, class T2> actor< composite< binary_operator< multiplies> , actor< T1> , typename as_actor< T2> ::type> >  
# 188
operator*(const actor< T1>  &_1, const T2 &_2) 
# 189
{ 
# 190
return compose(binary_operator< multiplies> (), make_actor(_1), make_actor(_2)); 
# 193
} 
# 195
template< class T1, class T2> actor< composite< binary_operator< multiplies> , actor< T1> , actor< T2> > >  
# 204
operator*(const actor< T1>  &_1, const actor< T2>  &_2) 
# 205
{ 
# 206
return compose(binary_operator< multiplies> (), make_actor(_1), make_actor(_2)); 
# 209
} 
# 211
template< class T1, class T2> actor< composite< binary_operator< divides> , actor< T1> , typename as_actor< T2> ::type> >  
# 220
operator/(const actor< T1>  &_1, const T2 &_2) 
# 221
{ 
# 222
return compose(binary_operator< divides> (), make_actor(_1), make_actor(_2)); 
# 225
} 
# 227
template< class T1, class T2> actor< composite< binary_operator< divides> , typename as_actor< T1> ::type, actor< T2> > >  
# 236
operator/(const T1 &_1, const actor< T2>  &_2) 
# 237
{ 
# 238
return compose(binary_operator< divides> (), make_actor(_1), make_actor(_2)); 
# 241
} 
# 243
template< class T1, class T2> actor< composite< binary_operator< divides> , actor< T1> , actor< T2> > >  
# 252
operator/(const actor< T1>  &_1, const actor< T2>  &_2) 
# 253
{ 
# 254
return compose(binary_operator< divides> (), make_actor(_1), make_actor(_2)); 
# 257
} 
# 259
template< class T1, class T2> actor< composite< binary_operator< modulus> , actor< T1> , typename as_actor< T2> ::type> >  
# 268
operator%(const actor< T1>  &_1, const T2 &_2) 
# 269
{ 
# 270
return compose(binary_operator< modulus> (), make_actor(_1), make_actor(_2)); 
# 273
} 
# 275
template< class T1, class T2> actor< composite< binary_operator< modulus> , typename as_actor< T1> ::type, actor< T2> > >  
# 284
operator%(const T1 &_1, const actor< T2>  &_2) 
# 285
{ 
# 286
return compose(binary_operator< modulus> (), make_actor(_1), make_actor(_2)); 
# 289
} 
# 291
template< class T1, class T2> actor< composite< binary_operator< modulus> , actor< T1> , actor< T2> > >  
# 300
operator%(const actor< T1>  &_1, const actor< T2>  &_2) 
# 301
{ 
# 302
return compose(binary_operator< modulus> (), make_actor(_1), make_actor(_2)); 
# 305
} 
# 308
template< class T> 
# 309
struct prefix_increment : public unary_function< T &, T &>  { 
# 312
T &operator()(T &x) const { return ++x; } 
# 313
}; 
# 315
template< class Eval> actor< composite< unary_operator< prefix_increment> , actor< Eval> > >  
# 323
operator++(const actor< Eval>  &_1) 
# 324
{ 
# 325
return compose(unary_operator< prefix_increment> (), _1); 
# 326
} 
# 329
template< class T> 
# 330
struct suffix_increment : public unary_function< T &, T>  { 
# 333
T operator()(T &x) const { return x++; } 
# 334
}; 
# 336
template< class Eval> actor< composite< unary_operator< suffix_increment> , actor< Eval> > >  
# 344
operator++(const actor< Eval>  &_1, int) 
# 345
{ 
# 346
return compose(unary_operator< suffix_increment> (), _1); 
# 347
} 
# 350
template< class T> 
# 351
struct prefix_decrement : public unary_function< T &, T &>  { 
# 354
T &operator()(T &x) const { return --x; } 
# 355
}; 
# 357
template< class Eval> actor< composite< unary_operator< prefix_decrement> , actor< Eval> > >  
# 365
operator--(const actor< Eval>  &_1) 
# 366
{ 
# 367
return compose(unary_operator< prefix_decrement> (), _1); 
# 368
} 
# 371
template< class T> 
# 372
struct suffix_decrement : public unary_function< T &, T>  { 
# 375
T operator()(T &x) const { return x--; } 
# 376
}; 
# 378
template< class Eval> actor< composite< unary_operator< suffix_decrement> , actor< Eval> > >  
# 386
operator--(const actor< Eval>  &_1, int) 
# 387
{ 
# 388
return compose(unary_operator< suffix_decrement> (), _1); 
# 389
} 
# 391
}
# 392
}
# 393
}
# 25 "/usr/local/cuda-8.0/include/thrust/detail/functional/operators/relational_operators.h"
namespace thrust { 
# 27
namespace detail { 
# 29
namespace functional { 
# 32
template< class T1, class T2> actor< composite< binary_operator< thrust::equal_to> , actor< T1> , typename as_actor< T2> ::type> >  
# 41
operator==(const actor< T1>  &_1, const T2 &_2) 
# 42
{ 
# 43
return compose(binary_operator< thrust::equal_to> (), make_actor(_1), make_actor(_2)); 
# 46
} 
# 48
template< class T1, class T2> actor< composite< binary_operator< thrust::equal_to> , typename as_actor< T1> ::type, actor< T2> > >  
# 57
operator==(const T1 &_1, const actor< T2>  &_2) 
# 58
{ 
# 59
return compose(binary_operator< thrust::equal_to> (), make_actor(_1), make_actor(_2)); 
# 62
} 
# 64
template< class T1, class T2> actor< composite< binary_operator< thrust::equal_to> , actor< T1> , actor< T2> > >  
# 73
operator==(const actor< T1>  &_1, const actor< T2>  &_2) 
# 74
{ 
# 75
return compose(binary_operator< thrust::equal_to> (), make_actor(_1), make_actor(_2)); 
# 78
} 
# 80
template< class T1, class T2> actor< composite< binary_operator< not_equal_to> , actor< T1> , typename as_actor< T2> ::type> >  
# 89
operator!=(const actor< T1>  &_1, const T2 &_2) 
# 90
{ 
# 91
return compose(binary_operator< not_equal_to> (), make_actor(_1), make_actor(_2)); 
# 94
} 
# 96
template< class T1, class T2> actor< composite< binary_operator< not_equal_to> , typename as_actor< T1> ::type, actor< T2> > >  
# 105
operator!=(const T1 &_1, const actor< T2>  &_2) 
# 106
{ 
# 107
return compose(binary_operator< not_equal_to> (), make_actor(_1), make_actor(_2)); 
# 110
} 
# 112
template< class T1, class T2> actor< composite< binary_operator< not_equal_to> , actor< T1> , actor< T2> > >  
# 121
operator!=(const actor< T1>  &_1, const actor< T2>  &_2) 
# 122
{ 
# 123
return compose(binary_operator< not_equal_to> (), make_actor(_1), make_actor(_2)); 
# 126
} 
# 128
template< class T1, class T2> actor< composite< binary_operator< greater> , actor< T1> , typename as_actor< T2> ::type> >  
# 137
operator>(const actor< T1>  &_1, const T2 &_2) 
# 138
{ 
# 139
return compose(binary_operator< greater> (), make_actor(_1), make_actor(_2)); 
# 142
} 
# 144
template< class T1, class T2> actor< composite< binary_operator< greater> , typename as_actor< T1> ::type, actor< T2> > >  
# 153
operator>(const T1 &_1, const actor< T2>  &_2) 
# 154
{ 
# 155
return compose(binary_operator< greater> (), make_actor(_1), make_actor(_2)); 
# 158
} 
# 160
template< class T1, class T2> actor< composite< binary_operator< greater> , actor< T1> , actor< T2> > >  
# 169
operator>(const actor< T1>  &_1, const actor< T2>  &_2) 
# 170
{ 
# 171
return compose(binary_operator< greater> (), make_actor(_1), make_actor(_2)); 
# 174
} 
# 176
template< class T1, class T2> actor< composite< binary_operator< less> , actor< T1> , typename as_actor< T2> ::type> >  
# 185
operator<(const actor< T1>  &_1, const T2 &_2) 
# 186
{ 
# 187
return compose(binary_operator< less> (), make_actor(_1), make_actor(_2)); 
# 190
} 
# 192
template< class T1, class T2> actor< composite< binary_operator< less> , typename as_actor< T1> ::type, actor< T2> > >  
# 201
operator<(const T1 &_1, const actor< T2>  &_2) 
# 202
{ 
# 203
return compose(binary_operator< less> (), make_actor(_1), make_actor(_2)); 
# 206
} 
# 208
template< class T1, class T2> actor< composite< binary_operator< less> , actor< T1> , actor< T2> > >  
# 217
operator<(const actor< T1>  &_1, const actor< T2>  &_2) 
# 218
{ 
# 219
return compose(binary_operator< less> (), make_actor(_1), make_actor(_2)); 
# 222
} 
# 224
template< class T1, class T2> actor< composite< binary_operator< greater_equal> , actor< T1> , typename as_actor< T2> ::type> >  
# 233
operator>=(const actor< T1>  &_1, const T2 &_2) 
# 234
{ 
# 235
return compose(binary_operator< greater_equal> (), make_actor(_1), make_actor(_2)); 
# 238
} 
# 240
template< class T1, class T2> actor< composite< binary_operator< greater_equal> , typename as_actor< T1> ::type, actor< T2> > >  
# 249
operator>=(const T1 &_1, const actor< T2>  &_2) 
# 250
{ 
# 251
return compose(binary_operator< greater_equal> (), make_actor(_1), make_actor(_2)); 
# 254
} 
# 256
template< class T1, class T2> actor< composite< binary_operator< greater_equal> , actor< T1> , actor< T2> > >  
# 265
operator>=(const actor< T1>  &_1, const actor< T2>  &_2) 
# 266
{ 
# 267
return compose(binary_operator< greater_equal> (), make_actor(_1), make_actor(_2)); 
# 270
} 
# 272
template< class T1, class T2> actor< composite< binary_operator< less_equal> , actor< T1> , typename as_actor< T2> ::type> >  
# 281
operator<=(const actor< T1>  &_1, const T2 &_2) 
# 282
{ 
# 283
return compose(binary_operator< less_equal> (), make_actor(_1), make_actor(_2)); 
# 286
} 
# 288
template< class T1, class T2> actor< composite< binary_operator< less_equal> , typename as_actor< T1> ::type, actor< T2> > >  
# 297
operator<=(const T1 &_1, const actor< T2>  &_2) 
# 298
{ 
# 299
return compose(binary_operator< less_equal> (), make_actor(_1), make_actor(_2)); 
# 302
} 
# 304
template< class T1, class T2> actor< composite< binary_operator< less_equal> , actor< T1> , actor< T2> > >  
# 313
operator<=(const actor< T1>  &_1, const actor< T2>  &_2) 
# 314
{ 
# 315
return compose(binary_operator< less_equal> (), make_actor(_1), make_actor(_2)); 
# 318
} 
# 320
}
# 321
}
# 322
}
# 25 "/usr/local/cuda-8.0/include/thrust/detail/functional/operators/logical_operators.h"
namespace thrust { 
# 27
namespace detail { 
# 29
namespace functional { 
# 32
template< class T1, class T2> actor< composite< binary_operator< logical_and> , actor< T1> , typename as_actor< T2> ::type> >  
# 41
operator&&(const actor< T1>  &_1, const T2 &_2) 
# 42
{ 
# 43
return compose(binary_operator< logical_and> (), make_actor(_1), make_actor(_2)); 
# 46
} 
# 48
template< class T1, class T2> actor< composite< binary_operator< logical_and> , typename as_actor< T1> ::type, actor< T2> > >  
# 57
operator&&(const T1 &_1, const actor< T2>  &_2) 
# 58
{ 
# 59
return compose(binary_operator< logical_and> (), make_actor(_1), make_actor(_2)); 
# 62
} 
# 64
template< class T1, class T2> actor< composite< binary_operator< logical_and> , actor< T1> , actor< T2> > >  
# 73
operator&&(const actor< T1>  &_1, const actor< T2>  &_2) 
# 74
{ 
# 75
return compose(binary_operator< logical_and> (), make_actor(_1), make_actor(_2)); 
# 78
} 
# 80
template< class T1, class T2> actor< composite< binary_operator< logical_or> , actor< T1> , typename as_actor< T2> ::type> >  
# 89
operator||(const actor< T1>  &_1, const T2 &_2) 
# 90
{ 
# 91
return compose(binary_operator< logical_or> (), make_actor(_1), make_actor(_2)); 
# 94
} 
# 96
template< class T1, class T2> actor< composite< binary_operator< logical_or> , typename as_actor< T1> ::type, actor< T2> > >  
# 105
operator||(const T1 &_1, const actor< T2>  &_2) 
# 106
{ 
# 107
return compose(binary_operator< logical_or> (), make_actor(_1), make_actor(_2)); 
# 110
} 
# 112
template< class T1, class T2> actor< composite< binary_operator< logical_or> , actor< T1> , actor< T2> > >  
# 121
operator||(const actor< T1>  &_1, const actor< T2>  &_2) 
# 122
{ 
# 123
return compose(binary_operator< logical_or> (), make_actor(_1), make_actor(_2)); 
# 126
} 
# 128
template< class Eval> actor< composite< unary_operator< logical_not> , actor< Eval> > >  
# 136
operator!(const actor< Eval>  &_1) 
# 137
{ 
# 138
return compose(unary_operator< logical_not> (), _1); 
# 139
} 
# 141
}
# 142
}
# 143
}
# 25 "/usr/local/cuda-8.0/include/thrust/detail/functional/operators/bitwise_operators.h"
namespace thrust { 
# 27
namespace detail { 
# 29
namespace functional { 
# 32
template< class T1, class T2> actor< composite< binary_operator< bit_and> , actor< T1> , typename as_actor< T2> ::type> >  
# 41
operator&(const actor< T1>  &_1, const T2 &_2) 
# 42
{ 
# 43
return compose(binary_operator< bit_and> (), make_actor(_1), make_actor(_2)); 
# 46
} 
# 48
template< class T1, class T2> actor< composite< binary_operator< bit_and> , typename as_actor< T1> ::type, actor< T2> > >  
# 57
operator&(const T1 &_1, const actor< T2>  &_2) 
# 58
{ 
# 59
return compose(binary_operator< bit_and> (), make_actor(_1), make_actor(_2)); 
# 62
} 
# 64
template< class T1, class T2> actor< composite< binary_operator< bit_and> , actor< T1> , actor< T2> > >  
# 73
operator&(const actor< T1>  &_1, const actor< T2>  &_2) 
# 74
{ 
# 75
return compose(binary_operator< bit_and> (), make_actor(_1), make_actor(_2)); 
# 78
} 
# 80
template< class T1, class T2> actor< composite< binary_operator< bit_or> , actor< T1> , typename as_actor< T2> ::type> >  
# 89
operator|(const actor< T1>  &_1, const T2 &_2) 
# 90
{ 
# 91
return compose(binary_operator< bit_or> (), make_actor(_1), make_actor(_2)); 
# 94
} 
# 96
template< class T1, class T2> actor< composite< binary_operator< bit_or> , typename as_actor< T1> ::type, actor< T2> > >  
# 105
operator|(const T1 &_1, const actor< T2>  &_2) 
# 106
{ 
# 107
return compose(binary_operator< bit_or> (), make_actor(_1), make_actor(_2)); 
# 110
} 
# 112
template< class T1, class T2> actor< composite< binary_operator< bit_or> , actor< T1> , actor< T2> > >  
# 121
operator|(const actor< T1>  &_1, const actor< T2>  &_2) 
# 122
{ 
# 123
return compose(binary_operator< bit_or> (), make_actor(_1), make_actor(_2)); 
# 126
} 
# 128
template< class T1, class T2> actor< composite< binary_operator< bit_xor> , actor< T1> , typename as_actor< T2> ::type> >  
# 137
operator^(const actor< T1>  &_1, const T2 &_2) 
# 138
{ 
# 139
return compose(binary_operator< bit_xor> (), make_actor(_1), make_actor(_2)); 
# 142
} 
# 144
template< class T1, class T2> actor< composite< binary_operator< bit_xor> , typename as_actor< T1> ::type, actor< T2> > >  
# 153
operator^(const T1 &_1, const actor< T2>  &_2) 
# 154
{ 
# 155
return compose(binary_operator< bit_xor> (), make_actor(_1), make_actor(_2)); 
# 158
} 
# 160
template< class T1, class T2> actor< composite< binary_operator< bit_xor> , actor< T1> , actor< T2> > >  
# 169
operator^(const actor< T1>  &_1, const actor< T2>  &_2) 
# 170
{ 
# 171
return compose(binary_operator< bit_xor> (), make_actor(_1), make_actor(_2)); 
# 174
} 
# 177
template< class T> 
# 178
struct bit_not : public unary_function< T, T>  { 
# 181
T operator()(const T &x) const { return ~x; } 
# 182
}; 
# 184
template< class Eval> actor< composite< unary_operator< bit_not> , actor< Eval> > >  
# 193
operator~(const actor< Eval>  &_1) 
# 194
{ 
# 195
return compose(unary_operator< bit_not> (), _1); 
# 196
} 
# 199
template< class T> 
# 200
struct bit_lshift : public binary_function< T, T, T>  { 
# 203
T operator()(const T &lhs, const T &rhs) const { return lhs << rhs; } 
# 204
}; 
# 206
template< class T1, class T2> actor< composite< binary_operator< bit_lshift> , actor< T1> , typename as_actor< T2> ::type> >  
# 215
operator<<(const actor< T1>  &_1, const T2 &_2) 
# 216
{ 
# 217
return compose(binary_operator< bit_lshift> (), make_actor(_1), make_actor(_2)); 
# 220
} 
# 222
template< class T1, class T2> actor< composite< binary_operator< bit_lshift> , typename as_actor< T1> ::type, actor< T2> > >  
# 231
operator<<(const T1 &_1, const actor< T2>  &_2) 
# 232
{ 
# 233
return compose(binary_operator< bit_lshift> (), make_actor(_1), make_actor(_2)); 
# 236
} 
# 238
template< class T1, class T2> actor< composite< binary_operator< bit_lshift> , actor< T1> , actor< T2> > >  
# 247
operator<<(const actor< T1>  &_1, const actor< T2>  &_2) 
# 248
{ 
# 249
return compose(binary_operator< bit_lshift> (), make_actor(_1), make_actor(_2)); 
# 252
} 
# 255
template< class T> 
# 256
struct bit_rshift : public binary_function< T, T, T>  { 
# 259
T operator()(const T &lhs, const T &rhs) const { return lhs >> rhs; } 
# 260
}; 
# 262
template< class T1, class T2> actor< composite< binary_operator< bit_rshift> , actor< T1> , typename as_actor< T2> ::type> >  
# 271
operator>>(const actor< T1>  &_1, const T2 &_2) 
# 272
{ 
# 273
return compose(binary_operator< bit_rshift> (), make_actor(_1), make_actor(_2)); 
# 276
} 
# 278
template< class T1, class T2> actor< composite< binary_operator< bit_rshift> , typename as_actor< T1> ::type, actor< T2> > >  
# 287
operator>>(const T1 &_1, const actor< T2>  &_2) 
# 288
{ 
# 289
return compose(binary_operator< bit_rshift> (), make_actor(_1), make_actor(_2)); 
# 292
} 
# 294
template< class T1, class T2> actor< composite< binary_operator< bit_rshift> , actor< T1> , actor< T2> > >  
# 303
operator>>(const actor< T1>  &_1, const actor< T2>  &_2) 
# 304
{ 
# 305
return compose(binary_operator< bit_rshift> (), make_actor(_1), make_actor(_2)); 
# 308
} 
# 310
}
# 311
}
# 312
}
# 24 "/usr/local/cuda-8.0/include/thrust/detail/functional/operators/compound_assignment_operators.h"
namespace thrust { 
# 26
namespace detail { 
# 28
namespace functional { 
# 31
template< class T> 
# 32
struct plus_equal : public binary_function< T &, T, T &>  { 
# 35
T &operator()(T &lhs, const T &rhs) const { return lhs += rhs; } 
# 36
}; 
# 38
template< class T1, class T2> actor< composite< binary_operator< plus_equal> , actor< T1> , typename as_actor< T2> ::type> >  
# 47
operator+=(const actor< T1>  &_1, const T2 &_2) 
# 48
{ 
# 49
return compose(binary_operator< plus_equal> (), make_actor(_1), make_actor(_2)); 
# 52
} 
# 54
template< class T1, class T2> actor< composite< binary_operator< plus_equal> , actor< T1> , actor< T2> > >  
# 63
operator+=(const actor< T1>  &_1, const actor< T2>  &_2) 
# 64
{ 
# 65
return compose(binary_operator< plus_equal> (), make_actor(_1), make_actor(_2)); 
# 68
} 
# 70
template< class T> 
# 71
struct minus_equal : public binary_function< T &, T, T &>  { 
# 74
T &operator()(T &lhs, const T &rhs) const { return lhs -= rhs; } 
# 75
}; 
# 77
template< class T1, class T2> actor< composite< binary_operator< minus_equal> , actor< T1> , typename as_actor< T2> ::type> >  
# 86
operator-=(const actor< T1>  &_1, const T2 &_2) 
# 87
{ 
# 88
return compose(binary_operator< minus_equal> (), make_actor(_1), make_actor(_2)); 
# 91
} 
# 93
template< class T1, class T2> actor< composite< binary_operator< minus_equal> , actor< T1> , actor< T2> > >  
# 102
operator-=(const actor< T1>  &_1, const actor< T2>  &_2) 
# 103
{ 
# 104
return compose(binary_operator< minus_equal> (), make_actor(_1), make_actor(_2)); 
# 107
} 
# 109
template< class T> 
# 110
struct multiplies_equal : public binary_function< T &, T, T &>  { 
# 113
T &operator()(T &lhs, const T &rhs) const { return lhs *= rhs; } 
# 114
}; 
# 116
template< class T1, class T2> actor< composite< binary_operator< multiplies_equal> , actor< T1> , typename as_actor< T2> ::type> >  
# 125
operator*=(const actor< T1>  &_1, const T2 &_2) 
# 126
{ 
# 127
return compose(binary_operator< multiplies_equal> (), make_actor(_1), make_actor(_2)); 
# 130
} 
# 132
template< class T1, class T2> actor< composite< binary_operator< multiplies_equal> , actor< T1> , actor< T2> > >  
# 141
operator*=(const actor< T1>  &_1, const actor< T2>  &_2) 
# 142
{ 
# 143
return compose(binary_operator< multiplies_equal> (), make_actor(_1), make_actor(_2)); 
# 146
} 
# 148
template< class T> 
# 149
struct divides_equal : public binary_function< T &, T, T &>  { 
# 152
T &operator()(T &lhs, const T &rhs) const { return lhs /= rhs; } 
# 153
}; 
# 155
template< class T1, class T2> actor< composite< binary_operator< divides_equal> , actor< T1> , typename as_actor< T2> ::type> >  
# 164
operator/=(const actor< T1>  &_1, const T2 &_2) 
# 165
{ 
# 166
return compose(binary_operator< divides_equal> (), make_actor(_1), make_actor(_2)); 
# 169
} 
# 171
template< class T1, class T2> actor< composite< binary_operator< divides_equal> , actor< T1> , actor< T2> > >  
# 180
operator/=(const actor< T1>  &_1, const actor< T2>  &_2) 
# 181
{ 
# 182
return compose(binary_operator< divides_equal> (), make_actor(_1), make_actor(_2)); 
# 185
} 
# 187
template< class T> 
# 188
struct modulus_equal : public binary_function< T &, T, T &>  { 
# 191
T &operator()(T &lhs, const T &rhs) const { return lhs %= rhs; } 
# 192
}; 
# 194
template< class T1, class T2> actor< composite< binary_operator< modulus_equal> , actor< T1> , typename as_actor< T2> ::type> >  
# 203
operator%=(const actor< T1>  &_1, const T2 &_2) 
# 204
{ 
# 205
return compose(binary_operator< modulus_equal> (), make_actor(_1), make_actor(_2)); 
# 208
} 
# 210
template< class T1, class T2> actor< composite< binary_operator< modulus_equal> , actor< T1> , actor< T2> > >  
# 219
operator%=(const actor< T1>  &_1, const actor< T2>  &_2) 
# 220
{ 
# 221
return compose(binary_operator< modulus_equal> (), make_actor(_1), make_actor(_2)); 
# 224
} 
# 226
template< class T> 
# 227
struct bit_and_equal : public binary_function< T &, T, T &>  { 
# 230
T &operator()(T &lhs, const T &rhs) const { return lhs &= rhs; } 
# 231
}; 
# 233
template< class T1, class T2> actor< composite< binary_operator< bit_and_equal> , actor< T1> , typename as_actor< T2> ::type> >  
# 242
operator&=(const actor< T1>  &_1, const T2 &_2) 
# 243
{ 
# 244
return compose(binary_operator< bit_and_equal> (), make_actor(_1), make_actor(_2)); 
# 247
} 
# 249
template< class T1, class T2> actor< composite< binary_operator< bit_and_equal> , actor< T1> , actor< T2> > >  
# 258
operator&=(const actor< T1>  &_1, const actor< T2>  &_2) 
# 259
{ 
# 260
return compose(binary_operator< bit_and_equal> (), make_actor(_1), make_actor(_2)); 
# 263
} 
# 265
template< class T> 
# 266
struct bit_or_equal : public binary_function< T &, T, T &>  { 
# 269
T &operator()(T &lhs, const T &rhs) const { return lhs |= rhs; } 
# 270
}; 
# 272
template< class T1, class T2> actor< composite< binary_operator< bit_or_equal> , actor< T1> , typename as_actor< T2> ::type> >  
# 281
operator|=(const actor< T1>  &_1, const T2 &_2) 
# 282
{ 
# 283
return compose(binary_operator< bit_or_equal> (), make_actor(_1), make_actor(_2)); 
# 286
} 
# 288
template< class T1, class T2> actor< composite< binary_operator< bit_or_equal> , actor< T1> , actor< T2> > >  
# 297
operator|=(const actor< T1>  &_1, const actor< T2>  &_2) 
# 298
{ 
# 299
return compose(binary_operator< bit_or_equal> (), make_actor(_1), make_actor(_2)); 
# 302
} 
# 304
template< class T> 
# 305
struct bit_xor_equal : public binary_function< T &, T, T &>  { 
# 308
T &operator()(T &lhs, const T &rhs) const { return lhs ^= rhs; } 
# 309
}; 
# 311
template< class T1, class T2> actor< composite< binary_operator< bit_xor_equal> , actor< T1> , typename as_actor< T2> ::type> >  
# 320
operator^=(const actor< T1>  &_1, const T2 &_2) 
# 321
{ 
# 322
return compose(binary_operator< bit_xor_equal> (), make_actor(_1), make_actor(_2)); 
# 325
} 
# 327
template< class T1, class T2> actor< composite< binary_operator< bit_xor_equal> , actor< T1> , actor< T2> > >  
# 336
operator^=(const actor< T1>  &_1, const actor< T2>  &_2) 
# 337
{ 
# 338
return compose(binary_operator< bit_xor_equal> (), make_actor(_1), make_actor(_2)); 
# 341
} 
# 343
template< class T> 
# 344
struct bit_lshift_equal : public binary_function< T &, T, T &>  { 
# 347
T &operator()(T &lhs, const T &rhs) const { return lhs <<= rhs; } 
# 348
}; 
# 350
template< class T1, class T2> actor< composite< binary_operator< bit_lshift_equal> , actor< T1> , typename as_actor< T2> ::type> >  
# 359
operator<<=(const actor< T1>  &_1, const T2 &_2) 
# 360
{ 
# 361
return compose(binary_operator< bit_lshift_equal> (), make_actor(_1), make_actor(_2)); 
# 364
} 
# 366
template< class T1, class T2> actor< composite< binary_operator< bit_lshift_equal> , actor< T1> , actor< T2> > >  
# 375
operator<<=(const actor< T1>  &_1, const actor< T2>  &_2) 
# 376
{ 
# 377
return compose(binary_operator< bit_lshift_equal> (), make_actor(_1), make_actor(_2)); 
# 380
} 
# 382
template< class T> 
# 383
struct bit_rshift_equal : public binary_function< T &, T, T &>  { 
# 386
T &operator()(T &lhs, const T &rhs) const { return lhs >>= rhs; } 
# 387
}; 
# 389
template< class T1, class T2> actor< composite< binary_operator< bit_rshift_equal> , actor< T1> , typename as_actor< T2> ::type> >  
# 398
operator>>=(const actor< T1>  &_1, const T2 &_2) 
# 399
{ 
# 400
return compose(binary_operator< bit_rshift_equal> (), make_actor(_1), make_actor(_2)); 
# 403
} 
# 405
template< class T1, class T2> actor< composite< binary_operator< bit_rshift_equal> , actor< T1> , actor< T2> > >  
# 414
operator>>=(const actor< T1>  &_1, const actor< T2>  &_2) 
# 415
{ 
# 416
return compose(binary_operator< bit_rshift_equal> (), make_actor(_1), make_actor(_2)); 
# 419
} 
# 421
}
# 422
}
# 423
}
# 22 "/usr/local/cuda-8.0/include/thrust/detail/reference_forward_declaration.h"
namespace thrust { 
# 25
template< class Element, class Pointer, class Derived = use_default> class reference; 
# 27
}
# 24 "/usr/local/cuda-8.0/include/thrust/iterator/detail/tuple_of_iterator_references.h"
namespace thrust { 
# 26
namespace detail { 
# 30
template< class 
# 31
T0, class T1, class T2, class 
# 32
T3, class T4, class T5, class 
# 33
T6, class T7, class T8, class 
# 34
T9> 
# 36
class tuple_of_iterator_references : public tuple< T0, T1, T2, T3, T4, T5, T6, T7, T8, T9>  { 
# 40
typedef ::thrust::tuple< T0, T1, T2, T3, T4, T5, T6, T7, T8, T9>  super_t; 
# 45
public: tuple_of_iterator_references(const super_t &other) : super_t(other) 
# 47
{ } 
# 51
template< class U1, class U2> tuple_of_iterator_references &
# 53
operator=(const cons< U1, U2>  &other) 
# 54
{ 
# 55
::thrust::tuple< T0, T1, T2, T3, T4, T5, T6, T7, T8, T9> ::operator=(other); 
# 56
return *this; 
# 57
} 
# 61
template< class U1, class U2> tuple_of_iterator_references &
# 63
operator=(const pair< U1, U2>  &other) 
# 64
{ 
# 65
::thrust::tuple< T0, T1, T2, T3, T4, T5, T6, T7, T8, T9> ::operator=(other); 
# 66
return *this; 
# 67
} 
# 72
template< class U0, class U1, class U2, class 
# 73
U3, class U4, class U5, class 
# 74
U6, class U7, class U8, class 
# 75
U9, class 
# 76
Pointer, class Derived> tuple_of_iterator_references &
# 87
operator=(const reference< ::thrust::tuple< U0, U1, U2, U3, U4, U5, U6, U7, U8, U9> , Pointer, Derived>  &other) 
# 88
{ 
# 89
typedef ::thrust::tuple< U0, U1, U2, U3, U4, U5, U6, U7, U8, U9>  tuple_type; 
# 92
tuple_type other_tuple = other; 
# 93
::thrust::tuple< T0, T1, T2, T3, T4, T5, T6, T7, T8, T9> ::operator=(other_tuple); 
# 94
return *this; 
# 95
} 
# 100
tuple_of_iterator_references() { } 
# 103
tuple_of_iterator_references(typename access_traits< T0> ::parameter_type t0) : super_t(t0, static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type())) 
# 114
{ } 
# 117
tuple_of_iterator_references(typename access_traits< T0> ::parameter_type t0, typename access_traits< T1> ::parameter_type 
# 118
t1) : super_t(t0, t1, static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type())) 
# 128
{ } 
# 131
tuple_of_iterator_references(typename access_traits< T0> ::parameter_type t0, typename access_traits< T1> ::parameter_type 
# 132
t1, typename access_traits< T2> ::parameter_type 
# 133
t2) : super_t(t0, t1, t2, static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type())) 
# 142
{ } 
# 145
tuple_of_iterator_references(typename access_traits< T0> ::parameter_type t0, typename access_traits< T1> ::parameter_type 
# 146
t1, typename access_traits< T2> ::parameter_type 
# 147
t2, typename access_traits< T3> ::parameter_type 
# 148
t3) : super_t(t0, t1, t2, t3, static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type())) 
# 156
{ } 
# 159
tuple_of_iterator_references(typename access_traits< T0> ::parameter_type t0, typename access_traits< T1> ::parameter_type 
# 160
t1, typename access_traits< T2> ::parameter_type 
# 161
t2, typename access_traits< T3> ::parameter_type 
# 162
t3, typename access_traits< T4> ::parameter_type 
# 163
t4) : super_t(t0, t1, t2, t3, t4, static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type())) 
# 170
{ } 
# 173
tuple_of_iterator_references(typename access_traits< T0> ::parameter_type t0, typename access_traits< T1> ::parameter_type 
# 174
t1, typename access_traits< T2> ::parameter_type 
# 175
t2, typename access_traits< T3> ::parameter_type 
# 176
t3, typename access_traits< T4> ::parameter_type 
# 177
t4, typename access_traits< T5> ::parameter_type 
# 178
t5) : super_t(t0, t1, t2, t3, t4, t5, static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type())) 
# 184
{ } 
# 187
tuple_of_iterator_references(typename access_traits< T0> ::parameter_type t0, typename access_traits< T1> ::parameter_type 
# 188
t1, typename access_traits< T2> ::parameter_type 
# 189
t2, typename access_traits< T3> ::parameter_type 
# 190
t3, typename access_traits< T4> ::parameter_type 
# 191
t4, typename access_traits< T5> ::parameter_type 
# 192
t5, typename access_traits< T6> ::parameter_type 
# 193
t6) : super_t(t0, t1, t2, t3, t4, t5, t6, static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type())) 
# 198
{ } 
# 201
tuple_of_iterator_references(typename access_traits< T0> ::parameter_type t0, typename access_traits< T1> ::parameter_type 
# 202
t1, typename access_traits< T2> ::parameter_type 
# 203
t2, typename access_traits< T3> ::parameter_type 
# 204
t3, typename access_traits< T4> ::parameter_type 
# 205
t4, typename access_traits< T5> ::parameter_type 
# 206
t5, typename access_traits< T6> ::parameter_type 
# 207
t6, typename access_traits< T7> ::parameter_type 
# 208
t7) : super_t(t0, t1, t2, t3, t4, t5, t6, t7, static_cast< const ::thrust::null_type &>(::thrust::null_type()), static_cast< const ::thrust::null_type &>(::thrust::null_type())) 
# 212
{ } 
# 215
tuple_of_iterator_references(typename access_traits< T0> ::parameter_type t0, typename access_traits< T1> ::parameter_type 
# 216
t1, typename access_traits< T2> ::parameter_type 
# 217
t2, typename access_traits< T3> ::parameter_type 
# 218
t3, typename access_traits< T4> ::parameter_type 
# 219
t4, typename access_traits< T5> ::parameter_type 
# 220
t5, typename access_traits< T6> ::parameter_type 
# 221
t6, typename access_traits< T7> ::parameter_type 
# 222
t7, typename access_traits< T8> ::parameter_type 
# 223
t8) : super_t(t0, t1, t2, t3, t4, t5, t6, t7, t8, static_cast< const ::thrust::null_type &>(::thrust::null_type())) 
# 226
{ } 
# 229
tuple_of_iterator_references(typename access_traits< T0> ::parameter_type t0, typename access_traits< T1> ::parameter_type 
# 230
t1, typename access_traits< T2> ::parameter_type 
# 231
t2, typename access_traits< T3> ::parameter_type 
# 232
t3, typename access_traits< T4> ::parameter_type 
# 233
t4, typename access_traits< T5> ::parameter_type 
# 234
t5, typename access_traits< T6> ::parameter_type 
# 235
t6, typename access_traits< T7> ::parameter_type 
# 236
t7, typename access_traits< T8> ::parameter_type 
# 237
t8, typename access_traits< T9> ::parameter_type 
# 238
t9) : super_t(t0, t1, t2, t3, t4, t5, t6, t7, t8, t9) 
# 240
{ } 
# 241
}; 
# 244
}
# 245
}
# 22 "/usr/local/cuda-8.0/include/thrust/detail/raw_pointer_cast.h"
namespace thrust { 
# 25
template< class Pointer> inline typename detail::pointer_traits< Pointer> ::raw_pointer 
# 27
raw_pointer_cast(const Pointer &ptr) 
# 28
{ 
# 29
return thrust::detail::pointer_traits< Pointer> ::get(ptr); 
# 30
} 
# 32
}
# 21 "/usr/local/cuda-8.0/include/thrust/detail/tuple_meta_transform.h"
namespace thrust { 
# 24
namespace detail { 
# 27
template< class Tuple, 
# 28
template< class >  class UnaryMetaFunction, unsigned 
# 29
sz = tuple_size< Tuple> ::value> struct tuple_meta_transform; 
# 32
template< class Tuple, 
# 33
template< class >  class UnaryMetaFunction> 
# 34
struct tuple_meta_transform< Tuple, UnaryMetaFunction, 0>  { 
# 36
typedef null_type type; 
# 37
}; 
# 39
template< class Tuple, 
# 40
template< class >  class UnaryMetaFunction> 
# 41
struct tuple_meta_transform< Tuple, UnaryMetaFunction, 1>  { 
# 45
typedef tuple< typename UnaryMetaFunction< typename tuple_element< 0, Tuple> ::type> ::type, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type>  type; 
# 46
}; 
# 48
template< class Tuple, 
# 49
template< class >  class UnaryMetaFunction> 
# 50
struct tuple_meta_transform< Tuple, UnaryMetaFunction, 2>  { 
# 55
typedef tuple< typename UnaryMetaFunction< typename tuple_element< 0, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 1, Tuple> ::type> ::type, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type>  type; 
# 56
}; 
# 58
template< class Tuple, 
# 59
template< class >  class UnaryMetaFunction> 
# 60
struct tuple_meta_transform< Tuple, UnaryMetaFunction, 3>  { 
# 66
typedef tuple< typename UnaryMetaFunction< typename tuple_element< 0, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 1, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 2, Tuple> ::type> ::type, null_type, null_type, null_type, null_type, null_type, null_type, null_type>  type; 
# 67
}; 
# 69
template< class Tuple, 
# 70
template< class >  class UnaryMetaFunction> 
# 71
struct tuple_meta_transform< Tuple, UnaryMetaFunction, 4>  { 
# 78
typedef tuple< typename UnaryMetaFunction< typename tuple_element< 0, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 1, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 2, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 3, Tuple> ::type> ::type, null_type, null_type, null_type, null_type, null_type, null_type>  type; 
# 79
}; 
# 81
template< class Tuple, 
# 82
template< class >  class UnaryMetaFunction> 
# 83
struct tuple_meta_transform< Tuple, UnaryMetaFunction, 5>  { 
# 91
typedef tuple< typename UnaryMetaFunction< typename tuple_element< 0, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 1, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 2, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 3, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 4, Tuple> ::type> ::type, null_type, null_type, null_type, null_type, null_type>  type; 
# 92
}; 
# 94
template< class Tuple, 
# 95
template< class >  class UnaryMetaFunction> 
# 96
struct tuple_meta_transform< Tuple, UnaryMetaFunction, 6>  { 
# 105
typedef tuple< typename UnaryMetaFunction< typename tuple_element< 0, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 1, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 2, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 3, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 4, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 5, Tuple> ::type> ::type, null_type, null_type, null_type, null_type>  type; 
# 106
}; 
# 108
template< class Tuple, 
# 109
template< class >  class UnaryMetaFunction> 
# 110
struct tuple_meta_transform< Tuple, UnaryMetaFunction, 7>  { 
# 120
typedef tuple< typename UnaryMetaFunction< typename tuple_element< 0, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 1, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 2, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 3, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 4, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 5, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 6, Tuple> ::type> ::type, null_type, null_type, null_type>  type; 
# 121
}; 
# 123
template< class Tuple, 
# 124
template< class >  class UnaryMetaFunction> 
# 125
struct tuple_meta_transform< Tuple, UnaryMetaFunction, 8>  { 
# 136
typedef tuple< typename UnaryMetaFunction< typename tuple_element< 0, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 1, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 2, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 3, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 4, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 5, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 6, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 7, Tuple> ::type> ::type, null_type, null_type>  type; 
# 137
}; 
# 139
template< class Tuple, 
# 140
template< class >  class UnaryMetaFunction> 
# 141
struct tuple_meta_transform< Tuple, UnaryMetaFunction, 9>  { 
# 153
typedef tuple< typename UnaryMetaFunction< typename tuple_element< 0, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 1, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 2, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 3, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 4, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 5, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 6, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 7, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 8, Tuple> ::type> ::type, null_type>  type; 
# 154
}; 
# 156
template< class Tuple, 
# 157
template< class >  class UnaryMetaFunction> 
# 158
struct tuple_meta_transform< Tuple, UnaryMetaFunction, 10>  { 
# 171
typedef tuple< typename UnaryMetaFunction< typename tuple_element< 0, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 1, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 2, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 3, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 4, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 5, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 6, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 7, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 8, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 9, Tuple> ::type> ::type>  type; 
# 172
}; 
# 174
}
# 176
}
# 22 "/usr/local/cuda-8.0/include/thrust/detail/tuple_transform.h"
namespace thrust { 
# 25
namespace detail { 
# 28
template< class Tuple, 
# 29
template< class >  class UnaryMetaFunction, class 
# 30
UnaryFunction, unsigned 
# 31
sz = tuple_size< Tuple> ::value> struct tuple_transform_functor; 
# 35
template< class Tuple, 
# 36
template< class >  class UnaryMetaFunction, class 
# 37
UnaryFunction> 
# 38
struct tuple_transform_functor< Tuple, UnaryMetaFunction, UnaryFunction, 0>  { 
# 42
static typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type do_it_on_the_host(const Tuple &t, UnaryFunction f) 
# 43
{ 
# 44
return null_type(); 
# 45
} 
# 49
static typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type do_it_on_the_host_or_device(const Tuple &t, UnaryFunction f) 
# 50
{ 
# 51
return null_type(); 
# 52
} 
# 53
}; 
# 56
template< class Tuple, 
# 57
template< class >  class UnaryMetaFunction, class 
# 58
UnaryFunction> 
# 59
struct tuple_transform_functor< Tuple, UnaryMetaFunction, UnaryFunction, 1>  { 
# 63
static typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type do_it_on_the_host(const Tuple &t, UnaryFunction f) 
# 64
{ 
# 65
typedef typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type XfrmTuple; 
# 67
return (XfrmTuple)f(thrust::get< 0> (t)); 
# 68
} 
# 72
static typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type do_it_on_the_host_or_device(const Tuple &t, UnaryFunction f) 
# 73
{ 
# 74
typedef typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type XfrmTuple; 
# 76
return (XfrmTuple)f(thrust::get< 0> (t)); 
# 77
} 
# 78
}; 
# 81
template< class Tuple, 
# 82
template< class >  class UnaryMetaFunction, class 
# 83
UnaryFunction> 
# 84
struct tuple_transform_functor< Tuple, UnaryMetaFunction, UnaryFunction, 2>  { 
# 88
static typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type do_it_on_the_host(const Tuple &t, UnaryFunction f) 
# 89
{ 
# 90
typedef typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type XfrmTuple; 
# 92
return XfrmTuple(f(thrust::get< 0> (t)), f(thrust::get< 1> (t))); 
# 94
} 
# 98
static typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type do_it_on_the_host_or_device(const Tuple &t, UnaryFunction f) 
# 99
{ 
# 100
typedef typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type XfrmTuple; 
# 102
return XfrmTuple(f(thrust::get< 0> (t)), f(thrust::get< 1> (t))); 
# 104
} 
# 105
}; 
# 108
template< class Tuple, 
# 109
template< class >  class UnaryMetaFunction, class 
# 110
UnaryFunction> 
# 111
struct tuple_transform_functor< Tuple, UnaryMetaFunction, UnaryFunction, 3>  { 
# 115
static typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type do_it_on_the_host(const Tuple &t, UnaryFunction f) 
# 116
{ 
# 117
typedef typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type XfrmTuple; 
# 119
return XfrmTuple(f(thrust::get< 0> (t)), f(thrust::get< 1> (t)), f(thrust::get< 2> (t))); 
# 122
} 
# 126
static typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type do_it_on_the_host_or_device(const Tuple &t, UnaryFunction f) 
# 127
{ 
# 128
typedef typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type XfrmTuple; 
# 130
return XfrmTuple(f(thrust::get< 0> (t)), f(thrust::get< 1> (t)), f(thrust::get< 2> (t))); 
# 133
} 
# 134
}; 
# 137
template< class Tuple, 
# 138
template< class >  class UnaryMetaFunction, class 
# 139
UnaryFunction> 
# 140
struct tuple_transform_functor< Tuple, UnaryMetaFunction, UnaryFunction, 4>  { 
# 144
static typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type do_it_on_the_host(const Tuple &t, UnaryFunction f) 
# 145
{ 
# 146
typedef typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type XfrmTuple; 
# 148
return XfrmTuple(f(thrust::get< 0> (t)), f(thrust::get< 1> (t)), f(thrust::get< 2> (t)), f(thrust::get< 3> (t))); 
# 152
} 
# 156
static typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type do_it_on_the_host_or_device(const Tuple &t, UnaryFunction f) 
# 157
{ 
# 158
typedef typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type XfrmTuple; 
# 160
return XfrmTuple(f(thrust::get< 0> (t)), f(thrust::get< 1> (t)), f(thrust::get< 2> (t)), f(thrust::get< 3> (t))); 
# 164
} 
# 165
}; 
# 168
template< class Tuple, 
# 169
template< class >  class UnaryMetaFunction, class 
# 170
UnaryFunction> 
# 171
struct tuple_transform_functor< Tuple, UnaryMetaFunction, UnaryFunction, 5>  { 
# 175
static typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type do_it_on_the_host(const Tuple &t, UnaryFunction f) 
# 176
{ 
# 177
typedef typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type XfrmTuple; 
# 179
return XfrmTuple(f(thrust::get< 0> (t)), f(thrust::get< 1> (t)), f(thrust::get< 2> (t)), f(thrust::get< 3> (t)), f(thrust::get< 4> (t))); 
# 184
} 
# 188
static typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type do_it_on_the_host_or_device(const Tuple &t, UnaryFunction f) 
# 189
{ 
# 190
typedef typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type XfrmTuple; 
# 192
return XfrmTuple(f(thrust::get< 0> (t)), f(thrust::get< 1> (t)), f(thrust::get< 2> (t)), f(thrust::get< 3> (t)), f(thrust::get< 4> (t))); 
# 197
} 
# 198
}; 
# 201
template< class Tuple, 
# 202
template< class >  class UnaryMetaFunction, class 
# 203
UnaryFunction> 
# 204
struct tuple_transform_functor< Tuple, UnaryMetaFunction, UnaryFunction, 6>  { 
# 208
static typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type do_it_on_the_host(const Tuple &t, UnaryFunction f) 
# 209
{ 
# 210
typedef typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type XfrmTuple; 
# 212
return XfrmTuple(f(thrust::get< 0> (t)), f(thrust::get< 1> (t)), f(thrust::get< 2> (t)), f(thrust::get< 3> (t)), f(thrust::get< 4> (t)), f(thrust::get< 5> (t))); 
# 218
} 
# 222
static typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type do_it_on_the_host_or_device(const Tuple &t, UnaryFunction f) 
# 223
{ 
# 224
typedef typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type XfrmTuple; 
# 226
return XfrmTuple(f(thrust::get< 0> (t)), f(thrust::get< 1> (t)), f(thrust::get< 2> (t)), f(thrust::get< 3> (t)), f(thrust::get< 4> (t)), f(thrust::get< 5> (t))); 
# 232
} 
# 233
}; 
# 236
template< class Tuple, 
# 237
template< class >  class UnaryMetaFunction, class 
# 238
UnaryFunction> 
# 239
struct tuple_transform_functor< Tuple, UnaryMetaFunction, UnaryFunction, 7>  { 
# 243
static typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type do_it_on_the_host(const Tuple &t, UnaryFunction f) 
# 244
{ 
# 245
typedef typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type XfrmTuple; 
# 247
return XfrmTuple(f(thrust::get< 0> (t)), f(thrust::get< 1> (t)), f(thrust::get< 2> (t)), f(thrust::get< 3> (t)), f(thrust::get< 4> (t)), f(thrust::get< 5> (t)), f(thrust::get< 6> (t))); 
# 254
} 
# 258
static typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type do_it_on_the_host_or_device(const Tuple &t, UnaryFunction f) 
# 259
{ 
# 260
typedef typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type XfrmTuple; 
# 262
return XfrmTuple(f(thrust::get< 0> (t)), f(thrust::get< 1> (t)), f(thrust::get< 2> (t)), f(thrust::get< 3> (t)), f(thrust::get< 4> (t)), f(thrust::get< 5> (t)), f(thrust::get< 6> (t))); 
# 269
} 
# 270
}; 
# 273
template< class Tuple, 
# 274
template< class >  class UnaryMetaFunction, class 
# 275
UnaryFunction> 
# 276
struct tuple_transform_functor< Tuple, UnaryMetaFunction, UnaryFunction, 8>  { 
# 280
static typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type do_it_on_the_host(const Tuple &t, UnaryFunction f) 
# 281
{ 
# 282
typedef typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type XfrmTuple; 
# 284
return XfrmTuple(f(thrust::get< 0> (t)), f(thrust::get< 1> (t)), f(thrust::get< 2> (t)), f(thrust::get< 3> (t)), f(thrust::get< 4> (t)), f(thrust::get< 5> (t)), f(thrust::get< 6> (t)), f(thrust::get< 7> (t))); 
# 292
} 
# 296
static typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type do_it_on_the_host_or_device(const Tuple &t, UnaryFunction f) 
# 297
{ 
# 298
typedef typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type XfrmTuple; 
# 300
return XfrmTuple(f(thrust::get< 0> (t)), f(thrust::get< 1> (t)), f(thrust::get< 2> (t)), f(thrust::get< 3> (t)), f(thrust::get< 4> (t)), f(thrust::get< 5> (t)), f(thrust::get< 6> (t)), f(thrust::get< 7> (t))); 
# 308
} 
# 309
}; 
# 312
template< class Tuple, 
# 313
template< class >  class UnaryMetaFunction, class 
# 314
UnaryFunction> 
# 315
struct tuple_transform_functor< Tuple, UnaryMetaFunction, UnaryFunction, 9>  { 
# 319
static typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type do_it_on_the_host(const Tuple &t, UnaryFunction f) 
# 320
{ 
# 321
typedef typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type XfrmTuple; 
# 323
return XfrmTuple(f(thrust::get< 0> (t)), f(thrust::get< 1> (t)), f(thrust::get< 2> (t)), f(thrust::get< 3> (t)), f(thrust::get< 4> (t)), f(thrust::get< 5> (t)), f(thrust::get< 6> (t)), f(thrust::get< 7> (t)), f(thrust::get< 8> (t))); 
# 332
} 
# 336
static typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type do_it_on_the_host_or_device(const Tuple &t, UnaryFunction f) 
# 337
{ 
# 338
typedef typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type XfrmTuple; 
# 340
return XfrmTuple(f(thrust::get< 0> (t)), f(thrust::get< 1> (t)), f(thrust::get< 2> (t)), f(thrust::get< 3> (t)), f(thrust::get< 4> (t)), f(thrust::get< 5> (t)), f(thrust::get< 6> (t)), f(thrust::get< 7> (t)), f(thrust::get< 8> (t))); 
# 349
} 
# 350
}; 
# 353
template< class Tuple, 
# 354
template< class >  class UnaryMetaFunction, class 
# 355
UnaryFunction> 
# 356
struct tuple_transform_functor< Tuple, UnaryMetaFunction, UnaryFunction, 10>  { 
# 360
static typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type do_it_on_the_host(const Tuple &t, UnaryFunction f) 
# 361
{ 
# 362
typedef typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type XfrmTuple; 
# 364
return XfrmTuple(f(thrust::get< 0> (t)), f(thrust::get< 1> (t)), f(thrust::get< 2> (t)), f(thrust::get< 3> (t)), f(thrust::get< 4> (t)), f(thrust::get< 5> (t)), f(thrust::get< 6> (t)), f(thrust::get< 7> (t)), f(thrust::get< 8> (t)), f(thrust::get< 9> (t))); 
# 374
} 
# 378
static typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type do_it_on_the_host_or_device(const Tuple &t, UnaryFunction f) 
# 379
{ 
# 380
typedef typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type XfrmTuple; 
# 382
return XfrmTuple(f(thrust::get< 0> (t)), f(thrust::get< 1> (t)), f(thrust::get< 2> (t)), f(thrust::get< 3> (t)), f(thrust::get< 4> (t)), f(thrust::get< 5> (t)), f(thrust::get< 6> (t)), f(thrust::get< 7> (t)), f(thrust::get< 8> (t)), f(thrust::get< 9> (t))); 
# 392
} 
# 393
}; 
# 396
template< template< class >  class UnaryMetaFunction, class 
# 397
Tuple, class 
# 398
UnaryFunction> typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type 
# 400
tuple_host_transform(const Tuple &t, UnaryFunction f) 
# 401
{ 
# 402
return tuple_transform_functor< Tuple, UnaryMetaFunction, UnaryFunction> ::do_it_on_the_host(t, f); 
# 403
} 
# 405
template< template< class >  class UnaryMetaFunction, class 
# 406
Tuple, class 
# 407
UnaryFunction> typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type 
# 410
tuple_host_device_transform(const Tuple &t, UnaryFunction f) 
# 411
{ 
# 412
return tuple_transform_functor< Tuple, UnaryMetaFunction, UnaryFunction> ::do_it_on_the_host_or_device(t, f); 
# 413
} 
# 415
}
# 417
}
# 32 "/usr/local/cuda-8.0/include/thrust/detail/raw_reference_cast.h"
namespace thrust { 
# 34
namespace detail { 
# 38
template< class T> struct is_wrapped_reference { typedef char yes_type; typedef int no_type; template< class S> static yes_type test(typename S::wrapped_reference_hint *); template< class S> static no_type test(...); static const bool value = (sizeof(test< T> (0)) == sizeof(yes_type)); typedef integral_constant< bool, value>  type; }; 
# 43
template< class T> 
# 44
struct is_unwrappable : public is_wrapped_reference< T>  { 
# 46
}; 
# 51
template< class 
# 52
T0, class T1, class T2, class 
# 53
T3, class T4, class T5, class 
# 54
T6, class T7, class T8, class 
# 55
T9> 
# 57
struct is_unwrappable< tuple< T0, T1, T2, T3, T4, T5, T6, T7, T8, T9> >  : public or_< is_unwrappable< T0> , is_unwrappable< T1> , is_unwrappable< T2> , is_unwrappable< T3> , is_unwrappable< T4> , is_unwrappable< T5> , is_unwrappable< T6> , is_unwrappable< T7> , is_unwrappable< T8> , is_unwrappable< T9> >  { 
# 72
}; 
# 77
template< class 
# 78
T0, class T1, class T2, class 
# 79
T3, class T4, class T5, class 
# 80
T6, class T7, class T8, class 
# 81
T9> 
# 83
struct is_unwrappable< tuple_of_iterator_references< T0, T1, T2, T3, T4, T5, T6, T7, T8, T9> >  : public or_< is_unwrappable< T0> , is_unwrappable< T1> , is_unwrappable< T2> , is_unwrappable< T3> , is_unwrappable< T4> , is_unwrappable< T5> , is_unwrappable< T6> , is_unwrappable< T7> , is_unwrappable< T8> , is_unwrappable< T9> >  { 
# 98
}; 
# 101
template< class T, class Result = void> 
# 102
struct enable_if_unwrappable : public enable_if< is_unwrappable< T> ::value, Result>  { 
# 107
}; 
# 110
namespace raw_reference_detail { 
# 114
template< class T, class Enable = void> 
# 115
struct raw_reference_impl : public add_reference< T>  { 
# 117
}; 
# 120
template< class T> 
# 121
struct raw_reference_impl< T, typename enable_if< is_wrapped_reference< typename remove_cv< T> ::type> ::value> ::type>  { 
# 132
typedef typename add_reference< typename pointer_element< typename T::pointer> ::type> ::type type; 
# 133
}; 
# 136
}
# 139
template< class T> 
# 140
struct raw_reference : public raw_reference_detail::raw_reference_impl< T>  { 
# 142
}; 
# 145
namespace raw_reference_detail { 
# 162
template< class T> 
# 163
struct raw_reference_tuple_helper : public eval_if< is_unwrappable< typename remove_cv< T> ::type> ::value, raw_reference< T> , identity_< T> >  { 
# 171
}; 
# 175
template< class 
# 176
T0, class T1, class T2, class 
# 177
T3, class T4, class T5, class 
# 178
T6, class T7, class T8, class 
# 179
T9> 
# 181
struct raw_reference_tuple_helper< tuple< T0, T1, T2, T3, T4, T5, T6, T7, T8, T9> >  { 
# 196
typedef tuple< typename raw_reference_detail::raw_reference_tuple_helper< T0> ::type, typename raw_reference_detail::raw_reference_tuple_helper< T1> ::type, typename raw_reference_detail::raw_reference_tuple_helper< T2> ::type, typename raw_reference_detail::raw_reference_tuple_helper< T3> ::type, typename raw_reference_detail::raw_reference_tuple_helper< T4> ::type, typename raw_reference_detail::raw_reference_tuple_helper< T5> ::type, typename raw_reference_detail::raw_reference_tuple_helper< T6> ::type, typename raw_reference_detail::raw_reference_tuple_helper< T7> ::type, typename raw_reference_detail::raw_reference_tuple_helper< T8> ::type, typename raw_reference_detail::raw_reference_tuple_helper< T9> ::type>  type; 
# 197
}; 
# 200
template< class 
# 201
T0, class T1, class T2, class 
# 202
T3, class T4, class T5, class 
# 203
T6, class T7, class T8, class 
# 204
T9> 
# 206
struct raw_reference_tuple_helper< tuple_of_iterator_references< T0, T1, T2, T3, T4, T5, T6, T7, T8, T9> >  { 
# 221
typedef tuple_of_iterator_references< typename raw_reference_detail::raw_reference_tuple_helper< T0> ::type, typename raw_reference_detail::raw_reference_tuple_helper< T1> ::type, typename raw_reference_detail::raw_reference_tuple_helper< T2> ::type, typename raw_reference_detail::raw_reference_tuple_helper< T3> ::type, typename raw_reference_detail::raw_reference_tuple_helper< T4> ::type, typename raw_reference_detail::raw_reference_tuple_helper< T5> ::type, typename raw_reference_detail::raw_reference_tuple_helper< T6> ::type, typename raw_reference_detail::raw_reference_tuple_helper< T7> ::type, typename raw_reference_detail::raw_reference_tuple_helper< T8> ::type, typename raw_reference_detail::raw_reference_tuple_helper< T9> ::type>  type; 
# 222
}; 
# 225
}
# 234
template< class 
# 235
T0, class T1, class T2, class 
# 236
T3, class T4, class T5, class 
# 237
T6, class T7, class T8, class 
# 238
T9> 
# 240
struct raw_reference< tuple< T0, T1, T2, T3, T4, T5, T6, T7, T8, T9> >  { 
# 245
private: typedef tuple< T0, T1, T2, T3, T4, T5, T6, T7, T8, T9>  tuple_type; 
# 252
public: typedef typename eval_if< is_unwrappable< tuple< T0, T1, T2, T3, T4, T5, T6, T7, T8, T9> > ::value, raw_reference_detail::raw_reference_tuple_helper< tuple< T0, T1, T2, T3, T4, T5, T6, T7, T8, T9> > , add_reference< tuple< T0, T1, T2, T3, T4, T5, T6, T7, T8, T9> > > ::type type; 
# 253
}; 
# 256
template< class 
# 257
T0, class T1, class T2, class 
# 258
T3, class T4, class T5, class 
# 259
T6, class T7, class T8, class 
# 260
T9> 
# 262
struct raw_reference< tuple_of_iterator_references< T0, T1, T2, T3, T4, T5, T6, T7, T8, T9> >  { 
# 267
private: typedef tuple_of_iterator_references< T0, T1, T2, T3, T4, T5, T6, T7, T8, T9>  tuple_type; 
# 270
public: typedef typename raw_reference_detail::raw_reference_tuple_helper< tuple_of_iterator_references< T0, T1, T2, T3, T4, T5, T6, T7, T8, T9> > ::type type; 
# 278
}; 
# 281
}
# 285
template< class T> inline typename detail::raw_reference< T> ::type raw_reference_cast(T & ref); 
# 291
template< class T> inline typename detail::raw_reference< const T> ::type raw_reference_cast(const T & ref); 
# 297
template< class 
# 298
T0, class T1, class T2, class 
# 299
T3, class T4, class T5, class 
# 300
T6, class T7, class T8, class 
# 301
T9> typename detail::enable_if_unwrappable< detail::tuple_of_iterator_references< T0, T1, T2, T3, T4, T5, T6, T7, T8, T9> , typename detail::raw_reference< detail::tuple_of_iterator_references< T0, T1, T2, T3, T4, T5, T6, T7, T8, T9> > ::type> ::type 
# 297
raw_reference_cast(detail::tuple_of_iterator_references< T0, T1, T2, T3, T4, T5, T6, T7, T8, T9>  t); 
# 313
namespace detail { 
# 317
struct raw_reference_caster { 
# 319
template< class T> typename raw_reference< T> ::type 
# 321
operator()(T &ref) 
# 322
{ 
# 323
return thrust::raw_reference_cast(ref); 
# 324
} 
# 326
template< class T> typename raw_reference< const T> ::type 
# 328
operator()(const T &ref) 
# 329
{ 
# 330
return thrust::raw_reference_cast(ref); 
# 331
} 
# 333
template< class 
# 334
T0, class T1, class T2, class 
# 335
T3, class T4, class T5, class 
# 336
T6, class T7, class T8, class 
# 337
T9> typename raw_reference< tuple_of_iterator_references< T0, T1, T2, T3, T4, T5, T6, T7, T8, T9> > ::type 
# 343
operator()(tuple_of_iterator_references< T0, T1, T2, T3, T4, T5, T6, T7, T8, T9>  t, typename enable_if< is_unwrappable< tuple_of_iterator_references< T0, T1, T2, T3, T4, T5, T6, T7, T8, T9> > ::value> ::type * = 0) 
# 347
{ 
# 348
return thrust::raw_reference_cast(t); 
# 349
} 
# 350
}; 
# 353
}
# 356
template< class T> inline typename detail::raw_reference< T> ::type 
# 359
raw_reference_cast(T &ref) 
# 360
{ 
# 361
return *thrust::raw_pointer_cast(&ref); 
# 362
} 
# 365
template< class T> inline typename detail::raw_reference< const T> ::type 
# 368
raw_reference_cast(const T &ref) 
# 369
{ 
# 370
return *thrust::raw_pointer_cast(&ref); 
# 371
} 
# 374
template< class 
# 375
T0, class T1, class T2, class 
# 376
T3, class T4, class T5, class 
# 377
T6, class T7, class T8, class 
# 378
T9> typename detail::enable_if_unwrappable< detail::tuple_of_iterator_references< T0, T1, T2, T3, T4, T5, T6, T7, T8, T9> , typename detail::raw_reference< detail::tuple_of_iterator_references< T0, T1, T2, T3, T4, T5, T6, T7, T8, T9> > ::type> ::type 
# 387
raw_reference_cast(detail::tuple_of_iterator_references< T0, T1, T2, T3, T4, T5, T6, T7, T8, T9>  t) 
# 388
{ 
# 389
detail::raw_reference_caster f; 
# 393
return detail::tuple_host_device_transform< detail::raw_reference_detail::raw_reference_tuple_helper> (t, f); 
# 394
} 
# 397
}
# 31 "/usr/local/cuda-8.0/include/thrust/detail/internal_functional.h"
namespace thrust { 
# 33
namespace detail { 
# 37
template< class Predicate> 
# 38
struct unary_negate { 
# 40
typedef bool result_type; 
# 42
Predicate pred; 
# 45
explicit unary_negate(const Predicate &pred) : pred(pred) { } 
# 47
template< class T> bool 
# 49
operator()(const T &x) 
# 50
{ 
# 51
return !((bool)(pred)(x)); 
# 52
} 
# 53
}; 
# 56
template< class Predicate> 
# 57
struct binary_negate { 
# 59
typedef bool result_type; 
# 61
Predicate pred; 
# 64
explicit binary_negate(const Predicate &pred) : pred(pred) { } 
# 66
template< class T1, class T2> bool 
# 68
operator()(const T1 &x, const T2 &y) 
# 69
{ 
# 70
return !((bool)(pred)(x, y)); 
# 71
} 
# 72
}; 
# 74
template< class Predicate> unary_negate< Predicate>  
# 76
not1(const Predicate &pred) 
# 77
{ 
# 78
return ((unary_negate< Predicate> )(pred)); 
# 79
} 
# 81
template< class Predicate> binary_negate< Predicate>  
# 83
not2(const Predicate &pred) 
# 84
{ 
# 85
return ((binary_negate< Predicate> )(pred)); 
# 86
} 
# 90
template< class Predicate, class IntegralType> 
# 91
struct predicate_to_integral { 
# 93
Predicate pred; 
# 96
explicit predicate_to_integral(const Predicate &pred) : pred(pred) { } 
# 98
template< class T> bool 
# 100
operator()(const T &x) 
# 101
{ 
# 102
return ((pred)(x)) ? (IntegralType)1 : ((IntegralType)0); 
# 103
} 
# 104
}; 
# 108
template< class T1> 
# 109
struct equal_to { 
# 111
typedef bool result_type; 
# 113
template< class T2> bool 
# 115
operator()(const T1 &lhs, const T2 &rhs) const 
# 116
{ 
# 117
return lhs == rhs; 
# 118
} 
# 119
}; 
# 122
template< class T2> 
# 123
struct equal_to_value { 
# 125
T2 rhs; 
# 128
equal_to_value(const T2 &rhs) : rhs(rhs) { } 
# 130
template< class T1> bool 
# 132
operator()(const T1 &lhs) const 
# 133
{ 
# 134
return lhs == (rhs); 
# 135
} 
# 136
}; 
# 138
template< class Predicate> 
# 139
struct tuple_binary_predicate { 
# 141
typedef bool result_type; 
# 144
tuple_binary_predicate(const Predicate &p) : pred(p) { } 
# 146
template< class Tuple> bool 
# 148
operator()(const Tuple &t) const 
# 149
{ 
# 150
return (pred)(thrust::get< 0> (t), thrust::get< 1> (t)); 
# 151
} 
# 153
mutable Predicate pred; 
# 154
}; 
# 156
template< class Predicate> 
# 157
struct tuple_not_binary_predicate { 
# 159
typedef bool result_type; 
# 162
tuple_not_binary_predicate(const Predicate &p) : pred(p) { } 
# 164
template< class Tuple> bool 
# 166
operator()(const Tuple &t) const 
# 167
{ 
# 168
return !(pred)(thrust::get< 0> (t), thrust::get< 1> (t)); 
# 169
} 
# 171
mutable Predicate pred; 
# 172
}; 
# 174
template< class Generator> 
# 175
struct host_generate_functor { 
# 177
typedef void result_type; 
# 180
host_generate_functor(Generator g) : gen(g) 
# 181
{ } 
# 193
template< class T> void 
# 195
operator()(const T &x) 
# 196
{ 
# 198
T &lvalue = const_cast< T &>(x); 
# 201
lvalue = (gen)(); 
# 202
} 
# 204
Generator gen; 
# 205
}; 
# 207
template< class Generator> 
# 208
struct device_generate_functor { 
# 210
typedef void result_type; 
# 213
device_generate_functor(Generator g) : gen(g) 
# 214
{ } 
# 226
template< class T> void 
# 228
operator()(const T &x) 
# 229
{ 
# 231
T &lvalue = const_cast< T &>(x); 
# 234
lvalue = (gen)(); 
# 235
} 
# 237
Generator gen; 
# 238
}; 
# 240
template< class System, class Generator> 
# 241
struct generate_functor : public eval_if< is_convertible< System, system::cpp::detail::tag> ::value, identity_< host_generate_functor< Generator> > , identity_< device_generate_functor< Generator> > >  { 
# 247
}; 
# 250
template< class ResultType, class BinaryFunction> 
# 251
struct zipped_binary_op { 
# 253
typedef ResultType result_type; 
# 256
zipped_binary_op(BinaryFunction binary_op) : m_binary_op(binary_op) 
# 257
{ } 
# 259
template< class Tuple> result_type 
# 261
operator()(Tuple t) 
# 262
{ 
# 263
return (m_binary_op)(thrust::get< 0> (t), thrust::get< 1> (t)); 
# 264
} 
# 266
BinaryFunction m_binary_op; 
# 267
}; 
# 270
template< class T> 
# 271
struct is_non_const_reference : public and_< not_< is_const< T> > , is_reference< T> >  { 
# 276
}; 
# 278
template< class T> struct is_tuple_of_iterator_references : public false_type { }; 
# 280
template< class T1, class T2, class T3, class 
# 281
T4, class T5, class T6, class 
# 282
T7, class T8, class T9, class 
# 283
T10> 
# 284
struct is_tuple_of_iterator_references< tuple_of_iterator_references< T1, T2, T3, T4, T5, T6, T7, T8, T9, T10> >  : public true_type { 
# 290
}; 
# 294
template< class T> 
# 295
struct enable_if_non_const_reference_or_tuple_of_iterator_references : public enable_if< is_non_const_reference< T> ::value || is_tuple_of_iterator_references< T> ::value>  { 
# 299
}; 
# 302
template< class UnaryFunction> 
# 303
struct unary_transform_functor { 
# 305
typedef void result_type; 
# 307
UnaryFunction f; 
# 310
unary_transform_functor(UnaryFunction f) : f(f) 
# 312
{ } 
# 315
template< class Tuple> typename enable_if_non_const_reference_or_tuple_of_iterator_references< typename tuple_element< 1, Tuple> ::type> ::type 
# 320
operator()(Tuple t) 
# 321
{ 
# 322
thrust::get< 1> (t) = (f)(thrust::get< 0> (t)); 
# 323
} 
# 324
}; 
# 327
template< class BinaryFunction> 
# 328
struct binary_transform_functor { 
# 330
BinaryFunction f; 
# 333
binary_transform_functor(BinaryFunction f) : f(f) 
# 335
{ } 
# 338
template< class Tuple> typename enable_if_non_const_reference_or_tuple_of_iterator_references< typename tuple_element< 2, Tuple> ::type> ::type 
# 343
operator()(Tuple t) 
# 344
{ 
# 345
thrust::get< 2> (t) = (f)(thrust::get< 0> (t), thrust::get< 1> (t)); 
# 346
} 
# 347
}; 
# 350
template< class UnaryFunction, class Predicate> 
# 351
struct unary_transform_if_functor { 
# 353
UnaryFunction unary_op; 
# 354
Predicate pred; 
# 357
unary_transform_if_functor(UnaryFunction unary_op, Predicate pred) : unary_op(unary_op), pred(pred) 
# 359
{ } 
# 362
template< class Tuple> typename enable_if_non_const_reference_or_tuple_of_iterator_references< typename tuple_element< 1, Tuple> ::type> ::type 
# 367
operator()(Tuple t) 
# 368
{ 
# 369
if ((pred)(thrust::get< 0> (t))) 
# 370
{ 
# 371
thrust::get< 1> (t) = (unary_op)(thrust::get< 0> (t)); 
# 372
}  
# 373
} 
# 374
}; 
# 377
template< class UnaryFunction, class Predicate> 
# 378
struct unary_transform_if_with_stencil_functor { 
# 380
UnaryFunction unary_op; 
# 381
Predicate pred; 
# 384
unary_transform_if_with_stencil_functor(UnaryFunction unary_op, Predicate pred) : unary_op(unary_op), pred(pred) 
# 386
{ } 
# 389
template< class Tuple> typename enable_if_non_const_reference_or_tuple_of_iterator_references< typename tuple_element< 2, Tuple> ::type> ::type 
# 394
operator()(Tuple t) 
# 395
{ 
# 396
if ((pred)(thrust::get< 1> (t))) { 
# 397
thrust::get< 2> (t) = (unary_op)(thrust::get< 0> (t)); }  
# 398
} 
# 399
}; 
# 402
template< class BinaryFunction, class Predicate> 
# 403
struct binary_transform_if_functor { 
# 405
BinaryFunction binary_op; 
# 406
Predicate pred; 
# 409
binary_transform_if_functor(BinaryFunction binary_op, Predicate pred) : binary_op(binary_op), pred(pred) 
# 410
{ } 
# 413
template< class Tuple> typename enable_if_non_const_reference_or_tuple_of_iterator_references< typename tuple_element< 3, Tuple> ::type> ::type 
# 418
operator()(Tuple t) 
# 419
{ 
# 420
if ((pred)(thrust::get< 2> (t))) { 
# 421
thrust::get< 3> (t) = (binary_op)(thrust::get< 0> (t), thrust::get< 1> (t)); }  
# 422
} 
# 423
}; 
# 426
template< class T> 
# 427
struct host_destroy_functor { 
# 430
void operator()(T &x) const 
# 431
{ 
# 432
(x.~T()); 
# 433
} 
# 434
}; 
# 437
template< class T> 
# 438
struct device_destroy_functor { 
# 442
void operator()(T &x) const 
# 443
{ 
# 444
(x.~T()); 
# 445
} 
# 446
}; 
# 449
template< class System, class T> 
# 450
struct destroy_functor : public eval_if< is_convertible< System, system::cpp::detail::tag> ::value, identity_< host_destroy_functor< T> > , identity_< device_destroy_functor< T> > >  { 
# 456
}; 
# 459
template< class T> 
# 460
struct fill_functor { 
# 462
T exemplar; 
# 465
fill_functor(const T &_exemplar) : exemplar(_exemplar) 
# 466
{ } 
# 469
T operator()() const 
# 470
{ 
# 471
return exemplar; 
# 472
} 
# 473
}; 
# 476
template< class T> 
# 477
struct uninitialized_fill_functor { 
# 479
T exemplar; 
# 482
uninitialized_fill_functor(T x) : exemplar(x) { } 
# 485
void operator()(T &x) 
# 486
{ 
# 487
::new (static_cast< void *>(&x)) (T)(exemplar); 
# 488
} 
# 489
}; 
# 496
template< class Compare> 
# 497
struct compare_first_less_second { 
# 499
compare_first_less_second(Compare c) : comp(c) 
# 500
{ } 
# 502
template< class T1, class T2> bool 
# 504
operator()(T1 lhs, T2 rhs) 
# 505
{ 
# 506
return (comp)(thrust::get< 0> (lhs), thrust::get< 0> (rhs)) || ((!(comp)(thrust::get< 0> (rhs), thrust::get< 0> (lhs))) && (thrust::get< 1> (lhs) < thrust::get< 1> (rhs))); 
# 507
} 
# 509
Compare comp; 
# 510
}; 
# 513
template< class Compare> 
# 514
struct compare_first { 
# 516
Compare comp; 
# 519
compare_first(Compare comp) : comp(comp) 
# 521
{ } 
# 523
template< class Tuple1, class Tuple2> bool 
# 525
operator()(const Tuple1 &x, const Tuple2 &y) 
# 526
{ 
# 527
return (comp)(thrust::raw_reference_cast(thrust::get< 0> (x)), thrust::raw_reference_cast(thrust::get< 0> (y))); 
# 528
} 
# 529
}; 
# 532
}
# 533
}
# 27 "/usr/local/cuda-8.0/include/thrust/transform.h"
namespace thrust { 
# 87
template< class DerivedPolicy, class 
# 88
InputIterator, class 
# 89
OutputIterator, class 
# 90
UnaryFunction> OutputIterator 
# 87
transform(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator first, InputIterator last, OutputIterator result, UnaryFunction op); 
# 138
template< class InputIterator, class 
# 139
OutputIterator, class 
# 140
UnaryFunction> OutputIterator 
# 138
transform(InputIterator first, InputIterator last, OutputIterator result, UnaryFunction op); 
# 201
template< class DerivedPolicy, class 
# 202
InputIterator1, class 
# 203
InputIterator2, class 
# 204
OutputIterator, class 
# 205
BinaryFunction> OutputIterator 
# 201
transform(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator1 first1, InputIterator1 last1, InputIterator2 first2, OutputIterator result, BinaryFunction op); 
# 262
template< class InputIterator1, class 
# 263
InputIterator2, class 
# 264
OutputIterator, class 
# 265
BinaryFunction> OutputIterator 
# 262
transform(InputIterator1 first1, InputIterator1 last1, InputIterator2 first2, OutputIterator result, BinaryFunction op); 
# 338
template< class DerivedPolicy, class 
# 339
InputIterator, class 
# 340
ForwardIterator, class 
# 341
UnaryFunction, class 
# 342
Predicate> ForwardIterator 
# 338
transform_if(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator first, InputIterator last, ForwardIterator result, UnaryFunction op, Predicate pred); 
# 410
template< class InputIterator, class 
# 411
ForwardIterator, class 
# 412
UnaryFunction, class 
# 413
Predicate> ForwardIterator 
# 410
transform_if(InputIterator first, InputIterator last, ForwardIterator result, UnaryFunction op, Predicate pred); 
# 481
template< class DerivedPolicy, class 
# 482
InputIterator1, class 
# 483
InputIterator2, class 
# 484
ForwardIterator, class 
# 485
UnaryFunction, class 
# 486
Predicate> ForwardIterator 
# 481
transform_if(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator1 first, InputIterator1 last, InputIterator2 stencil, ForwardIterator result, UnaryFunction op, Predicate pred); 
# 550
template< class InputIterator1, class 
# 551
InputIterator2, class 
# 552
ForwardIterator, class 
# 553
UnaryFunction, class 
# 554
Predicate> ForwardIterator 
# 550
transform_if(InputIterator1 first, InputIterator1 last, InputIterator2 stencil, ForwardIterator result, UnaryFunction op, Predicate pred); 
# 628
template< class DerivedPolicy, class 
# 629
InputIterator1, class 
# 630
InputIterator2, class 
# 631
InputIterator3, class 
# 632
ForwardIterator, class 
# 633
BinaryFunction, class 
# 634
Predicate> ForwardIterator 
# 628
transform_if(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator1 first1, InputIterator1 last1, InputIterator2 first2, InputIterator3 stencil, ForwardIterator result, BinaryFunction binary_op, Predicate pred); 
# 704
template< class InputIterator1, class 
# 705
InputIterator2, class 
# 706
InputIterator3, class 
# 707
ForwardIterator, class 
# 708
BinaryFunction, class 
# 709
Predicate> ForwardIterator 
# 704
transform_if(InputIterator1 first1, InputIterator1 last1, InputIterator2 first2, InputIterator3 stencil, ForwardIterator result, BinaryFunction binary_op, Predicate pred); 
# 722
}
# 22 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/transform.h"
namespace thrust { 
# 24
namespace system { 
# 26
namespace detail { 
# 28
namespace generic { 
# 31
template< class DerivedPolicy, class 
# 32
InputIterator, class 
# 33
OutputIterator, class 
# 34
UnaryFunction> OutputIterator 
# 31
transform(execution_policy< DerivedPolicy>  & exec, InputIterator first, InputIterator last, OutputIterator result, UnaryFunction op); 
# 42
template< class DerivedPolicy, class 
# 43
InputIterator1, class 
# 44
InputIterator2, class 
# 45
OutputIterator, class 
# 46
BinaryFunction> OutputIterator 
# 42
transform(execution_policy< DerivedPolicy>  & exec, InputIterator1 first1, InputIterator1 last1, InputIterator2 first2, OutputIterator result, BinaryFunction op); 
# 55
template< class DerivedPolicy, class 
# 56
InputIterator, class 
# 57
ForwardIterator, class 
# 58
UnaryFunction, class 
# 59
Predicate> ForwardIterator 
# 55
transform_if(execution_policy< DerivedPolicy>  & exec, InputIterator first, InputIterator last, ForwardIterator result, UnaryFunction unary_op, Predicate pred); 
# 68
template< class DerivedPolicy, class 
# 69
InputIterator1, class 
# 70
InputIterator2, class 
# 71
ForwardIterator, class 
# 72
UnaryFunction, class 
# 73
Predicate> ForwardIterator 
# 68
transform_if(execution_policy< DerivedPolicy>  & exec, InputIterator1 first, InputIterator1 last, InputIterator2 stencil, ForwardIterator result, UnaryFunction unary_op, Predicate pred); 
# 83
template< class DerivedPolicy, class 
# 84
InputIterator1, class 
# 85
InputIterator2, class 
# 86
InputIterator3, class 
# 87
ForwardIterator, class 
# 88
BinaryFunction, class 
# 89
Predicate> ForwardIterator 
# 83
transform_if(execution_policy< DerivedPolicy>  & exec, InputIterator1 first1, InputIterator1 last1, InputIterator2 first2, InputIterator3 stencil, ForwardIterator result, BinaryFunction binary_op, Predicate pred); 
# 100
}
# 101
}
# 102
}
# 103
}
# 27 "/usr/local/cuda-8.0/include/thrust/for_each.h"
namespace thrust { 
# 91
template< class DerivedPolicy, class 
# 92
InputIterator, class 
# 93
UnaryFunction> InputIterator 
# 91
for_each(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator first, InputIterator last, UnaryFunction f); 
# 154
template< class DerivedPolicy, class 
# 155
InputIterator, class 
# 156
Size, class 
# 157
UnaryFunction> InputIterator 
# 154
for_each_n(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator first, Size n, UnaryFunction f); 
# 212
template< class InputIterator, class 
# 213
UnaryFunction> InputIterator 
# 212
for_each(InputIterator first, InputIterator last, UnaryFunction f); 
# 267
template< class InputIterator, class 
# 268
Size, class 
# 269
UnaryFunction> InputIterator 
# 267
for_each_n(InputIterator first, Size n, UnaryFunction f); 
# 277
}
# 43 "/usr/local/cuda-8.0/include/thrust/detail/static_assert.h"
namespace thrust { 
# 46
namespace detail { 
# 50
template< bool x> struct STATIC_ASSERTION_FAILURE; 
# 52
template<> struct STATIC_ASSERTION_FAILURE< true>  { enum { value = 1}; }; 
# 55
template< int x> struct static_assert_test { }; 
# 57
template< class , bool x> 
# 58
struct depend_on_instantiation { 
# 60
static const bool value = x; 
# 61
}; 
# 63
}
# 65
}
# 29 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/for_each.h"
namespace thrust { 
# 31
namespace system { 
# 33
namespace detail { 
# 35
namespace generic { 
# 39
template< class DerivedPolicy, class 
# 40
InputIterator, class 
# 41
UnaryFunction> InputIterator 
# 43
for_each(execution_policy< DerivedPolicy>  &exec, InputIterator 
# 44
first, InputIterator 
# 45
last, UnaryFunction 
# 46
f) 
# 47
{ 
# 49
typedef thrust::detail::static_assert_test< sizeof(thrust::detail::STATIC_ASSERTION_FAILURE< (bool)(thrust::detail::depend_on_instantiation< InputIterator, false> ::value)> )>  thrust_static_assert_typedef_49 __attribute((unused)); 
# 50
return first; 
# 51
} 
# 54
template< class DerivedPolicy, class 
# 55
InputIterator, class 
# 56
Size, class 
# 57
UnaryFunction> InputIterator 
# 59
for_each_n(execution_policy< DerivedPolicy>  &exec, InputIterator 
# 60
first, Size 
# 61
n, UnaryFunction 
# 62
f) 
# 63
{ 
# 65
typedef thrust::detail::static_assert_test< sizeof(thrust::detail::STATIC_ASSERTION_FAILURE< (bool)(thrust::detail::depend_on_instantiation< InputIterator, false> ::value)> )>  thrust_static_assert_typedef_65 __attribute((unused)); 
# 66
return first; 
# 67
} 
# 70
}
# 71
}
# 72
}
# 73
}
# 22 "/usr/local/cuda-8.0/include/thrust/detail/function.h"
namespace thrust { 
# 24
namespace detail { 
# 28
template< class Function, class Result> 
# 29
struct wrapped_function { 
# 32
mutable Function m_f; 
# 35
wrapped_function() : m_f() 
# 37
{ } 
# 40
wrapped_function(const Function &f) : m_f(f) 
# 42
{ } 
# 45
template< class Argument> Result 
# 47
operator()(Argument &x) const 
# 48
{ 
# 51
return static_cast< Result>((m_f)(thrust::raw_reference_cast(x))); 
# 52
} 
# 55
template< class Argument> Result 
# 56
operator()(const Argument &x) const 
# 57
{ 
# 60
return static_cast< Result>((m_f)(thrust::raw_reference_cast(x))); 
# 61
} 
# 64
template< class Argument1, class Argument2> Result 
# 65
operator()(Argument1 &x, Argument2 &y) const 
# 66
{ 
# 69
return static_cast< Result>((m_f)(thrust::raw_reference_cast(x), thrust::raw_reference_cast(y))); 
# 70
} 
# 73
template< class Argument1, class Argument2> Result 
# 74
operator()(const Argument1 &x, Argument2 &y) const 
# 75
{ 
# 78
return static_cast< Result>((m_f)(thrust::raw_reference_cast(x), thrust::raw_reference_cast(y))); 
# 79
} 
# 82
template< class Argument1, class Argument2> Result 
# 83
operator()(const Argument1 &x, const Argument2 &y) const 
# 84
{ 
# 87
return static_cast< Result>((m_f)(thrust::raw_reference_cast(x), thrust::raw_reference_cast(y))); 
# 88
} 
# 91
template< class Argument1, class Argument2> Result 
# 92
operator()(Argument1 &x, const Argument2 &y) const 
# 93
{ 
# 96
return static_cast< Result>((m_f)(thrust::raw_reference_cast(x), thrust::raw_reference_cast(y))); 
# 97
} 
# 98
}; 
# 101
}
# 102
}
# 28 "/usr/local/cuda-8.0/include/thrust/system/detail/sequential/for_each.h"
namespace thrust { 
# 30
namespace system { 
# 32
namespace detail { 
# 34
namespace sequential { 
# 39
template< class DerivedPolicy, class 
# 40
InputIterator, class 
# 41
UnaryFunction> InputIterator 
# 43
for_each(execution_policy< DerivedPolicy>  &, InputIterator 
# 44
first, InputIterator 
# 45
last, UnaryFunction 
# 46
f) 
# 47
{ 
# 52
thrust::detail::wrapped_function< UnaryFunction, void>  wrapped_f(f); 
# 54
for (; first != last; ++first) 
# 55
{ 
# 56
wrapped_f(*first); 
# 57
}  
# 59
return first; 
# 60
} 
# 63
template< class DerivedPolicy, class 
# 64
InputIterator, class 
# 65
Size, class 
# 66
UnaryFunction> InputIterator 
# 68
for_each_n(execution_policy< DerivedPolicy>  &, InputIterator 
# 69
first, Size 
# 70
n, UnaryFunction 
# 71
f) 
# 72
{ 
# 77
thrust::detail::wrapped_function< UnaryFunction, void>  wrapped_f(f); 
# 79
for (Size i = (0); i != n; i++) 
# 80
{ 
# 83
wrapped_f(*first); 
# 84
++first; 
# 85
}  
# 87
return first; 
# 88
} 
# 91
}
# 92
}
# 93
}
# 94
}
# 28 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/for_each.h"
namespace thrust { 
# 30
namespace system { 
# 32
namespace cuda { 
# 34
namespace detail { 
# 38
template< class DerivedPolicy, class 
# 39
RandomAccessIterator, class 
# 40
UnaryFunction> RandomAccessIterator 
# 38
for_each(execution_policy< DerivedPolicy>  & s, RandomAccessIterator first, RandomAccessIterator last, UnaryFunction f); 
# 48
template< class DerivedPolicy, class 
# 49
RandomAccessIterator, class 
# 50
Size, class 
# 51
UnaryFunction> RandomAccessIterator 
# 48
for_each_n(execution_policy< DerivedPolicy>  & s, RandomAccessIterator first, Size n, UnaryFunction f); 
# 59
}
# 60
}
# 61
}
# 62
}
# 27 "/usr/local/cuda-8.0/include/thrust/distance.h"
namespace thrust { 
# 66
template< class InputIterator> inline typename iterator_traits< InputIterator> ::difference_type distance(InputIterator first, InputIterator last); 
# 74
}
# 26 "/usr/local/cuda-8.0/include/thrust/advance.h"
namespace thrust { 
# 64
template< class InputIterator, class Distance> void advance(InputIterator & i, Distance n); 
# 71
}
# 22 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/advance.h"
namespace thrust { 
# 24
namespace system { 
# 26
namespace detail { 
# 28
namespace generic { 
# 31
template< class InputIterator, class Distance> void advance(InputIterator & i, Distance n); 
# 35
}
# 36
}
# 37
}
# 38
}
# 21 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/advance.inl"
namespace thrust { 
# 23
namespace system { 
# 25
namespace detail { 
# 27
namespace generic { 
# 29
namespace detail { 
# 33
template< class InputIterator, class Distance> void 
# 35
advance(InputIterator &i, Distance n, incrementable_traversal_tag) 
# 36
{ 
# 37
while (n) 
# 38
{ 
# 39
++i; 
# 40
--n; 
# 41
}  
# 42
} 
# 45
template< class InputIterator, class Distance> void 
# 47
advance(InputIterator &i, Distance n, random_access_traversal_tag) 
# 48
{ 
# 49
i += n; 
# 50
} 
# 52
}
# 54
template< class InputIterator, class Distance> void 
# 56
advance(InputIterator &i, Distance n) 
# 57
{ 
# 59
detail::advance(i, n, typename iterator_traversal< InputIterator> ::type()); 
# 61
} 
# 63
}
# 64
}
# 65
}
# 66
}
# 26 "/usr/local/cuda-8.0/include/thrust/detail/advance.inl"
namespace thrust { 
# 30
template< class InputIterator, class Distance> void 
# 32
advance(InputIterator &i, Distance n) 
# 33
{ 
# 34
system::detail::generic::advance(i, n); 
# 35
} 
# 38
}
# 23 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/distance.h"
namespace thrust { 
# 25
namespace system { 
# 27
namespace detail { 
# 29
namespace generic { 
# 32
template< class InputIterator> inline typename iterator_traits< InputIterator> ::difference_type distance(InputIterator first, InputIterator last); 
# 37
}
# 38
}
# 39
}
# 40
}
# 21 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/distance.inl"
namespace thrust { 
# 23
namespace system { 
# 25
namespace detail { 
# 27
namespace generic { 
# 29
namespace detail { 
# 34
template< class InputIterator> inline typename iterator_traits< InputIterator> ::difference_type 
# 37
distance(InputIterator first, InputIterator last, incrementable_traversal_tag) 
# 38
{ 
# 39
typename iterator_traits< InputIterator> ::difference_type result(0); 
# 41
while (first != last) 
# 42
{ 
# 43
++first; 
# 44
++result; 
# 45
}  
# 47
return result; 
# 48
} 
# 52
template< class InputIterator> inline typename iterator_traits< InputIterator> ::difference_type 
# 55
distance(InputIterator first, InputIterator last, random_access_traversal_tag) 
# 56
{ 
# 57
return last - first; 
# 58
} 
# 61
}
# 64
template< class InputIterator> inline typename iterator_traits< InputIterator> ::difference_type 
# 67
distance(InputIterator first, InputIterator last) 
# 68
{ 
# 70
return detail::distance(first, last, typename iterator_traversal< InputIterator> ::type()); 
# 72
} 
# 75
}
# 76
}
# 77
}
# 78
}
# 26 "/usr/local/cuda-8.0/include/thrust/detail/distance.inl"
namespace thrust { 
# 30
template< class InputIterator> inline typename iterator_traits< InputIterator> ::difference_type 
# 33
distance(InputIterator first, InputIterator last) 
# 34
{ 
# 35
return system::detail::generic::distance(first, last); 
# 36
} 
# 39
}
# 83 "/usr/local/cuda-8.0/include/thrust/version.h"
namespace thrust { 
# 86
}
# 94 "/usr/include/c++/4.8.2/cstdio" 3
namespace std { 
# 96
using ::FILE;
# 97
using ::fpos_t;
# 99
using ::clearerr;
# 100
using ::fclose;
# 101
using ::feof;
# 102
using ::ferror;
# 103
using ::fflush;
# 104
using ::fgetc;
# 105
using ::fgetpos;
# 106
using ::fgets;
# 107
using ::fopen;
# 108
using ::fprintf;
# 109
using ::fputc;
# 110
using ::fputs;
# 111
using ::fread;
# 112
using ::freopen;
# 113
using ::fscanf;
# 114
using ::fseek;
# 115
using ::fsetpos;
# 116
using ::ftell;
# 117
using ::fwrite;
# 118
using ::getc;
# 119
using ::getchar;
# 120
using ::gets;
# 121
using ::perror;
# 122
using ::printf;
# 123
using ::putc;
# 124
using ::putchar;
# 125
using ::puts;
# 126
using ::remove;
# 127
using ::rename;
# 128
using ::rewind;
# 129
using ::scanf;
# 130
using ::setbuf;
# 131
using ::setvbuf;
# 132
using ::sprintf;
# 133
using ::sscanf;
# 134
using ::tmpfile;
# 135
using ::tmpnam;
# 136
using ::ungetc;
# 137
using ::vfprintf;
# 138
using ::vprintf;
# 139
using ::vsprintf;
# 140
}
# 150
namespace __gnu_cxx { 
# 168
using ::snprintf;
# 169
using ::vfscanf;
# 170
using ::vscanf;
# 171
using ::vsnprintf;
# 172
using ::vsscanf;
# 174
}
# 176
namespace std { 
# 178
using __gnu_cxx::snprintf;
# 179
using __gnu_cxx::vfscanf;
# 180
using __gnu_cxx::vscanf;
# 181
using __gnu_cxx::vsnprintf;
# 182
using __gnu_cxx::vsscanf;
# 183
}
# 23 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/detail/terminate.hpp"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 24
namespace bulk_ { 
# 26
namespace detail { 
# 31
inline void terminate() 
# 32
{ 
# 36
std::terminate(); 
# 38
} 
# 42
inline void terminate_with_message(const char *message) 
# 43
{ 
# 45
std::printf("%s\n", message); 
# 48
bulk_::detail::terminate(); 
# 49
} 
# 53
inline void terminate_on_error(cudaError_t e, const char *message) 
# 54
{ 
# 55
if (e) 
# 56
{ 
# 58
printf("Error after: %s: %s\n", message, cudaGetErrorString(e)); 
# 62
bulk_::detail::terminate(); 
# 63
}  
# 64
} 
# 67
}
# 68
}
# 69
}}}}
# 25 "/usr/local/cuda-8.0/include/thrust/system_error.h"
namespace thrust { 
# 40
namespace system { 
# 42
}
# 47
}
# 27 "/usr/local/cuda-8.0/include/thrust/system/detail/errno.h"
namespace thrust { 
# 30
namespace system { 
# 33
namespace detail { 
# 36
static const int eafnosupport = 9901; 
# 37
static const int eaddrinuse = 9902; 
# 38
static const int eaddrnotavail = 9903; 
# 39
static const int eisconn = 9904; 
# 40
static const int ebadmsg = 9905; 
# 41
static const int econnaborted = 9906; 
# 42
static const int ealready = 9907; 
# 43
static const int econnrefused = 9908; 
# 44
static const int econnreset = 9909; 
# 45
static const int edestaddrreq = 9910; 
# 46
static const int ehostunreach = 9911; 
# 47
static const int eidrm = 9912; 
# 48
static const int emsgsize = 9913; 
# 49
static const int enetdown = 9914; 
# 50
static const int enetreset = 9915; 
# 51
static const int enetunreach = 9916; 
# 52
static const int enobufs = 9917; 
# 53
static const int enolink = 9918; 
# 54
static const int enodata = 9919; 
# 55
static const int enomsg = 9920; 
# 56
static const int enoprotoopt = 9921; 
# 57
static const int enosr = 9922; 
# 58
static const int enotsock = 9923; 
# 59
static const int enostr = 9924; 
# 60
static const int enotconn = 9925; 
# 61
static const int enotsup = 9926; 
# 62
static const int ecanceled = 9927; 
# 63
static const int einprogress = 9928; 
# 64
static const int eopnotsupp = 9929; 
# 65
static const int ewouldblock = 9930; 
# 66
static const int eownerdead = 9931; 
# 67
static const int eproto = 9932; 
# 68
static const int eprotonosupport = 9933; 
# 69
static const int enotrecoverable = 9934; 
# 70
static const int etime = 9935; 
# 71
static const int etxtbsy = 9936; 
# 72
static const int etimedout = 9938; 
# 73
static const int eloop = 9939; 
# 74
static const int eoverflow = 9940; 
# 75
static const int eprototype = 9941; 
# 76
static const int enosys = 9942; 
# 77
static const int einval = 9943; 
# 78
static const int erange = 9944; 
# 79
static const int eilseq = 9945; 
# 80
static const int e2big = 9946; 
# 81
static const int edom = 9947; 
# 82
static const int efault = 9948; 
# 83
static const int ebadf = 9949; 
# 84
static const int epipe = 9950; 
# 85
static const int exdev = 9951; 
# 86
static const int ebusy = 9952; 
# 87
static const int enotempty = 9953; 
# 88
static const int enoexec = 9954; 
# 89
static const int eexist = 9955; 
# 90
static const int efbig = 9956; 
# 91
static const int enametoolong = 9957; 
# 92
static const int enotty = 9958; 
# 93
static const int eintr = 9959; 
# 94
static const int espipe = 9960; 
# 95
static const int eio = 9961; 
# 96
static const int eisdir = 9962; 
# 97
static const int echild = 9963; 
# 98
static const int enolck = 9964; 
# 99
static const int enospc = 9965; 
# 100
static const int enxio = 9966; 
# 101
static const int enodev = 9967; 
# 102
static const int enoent = 9968; 
# 103
static const int esrch = 9969; 
# 104
static const int enotdir = 9970; 
# 105
static const int enomem = 9971; 
# 106
static const int eperm = 9972; 
# 107
static const int eacces = 9973; 
# 108
static const int erofs = 9974; 
# 109
static const int edeadlk = 9975; 
# 110
static const int eagain = 9976; 
# 111
static const int enfile = 9977; 
# 112
static const int emfile = 9978; 
# 113
static const int emlink = 9979; 
# 115
}
# 117
}
# 119
}
# 42 "/usr/include/c++/4.8.2/iostream" 3
namespace std __attribute((__visibility__("default"))) { 
# 60
extern istream cin; 
# 61
extern ostream cout; 
# 62
extern ostream cerr; 
# 63
extern ostream clog; 
# 66
extern wistream wcin; 
# 67
extern wostream wcout; 
# 68
extern wostream wcerr; 
# 69
extern wostream wclog; 
# 74
static ios_base::Init __ioinit; 
# 77
}
# 30 "/usr/local/cuda-8.0/include/thrust/system/error_code.h"
namespace thrust { 
# 33
namespace system { 
# 41
class error_condition; 
# 42
class error_code; 
# 46
template< class T> struct is_error_code_enum : public thrust::detail::false_type { }; 
# 50
template< class T> struct is_error_condition_enum : public thrust::detail::false_type { }; 
# 54
namespace errc { 
# 57
enum errc_t { 
# 59
address_family_not_supported = 9901, 
# 60
address_in_use, 
# 61
address_not_available, 
# 62
already_connected, 
# 63
argument_list_too_long = 9946, 
# 64
argument_out_of_domain, 
# 65
bad_address, 
# 66
bad_file_descriptor, 
# 67
bad_message = 9905, 
# 68
broken_pipe = 9950, 
# 69
connection_aborted = 9906, 
# 70
connection_already_in_progress, 
# 71
connection_refused, 
# 72
connection_reset, 
# 73
cross_device_link = 9951, 
# 74
destination_address_required = 9910, 
# 75
device_or_resource_busy = 9952, 
# 76
directory_not_empty, 
# 77
executable_format_error, 
# 78
file_exists, 
# 79
file_too_large, 
# 80
filename_too_long, 
# 81
function_not_supported = 9942, 
# 82
host_unreachable = 9911, 
# 83
identifier_removed, 
# 84
illegal_byte_sequence = 9945, 
# 85
inappropriate_io_control_operation = 9958, 
# 86
interrupted, 
# 87
invalid_argument = 9943, 
# 88
invalid_seek = 9960, 
# 89
io_error, 
# 90
is_a_directory, 
# 91
message_size = 9913, 
# 92
network_down, 
# 93
network_reset, 
# 94
network_unreachable, 
# 95
no_buffer_space, 
# 96
no_child_process = 9963, 
# 97
no_link = 9918, 
# 98
no_lock_available = 9964, 
# 99
no_message_available = 9919, 
# 100
no_message, 
# 101
no_protocol_option, 
# 102
no_space_on_device = 9965, 
# 103
no_stream_resources = 9922, 
# 104
no_such_device_or_address = 9966, 
# 105
no_such_device, 
# 106
no_such_file_or_directory, 
# 107
no_such_process, 
# 108
not_a_directory, 
# 109
not_a_socket = 9923, 
# 110
not_a_stream, 
# 111
not_connected, 
# 112
not_enough_memory = 9971, 
# 113
not_supported = 9926, 
# 114
operation_canceled, 
# 115
operation_in_progress, 
# 116
operation_not_permitted = 9972, 
# 117
operation_not_supported = 9929, 
# 118
operation_would_block, 
# 119
owner_dead, 
# 120
permission_denied = 9973, 
# 121
protocol_error = 9932, 
# 122
protocol_not_supported, 
# 123
read_only_file_system = 9974, 
# 124
resource_deadlock_would_occur, 
# 125
resource_unavailable_try_again, 
# 126
result_out_of_range = 9944, 
# 127
state_not_recoverable = 9934, 
# 128
stream_timeout, 
# 129
text_file_busy, 
# 130
timed_out = 9938, 
# 131
too_many_files_open_in_system = 9977, 
# 132
too_many_files_open, 
# 133
too_many_links, 
# 134
too_many_symbolic_link_levels = 9939, 
# 135
value_too_large, 
# 136
wrong_protocol_type
# 137
}; 
# 139
}
# 144
template<> struct is_error_condition_enum< errc::errc_t>  : public thrust::detail::true_type { }; 
# 154
class error_category { 
# 159
public: inline virtual ~error_category(); 
# 167
inline virtual const char *name() const = 0; 
# 171
inline virtual error_condition default_error_condition(int ev) const; 
# 175
inline virtual bool equivalent(int code, const error_condition & condition) const; 
# 179
inline virtual bool equivalent(const error_code & code, int condition) const; 
# 183
virtual std::string message(int ev) const = 0; 
# 187
inline bool operator==(const error_category & rhs) const; 
# 191
inline bool operator!=(const error_category & rhs) const; 
# 196
inline bool operator<(const error_category & rhs) const; 
# 197
}; 
# 208
inline const error_category &generic_category(); 
# 222
inline const error_category &system_category(); 
# 232
class error_code { 
# 240
public: inline error_code(); 
# 245
inline error_code(int val, const error_category & cat); 
# 250
template< class ErrorCodeEnum> error_code(ErrorCodeEnum e, typename thrust::detail::enable_if< is_error_code_enum< ErrorCodeEnum> ::value> ::type * = 0); 
# 262
inline void assign(int val, const error_category & cat); 
# 266
template< class ErrorCodeEnum> typename thrust::detail::enable_if< is_error_code_enum< ErrorCodeEnum> ::value, error_code> ::type &operator=(ErrorCodeEnum e); 
# 277
inline void clear(); 
# 283
inline int value() const; 
# 287
inline const error_category &category() const; 
# 291
inline error_condition default_error_condition() const; 
# 295
inline std::string message() const; 
# 302
inline operator bool() const; 
# 307
private: int m_val; 
# 308
const error_category *m_cat; 
# 311
}; 
# 320
inline error_code make_error_code(errc::errc_t e); 
# 325
inline bool operator<(const error_code & lhs, const error_code & rhs); 
# 330
template< class charT, class traits> std::basic_ostream< charT, traits>  &operator<<(std::basic_ostream< charT, traits>  & os, const error_code & ec); 
# 344
class error_condition { 
# 353
public: inline error_condition(); 
# 359
inline error_condition(int val, const error_category & cat); 
# 366
template< class ErrorConditionEnum> error_condition(ErrorConditionEnum e, typename thrust::detail::enable_if< is_error_condition_enum< ErrorConditionEnum> ::value> ::type * = 0); 
# 382
inline void assign(int val, const error_category & cat); 
# 390
template< class ErrorConditionEnum> typename thrust::detail::enable_if< is_error_condition_enum< ErrorConditionEnum> ::value, error_condition> ::type &operator=(ErrorConditionEnum e); 
# 403
inline void clear(); 
# 409
inline int value() const; 
# 413
inline const error_category &category() const; 
# 417
inline std::string message() const; 
# 424
inline operator bool() const; 
# 430
private: int m_val; 
# 431
const error_category *m_cat; 
# 435
}; 
# 444
inline error_condition make_error_condition(errc::errc_t e); 
# 449
inline bool operator<(const error_condition & lhs, const error_condition & rhs); 
# 457
inline bool operator==(const error_code & lhs, const error_code & rhs); 
# 462
inline bool operator==(const error_code & lhs, const error_condition & rhs); 
# 467
inline bool operator==(const error_condition & lhs, const error_code & rhs); 
# 472
inline bool operator==(const error_condition & lhs, const error_condition & rhs); 
# 477
inline bool operator!=(const error_code & lhs, const error_code & rhs); 
# 482
inline bool operator!=(const error_code & lhs, const error_condition & rhs); 
# 487
inline bool operator!=(const error_condition & lhs, const error_code & rhs); 
# 492
inline bool operator!=(const error_condition & lhs, const error_condition & rhs); 
# 498
}
# 502
using system::error_category;
# 503
using system::error_code;
# 504
using system::error_condition;
# 505
using system::is_error_code_enum;
# 506
using system::is_error_condition_enum;
# 507
using system::make_error_code;
# 508
using system::make_error_condition;
# 511
namespace errc = system::errc;
# 513
using system::generic_category;
# 514
using system::system_category;
# 516
}
# 71 "/usr/include/c++/4.8.2/cstring" 3
namespace std __attribute((__visibility__("default"))) { 
# 75
using ::memchr;
# 76
using ::memcmp;
# 77
using ::memcpy;
# 78
using ::memmove;
# 79
using ::memset;
# 80
using ::strcat;
# 81
using ::strcmp;
# 82
using ::strcoll;
# 83
using ::strcpy;
# 84
using ::strcspn;
# 85
using ::strerror;
# 86
using ::strlen;
# 87
using ::strncat;
# 88
using ::strncmp;
# 89
using ::strncpy;
# 90
using ::strspn;
# 91
using ::strtok;
# 92
using ::strxfrm;
# 93
using ::strchr;
# 94
using ::strpbrk;
# 95
using ::strrchr;
# 96
using ::strstr;
# 121
}
# 25 "/usr/local/cuda-8.0/include/thrust/system/detail/error_category.inl"
namespace thrust { 
# 28
namespace system { 
# 32
inline error_category::~error_category() 
# 33
{ 
# 34
; 
# 35
} 
# 39
inline error_condition error_category::default_error_condition(int ev) const 
# 40
{ 
# 41
return error_condition(ev, *this); 
# 42
} 
# 46
inline bool error_category::equivalent(int code, const error_condition &condition) const 
# 47
{ 
# 48
return ((this->default_error_condition(code)) == condition); 
# 49
} 
# 53
inline bool error_category::equivalent(const error_code &code, int condition) const 
# 54
{ 
# 55
bool result = this->operator==(code.category()) && (code.value() == condition); 
# 56
return result; 
# 57
} 
# 61
inline bool error_category::operator==(const error_category &rhs) const 
# 62
{ 
# 63
return this == (&rhs); 
# 64
} 
# 68
inline bool error_category::operator!=(const error_category &rhs) const 
# 69
{ 
# 70
return !this->operator==(rhs); 
# 71
} 
# 75
inline bool error_category::operator<(const error_category &rhs) const 
# 76
{ 
# 77
return less< const error_category *> ()(this, &rhs); 
# 78
} 
# 81
namespace detail { 
# 85
class generic_error_category : public error_category { 
# 89
public: generic_error_category() { } 
# 91
virtual const char *name() const 
# 92
{ 
# 93
return "generic"; 
# 94
} 
# 96
virtual std::string message(int ev) const 
# 97
{ 
# 98
static const std::string unknown_err("Unknown error"); 
# 102
const char *c_str = std::strerror(ev); 
# 103
return ((c_str) ? ((std::string)(c_str)) : unknown_err); 
# 104
} 
# 105
}; 
# 108
class system_error_category : public error_category { 
# 112
public: system_error_category() { } 
# 114
virtual const char *name() const 
# 115
{ 
# 116
return "system"; 
# 117
} 
# 119
virtual std::string message(int ev) const 
# 120
{ 
# 121
return generic_category().message(ev); 
# 122
} 
# 124
virtual error_condition default_error_condition(int ev) const 
# 125
{ 
# 126
using namespace errc;
# 128
switch (ev) 
# 129
{ 
# 130
case eafnosupport:  return make_error_condition(address_family_not_supported); 
# 131
case eaddrinuse:  return make_error_condition(address_in_use); 
# 132
case eaddrnotavail:  return make_error_condition(address_not_available); 
# 133
case eisconn:  return make_error_condition(already_connected); 
# 134
case e2big:  return make_error_condition(argument_list_too_long); 
# 135
case edom:  return make_error_condition(argument_out_of_domain); 
# 136
case efault:  return make_error_condition(bad_address); 
# 137
case ebadf:  return make_error_condition(bad_file_descriptor); 
# 138
case ebadmsg:  return make_error_condition(bad_message); 
# 139
case epipe:  return make_error_condition(broken_pipe); 
# 140
case econnaborted:  return make_error_condition(connection_aborted); 
# 141
case ealready:  return make_error_condition(connection_already_in_progress); 
# 142
case econnrefused:  return make_error_condition(connection_refused); 
# 143
case econnreset:  return make_error_condition(connection_reset); 
# 144
case exdev:  return make_error_condition(cross_device_link); 
# 145
case edestaddrreq:  return make_error_condition(destination_address_required); 
# 146
case ebusy:  return make_error_condition(device_or_resource_busy); 
# 147
case enotempty:  return make_error_condition(directory_not_empty); 
# 148
case enoexec:  return make_error_condition(executable_format_error); 
# 149
case eexist:  return make_error_condition(file_exists); 
# 150
case efbig:  return make_error_condition(file_too_large); 
# 151
case enametoolong:  return make_error_condition(filename_too_long); 
# 152
case enosys:  return make_error_condition(function_not_supported); 
# 153
case ehostunreach:  return make_error_condition(host_unreachable); 
# 154
case eidrm:  return make_error_condition(identifier_removed); 
# 155
case eilseq:  return make_error_condition(illegal_byte_sequence); 
# 156
case enotty:  return make_error_condition(inappropriate_io_control_operation); 
# 157
case eintr:  return make_error_condition(interrupted); 
# 158
case einval:  return make_error_condition(invalid_argument); 
# 159
case espipe:  return make_error_condition(invalid_seek); 
# 160
case eio:  return make_error_condition(io_error); 
# 161
case eisdir:  return make_error_condition(is_a_directory); 
# 162
case emsgsize:  return make_error_condition(message_size); 
# 163
case enetdown:  return make_error_condition(network_down); 
# 164
case enetreset:  return make_error_condition(network_reset); 
# 165
case enetunreach:  return make_error_condition(network_unreachable); 
# 166
case enobufs:  return make_error_condition(no_buffer_space); 
# 167
case echild:  return make_error_condition(no_child_process); 
# 168
case enolink:  return make_error_condition(no_link); 
# 169
case enolck:  return make_error_condition(no_lock_available); 
# 170
case enodata:  return make_error_condition(no_message_available); 
# 171
case enomsg:  return make_error_condition(no_message); 
# 172
case enoprotoopt:  return make_error_condition(no_protocol_option); 
# 173
case enospc:  return make_error_condition(no_space_on_device); 
# 174
case enosr:  return make_error_condition(no_stream_resources); 
# 175
case enxio:  return make_error_condition(no_such_device_or_address); 
# 176
case enodev:  return make_error_condition(no_such_device); 
# 177
case enoent:  return make_error_condition(no_such_file_or_directory); 
# 178
case esrch:  return make_error_condition(no_such_process); 
# 179
case enotdir:  return make_error_condition(not_a_directory); 
# 180
case enotsock:  return make_error_condition(not_a_socket); 
# 181
case enostr:  return make_error_condition(not_a_stream); 
# 182
case enotconn:  return make_error_condition(not_connected); 
# 183
case enomem:  return make_error_condition(not_enough_memory); 
# 184
case enotsup:  return make_error_condition(not_supported); 
# 185
case ecanceled:  return make_error_condition(operation_canceled); 
# 186
case einprogress:  return make_error_condition(operation_in_progress); 
# 187
case eperm:  return make_error_condition(operation_not_permitted); 
# 188
case eopnotsupp:  return make_error_condition(operation_not_supported); 
# 189
case ewouldblock:  return make_error_condition(operation_would_block); 
# 190
case eownerdead:  return make_error_condition(owner_dead); 
# 191
case eacces:  return make_error_condition(permission_denied); 
# 192
case eproto:  return make_error_condition(protocol_error); 
# 193
case eprotonosupport:  return make_error_condition(protocol_not_supported); 
# 194
case erofs:  return make_error_condition(read_only_file_system); 
# 195
case edeadlk:  return make_error_condition(resource_deadlock_would_occur); 
# 196
case eagain:  return make_error_condition(resource_unavailable_try_again); 
# 197
case erange:  return make_error_condition(result_out_of_range); 
# 198
case enotrecoverable:  return make_error_condition(state_not_recoverable); 
# 199
case etime:  return make_error_condition(stream_timeout); 
# 200
case etxtbsy:  return make_error_condition(text_file_busy); 
# 201
case etimedout:  return make_error_condition(timed_out); 
# 202
case enfile:  return make_error_condition(too_many_files_open_in_system); 
# 203
case emfile:  return make_error_condition(too_many_files_open); 
# 204
case emlink:  return make_error_condition(too_many_links); 
# 205
case eloop:  return make_error_condition(too_many_symbolic_link_levels); 
# 206
case eoverflow:  return make_error_condition(value_too_large); 
# 207
case eprototype:  return make_error_condition(wrong_protocol_type); 
# 208
default:  return error_condition(ev, system_category()); 
# 209
}  
# 210
} 
# 211
}; 
# 214
}
# 217
inline const error_category &generic_category() 
# 218
{ 
# 219
static const detail::generic_error_category result; 
# 220
return result; 
# 221
} 
# 224
inline const error_category &system_category() 
# 225
{ 
# 226
static const detail::system_error_category result; 
# 227
return result; 
# 228
} 
# 231
}
# 233
}
# 22 "/usr/local/cuda-8.0/include/thrust/system/detail/error_code.inl"
namespace thrust { 
# 25
namespace system { 
# 29
inline error_code::error_code() : m_val(0), m_cat(&system_category()) 
# 31
{ 
# 32
; 
# 33
} 
# 37
inline error_code::error_code(int val, const error_category &cat) : m_val(val), m_cat(&cat) 
# 39
{ 
# 40
; 
# 41
} 
# 44
template< class ErrorCodeEnum> 
# 46
error_code::error_code(ErrorCodeEnum e, typename thrust::detail::enable_if< is_error_code_enum< ErrorCodeEnum> ::value> ::type *) 
# 52
{ 
# 53
(*this) = make_error_code(e); 
# 54
} 
# 58
inline void error_code::assign(int val, const error_category &cat) 
# 59
{ 
# 60
(m_val) = val; 
# 61
(m_cat) = (&cat); 
# 62
} 
# 65
template< class ErrorCodeEnum> typename thrust::detail::enable_if< is_error_code_enum< ErrorCodeEnum> ::value, error_code> ::type &
# 73
error_code::operator=(ErrorCodeEnum e) 
# 74
{ 
# 75
(*this) = make_error_code(e); 
# 76
return *this; 
# 77
} 
# 81
inline void error_code::clear() 
# 82
{ 
# 83
(m_val) = 0; 
# 84
(m_cat) = (&system_category()); 
# 85
} 
# 89
inline int error_code::value() const 
# 90
{ 
# 91
return m_val; 
# 92
} 
# 96
inline const error_category &error_code::category() const 
# 97
{ 
# 98
return *(m_cat); 
# 99
} 
# 103
inline error_condition error_code::default_error_condition() const 
# 104
{ 
# 105
return this->category().default_error_condition(this->value()); 
# 106
} 
# 110
inline std::string error_code::message() const 
# 111
{ 
# 112
return this->category().message(this->value()); 
# 113
} 
# 117
inline error_code::operator bool() const 
# 118
{ 
# 119
return this->value() != 0; 
# 120
} 
# 123
inline error_code make_error_code(errc::errc_t e) 
# 124
{ 
# 125
return error_code(static_cast< int>(e), generic_category()); 
# 126
} 
# 129
inline bool operator<(const error_code &lhs, const error_code &rhs) 
# 130
{ 
# 131
bool result = lhs.category().operator<(rhs.category()); 
# 132
result = (result || lhs.category().operator==(rhs.category())); 
# 133
result = (result || (lhs.value() < rhs.value())); 
# 134
return result; 
# 135
} 
# 138
template< class charT, class traits> std::basic_ostream< charT, traits>  &
# 140
operator<<(std::basic_ostream< charT, traits>  &os, const error_code &ec) 
# 141
{ 
# 142
return ((os << ec.category().name()) << ':') << ec.value(); 
# 143
} 
# 146
inline bool operator==(const error_code &lhs, const error_code &rhs) 
# 147
{ 
# 148
return lhs.category().operator==(rhs.category()) && (lhs.value() == rhs.value()); 
# 149
} 
# 152
inline bool operator==(const error_code &lhs, const error_condition &rhs) 
# 153
{ 
# 154
return lhs.category().equivalent(lhs.value(), rhs) || rhs.category().equivalent(lhs, rhs.value()); 
# 155
} 
# 158
inline bool operator==(const error_condition &lhs, const error_code &rhs) 
# 159
{ 
# 160
return rhs.category().equivalent(lhs.value(), lhs) || lhs.category().equivalent(rhs, lhs.value()); 
# 161
} 
# 164
inline bool operator==(const error_condition &lhs, const error_condition &rhs) 
# 165
{ 
# 166
return lhs.category().operator==(rhs.category()) && (lhs.value() == rhs.value()); 
# 167
} 
# 170
inline bool operator!=(const error_code &lhs, const error_code &rhs) 
# 171
{ 
# 172
return !((lhs == rhs)); 
# 173
} 
# 176
inline bool operator!=(const error_code &lhs, const error_condition &rhs) 
# 177
{ 
# 178
return !((lhs == rhs)); 
# 179
} 
# 182
inline bool operator!=(const error_condition &lhs, const error_code &rhs) 
# 183
{ 
# 184
return !((lhs == rhs)); 
# 185
} 
# 188
inline bool operator!=(const error_condition &lhs, const error_condition &rhs) 
# 189
{ 
# 190
return !((lhs == rhs)); 
# 191
} 
# 194
}
# 196
}
# 23 "/usr/local/cuda-8.0/include/thrust/system/detail/error_condition.inl"
namespace thrust { 
# 26
namespace system { 
# 30
inline error_condition::error_condition() : m_val(0), m_cat(&generic_category()) 
# 32
{ 
# 33
; 
# 34
} 
# 38
inline error_condition::error_condition(int val, const error_category &cat) : m_val(val), m_cat(&cat) 
# 40
{ 
# 41
; 
# 42
} 
# 45
template< class ErrorConditionEnum> 
# 47
error_condition::error_condition(ErrorConditionEnum e, typename thrust::detail::enable_if< is_error_condition_enum< ErrorConditionEnum> ::value> ::type *) 
# 53
{ 
# 54
(*this) = make_error_condition(e); 
# 55
} 
# 59
inline void error_condition::assign(int val, const error_category &cat) 
# 60
{ 
# 61
(m_val) = val; 
# 62
(m_cat) = (&cat); 
# 63
} 
# 66
template< class ErrorConditionEnum> typename thrust::detail::enable_if< is_error_condition_enum< ErrorConditionEnum> ::value, error_condition> ::type &
# 74
error_condition::operator=(ErrorConditionEnum e) 
# 75
{ 
# 76
(*this) = make_error_condition(e); 
# 77
return *this; 
# 78
} 
# 82
inline void error_condition::clear() 
# 83
{ 
# 84
(m_val) = 0; 
# 85
(m_cat) = (&generic_category()); 
# 86
} 
# 90
inline int error_condition::value() const 
# 91
{ 
# 92
return m_val; 
# 93
} 
# 97
inline const error_category &error_condition::category() const 
# 98
{ 
# 99
return *(m_cat); 
# 100
} 
# 104
inline std::string error_condition::message() const 
# 105
{ 
# 106
return this->category().message(this->value()); 
# 107
} 
# 111
inline error_condition::operator bool() const 
# 112
{ 
# 113
return this->value() != 0; 
# 114
} 
# 117
inline error_condition make_error_condition(errc::errc_t e) 
# 118
{ 
# 119
return error_condition(static_cast< int>(e), generic_category()); 
# 120
} 
# 123
inline bool operator<(const error_condition &lhs, const error_condition &
# 124
rhs) 
# 125
{ 
# 126
return lhs.category().operator<(rhs.category()) || (lhs.category().operator==(rhs.category()) && (lhs.value() < rhs.value())); 
# 127
} 
# 130
}
# 132
}
# 41 "/usr/include/c++/4.8.2/stdexcept" 3
namespace std __attribute((__visibility__("default"))) { 
# 55
class logic_error : public exception { 
# 57
string _M_msg; 
# 62
public: explicit logic_error(const string & __arg); 
# 64
virtual ~logic_error() throw(); 
# 69
virtual const char *what() const throw(); 
# 70
}; 
# 74
class domain_error : public logic_error { 
# 77
public: explicit domain_error(const string & __arg); 
# 78
virtual ~domain_error() throw(); 
# 79
}; 
# 82
class invalid_argument : public logic_error { 
# 85
public: explicit invalid_argument(const string & __arg); 
# 86
virtual ~invalid_argument() throw(); 
# 87
}; 
# 91
class length_error : public logic_error { 
# 94
public: explicit length_error(const string & __arg); 
# 95
virtual ~length_error() throw(); 
# 96
}; 
# 100
class out_of_range : public logic_error { 
# 103
public: explicit out_of_range(const string & __arg); 
# 104
virtual ~out_of_range() throw(); 
# 105
}; 
# 112
class runtime_error : public exception { 
# 114
string _M_msg; 
# 119
public: explicit runtime_error(const string & __arg); 
# 121
virtual ~runtime_error() throw(); 
# 126
virtual const char *what() const throw(); 
# 127
}; 
# 130
class range_error : public runtime_error { 
# 133
public: explicit range_error(const string & __arg); 
# 134
virtual ~range_error() throw(); 
# 135
}; 
# 138
class overflow_error : public runtime_error { 
# 141
public: explicit overflow_error(const string & __arg); 
# 142
virtual ~overflow_error() throw(); 
# 143
}; 
# 146
class underflow_error : public runtime_error { 
# 149
public: explicit underflow_error(const string & __arg); 
# 150
virtual ~underflow_error() throw(); 
# 151
}; 
# 156
}
# 31 "/usr/local/cuda-8.0/include/thrust/system/system_error.h"
namespace thrust { 
# 34
namespace system { 
# 89
class system_error : public std::runtime_error { 
# 101
public: inline system_error(error_code ec, const std::string & what_arg); 
# 109
inline system_error(error_code ec, const char * what_arg); 
# 115
inline system_error(error_code ec); 
# 124
inline system_error(int ev, const error_category & ecat, const std::string & what_arg); 
# 133
inline system_error(int ev, const error_category & ecat, const char * what_arg); 
# 140
inline system_error(int ev, const error_category & ecat); 
# 144
virtual ~system_error() throw() { } 
# 150
inline const error_code &code() const throw(); 
# 156
inline virtual const char *what() const throw(); 
# 161
private: error_code m_error_code; 
# 162
mutable std::string m_what; 
# 166
}; 
# 168
}
# 174
using system::system_error;
# 176
}
# 22 "/usr/local/cuda-8.0/include/thrust/system/detail/system_error.inl"
namespace thrust { 
# 25
namespace system { 
# 30
inline system_error::system_error(error_code ec, const std::string &what_arg) : std::runtime_error(what_arg), m_error_code(ec) 
# 32
{ 
# 34
} 
# 38
inline system_error::system_error(error_code ec, const char *what_arg) : std::runtime_error(what_arg), m_error_code(ec) 
# 40
{ 
# 41
; 
# 42
} 
# 46
inline system_error::system_error(error_code ec) : std::runtime_error(""), m_error_code(ec) 
# 48
{ 
# 49
; 
# 50
} 
# 54
inline system_error::system_error(int ev, const error_category &ecat, const std::string &what_arg) : std::runtime_error(what_arg), m_error_code(ev, ecat) 
# 56
{ 
# 57
; 
# 58
} 
# 62
inline system_error::system_error(int ev, const error_category &ecat, const char *what_arg) : std::runtime_error(what_arg), m_error_code(ev, ecat) 
# 64
{ 
# 65
; 
# 66
} 
# 70
inline system_error::system_error(int ev, const error_category &ecat) : std::runtime_error(""), m_error_code(ev, ecat) 
# 72
{ 
# 73
; 
# 74
} 
# 78
inline const error_code &system_error::code() const throw() 
# 79
{ 
# 80
return m_error_code; 
# 81
} 
# 85
inline const char *system_error::what() const throw() 
# 86
{ 
# 87
if ((m_what).empty()) 
# 88
{ 
# 89
try 
# 90
{ 
# 91
((m_what) = (this->std::runtime_error::what())); 
# 92
if ((m_error_code)) 
# 93
{ 
# 94
if (!(m_what).empty()) { ((m_what) += (": ")); }  
# 95
((m_what) += ((m_error_code).message())); 
# 96
}  
# 97
} 
# 98
catch (...) 
# 99
{ 
# 100
return this->std::runtime_error::what(); 
# 101
}  
# 102
}  
# 104
return (m_what).c_str(); 
# 105
} 
# 108
}
# 110
}
# 29 "/usr/local/cuda-8.0/include/thrust/system/cuda/error.h"
namespace thrust { 
# 32
namespace system { 
# 35
namespace cuda { 
# 47
namespace errc { 
# 52
enum errc_t { 
# 56
success, 
# 57
missing_configuration, 
# 58
memory_allocation, 
# 59
initialization_error, 
# 60
launch_failure, 
# 61
prior_launch_failure, 
# 62
launch_timeout, 
# 63
launch_out_of_resources, 
# 64
invalid_device_function, 
# 65
invalid_configuration, 
# 66
invalid_device, 
# 67
invalid_value, 
# 68
invalid_pitch_value, 
# 69
invalid_symbol, 
# 70
map_buffer_object_failed, 
# 71
unmap_buffer_object_failed, 
# 72
invalid_host_pointer, 
# 73
invalid_device_pointer, 
# 74
invalid_texture, 
# 75
invalid_texture_binding, 
# 76
invalid_channel_descriptor, 
# 77
invalid_memcpy_direction, 
# 78
address_of_constant_error, 
# 79
texture_fetch_failed, 
# 80
texture_not_bound, 
# 81
synchronization_error, 
# 82
invalid_filter_setting, 
# 83
invalid_norm_setting, 
# 84
mixed_device_execution, 
# 85
cuda_runtime_unloading, 
# 86
unknown, 
# 87
not_yet_implemented, 
# 88
memory_value_too_large, 
# 89
invalid_resource_handle, 
# 90
not_ready, 
# 91
insufficient_driver, 
# 92
set_on_active_process_error, 
# 93
no_device = 38, 
# 94
ecc_uncorrectable, 
# 97
shared_object_symbol_not_found, 
# 98
shared_object_init_failed, 
# 99
unsupported_limit, 
# 100
duplicate_variable_name, 
# 101
duplicate_texture_name, 
# 102
duplicate_surface_name, 
# 103
devices_unavailable, 
# 104
invalid_kernel_image, 
# 105
no_kernel_image_for_device, 
# 106
incompatible_driver_context, 
# 107
peer_access_already_enabled, 
# 108
peer_access_not_enabled, 
# 109
device_already_in_use = 54, 
# 110
profiler_disabled, 
# 111
assert_triggered = 59, 
# 112
too_many_peers, 
# 113
host_memory_already_registered, 
# 114
host_memory_not_registered, 
# 115
operating_system_error, 
# 119
peer_access_unsupported, 
# 120
launch_max_depth_exceeded, 
# 121
launch_file_scoped_texture_used, 
# 122
launch_file_scoped_surface_used, 
# 123
sync_depth_exceeded, 
# 124
attempted_operation_not_permitted = 70, 
# 125
attempted_operation_not_supported, 
# 128
startup_failure = 127
# 129
}; 
# 132
}
# 134
}
# 146
inline const error_category &cuda_category(); 
# 153
template<> struct is_error_code_enum< cuda::errc::errc_t>  : public thrust::detail::true_type { }; 
# 159
inline error_code make_error_code(cuda::errc::errc_t e); 
# 165
inline error_condition make_error_condition(cuda::errc::errc_t e); 
# 171
}
# 173
namespace cuda { 
# 177
namespace errc = system::cuda::errc;
# 179
}
# 181
using system::cuda_category;
# 183
}
# 23 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/error.inl"
namespace thrust { 
# 26
namespace system { 
# 30
inline error_code make_error_code(cuda::errc::errc_t e) 
# 31
{ 
# 32
return error_code(static_cast< int>(e), cuda_category()); 
# 33
} 
# 36
inline error_condition make_error_condition(cuda::errc::errc_t e) 
# 37
{ 
# 38
return error_condition(static_cast< int>(e), cuda_category()); 
# 39
} 
# 42
namespace cuda { 
# 45
namespace detail { 
# 49
class cuda_error_category : public error_category { 
# 53
public: cuda_error_category() { } 
# 55
virtual const char *name() const 
# 56
{ 
# 57
return "cuda"; 
# 58
} 
# 60
virtual std::string message(int ev) const 
# 61
{ 
# 62
static const std::string unknown_err("Unknown error"); 
# 63
const char *c_str = ::cudaGetErrorString(static_cast< cudaError_t>(ev)); 
# 64
return ((c_str) ? ((std::string)(c_str)) : unknown_err); 
# 65
} 
# 67
virtual error_condition default_error_condition(int ev) const 
# 68
{ 
# 69
using namespace errc;
# 71
if (ev < (::cudaErrorApiFailureBase)) 
# 72
{ 
# 73
return make_error_condition(static_cast< errc::errc_t>(ev)); 
# 74
}  
# 76
return system_category().default_error_condition(ev); 
# 77
} 
# 78
}; 
# 80
}
# 82
}
# 85
inline const error_category &cuda_category() 
# 86
{ 
# 87
static const cuda::detail::cuda_error_category result; 
# 88
return result; 
# 89
} 
# 92
}
# 94
}
# 26 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/detail/throw_on_error.hpp"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 27
namespace bulk_ { 
# 29
namespace detail { 
# 34
inline void throw_on_error(cudaError_t e, const char *message) 
# 35
{ 
# 36
if (e) 
# 37
{ 
# 39
throw system_error(e, thrust::cuda_category(), message); 
# 48
}  
# 49
} 
# 52
}
# 53
}
# 54
}}}}
# 28 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/future.hpp"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 29
namespace bulk_ { 
# 31
namespace detail { 
# 35
struct future_core_access; 
# 38
}
# 41
template< class T> class future; 
# 45
template<> class future< void>  { 
# 49
public: ~future() 
# 50
{ 
# 51
if (this->valid()) 
# 52
{ 
# 55
cudaError_t e = cudaEventDestroy(m_event); 
# 58
if (e) 
# 59
{ 
# 60
printf("CUDA error after cudaEventDestroy in future dtor: %s", cudaGetErrorString(e)); 
# 61
}  
# 64
if (m_owns_stream) 
# 65
{ 
# 66
e = cudaStreamDestroy(m_stream); 
# 69
if (e) 
# 70
{ 
# 71
printf("CUDA error after cudaStreamDestroy in future dtor: %s", cudaGetErrorString(e)); 
# 72
}  
# 74
}  
# 76
}  
# 77
} 
# 80
void wait() const 
# 81
{ 
# 88
bulk_::detail::throw_on_error(cudaEventSynchronize(m_event), "cudaEventSynchronize in future::wait"); 
# 98
} 
# 101
bool valid() const 
# 102
{ 
# 103
return (m_event) != (0); 
# 104
} 
# 107
future() : m_stream((0)), m_event((0)), m_owns_stream(false) 
# 109
{ } 
# 114
future(const bulk_::future< void>  &other) : m_stream((0)), m_event((0)), m_owns_stream(false) 
# 116
{ 
# 117
thrust::swap(m_stream, (const_cast< bulk_::future< void>  &>(other)).m_stream); 
# 118
thrust::swap(m_event, (const_cast< bulk_::future< void>  &>(other)).m_event); 
# 119
thrust::swap(m_owns_stream, (const_cast< bulk_::future< void>  &>(other)).m_owns_stream); 
# 120
} 
# 125
bulk_::future< void>  &operator=(const bulk_::future< void>  &other) 
# 126
{ 
# 127
thrust::swap(m_stream, (const_cast< bulk_::future< void>  &>(other)).m_stream); 
# 128
thrust::swap(m_event, (const_cast< bulk_::future< void>  &>(other)).m_event); 
# 129
thrust::swap(m_owns_stream, (const_cast< bulk_::future< void>  &>(other)).m_owns_stream); 
# 130
return *this; 
# 131
} 
# 134
friend struct detail::future_core_access; 
# 137
private: future(cudaStream_t s, bool owns_stream) : m_stream(s), m_owns_stream(owns_stream) 
# 139
{ 
# 141
bulk_::detail::throw_on_error(cudaEventCreateWithFlags(&(m_event), create_flags), "cudaEventCreateWithFlags in future ctor"); 
# 142
bulk_::detail::throw_on_error(cudaEventRecord(m_event, m_stream), "cudaEventRecord in future ctor"); 
# 144
} 
# 148
static const int create_flags = 2; 
# 150
cudaStream_t m_stream; 
# 151
cudaEvent_t m_event; 
# 152
bool m_owns_stream; 
# 153
}; 
# 156
namespace detail { 
# 160
struct future_core_access { 
# 163
static future< void>  create(cudaStream_t s, bool owns_stream) 
# 164
{ 
# 165
return future< void> (s, owns_stream); 
# 166
} 
# 169
static cudaEvent_t event(const future< void>  &f) 
# 170
{ 
# 171
return f.m_event; 
# 172
} 
# 173
}; 
# 176
}
# 179
}
# 180
}}}}
# 21 "/usr/local/cuda-8.0/include/thrust/detail/minmax.h"
namespace thrust { 
# 25
template< class T, class BinaryPredicate> T 
# 27
min(const T &lhs, const T &rhs, BinaryPredicate comp) 
# 28
{ 
# 29
return (comp(rhs, lhs)) ? rhs : lhs; 
# 30
} 
# 32
template< class T> T 
# 34
min(const T &lhs, const T &rhs) 
# 35
{ 
# 36
return (rhs < lhs) ? rhs : lhs; 
# 37
} 
# 39
template< class T, class BinaryPredicate> T 
# 41
max(const T &lhs, const T &rhs, BinaryPredicate comp) 
# 42
{ 
# 43
return (comp(lhs, rhs)) ? rhs : lhs; 
# 44
} 
# 46
template< class T> T 
# 48
max(const T &lhs, const T &rhs) 
# 49
{ 
# 50
return (lhs < rhs) ? rhs : lhs; 
# 51
} 
# 54
}
# 26 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/detail/cuda_launcher/cuda_launch_config.hpp"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 27
namespace bulk_ { 
# 29
namespace detail { 
# 35
struct device_properties_t { 
# 39
int major; 
# 40
int maxGridSize[3]; 
# 41
int maxThreadsPerBlock; 
# 42
int maxThreadsPerMultiProcessor; 
# 43
int minor; 
# 44
int multiProcessorCount; 
# 45
int regsPerBlock; 
# 46
size_t sharedMemPerBlock; 
# 47
int warpSize; 
# 48
}; 
# 53
struct function_attributes_t { 
# 57
size_t constSizeBytes; 
# 58
size_t localSizeBytes; 
# 59
int maxThreadsPerBlock; 
# 60
int numRegs; 
# 61
int ptxVersion; 
# 62
size_t sharedSizeBytes; 
# 63
}; 
# 75
inline std::size_t block_size_with_maximum_potential_occupancy(const function_attributes_t & attributes, const device_properties_t & properties); 
# 89
template< class UnaryFunction> inline std::size_t block_size_with_maximum_potential_occupancy(const function_attributes_t & attributes, const device_properties_t & properties, UnaryFunction block_size_to_dynamic_smem_size); 
# 104
inline size_t proportional_smem_allocation(const device_properties_t & properties, const function_attributes_t & attributes, size_t blocks_per_processor); 
# 109
template< class UnaryFunction> inline size_t max_blocksize_subject_to_smem_usage(const device_properties_t & properties, const function_attributes_t & attributes, UnaryFunction blocksize_to_dynamic_smem_usage); 
# 117
namespace cuda_launch_config_detail { 
# 120
using std::size_t;
# 122
namespace util { 
# 126
template< class T> inline T 
# 128
min_(const T &lhs, const T &rhs) 
# 129
{ 
# 130
return (rhs < lhs) ? rhs : lhs; 
# 131
} 
# 134
template< class T> 
# 135
struct zero_function { 
# 138
T operator()(T) 
# 139
{ 
# 140
return 0; 
# 141
} 
# 142
}; 
# 146
template< class L, class R> inline L 
# 147
divide_ri(const L x, const R y) 
# 148
{ 
# 149
return (x + (y - 1)) / y; 
# 150
} 
# 153
template< class L, class R> inline L 
# 154
divide_rz(const L x, const R y) 
# 155
{ 
# 156
return x / y; 
# 157
} 
# 160
template< class L, class R> inline L 
# 161
round_i(const L x, const R y) { return y * divide_ri(x, y); } 
# 164
template< class L, class R> inline L 
# 165
round_z(const L x, const R y) { return y * divide_rz(x, y); } 
# 167
}
# 173
inline std::size_t smem_allocation_unit(const device_properties_t &properties) 
# 174
{ 
# 175
switch (properties.major) 
# 176
{ 
# 177
case 1:  return 512; 
# 178
case 2:  return 128; 
# 179
case 3:  return 256; 
# 180
default:  return 256; 
# 181
}  
# 182
} 
# 187
inline int reg_allocation_unit(const device_properties_t &properties, const std::size_t regsPerThread) 
# 188
{ 
# 189
switch (properties.major) 
# 190
{ 
# 191
case 1:  return ((properties.minor) <= 1) ? 256 : 512; 
# 192
case 2:  switch (regsPerThread) 
# 193
{ 
# 194
case 21:  
# 195
case 22:  
# 196
case 29:  
# 197
case 30:  
# 198
case 37:  
# 199
case 38:  
# 200
case 45:  
# 201
case 46:  
# 202
return 128; 
# 203
default:  
# 204
return 64; 
# 205
}  
# 206
case 3:  return 256; 
# 207
default:  return 256; 
# 208
}  
# 209
} 
# 214
inline std::size_t warp_allocation_multiple(const device_properties_t &properties) 
# 215
{ 
# 216
return ((properties.major) <= 1) ? 2 : 1; 
# 217
} 
# 221
inline std::size_t num_sides_per_multiprocessor(const device_properties_t &properties) 
# 222
{ 
# 223
switch (properties.major) 
# 224
{ 
# 225
case 1:  return 1; 
# 226
case 2:  return 2; 
# 227
case 3:  return 4; 
# 228
default:  return 4; 
# 229
}  
# 230
} 
# 234
inline std::size_t max_blocks_per_multiprocessor(const device_properties_t &properties) 
# 235
{ 
# 236
return ((properties.major) <= 2) ? 8 : 16; 
# 237
} 
# 241
inline std::size_t max_active_blocks_per_multiprocessor(const device_properties_t &properties, const function_attributes_t &
# 242
attributes, std::size_t 
# 243
CTA_SIZE, std::size_t 
# 244
dynamic_smem_bytes) 
# 245
{ 
# 252
const std::size_t maxThreadsPerSM = properties.maxThreadsPerMultiProcessor; 
# 253
const std::size_t maxBlocksPerSM = max_blocks_per_multiprocessor(properties); 
# 256
const std::size_t ctaLimitThreads = (CTA_SIZE <= ((std::size_t)(properties.maxThreadsPerBlock))) ? maxThreadsPerSM / CTA_SIZE : (0); 
# 257
const std::size_t ctaLimitBlocks = maxBlocksPerSM; 
# 262
const std::size_t smemAllocationUnit = smem_allocation_unit(properties); 
# 263
const std::size_t smemBytes = (attributes.sharedSizeBytes) + dynamic_smem_bytes; 
# 264
const std::size_t smemPerCTA = util::round_i(smemBytes, smemAllocationUnit); 
# 267
const std::size_t ctaLimitSMem = (smemPerCTA > (0)) ? (properties.sharedMemPerBlock) / smemPerCTA : maxBlocksPerSM; 
# 272
const int regAllocationUnit = reg_allocation_unit(properties, attributes.numRegs); 
# 273
const std::size_t warpAllocationMultiple = warp_allocation_multiple(properties); 
# 274
const std::size_t numWarps = util::round_i(util::divide_ri(CTA_SIZE, properties.warpSize), warpAllocationMultiple); 
# 277
std::size_t ctaLimitRegs; 
# 278
if ((properties.major) <= 1) 
# 279
{ 
# 282
const std::size_t regsPerCTA = util::round_i(((attributes.numRegs) * (properties.warpSize)) * numWarps, regAllocationUnit); 
# 283
ctaLimitRegs = ((regsPerCTA > (0)) ? (properties.regsPerBlock) / regsPerCTA : maxBlocksPerSM); 
# 284
} else 
# 286
{ 
# 289
const std::size_t regsPerWarp = util::round_i((attributes.numRegs) * (properties.warpSize), regAllocationUnit); 
# 290
const std::size_t numSides = num_sides_per_multiprocessor(properties); 
# 291
const std::size_t numRegsPerSide = (properties.regsPerBlock) / numSides; 
# 292
ctaLimitRegs = ((regsPerWarp > (0)) ? ((numRegsPerSide / regsPerWarp) * numSides) / numWarps : maxBlocksPerSM); 
# 293
}  
# 298
return util::min_(ctaLimitRegs, util::min_(ctaLimitSMem, util::min_(ctaLimitThreads, ctaLimitBlocks))); 
# 299
} 
# 302
}
# 305
template< class UnaryFunction> inline std::size_t 
# 307
block_size_with_maximum_potential_occupancy(const function_attributes_t &attributes, const device_properties_t &
# 308
properties, UnaryFunction 
# 309
block_size_to_dynamic_smem_size) 
# 310
{ 
# 311
size_t max_occupancy = properties.maxThreadsPerMultiProcessor; 
# 312
size_t largest_blocksize = cuda_launch_config_detail::util::min_(properties.maxThreadsPerBlock, attributes.maxThreadsPerBlock); 
# 313
size_t granularity = properties.warpSize; 
# 314
size_t max_blocksize = (0); 
# 315
size_t highest_occupancy = (0); 
# 317
for (size_t blocksize = largest_blocksize; blocksize != (0); blocksize -= granularity) 
# 318
{ 
# 319
size_t occupancy = blocksize * cuda_launch_config_detail::max_active_blocks_per_multiprocessor(properties, attributes, blocksize, block_size_to_dynamic_smem_size(blocksize)); 
# 321
if (occupancy > highest_occupancy) 
# 322
{ 
# 323
max_blocksize = blocksize; 
# 324
highest_occupancy = occupancy; 
# 325
}  
# 328
if (highest_occupancy == max_occupancy) { 
# 329
break; }  
# 330
}  
# 332
return max_blocksize; 
# 333
} 
# 337
inline std::size_t block_size_with_maximum_potential_occupancy(const function_attributes_t &attributes, const device_properties_t &
# 338
properties) 
# 339
{ 
# 340
return block_size_with_maximum_potential_occupancy(attributes, properties, cuda_launch_config_detail::util::zero_function< unsigned long> ()); 
# 341
} 
# 345
inline size_t proportional_smem_allocation(const device_properties_t &properties, const function_attributes_t &
# 346
attributes, size_t 
# 347
blocks_per_processor) 
# 348
{ 
# 349
size_t smem_per_processor = properties.sharedMemPerBlock; 
# 350
size_t smem_allocation_unit = cuda_launch_config_detail::smem_allocation_unit(properties); 
# 352
size_t total_smem_per_block = cuda_launch_config_detail::util::round_z(smem_per_processor / blocks_per_processor, smem_allocation_unit); 
# 353
size_t static_smem_per_block = attributes.sharedSizeBytes; 
# 355
return total_smem_per_block - static_smem_per_block; 
# 356
} 
# 359
template< class UnaryFunction> inline size_t 
# 361
max_blocksize_subject_to_smem_usage(const device_properties_t &properties, const function_attributes_t &
# 362
attributes, UnaryFunction 
# 363
blocksize_to_dynamic_smem_usage) 
# 364
{ 
# 365
size_t largest_blocksize = (thrust::min)(properties.maxThreadsPerBlock, attributes.maxThreadsPerBlock); 
# 366
size_t granularity = properties.warpSize; 
# 368
for (int blocksize = largest_blocksize; blocksize > 0; blocksize -= granularity) 
# 369
{ 
# 370
size_t total_smem_usage = blocksize_to_dynamic_smem_usage(blocksize) + (attributes.sharedSizeBytes); 
# 372
if (total_smem_usage <= (properties.sharedMemPerBlock)) 
# 373
{ 
# 374
return blocksize; 
# 375
}  
# 376
}  
# 378
return 0; 
# 379
} 
# 382
}
# 383
}
# 384
}}}}
# 32 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/detail/cuda_launcher/runtime_introspection.hpp"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 33
namespace bulk_ { 
# 35
namespace detail { 
# 42
inline int current_device(); 
# 48
inline device_properties_t device_properties(int device_id); 
# 54
inline device_properties_t device_properties(); 
# 59
template< class KernelFunction> inline function_attributes_t function_attributes(KernelFunction kernel); 
# 68
inline size_t compute_capability(const device_properties_t & properties); 
# 71
inline size_t compute_capability(); 
# 74
}
# 75
}
# 76
}}}}
# 22 "/usr/local/cuda-8.0/include/thrust/detail/util/blocking.h"
namespace thrust { 
# 25
namespace detail { 
# 28
namespace util { 
# 32
template< class L, class R> inline L 
# 33
divide_ri(const L x, const R y) 
# 34
{ 
# 35
return (x + (y - 1)) / y; 
# 36
} 
# 39
template< class L, class R> inline L 
# 40
divide_rz(const L x, const R y) 
# 41
{ 
# 42
return x / y; 
# 43
} 
# 46
template< class L, class R> inline L 
# 47
round_i(const L x, const R y) { return y * divide_ri(x, y); } 
# 50
template< class L, class R> inline L 
# 51
round_z(const L x, const R y) { return y * divide_rz(x, y); } 
# 53
}
# 55
}
# 57
}
# 27 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/detail/cuda_launcher/runtime_introspection.inl"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 28
namespace bulk_ { 
# 30
namespace detail { 
# 35
inline device_properties_t device_properties_uncached(int device_id) 
# 36
{ 
# 37
device_properties_t prop = {0, {0, 0, 0}, 0, 0, 0, 0, 0, (0), 0}; 
# 39
cudaError_t error = cudaErrorNoDevice; 
# 42
error = cudaDeviceGetAttribute(&(prop.major), cudaDevAttrComputeCapabilityMajor, device_id); 
# 43
error = cudaDeviceGetAttribute(&((prop.maxGridSize)[0]), cudaDevAttrMaxGridDimX, device_id); 
# 44
error = cudaDeviceGetAttribute(&((prop.maxGridSize)[1]), cudaDevAttrMaxGridDimY, device_id); 
# 45
error = cudaDeviceGetAttribute(&((prop.maxGridSize)[2]), cudaDevAttrMaxGridDimZ, device_id); 
# 46
error = cudaDeviceGetAttribute(&(prop.maxThreadsPerBlock), cudaDevAttrMaxThreadsPerBlock, device_id); 
# 47
error = cudaDeviceGetAttribute(&(prop.maxThreadsPerMultiProcessor), cudaDevAttrMaxThreadsPerMultiProcessor, device_id); 
# 48
error = cudaDeviceGetAttribute(&(prop.minor), cudaDevAttrComputeCapabilityMinor, device_id); 
# 49
error = cudaDeviceGetAttribute(&(prop.multiProcessorCount), cudaDevAttrMultiProcessorCount, device_id); 
# 50
error = cudaDeviceGetAttribute(&(prop.regsPerBlock), cudaDevAttrMaxRegistersPerBlock, device_id); 
# 51
int temp; 
# 52
error = cudaDeviceGetAttribute(&temp, cudaDevAttrMaxSharedMemoryPerBlock, device_id); 
# 53
(prop.sharedMemPerBlock) = temp; 
# 54
error = cudaDeviceGetAttribute(&(prop.warpSize), cudaDevAttrWarpSize, device_id); 
# 59
throw_on_error(error, "cudaDeviceGetProperty in get_device_properties"); 
# 61
return prop; 
# 62
} 
# 65
inline device_properties_t device_properties_cached(int device_id) 
# 66
{ 
# 69
static const int max_num_devices = 16; 
# 71
static bool properties_exist[max_num_devices] = {(0)}; 
# 72
static device_properties_t device_properties[max_num_devices] = {}; 
# 74
if (device_id >= max_num_devices) 
# 75
{ 
# 76
return device_properties_uncached(device_id); 
# 77
}  
# 79
if (!((properties_exist)[device_id])) 
# 80
{ 
# 81
((device_properties)[device_id]) = device_properties_uncached(device_id); 
# 85
__sync_synchronize(); 
# 87
((properties_exist)[device_id]) = true; 
# 88
}  
# 90
return (device_properties)[device_id]; 
# 91
} 
# 95
inline device_properties_t device_properties(int device_id) 
# 96
{ 
# 98
return device_properties_cached(device_id); 
# 102
} 
# 106
inline int current_device() 
# 107
{ 
# 108
int result = (-1); 
# 111
bulk_::detail::throw_on_error(cudaGetDevice(&result), "current_device(): after cudaGetDevice"); 
# 114
if (result < 0) 
# 115
{ 
# 116
bulk_::detail::throw_on_error(cudaErrorNoDevice, "current_device(): after cudaGetDevice"); 
# 117
}  
# 119
return result; 
# 120
} 
# 124
inline device_properties_t device_properties() 
# 125
{ 
# 126
return device_properties(current_device()); 
# 127
} 
# 130
template< class KernelFunction> inline function_attributes_t 
# 132
function_attributes(KernelFunction kernel) 
# 133
{ 
# 135
typedef void (*fun_ptr_type)(void); 
# 137
fun_ptr_type fun_ptr = reinterpret_cast< fun_ptr_type>(kernel); 
# 139
cudaFuncAttributes attributes; 
# 141
bulk_::detail::throw_on_error(cudaFuncGetAttributes(&attributes, fun_ptr), "function_attributes(): after cudaFuncGetAttributes"); 
# 144
function_attributes_t result = {attributes.constSizeBytes, attributes.localSizeBytes, attributes.maxThreadsPerBlock, attributes.numRegs, attributes.ptxVersion, attributes.sharedSizeBytes}; 
# 153
return result; 
# 157
} 
# 160
inline size_t compute_capability(const device_properties_t &properties) 
# 161
{ 
# 162
return (10 * (properties.major)) + (properties.minor); 
# 163
} 
# 167
inline size_t compute_capability() 
# 168
{ 
# 169
return compute_capability(device_properties()); 
# 170
} 
# 173
}
# 174
}
# 175
}}}}
# 25 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/execution_policy.hpp"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 26
namespace bulk_ { 
# 57
static const int invalid_index = 2147483647; 
# 62
template< std::size_t grainsize_ = 1UL> 
# 63
class agent { 
# 66
public: typedef int size_type; 
# 68
static const size_type static_grainsize = (grainsize_); 
# 71
agent(size_type i = invalid_index) : m_index(i) 
# 73
{ } 
# 76
size_type index() const 
# 77
{ 
# 78
return m_index; 
# 79
} 
# 82
size_type grainsize() const 
# 83
{ 
# 84
return static_grainsize; 
# 85
} 
# 88
private: const size_type m_index; 
# 89
}; 
# 92
static const int use_default = 2147483647; 
# 94
static const int dynamic_group_size = 0; 
# 97
namespace detail { 
# 99
namespace group_detail { 
# 103
template< class ExecutionAgent, std::size_t size_> 
# 104
class group_base { 
# 107
public: typedef ExecutionAgent agent_type; 
# 109
typedef int size_type; 
# 111
static const size_type static_size = (size_); 
# 114
group_base(agent_type exec = agent_type(), size_type i = invalid_index) : this_exec(exec), m_index(i) 
# 117
{ } 
# 120
size_type index() const 
# 121
{ 
# 122
return m_index; 
# 123
} 
# 126
size_type size() const 
# 127
{ 
# 128
return static_size; 
# 129
} 
# 132
size_type global_index() const 
# 133
{int volatile ___ = 1;
# 135
::exit(___);}
#if 0
# 133
{ 
# 134
return (index() * size()) + ((this_exec).index()); 
# 135
} 
#endif
# 137 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/execution_policy.hpp"
agent_type this_exec; 
# 140
private: const size_type m_index; 
# 141
}; 
# 144
template< class ExecutionAgent> 
# 145
class group_base< ExecutionAgent, dynamic_group_size>  { 
# 148
public: typedef ExecutionAgent agent_type; 
# 150
typedef int size_type; 
# 153
group_base(size_type sz, agent_type exec = agent_type(), size_type i = invalid_index) : this_exec(exec), m_size(sz), m_index(i) 
# 157
{ } 
# 160
size_type index() const 
# 161
{ 
# 162
return m_index; 
# 163
} 
# 166
size_type size() const 
# 167
{ 
# 168
return m_size; 
# 169
} 
# 172
size_type global_index() const 
# 173
{ 
# 174
return (index() * size()) + ((this_exec).index()); 
# 175
} 
# 177
agent_type this_exec; 
# 180
private: const size_type m_size; 
# 181
const size_type m_index; 
# 182
}; 
# 185
}
# 186
}
# 190
template< class ExecutionAgent = agent<> , std::size_t 
# 191
size_ = 0UL> 
# 192
class parallel_group : public detail::group_detail::group_base< ExecutionAgent, size_>  { 
# 199
typedef ::thrust::system::cuda::detail::bulk_::detail::group_detail::group_base< ExecutionAgent, size_>  super_t; 
# 202
public: typedef typename ::thrust::system::cuda::detail::bulk_::detail::group_detail::group_base< ExecutionAgent, size_> ::agent_type agent_type; 
# 204
typedef typename ::thrust::system::cuda::detail::bulk_::detail::group_detail::group_base< ExecutionAgent, size_> ::size_type size_type; 
# 208
parallel_group(agent_type exec = agent_type(), size_type i = invalid_index) : super_t(exec, i) 
# 210
{ } 
# 211
}; 
# 214
template< class ExecutionAgent> 
# 215
class parallel_group< ExecutionAgent, dynamic_group_size>  : public detail::group_detail::group_base< ExecutionAgent, 0UL>  { 
# 222
typedef ::thrust::system::cuda::detail::bulk_::detail::group_detail::group_base< ExecutionAgent, 0UL>  super_t; 
# 225
public: typedef typename ::thrust::system::cuda::detail::bulk_::detail::group_detail::group_base< ExecutionAgent, 0UL> ::agent_type agent_type; 
# 227
typedef typename ::thrust::system::cuda::detail::bulk_::detail::group_detail::group_base< ExecutionAgent, 0UL> ::size_type size_type; 
# 231
parallel_group(size_type size, agent_type exec = agent_type(), size_type i = invalid_index) : super_t(size, exec, i) 
# 233
{ } 
# 234
}; 
# 239
inline parallel_group<>  par(size_t size) 
# 240
{ 
# 241
typedef parallel_group<> ::size_type size_type; 
# 242
return ((parallel_group<> )(static_cast< size_type>(size))); 
# 243
} 
# 247
template< class ExecutionAgent> parallel_group< ExecutionAgent>  
# 249
par(ExecutionAgent exec, size_t size) 
# 250
{ 
# 251
typedef typename parallel_group< ExecutionAgent> ::size_type size_type; 
# 252
return parallel_group< ExecutionAgent> (static_cast< size_type>(size), exec); 
# 253
} 
# 256
template< class ExecutionAgent> 
# 257
class async_launch { 
# 261
public: async_launch(ExecutionAgent exec, cudaStream_t s, cudaEvent_t be = 0) : stream_valid(true), e(exec), s(s), be(be) 
# 263
{ } 
# 266
async_launch(ExecutionAgent exec, cudaEvent_t be) : stream_valid(false), e(exec), s((0)), be(be) 
# 268
{ } 
# 271
ExecutionAgent exec() const 
# 272
{ 
# 273
return e; 
# 274
} 
# 277
cudaStream_t stream() const 
# 278
{ 
# 279
return s; 
# 280
} 
# 283
cudaEvent_t before_event() const 
# 284
{ 
# 285
return be; 
# 286
} 
# 289
bool is_stream_valid() const 
# 290
{ 
# 291
return stream_valid; 
# 292
} 
# 295
private: bool stream_valid; 
# 296
ExecutionAgent e; 
# 297
cudaStream_t s; 
# 298
cudaEvent_t be; 
# 299
}; 
# 303
inline async_launch< parallel_group<> >  par(cudaStream_t s, size_t num_threads) 
# 304
{ 
# 305
typedef parallel_group<> ::size_type size_type; 
# 306
return async_launch< parallel_group<> > (((parallel_group<> )(static_cast< size_type>(num_threads))), s); 
# 307
} 
# 310
template< class ExecutionAgent> inline async_launch< parallel_group< ExecutionAgent> >  
# 312
par(cudaStream_t s, ExecutionAgent exec, size_t num_groups) 
# 313
{ 
# 314
return async_launch< parallel_group< ExecutionAgent> > (bulk_::par(exec, num_groups), s); 
# 315
} 
# 318
inline async_launch< parallel_group<> >  par(future< void>  &before, size_t num_threads) 
# 319
{ 
# 320
cudaEvent_t before_event = bulk_::detail::future_core_access::event(before); 
# 322
typedef parallel_group<> ::size_type size_type; 
# 323
return async_launch< parallel_group<> > (((parallel_group<> )(static_cast< size_type>(num_threads))), before_event); 
# 324
} 
# 328
template< class ExecutionAgent = agent<> , std::size_t 
# 329
size_ = 0UL> 
# 330
class concurrent_group : public parallel_group< ExecutionAgent, size_>  { 
# 337
typedef ::thrust::system::cuda::detail::bulk_::parallel_group< ExecutionAgent, size_>  super_t; 
# 340
public: typedef typename ::thrust::system::cuda::detail::bulk_::parallel_group< ExecutionAgent, size_> ::agent_type agent_type; 
# 341
typedef typename ::thrust::system::cuda::detail::bulk_::parallel_group< ExecutionAgent, size_> ::size_type size_type; 
# 345
concurrent_group(size_type heap_size = use_default, agent_type 
# 346
exec = agent_type(), size_type 
# 347
i = invalid_index) : super_t(exec, i), m_heap_size(heap_size) 
# 350
{ } 
# 353
void wait() const 
# 354
{int volatile ___ = 1;
# 359
::exit(___);}
#if 0
# 354
{ 
# 359
} 
#endif
# 362 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/execution_policy.hpp"
size_type heap_size() const 
# 363
{ 
# 364
return m_heap_size; 
# 365
} 
# 369
static size_type hardware_concurrency() 
# 370
{ 
# 372
return static_cast< size_type>(bulk_::detail::device_properties().multiProcessorCount); 
# 376
} 
# 379
private: size_type m_heap_size; 
# 380
}; 
# 383
template< class ExecutionAgent> 
# 384
class concurrent_group< ExecutionAgent, dynamic_group_size>  : public parallel_group< ExecutionAgent, 0UL>  { 
# 391
typedef ::thrust::system::cuda::detail::bulk_::parallel_group< ExecutionAgent, 0UL>  super_t; 
# 394
public: typedef typename ::thrust::system::cuda::detail::bulk_::parallel_group< ExecutionAgent, 0UL> ::agent_type agent_type; 
# 396
typedef typename ::thrust::system::cuda::detail::bulk_::parallel_group< ExecutionAgent, 0UL> ::size_type size_type; 
# 400
concurrent_group(size_type size, size_type 
# 401
heap_size = use_default, agent_type 
# 402
exec = agent_type(), size_type 
# 403
i = invalid_index) : super_t(size, exec, i), m_heap_size(heap_size) 
# 406
{ } 
# 409
void wait() 
# 410
{int volatile ___ = 1;
# 415
::exit(___);}
#if 0
# 410
{ 
# 415
} 
#endif
# 418 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/execution_policy.hpp"
size_type heap_size() const 
# 419
{ 
# 420
return m_heap_size; 
# 421
} 
# 425
static size_type hardware_concurrency() 
# 426
{ 
# 428
return static_cast< size_type>(bulk_::detail::device_properties().multiProcessorCount); 
# 432
} 
# 435
private: size_type m_heap_size; 
# 436
}; 
# 441
inline concurrent_group<>  con(size_t size, size_t heap_size = use_default) 
# 442
{ 
# 443
typedef concurrent_group<> ::size_type size_type; 
# 444
return concurrent_group<> (static_cast< size_type>(size), static_cast< size_type>(heap_size)); 
# 445
} 
# 449
template< class ExecutionAgent> concurrent_group< ExecutionAgent>  
# 451
con(ExecutionAgent exec, size_t size, size_t heap_size = use_default) 
# 452
{ 
# 453
typedef typename concurrent_group< ExecutionAgent> ::size_type size_type; 
# 454
return concurrent_group< ExecutionAgent> (static_cast< size_type>(size), static_cast< size_type>(heap_size), exec); 
# 455
} 
# 459
template< std::size_t groupsize, std::size_t grainsize> concurrent_group< agent< grainsize> , groupsize>  
# 462
con(size_t heap_size) 
# 463
{ 
# 464
typedef typename concurrent_group< agent< grainsize> , groupsize> ::size_type size_type; 
# 465
return ((concurrent_group< agent< grainsize> , groupsize> )(static_cast< size_type>(heap_size))); 
# 466
} 
# 470
template< std::size_t bound_, class ExecutionAgent> 
# 471
class bounded : public ExecutionAgent { 
# 475
public: typedef typename ExecutionAgent::size_type size_type; 
# 477
static const size_type static_bound = (bound_); 
# 480
size_type bound() const 
# 481
{ 
# 482
return static_bound; 
# 483
} 
# 487
ExecutionAgent &unbound() 
# 488
{ 
# 489
return *this; 
# 490
} 
# 494
const ExecutionAgent &unbound() const 
# 495
{ 
# 496
return *this; 
# 497
} 
# 502
private: bounded(); 
# 504
bounded(const bounded &); 
# 505
}; 
# 508
template< std::size_t bound_, class ExecutionAgent> bounded< bound_, ExecutionAgent>  &
# 510
bound(ExecutionAgent &exec) 
# 511
{ 
# 512
return static_cast< bounded< bound_, ExecutionAgent>  &>(exec); 
# 513
} 
# 516
template< std::size_t bound_, class ExecutionAgent> const bounded< bound_, ExecutionAgent>  &
# 518
bound(const ExecutionAgent &exec) 
# 519
{ 
# 520
return static_cast< const bounded< bound_, ExecutionAgent>  &>(exec); 
# 521
} 
# 524
namespace detail { 
# 528
template< unsigned depth, class ExecutionAgent> 
# 529
struct agent_at_depth { 
# 533
typedef typename detail::agent_at_depth< depth - (1), ExecutionAgent> ::type parent_agent_type; 
# 535
typedef typename detail::agent_at_depth< depth - (1), ExecutionAgent> ::type::agent_type type; 
# 536
}; 
# 539
template< class ExecutionAgent> 
# 540
struct agent_at_depth< 0, ExecutionAgent>  { 
# 542
typedef ExecutionAgent type; 
# 543
}; 
# 546
template< class Cursor, class ExecutionGroup> 
# 547
struct cursor_result { 
# 549
typedef typename agent_at_depth< Cursor::depth, ExecutionGroup> ::type &type; 
# 550
}; 
# 553
template< unsigned d> struct cursor; 
# 556
template< unsigned d> 
# 557
struct cursor { 
# 559
static const unsigned depth = d; 
# 561
cursor() { } 
# 563
detail::cursor< depth + (1)>  this_exec; 
# 565
template< class ExecutionGroup> static typename cursor_result< cursor, ExecutionGroup> ::type 
# 568
get(ExecutionGroup &root) 
# 569
{ 
# 570
return cursor< depth - (1)> ::get((root.this_exec)); 
# 571
} 
# 572
}; 
# 575
template<> struct cursor< 3U>  { 
# 577
static const unsigned depth = (3); 
# 579
cursor() { } 
# 581
template< class ExecutionGroup> static typename cursor_result< detail::cursor< 3U> , ExecutionGroup> ::type 
# 584
get(ExecutionGroup &root) 
# 585
{ 
# 586
return detail::cursor< 2U> ::get((root.this_exec)); 
# 587
} 
# 588
}; 
# 591
template<> struct cursor< 0U>  { 
# 593
static const unsigned depth = (0); 
# 595
cursor() { } 
# 597
detail::cursor< 1U>  this_exec; 
# 600
template< class ExecutionAgent> static ExecutionAgent &
# 602
get(ExecutionAgent &root) 
# 603
{ 
# 604
return root; 
# 605
} 
# 606
}; 
# 609
template< class T> struct is_cursor : public thrust::detail::false_type { }; 
# 612
template< unsigned d> 
# 613
struct is_cursor< cursor< d> >  : public thrust::detail::true_type { 
# 615
}; 
# 618
}
# 624
static const detail::cursor< 0U>  root; 
# 630
inline parallel_group< concurrent_group<> >  grid(size_t num_groups = use_default, size_t group_size = use_default, size_t heap_size = use_default) 
# 631
{ 
# 632
return par(con(group_size, heap_size), num_groups); 
# 633
} 
# 642
inline async_launch< parallel_group< concurrent_group<> > >  grid(size_t num_groups, size_t group_size, size_t heap_size, cudaStream_t stream) 
# 643
{ 
# 644
return par(stream, con(group_size, heap_size), num_groups); 
# 645
} 
# 648
template< std::size_t groupsize, std::size_t grainsize> parallel_group< concurrent_group< agent< grainsize> , groupsize> >  
# 656
grid(size_t num_groups, size_t heap_size = use_default) 
# 657
{ 
# 658
return par(con< groupsize, grainsize> (heap_size), num_groups); 
# 659
} 
# 662
template< std::size_t groupsize, std::size_t grainsize> async_launch< parallel_group< concurrent_group< agent< grainsize> , groupsize> > >  
# 672
grid(size_t num_groups, size_t heap_size, cudaStream_t stream) 
# 673
{ 
# 674
return par(stream, con< groupsize, grainsize> (heap_size), num_groups); 
# 675
} 
# 678
}
# 679
}}}}
# 24 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/choose_sizes.hpp"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 25
namespace bulk_ { 
# 29
template< class Function> pair< int, int>  choose_sizes(parallel_group< concurrent_group<> >  g, Function f); 
# 36
template< class Function, class Arg1> pair< int, int>  choose_sizes(parallel_group< concurrent_group<> >  g, Function f, Arg1 arg1); 
# 43
template< class Function, class Arg1, class Arg2> pair< int, int>  choose_sizes(parallel_group< concurrent_group<> >  g, Function f, Arg1 arg1, Arg2 arg2); 
# 50
template< class Function, class Arg1, class Arg2, class Arg3> pair< int, int>  choose_sizes(parallel_group< concurrent_group<> >  g, Function f, Arg1 arg1, Arg2 arg2, Arg3 arg3); 
# 57
template< class Function, class Arg1, class Arg2, class Arg3, class Arg4> pair< int, int>  choose_sizes(parallel_group< concurrent_group<> >  g, Function f, Arg1 arg1, Arg2 arg2, Arg3 arg3, Arg4 arg4); 
# 64
template< class Function, class Arg1, class Arg2, class Arg3, class Arg4, class Arg5> pair< int, int>  choose_sizes(parallel_group< concurrent_group<> >  g, Function f, Arg1 arg1, Arg2 arg2, Arg3 arg3, Arg4 arg4, Arg5 arg5); 
# 71
template< class Function, class Arg1, class Arg2, class Arg3, class Arg4, class Arg5, class Arg6> pair< int, int>  choose_sizes(parallel_group< concurrent_group<> >  g, Function f, Arg1 arg1, Arg2 arg2, Arg3 arg3, Arg4 arg4, Arg5 arg5, Arg6 arg6); 
# 78
}
# 79
}}}}
# 22 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/detail/apply_from_tuple.hpp"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 23
namespace bulk_ { 
# 25
namespace detail { 
# 29
template< class Function> void 
# 31
apply_from_tuple(Function f, const tuple< null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type>  &) 
# 32
{ 
# 33
f(); 
# 34
} 
# 37
template< class Function, class Arg1> void 
# 39
apply_from_tuple(Function f, const tuple< Arg1, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type>  &args) 
# 40
{ 
# 41
f(thrust::get< 0> (args)); 
# 42
} 
# 45
template< class Function, class Arg1, class Arg2> void 
# 47
apply_from_tuple(Function f, const tuple< Arg1, Arg2, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type>  &args) 
# 48
{ 
# 49
f(thrust::get< 0> (args), thrust::get< 1> (args)); 
# 51
} 
# 54
template< class Function, class Arg1, class Arg2, class Arg3> void 
# 56
apply_from_tuple(Function f, const tuple< Arg1, Arg2, Arg3, null_type, null_type, null_type, null_type, null_type, null_type, null_type>  &args) 
# 57
{ 
# 58
f(thrust::get< 0> (args), thrust::get< 1> (args), thrust::get< 2> (args)); 
# 61
} 
# 64
template< class Function, class Arg1, class Arg2, class Arg3, class Arg4> void 
# 66
apply_from_tuple(Function f, const tuple< Arg1, Arg2, Arg3, Arg4, null_type, null_type, null_type, null_type, null_type, null_type>  &args) 
# 67
{ 
# 68
f(thrust::get< 0> (args), thrust::get< 1> (args), thrust::get< 2> (args), thrust::get< 3> (args)); 
# 72
} 
# 75
template< class Function, class Arg1, class Arg2, class Arg3, class Arg4, class Arg5> void 
# 77
apply_from_tuple(Function f, const tuple< Arg1, Arg2, Arg3, Arg4, Arg5, null_type, null_type, null_type, null_type, null_type>  &args) 
# 78
{ 
# 79
f(thrust::get< 0> (args), thrust::get< 1> (args), thrust::get< 2> (args), thrust::get< 3> (args), thrust::get< 4> (args)); 
# 84
} 
# 87
template< class Function, class Arg1, class Arg2, class Arg3, class Arg4, class Arg5, class Arg6> void 
# 89
apply_from_tuple(Function f, const tuple< Arg1, Arg2, Arg3, Arg4, Arg5, Arg6, null_type, null_type, null_type, null_type>  &args) 
# 90
{ 
# 91
f(thrust::get< 0> (args), thrust::get< 1> (args), thrust::get< 2> (args), thrust::get< 3> (args), thrust::get< 4> (args), thrust::get< 5> (args)); 
# 97
} 
# 100
template< class Function, class Arg1, class Arg2, class Arg3, class Arg4, class Arg5, class Arg6, class Arg7> void 
# 102
apply_from_tuple(Function f, const tuple< Arg1, Arg2, Arg3, Arg4, Arg5, Arg6, Arg7, null_type, null_type, null_type>  &args) 
# 103
{ 
# 104
f(thrust::get< 0> (args), thrust::get< 1> (args), thrust::get< 2> (args), thrust::get< 3> (args), thrust::get< 4> (args), thrust::get< 5> (args), thrust::get< 6> (args)); 
# 111
} 
# 114
template< class Function, class Arg1, class Arg2, class Arg3, class Arg4, class Arg5, class Arg6, class Arg7, class Arg8> void 
# 116
apply_from_tuple(Function f, const tuple< Arg1, Arg2, Arg3, Arg4, Arg5, Arg6, Arg7, Arg8, null_type, null_type>  &args) 
# 117
{ 
# 118
f(thrust::get< 0> (args), thrust::get< 1> (args), thrust::get< 2> (args), thrust::get< 3> (args), thrust::get< 4> (args), thrust::get< 5> (args), thrust::get< 6> (args), thrust::get< 7> (args)); 
# 126
} 
# 129
template< class Function, class Arg1, class Arg2, class Arg3, class Arg4, class Arg5, class Arg6, class Arg7, class Arg8, class Arg9> void 
# 131
apply_from_tuple(Function f, const tuple< Arg1, Arg2, Arg3, Arg4, Arg5, Arg6, Arg7, Arg8, Arg9, null_type>  &args) 
# 132
{ 
# 133
f(thrust::get< 0> (args), thrust::get< 1> (args), thrust::get< 2> (args), thrust::get< 3> (args), thrust::get< 4> (args), thrust::get< 5> (args), thrust::get< 6> (args), thrust::get< 7> (args), thrust::get< 8> (args)); 
# 142
} 
# 145
template< class Function, class Arg1, class Arg2, class Arg3, class Arg4, class Arg5, class Arg6, class Arg7, class Arg8, class Arg9, class Arg10> void 
# 147
apply_from_tuple(Function f, const tuple< Arg1, Arg2, Arg3, Arg4, Arg5, Arg6, Arg7, Arg8, Arg9, Arg10>  &args) 
# 148
{ 
# 149
f(thrust::get< 0> (args), thrust::get< 1> (args), thrust::get< 2> (args), thrust::get< 3> (args), thrust::get< 4> (args), thrust::get< 5> (args), thrust::get< 6> (args), thrust::get< 7> (args), thrust::get< 8> (args), thrust::get< 9> (args)); 
# 159
} 
# 162
}
# 163
}
# 164
}}}}
# 25 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/detail/closure.hpp"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 26
namespace bulk_ { 
# 28
namespace detail { 
# 32
template< class Function, class Tuple> 
# 33
class closure { 
# 36
public: typedef Function function_type; 
# 38
typedef Tuple arguments_type; 
# 41
closure(function_type f, const arguments_type &args) : f(f), args(args) 
# 44
{ } 
# 48
void operator()() 
# 49
{ 
# 50
apply_from_tuple(f, args); 
# 51
} 
# 55
function_type function() const 
# 56
{ 
# 57
return f; 
# 58
} 
# 62
arguments_type arguments() const 
# 63
{ 
# 64
return args; 
# 65
} 
# 69
private: function_type f; 
# 70
arguments_type args; 
# 71
}; 
# 74
template< class Function, class Arguments> const closure< Function, Arguments>  &
# 76
make_closure(const closure< Function, Arguments>  &c) 
# 77
{ 
# 78
return c; 
# 79
} 
# 82
template< class Function> closure< Function, tuple< null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type> >  
# 84
make_closure(Function f) 
# 85
{ 
# 86
return closure< Function, tuple< null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type> > (f, tuple< null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type> ()); 
# 87
} 
# 90
template< class Function, class Arg1> closure< Function, tuple< Arg1, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type> >  
# 92
make_closure(Function f, const Arg1 &a1) 
# 93
{ 
# 94
return closure< Function, tuple< Arg1, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type> > (f, thrust::make_tuple(a1)); 
# 95
} 
# 98
template< class Function, class Arg1, class Arg2> closure< Function, tuple< Arg1, Arg2, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type> >  
# 104
make_closure(Function f, const Arg1 &a1, const Arg2 &a2) 
# 105
{ 
# 106
return closure< Function, tuple< Arg1, Arg2, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type> > (f, thrust::make_tuple(a1, a2)); 
# 107
} 
# 110
template< class Function, class Arg1, class Arg2, class Arg3> closure< Function, tuple< Arg1, Arg2, Arg3, null_type, null_type, null_type, null_type, null_type, null_type, null_type> >  
# 116
make_closure(Function f, const Arg1 &a1, const Arg2 &a2, const Arg3 &a3) 
# 117
{ 
# 118
return closure< Function, tuple< Arg1, Arg2, Arg3, null_type, null_type, null_type, null_type, null_type, null_type, null_type> > (f, thrust::make_tuple(a1, a2, a3)); 
# 119
} 
# 122
template< class Function, class Arg1, class Arg2, class Arg3, class Arg4> closure< Function, tuple< Arg1, Arg2, Arg3, Arg4, null_type, null_type, null_type, null_type, null_type, null_type> >  
# 128
make_closure(Function f, const Arg1 &a1, const Arg2 &a2, const Arg3 &a3, const Arg4 &a4) 
# 129
{ 
# 130
return closure< Function, tuple< Arg1, Arg2, Arg3, Arg4, null_type, null_type, null_type, null_type, null_type, null_type> > (f, thrust::make_tuple(a1, a2, a3, a4)); 
# 131
} 
# 134
template< class Function, class Arg1, class Arg2, class Arg3, class Arg4, class Arg5> closure< Function, tuple< Arg1, Arg2, Arg3, Arg4, Arg5, null_type, null_type, null_type, null_type, null_type> >  
# 140
make_closure(Function f, const Arg1 &a1, const Arg2 &a2, const Arg3 &a3, const Arg4 &a4, const Arg5 &a5) 
# 141
{ 
# 142
return closure< Function, tuple< Arg1, Arg2, Arg3, Arg4, Arg5, null_type, null_type, null_type, null_type, null_type> > (f, thrust::make_tuple(a1, a2, a3, a4, a5)); 
# 143
} 
# 146
template< class Function, class Arg1, class Arg2, class Arg3, class Arg4, class Arg5, class Arg6> closure< Function, tuple< Arg1, Arg2, Arg3, Arg4, Arg5, Arg6, null_type, null_type, null_type, null_type> >  
# 152
make_closure(Function f, const Arg1 &a1, const Arg2 &a2, const Arg3 &a3, const Arg4 &a4, const Arg5 &a5, const Arg6 &a6) 
# 153
{ 
# 154
return closure< Function, tuple< Arg1, Arg2, Arg3, Arg4, Arg5, Arg6, null_type, null_type, null_type, null_type> > (f, thrust::make_tuple(a1, a2, a3, a4, a5, a6)); 
# 155
} 
# 158
template< class Function, class Arg1, class Arg2, class Arg3, class Arg4, class Arg5, class Arg6, class Arg7> closure< Function, tuple< Arg1, Arg2, Arg3, Arg4, Arg5, Arg6, Arg7, null_type, null_type, null_type> >  
# 164
make_closure(Function f, const Arg1 &a1, const Arg2 &a2, const Arg3 &a3, const Arg4 &a4, const Arg5 &a5, const Arg6 &a6, const Arg7 &a7) 
# 165
{ 
# 166
return closure< Function, tuple< Arg1, Arg2, Arg3, Arg4, Arg5, Arg6, Arg7, null_type, null_type, null_type> > (f, thrust::make_tuple(a1, a2, a3, a4, a5, a6, a7)); 
# 167
} 
# 170
template< class Function, class Arg1, class Arg2, class Arg3, class Arg4, class Arg5, class Arg6, class Arg7, class Arg8> closure< Function, tuple< Arg1, Arg2, Arg3, Arg4, Arg5, Arg6, Arg7, Arg8, null_type, null_type> >  
# 176
make_closure(Function f, const Arg1 &a1, const Arg2 &a2, const Arg3 &a3, const Arg4 &a4, const Arg5 &a5, const Arg6 &a6, const Arg7 &a7, const Arg8 &a8) 
# 177
{ 
# 178
return closure< Function, tuple< Arg1, Arg2, Arg3, Arg4, Arg5, Arg6, Arg7, Arg8, null_type, null_type> > (f, thrust::make_tuple(a1, a2, a3, a4, a5, a6, a7, a8)); 
# 179
} 
# 182
template< class Function, class Arg1, class Arg2, class Arg3, class Arg4, class Arg5, class Arg6, class Arg7, class Arg8, class Arg9> closure< Function, tuple< Arg1, Arg2, Arg3, Arg4, Arg5, Arg6, Arg7, Arg8, Arg9, null_type> >  
# 188
make_closure(Function f, const Arg1 &a1, const Arg2 &a2, const Arg3 &a3, const Arg4 &a4, const Arg5 &a5, const Arg6 &a6, const Arg7 &a7, const Arg8 &a8, const Arg9 &a9) 
# 189
{ 
# 190
return closure< Function, tuple< Arg1, Arg2, Arg3, Arg4, Arg5, Arg6, Arg7, Arg8, Arg9, null_type> > (f, thrust::make_tuple(a1, a2, a3, a4, a5, a6, a7, a8, a9)); 
# 191
} 
# 194
template< class Function, class Arg1, class Arg2, class Arg3, class Arg4, class Arg5, class Arg6, class Arg7, class Arg8, class Arg9, class Arg10> closure< Function, tuple< Arg1, Arg2, Arg3, Arg4, Arg5, Arg6, Arg7, Arg8, Arg9, Arg10> >  
# 200
make_closure(Function f, const Arg1 &a1, const Arg2 &a2, const Arg3 &a3, const Arg4 &a4, const Arg5 &a5, const Arg6 &a6, const Arg7 &a7, const Arg8 &a8, const Arg9 &a9, const Arg10 &a10) 
# 201
{ 
# 202
return closure< Function, tuple< Arg1, Arg2, Arg3, Arg4, Arg5, Arg6, Arg7, Arg8, Arg9, Arg10> > (f, thrust::make_tuple(a1, a2, a3, a4, a5, a6, a7, a8, a9, a10)); 
# 203
} 
# 206
}
# 207
}
# 208
}}}}
# 21 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/detail/alignment.hpp"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 22
namespace bulk_ { 
# 24
namespace detail { 
# 26
namespace alignment_of_detail { 
# 30
template< class T> class alignment_of_impl; 
# 32
template< class T, std::size_t size_diff> 
# 33
struct helper { 
# 35
static const std::size_t value = size_diff; 
# 36
}; 
# 38
template< class T> 
# 39
class helper< T, 0>  { 
# 42
public: static const std::size_t value = (alignment_of_impl< T> ::value); 
# 43
}; 
# 45
template< class T> 
# 46
class alignment_of_impl { 
# 49
struct big { T x; char c; }; 
# 52
public: static const std::size_t value = (helper< big, sizeof(big) - sizeof(T)> ::value); 
# 53
}; 
# 56
}
# 59
template< class T> 
# 60
struct alignment_of : public alignment_of_detail::alignment_of_impl< T>  { 
# 62
}; 
# 65
template< std::size_t Align> struct aligned_type; 
# 190
template< std::size_t Align> struct aligned_type { 
# 192
struct __attribute((aligned(Align))) type { }; 
# 193
}; 
# 203
template< std::size_t Len, std::size_t Align> 
# 204
struct aligned_storage { 
# 206
union type { 
# 208
unsigned char data[Len]; 
# 210
typename aligned_type< Align> ::type align; 
# 211
}; 
# 212
}; 
# 215
}
# 216
}
# 217
}}}}
# 21 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/detail/pointer_traits.hpp"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 22
namespace bulk_ { 
# 24
namespace detail { 
# 28
__attribute__((unused)) inline unsigned __isShared(const void *ptr) 
# 29
{int volatile ___ = 1;(void)ptr;
# 50
::exit(___);}
#if 0
# 29
{ 
# 31
(void)ptr; 
# 33
unsigned ret; 
# 46
ret = (0); 
# 49
return ret; 
# 50
} 
#endif
# 53 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/detail/pointer_traits.hpp"
__attribute__((unused)) inline bool is_shared(const void *ptr) 
# 54
{int volatile ___ = 1;(void)ptr;
# 56
::exit(___);}
#if 0
# 54
{ 
# 55
return __isShared(ptr); 
# 56
} 
#endif
# 59 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/detail/pointer_traits.hpp"
__attribute__((unused)) inline bool is_global(const void *ptr) 
# 60
{int volatile ___ = 1;(void)ptr;
# 69
::exit(___);}
#if 0
# 60
{ 
# 62
(void)ptr; 
# 67
return false; 
# 69
} 
#endif
# 72 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/detail/pointer_traits.hpp"
}
# 73
}
# 74
}}}}
# 25 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/uninitialized.hpp"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 26
namespace bulk_ { 
# 30
template< class T> 
# 31
class uninitialized { 
# 37
typename detail::aligned_storage< sizeof(T), detail::alignment_of< T> ::value> ::type storage; 
# 39
__attribute((always_inline)) const T *
# 40
ptr() const 
# 41
{ 
# 42
const void *result = (((storage).data)); 
# 43
return reinterpret_cast< const T *>(result); 
# 44
} 
# 46
__attribute((always_inline)) T *
# 47
ptr() 
# 48
{ 
# 49
void *result = (((storage).data)); 
# 50
return reinterpret_cast< T *>(result); 
# 51
} 
# 56
public: 
# 55
__attribute((always_inline)) uninitialized &
# 56
operator=(const T &other) 
# 57
{ 
# 58
T &self = *this; 
# 59
self = other; 
# 60
return *this; 
# 61
} 
# 63
__attribute((always_inline)) T &
# 64
get() 
# 65
{ 
# 66
return *this->ptr(); 
# 67
} 
# 69
__attribute((always_inline)) const T &
# 70
get() const 
# 71
{ 
# 72
return *this->ptr(); 
# 73
} 
# 75
__attribute((always_inline)) 
# 76
operator T &() 
# 77
{ 
# 78
return this->get(); 
# 79
} 
# 81
__attribute((always_inline)) 
# 82
operator const T &() const 
# 83
{ 
# 84
return this->get(); 
# 85
} 
# 88
__attribute((always_inline)) void 
# 89
construct() 
# 90
{ 
# 91
::new (this->ptr()) (T)(); 
# 92
} 
# 95
template< class Arg> 
# 96
__attribute((always_inline)) void 
# 97
construct(const Arg &a) 
# 98
{ 
# 99
::new (this->ptr()) (T)(a); 
# 100
} 
# 103
template< class Arg1, class Arg2> 
# 104
__attribute((always_inline)) void 
# 105
construct(const Arg1 &a1, const Arg2 &a2) 
# 106
{ 
# 107
::new (this->ptr()) (T)(a1, a2); 
# 108
} 
# 111
template< class Arg1, class Arg2, class Arg3> 
# 112
__attribute((always_inline)) void 
# 113
construct(const Arg1 &a1, const Arg2 &a2, const Arg3 &a3) 
# 114
{ 
# 115
::new (this->ptr()) (T)(a1, a2, a3); 
# 116
} 
# 119
template< class Arg1, class Arg2, class Arg3, class Arg4> 
# 120
__attribute((always_inline)) void 
# 121
construct(const Arg1 &a1, const Arg2 &a2, const Arg3 &a3, const Arg4 &a4) 
# 122
{ 
# 123
::new (this->ptr()) (T)(a1, a2, a3, a4); 
# 124
} 
# 127
template< class Arg1, class Arg2, class Arg3, class Arg4, class Arg5> 
# 128
__attribute((always_inline)) void 
# 129
construct(const Arg1 &a1, const Arg2 &a2, const Arg3 &a3, const Arg4 &a4, const Arg5 &a5) 
# 130
{ 
# 131
::new (this->ptr()) (T)(a1, a2, a3, a4, a5); 
# 132
} 
# 135
template< class Arg1, class Arg2, class Arg3, class Arg4, class Arg5, class Arg6> 
# 136
__attribute((always_inline)) void 
# 137
construct(const Arg1 &a1, const Arg2 &a2, const Arg3 &a3, const Arg4 &a4, const Arg5 &a5, const Arg6 &a6) 
# 138
{ 
# 139
::new (this->ptr()) (T)(a1, a2, a3, a4, a5, a6); 
# 140
} 
# 143
template< class Arg1, class Arg2, class Arg3, class Arg4, class Arg5, class Arg6, class Arg7> 
# 144
__attribute((always_inline)) void 
# 145
construct(const Arg1 &a1, const Arg2 &a2, const Arg3 &a3, const Arg4 &a4, const Arg5 &a5, const Arg6 &a6, const Arg7 &a7) 
# 146
{ 
# 147
::new (this->ptr()) (T)(a1, a2, a3, a4, a5, a6, a7); 
# 148
} 
# 151
template< class Arg1, class Arg2, class Arg3, class Arg4, class Arg5, class Arg6, class Arg7, class Arg8> 
# 152
__attribute((always_inline)) void 
# 153
construct(const Arg1 &a1, const Arg2 &a2, const Arg3 &a3, const Arg4 &a4, const Arg5 &a5, const Arg6 &a6, const Arg7 &a7, const Arg8 &a8) 
# 154
{ 
# 155
::new (this->ptr()) (T)(a1, a2, a3, a4, a5, a6, a7, a8); 
# 156
} 
# 159
template< class Arg1, class Arg2, class Arg3, class Arg4, class Arg5, class Arg6, class Arg7, class Arg8, class Arg9> 
# 160
__attribute((always_inline)) void 
# 161
construct(const Arg1 &a1, const Arg2 &a2, const Arg3 &a3, const Arg4 &a4, const Arg5 &a5, const Arg6 &a6, const Arg7 &a7, const Arg8 &a8, const Arg9 &a9) 
# 162
{ 
# 163
::new (this->ptr()) (T)(a1, a2, a3, a4, a5, a6, a7, a8, a9); 
# 164
} 
# 167
template< class Arg1, class Arg2, class Arg3, class Arg4, class Arg5, class Arg6, class Arg7, class Arg8, class Arg9, class Arg10> 
# 168
__attribute((always_inline)) void 
# 169
construct(const Arg1 &a1, const Arg2 &a2, const Arg3 &a3, const Arg4 &a4, const Arg5 &a5, const Arg6 &a6, const Arg7 &a7, const Arg8 &a8, const Arg9 &a9, const Arg10 &a10) 
# 170
{ 
# 171
::new (this->ptr()) (T)(a1, a2, a3, a4, a5, a6, a7, a8, a9, a10); 
# 172
} 
# 175
__attribute((always_inline)) void 
# 176
destroy() 
# 177
{ 
# 178
T &self = *this; 
# 179
(self.~T()); 
# 180
} 
# 181
}; 
# 184
template< class T, std::size_t N> 
# 185
class uninitialized_array { 
# 188
public: typedef T value_type; 
# 189
typedef T &reference; 
# 190
typedef const T &const_reference; 
# 191
typedef T *pointer; 
# 192
typedef const T *const_pointer; 
# 193
typedef pointer iterator; 
# 194
typedef const_pointer const_iterator; 
# 195
typedef std::size_t size_type; 
# 197
__attribute((always_inline)) iterator 
# 198
begin() 
# 199
{ 
# 200
return this->data(); 
# 201
} 
# 203
__attribute((always_inline)) const_iterator 
# 204
begin() const 
# 205
{ 
# 206
return this->data(); 
# 207
} 
# 209
__attribute((always_inline)) iterator 
# 210
end() 
# 211
{ 
# 212
return this->begin() + size(); 
# 213
} 
# 215
__attribute((always_inline)) const_iterator 
# 216
end() const 
# 217
{ 
# 218
return this->begin() + size(); 
# 219
} 
# 221
__attribute((always_inline)) const_iterator 
# 222
cbegin() const 
# 223
{ 
# 224
return this->begin(); 
# 225
} 
# 227
__attribute((always_inline)) const_iterator 
# 228
cend() const 
# 229
{ 
# 230
return this->end(); 
# 231
} 
# 233
__attribute((always_inline)) size_type 
# 234
size() const 
# 235
{ 
# 236
return N; 
# 237
} 
# 239
__attribute((always_inline)) bool 
# 240
empty() const 
# 241
{ 
# 242
return false; 
# 243
} 
# 245
__attribute((always_inline)) T *
# 246
data() 
# 247
{ 
# 248
return ((impl).get()); 
# 249
} 
# 251
__attribute((always_inline)) const T *
# 252
data() const 
# 253
{ 
# 254
return ((impl).get()); 
# 255
} 
# 258
__attribute((always_inline)) reference 
# 259
operator[](size_type n) 
# 260
{ 
# 261
return this->data()[n]; 
# 262
} 
# 264
__attribute((always_inline)) const_reference 
# 265
operator[](size_type n) const 
# 266
{ 
# 267
return this->data()[n]; 
# 268
} 
# 270
__attribute((always_inline)) reference 
# 271
front() 
# 272
{ 
# 273
return *this->data(); 
# 274
} 
# 276
__attribute((always_inline)) const_reference 
# 277
front() const 
# 278
{ 
# 279
return *this->data(); 
# 280
} 
# 282
__attribute((always_inline)) reference 
# 283
back() 
# 284
{ 
# 285
return this->data()[size() - ((size_type)1)]; 
# 286
} 
# 288
__attribute((always_inline)) const_reference 
# 289
back() const 
# 290
{ 
# 291
return this->data()[size() - ((size_type)1)]; 
# 292
} 
# 295
private: uninitialized< T [N]>  impl; 
# 296
}; 
# 299
}
# 300
}}}}
# 27 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/malloc.hpp"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 28
namespace bulk_ { 
# 32
__attribute__((unused)) inline bool is_on_chip(void *ptr) 
# 33
{int volatile ___ = 1;(void)ptr;
# 35
::exit(___);}
#if 0
# 33
{ 
# 34
return bulk_::detail::is_shared(ptr); 
# 35
} 
#endif
# 38 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/malloc.hpp"
template< class T> __attribute__((unused)) inline T *
# 39
on_chip_cast(T *ptr) 
# 40
{int volatile ___ = 1;(void)ptr;
# 44
::exit(___);}
#if 0
# 40
{ 
# 41
__attribute__((unused)) extern char s_begin[]; 
# 42
void *result = ((reinterpret_cast< char *>(ptr)) - (s_begin)) + (s_begin); 
# 43
return reinterpret_cast< T *>(result); 
# 44
} 
#endif
# 47 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/malloc.hpp"
namespace detail { 
# 51
__attribute__((unused)) extern int s_data_segment_begin[]; 
# 54
class os { 
# 57
public: os(size_t max_data_segment_size) : m_program_break(s_data_segment_begin), m_max_data_segment_size(max_data_segment_size) 
# 60
{int *volatile ___ = 0;(void)max_data_segment_size;
# 61
::free(___);}
#if 0
# 60
{ 
# 61
} 
#endif
# 64 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/malloc.hpp"
int brk(void *end_data_segment) 
# 65
{int volatile ___ = 1;(void)end_data_segment;
# 73
::exit(___);}
#if 0
# 65
{ 
# 66
if (end_data_segment <= (m_program_break)) 
# 67
{ 
# 68
(m_program_break) = end_data_segment; 
# 69
return 0; 
# 70
}  
# 72
return -1; 
# 73
} 
#endif
# 76 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/malloc.hpp"
void *sbrk(size_t increment) 
# 77
{int volatile ___ = 1;(void)increment;
# 88
::exit(___);}
#if 0
# 77
{ 
# 78
if ((this->data_segment_size() + increment) <= (m_max_data_segment_size)) 
# 79
{ 
# 80
(m_program_break) = ((reinterpret_cast< char *>(m_program_break)) + increment); 
# 81
} else 
# 83
{ 
# 84
return reinterpret_cast< void *>(-1); 
# 85
}  
# 87
return m_program_break; 
# 88
} 
#endif
# 91 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/malloc.hpp"
void *program_break() const 
# 92
{int volatile ___ = 1;
# 94
::exit(___);}
#if 0
# 92
{ 
# 93
return m_program_break; 
# 94
} 
#endif
# 97 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/malloc.hpp"
void *data_segment_begin() const 
# 98
{int volatile ___ = 1;
# 100
::exit(___);}
#if 0
# 98
{ 
# 99
return s_data_segment_begin; 
# 100
} 
#endif
# 104 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/malloc.hpp"
private: size_t data_segment_size() 
# 105
{int volatile ___ = 1;
# 107
::exit(___);}
#if 0
# 105
{ 
# 106
return (reinterpret_cast< char *>(m_program_break)) - (reinterpret_cast< char *>(s_data_segment_begin)); 
# 107
} 
#endif
# 110 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/malloc.hpp"
void *m_program_break; 
# 113
size_t m_max_data_segment_size; 
# 114
}; 
# 118
class singleton_unsafe_on_chip_allocator { 
# 121
public: singleton_unsafe_on_chip_allocator(size_t max_data_segment_size) : m_os(max_data_segment_size) 
# 123
{int *volatile ___ = 0;(void)max_data_segment_size;::free(___);}
#if 0
# 123
{ } 
#endif
# 125 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/malloc.hpp"
void *allocate(size_t size) 
# 126
{int volatile ___ = 1;(void)size;
# 154
::exit(___);}
#if 0
# 126
{ 
# 127
size_t aligned_size = align8(size); 
# 129
block *prev = find_first_free_insertion_point(this->heap_begin(), this->heap_end(), aligned_size); 
# 131
block *b; 
# 133
if ((prev != this->heap_end()) && ((b = prev->next()) != this->heap_end())) 
# 134
{ 
# 136
if ((b->size() - aligned_size) >= sizeof(block)) 
# 137
{ 
# 138
this->split_block(b, aligned_size); 
# 139
}  
# 141
b->set_is_free(false); 
# 142
} else 
# 144
{ 
# 146
b = this->extend_heap(prev, aligned_size); 
# 147
if (b == this->heap_end()) 
# 148
{ 
# 149
return 0; 
# 150
}  
# 151
}  
# 153
return b->data(); 
# 154
} 
#endif
# 157 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/malloc.hpp"
void deallocate(void *ptr) 
# 158
{int volatile ___ = 1;(void)ptr;
# 184
::exit(___);}
#if 0
# 158
{ 
# 159
if (ptr != (0)) 
# 160
{ 
# 161
block *b = get_block(ptr); 
# 164
b->set_is_free(true); 
# 167
if ((b->prev()) && b->prev()->is_free()) 
# 168
{ 
# 169
b = b->prev(); 
# 170
this->fuse_block(b); 
# 171
}  
# 174
if (b->next() != this->heap_end()) 
# 175
{ 
# 176
this->fuse_block(b); 
# 177
} else 
# 179
{ 
# 181
(m_os).brk(b); 
# 182
}  
# 183
}  
# 184
} 
#endif
# 189 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/malloc.hpp"
private: class block : public aligned_type< 16UL> ::type { 
# 192
public: size_t size() const 
# 193
{int volatile ___ = 1;
# 195
::exit(___);}
#if 0
# 193
{ 
# 194
return m_size; 
# 195
} 
#endif
# 197 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/malloc.hpp"
void set_size(size_t sz) 
# 198
{int volatile ___ = 1;(void)sz;
# 200
::exit(___);}
#if 0
# 198
{ 
# 199
(m_size) = sz; 
# 200
} 
#endif
# 202 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/malloc.hpp"
block *prev() const 
# 203
{int volatile ___ = 1;
# 205
::exit(___);}
#if 0
# 203
{ 
# 204
return m_prev; 
# 205
} 
#endif
# 207 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/malloc.hpp"
void set_prev(block *p) 
# 208
{int volatile ___ = 1;(void)p;
# 210
::exit(___);}
#if 0
# 208
{ 
# 209
(m_prev) = p; 
# 210
} 
#endif
# 213 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/malloc.hpp"
void *byte_at(size_t index) const 
# 214
{int volatile ___ = 1;(void)index;
# 216
::exit(___);}
#if 0
# 214
{ 
# 215
return (reinterpret_cast< char *>(this->data())) + index; 
# 216
} 
#endif
# 218 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/malloc.hpp"
block *next() const 
# 219
{int volatile ___ = 1;
# 221
::exit(___);}
#if 0
# 219
{ 
# 220
return reinterpret_cast< block *>(this->byte_at(this->size())); 
# 221
} 
#endif
# 223 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/malloc.hpp"
bool is_free() const 
# 224
{int volatile ___ = 1;
# 226
::exit(___);}
#if 0
# 224
{ 
# 225
return m_is_free; 
# 226
} 
#endif
# 228 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/malloc.hpp"
void set_is_free(bool f) 
# 229
{int volatile ___ = 1;(void)f;
# 231
::exit(___);}
#if 0
# 229
{ 
# 230
(m_is_free) = f; 
# 231
} 
#endif
# 233 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/malloc.hpp"
void *data() const 
# 234
{int volatile ___ = 1;
# 236
::exit(___);}
#if 0
# 234
{ 
# 235
return (reinterpret_cast< char *>(const_cast< block *>(this))) + sizeof(block); 
# 236
} 
#endif
# 242 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/malloc.hpp"
private: bool m_is_free:1; 
# 243
size_t m_size:((8) * sizeof(size_t)) - (1); 
# 244
block *m_prev; 
# 245
}; 
# 248
os m_os; 
# 250
block *heap_begin() const 
# 251
{int volatile ___ = 1;
# 253
::exit(___);}
#if 0
# 251
{ 
# 252
return reinterpret_cast< block *>((m_os).data_segment_begin()); 
# 253
} 
#endif
# 256 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/malloc.hpp"
block *heap_end() const 
# 257
{int volatile ___ = 1;
# 259
::exit(___);}
#if 0
# 257
{ 
# 258
return reinterpret_cast< block *>((m_os).program_break()); 
# 259
} 
#endif
# 262 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/malloc.hpp"
void split_block(block *b, size_t size) 
# 263
{int volatile ___ = 1;(void)b;(void)size;
# 283
::exit(___);}
#if 0
# 263
{ 
# 264
block *new_block; 
# 267
new_block = (reinterpret_cast< block *>(b->byte_at(size))); 
# 270
new_block->set_size((b->size() - size) - sizeof(block)); 
# 272
new_block->set_prev(b); 
# 273
new_block->set_is_free(true); 
# 276
b->set_size(size); 
# 279
if (new_block->next() != this->heap_end()) 
# 280
{ 
# 281
new_block->next()->set_prev(new_block); 
# 282
}  
# 283
} 
#endif
# 286 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/malloc.hpp"
bool fuse_block(block *b) 
# 287
{int volatile ___ = 1;(void)b;
# 302
::exit(___);}
#if 0
# 287
{ 
# 288
if ((b->next() != this->heap_end()) && b->next()->is_free()) 
# 289
{ 
# 291
b->set_size((sizeof(block) + b->next()->size()) + b->size()); 
# 293
if (b->next() != this->heap_end()) 
# 294
{ 
# 295
b->next()->set_prev(b); 
# 296
}  
# 298
return true; 
# 299
}  
# 301
return false; 
# 302
} 
#endif
# 305 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/malloc.hpp"
static block *get_block(void *data) 
# 306
{int volatile ___ = 1;(void)data;
# 310
::exit(___);}
#if 0
# 306
{ 
# 308
void *ptr = (reinterpret_cast< char *>(data)) - sizeof(block); 
# 309
return reinterpret_cast< block *>(ptr); 
# 310
} 
#endif
# 313 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/malloc.hpp"
static block *find_first_free_insertion_point(block *first, block *last, size_t size) 
# 314
{int volatile ___ = 1;(void)first;(void)last;(void)size;
# 324
::exit(___);}
#if 0
# 314
{ 
# 315
block *prev = last; 
# 317
while ((first != last) && (!(first->is_free() && (first->size() >= size)))) 
# 318
{ 
# 319
prev = first; 
# 320
first = first->next(); 
# 321
}  
# 323
return prev; 
# 324
} 
#endif
# 327 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/malloc.hpp"
block *extend_heap(block *prev, size_t size) 
# 328
{int volatile ___ = 1;(void)prev;(void)size;
# 344
::exit(___);}
#if 0
# 328
{ 
# 330
block *new_block = this->heap_end(); 
# 333
if ((m_os).sbrk(sizeof(block) + size) == (reinterpret_cast< void *>(-1))) 
# 334
{ 
# 336
return new_block; 
# 337
}  
# 339
on_chip_cast(new_block)->set_size(size); 
# 340
on_chip_cast(new_block)->set_prev(prev); 
# 341
on_chip_cast(new_block)->set_is_free(false); 
# 343
return new_block; 
# 344
} 
#endif
# 347 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/malloc.hpp"
static size_t align8(size_t size) 
# 348
{int volatile ___ = 1;(void)size;
# 350
::exit(___);}
#if 0
# 348
{ 
# 349
return (((size - (1)) >> 3) << 3) + (8); 
# 350
} 
#endif
# 351 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/malloc.hpp"
}; 
# 354
class singleton_on_chip_allocator { 
# 359
public: singleton_on_chip_allocator(size_t max_data_segment_size) : m_mutex(), m_alloc(max_data_segment_size) 
# 362
{ } 
# 366
void *unsafe_allocate(size_t size) 
# 367
{int volatile ___ = 1;(void)size;
# 369
::exit(___);}
#if 0
# 367
{ 
# 368
return (m_alloc).allocate(size); 
# 369
} 
#endif
# 373 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/malloc.hpp"
void *allocate(size_t size) 
# 374
{int volatile ___ = 1;(void)size;
# 384
::exit(___);}
#if 0
# 374
{ 
# 375
void *result; 
# 377
(m_mutex).lock(); 
# 378
{ 
# 379
result = this->unsafe_allocate(size); 
# 380
} 
# 381
(m_mutex).unlock(); 
# 383
return result; 
# 384
} 
#endif
# 388 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/malloc.hpp"
void unsafe_deallocate(void *ptr) 
# 389
{int volatile ___ = 1;(void)ptr;
# 391
::exit(___);}
#if 0
# 389
{ 
# 390
(m_alloc).deallocate(ptr); 
# 391
} 
#endif
# 395 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/malloc.hpp"
void deallocate(void *ptr) 
# 396
{int volatile ___ = 1;(void)ptr;
# 402
::exit(___);}
#if 0
# 396
{ 
# 397
(m_mutex).lock(); 
# 398
{ 
# 399
this->unsafe_deallocate(ptr); 
# 400
} 
# 401
(m_mutex).unlock(); 
# 402
} 
#endif
# 406 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/malloc.hpp"
private: class mutex { 
# 410
public: mutex() : m_in_use((0)) 
# 412
{int *volatile ___ = 0;::free(___);}
#if 0
# 412
{ } 
#endif
# 416 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/malloc.hpp"
bool try_lock() 
# 417
{int volatile ___ = 1;
# 423
::exit(___);}
#if 0
# 417
{ 
# 421
return false; 
# 423
} 
#endif
# 427 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/malloc.hpp"
void lock() 
# 428
{int volatile ___ = 1;
# 434
::exit(___);}
#if 0
# 428
{ 
# 430
while (this->try_lock()) 
# 431
{ 
# 432
; 
# 433
}  
# 434
} 
#endif
# 438 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/malloc.hpp"
void unlock() 
# 439
{int volatile ___ = 1;
# 441
::exit(___);}
#if 0
# 439
{ 
# 440
(m_in_use) = (0); 
# 441
} 
#endif
# 445 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/malloc.hpp"
private: unsigned m_in_use; 
# 446
}; 
# 449
mutex m_mutex; 
# 450
singleton_unsafe_on_chip_allocator m_alloc; 
# 451
}; 
# 456
namespace _GLOBAL__N__17_gpu_setup_cpp1_ii_524b47c1 { }; using namespace ::thrust::system::cuda::detail::bulk_::detail::_GLOBAL__N__17_gpu_setup_cpp1_ii_524b47c1; namespace _GLOBAL__N__17_gpu_setup_cpp1_ii_524b47c1 { 
# 458
__attribute__((unused)) static uninitialized< singleton_on_chip_allocator>  s_on_chip_allocator; 
# 460
}
# 463
__attribute__((unused)) inline void init_on_chip_malloc(size_t max_data_segment_size) 
# 464
{int volatile ___ = 1;(void)max_data_segment_size;
# 466
::exit(___);}
#if 0
# 464
{ 
# 465
s_on_chip_allocator.construct(max_data_segment_size); 
# 466
} 
#endif
# 469 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/malloc.hpp"
__attribute__((unused)) inline void *on_chip_malloc(size_t size) 
# 470
{int volatile ___ = 1;(void)size;
# 473
::exit(___);}
#if 0
# 470
{ 
# 471
void *result = s_on_chip_allocator.get().allocate(size); 
# 472
return on_chip_cast(result); 
# 473
} 
#endif
# 476 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/malloc.hpp"
__attribute__((unused)) inline void on_chip_free(void *ptr) 
# 477
{int volatile ___ = 1;(void)ptr;
# 479
::exit(___);}
#if 0
# 477
{ 
# 478
s_on_chip_allocator.get().deallocate(ptr); 
# 479
} 
#endif
# 482 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/malloc.hpp"
__attribute__((unused)) inline void *unsafe_on_chip_malloc(size_t size) 
# 483
{int volatile ___ = 1;(void)size;
# 486
::exit(___);}
#if 0
# 483
{ 
# 484
void *result = s_on_chip_allocator.get().unsafe_allocate(size); 
# 485
return on_chip_cast(result); 
# 486
} 
#endif
# 489 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/malloc.hpp"
__attribute__((unused)) inline void unsafe_on_chip_free(void *ptr) 
# 490
{int volatile ___ = 1;(void)ptr;
# 492
::exit(___);}
#if 0
# 490
{ 
# 491
s_on_chip_allocator.get().unsafe_deallocate(ptr); 
# 492
} 
#endif
# 495 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/malloc.hpp"
}
# 498
__attribute__((unused)) inline void *shmalloc(size_t num_bytes) 
# 499
{int volatile ___ = 1;(void)num_bytes;
# 511
::exit(___);}
#if 0
# 499
{ 
# 501
void *result = detail::on_chip_malloc(num_bytes); 
# 510
return result; 
# 511
} 
#endif
# 514 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/malloc.hpp"
__attribute__((unused)) inline void *unsafe_shmalloc(size_t num_bytes) 
# 515
{int volatile ___ = 1;(void)num_bytes;
# 527
::exit(___);}
#if 0
# 515
{ 
# 517
void *result = detail::unsafe_on_chip_malloc(num_bytes); 
# 526
return result; 
# 527
} 
#endif
# 530 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/malloc.hpp"
__attribute__((unused)) inline void shfree(void *ptr) 
# 531
{int volatile ___ = 1;(void)ptr;
# 544
::exit(___);}
#if 0
# 531
{ 
# 542
bulk_::detail::on_chip_free(bulk_::on_chip_cast(ptr)); 
# 544
} 
#endif
# 547 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/malloc.hpp"
__attribute__((unused)) inline void unsafe_shfree(void *ptr) 
# 548
{int volatile ___ = 1;(void)ptr;
# 561
::exit(___);}
#if 0
# 548
{ 
# 559
bulk_::detail::unsafe_on_chip_free(bulk_::on_chip_cast(ptr)); 
# 561
} 
#endif
# 564 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/malloc.hpp"
template< class ConcurrentGroup> __attribute__((unused)) inline void *
# 566
malloc(ConcurrentGroup &g, size_t num_bytes) 
# 567
{int volatile ___ = 1;(void)g;(void)num_bytes;
# 582
::exit(___);}
#if 0
# 567
{ 
# 568
__attribute__((unused)) static void *s_result; 
# 572
(g.wait()); 
# 574
if (((g.this_exec).index()) == 0) 
# 575
{ 
# 576
s_result = bulk_::unsafe_shmalloc(num_bytes); 
# 577
}  
# 579
(g.wait()); 
# 581
return s_result; 
# 582
} 
#endif
# 585 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/malloc.hpp"
template< class ConcurrentGroup> __attribute__((unused)) inline void 
# 587
free(ConcurrentGroup &g, void *ptr) 
# 588
{int volatile ___ = 1;(void)g;(void)ptr;
# 595
::exit(___);}
#if 0
# 588
{ 
# 589
if (((g.this_exec).index()) == 0) 
# 590
{ 
# 591
bulk_::unsafe_shfree(ptr); 
# 592
}  
# 594
(g.wait()); 
# 595
} 
#endif
# 598 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/malloc.hpp"
}
# 599
}}}}
# 22 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/detail/tuple_meta_transform.hpp"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 23
namespace bulk_ { 
# 25
namespace detail { 
# 29
template< class Tuple, 
# 30
template< class >  class UnaryMetaFunction, unsigned 
# 31
sz = tuple_size< Tuple> ::value> struct tuple_meta_transform; 
# 34
template< class Tuple, 
# 35
template< class >  class UnaryMetaFunction> 
# 36
struct tuple_meta_transform< Tuple, UnaryMetaFunction, 0>  { 
# 38
typedef tuple< null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type>  type; 
# 39
}; 
# 41
template< class Tuple, 
# 42
template< class >  class UnaryMetaFunction> 
# 43
struct tuple_meta_transform< Tuple, UnaryMetaFunction, 1>  { 
# 47
typedef tuple< typename UnaryMetaFunction< typename tuple_element< 0, Tuple> ::type> ::type, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type>  type; 
# 48
}; 
# 50
template< class Tuple, 
# 51
template< class >  class UnaryMetaFunction> 
# 52
struct tuple_meta_transform< Tuple, UnaryMetaFunction, 2>  { 
# 57
typedef tuple< typename UnaryMetaFunction< typename tuple_element< 0, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 1, Tuple> ::type> ::type, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type>  type; 
# 58
}; 
# 60
template< class Tuple, 
# 61
template< class >  class UnaryMetaFunction> 
# 62
struct tuple_meta_transform< Tuple, UnaryMetaFunction, 3>  { 
# 68
typedef tuple< typename UnaryMetaFunction< typename tuple_element< 0, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 1, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 2, Tuple> ::type> ::type, null_type, null_type, null_type, null_type, null_type, null_type, null_type>  type; 
# 69
}; 
# 71
template< class Tuple, 
# 72
template< class >  class UnaryMetaFunction> 
# 73
struct tuple_meta_transform< Tuple, UnaryMetaFunction, 4>  { 
# 80
typedef tuple< typename UnaryMetaFunction< typename tuple_element< 0, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 1, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 2, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 3, Tuple> ::type> ::type, null_type, null_type, null_type, null_type, null_type, null_type>  type; 
# 81
}; 
# 83
template< class Tuple, 
# 84
template< class >  class UnaryMetaFunction> 
# 85
struct tuple_meta_transform< Tuple, UnaryMetaFunction, 5>  { 
# 93
typedef tuple< typename UnaryMetaFunction< typename tuple_element< 0, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 1, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 2, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 3, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 4, Tuple> ::type> ::type, null_type, null_type, null_type, null_type, null_type>  type; 
# 94
}; 
# 96
template< class Tuple, 
# 97
template< class >  class UnaryMetaFunction> 
# 98
struct tuple_meta_transform< Tuple, UnaryMetaFunction, 6>  { 
# 107
typedef tuple< typename UnaryMetaFunction< typename tuple_element< 0, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 1, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 2, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 3, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 4, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 5, Tuple> ::type> ::type, null_type, null_type, null_type, null_type>  type; 
# 108
}; 
# 110
template< class Tuple, 
# 111
template< class >  class UnaryMetaFunction> 
# 112
struct tuple_meta_transform< Tuple, UnaryMetaFunction, 7>  { 
# 122
typedef tuple< typename UnaryMetaFunction< typename tuple_element< 0, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 1, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 2, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 3, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 4, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 5, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 6, Tuple> ::type> ::type, null_type, null_type, null_type>  type; 
# 123
}; 
# 125
template< class Tuple, 
# 126
template< class >  class UnaryMetaFunction> 
# 127
struct tuple_meta_transform< Tuple, UnaryMetaFunction, 8>  { 
# 138
typedef tuple< typename UnaryMetaFunction< typename tuple_element< 0, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 1, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 2, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 3, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 4, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 5, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 6, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 7, Tuple> ::type> ::type, null_type, null_type>  type; 
# 139
}; 
# 141
template< class Tuple, 
# 142
template< class >  class UnaryMetaFunction> 
# 143
struct tuple_meta_transform< Tuple, UnaryMetaFunction, 9>  { 
# 155
typedef tuple< typename UnaryMetaFunction< typename tuple_element< 0, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 1, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 2, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 3, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 4, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 5, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 6, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 7, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 8, Tuple> ::type> ::type, null_type>  type; 
# 156
}; 
# 158
template< class Tuple, 
# 159
template< class >  class UnaryMetaFunction> 
# 160
struct tuple_meta_transform< Tuple, UnaryMetaFunction, 10>  { 
# 173
typedef tuple< typename UnaryMetaFunction< typename tuple_element< 0, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 1, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 2, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 3, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 4, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 5, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 6, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 7, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 8, Tuple> ::type> ::type, typename UnaryMetaFunction< typename tuple_element< 9, Tuple> ::type> ::type>  type; 
# 174
}; 
# 177
}
# 178
}
# 179
}}}}
# 23 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/detail/tuple_transform.hpp"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 24
namespace bulk_ { 
# 26
namespace detail { 
# 29
template< class Tuple, 
# 30
template< class >  class UnaryMetaFunction, class 
# 31
UnaryFunction, unsigned 
# 32
sz = tuple_size< Tuple> ::value> struct tuple_transform_functor; 
# 36
template< class Tuple, 
# 37
template< class >  class UnaryMetaFunction, class 
# 38
UnaryFunction> 
# 39
struct tuple_transform_functor< Tuple, UnaryMetaFunction, UnaryFunction, 0>  { 
# 43
static typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type do_it_on_the_host(const Tuple &t, UnaryFunction f) 
# 44
{ 
# 45
return tuple< null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type> (); 
# 46
} 
# 50
static typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type do_it_on_the_host_or_device(const Tuple &t, UnaryFunction f) 
# 51
{ 
# 52
return tuple< null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type> (); 
# 53
} 
# 54
}; 
# 57
template< class Tuple, 
# 58
template< class >  class UnaryMetaFunction, class 
# 59
UnaryFunction> 
# 60
struct tuple_transform_functor< Tuple, UnaryMetaFunction, UnaryFunction, 1>  { 
# 64
static typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type do_it_on_the_host(const Tuple &t, UnaryFunction f) 
# 65
{ 
# 66
typedef typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type XfrmTuple; 
# 68
return (XfrmTuple)f(thrust::get< 0> (t)); 
# 69
} 
# 73
static typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type do_it_on_the_host_or_device(const Tuple &t, UnaryFunction f) 
# 74
{ 
# 75
typedef typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type XfrmTuple; 
# 77
return (XfrmTuple)f(thrust::get< 0> (t)); 
# 78
} 
# 79
}; 
# 82
template< class Tuple, 
# 83
template< class >  class UnaryMetaFunction, class 
# 84
UnaryFunction> 
# 85
struct tuple_transform_functor< Tuple, UnaryMetaFunction, UnaryFunction, 2>  { 
# 89
static typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type do_it_on_the_host(const Tuple &t, UnaryFunction f) 
# 90
{ 
# 91
typedef typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type XfrmTuple; 
# 93
return XfrmTuple(f(thrust::get< 0> (t)), f(thrust::get< 1> (t))); 
# 95
} 
# 99
static typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type do_it_on_the_host_or_device(const Tuple &t, UnaryFunction f) 
# 100
{ 
# 101
typedef typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type XfrmTuple; 
# 103
return XfrmTuple(f(thrust::get< 0> (t)), f(thrust::get< 1> (t))); 
# 105
} 
# 106
}; 
# 109
template< class Tuple, 
# 110
template< class >  class UnaryMetaFunction, class 
# 111
UnaryFunction> 
# 112
struct tuple_transform_functor< Tuple, UnaryMetaFunction, UnaryFunction, 3>  { 
# 116
static typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type do_it_on_the_host(const Tuple &t, UnaryFunction f) 
# 117
{ 
# 118
typedef typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type XfrmTuple; 
# 120
return XfrmTuple(f(thrust::get< 0> (t)), f(thrust::get< 1> (t)), f(thrust::get< 2> (t))); 
# 123
} 
# 127
static typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type do_it_on_the_host_or_device(const Tuple &t, UnaryFunction f) 
# 128
{ 
# 129
typedef typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type XfrmTuple; 
# 131
return XfrmTuple(f(thrust::get< 0> (t)), f(thrust::get< 1> (t)), f(thrust::get< 2> (t))); 
# 134
} 
# 135
}; 
# 138
template< class Tuple, 
# 139
template< class >  class UnaryMetaFunction, class 
# 140
UnaryFunction> 
# 141
struct tuple_transform_functor< Tuple, UnaryMetaFunction, UnaryFunction, 4>  { 
# 145
static typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type do_it_on_the_host(const Tuple &t, UnaryFunction f) 
# 146
{ 
# 147
typedef typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type XfrmTuple; 
# 149
return XfrmTuple(f(thrust::get< 0> (t)), f(thrust::get< 1> (t)), f(thrust::get< 2> (t)), f(thrust::get< 3> (t))); 
# 153
} 
# 157
static typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type do_it_on_the_host_or_device(const Tuple &t, UnaryFunction f) 
# 158
{ 
# 159
typedef typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type XfrmTuple; 
# 161
return XfrmTuple(f(thrust::get< 0> (t)), f(thrust::get< 1> (t)), f(thrust::get< 2> (t)), f(thrust::get< 3> (t))); 
# 165
} 
# 166
}; 
# 169
template< class Tuple, 
# 170
template< class >  class UnaryMetaFunction, class 
# 171
UnaryFunction> 
# 172
struct tuple_transform_functor< Tuple, UnaryMetaFunction, UnaryFunction, 5>  { 
# 176
static typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type do_it_on_the_host(const Tuple &t, UnaryFunction f) 
# 177
{ 
# 178
typedef typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type XfrmTuple; 
# 180
return XfrmTuple(f(thrust::get< 0> (t)), f(thrust::get< 1> (t)), f(thrust::get< 2> (t)), f(thrust::get< 3> (t)), f(thrust::get< 4> (t))); 
# 185
} 
# 189
static typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type do_it_on_the_host_or_device(const Tuple &t, UnaryFunction f) 
# 190
{ 
# 191
typedef typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type XfrmTuple; 
# 193
return XfrmTuple(f(thrust::get< 0> (t)), f(thrust::get< 1> (t)), f(thrust::get< 2> (t)), f(thrust::get< 3> (t)), f(thrust::get< 4> (t))); 
# 198
} 
# 199
}; 
# 202
template< class Tuple, 
# 203
template< class >  class UnaryMetaFunction, class 
# 204
UnaryFunction> 
# 205
struct tuple_transform_functor< Tuple, UnaryMetaFunction, UnaryFunction, 6>  { 
# 209
static typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type do_it_on_the_host(const Tuple &t, UnaryFunction f) 
# 210
{ 
# 211
typedef typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type XfrmTuple; 
# 213
return XfrmTuple(f(thrust::get< 0> (t)), f(thrust::get< 1> (t)), f(thrust::get< 2> (t)), f(thrust::get< 3> (t)), f(thrust::get< 4> (t)), f(thrust::get< 5> (t))); 
# 219
} 
# 223
static typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type do_it_on_the_host_or_device(const Tuple &t, UnaryFunction f) 
# 224
{ 
# 225
typedef typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type XfrmTuple; 
# 227
return XfrmTuple(f(thrust::get< 0> (t)), f(thrust::get< 1> (t)), f(thrust::get< 2> (t)), f(thrust::get< 3> (t)), f(thrust::get< 4> (t)), f(thrust::get< 5> (t))); 
# 233
} 
# 234
}; 
# 237
template< class Tuple, 
# 238
template< class >  class UnaryMetaFunction, class 
# 239
UnaryFunction> 
# 240
struct tuple_transform_functor< Tuple, UnaryMetaFunction, UnaryFunction, 7>  { 
# 244
static typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type do_it_on_the_host(const Tuple &t, UnaryFunction f) 
# 245
{ 
# 246
typedef typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type XfrmTuple; 
# 248
return XfrmTuple(f(thrust::get< 0> (t)), f(thrust::get< 1> (t)), f(thrust::get< 2> (t)), f(thrust::get< 3> (t)), f(thrust::get< 4> (t)), f(thrust::get< 5> (t)), f(thrust::get< 6> (t))); 
# 255
} 
# 259
static typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type do_it_on_the_host_or_device(const Tuple &t, UnaryFunction f) 
# 260
{ 
# 261
typedef typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type XfrmTuple; 
# 263
return XfrmTuple(f(thrust::get< 0> (t)), f(thrust::get< 1> (t)), f(thrust::get< 2> (t)), f(thrust::get< 3> (t)), f(thrust::get< 4> (t)), f(thrust::get< 5> (t)), f(thrust::get< 6> (t))); 
# 270
} 
# 271
}; 
# 274
template< class Tuple, 
# 275
template< class >  class UnaryMetaFunction, class 
# 276
UnaryFunction> 
# 277
struct tuple_transform_functor< Tuple, UnaryMetaFunction, UnaryFunction, 8>  { 
# 281
static typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type do_it_on_the_host(const Tuple &t, UnaryFunction f) 
# 282
{ 
# 283
typedef typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type XfrmTuple; 
# 285
return XfrmTuple(f(thrust::get< 0> (t)), f(thrust::get< 1> (t)), f(thrust::get< 2> (t)), f(thrust::get< 3> (t)), f(thrust::get< 4> (t)), f(thrust::get< 5> (t)), f(thrust::get< 6> (t)), f(thrust::get< 7> (t))); 
# 293
} 
# 297
static typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type do_it_on_the_host_or_device(const Tuple &t, UnaryFunction f) 
# 298
{ 
# 299
typedef typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type XfrmTuple; 
# 301
return XfrmTuple(f(thrust::get< 0> (t)), f(thrust::get< 1> (t)), f(thrust::get< 2> (t)), f(thrust::get< 3> (t)), f(thrust::get< 4> (t)), f(thrust::get< 5> (t)), f(thrust::get< 6> (t)), f(thrust::get< 7> (t))); 
# 309
} 
# 310
}; 
# 313
template< class Tuple, 
# 314
template< class >  class UnaryMetaFunction, class 
# 315
UnaryFunction> 
# 316
struct tuple_transform_functor< Tuple, UnaryMetaFunction, UnaryFunction, 9>  { 
# 320
static typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type do_it_on_the_host(const Tuple &t, UnaryFunction f) 
# 321
{ 
# 322
typedef typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type XfrmTuple; 
# 324
return XfrmTuple(f(thrust::get< 0> (t)), f(thrust::get< 1> (t)), f(thrust::get< 2> (t)), f(thrust::get< 3> (t)), f(thrust::get< 4> (t)), f(thrust::get< 5> (t)), f(thrust::get< 6> (t)), f(thrust::get< 7> (t)), f(thrust::get< 8> (t))); 
# 333
} 
# 337
static typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type do_it_on_the_host_or_device(const Tuple &t, UnaryFunction f) 
# 338
{ 
# 339
typedef typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type XfrmTuple; 
# 341
return XfrmTuple(f(thrust::get< 0> (t)), f(thrust::get< 1> (t)), f(thrust::get< 2> (t)), f(thrust::get< 3> (t)), f(thrust::get< 4> (t)), f(thrust::get< 5> (t)), f(thrust::get< 6> (t)), f(thrust::get< 7> (t)), f(thrust::get< 8> (t))); 
# 350
} 
# 351
}; 
# 354
template< class Tuple, 
# 355
template< class >  class UnaryMetaFunction, class 
# 356
UnaryFunction> 
# 357
struct tuple_transform_functor< Tuple, UnaryMetaFunction, UnaryFunction, 10>  { 
# 361
static typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type do_it_on_the_host(const Tuple &t, UnaryFunction f) 
# 362
{ 
# 363
typedef typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type XfrmTuple; 
# 365
return XfrmTuple(f(thrust::get< 0> (t)), f(thrust::get< 1> (t)), f(thrust::get< 2> (t)), f(thrust::get< 3> (t)), f(thrust::get< 4> (t)), f(thrust::get< 5> (t)), f(thrust::get< 6> (t)), f(thrust::get< 7> (t)), f(thrust::get< 8> (t)), f(thrust::get< 9> (t))); 
# 375
} 
# 379
static typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type do_it_on_the_host_or_device(const Tuple &t, UnaryFunction f) 
# 380
{ 
# 381
typedef typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type XfrmTuple; 
# 383
return XfrmTuple(f(thrust::get< 0> (t)), f(thrust::get< 1> (t)), f(thrust::get< 2> (t)), f(thrust::get< 3> (t)), f(thrust::get< 4> (t)), f(thrust::get< 5> (t)), f(thrust::get< 6> (t)), f(thrust::get< 7> (t)), f(thrust::get< 8> (t)), f(thrust::get< 9> (t))); 
# 393
} 
# 394
}; 
# 397
template< template< class >  class UnaryMetaFunction, class 
# 398
Tuple, class 
# 399
UnaryFunction> typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type 
# 401
tuple_host_transform(const Tuple &t, UnaryFunction f) 
# 402
{ 
# 403
return tuple_transform_functor< Tuple, UnaryMetaFunction, UnaryFunction> ::do_it_on_the_host(t, f); 
# 404
} 
# 406
template< template< class >  class UnaryMetaFunction, class 
# 407
Tuple, class 
# 408
UnaryFunction> typename tuple_meta_transform< Tuple, UnaryMetaFunction> ::type 
# 411
tuple_host_device_transform(const Tuple &t, UnaryFunction f) 
# 412
{ 
# 413
return tuple_transform_functor< Tuple, UnaryMetaFunction, UnaryFunction> ::do_it_on_the_host_or_device(t, f); 
# 414
} 
# 416
}
# 417
}
# 418
}}}}
# 28 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/detail/cuda_task.hpp"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 29
namespace bulk_ { 
# 31
namespace detail { 
# 35
template< class ExecutionGroup, class Closure> 
# 36
class task_base { 
# 39
public: typedef ExecutionGroup group_type; 
# 40
typedef Closure closure_type; 
# 43
task_base(group_type g, closure_type c) : c(c), g(g) 
# 45
{ } 
# 49
protected: static void substitute_placeholders_and_execute(group_type &g, closure_type &c) 
# 50
{ 
# 52
substituted_arguments_type new_args = (substitute_placeholders)(g, (c.arguments())); 
# 55
closure< typename Closure::function_type, typename tuple_meta_transform< typename Closure::arguments_type, substitutor_result> ::type>  new_c((c.function()), new_args); 
# 58
new_c(); 
# 59
} 
# 61
closure_type c; 
# 62
group_type g; 
# 66
private: 
# 65
template< class T> 
# 66
struct substitutor_result : public thrust::detail::eval_if< is_cursor< T> ::value, cursor_result< T, ExecutionGroup> , thrust::detail::identity_< T> >  { 
# 72
}; 
# 77
typedef typename tuple_meta_transform< typename Closure::arguments_type, substitutor_result> ::type substituted_arguments_type; 
# 79
struct substitutor { 
# 81
group_type &g; 
# 84
substitutor(group_type &g) : g(g) 
# 86
{int *volatile ___ = 0;(void)g;::free(___);}
#if 0
# 86
{ } 
#endif
# 88 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/detail/cuda_task.hpp"
template< unsigned depth> typename cursor_result< cursor< depth> , ExecutionGroup> ::type 
# 91
operator()(cursor< depth>  c) const 
# 92
{int volatile ___ = 1;(void)c;
# 94
::exit(___);}
#if 0
# 92
{ 
# 93
return (c.get(g)); 
# 94
} 
#endif
# 96 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/detail/cuda_task.hpp"
template< class T> T &
# 98
operator()(T &x) const 
# 99
{int volatile ___ = 1;(void)x;
# 101
::exit(___);}
#if 0
# 99
{ 
# 100
return x; 
# 101
} 
#endif
# 102 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/detail/cuda_task.hpp"
}; 
# 105
static substituted_arguments_type substitute_placeholders(group_type &g, typename Closure::arguments_type args) 
# 106
{ 
# 107
return detail::tuple_host_device_transform< substitutor_result> (args, (substitutor)g); 
# 108
} 
# 109
}; 
# 112
template< std::size_t blocksize, std::size_t grainsize> 
# 113
struct cuda_block { 
# 115
typedef concurrent_group< agent< grainsize> , blocksize>  type; 
# 116
}; 
# 119
template< std::size_t gridsize, std::size_t blocksize, std::size_t grainsize> 
# 120
struct cuda_grid { 
# 124
typedef parallel_group< typename cuda_block< blocksize, grainsize> ::type>  type; 
# 125
}; 
# 128
template< class Group, class Closure> class cuda_task; 
# 131
template< class Grid> 
# 132
struct grid_maker { 
# 135
static Grid make(typename Grid::size_type size, typename Grid::agent_type 
# 136
block, typename Grid::size_type 
# 137
index) 
# 138
{ 
# 139
return Grid(block, index); 
# 140
} 
# 141
}; 
# 144
template< class Block> 
# 145
struct grid_maker< parallel_group< Block, dynamic_group_size> >  { 
# 148
static parallel_group< Block, 0UL>  make(typename parallel_group< Block, 0UL> ::size_type size, Block 
# 149
block, typename parallel_group< Block, 0UL> ::size_type 
# 150
index) 
# 151
{ 
# 152
return parallel_group< Block, 0UL> (size, block, index); 
# 153
} 
# 154
}; 
# 157
template< class Block> 
# 158
struct block_maker { 
# 161
static Block make(typename Block::size_type size, typename Block::size_type 
# 162
heap_size, typename Block::agent_type 
# 163
thread, typename Block::size_type 
# 164
index) 
# 165
{ 
# 166
return Block(heap_size, thread, index); 
# 167
} 
# 168
}; 
# 170
template< class Thread> 
# 171
struct block_maker< concurrent_group< Thread, dynamic_group_size> >  { 
# 174
static concurrent_group< Thread, 0UL>  make(typename concurrent_group< Thread, 0UL> ::size_type size, typename concurrent_group< Thread, 0UL> ::size_type 
# 175
heap_size, Thread 
# 176
thread, typename concurrent_group< Thread, 0UL> ::size_type 
# 177
index) 
# 178
{ 
# 179
return concurrent_group< Thread, 0UL> (size, heap_size, thread, index); 
# 180
} 
# 181
}; 
# 184
template< class Grid> Grid 
# 186
make_grid(typename Grid::size_type size, typename Grid::agent_type block, typename Grid::size_type index = invalid_index) 
# 187
{ 
# 188
return grid_maker< Grid> ::make(size, block, index); 
# 189
} 
# 192
template< class Block> Block 
# 194
make_block(typename Block::size_type size, typename Block::size_type heap_size, typename Block::agent_type thread = typename Block::agent_type(), typename Block::size_type index = invalid_index) 
# 195
{ 
# 196
return block_maker< Block> ::make(size, heap_size, thread, index); 
# 197
} 
# 201
template< std::size_t gridsize, std::size_t blocksize, std::size_t grainsize, class Closure> 
# 202
class cuda_task< parallel_group< concurrent_group< agent< grainsize> , blocksize> , gridsize> , Closure>  : public task_base< typename cuda_grid< gridsize, blocksize, grainsize> ::type, Closure>  { 
# 214
typedef ::thrust::system::cuda::detail::bulk_::detail::task_base< typename cuda_grid< gridsize, blocksize, grainsize> ::type, Closure>  super_t; 
# 217
public: typedef typename ::thrust::system::cuda::detail::bulk_::detail::task_base< typename cuda_grid< gridsize, blocksize, grainsize> ::type, Closure> ::group_type grid_type; 
# 218
typedef typename ::thrust::system::cuda::detail::bulk_::detail::task_base< typename cuda_grid< gridsize, blocksize, grainsize> ::type, Closure> ::group_type::agent_type block_type; 
# 219
typedef typename ::thrust::system::cuda::detail::bulk_::detail::task_base< typename cuda_grid< gridsize, blocksize, grainsize> ::type, Closure> ::group_type::agent_type::agent_type thread_type; 
# 220
typedef typename ::thrust::system::cuda::detail::bulk_::detail::task_base< typename cuda_grid< gridsize, blocksize, grainsize> ::type, Closure> ::closure_type closure_type; 
# 221
typedef typename ::thrust::system::cuda::detail::bulk_::detail::task_base< typename cuda_grid< gridsize, blocksize, grainsize> ::type, Closure> ::group_type::size_type size_type; 
# 224
private: size_type block_offset; 
# 229
public: cuda_task(grid_type g, closure_type c, size_type offset) : super_t(g, c), block_offset(offset) 
# 232
{ } 
# 235
void operator()() 
# 236
{int volatile ___ = 1;
# 263
::exit(___);}
#if 0
# 236
{ 
# 263
} 
#endif
# 264 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/detail/cuda_task.hpp"
}; 
# 268
template< std::size_t blocksize, std::size_t grainsize, class Closure> 
# 269
class cuda_task< concurrent_group< agent< grainsize> , blocksize> , Closure>  : public task_base< typename cuda_block< blocksize, grainsize> ::type, Closure>  { 
# 278
typedef ::thrust::system::cuda::detail::bulk_::detail::task_base< typename cuda_block< blocksize, grainsize> ::type, Closure>  super_t; 
# 281
public: typedef typename ::thrust::system::cuda::detail::bulk_::detail::task_base< typename cuda_block< blocksize, grainsize> ::type, Closure> ::group_type block_type; 
# 282
typedef typename ::thrust::system::cuda::detail::bulk_::detail::task_base< typename cuda_block< blocksize, grainsize> ::type, Closure> ::group_type::agent_type thread_type; 
# 283
typedef typename ::thrust::system::cuda::detail::bulk_::detail::task_base< typename cuda_block< blocksize, grainsize> ::type, Closure> ::closure_type closure_type; 
# 284
typedef typename ::thrust::system::cuda::detail::bulk_::detail::task_base< typename cuda_block< blocksize, grainsize> ::type, Closure> ::group_type::size_type size_type; 
# 288
cuda_task(block_type b, closure_type c) : super_t(b, c) 
# 290
{ } 
# 293
void operator()() 
# 294
{int volatile ___ = 1;
# 317
::exit(___);}
#if 0
# 294
{ 
# 317
} 
#endif
# 318 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/detail/cuda_task.hpp"
}; 
# 322
template< std::size_t groupsize, std::size_t grainsize, class Closure> 
# 323
class cuda_task< parallel_group< agent< grainsize> , groupsize> , Closure>  : public task_base< parallel_group< agent< grainsize> , groupsize> , Closure>  { 
# 327
typedef ::thrust::system::cuda::detail::bulk_::detail::task_base< parallel_group< agent< grainsize> , groupsize> , Closure>  super_t; 
# 330
public: typedef typename ::thrust::system::cuda::detail::bulk_::detail::task_base< parallel_group< agent< grainsize> , groupsize> , Closure> ::closure_type closure_type; 
# 331
typedef typename ::thrust::system::cuda::detail::bulk_::detail::task_base< parallel_group< agent< grainsize> , groupsize> , Closure> ::group_type group_type; 
# 334
cuda_task(group_type g, closure_type c) : super_t(g, c) 
# 336
{ } 
# 339
void operator()() 
# 340
{int volatile ___ = 1;
# 361
::exit(___);}
#if 0
# 340
{ 
# 361
} 
#endif
# 362 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/detail/cuda_task.hpp"
}; 
# 365
}
# 366
}
# 367
}}}}
# 27 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/detail/cuda_launcher/parameter_ptr.hpp"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 28
namespace bulk_ { 
# 30
namespace detail { 
# 35
template< class T> 
# 36
class parameter_ptr { 
# 39
public: typedef T element_type; 
# 42
explicit parameter_ptr(element_type *ptr) : m_ptr(ptr) 
# 44
{ } 
# 48
parameter_ptr(const parameter_ptr &other_) 
# 49
{ 
# 50
parameter_ptr &other = const_cast< parameter_ptr &>(other_); 
# 51
thrust::swap(m_ptr, other.m_ptr); 
# 52
} 
# 55
~parameter_ptr() 
# 56
{ 
# 58
if (m_ptr) 
# 59
{ 
# 60
detail::terminate_on_error(cudaFree(m_ptr), "in parameter_ptr dtor"); 
# 61
}  
# 65
} 
# 69
parameter_ptr &operator=(const parameter_ptr &other_) 
# 70
{ 
# 71
parameter_ptr &other = const_cast< parameter_ptr &>(other_); 
# 72
thrust::swap(m_ptr, other.m_ptr); 
# 73
return *this; 
# 74
} 
# 77
T *get() const 
# 78
{ 
# 79
return m_ptr; 
# 80
} 
# 83
private: T *m_ptr; 
# 84
}; 
# 87
template< class T> parameter_ptr< T>  
# 89
make_parameter(const T &x) 
# 90
{ 
# 91
T *raw_ptr = (0); 
# 95
detail::throw_on_error(cudaMalloc(&raw_ptr, sizeof(T)), "make_parameter(): after cudaMalloc"); 
# 102
detail::throw_on_error(cudaMemcpy(raw_ptr, &x, sizeof(T), cudaMemcpyHostToDevice), "make_parameter(): after cudaMemcpy"); 
# 108
return ((parameter_ptr< T> )(raw_ptr)); 
# 109
} 
# 112
}
# 113
}
# 114
}}}}
# 34 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/detail/cuda_launcher/triple_chevron_launcher.hpp"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 35
namespace bulk_ { 
# 37
namespace detail { 
# 57
template< unsigned block_size, class Function, bool by_value = sizeof(Function) <= (4096)> struct triple_chevron_launcher_base; 
# 60
template< unsigned block_size, class Function> static void 
# 63
__wrapper__device_stub_launch_by_value(Function &f) {exit(1);}
#if 0
# 64
{ 
# 65
f(); 
# 66
} 
#endif
# 60 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/detail/cuda_launcher/triple_chevron_launcher.hpp"
template< unsigned block_size, class Function> void 
# 63
launch_by_value(Function f) 
# 64
{__wrapper__device_stub_launch_by_value<block_size,Function>(f);
# 66
return;}
#if 0
# 64
{ 
# 65
f(); 
# 66
} 
#endif
# 69 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/detail/cuda_launcher/triple_chevron_launcher.hpp"
template< unsigned block_size, class Function> 
# 70
struct triple_chevron_launcher_base< block_size, Function, true>  { 
# 72
typedef void (*global_function_pointer_t)(Function); 
# 75
static global_function_pointer_t global_function_pointer() 
# 76
{ 
# 77
return &launch_by_value< block_size, Function> ; 
# 78
} 
# 79
}; 
# 82
template< unsigned block_size, class Function> static void 
# 85
__wrapper__device_stub_launch_by_pointer(const Function *&f) {exit(1);}
#if 0
# 86
{ 
# 88
Function f_reg = *f; 
# 89
f_reg(); 
# 90
} 
#endif
# 82 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/detail/cuda_launcher/triple_chevron_launcher.hpp"
template< unsigned block_size, class Function> void 
# 85
launch_by_pointer(const Function *f) 
# 86
{__wrapper__device_stub_launch_by_pointer<block_size,Function>(f);
# 90
return;}
#if 0
# 86
{ 
# 88
Function f_reg = *f; 
# 89
f_reg(); 
# 90
} 
#endif
# 93 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/detail/cuda_launcher/triple_chevron_launcher.hpp"
template< unsigned block_size, class Function> 
# 94
struct triple_chevron_launcher_base< block_size, Function, false>  { 
# 96
typedef void (*global_function_pointer_t)(const Function *); 
# 99
static global_function_pointer_t global_function_pointer() 
# 100
{ 
# 101
return &launch_by_pointer< block_size, Function> ; 
# 102
} 
# 103
}; 
# 108
template< unsigned block_size_, class Function, bool by_value = sizeof(Function) <= (4096)> 
# 109
class triple_chevron_launcher : protected triple_chevron_launcher_base< block_size_, Function>  { 
# 112
typedef triple_chevron_launcher_base< block_size_, Function>  super_t; 
# 115
public: typedef Function task_type; 
# 118
void launch(unsigned num_blocks, unsigned block_size, ::size_t num_dynamic_smem_bytes, ::cudaStream_t stream, task_type task) 
# 119
{ 
# 120
struct workaround { 
# 123
static void supported_path(unsigned num_blocks, unsigned block_size, ::size_t num_dynamic_smem_bytes, ::cudaStream_t stream, task_type task) 
# 124
{ 
# 127
cudaConfigureCall(((::dim3)(num_blocks)), ((::dim3)(block_size)), num_dynamic_smem_bytes, stream); 
# 128
cudaSetupArgument(task, 0); 
# 129
::thrust::system::cuda::detail::bulk_::detail::throw_on_error(cudaLaunch(super_t::global_function_pointer()), "after cudaLaunch in triple_chevron_launcher::launch()"); 
# 137
} 
# 140
static void unsupported_path(unsigned, unsigned, ::size_t, ::cudaStream_t, task_type) 
# 141
{ 
# 142
bulk_::detail::terminate_with_message("triple_chevron_launcher::launch(): CUDA kernel launch requires CUDART."); 
# 143
} 
# 144
}; 
# 147
(workaround::supported_path)(num_blocks, block_size, num_dynamic_smem_bytes, stream, task); 
# 151
} 
# 152
}; 
# 159
template< unsigned block_size_, class Function> 
# 160
class triple_chevron_launcher< block_size_, Function, false>  : protected triple_chevron_launcher_base< block_size_, Function>  { 
# 163
typedef triple_chevron_launcher_base< block_size_, Function>  super_t; 
# 166
public: typedef Function task_type; 
# 169
void launch(unsigned num_blocks, unsigned block_size, ::size_t num_dynamic_smem_bytes, ::cudaStream_t stream, task_type task) 
# 170
{ 
# 171
struct workaround { 
# 174
static void supported_path(unsigned num_blocks, unsigned block_size, ::size_t num_dynamic_smem_bytes, ::cudaStream_t stream, task_type task) 
# 175
{ 
# 176
parameter_ptr< Function>  parm = ::thrust::system::cuda::detail::bulk_::detail::make_parameter< task_type> (task); 
# 180
cudaConfigureCall(((::dim3)(num_blocks)), ((::dim3)(block_size)), num_dynamic_smem_bytes, stream); 
# 181
cudaSetupArgument(static_cast< const task_type *>((parm.get())), 0); 
# 182
::thrust::system::cuda::detail::bulk_::detail::throw_on_error(cudaLaunch(super_t::global_function_pointer()), "after cudaLaunch in triple_chevron_launcher::launch()"); 
# 191
} 
# 194
static void unsupported_path(unsigned, unsigned, ::size_t, ::cudaStream_t, task_type) 
# 195
{ 
# 196
bulk_::detail::terminate_with_message("triple_chevron_launcher::launch(): CUDA kernel launch requires CUDART."); 
# 197
} 
# 198
}; 
# 201
(workaround::supported_path)(num_blocks, block_size, num_dynamic_smem_bytes, stream, task); 
# 205
} 
# 206
}; 
# 209
}
# 210
}
# 211
}}}}
# 25 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/detail/synchronize.hpp"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 26
namespace bulk_ { 
# 28
namespace detail { 
# 33
inline void synchronize(const char *message = "") 
# 34
{ 
# 36
bulk_::detail::throw_on_error(cudaDeviceSynchronize(), message); 
# 41
} 
# 45
inline void synchronize_if_enabled(const char *message = "") 
# 46
{ 
# 53
(void)message; 
# 55
} 
# 58
}
# 59
}
# 60
}}}}
# 40 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/detail/cuda_launcher/cuda_launcher.hpp"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 41
namespace bulk_ { 
# 43
namespace detail { 
# 49
template< unsigned block_size_, class ExecutionGroup, class Closure> 
# 50
struct cuda_launcher_base : public triple_chevron_launcher< block_size_, cuda_task< ExecutionGroup, Closure> >  { 
# 56
typedef ::thrust::system::cuda::detail::bulk_::detail::triple_chevron_launcher< block_size_, cuda_task< ExecutionGroup, Closure> >  super_t; 
# 57
typedef typename ::thrust::system::cuda::detail::bulk_::detail::triple_chevron_launcher< block_size_, cuda_task< ExecutionGroup, Closure> > ::task_type task_type; 
# 58
typedef typename ExecutionGroup::size_type size_type; 
# 62
cuda_launcher_base() : m_device_properties(bulk_::detail::device_properties()) 
# 64
{ } 
# 68
void launch(size_type num_blocks, size_type block_size, size_type num_dynamic_smem_bytes, ::cudaStream_t stream, task_type task) 
# 69
{ 
# 70
if (num_blocks > 0) 
# 71
{ 
# 72
super_t::launch(num_blocks, block_size, num_dynamic_smem_bytes, stream, task); 
# 74
bulk_::detail::synchronize_if_enabled("bulk_kernel_by_value"); 
# 75
}  
# 76
} 
# 80
static size_type max_active_blocks_per_multiprocessor(const ::thrust::system::cuda::detail::bulk_::detail::device_properties_t &props, const ::thrust::system::cuda::detail::bulk_::detail::function_attributes_t &
# 81
attr, size_type 
# 82
num_threads_per_block, size_type 
# 83
num_smem_bytes_per_block) 
# 84
{ 
# 85
return static_cast< size_type>(::thrust::system::cuda::detail::bulk_::detail::cuda_launch_config_detail::max_active_blocks_per_multiprocessor(props, attr, num_threads_per_block, num_smem_bytes_per_block)); 
# 86
} 
# 93
static pair< typename ExecutionGroup::size_type, typename ExecutionGroup::size_type>  dynamic_smem_occupancy_limit(const ::thrust::system::cuda::detail::bulk_::detail::device_properties_t &props, const ::thrust::system::cuda::detail::bulk_::detail::function_attributes_t &attr, size_type num_threads_per_block, size_type num_smem_bytes_per_block) 
# 94
{ 
# 96
size_type occupancy = (max_active_blocks_per_multiprocessor)(props, attr, num_threads_per_block, num_smem_bytes_per_block); 
# 99
if (occupancy < 1) { return thrust::make_pair(0, 0); }  
# 101
return ::thrust::make_pair(static_cast< size_type>(::thrust::system::cuda::detail::bulk_::detail::proportional_smem_allocation(props, attr, occupancy)), occupancy); 
# 102
} 
# 106
size_type choose_heap_size(const ::thrust::system::cuda::detail::bulk_::detail::device_properties_t &props, size_type group_size, size_type requested_size) 
# 107
{ 
# 108
::thrust::system::cuda::detail::bulk_::detail::function_attributes_t attr = ::thrust::system::cuda::detail::bulk_::detail::function_attributes(super_t::global_function_pointer()); 
# 112
if (((attr.ptxVersion) < 20) || (requested_size == 0)) 
# 113
{ 
# 114
return 0; 
# 115
}  
# 118
size_type result = (0), occupancy = (0); 
# 119
::thrust::tie(result, occupancy) = (dynamic_smem_occupancy_limit)(props, attr, group_size, 0); 
# 124
if ((requested_size != use_default) && (requested_size > result) && (occupancy > 1)) 
# 125
{ 
# 127
requested_size += 48; 
# 130
if (requested_size > result) 
# 131
{ 
# 133
size_type next_level_result = (0), next_level_occupancy = (0); 
# 134
::thrust::tie(next_level_result, next_level_occupancy) = (dynamic_smem_occupancy_limit)(props, attr, group_size, requested_size); 
# 138
if (next_level_occupancy > 0) { result = next_level_result; }  
# 139
}  
# 140
}  
# 142
return result; 
# 143
} 
# 147
size_type choose_group_size(size_type requested_size) 
# 148
{ 
# 149
size_type result = requested_size; 
# 151
if (result == use_default) 
# 152
{ 
# 153
::thrust::system::cuda::detail::bulk_::detail::function_attributes_t attr = ::thrust::system::cuda::detail::bulk_::detail::function_attributes(super_t::global_function_pointer()); 
# 155
return static_cast< size_type>(::thrust::system::cuda::detail::bulk_::detail::block_size_with_maximum_potential_occupancy(attr, device_properties())); 
# 156
}  
# 158
return result; 
# 159
} 
# 163
size_type choose_subscription(size_type block_size) 
# 164
{ 
# 166
return (block_size > 0) ? (device_properties().maxThreadsPerMultiProcessor) / block_size : 0; 
# 167
} 
# 171
size_type choose_num_groups(size_type requested_num_groups, size_type group_size) 
# 172
{ 
# 173
size_type result = requested_num_groups; 
# 175
if (result == use_default) 
# 176
{ 
# 179
size_type subscription = choose_subscription(group_size); 
# 181
result = ::thrust::min< size_type> (subscription * (device_properties().multiProcessorCount), max_physical_grid_size()); 
# 182
}  
# 184
return result; 
# 185
} 
# 189
size_type max_physical_grid_size() 
# 190
{ 
# 192
int actual_limit = (device_properties().maxGridSize)[0]; 
# 195
int ptx_version = ((::thrust::system::cuda::detail::bulk_::detail::function_attributes(super_t::global_function_pointer()).ptxVersion)); 
# 197
int ptx_limit = 0; 
# 200
if (ptx_version < 30) 
# 201
{ 
# 202
ptx_limit = 65535; 
# 203
} else 
# 205
{ 
# 206
ptx_limit = ((1U << 31) - (1)); 
# 207
}  
# 209
return ::thrust::min< size_type> (actual_limit, ptx_limit); 
# 210
} 
# 214
const ::thrust::system::cuda::detail::bulk_::detail::device_properties_t &device_properties() const 
# 215
{ 
# 216
return m_device_properties; 
# 217
} 
# 220
::thrust::system::cuda::detail::bulk_::detail::device_properties_t m_device_properties; 
# 221
}; 
# 224
template< class ExecutionGroup, class Closure> struct cuda_launcher; 
# 227
template< std::size_t gridsize, std::size_t blocksize, std::size_t grainsize, class Closure> 
# 228
struct cuda_launcher< parallel_group< concurrent_group< agent< grainsize> , blocksize> , gridsize> , Closure>  : public cuda_launcher_base< blocksize, typename cuda_grid< gridsize, blocksize, grainsize> ::type, Closure>  { 
# 240
typedef ::thrust::system::cuda::detail::bulk_::detail::cuda_launcher_base< blocksize, typename cuda_grid< gridsize, blocksize, grainsize> ::type, Closure>  super_t; 
# 241
typedef typename ::thrust::system::cuda::detail::bulk_::detail::cuda_launcher_base< blocksize, typename cuda_grid< gridsize, blocksize, grainsize> ::type, Closure> ::size_type size_type; 
# 243
typedef typename cuda_grid< gridsize, blocksize, grainsize> ::type grid_type; 
# 244
typedef typename cuda_grid< gridsize, blocksize, grainsize> ::type::agent_type block_type; 
# 245
typedef typename cuda_grid< gridsize, blocksize, grainsize> ::type::agent_type::agent_type thread_type; 
# 247
typedef typename ::thrust::system::cuda::detail::bulk_::detail::cuda_launcher_base< blocksize, typename cuda_grid< gridsize, blocksize, grainsize> ::type, Closure> ::task_type task_type; 
# 251
void launch(grid_type request, Closure c, ::cudaStream_t stream) 
# 252
{ 
# 253
grid_type g = configure(request); 
# 255
size_type num_blocks = (g.size()); 
# 256
size_type block_size = ((g.this_exec).size()); 
# 258
if ((num_blocks > 0) && (block_size > 0)) 
# 259
{ 
# 260
size_type heap_size = ((g.this_exec).heap_size()); 
# 262
size_type max_physical_grid_size = super_t::max_physical_grid_size(); 
# 267
if (block_size > 0) 
# 268
{ 
# 269
size_type num_remaining_physical_blocks = num_blocks; 
# 270
for (size_type block_offset = (0); block_offset < num_blocks; block_offset += max_physical_grid_size) 
# 273
{ 
# 274
task_type task(g, c, block_offset); 
# 276
size_type num_physical_blocks = ::thrust::min< size_type> (num_remaining_physical_blocks, max_physical_grid_size); 
# 278
super_t::launch(num_physical_blocks, block_size, heap_size, stream, task); 
# 280
num_remaining_physical_blocks -= num_physical_blocks; 
# 281
}  
# 282
}  
# 283
}  
# 284
} 
# 287
grid_type configure(grid_type g) 
# 288
{ 
# 289
size_type block_size = super_t::choose_group_size(((g.this_exec).size())); 
# 290
size_type heap_size = super_t::choose_heap_size(device_properties(), block_size, ((g.this_exec).heap_size())); 
# 291
size_type num_blocks = (g.size()); 
# 293
return make_grid< grid_type> (num_blocks, make_block< block_type> (block_size, heap_size)); 
# 294
} 
# 298
pair< typename ::thrust::system::cuda::detail::bulk_::detail::cuda_launcher_base< blocksize, typename cuda_grid< gridsize, blocksize, grainsize> ::type, Closure> ::size_type, typename ::thrust::system::cuda::detail::bulk_::detail::cuda_launcher_base< blocksize, typename cuda_grid< gridsize, blocksize, grainsize> ::type, Closure> ::size_type>  choose_sizes(size_type requested_num_groups, size_type requested_group_size) 
# 299
{ 
# 302
size_type group_size = (blocksize); 
# 303
if (group_size == 0) 
# 304
{ 
# 305
group_size = super_t::choose_group_size(requested_group_size); 
# 306
}  
# 310
size_type num_groups = (gridsize); 
# 311
if (num_groups == 0) 
# 312
{ 
# 313
num_groups = super_t::choose_num_groups(requested_num_groups, group_size); 
# 314
}  
# 316
return ::thrust::make_pair(num_groups, group_size); 
# 317
} 
# 318
}; 
# 321
template< std::size_t blocksize, std::size_t grainsize, class Closure> 
# 322
struct cuda_launcher< concurrent_group< agent< grainsize> , blocksize> , Closure>  : public cuda_launcher_base< blocksize, concurrent_group< agent< grainsize> , blocksize> , Closure>  { 
# 331
typedef ::thrust::system::cuda::detail::bulk_::detail::cuda_launcher_base< blocksize, concurrent_group< agent< grainsize> , blocksize> , Closure>  super_t; 
# 332
typedef typename ::thrust::system::cuda::detail::bulk_::detail::cuda_launcher_base< blocksize, concurrent_group< agent< grainsize> , blocksize> , Closure> ::size_type size_type; 
# 333
typedef typename ::thrust::system::cuda::detail::bulk_::detail::cuda_launcher_base< blocksize, concurrent_group< agent< grainsize> , blocksize> , Closure> ::task_type task_type; 
# 335
typedef concurrent_group< agent< grainsize> , blocksize>  block_type; 
# 338
void launch(block_type request, Closure c, ::cudaStream_t stream) 
# 339
{ 
# 340
block_type b = configure(request); 
# 342
size_type block_size = (b.size()); 
# 343
size_type heap_size = (b.heap_size()); 
# 345
if (block_size > 0) 
# 346
{ 
# 347
task_type task(b, c); 
# 348
super_t::launch(1, block_size, heap_size, stream, task); 
# 349
}  
# 350
} 
# 353
block_type configure(block_type b) 
# 354
{ 
# 355
size_type block_size = super_t::choose_group_size((b.size())); 
# 356
size_type heap_size = super_t::choose_heap_size(device_properties(), block_size, (b.heap_size())); 
# 357
return make_block< block_type> (block_size, heap_size); 
# 358
} 
# 359
}; 
# 362
template< std::size_t groupsize, std::size_t grainsize, class Closure> 
# 363
struct cuda_launcher< parallel_group< agent< grainsize> , groupsize> , Closure>  : public cuda_launcher_base< 0U, parallel_group< agent< grainsize> , groupsize> , Closure>  { 
# 372
typedef ::thrust::system::cuda::detail::bulk_::detail::cuda_launcher_base< 0U, parallel_group< agent< grainsize> , groupsize> , Closure>  super_t; 
# 373
typedef typename ::thrust::system::cuda::detail::bulk_::detail::cuda_launcher_base< 0U, parallel_group< agent< grainsize> , groupsize> , Closure> ::size_type size_type; 
# 374
typedef typename ::thrust::system::cuda::detail::bulk_::detail::cuda_launcher_base< 0U, parallel_group< agent< grainsize> , groupsize> , Closure> ::task_type task_type; 
# 376
typedef parallel_group< agent< grainsize> , groupsize>  group_type; 
# 379
void launch(group_type g, Closure c, ::cudaStream_t stream) 
# 380
{ 
# 381
size_type num_blocks, block_size; 
# 382
::thrust::tie(num_blocks, block_size) = configure(g); 
# 384
if ((num_blocks > 0) && (block_size > 0)) 
# 385
{ 
# 386
task_type task(g, c); 
# 388
super_t::launch(num_blocks, block_size, 0, stream, task); 
# 389
}  
# 390
} 
# 393
tuple< typename ::thrust::system::cuda::detail::bulk_::detail::cuda_launcher_base< 0U, parallel_group< agent< grainsize> , groupsize> , Closure> ::size_type, typename ::thrust::system::cuda::detail::bulk_::detail::cuda_launcher_base< 0U, parallel_group< agent< grainsize> , groupsize> , Closure> ::size_type, ::thrust::null_type, ::thrust::null_type, ::thrust::null_type, ::thrust::null_type, ::thrust::null_type, ::thrust::null_type, ::thrust::null_type, ::thrust::null_type>  configure(group_type g) 
# 394
{ 
# 395
size_type block_size = ::thrust::min< size_type> ((g.size()), super_t::choose_group_size(use_default)); 
# 398
size_type max_blocks = super_t::choose_num_groups(bulk_::use_default, block_size); 
# 401
size_type num_blocks = (block_size > 0) ? (((g.size()) + block_size) - 1) / block_size : 0; 
# 404
num_blocks = ::thrust::min< size_type> (num_blocks, max_blocks); 
# 406
return ::thrust::make_tuple(num_blocks, block_size); 
# 407
} 
# 408
}; 
# 411
}
# 412
}
# 413
}}}}
# 25 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/detail/choose_sizes.inl"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 26
namespace bulk_ { 
# 28
namespace detail { 
# 32
template< class Closure> pair< int, int>  
# 36
choose_sizes(parallel_group< concurrent_group<> >  g, Closure) 
# 37
{ 
# 41
cuda_launcher< parallel_group< concurrent_group<> > , Closure>  launcher; 
# 43
return (launcher.choose_sizes(g.size(), (g.this_exec).size())); 
# 44
} 
# 47
}
# 50
template< class Function> pair< int, int>  
# 54
choose_sizes(parallel_group< concurrent_group<> >  g, Function f) 
# 55
{ 
# 56
return detail::choose_sizes(g, detail::make_closure(f)); 
# 57
} 
# 60
template< class Function, class Arg1> pair< int, int>  
# 64
choose_sizes(parallel_group< concurrent_group<> >  g, Function f, Arg1 arg1) 
# 65
{ 
# 66
return detail::choose_sizes(g, detail::make_closure(f, arg1)); 
# 67
} 
# 70
template< class Function, class Arg1, class Arg2> pair< int, int>  
# 74
choose_sizes(parallel_group< concurrent_group<> >  g, Function f, Arg1 arg1, Arg2 arg2) 
# 75
{ 
# 76
return detail::choose_sizes(g, detail::make_closure(f, arg1, arg2)); 
# 77
} 
# 80
template< class Function, class Arg1, class Arg2, class Arg3> pair< int, int>  
# 84
choose_sizes(parallel_group< concurrent_group<> >  g, Function f, Arg1 arg1, Arg2 arg2, Arg3 arg3) 
# 85
{ 
# 86
return detail::choose_sizes(g, detail::make_closure(f, arg1, arg2, arg3)); 
# 87
} 
# 90
template< class Function, class Arg1, class Arg2, class Arg3, class Arg4> pair< int, int>  
# 94
choose_sizes(parallel_group< concurrent_group<> >  g, Function f, Arg1 arg1, Arg2 arg2, Arg3 arg3, Arg4 arg4) 
# 95
{ 
# 96
return detail::choose_sizes(g, detail::make_closure(f, arg1, arg2, arg3, arg4)); 
# 97
} 
# 100
template< class Function, class Arg1, class Arg2, class Arg3, class Arg4, class Arg5> pair< int, int>  
# 104
choose_sizes(parallel_group< concurrent_group<> >  g, Function f, Arg1 arg1, Arg2 arg2, Arg3 arg3, Arg4 arg4, Arg5 arg5) 
# 105
{ 
# 106
return detail::choose_sizes(g, detail::make_closure(f, arg1, arg2, arg3, arg4, arg5)); 
# 107
} 
# 110
template< class Function, class Arg1, class Arg2, class Arg3, class Arg4, class Arg5, class Arg6> pair< int, int>  
# 114
choose_sizes(parallel_group< concurrent_group<> >  g, Function f, Arg1 arg1, Arg2 arg2, Arg3 arg3, Arg4 arg4, Arg5 arg5, Arg6 arg6) 
# 115
{ 
# 116
return detail::choose_sizes(g, detail::make_closure(f, arg1, arg2, arg3, arg4, arg5, arg6)); 
# 117
} 
# 120
}
# 121
}}}}
# 23 "/usr/local/cuda-8.0/include/thrust/detail/cstdint.h"
namespace thrust { 
# 25
namespace detail { 
# 50
typedef ::int8_t int8_t; 
# 51
typedef ::int16_t int16_t; 
# 52
typedef ::int32_t int32_t; 
# 53
typedef ::int64_t int64_t; 
# 54
typedef ::uint8_t uint8_t; 
# 55
typedef ::uint16_t uint16_t; 
# 56
typedef ::uint32_t uint32_t; 
# 57
typedef ::uint64_t uint64_t; 
# 63
template< int word_size = 8> struct divine_intptr_t; 
# 64
template< int word_size = 8> struct divine_uintptr_t; 
# 67
template<> struct divine_intptr_t< 4>  { typedef int32_t type; }; 
# 68
template<> struct divine_uintptr_t< 4>  { typedef uint32_t type; }; 
# 71
template<> struct divine_intptr_t<>  { typedef int64_t type; }; 
# 72
template<> struct divine_uintptr_t<>  { typedef uint64_t type; }; 
# 74
typedef divine_intptr_t<> ::type intptr_t; 
# 75
typedef divine_uintptr_t<> ::type uintptr_t; 
# 77
}
# 78
}
# 26 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/async.hpp"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 27
namespace bulk_ { 
# 31
template< class ExecutionGroup, class Function> future< void>  async(ExecutionGroup g, Function f); 
# 36
template< class ExecutionGroup, class Function, class Arg1> future< void>  async(ExecutionGroup g, Function f, Arg1 arg1); 
# 41
template< class ExecutionGroup, class Function, class Arg1, class Arg2> future< void>  async(ExecutionGroup g, Function f, Arg1 arg1, Arg2 arg2); 
# 46
template< class ExecutionGroup, class Function, class Arg1, class Arg2, class Arg3> future< void>  async(ExecutionGroup g, Function f, Arg1 arg1, Arg2 arg2, Arg3 arg3); 
# 51
template< class ExecutionGroup, class Function, class Arg1, class Arg2, class Arg3, class Arg4> future< void>  async(ExecutionGroup g, Function f, Arg1 arg1, Arg2 arg2, Arg3 arg3, Arg4 arg4); 
# 56
template< class ExecutionGroup, class Function, class Arg1, class Arg2, class Arg3, class Arg4, class Arg5> future< void>  async(ExecutionGroup g, Function f, Arg1 arg1, Arg2 arg2, Arg3 arg3, Arg4 arg4, Arg5 arg5); 
# 61
template< class ExecutionGroup, class Function, class Arg1, class Arg2, class Arg3, class Arg4, class Arg5, class Arg6> future< void>  async(ExecutionGroup g, Function f, Arg1 arg1, Arg2 arg2, Arg3 arg3, Arg4 arg4, Arg5 arg5, Arg6 arg6); 
# 66
template< class ExecutionGroup, class Function, class Arg1, class Arg2, class Arg3, class Arg4, class Arg5, class Arg6, class Arg7> future< void>  async(ExecutionGroup g, Function f, Arg1 arg1, Arg2 arg2, Arg3 arg3, Arg4 arg4, Arg5 arg5, Arg6 arg6, Arg7 arg7); 
# 71
template< class ExecutionGroup, class Function, class Arg1, class Arg2, class Arg3, class Arg4, class Arg5, class Arg6, class Arg7, class Arg8> future< void>  async(ExecutionGroup g, Function f, Arg1 arg1, Arg2 arg2, Arg3 arg3, Arg4 arg4, Arg5 arg5, Arg6 arg6, Arg7 arg7, Arg8 arg8); 
# 76
template< class ExecutionGroup, class Function, class Arg1, class Arg2, class Arg3, class Arg4, class Arg5, class Arg6, class Arg7, class Arg8, class Arg9> future< void>  async(ExecutionGroup g, Function f, Arg1 arg1, Arg2 arg2, Arg3 arg3, Arg4 arg4, Arg5 arg5, Arg6 arg6, Arg7 arg7, Arg8 arg8, Arg9 arg9); 
# 81
template< class ExecutionGroup, class Function, class Arg1, class Arg2, class Arg3, class Arg4, class Arg5, class Arg6, class Arg7, class Arg8, class Arg9, class Arg10> future< void>  async(ExecutionGroup g, Function f, Arg1 arg1, Arg2 arg2, Arg3 arg3, Arg4 arg4, Arg5 arg5, Arg6 arg6, Arg7 arg7, Arg8 arg8, Arg9 arg9, Arg10 arg10); 
# 86
}
# 87
}}}}
# 25 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/detail/async.inl"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 26
namespace bulk_ { 
# 28
namespace detail { 
# 32
template< class ExecutionGroup, class Closure> future< void>  
# 34
async_in_stream(ExecutionGroup g, Closure c, cudaStream_t s, cudaEvent_t before_event) 
# 35
{ 
# 37
if (before_event != (0)) 
# 38
{ 
# 39
bulk_::detail::throw_on_error(cudaStreamWaitEvent(s, before_event, 0), "cudaStreamWaitEvent in async_in_stream"); 
# 40
}  
# 45
cuda_launcher< ExecutionGroup, Closure>  launcher; 
# 46
(launcher.launch(g, c, s)); 
# 48
return future_core_access::create(s, false); 
# 49
} 
# 52
template< class ExecutionGroup, class Closure> future< void>  
# 54
async(ExecutionGroup g, Closure c, cudaEvent_t before_event) 
# 55
{ 
# 56
cudaStream_t s; 
# 61
bulk_::detail::throw_on_error(cudaStreamCreate(&s), "cudaStreamCreate in bulk::detail::async"); 
# 68
if (before_event != (0)) 
# 69
{ 
# 70
bulk_::detail::throw_on_error(cudaStreamWaitEvent(s, before_event, 0), "cudaStreamWaitEvent in bulk::detail::async"); 
# 71
}  
# 76
cuda_launcher< ExecutionGroup, Closure>  launcher; 
# 77
(launcher.launch(g, c, s)); 
# 80
return future_core_access::create(s, true); 
# 81
} 
# 84
template< class ExecutionGroup, class Closure> future< void>  
# 86
async(ExecutionGroup g, Closure c) 
# 87
{ 
# 88
return detail::async_in_stream(g, c, 0, 0); 
# 89
} 
# 92
template< class ExecutionGroup, class Closure> future< void>  
# 94
async(async_launch< ExecutionGroup>  launch, Closure c) 
# 95
{ 
# 96
return ((launch.is_stream_valid())) ? detail::async_in_stream((launch.exec()), c, (launch.stream()), (launch.before_event())) : detail::async((launch.exec()), c, (launch.before_event())); 
# 99
} 
# 102
}
# 105
template< class ExecutionGroup, class Function> future< void>  
# 107
async(ExecutionGroup g, Function f) 
# 108
{ 
# 109
return detail::async(g, detail::make_closure(f)); 
# 110
} 
# 113
template< class ExecutionGroup, class Function, class Arg1> future< void>  
# 115
async(ExecutionGroup g, Function f, Arg1 arg1) 
# 116
{ 
# 117
return detail::async(g, detail::make_closure(f, arg1)); 
# 118
} 
# 121
template< class ExecutionGroup, class Function, class Arg1, class Arg2> future< void>  
# 123
async(ExecutionGroup g, Function f, Arg1 arg1, Arg2 arg2) 
# 124
{ 
# 125
return detail::async(g, detail::make_closure(f, arg1, arg2)); 
# 126
} 
# 129
template< class ExecutionGroup, class Function, class Arg1, class Arg2, class Arg3> future< void>  
# 131
async(ExecutionGroup g, Function f, Arg1 arg1, Arg2 arg2, Arg3 arg3) 
# 132
{ 
# 133
return detail::async(g, detail::make_closure(f, arg1, arg2, arg3)); 
# 134
} 
# 137
template< class ExecutionGroup, class Function, class Arg1, class Arg2, class Arg3, class Arg4> future< void>  
# 139
async(ExecutionGroup g, Function f, Arg1 arg1, Arg2 arg2, Arg3 arg3, Arg4 arg4) 
# 140
{ 
# 141
return detail::async(g, detail::make_closure(f, arg1, arg2, arg3, arg4)); 
# 142
} 
# 145
template< class ExecutionGroup, class Function, class Arg1, class Arg2, class Arg3, class Arg4, class Arg5> future< void>  
# 147
async(ExecutionGroup g, Function f, Arg1 arg1, Arg2 arg2, Arg3 arg3, Arg4 arg4, Arg5 arg5) 
# 148
{ 
# 149
return detail::async(g, detail::make_closure(f, arg1, arg2, arg3, arg4, arg5)); 
# 150
} 
# 153
template< class ExecutionGroup, class Function, class Arg1, class Arg2, class Arg3, class Arg4, class Arg5, class Arg6> future< void>  
# 155
async(ExecutionGroup g, Function f, Arg1 arg1, Arg2 arg2, Arg3 arg3, Arg4 arg4, Arg5 arg5, Arg6 arg6) 
# 156
{ 
# 157
return detail::async(g, detail::make_closure(f, arg1, arg2, arg3, arg4, arg5, arg6)); 
# 158
} 
# 161
template< class ExecutionGroup, class Function, class Arg1, class Arg2, class Arg3, class Arg4, class Arg5, class Arg6, class Arg7> future< void>  
# 163
async(ExecutionGroup g, Function f, Arg1 arg1, Arg2 arg2, Arg3 arg3, Arg4 arg4, Arg5 arg5, Arg6 arg6, Arg7 arg7) 
# 164
{ 
# 165
return detail::async(g, detail::make_closure(f, arg1, arg2, arg3, arg4, arg5, arg6, arg7)); 
# 166
} 
# 169
template< class ExecutionGroup, class Function, class Arg1, class Arg2, class Arg3, class Arg4, class Arg5, class Arg6, class Arg7, class Arg8> future< void>  
# 171
async(ExecutionGroup g, Function f, Arg1 arg1, Arg2 arg2, Arg3 arg3, Arg4 arg4, Arg5 arg5, Arg6 arg6, Arg7 arg7, Arg8 arg8) 
# 172
{ 
# 173
return detail::async(g, detail::make_closure(f, arg1, arg2, arg3, arg4, arg5, arg6, arg7, arg8)); 
# 174
} 
# 177
template< class ExecutionGroup, class Function, class Arg1, class Arg2, class Arg3, class Arg4, class Arg5, class Arg6, class Arg7, class Arg8, class Arg9> future< void>  
# 179
async(ExecutionGroup g, Function f, Arg1 arg1, Arg2 arg2, Arg3 arg3, Arg4 arg4, Arg5 arg5, Arg6 arg6, Arg7 arg7, Arg8 arg8, Arg9 arg9) 
# 180
{ 
# 181
return detail::async(g, detail::make_closure(f, arg1, arg2, arg3, arg4, arg5, arg6, arg7, arg8, arg9)); 
# 182
} 
# 185
template< class ExecutionGroup, class Function, class Arg1, class Arg2, class Arg3, class Arg4, class Arg5, class Arg6, class Arg7, class Arg8, class Arg9, class Arg10> future< void>  
# 187
async(ExecutionGroup g, Function f, Arg1 arg1, Arg2 arg2, Arg3 arg3, Arg4 arg4, Arg5 arg5, Arg6 arg6, Arg7 arg7, Arg8 arg8, Arg9 arg9, Arg10 arg10) 
# 188
{ 
# 189
return detail::async(g, detail::make_closure(f, arg1, arg2, arg3, arg4, arg5, arg6, arg7, arg8, arg9, arg10)); 
# 190
} 
# 193
}
# 194
}}}}
# 22 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/detail/is_contiguous_iterator.hpp"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 23
namespace bulk_ { 
# 25
namespace detail { 
# 29
template< class T> 
# 30
struct is_contiguous_iterator : public thrust::detail::is_trivial_iterator< T>  { 
# 32
}; 
# 35
}
# 36
}
# 37
}}}}
# 26 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/copy.hpp"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 27
namespace bulk_ { 
# 31
template< std::size_t bound, std::size_t 
# 32
grainsize, class 
# 33
RandomAccessIterator1, class 
# 34
Size, class 
# 35
RandomAccessIterator2> 
# 36
__attribute((always_inline)) __attribute__((unused)) inline RandomAccessIterator2 
# 37
copy_n(const bounded< bound, agent< grainsize> >  &b, RandomAccessIterator1 
# 38
first, Size 
# 39
n, RandomAccessIterator2 
# 40
result) 
# 41
{int volatile ___ = 1;(void)b;(void)first;(void)n;(void)result;
# 64
::exit(___);}
#if 0
# 41
{ 
# 42
typedef typename bounded< bound, agent< grainsize> > ::size_type size_type; 
# 44
if (bound <= n) 
# 45
{ 
# 46
for (size_type i = (0); i < (b.bound()); ((++i), (++result)), (++first)) 
# 47
{ 
# 48
(*result) = (*first); 
# 49
}  
# 50
} else 
# 52
{ 
# 53
for (size_type i = (0); i < (b.bound()); (++i), (++first)) 
# 54
{ 
# 55
if (i < n) 
# 56
{ 
# 57
(*result) = (*first); 
# 58
++result; 
# 59
}  
# 60
}  
# 61
}  
# 63
return result; 
# 64
} 
#endif
# 68 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/copy.hpp"
namespace detail { 
# 72
template< class ConcurrentGroup, class 
# 73
RandomAccessIterator1, class 
# 74
Size, class 
# 75
RandomAccessIterator2> 
# 76
__attribute((always_inline)) __attribute__((unused)) inline RandomAccessIterator2 
# 77
simple_copy_n(ConcurrentGroup &g, RandomAccessIterator1 first, Size n, RandomAccessIterator2 result) 
# 78
{int volatile ___ = 1;(void)g;(void)first;(void)n;(void)result;
# 89
::exit(___);}
#if 0
# 78
{ 
# 79
for (Size i = ((g.this_exec).index()); i < n; i += (g.size())) 
# 82
{ 
# 83
(result[i]) = (first[i]); 
# 84
}  
# 86
(g.wait()); 
# 88
return result + n; 
# 89
} 
#endif
# 92 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/copy.hpp"
template< std::size_t size, std::size_t 
# 93
grainsize, class 
# 94
RandomAccessIterator1, class 
# 95
Size, class 
# 96
RandomAccessIterator2> 
# 97
__attribute((always_inline)) __attribute__((unused)) inline typename thrust::detail::enable_if< ((size * grainsize) > (0)), RandomAccessIterator2> ::type 
# 102
simple_copy_n(concurrent_group< agent< grainsize> , size>  &
# 105
g, RandomAccessIterator1 
# 106
first, Size n, RandomAccessIterator2 
# 107
result) 
# 108
{int volatile ___ = 1;(void)g;(void)first;(void)n;(void)result;
# 166
::exit(___);}
#if 0
# 108
{ 
# 112
typedef concurrent_group< agent< grainsize> , size>  group_type; 
# 114
RandomAccessIterator2 return_me = result + n; 
# 116
typedef typename concurrent_group< agent< grainsize> , size> ::size_type size_type; 
# 117
size_type chunk_size = (size * grainsize); 
# 119
size_type tid = ((g.this_exec).index()); 
# 122
if (chunk_size == n) 
# 123
{ 
# 125
first += tid; 
# 126
result += tid; 
# 128
for (size_type i = (0); i < grainsize; ((++i), (first += size)), (result += size)) 
# 129
{ 
# 130
(*result) = (*first); 
# 131
}  
# 132
} else 
# 134
{ 
# 136
for (RandomAccessIterator1 last = first + n; first < last; (first += chunk_size), (result += chunk_size)) 
# 139
{ 
# 141
if ((last - first) >= chunk_size) 
# 142
{ 
# 143
for (size_type i = (0); i < grainsize; ++i) 
# 144
{ 
# 145
size_type idx = (size * i) + tid; 
# 146
(result[idx]) = (first[idx]); 
# 147
}  
# 148
} else 
# 150
{ 
# 151
for (size_type i = (0); i < grainsize; ++i) 
# 152
{ 
# 153
size_type idx = (size * i) + tid; 
# 154
if (idx < (last - first)) 
# 155
{ 
# 156
(result[idx]) = (first[idx]); 
# 157
}  
# 158
}  
# 159
}  
# 160
}  
# 161
}  
# 163
(g.wait()); 
# 165
return return_me; 
# 166
} 
#endif
# 169 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/copy.hpp"
template< std::size_t size, std::size_t 
# 170
grainsize, class 
# 171
RandomAccessIterator1, class 
# 172
Size, class 
# 173
RandomAccessIterator2> 
# 174
__attribute((always_inline)) __attribute__((unused)) inline RandomAccessIterator2 
# 175
copy_n(concurrent_group< agent< grainsize> , size>  &
# 178
g, RandomAccessIterator1 
# 179
first, Size 
# 180
n, RandomAccessIterator2 
# 181
result) 
# 182
{int volatile ___ = 1;(void)g;(void)first;(void)n;(void)result;
# 184
::exit(___);}
#if 0
# 182
{ 
# 183
return detail::simple_copy_n(g, first, n, result); 
# 184
} 
#endif
# 187 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/copy.hpp"
}
# 190
template< std::size_t groupsize, class 
# 191
Executor, class 
# 192
RandomAccessIterator1, class 
# 193
Size, class 
# 194
RandomAccessIterator2> 
# 195
__attribute((always_inline)) __attribute__((unused)) inline RandomAccessIterator2 
# 197
copy_n(concurrent_group< Executor, groupsize>  &g, RandomAccessIterator1 first, Size n, RandomAccessIterator2 result) 
# 198
{int volatile ___ = 1;(void)g;(void)first;(void)n;(void)result;
# 200
::exit(___);}
#if 0
# 198
{ 
# 199
return detail::copy_n(g, first, n, result); 
# 200
} 
#endif
# 203 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/copy.hpp"
template< std::size_t bound, std::size_t groupsize, std::size_t grainsize, class RandomAccessIterator1, class Size, class RandomAccessIterator2> __attribute__((unused)) typename thrust::detail::enable_if< bound <= (groupsize * grainsize), RandomAccessIterator2> ::type 
# 209
copy_n(bounded< bound, concurrent_group< agent< grainsize> , groupsize> >  &
# 215
g, RandomAccessIterator1 
# 216
first, Size 
# 217
n, RandomAccessIterator2 
# 218
result) 
# 219
{int volatile ___ = 1;(void)g;(void)first;(void)n;(void)result;
# 276
::exit(___);}
#if 0
# 219
{ 
# 226
typedef bounded< bound, concurrent_group< agent< grainsize> , groupsize> >  group_type; 
# 228
typedef typename bounded< bound, concurrent_group< agent< grainsize> , groupsize> > ::size_type size_type; 
# 230
size_type tid = ((g.this_exec).index()); 
# 232
typedef typename iterator_value< RandomAccessIterator1> ::type value_type; 
# 235
value_type stage[grainsize]; 
# 238
if ((groupsize * grainsize) <= n) 
# 239
{ 
# 240
for (size_type i = (0); i < grainsize; ++i) 
# 241
{ 
# 242
size_type src_idx = ((g.size()) * i) + tid; 
# 243
(stage[i]) = (first[src_idx]); 
# 244
}  
# 246
for (size_type i = (0); i < grainsize; ++i) 
# 247
{ 
# 248
size_type dst_idx = ((g.size()) * i) + tid; 
# 249
(result[dst_idx]) = (stage[i]); 
# 250
}  
# 251
} else 
# 253
{ 
# 254
for (size_type i = (0); i < grainsize; ++i) 
# 255
{ 
# 256
size_type src_idx = ((g.size()) * i) + tid; 
# 257
if (src_idx < n) 
# 258
{ 
# 259
(stage[i]) = (first[src_idx]); 
# 260
}  
# 261
}  
# 263
for (size_type i = (0); i < grainsize; ++i) 
# 264
{ 
# 265
size_type dst_idx = ((g.size()) * i) + tid; 
# 266
if (dst_idx < n) 
# 267
{ 
# 268
(result[dst_idx]) = (stage[i]); 
# 269
}  
# 270
}  
# 271
}  
# 273
(g.wait()); 
# 275
return result + thrust::min< Size> ((g.size()) * grainsize, n); 
# 276
} 
#endif
# 279 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/copy.hpp"
}
# 280
}}}}
# 23 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/iterator/strided_iterator.hpp"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 24
namespace bulk_ { 
# 28
template< class Iterator, class 
# 29
Size = typename iterator_difference< Iterator> ::type> 
# 30
class strided_iterator : public iterator_adaptor< strided_iterator< Iterator> , Iterator>  { 
# 37
typedef ::thrust::iterator_adaptor< ::thrust::system::cuda::detail::bulk_::strided_iterator< Iterator> , Iterator>  super_t; 
# 40
public: typedef Size stride_type; 
# 43
strided_iterator() : super_t(), m_stride(1) 
# 45
{ } 
# 48
strided_iterator(const strided_iterator &other) : super_t(other), m_stride(other.m_stride) 
# 50
{ } 
# 53
strided_iterator(const Iterator &base, stride_type stride) : super_t(base), m_stride(stride) 
# 55
{ } 
# 58
stride_type stride() const 
# 59
{ 
# 60
return m_stride; 
# 61
} 
# 64
friend class ::thrust::iterator_core_access; 
# 67
private: void increment() 
# 68
{ 
# 69
super_t::base_reference() += stride(); 
# 70
} 
# 73
void decrement() 
# 74
{ 
# 75
super_t::base_reference() -= stride(); 
# 76
} 
# 79
void advance(typename ::thrust::iterator_adaptor< ::thrust::system::cuda::detail::bulk_::strided_iterator< Iterator> , Iterator> ::difference_type n) 
# 80
{ 
# 81
super_t::base_reference() += (n * stride()); 
# 82
} 
# 84
template< class OtherIterator> typename ::thrust::iterator_adaptor< ::thrust::system::cuda::detail::bulk_::strided_iterator< Iterator> , Iterator> ::difference_type 
# 86
distance_to(const ::thrust::system::cuda::detail::bulk_::strided_iterator< OtherIterator>  &other) const 
# 87
{ 
# 88
if ((other.base()) >= (this->base())) 
# 89
{ 
# 90
return (((other.base()) - (this->base())) + (stride() - 1)) / stride(); 
# 91
}  
# 93
return (((other.base()) - (this->base())) - (stride() - 1)) / stride(); 
# 94
} 
# 96
stride_type m_stride; 
# 97
}; 
# 100
template< class Iterator, class Size> strided_iterator< Iterator, Size>  
# 102
make_strided_iterator(Iterator iter, Size stride) 
# 103
{ 
# 104
return strided_iterator< Iterator, Size> (iter, stride); 
# 105
} 
# 108
}
# 109
}}}}
# 28 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/reduce.hpp"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 29
namespace bulk_ { 
# 33
template< std::size_t bound, std::size_t 
# 34
grainsize, class 
# 35
RandomAccessIterator, class 
# 36
T, class 
# 37
BinaryFunction> 
# 38
__attribute((always_inline)) __attribute__((unused)) inline T 
# 39
reduce(const bounded< bound, agent< grainsize> >  &exec, RandomAccessIterator 
# 40
first, RandomAccessIterator 
# 41
last, T 
# 42
init, BinaryFunction 
# 43
binary_op) 
# 44
{int volatile ___ = 1;(void)exec;(void)first;(void)last;(void)init;(void)binary_op;
# 58
::exit(___);}
#if 0
# 44
{ 
# 45
typedef typename bounded< bound, agent< grainsize> > ::size_type size_type; 
# 47
size_type n = last - first; 
# 49
for (size_type i = (0); i < (exec.bound()); ++i) 
# 50
{ 
# 51
if (i < n) 
# 52
{ 
# 53
init = binary_op(init, first[i]); 
# 54
}  
# 55
}  
# 57
return init; 
# 58
} 
#endif
# 61 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/reduce.hpp"
namespace detail { 
# 63
namespace reduce_detail { 
# 67
template< class ConcurrentGroup, class RandomAccessIterator, class Size, class T, class BinaryFunction> __attribute__((unused)) T 
# 68
destructive_reduce_n(ConcurrentGroup &g, RandomAccessIterator first, Size n, T init, BinaryFunction binary_op) 
# 69
{int volatile ___ = 1;(void)g;(void)first;(void)n;(void)init;(void)binary_op;
# 103
::exit(___);}
#if 0
# 69
{ 
# 70
typedef int size_type; 
# 72
size_type tid = ((g.this_exec).index()); 
# 74
Size m = n; 
# 76
while (m > 1) 
# 77
{ 
# 78
Size half_m = m >> 1; 
# 80
if (tid < half_m) 
# 81
{ 
# 82
T old_val = first[tid]; 
# 84
(first[tid]) = binary_op(old_val, first[(m - tid) - 1]); 
# 85
}  
# 87
(g.wait()); 
# 89
m -= half_m; 
# 90
}  
# 92
(g.wait()); 
# 94
T result = init; 
# 95
if (n > 0) 
# 96
{ 
# 97
result = binary_op(result, first[0]); 
# 98
}  
# 100
(g.wait()); 
# 102
return result; 
# 103
} 
#endif
# 106 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/reduce.hpp"
}
# 107
}
# 110
template< std::size_t groupsize, std::size_t grainsize, class RandomAccessIterator, class T, class BinaryFunction> __attribute__((unused)) T 
# 112
reduce(concurrent_group< agent< grainsize> , groupsize>  &g, RandomAccessIterator 
# 113
first, RandomAccessIterator 
# 114
last, T 
# 115
init, BinaryFunction 
# 116
binary_op) 
# 117
{int volatile ___ = 1;(void)g;(void)first;(void)last;(void)init;(void)binary_op;
# 219
::exit(___);}
#if 0
# 117
{ 
# 118
typedef int size_type; 
# 120
const size_type elements_per_group = (groupsize * grainsize); 
# 122
size_type tid = ((g.this_exec).index()); 
# 124
T this_sum; 
# 126
bool this_sum_defined = false; 
# 128
size_type n = last - first; 
# 133
for (size_type offset = 0; offset < n; (first += elements_per_group), (offset += elements_per_group)) 
# 134
{ 
# 135
size_type partition_size = thrust::min< int> (elements_per_group, last - first); 
# 137
typedef typename iterator_value< RandomAccessIterator> ::type input_type; 
# 140
input_type local_inputs[grainsize]; 
# 144
strided_iterator< RandomAccessIterator, int>  local_first = make_strided_iterator(first + tid, static_cast< size_type>(groupsize)); 
# 149
size_type local_size = 0; 
# 150
if (partition_size < elements_per_group) 
# 151
{ 
# 163
RandomAccessIterator iter = (local_first.base()); 
# 164
size_type index = tid; 
# 165
for (size_type i = 0; i < grainsize; ((++i), (index += groupsize)), (iter += groupsize)) 
# 166
{ 
# 167
if (index < partition_size) 
# 168
{ 
# 169
((local_inputs)[i]) = (*iter); 
# 170
++local_size; 
# 171
}  
# 172
}  
# 173
} else 
# 175
{ 
# 176
local_size = (grainsize); 
# 182
RandomAccessIterator iter = (local_first.base()); 
# 183
for (size_type i = 0; i < grainsize; (++i), (iter += groupsize)) 
# 184
{ 
# 185
((local_inputs)[i]) = (*iter); 
# 186
}  
# 187
}  
# 190
this_sum = (this_sum_defined ? bulk_::reduce(bulk_::bound< grainsize> ((g.this_exec)), local_inputs, (local_inputs) + local_size, this_sum, binary_op) : bulk_::reduce(bulk_::bound< grainsize - (1)> ((g.this_exec)), (local_inputs) + 1, (local_inputs) + local_size, (T)((local_inputs)[0]), binary_op)); 
# 194
this_sum_defined = true; 
# 195
}  
# 200
__attribute__((unused)) static uninitialized_array< T, groupsize>  buffer_impl; 
# 201
T *buffer = (buffer_impl.data()); 
# 204
if (this_sum_defined) 
# 205
{ 
# 206
(buffer[tid]) = this_sum; 
# 207
}  
# 209
(g.wait()); 
# 212
T result = detail::reduce_detail::destructive_reduce_n(g, buffer, thrust::min< int> (groupsize, n), init, binary_op); 
# 218
return result; 
# 219
} 
#endif
# 222 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/reduce.hpp"
template< class RandomAccessIterator, class T, class BinaryFunction> __attribute__((unused)) T 
# 224
reduce(concurrent_group<>  &g, RandomAccessIterator 
# 225
first, RandomAccessIterator 
# 226
last, T 
# 227
init, BinaryFunction 
# 228
binary_op) 
# 229
{int volatile ___ = 1;(void)g;(void)first;(void)last;(void)init;(void)binary_op;
# 264
::exit(___);}
#if 0
# 229
{ 
# 230
typedef int size_type; 
# 232
size_type tid = (g.this_exec).index(); 
# 234
T this_sum; 
# 236
bool this_sum_defined = false; 
# 238
typename iterator_difference< RandomAccessIterator> ::type n = last - first; 
# 240
T *buffer = reinterpret_cast< T *>(bulk_::malloc(g, (g.size()) * sizeof(T))); 
# 242
for (size_type i = tid; i < n; i += g.size()) 
# 243
{ 
# 244
typedef typename iterator_value< RandomAccessIterator> ::type input_type; 
# 245
input_type x = first[i]; 
# 246
this_sum = (this_sum_defined ? binary_op(this_sum, x) : x); 
# 248
this_sum_defined = true; 
# 249
}  
# 251
if (this_sum_defined) 
# 252
{ 
# 253
(buffer[tid]) = this_sum; 
# 254
}  
# 256
g.wait(); 
# 259
T result = detail::reduce_detail::destructive_reduce_n(g, buffer, thrust::min< int> (g.size(), n), init, binary_op); 
# 261
bulk_::free(g, buffer); 
# 263
return result; 
# 264
} 
#endif
# 267 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/reduce.hpp"
}
# 268
}}}}
# 25 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/accumulate.hpp"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 26
namespace bulk_ { 
# 30
template< std::size_t bound, std::size_t 
# 31
grainsize, class 
# 32
RandomAccessIterator, class 
# 33
T, class 
# 34
BinaryFunction> 
# 35
__attribute((always_inline)) __attribute__((unused)) inline T 
# 36
accumulate(const bounded< bound, agent< grainsize> >  &exec, RandomAccessIterator 
# 37
first, RandomAccessIterator 
# 38
last, T 
# 39
init, BinaryFunction 
# 40
binary_op) 
# 41
{int volatile ___ = 1;(void)exec;(void)first;(void)last;(void)init;(void)binary_op;
# 55
::exit(___);}
#if 0
# 41
{ 
# 42
typedef typename bounded< bound, agent< grainsize> > ::size_type size_type; 
# 44
size_type n = last - first; 
# 46
for (size_type i = (0); i < (exec.bound()); ++i) 
# 47
{ 
# 48
if (i < n) 
# 49
{ 
# 50
init = binary_op(init, first[i]); 
# 51
}  
# 52
}  
# 54
return init; 
# 55
} 
#endif
# 58 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/accumulate.hpp"
namespace detail { 
# 60
namespace accumulate_detail { 
# 66
template< class ConcurrentGroup, class RandomAccessIterator, class Size, class T, class BinaryFunction> __attribute__((unused)) T 
# 67
destructive_accumulate_n(ConcurrentGroup &g, RandomAccessIterator first, Size n, T init, BinaryFunction binary_op) 
# 68
{int volatile ___ = 1;(void)g;(void)first;(void)n;(void)init;(void)binary_op;
# 103
::exit(___);}
#if 0
# 68
{ 
# 69
typedef typename ConcurrentGroup::size_type size_type; 
# 71
size_type tid = ((g.this_exec).index()); 
# 73
T x = init; 
# 74
if (tid < n) 
# 75
{ 
# 76
x = (first[tid]); 
# 77
}  
# 79
(g.wait()); 
# 81
for (size_type offset = (1); offset < (g.size()); offset += offset) 
# 82
{ 
# 83
if ((tid >= offset) && ((tid - offset) < n)) 
# 84
{ 
# 85
x = binary_op(first[tid - offset], x); 
# 86
}  
# 88
(g.wait()); 
# 90
if (tid < n) 
# 91
{ 
# 92
(first[tid]) = x; 
# 93
}  
# 95
(g.wait()); 
# 96
}  
# 98
T result = binary_op(init, first[n - 1]); 
# 100
(g.wait()); 
# 102
return result; 
# 103
} 
#endif
# 106 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/accumulate.hpp"
template< std::size_t groupsize, std::size_t grainsize, class RandomAccessIterator, class T> 
# 107
struct buffer { 
# 109
typedef typename iterator_value< RandomAccessIterator> ::type value_type; 
# 112
union { 
# 113
uninitialized_array< typename iterator_value< RandomAccessIterator> ::type, groupsize * grainsize>  inputs; 
# 114
uninitialized_array< T, groupsize>  sums; 
# 115
}; 
# 116
}; 
# 119
template< std::size_t groupsize, std::size_t grainsize, class RandomAccessIterator, class T, class BinaryFunction> __attribute__((unused)) T 
# 121
accumulate(concurrent_group< agent< grainsize> , groupsize>  &g, RandomAccessIterator 
# 122
first, RandomAccessIterator 
# 123
last, T 
# 124
init, BinaryFunction 
# 125
binary_op) 
# 126
{int volatile ___ = 1;(void)g;(void)first;(void)last;(void)init;(void)binary_op;
# 193
::exit(___);}
#if 0
# 126
{ 
# 127
typedef typename concurrent_group< agent< grainsize> , groupsize> ::size_type size_type; 
# 129
const size_type elements_per_group = (groupsize * grainsize); 
# 131
size_type tid = ((g.this_exec).index()); 
# 133
T sum = init; 
# 135
typename iterator_difference< RandomAccessIterator> ::type n = last - first; 
# 142
typedef accumulate_detail::buffer< groupsize, grainsize, RandomAccessIterator, T>  buffer_type; 
# 147
__attribute__((unused)) static uninitialized< accumulate_detail::buffer< groupsize, grainsize, RandomAccessIterator, T> >  buffer_impl; 
# 148
buffer_type *buffer = (&(buffer_impl.get())); 
# 151
for (; first < last; first += elements_per_group) 
# 152
{ 
# 155
size_type partition_size = thrust::min< typename concurrent_group< agent< grainsize> , groupsize> ::size_type> (elements_per_group, last - first); 
# 158
bulk_::copy_n(g, first, partition_size, ((buffer->inputs).data())); 
# 160
T this_sum; 
# 161
size_type local_offset = grainsize * ((g.this_exec).index()); 
# 163
size_type local_size = thrust::max< typename concurrent_group< agent< grainsize> , groupsize> ::size_type> (0, thrust::min< typename concurrent_group< agent< grainsize> , groupsize> ::size_type> (grainsize, partition_size - (grainsize * tid))); 
# 165
if (local_size) 
# 166
{ 
# 167
this_sum = ((buffer->inputs)[local_offset]); 
# 168
this_sum = bulk_::accumulate(bound< grainsize - (1)> ((g.this_exec)), (((buffer->inputs).data()) + local_offset) + 1, (((buffer->inputs).data()) + local_offset) + local_size, this_sum, binary_op); 
# 173
}  
# 175
(g.wait()); 
# 177
if (local_size) 
# 178
{ 
# 179
((buffer->sums)[tid]) = this_sum; 
# 180
}  
# 182
(g.wait()); 
# 185
sum = accumulate_detail::destructive_accumulate_n(g, ((buffer->sums).data()), thrust::min< typename concurrent_group< agent< grainsize> , groupsize> ::size_type> (groupsize, n), sum, binary_op); 
# 186
}  
# 192
return sum; 
# 193
} 
#endif
# 194 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/accumulate.hpp"
}
# 195
}
# 198
template< std::size_t groupsize, std::size_t grainsize, class RandomAccessIterator, class T, class BinaryFunction> __attribute__((unused)) T 
# 200
accumulate(concurrent_group< agent< grainsize> , groupsize>  &g, RandomAccessIterator 
# 201
first, RandomAccessIterator 
# 202
last, T 
# 203
init, BinaryFunction 
# 204
binary_op) 
# 205
{int volatile ___ = 1;(void)g;(void)first;(void)last;(void)init;(void)binary_op;
# 217
::exit(___);}
#if 0
# 205
{ 
# 207
if (thrust::detail::is_commutative< BinaryFunction> ::value) 
# 208
{ 
# 209
init = bulk_::reduce(g, first, last, init, binary_op); 
# 210
} else 
# 212
{ 
# 213
init = detail::accumulate_detail::accumulate(g, first, last, init, binary_op); 
# 214
}  
# 216
return init; 
# 217
} 
#endif
# 220 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/accumulate.hpp"
}
# 221
}}}}
# 21 "/usr/local/cuda-8.0/include/thrust/iterator/detail/any_assign.h"
namespace thrust { 
# 23
namespace detail { 
# 28
struct any_assign { 
# 30
any_assign() 
# 31
{ } 
# 33
template< class T> 
# 34
any_assign(T) 
# 35
{ } 
# 37
template< class T> any_assign &
# 39
operator=(T) 
# 40
{ 
# 41
if (0) 
# 42
{ 
# 44
int *x = (0); 
# 45
(*x) = 13; 
# 46
}  
# 48
return *this; 
# 49
} 
# 50
}; 
# 53
}
# 54
}
# 25 "/usr/local/cuda-8.0/include/thrust/detail/type_traits/iterator/is_output_iterator.h"
namespace thrust { 
# 28
namespace detail { 
# 32
template< class T> 
# 33
struct is_void_like : public or_< is_void< T> , is_same< T, any_assign> >  { 
# 38
}; 
# 41
template< class T> 
# 42
struct lazy_is_void_like : public is_void_like< typename T::type>  { 
# 44
}; 
# 53
template< class T> 
# 54
struct is_output_iterator : public eval_if< is_metafunction_defined< iterator_value< T> > ::value, lazy_is_void_like< iterator_value< T> > , integral_constant< bool, true> > ::type { 
# 61
}; 
# 63
}
# 65
}
# 30 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/scan.hpp"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 31
namespace bulk_ { 
# 35
template< std::size_t bound, std::size_t grainsize, class RandomAccessIterator1, class RandomAccessIterator2, class T, class BinaryFunction> 
# 36
__attribute((always_inline)) __attribute__((unused)) inline RandomAccessIterator2 
# 38
inclusive_scan(const bounded< bound, agent< grainsize> >  &exec, RandomAccessIterator1 
# 39
first, RandomAccessIterator1 
# 40
last, RandomAccessIterator2 
# 41
result, T 
# 42
init, BinaryFunction 
# 43
binary_op) 
# 44
{int volatile ___ = 1;(void)exec;(void)first;(void)last;(void)result;(void)init;(void)binary_op;
# 55
::exit(___);}
#if 0
# 44
{ 
# 45
for (int i = 0; i < (exec.bound()); ++i) 
# 46
{ 
# 47
if ((first + i) < last) 
# 48
{ 
# 49
init = binary_op(init, first[i]); 
# 50
(result[i]) = init; 
# 51
}  
# 52
}  
# 54
return result + (last - first); 
# 55
} 
#endif
# 58 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/scan.hpp"
template< std::size_t bound, std::size_t grainsize, class RandomAccessIterator1, class RandomAccessIterator2, class T, class BinaryFunction> 
# 59
__attribute((always_inline)) __attribute__((unused)) inline RandomAccessIterator2 
# 61
exclusive_scan(const bounded< bound, agent< grainsize> >  &exec, RandomAccessIterator1 
# 62
first, RandomAccessIterator1 
# 63
last, RandomAccessIterator2 
# 64
result, T 
# 65
init, BinaryFunction 
# 66
binary_op) 
# 67
{int volatile ___ = 1;(void)exec;(void)first;(void)last;(void)result;(void)init;(void)binary_op;
# 78
::exit(___);}
#if 0
# 67
{ 
# 68
for (int i = 0; i < (exec.bound()); ++i) 
# 69
{ 
# 70
if ((first + i) < last) 
# 71
{ 
# 72
(result[i]) = init; 
# 73
init = binary_op(init, first[i]); 
# 74
}  
# 75
}  
# 77
return result + (last - first); 
# 78
} 
#endif
# 81 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/scan.hpp"
namespace detail { 
# 83
namespace scan_detail { 
# 87
template< class InputIterator, class OutputIterator, class BinaryFunction> 
# 88
struct scan_intermediate : public thrust::detail::eval_if< thrust::detail::has_result_type< BinaryFunction> ::value, thrust::detail::result_type< BinaryFunction> , thrust::detail::eval_if< thrust::detail::is_output_iterator< OutputIterator> ::value, iterator_value< InputIterator> , iterator_value< OutputIterator> > >  { 
# 98
}; 
# 101
template< class ConcurrentGroup, class RandomAccessIterator, class T, class BinaryFunction> __attribute__((unused)) T 
# 102
inplace_exclusive_scan(ConcurrentGroup &g, RandomAccessIterator first, T init, BinaryFunction binary_op) 
# 103
{int volatile ___ = 1;(void)g;(void)first;(void)init;(void)binary_op;
# 149
::exit(___);}
#if 0
# 103
{ 
# 104
typedef typename ConcurrentGroup::size_type size_type; 
# 106
size_type tid = ((g.this_exec).index()); 
# 108
if (tid == 0) 
# 109
{ 
# 110
(first[0]) = binary_op(init, first[0]); 
# 111
}  
# 113
T x = first[tid]; 
# 115
(g.wait()); 
# 117
for (size_type offset = (1); offset < (g.size()); offset += offset) 
# 118
{ 
# 119
if (tid >= offset) 
# 120
{ 
# 121
x = binary_op(first[tid - offset], x); 
# 122
}  
# 124
(g.wait()); 
# 126
(first[tid]) = x; 
# 128
(g.wait()); 
# 129
}  
# 131
T result = first[(g.size()) - 1]; 
# 133
if (tid == 0) 
# 134
{ 
# 135
x = init; 
# 136
} else 
# 138
{ 
# 139
x = (first[tid - 1]); 
# 140
}  
# 142
(g.wait()); 
# 144
(first[tid]) = x; 
# 146
(g.wait()); 
# 148
return result; 
# 149
} 
#endif
# 152 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/scan.hpp"
template< class ConcurrentGroup, class RandomAccessIterator, class Size, class T, class BinaryFunction> __attribute__((unused)) T 
# 153
small_inplace_exclusive_scan(ConcurrentGroup &g, RandomAccessIterator first, Size n, T init, BinaryFunction binary_op) 
# 154
{int volatile ___ = 1;(void)g;(void)first;(void)n;(void)init;(void)binary_op;
# 209
::exit(___);}
#if 0
# 154
{ 
# 155
typedef typename ConcurrentGroup::size_type size_type; 
# 157
size_type tid = ((g.this_exec).index()); 
# 159
if (tid == 0) 
# 160
{ 
# 161
(first[0]) = binary_op(init, first[0]); 
# 162
}  
# 164
T x = (tid < n) ? first[tid] : init; 
# 166
(g.wait()); 
# 168
for (size_type offset = (1); offset < (g.size()); offset += offset) 
# 169
{ 
# 170
if ((tid >= offset) && ((tid - offset) < n)) 
# 171
{ 
# 172
x = binary_op(first[tid - offset], x); 
# 173
}  
# 175
(g.wait()); 
# 177
if (tid < n) 
# 178
{ 
# 179
(first[tid]) = x; 
# 180
}  
# 182
(g.wait()); 
# 183
}  
# 185
T result = first[n - 1]; 
# 187
if (tid < n) 
# 188
{ 
# 189
if (tid == 0) 
# 190
{ 
# 191
x = init; 
# 192
} else 
# 194
{ 
# 195
x = (first[tid - 1]); 
# 196
}  
# 197
}  
# 199
(g.wait()); 
# 201
if (tid < n) 
# 202
{ 
# 203
(first[tid]) = x; 
# 204
}  
# 206
(g.wait()); 
# 208
return result; 
# 209
} 
#endif
# 213 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/scan.hpp"
template< class ConcurrentGroup, class RandomAccessIterator, class Size, class T, class BinaryFunction> __attribute__((unused)) T 
# 214
bounded_inplace_exclusive_scan(ConcurrentGroup &g, RandomAccessIterator first, Size n, T init, BinaryFunction binary_op) 
# 215
{int volatile ___ = 1;(void)g;(void)first;(void)n;(void)init;(void)binary_op;
# 219
::exit(___);}
#if 0
# 215
{ 
# 216
return (n == (g.size())) ? inplace_exclusive_scan(g, first, init, binary_op) : small_inplace_exclusive_scan(g, first, n, init, binary_op); 
# 219
} 
#endif
# 222 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/scan.hpp"
template< bool inclusive, std::size_t 
# 223
bound, std::size_t groupsize, std::size_t grainsize, class 
# 224
RandomAccessIterator1, class 
# 225
RandomAccessIterator2, class 
# 226
T, class 
# 227
BinaryFunction> __attribute__((unused)) T 
# 235
scan(bounded< bound, concurrent_group< agent< grainsize> , groupsize> >  &
# 238
g, RandomAccessIterator1 
# 239
first, RandomAccessIterator1 last, RandomAccessIterator2 
# 240
result, T 
# 241
carry_in, BinaryFunction 
# 242
binary_op) 
# 243
{int volatile ___ = 1;(void)g;(void)first;(void)last;(void)result;(void)carry_in;(void)binary_op;
# 313
::exit(___);}
#if 0
# 243
{ 
# 244
typedef typename iterator_value< RandomAccessIterator1> ::type input_type; 
# 250
typedef typename scan_intermediate< RandomAccessIterator1, RandomAccessIterator2, BinaryFunction> ::type intermediate_type; 
# 255
typedef typename bounded< bound, concurrent_group< agent< grainsize> , groupsize> > ::size_type size_type; 
# 257
size_type tid = ((g.this_exec).index()); 
# 258
size_type n = last - first; 
# 261
input_type local_inputs[grainsize]; 
# 263
size_type local_offset = grainsize * tid; 
# 264
size_type local_size = thrust::max< typename bounded< bound, concurrent_group< agent< grainsize> , groupsize> > ::size_type> (0, thrust::min< typename bounded< bound, concurrent_group< agent< grainsize> , groupsize> > ::size_type> (grainsize, n - (grainsize * tid))); 
# 266
bulk_::copy_n(bulk_::bound< grainsize> ((g.this_exec)), first + local_offset, local_size, local_inputs); 
# 269
intermediate_type x; 
# 271
if (local_size) 
# 272
{ 
# 273
x = ((local_inputs)[0]); 
# 274
x = bulk_::accumulate(bulk_::bound< grainsize - (1)> ((g.this_exec)), (local_inputs) + 1, local_inputs + local_size, x, binary_op); 
# 275
}  
# 277
(g.wait()); 
# 279
if (local_size) 
# 280
{ 
# 281
(result[tid]) = x; 
# 282
}  
# 284
(g.wait()); 
# 287
const size_type spine_n = (n >= ((g.size()) * ((g.this_exec).grainsize()))) ? (g.size()) : (((n + ((g.this_exec).grainsize())) - 1) / ((g.this_exec).grainsize())); 
# 292
carry_in = bounded_inplace_exclusive_scan(g, result, spine_n, carry_in, binary_op); 
# 294
if (local_size) 
# 295
{ 
# 296
x = (result[tid]); 
# 297
}  
# 299
(g.wait()); 
# 301
if (inclusive) 
# 302
{ 
# 303
bulk_::inclusive_scan(bulk_::bound< grainsize> ((g.this_exec)), local_inputs, local_inputs + local_size, result + local_offset, x, binary_op); 
# 304
} else 
# 306
{ 
# 307
bulk_::exclusive_scan(bulk_::bound< grainsize> ((g.this_exec)), local_inputs, local_inputs + local_size, result + local_offset, x, binary_op); 
# 308
}  
# 310
(g.wait()); 
# 312
return carry_in; 
# 313
} 
#endif
# 316 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/scan.hpp"
template< std::size_t groupsize, std::size_t grainsize, class RandomAccessIterator1, class RandomAccessIterator2, class BinaryFunction> 
# 317
struct scan_buffer { 
# 319
typedef typename iterator_value< RandomAccessIterator1> ::type input_type; 
# 325
typedef typename scan_intermediate< RandomAccessIterator1, RandomAccessIterator2, BinaryFunction> ::type intermediate_type; 
# 328
union { 
# 329
uninitialized_array< typename iterator_value< RandomAccessIterator1> ::type, groupsize * grainsize>  inputs; 
# 330
uninitialized_array< typename scan_intermediate< RandomAccessIterator1, RandomAccessIterator2, BinaryFunction> ::type, groupsize * grainsize>  results; 
# 331
}; 
# 332
}; 
# 335
template< bool inclusive, std::size_t groupsize, std::size_t grainsize, class RandomAccessIterator1, class RandomAccessIterator2, class T, class BinaryFunction> __attribute__((unused)) void 
# 336
scan_with_buffer(concurrent_group< agent< grainsize> , groupsize>  &g, RandomAccessIterator1 
# 337
first, RandomAccessIterator1 last, RandomAccessIterator2 
# 338
result, T 
# 339
carry_in, BinaryFunction 
# 340
binary_op, scan_buffer< groupsize, grainsize, RandomAccessIterator1, RandomAccessIterator2, BinaryFunction>  &
# 341
buffer) 
# 342
{int volatile ___ = 1;(void)g;(void)first;(void)last;(void)result;(void)carry_in;(void)binary_op;(void)buffer;
# 386
::exit(___);}
#if 0
# 342
{ 
# 349
typedef scan_buffer< groupsize, grainsize, RandomAccessIterator1, RandomAccessIterator2, BinaryFunction>  buffer_type; 
# 351
typedef typename scan_buffer< groupsize, grainsize, RandomAccessIterator1, RandomAccessIterator2, BinaryFunction> ::input_type input_type; 
# 352
typedef typename scan_buffer< groupsize, grainsize, RandomAccessIterator1, RandomAccessIterator2, BinaryFunction> ::intermediate_type intermediate_type; 
# 357
union { 
# 358
input_type *inputs; 
# 359
intermediate_type *results; 
# 360
} stage; 
# 362
(stage.inputs) = ((buffer.inputs).data()); 
# 364
typedef typename concurrent_group< agent< grainsize> , groupsize> ::size_type size_type; 
# 366
size_type tid = ((g.this_exec).index()); 
# 368
const size_type elements_per_group = (groupsize * grainsize); 
# 370
for (; first < last; (first += elements_per_group), (result += elements_per_group)) 
# 371
{ 
# 372
size_type partition_size = thrust::min< typename concurrent_group< agent< grainsize> , groupsize> ::size_type> (elements_per_group, last - first); 
# 375
bulk_::copy_n(g, first, partition_size, stage.inputs); 
# 377
carry_in = scan< inclusive> (bulk_::bound< elements_per_group> (g), stage.inputs, (stage.inputs) + partition_size, stage.results, carry_in, binary_op); 
# 384
bulk_::copy_n(g, stage.results, partition_size, result); 
# 385
}  
# 386
} 
#endif
# 389 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/scan.hpp"
}
# 390
}
# 393
template< std::size_t bound, std::size_t 
# 394
groupsize, std::size_t 
# 395
grainsize, class 
# 396
RandomAccessIterator1, class 
# 397
RandomAccessIterator2, class 
# 398
T, class 
# 399
BinaryFunction> __attribute__((unused)) typename thrust::detail::enable_if< bound <= (groupsize * grainsize), RandomAccessIterator2> ::type 
# 405
inclusive_scan(bounded< bound, concurrent_group< agent< grainsize> , groupsize> >  &
# 408
g, RandomAccessIterator1 
# 409
first, RandomAccessIterator1 last, RandomAccessIterator2 
# 410
result, T 
# 411
carry_in, BinaryFunction 
# 412
binary_op) 
# 413
{int volatile ___ = 1;(void)g;(void)first;(void)last;(void)result;(void)carry_in;(void)binary_op;
# 416
::exit(___);}
#if 0
# 413
{ 
# 414
detail::scan_detail::scan< true> (g, first, last, result, carry_in, binary_op); 
# 415
return result + (last - first); 
# 416
} 
#endif
# 419 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/scan.hpp"
template< std::size_t bound, std::size_t 
# 420
groupsize, std::size_t 
# 421
grainsize, class 
# 422
RandomAccessIterator1, class 
# 423
RandomAccessIterator2, class 
# 424
BinaryFunction> __attribute__((unused)) typename thrust::detail::enable_if< bound <= (groupsize * grainsize), RandomAccessIterator2> ::type 
# 430
inclusive_scan(bounded< bound, concurrent_group< agent< grainsize> , groupsize> >  &
# 433
g, RandomAccessIterator1 
# 434
first, RandomAccessIterator1 last, RandomAccessIterator2 
# 435
result, BinaryFunction 
# 436
binary_op) 
# 437
{int volatile ___ = 1;(void)g;(void)first;(void)last;(void)result;(void)binary_op;
# 454
::exit(___);}
#if 0
# 437
{ 
# 438
if ((bound > (0)) && (first < last)) 
# 439
{ 
# 440
typename iterator_value< RandomAccessIterator1> ::type init = *first; 
# 443
(g.wait()); 
# 445
if (((g.this_exec).index()) == 0) 
# 446
{ 
# 447
(*result) = init; 
# 448
}  
# 450
detail::scan_detail::scan< true> (g, first + 1, last, result + 1, init, binary_op); 
# 451
}  
# 453
return result + (last - first); 
# 454
} 
#endif
# 457 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/scan.hpp"
template< std::size_t groupsize, std::size_t 
# 458
grainsize, class 
# 459
RandomAccessIterator1, class 
# 460
RandomAccessIterator2, class 
# 461
T, class 
# 462
BinaryFunction> __attribute__((unused)) void 
# 463
inclusive_scan(concurrent_group< agent< grainsize> , groupsize>  &g, RandomAccessIterator1 
# 464
first, RandomAccessIterator1 last, RandomAccessIterator2 
# 465
result, T 
# 466
init, BinaryFunction 
# 467
binary_op) 
# 468
{int volatile ___ = 1;(void)g;(void)first;(void)last;(void)result;(void)init;(void)binary_op;
# 488
::exit(___);}
#if 0
# 468
{ 
# 469
typedef detail::scan_detail::scan_buffer< groupsize, grainsize, RandomAccessIterator1, RandomAccessIterator2, BinaryFunction>  buffer_type; 
# 485
__attribute__((unused)) static uninitialized< detail::scan_detail::scan_buffer< groupsize, grainsize, RandomAccessIterator1, RandomAccessIterator2, BinaryFunction> >  buffer; 
# 486
detail::scan_detail::scan_with_buffer< true> (g, first, last, result, init, binary_op, (buffer.get())); 
# 488
} 
#endif
# 491 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/scan.hpp"
template< std::size_t size, std::size_t 
# 492
grainsize, class 
# 493
RandomAccessIterator1, class 
# 494
RandomAccessIterator2, class 
# 495
BinaryFunction> __attribute__((unused)) RandomAccessIterator2 
# 498
inclusive_scan(concurrent_group< agent< grainsize> , size>  &this_group, RandomAccessIterator1 
# 499
first, RandomAccessIterator1 
# 500
last, RandomAccessIterator2 
# 501
result, BinaryFunction 
# 502
binary_op) 
# 503
{int volatile ___ = 1;(void)this_group;(void)first;(void)last;(void)result;(void)binary_op;
# 528
::exit(___);}
#if 0
# 503
{ 
# 504
if (first < last) 
# 505
{ 
# 514
typename detail::scan_detail::scan_intermediate< RandomAccessIterator1, RandomAccessIterator2, BinaryFunction> ::type init = *first; 
# 517
(this_group.wait()); 
# 519
if (((this_group.this_exec).index()) == 0) 
# 520
{ 
# 521
(*result) = init; 
# 522
}  
# 524
bulk_::inclusive_scan(this_group, first + 1, last, result + 1, init, binary_op); 
# 525
}  
# 527
return result + (last - first); 
# 528
} 
#endif
# 531 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/scan.hpp"
template< std::size_t bound, std::size_t groupsize, std::size_t grainsize, class 
# 532
RandomAccessIterator1, class 
# 533
RandomAccessIterator2, class 
# 534
T, class 
# 535
BinaryFunction> __attribute__((unused)) typename thrust::detail::enable_if< bound <= (groupsize * grainsize), RandomAccessIterator2> ::type 
# 541
exclusive_scan(bounded< bound, concurrent_group< agent< grainsize> , groupsize> >  &
# 544
g, RandomAccessIterator1 
# 545
first, RandomAccessIterator1 last, RandomAccessIterator2 
# 546
result, T 
# 547
carry_in, BinaryFunction 
# 548
binary_op) 
# 549
{int volatile ___ = 1;(void)g;(void)first;(void)last;(void)result;(void)carry_in;(void)binary_op;
# 552
::exit(___);}
#if 0
# 549
{ 
# 550
detail::scan_detail::scan< true> (g, first, last, result, carry_in, binary_op); 
# 551
return result + (last - first); 
# 552
} 
#endif
# 555 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/scan.hpp"
template< std::size_t groupsize, std::size_t 
# 556
grainsize, class 
# 557
RandomAccessIterator1, class 
# 558
RandomAccessIterator2, class 
# 559
T, class 
# 560
BinaryFunction> __attribute__((unused)) typename thrust::detail::enable_if< (groupsize > (0)), RandomAccessIterator2> ::type 
# 566
exclusive_scan(concurrent_group< agent< grainsize> , groupsize>  &g, RandomAccessIterator1 
# 567
first, RandomAccessIterator1 last, RandomAccessIterator2 
# 568
result, T 
# 569
init, BinaryFunction 
# 570
binary_op) 
# 571
{int volatile ___ = 1;(void)g;(void)first;(void)last;(void)result;(void)init;(void)binary_op;
# 593
::exit(___);}
#if 0
# 571
{ 
# 572
typedef detail::scan_detail::scan_buffer< groupsize, grainsize, RandomAccessIterator1, RandomAccessIterator2, BinaryFunction>  buffer_type; 
# 588
__attribute__((unused)) static uninitialized< detail::scan_detail::scan_buffer< groupsize, grainsize, RandomAccessIterator1, RandomAccessIterator2, BinaryFunction> >  buffer; 
# 589
detail::scan_detail::scan_with_buffer< false> (g, first, last, result, init, binary_op, (buffer.get())); 
# 592
return result + (last - first); 
# 593
} 
#endif
# 596 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/scan.hpp"
}
# 597
}}}}
# 24 "/usr/local/cuda-8.0/include/thrust/iterator/detail/permutation_iterator_base.h"
namespace thrust { 
# 27
template< class , class > class permutation_iterator; 
# 30
namespace detail { 
# 33
template< class ElementIterator, class 
# 34
IndexIterator> 
# 35
struct permutation_iterator_base { 
# 37
typedef typename iterator_system< ElementIterator> ::type System1; 
# 38
typedef typename iterator_system< IndexIterator> ::type System2; 
# 47
typedef iterator_adaptor< permutation_iterator< ElementIterator, IndexIterator> , IndexIterator, typename iterator_value< ElementIterator> ::type, typename minimum_system< typename iterator_system< ElementIterator> ::type, typename iterator_system< IndexIterator> ::type> ::type, use_default, typename iterator_reference< ElementIterator> ::type>  type; 
# 48
}; 
# 50
}
# 52
}
# 40 "/usr/local/cuda-8.0/include/thrust/iterator/permutation_iterator.h"
namespace thrust { 
# 118
template< class ElementIterator, class 
# 119
IndexIterator> 
# 120
class permutation_iterator : public detail::permutation_iterator_base< ElementIterator, IndexIterator> ::type { 
# 129
typedef typename ::thrust::detail::permutation_iterator_base< ElementIterator, IndexIterator> ::type super_t; 
# 131
friend class iterator_core_access; 
# 140
public: permutation_iterator() : m_element_iterator() 
# 141
{ } 
# 151
explicit permutation_iterator(ElementIterator x, IndexIterator y) : super_t(y), m_element_iterator(x) 
# 152
{ } 
# 157
template< class OtherElementIterator, class OtherIndexIterator> 
# 159
permutation_iterator(const ::thrust::permutation_iterator< OtherElementIterator, OtherIndexIterator>  &r, typename ::thrust::detail::enable_if_convertible< OtherElementIterator, ElementIterator> ::type * = 0, typename ::thrust::detail::enable_if_convertible< OtherIndexIterator, IndexIterator> ::type * = 0) : super_t((r.base())), m_element_iterator((r.m_element_iterator)) 
# 165
{ } 
# 172
private: typename ::thrust::detail::permutation_iterator_base< ElementIterator, IndexIterator> ::type::reference dereference() const 
# 173
{ 
# 174
return *((m_element_iterator) + (*(this->base()))); 
# 175
} 
# 178
template< class , class > friend class permutation_iterator; 
# 180
ElementIterator m_element_iterator; 
# 183
}; 
# 196
template< class ElementIterator, class IndexIterator> permutation_iterator< ElementIterator, IndexIterator>  
# 198
make_permutation_iterator(ElementIterator e, IndexIterator i) 
# 199
{ 
# 200
return permutation_iterator< ElementIterator, IndexIterator> (e, i); 
# 201
} 
# 209
}
# 25 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/gather.hpp"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 26
namespace bulk_ { 
# 31
template< std::size_t bound, std::size_t 
# 32
grainsize, class 
# 33
RandomAccessIterator1, class 
# 34
RandomAccessIterator2, class 
# 35
RandomAccessIterator3> 
# 36
__attribute((always_inline)) __attribute__((unused)) inline RandomAccessIterator3 
# 37
gather(const bounded< bound, agent< grainsize> >  &, RandomAccessIterator1 
# 38
map_first, RandomAccessIterator1 
# 39
map_last, RandomAccessIterator2 
# 40
input_first, RandomAccessIterator3 
# 41
result) 
# 42
{int volatile ___ = 1;(void)map_first;(void)map_last;(void)input_first;(void)result;
# 66
::exit(___);}
#if 0
# 42
{ 
# 43
typedef typename bounded< bound, agent< grainsize> > ::size_type size_type; 
# 45
size_type n = map_last - map_first; 
# 47
if (bound <= n) 
# 48
{ 
# 49
for (size_type i = (0); i < bound; ++i) 
# 50
{ 
# 51
(result[i]) = (input_first[map_first[i]]); 
# 52
}  
# 53
} else 
# 55
{ 
# 56
for (size_type i = (0); i < bound; ++i) 
# 57
{ 
# 58
if (i < n) 
# 59
{ 
# 60
(result[i]) = (input_first[map_first[i]]); 
# 61
}  
# 62
}  
# 63
}  
# 65
return result + n; 
# 66
} 
#endif
# 69 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/gather.hpp"
template< class ExecutionGroup, class RandomAccessIterator1, class RandomAccessIterator2, class RandomAccessIterator3> 
# 70
__attribute((always_inline)) __attribute__((unused)) inline RandomAccessIterator3 
# 71
gather(ExecutionGroup &g, RandomAccessIterator1 
# 72
map_first, RandomAccessIterator1 
# 73
map_last, RandomAccessIterator2 
# 74
input_first, RandomAccessIterator3 
# 75
result) 
# 76
{int volatile ___ = 1;(void)g;(void)map_first;(void)map_last;(void)input_first;(void)result;
# 81
::exit(___);}
#if 0
# 76
{ 
# 77
return bulk_::copy_n(g, thrust::make_permutation_iterator(input_first, map_first), map_last - map_first, result); 
# 81
} 
#endif
# 84 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/gather.hpp"
}
# 85
}}}}
# 24 "/usr/local/cuda-8.0/include/thrust/detail/numeric_traits.h"
namespace thrust { 
# 27
namespace detail { 
# 31
typedef long long intmax_t; 
# 33
template< class Number> 
# 34
struct is_signed : public integral_constant< bool, std::numeric_limits< Number> ::is_signed>  { 
# 36
}; 
# 39
template< class T> 
# 40
struct num_digits : public eval_if< std::numeric_limits< T> ::is_specialized, integral_constant< int, std::numeric_limits< T> ::digits> , integral_constant< int, (sizeof(T) * std::numeric_limits< unsigned char> ::digits) - ((is_signed< T> ::value) ? 1 : 0)> > ::type { 
# 52
}; 
# 55
template< class Integer> 
# 56
struct integer_difference { 
# 75
private: 
# 74
template< bool x, bool y> 
# 75
struct and_ { 
# 77
static const bool value = false; 
# 78
}; 
# 80
template< bool y> 
# 81
struct and_< true, y>  { 
# 83
static const bool value = y; 
# 84
}; 
# 104
public: typedef typename eval_if< and_< std::numeric_limits< Integer> ::is_signed, (!std::numeric_limits< Integer> ::is_bounded) || ((((int)std::numeric_limits< Integer> ::digits) + 1) >= integral_constant< int, 63> ::value)> ::value, identity_< Integer> , eval_if< (((int)std::numeric_limits< Integer> ::digits) + 1) < integral_constant< int, 31> ::value, identity_< signed int> , eval_if< (((int)std::numeric_limits< Integer> ::digits) + 1) < integral_constant< int, 63> ::value, identity_< signed long> , identity_< long long> > > > ::type type; 
# 105
}; 
# 108
template< class Number> 
# 109
struct numeric_difference : public eval_if< is_integral< Number> ::value, integer_difference< Number> , identity_< Number> >  { 
# 115
}; 
# 118
template< class Number> typename numeric_difference< Number> ::type 
# 121
numeric_distance(Number x, Number y) 
# 122
{ 
# 123
typedef typename numeric_difference< Number> ::type difference_type; 
# 124
return ((difference_type)y) - ((difference_type)x); 
# 125
} 
# 127
}
# 129
}
# 25 "/usr/local/cuda-8.0/include/thrust/iterator/detail/counting_iterator.inl"
namespace thrust { 
# 29
template< class Incrementable, class System, class Traversal, class Difference> class counting_iterator; 
# 32
namespace detail { 
# 35
template< class Incrementable, class System, class Traversal, class Difference> 
# 36
struct counting_iterator_base { 
# 43
typedef typename eval_if< is_same< System, use_default> ::value, identity_< any_system_tag> , identity_< System> > ::type system; 
# 52
typedef typename ia_dflt_help< Traversal, eval_if< is_numeric< Incrementable> ::value, identity_< random_access_traversal_tag> , iterator_traversal< Incrementable> > > ::type traversal; 
# 67
typedef typename ia_dflt_help< Difference, eval_if< is_numeric< Incrementable> ::value, eval_if< is_integral< Incrementable> ::value, numeric_difference< Incrementable> , identity_< signed long> > , iterator_difference< Incrementable> > > ::type difference; 
# 81
typedef iterator_adaptor< counting_iterator< Incrementable, System, Traversal, Difference> , Incrementable, Incrementable, typename eval_if< is_same< System, use_default> ::value, identity_< any_system_tag> , identity_< System> > ::type, typename ia_dflt_help< Traversal, eval_if< is_numeric< Incrementable> ::value, identity_< random_access_traversal_tag> , iterator_traversal< Incrementable> > > ::type, Incrementable, typename ia_dflt_help< Difference, eval_if< is_numeric< Incrementable> ::value, eval_if< is_integral< Incrementable> ::value, numeric_difference< Incrementable> , identity_< signed long> > , iterator_difference< Incrementable> > > ::type>  type; 
# 82
}; 
# 85
template< class Difference, class Incrementable1, class Incrementable2> 
# 86
struct iterator_distance { 
# 89
static Difference distance(Incrementable1 x, Incrementable2 y) 
# 90
{ 
# 91
return y - x; 
# 92
} 
# 93
}; 
# 96
template< class Difference, class Incrementable1, class Incrementable2> 
# 97
struct number_distance { 
# 100
static Difference distance(Incrementable1 x, Incrementable2 y) 
# 101
{ 
# 102
return static_cast< Difference>(numeric_distance(x, y)); 
# 103
} 
# 104
}; 
# 107
template< class Difference, class Incrementable1, class Incrementable2, class Enable = void> 
# 108
struct counting_iterator_equal { 
# 111
static bool equal(Incrementable1 x, Incrementable2 y) 
# 112
{ 
# 113
return x == y; 
# 114
} 
# 115
}; 
# 119
template< class Difference, class Incrementable1, class Incrementable2> 
# 120
struct counting_iterator_equal< Difference, Incrementable1, Incrementable2, typename enable_if< is_floating_point< Incrementable1> ::value || is_floating_point< Incrementable2> ::value> ::type>  { 
# 131
static bool equal(Incrementable1 x, Incrementable2 y) 
# 132
{ 
# 133
typedef number_distance< Difference, Incrementable1, Incrementable2>  d; 
# 134
return d::distance(x, y) == 0; 
# 135
} 
# 136
}; 
# 139
}
# 140
}
# 42 "/usr/local/cuda-8.0/include/thrust/iterator/counting_iterator.h"
namespace thrust { 
# 128
template< class Incrementable, class 
# 129
System = use_default, class 
# 130
Traversal = use_default, class 
# 131
Difference = use_default> 
# 132
class counting_iterator : public detail::counting_iterator_base< Incrementable, System, Traversal, Difference> ::type { 
# 137
typedef typename ::thrust::detail::counting_iterator_base< Incrementable, System, Traversal, Difference> ::type super_t; 
# 139
friend class iterator_core_access; 
# 142
public: typedef typename ::thrust::detail::counting_iterator_base< Incrementable, System, Traversal, Difference> ::type::reference reference; 
# 143
typedef typename ::thrust::detail::counting_iterator_base< Incrementable, System, Traversal, Difference> ::type::difference_type difference_type; 
# 152
counting_iterator() { } 
# 160
counting_iterator(const counting_iterator &rhs) : super_t((rhs.base())) { } 
# 167
template< class OtherSystem> 
# 169
counting_iterator(const ::thrust::counting_iterator< Incrementable, OtherSystem, Traversal, Difference>  &rhs, typename ::thrust::detail::enable_if_convertible< typename iterator_system< ::thrust::counting_iterator< Incrementable, OtherSystem, Traversal, Difference> > ::type, typename iterator_system< typename ::thrust::detail::counting_iterator_base< Incrementable, System, Traversal, Difference> ::type> ::type> ::type * = 0) : super_t((rhs.base())) 
# 174
{ } 
# 183
explicit counting_iterator(Incrementable x) : super_t(x) { } 
# 189
private: reference dereference() const 
# 190
{ 
# 191
return (this->base_reference()); 
# 192
} 
# 195
template< class OtherIncrementable, class OtherSystem, class OtherTraversal, class OtherDifference> bool 
# 197
equal(const ::thrust::counting_iterator< OtherIncrementable, OtherSystem, OtherTraversal, OtherDifference>  &y) const 
# 198
{ 
# 199
typedef ::thrust::detail::counting_iterator_equal< typename ::thrust::detail::counting_iterator_base< Incrementable, System, Traversal, Difference> ::type::difference_type, Incrementable, OtherIncrementable>  e; 
# 200
return e::equal((this->base()), (y.base())); 
# 201
} 
# 203
template< class OtherIncrementable> difference_type 
# 206
distance_to(const ::thrust::counting_iterator< OtherIncrementable, System, Traversal, Difference>  &y) const 
# 207
{ 
# 213
typedef typename ::thrust::detail::eval_if< ::thrust::detail::is_numeric< Incrementable> ::value, ::thrust::detail::identity_< ::thrust::detail::number_distance< typename ::thrust::detail::counting_iterator_base< Incrementable, System, Traversal, Difference> ::type::difference_type, Incrementable, OtherIncrementable> > , ::thrust::detail::identity_< ::thrust::detail::iterator_distance< typename ::thrust::detail::counting_iterator_base< Incrementable, System, Traversal, Difference> ::type::difference_type, Incrementable, OtherIncrementable> > > ::type d; 
# 215
return d::distance((this->base()), (y.base())); 
# 216
} 
# 220
}; 
# 229
template< class Incrementable> inline counting_iterator< Incrementable>  
# 231
make_counting_iterator(Incrementable x) 
# 232
{ 
# 233
return ((counting_iterator< Incrementable> )(x)); 
# 234
} 
# 242
}
# 26 "/usr/local/cuda-8.0/include/thrust/iterator/detail/join_iterator.h"
namespace thrust { 
# 28
namespace detail { 
# 32
template< class RandomAccessIterator1, class 
# 33
RandomAccessIterator2, class 
# 34
Difference, class 
# 35
Reference> class join_iterator; 
# 39
namespace join_iterator_detail { 
# 43
template< class RandomAccessIterator1, class 
# 44
RandomAccessIterator2, class 
# 45
Difference, class 
# 46
Reference> 
# 47
struct join_iterator_base { 
# 49
typedef typename remove_reference< Reference> ::type value_type; 
# 51
typedef typename iterator_system< RandomAccessIterator1> ::type system1; 
# 52
typedef typename iterator_system< RandomAccessIterator2> ::type system2; 
# 53
typedef typename minimum_system< typename iterator_system< RandomAccessIterator1> ::type, typename iterator_system< RandomAccessIterator2> ::type> ::type system; 
# 63
typedef iterator_adaptor< join_iterator< RandomAccessIterator1, RandomAccessIterator2, Difference, Reference> , counting_iterator< Difference> , typename remove_reference< Reference> ::type, typename minimum_system< typename iterator_system< RandomAccessIterator1> ::type, typename iterator_system< RandomAccessIterator2> ::type> ::type, random_access_traversal_tag, Reference, Difference>  type; 
# 64
}; 
# 67
}
# 70
template< class RandomAccessIterator1, class 
# 71
RandomAccessIterator2, class 
# 72
Difference = typename iterator_difference< RandomAccessIterator1> ::type, class 
# 73
Reference = typename iterator_value< RandomAccessIterator1> ::type> 
# 74
class join_iterator : public join_iterator_detail::join_iterator_base< RandomAccessIterator1, RandomAccessIterator2, Difference, Reference> ::type { 
# 78
typedef typename ::thrust::detail::join_iterator_detail::join_iterator_base< RandomAccessIterator1, RandomAccessIterator2, Difference, Reference> ::type super_t; 
# 79
typedef typename ::thrust::detail::join_iterator_detail::join_iterator_base< RandomAccessIterator1, RandomAccessIterator2, Difference, Reference> ::type::difference_type size_type; 
# 83
public: join_iterator(RandomAccessIterator1 first1, size_type n, RandomAccessIterator2 first2) : super_t(((counting_iterator< typename ::thrust::detail::join_iterator_detail::join_iterator_base< RandomAccessIterator1, RandomAccessIterator2, Difference, Reference> ::type::difference_type> )(0))), m_n1(n), m_iter1(first1), m_iter2(first2 - (m_n1)) 
# 88
{ } 
# 92
join_iterator(const join_iterator &other) : super_t(other), m_n1(other.m_n1), m_iter1(other.m_iter1), m_iter2(other.m_iter2) 
# 97
{ } 
# 101
friend class ::thrust::iterator_core_access; 
# 105
private: typename ::thrust::detail::join_iterator_detail::join_iterator_base< RandomAccessIterator1, RandomAccessIterator2, Difference, Reference> ::type::reference dereference() const 
# 106
{ 
# 107
size_type i = *super_t::base(); 
# 108
return (i < (m_n1)) ? (m_iter1)[i] : (static_cast< typename ::thrust::detail::join_iterator_detail::join_iterator_base< RandomAccessIterator1, RandomAccessIterator2, Difference, Reference> ::type::reference>((m_iter2)[i])); 
# 109
} 
# 112
size_type m_n1; 
# 113
RandomAccessIterator1 m_iter1; 
# 114
RandomAccessIterator2 m_iter2; 
# 115
}; 
# 118
template< class RandomAccessIterator1, class Size, class RandomAccessIterator2> join_iterator< RandomAccessIterator1, RandomAccessIterator2, Size>  
# 120
make_join_iterator(RandomAccessIterator1 first1, Size n1, RandomAccessIterator2 first2) 
# 121
{ 
# 122
return join_iterator< RandomAccessIterator1, RandomAccessIterator2, Size> (first1, n1, first2); 
# 123
} 
# 126
}
# 127
}
# 30 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/merge.hpp"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 31
namespace bulk_ { 
# 35
template< class RandomAccessIterator1, class Size, class RandomAccessIterator2, class Compare> __attribute__((unused)) Size 
# 37
merge_path(RandomAccessIterator1 first1, Size n1, RandomAccessIterator2 
# 38
first2, Size n2, Size 
# 39
diag, Compare 
# 40
comp) 
# 41
{int volatile ___ = 1;(void)first1;(void)n1;(void)first2;(void)n2;(void)diag;(void)comp;
# 60
::exit(___);}
#if 0
# 41
{ 
# 42
Size begin = thrust::max< Size> ((Size)0, diag - n2); 
# 43
Size end = thrust::min< Size> (diag, n1); 
# 45
while (begin < end) 
# 46
{ 
# 47
Size mid = (begin + end) >> 1; 
# 49
if (comp(first2[(diag - 1) - mid], first1[mid])) 
# 50
{ 
# 51
end = mid; 
# 52
} else 
# 54
{ 
# 55
begin = (mid + 1); 
# 56
}  
# 57
}  
# 59
return begin; 
# 60
} 
#endif
# 63 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/merge.hpp"
template< std::size_t bound, std::size_t 
# 64
grainsize, class 
# 65
InputIterator1, class 
# 66
InputIterator2, class 
# 67
OutputIterator, class 
# 68
Compare> __attribute__((unused)) OutputIterator 
# 70
merge(const bounded< bound, agent< grainsize> >  &e, InputIterator1 
# 71
first1, InputIterator1 last1, InputIterator2 
# 72
first2, InputIterator2 last2, OutputIterator 
# 73
result, Compare 
# 74
comp) 
# 75
{int volatile ___ = 1;(void)e;(void)first1;(void)last1;(void)first2;(void)last2;(void)result;(void)comp;
# 170
::exit(___);}
#if 0
# 75
{ 
# 76
typedef typename bounded< bound, agent< grainsize> > ::size_type size_type; 
# 78
typedef typename iterator_value< InputIterator1> ::type value_type1; 
# 79
typedef typename iterator_value< InputIterator2> ::type value_type2; 
# 81
size_type n = (last1 - first1) + (last2 - first2); 
# 85
value_type1 key_a; 
# 86
size_type n1 = last1 - first1; 
# 87
size_type idx1 = (0); 
# 89
if (n1 > 0) 
# 90
{ 
# 92
key_a = (first1[idx1]); 
# 93
}  
# 96
value_type2 key_b; 
# 97
size_type n2 = last2 - first2; 
# 98
size_type idx2 = (0); 
# 100
if (n2 > 0) 
# 101
{ 
# 103
key_b = (first2[idx2]); 
# 104
}  
# 107
if (bound <= n) 
# 108
{ 
# 109
for (size_type i = (0); i < grainsize; ++i) 
# 110
{ 
# 111
bool p = (idx2 >= n2) || ((idx1 < n1) && (!comp(key_b, key_a))); 
# 113
(result[i]) = (p ? key_a : key_b); 
# 115
if (p) 
# 116
{ 
# 117
++idx1; 
# 120
key_a = (first1[min(idx1, n1 - 1)]); 
# 121
} else 
# 123
{ 
# 124
++idx2; 
# 127
key_b = (first2[min(idx2, n2 - 1)]); 
# 128
}  
# 129
}  
# 130
} else 
# 132
{ 
# 133
for (size_type i = (0); i < grainsize; ++i) 
# 134
{ 
# 135
if (i < n) 
# 136
{ 
# 137
bool p = (idx2 >= n2) || ((idx1 < n1) && (!comp(key_b, key_a))); 
# 139
(result[i]) = (p ? key_a : key_b); 
# 141
if (p) 
# 142
{ 
# 143
++idx1; 
# 146
key_a = (first1[min(idx1, n1 - 1)]); 
# 147
} else 
# 149
{ 
# 150
++idx2; 
# 153
key_b = (first2[min(idx2, n2 - 1)]); 
# 154
}  
# 155
}  
# 156
}  
# 157
}  
# 169
return result + n; 
# 170
} 
#endif
# 173 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/merge.hpp"
template< std::size_t bound, std::size_t grainsize, class 
# 174
RandomAccessIterator1, class 
# 175
RandomAccessIterator2, class 
# 176
RandomAccessIterator3, class 
# 177
RandomAccessIterator4, class 
# 178
RandomAccessIterator5, class 
# 179
RandomAccessIterator6, class 
# 180
Compare> __attribute__((unused)) pair< RandomAccessIterator5, RandomAccessIterator6>  
# 183
merge_by_key(const bounded< bound, agent< grainsize> >  &, RandomAccessIterator1 
# 184
keys_first1, RandomAccessIterator1 keys_last1, RandomAccessIterator2 
# 185
keys_first2, RandomAccessIterator2 keys_last2, RandomAccessIterator3 
# 186
values_first1, RandomAccessIterator4 
# 187
values_first2, RandomAccessIterator5 
# 188
keys_result, RandomAccessIterator6 
# 189
values_result, Compare 
# 190
comp) 
# 191
{int volatile ___ = 1;(void)keys_first1;(void)keys_last1;(void)keys_first2;(void)keys_last2;(void)values_first1;(void)values_first2;(void)keys_result;(void)values_result;(void)comp;
# 305
::exit(___);}
#if 0
# 191
{ 
# 192
typedef typename bounded< bound, agent< grainsize> > ::size_type size_type; 
# 194
typedef typename iterator_value< RandomAccessIterator1> ::type key_type1; 
# 195
typedef typename iterator_value< RandomAccessIterator2> ::type key_type2; 
# 197
typedef typename iterator_value< RandomAccessIterator3> ::type value_type1; 
# 198
typedef typename iterator_value< RandomAccessIterator4> ::type value_type2; 
# 200
size_type n = (keys_last1 - keys_first1) + (keys_last2 - keys_first2); 
# 205
key_type1 key_a; 
# 206
value_type1 val_a; 
# 207
size_type n1 = keys_last1 - keys_first1; 
# 208
size_type idx1 = (0); 
# 210
if (n1 > 0) 
# 211
{ 
# 214
key_a = (keys_first1[idx1]); 
# 215
val_a = (values_first1[idx1]); 
# 216
}  
# 220
key_type2 key_b; 
# 221
value_type2 val_b; 
# 222
size_type n2 = keys_last2 - keys_first2; 
# 223
size_type idx2 = (0); 
# 225
if (n2 > 0) 
# 226
{ 
# 229
key_b = (keys_first2[idx2]); 
# 230
val_b = (values_first2[idx2]); 
# 231
}  
# 234
if (bound <= n) 
# 235
{ 
# 236
for (size_type i = (0); i < grainsize; ++i) 
# 237
{ 
# 238
bool p = (idx2 >= n2) || ((idx1 < n1) && (!comp(key_b, key_a))); 
# 240
(keys_result[i]) = (p ? key_a : key_b); 
# 241
(values_result[i]) = (p ? val_a : val_b); 
# 243
if (p) 
# 244
{ 
# 245
++idx1; 
# 248
key_a = (keys_first1[min(idx1, n1 - 1)]); 
# 249
val_a = (values_first1[min(idx1, n1 - 1)]); 
# 250
} else 
# 252
{ 
# 253
++idx2; 
# 256
key_b = (keys_first2[min(idx2, n2 - 1)]); 
# 257
val_b = (values_first2[min(idx2, n2 - 1)]); 
# 258
}  
# 259
}  
# 260
} else 
# 262
{ 
# 263
for (size_type i = (0); i < grainsize; ++i) 
# 264
{ 
# 265
if (i < n) 
# 266
{ 
# 267
bool p = (idx2 >= n2) || ((idx1 < n1) && (!comp(key_b, key_a))); 
# 269
(keys_result[i]) = (p ? key_a : key_b); 
# 270
(values_result[i]) = (p ? val_a : val_b); 
# 272
if (p) 
# 273
{ 
# 274
++idx1; 
# 277
key_a = (keys_first1[min(idx1, n1 - 1)]); 
# 278
val_a = (values_first1[min(idx1, n1 - 1)]); 
# 279
} else 
# 281
{ 
# 282
++idx2; 
# 285
key_b = (keys_first2[min(idx2, n2 - 1)]); 
# 286
val_b = (values_first2[min(idx2, n2 - 1)]); 
# 287
}  
# 288
}  
# 289
}  
# 290
}  
# 304
return thrust::make_pair(keys_result + n, values_result + n); 
# 305
} 
#endif
# 308 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/merge.hpp"
template< std::size_t bound, std::size_t groupsize, std::size_t grainsize, class RandomAccessIterator, class Compare> __attribute__((unused)) typename thrust::detail::enable_if< bound <= (groupsize * grainsize)> ::type 
# 313
inplace_merge(bounded< bound, concurrent_group< agent< grainsize> , groupsize> >  &
# 319
g, RandomAccessIterator 
# 320
first, RandomAccessIterator middle, RandomAccessIterator last, Compare 
# 321
comp) 
# 322
{int volatile ___ = 1;(void)g;(void)first;(void)middle;(void)last;(void)comp;
# 353
::exit(___);}
#if 0
# 322
{ 
# 323
typedef typename concurrent_group< agent< grainsize> , groupsize> ::size_type size_type; 
# 325
size_type n1 = middle - first; 
# 326
size_type n2 = last - middle; 
# 329
size_type local_offset = grainsize * ((g.this_exec).index()); 
# 331
size_type mp = bulk_::merge_path(first, n1, middle, n2, local_offset, comp); 
# 334
size_type local_offset1 = mp; 
# 335
size_type local_offset2 = (n1 + local_offset) - mp; 
# 337
typedef typename iterator_value< RandomAccessIterator> ::type value_type; 
# 338
value_type local_result[grainsize]; 
# 339
bulk_::merge(bulk_::bound< grainsize> ((g.this_exec)), first + local_offset1, middle, first + local_offset2, last, local_result, comp); 
# 345
(g.wait()); 
# 349
size_type local_size = thrust::max< typename concurrent_group< agent< grainsize> , groupsize> ::size_type> (0, thrust::min< typename concurrent_group< agent< grainsize> , groupsize> ::size_type> (grainsize, (n1 + n2) - local_offset)); 
# 350
bulk_::copy_n(bulk_::bound< grainsize> ((g.this_exec)), local_result, local_size, first + local_offset); 
# 352
(g.wait()); 
# 353
} 
#endif
# 356 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/merge.hpp"
template< std::size_t bound, std::size_t groupsize, std::size_t grainsize, class 
# 357
RandomAccessIterator1, class 
# 358
RandomAccessIterator2, class 
# 359
RandomAccessIterator3, class 
# 360
Compare> __attribute__((unused)) typename thrust::detail::enable_if< bound <= (groupsize * grainsize), RandomAccessIterator3> ::type 
# 366
merge(bounded< bound, concurrent_group< agent< grainsize> , groupsize> >  &
# 372
g, RandomAccessIterator1 
# 373
first1, RandomAccessIterator1 last1, RandomAccessIterator2 
# 374
first2, RandomAccessIterator2 last2, RandomAccessIterator3 
# 375
result, Compare 
# 376
comp) 
# 377
{int volatile ___ = 1;(void)g;(void)first1;(void)last1;(void)first2;(void)last2;(void)result;(void)comp;
# 408
::exit(___);}
#if 0
# 377
{ 
# 378
typedef typename concurrent_group< agent< grainsize> , groupsize> ::size_type size_type; 
# 380
size_type n1 = last1 - first1; 
# 381
size_type n2 = last2 - first2; 
# 384
size_type local_offset = grainsize * ((g.this_exec).index()); 
# 386
size_type mp = bulk_::merge_path(first1, n1, first2, n2, local_offset, comp); 
# 389
size_type local_offset1 = mp; 
# 390
size_type local_offset2 = local_offset - mp; 
# 392
typedef typename iterator_value< RandomAccessIterator3> ::type value_type; 
# 393
value_type local_result[grainsize]; 
# 394
bulk_::merge(bulk_::bound< grainsize> ((g.this_exec)), first1 + local_offset1, last1, first2 + local_offset2, last2, local_result, comp); 
# 402
size_type local_size = thrust::max< typename concurrent_group< agent< grainsize> , groupsize> ::size_type> (0, thrust::min< typename concurrent_group< agent< grainsize> , groupsize> ::size_type> (grainsize, (n1 + n2) - local_offset)); 
# 403
bulk_::copy_n(bulk_::bound< grainsize> ((g.this_exec)), local_result, local_size, result + local_offset); 
# 405
(g.wait()); 
# 407
return result + thrust::min< typename concurrent_group< agent< grainsize> , groupsize> ::size_type> (groupsize * grainsize, n1 + n2); 
# 408
} 
#endif
# 411 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/merge.hpp"
namespace detail { 
# 413
namespace merge_detail { 
# 418
template< std::size_t groupsize, std::size_t grainsize, class RandomAccessIterator1, class RandomAccessIterator2, class RandomAccessIterator3, class RandomAccessIterator4, class Compare> __attribute__((unused)) RandomAccessIterator4 
# 421
bounded_merge_with_buffer(concurrent_group< agent< grainsize> , groupsize>  &exec, RandomAccessIterator1 
# 422
first1, RandomAccessIterator1 last1, RandomAccessIterator2 
# 423
first2, RandomAccessIterator2 last2, RandomAccessIterator3 
# 424
buffer, RandomAccessIterator4 
# 425
result, Compare 
# 426
comp) 
# 427
{int volatile ___ = 1;(void)exec;(void)first1;(void)last1;(void)first2;(void)last2;(void)buffer;(void)result;(void)comp;
# 447
::exit(___);}
#if 0
# 427
{ 
# 428
typedef typename concurrent_group< agent< grainsize> , groupsize> ::size_type size_type; 
# 430
size_type n1 = last1 - first1; 
# 431
size_type n2 = last2 - first2; 
# 434
bulk_::copy_n(bulk_::bound< groupsize * grainsize> (exec), thrust::detail::make_join_iterator(first1, n1, first2), n1 + n2, buffer); 
# 440
bulk_::inplace_merge(bulk_::bound< groupsize * grainsize> (exec), buffer, buffer + n1, (buffer + n1) + n2, comp); 
# 446
return bulk_::copy_n(exec, buffer, n1 + n2, result); 
# 447
} 
#endif
# 450 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/merge.hpp"
}
# 451
}
# 454
template< std::size_t groupsize, std::size_t grainsize, class RandomAccessIterator1, class RandomAccessIterator2, class RandomAccessIterator3, class Compare> __attribute__((unused)) RandomAccessIterator3 
# 456
merge(concurrent_group< agent< grainsize> , groupsize>  &exec, RandomAccessIterator1 
# 457
first1, RandomAccessIterator1 last1, RandomAccessIterator2 
# 458
first2, RandomAccessIterator2 last2, RandomAccessIterator3 
# 459
result, Compare 
# 460
comp) 
# 461
{int volatile ___ = 1;(void)exec;(void)first1;(void)last1;(void)first2;(void)last2;(void)result;(void)comp;
# 504
::exit(___);}
#if 0
# 461
{ 
# 462
typedef typename concurrent_group< agent< grainsize> , groupsize> ::size_type size_type; 
# 464
typedef typename iterator_value< RandomAccessIterator3> ::type value_type; 
# 466
value_type *buffer = reinterpret_cast< value_type *>(bulk_::malloc(exec, ((exec.size()) * (exec.grainsize())) * sizeof(value_type))); 
# 468
size_type chunk_size = (exec.size()) * ((exec.this_exec).grainsize()); 
# 470
size_type n1 = last1 - first1; 
# 471
size_type n2 = last2 - first2; 
# 474
if ((n1 + n2) <= chunk_size) 
# 475
{ 
# 476
result = detail::merge_detail::bounded_merge_with_buffer(exec, first1, last1, first2, last2, buffer, result, comp); 
# 477
} else 
# 479
{ 
# 480
while ((first1 < last1) || (first2 < last2)) 
# 481
{ 
# 482
size_type n1 = last1 - first1; 
# 483
size_type n2 = last2 - first2; 
# 485
size_type diag = thrust::min< typename concurrent_group< agent< grainsize> , groupsize> ::size_type> (chunk_size, n1 + n2); 
# 487
size_type mp = bulk_::merge_path(first1, n1, first2, n2, diag, comp); 
# 489
result = detail::merge_detail::bounded_merge_with_buffer(exec, first1, first1 + mp, first2, (first2 + diag) - mp, buffer, result, comp); 
# 496
first1 += mp; 
# 497
first2 += (diag - mp); 
# 498
}  
# 499
}  
# 501
bulk_::free(exec, buffer); 
# 503
return result; 
# 504
} 
#endif
# 507 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/merge.hpp"
template< std::size_t groupsize, std::size_t grainsize, class 
# 508
RandomAccessIterator1, class 
# 509
RandomAccessIterator2, class 
# 510
RandomAccessIterator3, class 
# 511
RandomAccessIterator4, class 
# 512
RandomAccessIterator5, class 
# 513
RandomAccessIterator6, class 
# 514
Compare> __attribute__((unused)) pair< RandomAccessIterator5, RandomAccessIterator6>  
# 517
merge_by_key(bounded< groupsize * grainsize, concurrent_group< agent< grainsize> , groupsize> >  &
# 520
g, RandomAccessIterator1 
# 521
keys_first1, RandomAccessIterator1 keys_last1, RandomAccessIterator2 
# 522
keys_first2, RandomAccessIterator2 keys_last2, RandomAccessIterator3 
# 523
values_first1, RandomAccessIterator4 
# 524
values_first2, RandomAccessIterator5 
# 525
keys_result, RandomAccessIterator6 
# 526
values_result, Compare 
# 527
comp) 
# 528
{int volatile ___ = 1;(void)g;(void)keys_first1;(void)keys_last1;(void)keys_first2;(void)keys_last2;(void)values_first1;(void)values_first2;(void)keys_result;(void)values_result;(void)comp;
# 607
::exit(___);}
#if 0
# 528
{ 
# 529
typedef typename concurrent_group< agent< grainsize> , groupsize> ::size_type size_type; 
# 531
typedef typename iterator_value< RandomAccessIterator5> ::type key_type; 
# 546
__attribute__((unused)) static 
# 543
union { 
# 544
key_type keys[groupsize * grainsize]; 
# 545
size_type indices[groupsize * grainsize]; 
# 546
} stage; 
# 549
size_type n1 = keys_last1 - keys_first1; 
# 550
size_type n2 = keys_last2 - keys_first2; 
# 551
size_type n = n1 + n2; 
# 554
bulk_::copy_n(g, thrust::detail::make_join_iterator(keys_first1, n1, keys_first2), n, stage.keys); 
# 560
size_type diag = thrust::min< typename concurrent_group< agent< grainsize> , groupsize> ::size_type> (n1 + n2, grainsize * ((g.this_exec).index())); 
# 561
size_type mp = bulk_::merge_path(stage.keys, n1, (stage.keys) + n1, n2, diag, comp); 
# 564
size_type start1 = mp; 
# 565
size_type start2 = (n1 + diag) - mp; 
# 567
size_type end1 = n1; 
# 568
size_type end2 = n1 + n2; 
# 571
key_type results[grainsize]; 
# 572
size_type indices[grainsize]; 
# 573
bulk_::merge_by_key(bulk_::bound< grainsize> ((g.this_exec)), (stage.keys) + start1, (stage.keys) + end1, (stage.keys) + start2, (stage.keys) + end2, thrust::make_counting_iterator< typename concurrent_group< agent< grainsize> , groupsize> ::size_type> (start1), thrust::make_counting_iterator< typename concurrent_group< agent< grainsize> , groupsize> ::size_type> (start2), results, indices, comp); 
# 581
(g.wait()); 
# 584
size_type local_offset = grainsize * ((g.this_exec).index()); 
# 585
size_type local_size = thrust::max< typename concurrent_group< agent< grainsize> , groupsize> ::size_type> (0, thrust::min< typename concurrent_group< agent< grainsize> , groupsize> ::size_type> (grainsize, n - local_offset)); 
# 586
bulk_::copy_n(bulk_::bound< grainsize> ((g.this_exec)), results, local_size, (stage.keys) + local_offset); 
# 587
(g.wait()); 
# 590
keys_result = bulk_::copy_n(g, stage.keys, n, keys_result); 
# 593
bulk_::copy_n(bulk_::bound< grainsize> ((g.this_exec)), indices, local_size, (stage.indices) + local_offset); 
# 594
(g.wait()); 
# 597
values_result = bulk_::gather(g, stage.indices, (stage.indices) + n, thrust::detail::make_join_iterator(values_first1, n1, values_first2), values_result); 
# 606
return thrust::make_pair(keys_result, values_result); 
# 607
} 
#endif
# 610 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/merge.hpp"
}
# 611
}}}}
# 22 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/scatter.hpp"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 23
namespace bulk_ { 
# 27
template< std::size_t bound, std::size_t 
# 28
grainsize, class 
# 29
RandomAccessIterator1, class 
# 30
RandomAccessIterator2, class 
# 31
RandomAccessIterator3, class 
# 32
RandomAccessIterator4> 
# 33
__attribute((always_inline)) __attribute__((unused)) inline void 
# 34
scatter_if(const bounded< bound, agent< grainsize> >  &exec, RandomAccessIterator1 
# 35
first, RandomAccessIterator1 
# 36
last, RandomAccessIterator2 
# 37
map, RandomAccessIterator3 
# 38
stencil, RandomAccessIterator4 
# 39
result) 
# 40
{int volatile ___ = 1;(void)exec;(void)first;(void)last;(void)map;(void)stencil;(void)result;
# 52
::exit(___);}
#if 0
# 40
{ 
# 41
typedef int size_type; 
# 43
size_type n = last - first; 
# 45
for (size_type i = 0; i < bound; ++i) 
# 46
{ 
# 47
if ((i < n) && (stencil[i])) 
# 48
{ 
# 49
(result[map[i]]) = (first[i]); 
# 50
}  
# 51
}  
# 52
} 
#endif
# 55 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/scatter.hpp"
template< std::size_t bound, std::size_t 
# 56
groupsize, std::size_t 
# 57
grainsize, class 
# 58
RandomAccessIterator1, class 
# 59
RandomAccessIterator2, class 
# 60
RandomAccessIterator3, class 
# 61
RandomAccessIterator4> __attribute__((unused)) typename thrust::detail::enable_if< bound <= (groupsize * grainsize)> ::type 
# 66
scatter_if(bounded< bound, concurrent_group< agent< grainsize> , groupsize> >  &
# 69
g, RandomAccessIterator1 
# 70
first, RandomAccessIterator1 
# 71
last, RandomAccessIterator2 
# 72
map, RandomAccessIterator3 
# 73
stencil, RandomAccessIterator4 
# 74
result) 
# 75
{int volatile ___ = 1;(void)g;(void)first;(void)last;(void)map;(void)stencil;(void)result;
# 112
::exit(___);}
#if 0
# 75
{ 
# 79
typedef typename bounded< bound, concurrent_group< agent< grainsize> , groupsize> > ::size_type size_type; 
# 81
size_type n = last - first; 
# 83
size_type tid = ((g.this_exec).index()); 
# 86
if (n == bound) 
# 87
{ 
# 88
for (size_type i = (0); i < ((g.this_exec).grainsize()); ++i) 
# 89
{ 
# 90
size_type idx = ((g.size()) * i) + tid; 
# 92
if (stencil[idx]) 
# 93
{ 
# 94
(result[map[idx]]) = (first[idx]); 
# 95
}  
# 96
}  
# 97
} else { 
# 98
if (n < bound) 
# 99
{ 
# 100
for (size_type i = (0); i < ((g.this_exec).grainsize()); ++i) 
# 101
{ 
# 102
size_type idx = ((g.size()) * i) + tid; 
# 104
if ((idx < (last - first)) && (stencil[idx])) 
# 105
{ 
# 106
(result[map[idx]]) = (first[idx]); 
# 107
}  
# 108
}  
# 109
}  }  
# 111
(g.wait()); 
# 112
} 
#endif
# 115 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/scatter.hpp"
template< std::size_t groupsize, std::size_t 
# 116
grainsize, class 
# 117
RandomAccessIterator1, class 
# 118
RandomAccessIterator2, class 
# 119
RandomAccessIterator3, class 
# 120
RandomAccessIterator4> __attribute__((unused)) void 
# 122
scatter_if(concurrent_group< agent< grainsize> , groupsize>  &g, RandomAccessIterator1 
# 123
first, RandomAccessIterator1 
# 124
last, RandomAccessIterator2 
# 125
map, RandomAccessIterator3 
# 126
stencil, RandomAccessIterator4 
# 127
result) 
# 128
{int volatile ___ = 1;(void)g;(void)first;(void)last;(void)map;(void)stencil;(void)result;
# 197
::exit(___);}
#if 0
# 128
{ 
# 129
typedef typename concurrent_group< agent< grainsize> , groupsize> ::size_type size_type; 
# 131
size_type chunk_size = (g.size()) * grainsize; 
# 133
size_type n = last - first; 
# 135
size_type tid = ((g.this_exec).index()); 
# 138
if (chunk_size == n) 
# 139
{ 
# 140
for (size_type i = (0); i < grainsize; ++i) 
# 141
{ 
# 142
size_type idx = ((g.size()) * i) + tid; 
# 144
if (stencil[idx]) 
# 145
{ 
# 146
(result[map[idx]]) = (first[idx]); 
# 147
}  
# 148
}  
# 149
} else { 
# 150
if (n < chunk_size) 
# 151
{ 
# 152
for (size_type i = (0); i < grainsize; ++i) 
# 153
{ 
# 154
size_type idx = ((g.size()) * i) + tid; 
# 156
if ((idx < (last - first)) && (stencil[idx])) 
# 157
{ 
# 158
(result[map[idx]]) = (first[idx]); 
# 159
}  
# 160
}  
# 161
} else 
# 163
{ 
# 164
for (; first < last; ((first += chunk_size), (map += chunk_size)), (stencil += chunk_size)) 
# 167
{ 
# 168
if ((last - first) >= chunk_size) 
# 169
{ 
# 171
for (size_type i = (0); i < grainsize; ++i) 
# 172
{ 
# 173
size_type idx = ((g.size()) * i) + tid; 
# 175
if (stencil[idx]) 
# 176
{ 
# 177
(result[map[idx]]) = (first[idx]); 
# 178
}  
# 179
}  
# 180
} else 
# 182
{ 
# 183
for (size_type i = (0); i < grainsize; ++i) 
# 184
{ 
# 185
size_type idx = ((g.size()) * i) + tid; 
# 187
if ((idx < (last - first)) && (stencil[idx])) 
# 188
{ 
# 189
(result[map[idx]]) = (first[idx]); 
# 190
}  
# 191
}  
# 192
}  
# 193
}  
# 194
}  }  
# 196
(g.wait()); 
# 197
} 
#endif
# 200 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/scatter.hpp"
}
# 201
}}}}
# 22 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/adjacent_difference.hpp"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 23
namespace bulk_ { 
# 27
template< std::size_t grainsize, class 
# 28
RandomAccessIterator1, class 
# 29
RandomAccessIterator2, class 
# 30
T, class 
# 31
BinaryOperation> __attribute__((unused)) RandomAccessIterator2 
# 33
adjacent_difference(agent< grainsize>  &exec, RandomAccessIterator1 
# 34
first, RandomAccessIterator1 last, RandomAccessIterator2 
# 35
result, T 
# 36
init, BinaryOperation 
# 37
binary_op) 
# 38
{int volatile ___ = 1;(void)exec;(void)first;(void)last;(void)result;(void)init;(void)binary_op;
# 47
::exit(___);}
#if 0
# 38
{ 
# 39
for (; first != last; (++first), (++result)) 
# 40
{ 
# 41
T temp = *first; 
# 42
(*result) = binary_op(temp, init); 
# 43
init = temp; 
# 44
}  
# 46
return result; 
# 47
} 
#endif
# 50 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/adjacent_difference.hpp"
template< std::size_t groupsize, std::size_t 
# 51
grainsize_, class 
# 52
RandomAccessIterator1, class 
# 53
RandomAccessIterator2, class 
# 54
T, class 
# 55
BinaryOperation> __attribute__((unused)) RandomAccessIterator2 
# 57
adjacent_difference(concurrent_group< agent< grainsize_> , groupsize>  &g, RandomAccessIterator1 
# 58
first, RandomAccessIterator1 last, RandomAccessIterator2 
# 59
result, T 
# 60
init, BinaryOperation 
# 61
binary_op) 
# 62
{int volatile ___ = 1;(void)g;(void)first;(void)last;(void)result;(void)init;(void)binary_op;
# 107
::exit(___);}
#if 0
# 62
{ 
# 67
typedef typename concurrent_group< agent< grainsize_> , groupsize> ::size_type size_type; 
# 69
RandomAccessIterator2 return_me = result + (last - first); 
# 71
const size_type grainsize = ((g.this_exec).grainsize()); 
# 72
const size_type tile_size = (g.size()) * grainsize; 
# 75
RandomAccessIterator1 first_init = (first + (grainsize * ((g.this_exec).index()))) - 1; 
# 76
if ((first <= first_init) && (first_init < last)) 
# 77
{ 
# 78
init = (*first_init); 
# 79
}  
# 81
(g.wait()); 
# 83
for (; first < last; (first += tile_size), (result += tile_size)) 
# 84
{ 
# 85
size_type local_offset = grainsize * ((g.this_exec).index()); 
# 86
size_type local_size = thrust::max(0, thrust::min< typename concurrent_group< agent< grainsize_> , groupsize> ::size_type> (grainsize, last - (first + local_offset))); 
# 89
T next_init = ((((first + local_offset) + tile_size) - 1) < last) ? first[tile_size - 1] : init; 
# 91
(g.wait()); 
# 94
bulk_::adjacent_difference((g.this_exec), first + local_offset, (first + local_offset) + local_size, result + local_offset, init, binary_op); 
# 101
init = next_init; 
# 102
}  
# 104
(g.wait()); 
# 106
return return_me; 
# 107
} 
#endif
# 110 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/adjacent_difference.hpp"
template< std::size_t groupsize, std::size_t 
# 111
grainsize, class 
# 112
RandomAccessIterator1, class 
# 113
RandomAccessIterator2, class 
# 114
BinaryOperation> __attribute__((unused)) RandomAccessIterator2 
# 116
adjacent_difference(concurrent_group< agent< grainsize> , groupsize>  &g, RandomAccessIterator1 
# 117
first, RandomAccessIterator1 last, RandomAccessIterator2 
# 118
result, BinaryOperation 
# 119
binary_op) 
# 120
{int volatile ___ = 1;(void)g;(void)first;(void)last;(void)result;(void)binary_op;
# 137
::exit(___);}
#if 0
# 120
{ 
# 121
if (first < last) 
# 122
{ 
# 123
typename iterator_value< RandomAccessIterator1> ::type init = *first; 
# 126
(g.wait()); 
# 128
if (((g.this_exec).index()) == 0) 
# 129
{ 
# 130
(*result) = init; 
# 131
}  
# 133
result = bulk_::adjacent_difference(g, first + 1, last, result + 1, init, binary_op); 
# 134
}  
# 136
return result; 
# 137
} 
#endif
# 140 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/adjacent_difference.hpp"
}
# 141
}}}}
# 23 "/usr/local/cuda-8.0/include/thrust/iterator/detail/transform_iterator.inl"
namespace thrust { 
# 26
template< class UnaryFunction, class Iterator, class Reference, class Value> class transform_iterator; 
# 29
namespace detail { 
# 33
template< class UnaryFunc, class Iterator, class Reference, class Value> 
# 34
struct transform_iterator_base { 
# 41
private: typedef typename ia_dflt_help< Reference, result_of_adaptable_function< UnaryFunc (typename iterator_value< Iterator> ::type)> > ::type reference; 
# 51
typedef typename ia_dflt_help< Value, remove_reference< typename ia_dflt_help< Reference, result_of_adaptable_function< UnaryFunc (typename iterator_value< Iterator> ::type)> > ::type> > ::type cv_value_type; 
# 66
public: typedef iterator_adaptor< transform_iterator< UnaryFunc, Iterator, Reference, Value> , Iterator, typename ia_dflt_help< Value, remove_reference< typename ia_dflt_help< Reference, result_of_adaptable_function< UnaryFunc (typename iterator_value< Iterator> ::type)> > ::type> > ::type, use_default, typename iterator_traits< Iterator> ::iterator_category, typename ia_dflt_help< Reference, result_of_adaptable_function< UnaryFunc (typename iterator_value< Iterator> ::type)> > ::type>  type; 
# 67
}; 
# 70
}
# 71
}
# 43 "/usr/local/cuda-8.0/include/thrust/iterator/transform_iterator.h"
namespace thrust { 
# 189
template< class AdaptableUnaryFunction, class Iterator, class Reference = use_default, class Value = use_default> 
# 190
class transform_iterator : public detail::transform_iterator_base< AdaptableUnaryFunction, Iterator, Reference, Value> ::type { 
# 198
public: typedef typename ::thrust::detail::transform_iterator_base< AdaptableUnaryFunction, Iterator, Reference, Value> ::type super_t; 
# 200
friend class iterator_core_access; 
# 208
transform_iterator() { } 
# 217
transform_iterator(const Iterator &x, AdaptableUnaryFunction f) : super_t(x), m_f(f) 
# 218
{ 
# 219
} 
# 227
explicit transform_iterator(const Iterator &x) : super_t(x) 
# 228
{ } 
# 235
template< class OtherAdaptableUnaryFunction, class 
# 236
OtherIterator, class 
# 237
OtherReference, class 
# 238
OtherValue> 
# 240
transform_iterator(const ::thrust::transform_iterator< OtherAdaptableUnaryFunction, OtherIterator, OtherReference, OtherValue>  &other, typename ::thrust::detail::enable_if_convertible< OtherIterator, Iterator> ::type * = 0, typename ::thrust::detail::enable_if_convertible< OtherAdaptableUnaryFunction, AdaptableUnaryFunction> ::type * = 0) : super_t((other.base())), m_f((other.functor())) 
# 243
{ } 
# 256
transform_iterator &operator=(const transform_iterator &other) 
# 257
{ 
# 258
return do_assign(other, typename ::thrust::detail::is_copy_assignable< AdaptableUnaryFunction> ::type()); 
# 266
} 
# 272
AdaptableUnaryFunction functor() const 
# 273
{ return m_f; } 
# 279
private: transform_iterator &do_assign(const transform_iterator &other, ::thrust::detail::true_type) 
# 280
{ 
# 281
::thrust::detail::transform_iterator_base< AdaptableUnaryFunction, Iterator, Reference, Value> ::type::operator=(other); 
# 284
(m_f) = other.functor(); 
# 286
return *this; 
# 287
} 
# 290
transform_iterator &do_assign(const transform_iterator &other, ::thrust::detail::false_type) 
# 291
{ 
# 292
::thrust::detail::transform_iterator_base< AdaptableUnaryFunction, Iterator, Reference, Value> ::type::operator=(other); 
# 296
return *this; 
# 297
} 
# 301
typename ::thrust::detail::transform_iterator_base< AdaptableUnaryFunction, Iterator, Reference, Value> ::type::reference dereference() const 
# 302
{ 
# 305
typename iterator_value< Iterator> ::type x = *(this->base()); 
# 306
return (m_f)(x); 
# 307
} 
# 311
mutable AdaptableUnaryFunction m_f; 
# 315
}; 
# 329
template< class AdaptableUnaryFunction, class Iterator> inline transform_iterator< AdaptableUnaryFunction, Iterator>  
# 332
make_transform_iterator(Iterator it, AdaptableUnaryFunction fun) 
# 333
{ 
# 334
return transform_iterator< AdaptableUnaryFunction, Iterator> (it, fun); 
# 335
} 
# 343
}
# 21 "/usr/local/cuda-8.0/include/thrust/iterator/detail/minimum_category.h"
namespace thrust { 
# 24
namespace detail { 
# 27
template< class T1, class 
# 28
T2 = minimum_type_detail::any_conversion, class 
# 29
T3 = minimum_type_detail::any_conversion, class 
# 30
T4 = minimum_type_detail::any_conversion, class 
# 31
T5 = minimum_type_detail::any_conversion, class 
# 32
T6 = minimum_type_detail::any_conversion, class 
# 33
T7 = minimum_type_detail::any_conversion, class 
# 34
T8 = minimum_type_detail::any_conversion, class 
# 35
T9 = minimum_type_detail::any_conversion, class 
# 36
T10 = minimum_type_detail::any_conversion, class 
# 37
T11 = minimum_type_detail::any_conversion, class 
# 38
T12 = minimum_type_detail::any_conversion, class 
# 39
T13 = minimum_type_detail::any_conversion, class 
# 40
T14 = minimum_type_detail::any_conversion, class 
# 41
T15 = minimum_type_detail::any_conversion, class 
# 42
T16 = minimum_type_detail::any_conversion> 
# 43
struct minimum_category : public minimum_type< T1, T2, T3, T4, T5, T6, T7, T8, T9, T10, T11, T12, T13, T14, T15, T16>  { 
# 46
}; 
# 48
}
# 50
}
# 30 "/usr/local/cuda-8.0/include/thrust/iterator/detail/zip_iterator_base.h"
namespace thrust { 
# 34
template< class IteratorTuple> class zip_iterator; 
# 36
namespace detail { 
# 42
template< class DiffType> 
# 43
class advance_iterator { 
# 47
public: advance_iterator(DiffType step) : m_step(step) { } 
# 50
template< class Iterator> void 
# 52
operator()(Iterator &it) const 
# 53
{ it += (m_step); } 
# 56
private: DiffType m_step; 
# 57
}; 
# 60
struct increment_iterator { 
# 63
template< class Iterator> void 
# 65
operator()(Iterator &it) 
# 66
{ ++it; } 
# 67
}; 
# 70
struct decrement_iterator { 
# 73
template< class Iterator> void 
# 75
operator()(Iterator &it) 
# 76
{ --it; } 
# 77
}; 
# 80
struct dereference_iterator { 
# 82
template< class Iterator> 
# 83
struct apply { 
# 87
typedef typename iterator_traits< Iterator> ::reference type; 
# 88
}; 
# 92
template< class Iterator> typename apply< Iterator> ::type 
# 94
operator()(const Iterator &it) 
# 95
{ 
# 96
return *it; 
# 97
} 
# 98
}; 
# 103
namespace tuple_impl_specific { 
# 107
template< class UnaryMetaFunctionClass, class Arg> 
# 108
struct apply1 : public UnaryMetaFunctionClass::template apply< Arg>  { 
# 111
}; 
# 115
template< class UnaryMetaFunctionClass, class Arg1, class Arg2> 
# 116
struct apply2 : public UnaryMetaFunctionClass::template apply< Arg1, Arg2>  { 
# 119
}; 
# 126
template< class Tuple, class BinaryMetaFun, class StartType> struct tuple_meta_accumulate; 
# 129
template< class 
# 130
Tuple, class 
# 131
BinaryMetaFun, class 
# 132
StartType> 
# 134
struct tuple_meta_accumulate_impl { 
# 144
typedef typename apply2< BinaryMetaFun, typename Tuple::head_type, typename tuple_meta_accumulate< typename Tuple::tail_type, BinaryMetaFun, StartType> ::type> ::type type; 
# 145
}; 
# 148
template< class 
# 149
Tuple, class 
# 150
BinaryMetaFun, class 
# 151
StartType> 
# 153
struct tuple_meta_accumulate : public eval_if< is_same< Tuple, null_type> ::value, identity_< StartType> , tuple_meta_accumulate_impl< Tuple, BinaryMetaFun, StartType> >  { 
# 164
}; 
# 187
template< class Fun> inline Fun 
# 189
tuple_for_each(null_type, Fun f) 
# 190
{ 
# 191
return f; 
# 192
} 
# 195
template< class Tuple, class Fun> inline Fun 
# 197
tuple_for_each(Tuple &t, Fun f) 
# 198
{ 
# 199
f((t.get_head())); 
# 200
return tuple_for_each((t.get_tail()), f); 
# 201
} 
# 210
inline bool tuple_equal(null_type, null_type) 
# 211
{ return true; } 
# 214
template< class Tuple1, class Tuple2> bool 
# 216
tuple_equal(const Tuple1 &t1, const Tuple2 &t2) 
# 217
{ 
# 218
return ((t1.get_head()) == (t2.get_head())) && tuple_equal((t1.get_tail()), (t2.get_tail())); 
# 220
} 
# 222
}
# 228
template< class IteratorTuple> 
# 229
struct tuple_of_value_types : public tuple_meta_transform< IteratorTuple, iterator_value>  { 
# 235
}; 
# 238
struct minimum_category_lambda { 
# 240
template< class T1, class T2> 
# 241
struct apply : public minimum_category< T1, T2>  { 
# 242
}; 
# 243
}; 
# 250
template< class IteratorTuple> 
# 251
struct minimum_traversal_category_in_iterator_tuple { 
# 256
typedef typename tuple_meta_transform< IteratorTuple, iterator_traversal> ::type tuple_of_traversal_tags; 
# 262
typedef typename tuple_impl_specific::tuple_meta_accumulate< typename tuple_meta_transform< IteratorTuple, iterator_traversal> ::type, minimum_category_lambda, random_access_traversal_tag> ::type type; 
# 263
}; 
# 266
struct minimum_system_lambda { 
# 268
template< class T1, class T2> 
# 269
struct apply : public minimum_system< T1, T2>  { 
# 270
}; 
# 271
}; 
# 277
template< class IteratorTuple> 
# 278
struct minimum_system_in_iterator_tuple { 
# 283
typedef typename tuple_meta_transform< IteratorTuple, iterator_system> ::type tuple_of_system_tags; 
# 289
typedef typename tuple_impl_specific::tuple_meta_accumulate< typename tuple_meta_transform< IteratorTuple, iterator_system> ::type, minimum_system_lambda, any_system_tag> ::type type; 
# 290
}; 
# 292
namespace zip_iterator_base_ns { 
# 296
template< int i, class Tuple> 
# 297
struct tuple_elements_helper : public eval_if< i < tuple_size< Tuple> ::value, tuple_element< i, Tuple> , identity_< null_type> >  { 
# 303
}; 
# 306
template< class Tuple> 
# 307
struct tuple_elements { 
# 309
typedef typename tuple_elements_helper< 0, Tuple> ::type T0; 
# 310
typedef typename tuple_elements_helper< 1, Tuple> ::type T1; 
# 311
typedef typename tuple_elements_helper< 2, Tuple> ::type T2; 
# 312
typedef typename tuple_elements_helper< 3, Tuple> ::type T3; 
# 313
typedef typename tuple_elements_helper< 4, Tuple> ::type T4; 
# 314
typedef typename tuple_elements_helper< 5, Tuple> ::type T5; 
# 315
typedef typename tuple_elements_helper< 6, Tuple> ::type T6; 
# 316
typedef typename tuple_elements_helper< 7, Tuple> ::type T7; 
# 317
typedef typename tuple_elements_helper< 8, Tuple> ::type T8; 
# 318
typedef typename tuple_elements_helper< 9, Tuple> ::type T9; 
# 319
}; 
# 322
template< class IteratorTuple> 
# 323
struct tuple_of_iterator_references { 
# 329
typedef typename tuple_meta_transform< IteratorTuple, iterator_reference> ::type tuple_of_references; 
# 332
typedef tuple_elements< typename tuple_meta_transform< IteratorTuple, iterator_reference> ::type>  elements; 
# 346
typedef detail::tuple_of_iterator_references< typename tuple_elements< typename tuple_meta_transform< IteratorTuple, iterator_reference> ::type> ::T0, typename tuple_elements< typename tuple_meta_transform< IteratorTuple, iterator_reference> ::type> ::T1, typename tuple_elements< typename tuple_meta_transform< IteratorTuple, iterator_reference> ::type> ::T2, typename tuple_elements< typename tuple_meta_transform< IteratorTuple, iterator_reference> ::type> ::T3, typename tuple_elements< typename tuple_meta_transform< IteratorTuple, iterator_reference> ::type> ::T4, typename tuple_elements< typename tuple_meta_transform< IteratorTuple, iterator_reference> ::type> ::T5, typename tuple_elements< typename tuple_meta_transform< IteratorTuple, iterator_reference> ::type> ::T6, typename tuple_elements< typename tuple_meta_transform< IteratorTuple, iterator_reference> ::type> ::T7, typename tuple_elements< typename tuple_meta_transform< IteratorTuple, iterator_reference> ::type> ::T8, typename tuple_elements< typename tuple_meta_transform< IteratorTuple, iterator_reference> ::type> ::T9>  type; 
# 347
}; 
# 350
}
# 359
template< class IteratorTuple> 
# 360
struct zip_iterator_base { 
# 365
typedef typename zip_iterator_base_ns::tuple_of_iterator_references< IteratorTuple> ::type reference; 
# 369
typedef typename tuple_of_value_types< IteratorTuple> ::type value_type; 
# 374
typedef typename iterator_traits< typename tuple_element< 0, IteratorTuple> ::type> ::difference_type difference_type; 
# 379
typedef typename minimum_system_in_iterator_tuple< IteratorTuple> ::type system; 
# 384
typedef typename minimum_traversal_category_in_iterator_tuple< IteratorTuple> ::type traversal_category; 
# 397
typedef iterator_facade< zip_iterator< IteratorTuple> , typename tuple_of_value_types< IteratorTuple> ::type, typename minimum_system_in_iterator_tuple< IteratorTuple> ::type, typename minimum_traversal_category_in_iterator_tuple< IteratorTuple> ::type, typename zip_iterator_base_ns::tuple_of_iterator_references< IteratorTuple> ::type, typename iterator_traits< typename tuple_element< 0, IteratorTuple> ::type> ::difference_type>  type; 
# 398
}; 
# 400
}
# 402
}
# 39 "/usr/local/cuda-8.0/include/thrust/iterator/zip_iterator.h"
namespace thrust { 
# 139
template< class IteratorTuple> 
# 140
class zip_iterator : public detail::zip_iterator_base< IteratorTuple> ::type { 
# 147
public: inline zip_iterator(); 
# 155
inline zip_iterator(IteratorTuple iterator_tuple); 
# 162
template< class OtherIteratorTuple> inline zip_iterator(const ::thrust::zip_iterator< OtherIteratorTuple>  & other, typename ::thrust::detail::enable_if_convertible< OtherIteratorTuple, IteratorTuple> ::type * = 0); 
# 177
inline const IteratorTuple &get_iterator_tuple() const; 
# 183
private: typedef typename ::thrust::detail::zip_iterator_base< IteratorTuple> ::type super_t; 
# 185
friend class iterator_core_access; 
# 190
typename ::thrust::detail::zip_iterator_base< IteratorTuple> ::type::reference dereference() const; 
# 195
template< class OtherIteratorTuple> inline bool equal(const ::thrust::zip_iterator< OtherIteratorTuple>  & other) const; 
# 201
inline void advance(typename ::thrust::detail::zip_iterator_base< IteratorTuple> ::type::difference_type n); 
# 205
inline void increment(); 
# 209
inline void decrement(); 
# 212
template< class OtherIteratorTuple> inline typename ::thrust::detail::zip_iterator_base< IteratorTuple> ::type::difference_type distance_to(const ::thrust::zip_iterator< OtherIteratorTuple>  & other) const; 
# 218
IteratorTuple m_iterator_tuple; 
# 222
}; 
# 232
template< class IteratorTuple> inline zip_iterator< IteratorTuple>  make_zip_iterator(IteratorTuple t); 
# 242
}
# 22 "/usr/local/cuda-8.0/include/thrust/iterator/detail/zip_iterator.inl"
namespace thrust { 
# 26
template< class IteratorTuple> inline 
# 29
zip_iterator< IteratorTuple> ::zip_iterator() 
# 30
{ 
# 31
} 
# 34
template< class IteratorTuple> inline 
# 37
zip_iterator< IteratorTuple> ::zip_iterator(IteratorTuple iterator_tuple) : m_iterator_tuple(iterator_tuple) 
# 39
{ 
# 40
} 
# 43
template< class IteratorTuple> 
# 44
template< class OtherIteratorTuple> inline 
# 47
zip_iterator< IteratorTuple> ::zip_iterator(const ::thrust::zip_iterator< OtherIteratorTuple>  &other, typename ::thrust::detail::enable_if_convertible< OtherIteratorTuple, IteratorTuple> ::type *) : m_iterator_tuple((other.get_iterator_tuple())) 
# 53
{ 
# 54
} 
# 57
template< class IteratorTuple> inline const IteratorTuple &
# 60
zip_iterator< IteratorTuple> ::get_iterator_tuple() const 
# 61
{ 
# 62
return m_iterator_tuple; 
# 63
} 
# 66
template< class IteratorTuple> typename detail::zip_iterator_base< IteratorTuple> ::type::reference 
# 70
zip_iterator< IteratorTuple> ::dereference() const 
# 71
{ 
# 72
using namespace ::thrust::detail::tuple_impl_specific;
# 74
return ::thrust::detail::tuple_host_device_transform< ::thrust::detail::dereference_iterator::template apply> (get_iterator_tuple(), ::thrust::detail::dereference_iterator()); 
# 75
} 
# 79
template< class IteratorTuple> 
# 80
template< class OtherIteratorTuple> inline bool 
# 83
zip_iterator< IteratorTuple> ::equal(const ::thrust::zip_iterator< OtherIteratorTuple>  &other) const 
# 84
{ 
# 85
return get< 0> (get_iterator_tuple()) == get< 0> ((other.get_iterator_tuple())); 
# 86
} 
# 89
template< class IteratorTuple> inline void 
# 92
zip_iterator< IteratorTuple> ::advance(typename ::thrust::detail::zip_iterator_base< IteratorTuple> ::type::difference_type n) 
# 93
{ 
# 94
using namespace ::thrust::detail::tuple_impl_specific;
# 95
tuple_for_each(m_iterator_tuple, ((::thrust::detail::advance_iterator< typename ::thrust::detail::zip_iterator_base< IteratorTuple> ::type::difference_type> )(n))); 
# 97
} 
# 100
template< class IteratorTuple> inline void 
# 103
zip_iterator< IteratorTuple> ::increment() 
# 104
{ 
# 105
using namespace ::thrust::detail::tuple_impl_specific;
# 106
tuple_for_each(m_iterator_tuple, ::thrust::detail::increment_iterator()); 
# 107
} 
# 110
template< class IteratorTuple> inline void 
# 113
zip_iterator< IteratorTuple> ::decrement() 
# 114
{ 
# 115
using namespace ::thrust::detail::tuple_impl_specific;
# 116
tuple_for_each(m_iterator_tuple, ::thrust::detail::decrement_iterator()); 
# 117
} 
# 121
template< class IteratorTuple> 
# 122
template< class OtherIteratorTuple> inline typename detail::zip_iterator_base< IteratorTuple> ::type::difference_type 
# 126
zip_iterator< IteratorTuple> ::distance_to(const ::thrust::zip_iterator< OtherIteratorTuple>  &other) const 
# 127
{ 
# 128
return get< 0> ((other.get_iterator_tuple())) - get< 0> (get_iterator_tuple()); 
# 129
} 
# 132
template< class IteratorTuple> inline zip_iterator< IteratorTuple>  
# 134
make_zip_iterator(IteratorTuple t) 
# 135
{ 
# 136
return ((zip_iterator< IteratorTuple> )(t)); 
# 137
} 
# 140
}
# 27 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/detail/head_flags.hpp"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 28
namespace bulk_ { 
# 30
namespace detail { 
# 34
template< class RandomAccessIterator, class 
# 35
BinaryPredicate = equal_to< typename iterator_value< RandomAccessIterator> ::type> , class 
# 36
ValueType = bool, class 
# 37
IndexType = typename iterator_difference< RandomAccessIterator> ::type> 
# 38
class head_flags_with_init { 
# 40
typedef typename iterator_value< RandomAccessIterator> ::type init_type; 
# 45
public: struct head_flag_functor { 
# 47
BinaryPredicate binary_pred; 
# 48
init_type init; 
# 49
IndexType n; 
# 51
typedef ValueType result_type; 
# 54
head_flag_functor(init_type init, IndexType n) : binary_pred(), init(init), n(n) 
# 56
{ } 
# 59
head_flag_functor(init_type init, IndexType n, BinaryPredicate binary_pred) : binary_pred(binary_pred), init(init), n(n) 
# 61
{ } 
# 63
template< class Tuple> 
# 64
__attribute((always_inline)) result_type 
# 65
operator()(const Tuple &t) 
# 66
{ 
# 67
const IndexType i = thrust::get< 0> (t); 
# 69
if (i == 0) 
# 70
{ 
# 71
return !(binary_pred)(init, thrust::get< 1> (t)); 
# 72
}  
# 74
return !(binary_pred)(thrust::get< 1> (t), thrust::get< 2> (t)); 
# 75
} 
# 76
}; 
# 78
typedef thrust::counting_iterator< IndexType>  counting_iterator; 
# 84
typedef transform_iterator< head_flag_functor, zip_iterator< tuple< thrust::counting_iterator< IndexType> , RandomAccessIterator, RandomAccessIterator, null_type, null_type, null_type, null_type, null_type, null_type, null_type> > >  iterator; 
# 88
head_flags_with_init(RandomAccessIterator first, RandomAccessIterator last, init_type init) : m_begin(thrust::make_transform_iterator(thrust::make_zip_iterator(thrust::make_tuple(((thrust::counting_iterator< IndexType> )(0)), first, first - 1)), head_flag_functor(init, last - first))), m_end((m_begin) + (last - first)) 
# 92
{ } 
# 95
head_flags_with_init(RandomAccessIterator first, RandomAccessIterator last, init_type init, BinaryPredicate binary_pred) : m_begin(thrust::make_transform_iterator(thrust::make_zip_iterator(thrust::make_tuple(((thrust::counting_iterator< IndexType> )(0)), first, first - 1)), head_flag_functor(init, last - first, binary_pred))), m_end((m_begin) + (last - first)) 
# 99
{ } 
# 102
iterator begin() const 
# 103
{ 
# 104
return m_begin; 
# 105
} 
# 108
iterator end() const 
# 109
{ 
# 110
return m_end; 
# 111
} 
# 113
template< class OtherIndex> typename transform_iterator< head_flag_functor, zip_iterator< tuple< thrust::counting_iterator< IndexType> , RandomAccessIterator, RandomAccessIterator, null_type, null_type, null_type, null_type, null_type, null_type, null_type> > > ::reference 
# 115
operator[](OtherIndex i) 
# 116
{ 
# 117
return *(begin() + i); 
# 118
} 
# 121
private: iterator m_begin, m_end; 
# 122
}; 
# 126
template< class RandomAccessIterator, class 
# 127
BinaryPredicate = equal_to< typename iterator_value< RandomAccessIterator> ::type> , class 
# 128
ValueType = bool, class 
# 129
IndexType = typename iterator_difference< RandomAccessIterator> ::type> 
# 131
class head_flags_ { 
# 136
public: struct head_flag_functor { 
# 138
BinaryPredicate binary_pred; 
# 139
IndexType n; 
# 141
typedef ValueType result_type; 
# 144
head_flag_functor(IndexType n) : binary_pred(), n(n) 
# 146
{ } 
# 149
head_flag_functor(IndexType n, BinaryPredicate binary_pred) : binary_pred(binary_pred), n(n) 
# 151
{ } 
# 153
template< class Tuple> 
# 154
__attribute((always_inline)) result_type 
# 155
operator()(const Tuple &t) 
# 156
{ 
# 157
const IndexType i = thrust::get< 0> (t); 
# 161
return (i == 0) || (!(binary_pred)(thrust::get< 1> (t), thrust::get< 2> (t))); 
# 162
} 
# 163
}; 
# 165
typedef thrust::counting_iterator< IndexType>  counting_iterator; 
# 171
typedef transform_iterator< head_flag_functor, zip_iterator< tuple< thrust::counting_iterator< IndexType> , RandomAccessIterator, RandomAccessIterator, null_type, null_type, null_type, null_type, null_type, null_type, null_type> > >  iterator; 
# 175
head_flags_(RandomAccessIterator first, RandomAccessIterator last) : m_begin(thrust::make_transform_iterator(thrust::make_zip_iterator(thrust::make_tuple(((thrust::counting_iterator< IndexType> )(0)), first, first - 1)), (head_flag_functor)(last - first))), m_end((m_begin) + (last - first)) 
# 179
{ } 
# 183
head_flags_(RandomAccessIterator first, RandomAccessIterator last, BinaryPredicate binary_pred) : m_begin(thrust::make_transform_iterator(thrust::make_zip_iterator(thrust::make_tuple(((thrust::counting_iterator< IndexType> )(0)), first, first - 1)), head_flag_functor(last - first, binary_pred))), m_end((m_begin) + (last - first)) 
# 187
{ } 
# 190
iterator begin() const 
# 191
{ 
# 192
return m_begin; 
# 193
} 
# 196
iterator end() const 
# 197
{ 
# 198
return m_end; 
# 199
} 
# 201
template< class OtherIndex> typename transform_iterator< head_flag_functor, zip_iterator< tuple< thrust::counting_iterator< IndexType> , RandomAccessIterator, RandomAccessIterator, null_type, null_type, null_type, null_type, null_type, null_type, null_type> > > ::reference 
# 203
operator[](OtherIndex i) 
# 204
{ 
# 205
return *(begin() + i); 
# 206
} 
# 209
private: iterator m_begin, m_end; 
# 210
}; 
# 213
template< class RandomAccessIterator, class BinaryPredicate> head_flags_< RandomAccessIterator, BinaryPredicate>  
# 217
make_head_flags(RandomAccessIterator first, RandomAccessIterator last, BinaryPredicate binary_pred) 
# 218
{ 
# 220
return head_flags_< RandomAccessIterator, BinaryPredicate> (first, last, binary_pred); 
# 221
} 
# 224
template< class RandomAccessIterator> head_flags_< RandomAccessIterator>  
# 228
make_head_flags(RandomAccessIterator first, RandomAccessIterator last) 
# 229
{ 
# 231
return head_flags_< RandomAccessIterator> (first, last); 
# 232
} 
# 235
}
# 236
}
# 237
}}}}
# 27 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/detail/tail_flags.hpp"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 28
namespace bulk_ { 
# 30
namespace detail { 
# 34
template< class RandomAccessIterator, class 
# 35
BinaryPredicate = equal_to< typename iterator_value< RandomAccessIterator> ::type> , class 
# 36
ValueType = bool, class 
# 37
IndexType = typename iterator_difference< RandomAccessIterator> ::type> 
# 38
class tail_flags_ { 
# 43
public: struct tail_flag_functor { 
# 45
BinaryPredicate binary_pred; 
# 46
RandomAccessIterator iter; 
# 47
IndexType n; 
# 49
typedef ValueType result_type; 
# 52
tail_flag_functor(RandomAccessIterator first, RandomAccessIterator last) : binary_pred(), iter(first), n(last - first) 
# 54
{ } 
# 57
tail_flag_functor(RandomAccessIterator first, RandomAccessIterator last, BinaryPredicate binary_pred) : binary_pred(binary_pred), iter(first), n(last - first) 
# 59
{ } 
# 61
__attribute((always_inline)) result_type 
# 62
operator()(const IndexType &i) 
# 63
{ 
# 64
return (i == ((n) - 1)) || (!(binary_pred)((iter)[i], (iter)[i + 1])); 
# 65
} 
# 66
}; 
# 68
typedef thrust::counting_iterator< IndexType>  counting_iterator; 
# 74
typedef transform_iterator< tail_flag_functor, thrust::counting_iterator< IndexType> >  iterator; 
# 78
tail_flags_(RandomAccessIterator first, RandomAccessIterator last) : m_begin(thrust::make_transform_iterator(((thrust::counting_iterator< IndexType> )(0)), tail_flag_functor(first, last))), m_end((m_begin) + (last - first)) 
# 82
{ } 
# 86
tail_flags_(RandomAccessIterator first, RandomAccessIterator last, BinaryPredicate binary_pred) : m_begin(thrust::make_transform_iterator(((thrust::counting_iterator< IndexType> )(0)), tail_flag_functor(first, last, binary_pred))), m_end((m_begin) + (last - first)) 
# 90
{ } 
# 93
iterator begin() const 
# 94
{ 
# 95
return m_begin; 
# 96
} 
# 99
iterator end() const 
# 100
{ 
# 101
return m_end; 
# 102
} 
# 104
template< class OtherIndex> typename transform_iterator< tail_flag_functor, thrust::counting_iterator< IndexType> > ::reference 
# 106
operator[](OtherIndex i) 
# 107
{ 
# 108
return *(begin() + i); 
# 109
} 
# 112
private: iterator m_begin, m_end; 
# 113
}; 
# 116
template< class RandomAccessIterator, class BinaryPredicate> tail_flags_< RandomAccessIterator, BinaryPredicate>  
# 120
make_tail_flags(RandomAccessIterator first, RandomAccessIterator last, BinaryPredicate binary_pred) 
# 121
{ 
# 123
return tail_flags_< RandomAccessIterator, BinaryPredicate> (first, last, binary_pred); 
# 124
} 
# 127
template< class RandomAccessIterator> tail_flags_< RandomAccessIterator>  
# 131
make_tail_flags(RandomAccessIterator first, RandomAccessIterator last) 
# 132
{ 
# 134
return tail_flags_< RandomAccessIterator> (first, last); 
# 135
} 
# 138
}
# 139
}
# 140
}}}}
# 32 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/reduce_by_key.hpp"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 33
namespace bulk_ { 
# 35
namespace detail { 
# 37
namespace reduce_by_key_detail { 
# 41
template< class FlagType, class ValueType, class BinaryFunction> 
# 42
struct scan_head_flags_functor { 
# 44
BinaryFunction binary_op; 
# 46
typedef tuple< FlagType, ValueType, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type>  result_type; 
# 47
typedef result_type first_argument_type; 
# 48
typedef result_type second_argument_type; 
# 51
scan_head_flags_functor(BinaryFunction binary_op) : binary_op(binary_op) 
# 53
{ } 
# 56
result_type operator()(const first_argument_type &a, const second_argument_type &b) 
# 57
{ 
# 58
ValueType val = (thrust::get< 0> (b)) ? thrust::get< 1> (b) : (binary_op)(thrust::get< 1> (a), thrust::get< 1> (b)); 
# 59
FlagType flag = thrust::get< 0> (a) + thrust::get< 0> (b); 
# 60
return result_type(flag, val); 
# 61
} 
# 62
}; 
# 65
template< class ConcurrentGroup, class 
# 66
InputIterator1, class 
# 67
Size, class 
# 68
InputIterator2, class 
# 69
InputIterator3, class 
# 70
OutputIterator1, class 
# 71
OutputIterator2> __attribute__((unused)) void 
# 73
scatter_tails_n(ConcurrentGroup &group, InputIterator1 
# 74
flags_first, Size 
# 75
n, InputIterator2 
# 76
keys_first, InputIterator3 
# 77
values_first, OutputIterator1 
# 78
keys_result, OutputIterator2 
# 79
values_result) 
# 80
{int volatile ___ = 1;(void)group;(void)flags_first;(void)n;(void)keys_first;(void)values_first;(void)keys_result;(void)values_result;
# 108
::exit(___);}
#if 0
# 80
{ 
# 94
bulk_::scatter_if(group, values_first, (values_first + n) - 1, thrust::make_transform_iterator(flags_first, (thrust::placeholders::_1 - (1))), (detail::make_tail_flags(flags_first, flags_first + n).begin()), values_result); 
# 101
bulk_::scatter_if(group, keys_first, (keys_first + n) - 1, thrust::make_transform_iterator(flags_first, (thrust::placeholders::_1 - (1))), (detail::make_tail_flags(flags_first, flags_first + n).begin()), keys_result); 
# 108
} 
#endif
# 111 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/reduce_by_key.hpp"
}
# 112
}
# 115
template< std::size_t groupsize, std::size_t 
# 116
grainsize, class 
# 117
InputIterator1, class 
# 118
InputIterator2, class 
# 119
OutputIterator1, class 
# 120
OutputIterator2, class 
# 121
T1, class 
# 122
T2, class 
# 123
BinaryPredicate, class 
# 124
BinaryFunction> __attribute__((unused)) tuple< OutputIterator1, OutputIterator2, typename iterator_value< InputIterator1> ::type, typename iterator_value< OutputIterator2> ::type, null_type, null_type, null_type, null_type, null_type, null_type>  
# 132
reduce_by_key(concurrent_group< agent< grainsize> , groupsize>  &g, InputIterator1 
# 133
keys_first, InputIterator1 keys_last, InputIterator2 
# 134
values_first, OutputIterator1 
# 135
keys_result, OutputIterator2 
# 136
values_result, T1 
# 137
init_key, T2 
# 138
init_value, BinaryPredicate 
# 139
pred, BinaryFunction 
# 140
binary_op) 
# 141
{int volatile ___ = 1;(void)g;(void)keys_first;(void)keys_last;(void)values_first;(void)keys_result;(void)values_result;(void)init_key;(void)init_value;(void)pred;(void)binary_op;
# 216
::exit(___);}
#if 0
# 141
{ 
# 142
typedef typename iterator_value< InputIterator2> ::type value_type; 
# 144
typedef typename concurrent_group< agent< grainsize> , groupsize> ::size_type size_type; 
# 146
const size_type interval_size = (groupsize * grainsize); 
# 152
__attribute__((unused)) static uninitialized_array< typename concurrent_group< agent< grainsize> , groupsize> ::size_type, interval_size>  s_flags_impl; 
# 153
size_type *s_flags = (s_flags_impl.data()); 
# 155
__attribute__((unused)) static uninitialized_array< typename iterator_value< InputIterator2> ::type, interval_size>  s_values_impl; 
# 156
value_type *s_values = (s_values_impl.data()); 
# 159
for (; keys_first < keys_last; (keys_first += interval_size), (values_first += interval_size)) 
# 160
{ 
# 162
size_type n = thrust::min< typename concurrent_group< agent< grainsize> , groupsize> ::size_type> (interval_size, keys_last - keys_first); 
# 168
detail::head_flags_with_init< InputIterator1, BinaryPredicate, typename concurrent_group< agent< grainsize> , groupsize> ::size_type>  flags(keys_first, keys_first + n, init_key, pred); 
# 170
detail::reduce_by_key_detail::scan_head_flags_functor< typename concurrent_group< agent< grainsize> , groupsize> ::size_type, typename iterator_value< InputIterator2> ::type, BinaryFunction>  f(binary_op); 
# 173
bulk_::copy_n(bulk_::bound< interval_size> (g), thrust::make_zip_iterator(thrust::make_tuple((flags.begin()), values_first)), n, thrust::make_zip_iterator(thrust::make_tuple(s_flags, s_values))); 
# 179
bulk_::inclusive_scan(bulk_::bound< interval_size> (g), thrust::make_zip_iterator(thrust::make_tuple(s_flags, s_values)), thrust::make_zip_iterator(thrust::make_tuple(s_flags + n, s_values)), thrust::make_zip_iterator(thrust::make_tuple(s_flags, s_values)), thrust::make_tuple(1, init_value), f); 
# 187
detail::reduce_by_key_detail::scatter_tails_n(bulk_::bound< interval_size> (g), s_flags, n, keys_first, s_values, keys_result, values_result); 
# 194
if ((((g.this_exec).index()) == 0) && ((s_flags[0]) > 1)) 
# 195
{ 
# 196
(keys_result[0]) = init_key; 
# 197
(values_result[0]) = init_value; 
# 198
}  
# 200
size_type result_size = (s_flags[n - 1]) - 1; 
# 202
keys_result += result_size; 
# 203
values_result += result_size; 
# 204
init_key = (keys_first[n - 1]); 
# 205
init_value = (s_values[n - 1]); 
# 207
(g.wait()); 
# 208
}  
# 215
return thrust::make_tuple(keys_result, values_result, init_key, init_value); 
# 216
} 
#endif
# 219 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/reduce_by_key.hpp"
}
# 220
}}}}
# 28 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/detail/stable_merge_sort.hpp"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 29
namespace bulk_ { 
# 34
template< std::size_t bound, std::size_t 
# 35
grainsize, class 
# 36
RandomAccessIterator1, class 
# 37
RandomAccessIterator2, class 
# 38
Compare> 
# 39
__attribute((always_inline)) __attribute__((unused)) inline void 
# 34
stable_sort_by_key(const bounded< bound, agent< grainsize> >  & exec, RandomAccessIterator1 keys_first, RandomAccessIterator1 keys_last, RandomAccessIterator2 values_first, Compare comp); 
# 46
namespace detail { 
# 48
namespace stable_merge_sort_detail { 
# 52
template< std::size_t bound, std::size_t groupsize, std::size_t grainsize, class KeyType, class ValType, class Compare> __attribute__((unused)) typename thrust::detail::enable_if< bound <= (groupsize * grainsize)> ::type 
# 57
inplace_merge_adjacent_partitions(bounded< bound, concurrent_group< agent< grainsize> , groupsize> >  &g, KeyType 
# 58
local_keys[], ValType local_values[], void *stage_ptr, int count, int local_size, Compare comp) 
# 59
{int volatile ___ = 1;(void)g;(void)local_keys;(void)local_values;(void)stage_ptr;(void)count;(void)local_size;(void)comp;
# 119
::exit(___);}
#if 0
# 59
{ 
# 60
union stage_t { 
# 62
KeyType *keys; 
# 63
ValType *vals; 
# 64
}; 
# 66
stage_t stage; 
# 67
(stage.keys) = (reinterpret_cast< KeyType *>(stage_ptr)); 
# 69
typedef typename agent< grainsize> ::size_type size_type; 
# 71
size_type local_offset = grainsize * ((g.this_exec).index()); 
# 75
for (size_type num_agents_per_merge = (2); num_agents_per_merge <= groupsize; num_agents_per_merge *= 2) 
# 76
{ 
# 78
bulk_::copy_n(bulk_::bound< grainsize> ((g.this_exec)), local_keys, local_size, (stage.keys) + local_offset); 
# 80
(g.wait()); 
# 83
size_type list = (~(num_agents_per_merge - 1)) & ((g.this_exec).index()); 
# 84
size_type diag = thrust::min< typename agent< grainsize> ::size_type> (count, grainsize * ((num_agents_per_merge - 1) & ((g.this_exec).index()))); 
# 85
size_type start = grainsize * list; 
# 88
size_type input_size = grainsize * (num_agents_per_merge / 2); 
# 90
size_type partition_first1 = thrust::min< typename agent< grainsize> ::size_type> (count, start); 
# 91
size_type partition_first2 = thrust::min< typename agent< grainsize> ::size_type> (count, partition_first1 + input_size); 
# 92
size_type partition_last2 = thrust::min< typename agent< grainsize> ::size_type> (count, partition_first2 + input_size); 
# 94
size_type n1 = partition_first2 - partition_first1; 
# 95
size_type n2 = partition_last2 - partition_first2; 
# 97
size_type mp = bulk_::merge_path((stage.keys) + partition_first1, n1, (stage.keys) + partition_first2, n2, diag, comp); 
# 101
size_type gather_indices[grainsize]; 
# 102
bulk_::merge_by_key(bulk_::bound< grainsize> ((g.this_exec)), ((stage.keys) + partition_first1) + mp, (stage.keys) + partition_first2, (((stage.keys) + partition_first2) + diag) - mp, (stage.keys) + partition_last2, thrust::make_counting_iterator< typename agent< grainsize> ::size_type> (partition_first1 + mp), thrust::make_counting_iterator< typename agent< grainsize> ::size_type> ((partition_first2 + diag) - mp), local_keys, gather_indices, comp); 
# 112
bulk_::copy_n(bulk_::bound< grainsize> ((g.this_exec)), local_values, local_size, (stage.vals) + local_offset); 
# 115
bulk_::gather(bulk_::bound< grainsize> ((g.this_exec)), gather_indices, (gather_indices) + local_size, stage.vals, local_values); 
# 117
(g.wait()); 
# 118
}  
# 119
} 
#endif
# 122 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/detail/stable_merge_sort.hpp"
}
# 125
template< std::size_t bound, std::size_t groupsize, std::size_t grainsize, class 
# 126
RandomAccessIterator1, class 
# 127
RandomAccessIterator2, class 
# 128
Compare> __attribute__((unused)) typename thrust::detail::enable_if< bound <= (groupsize * grainsize)> ::type 
# 133
stable_merge_sort_by_key(bounded< bound, concurrent_group< agent< grainsize> , groupsize> >  &g, RandomAccessIterator1 
# 134
keys_first, RandomAccessIterator1 keys_last, RandomAccessIterator2 
# 135
values_first, Compare 
# 136
comp) 
# 137
{int volatile ___ = 1;(void)g;(void)keys_first;(void)keys_last;(void)values_first;(void)comp;
# 206
::exit(___);}
#if 0
# 137
{ 
# 138
typedef typename iterator_value< RandomAccessIterator1> ::type key_type; 
# 139
typedef typename iterator_value< RandomAccessIterator2> ::type value_type; 
# 141
typedef typename agent< grainsize> ::size_type size_type; 
# 143
size_type n = keys_last - keys_first; 
# 144
const size_type tile_size = (groupsize * grainsize); 
# 146
size_type local_offset = grainsize * ((g.this_exec).index()); 
# 147
size_type local_size = thrust::max< typename agent< grainsize> ::size_type> (0, thrust::min< typename agent< grainsize> ::size_type> (grainsize, n - local_offset)); 
# 162
__attribute__((unused)) static 
# 159
union { 
# 160
key_type keys[tile_size]; 
# 161
value_type values[tile_size]; 
# 162
} stage; 
# 166
bulk_::copy_n(bulk_::bound< tile_size> (g), keys_first, n, stage.keys); 
# 168
key_type local_keys[grainsize]; 
# 169
bulk_::copy_n(bulk_::bound< grainsize> ((g.this_exec)), (stage.keys) + local_offset, local_size, local_keys); 
# 172
bulk_::copy_n(bulk_::bound< tile_size> (g), values_first, n, stage.values); 
# 174
value_type local_values[grainsize]; 
# 175
bulk_::copy_n(bulk_::bound< grainsize> ((g.this_exec)), (stage.values) + local_offset, local_size, local_values); 
# 178
bulk_::stable_sort_by_key(bulk_::bound< grainsize> ((g.this_exec)), local_keys, local_keys + local_size, local_values, comp); 
# 182
if (n == tile_size) 
# 183
{ 
# 184
stable_merge_sort_detail::inplace_merge_adjacent_partitions(g, local_keys, local_values, stage.keys, tile_size, grainsize, comp); 
# 185
} else 
# 187
{ 
# 188
stable_merge_sort_detail::inplace_merge_adjacent_partitions(g, local_keys, local_values, stage.keys, n, local_size, comp); 
# 189
}  
# 192
bulk_::copy_n(bulk_::bound< grainsize> ((g.this_exec)), local_keys, local_size, (stage.keys) + local_offset); 
# 193
(g.wait()); 
# 195
bulk_::copy_n(bulk_::bound< tile_size> (g), stage.keys, n, keys_first); 
# 198
bulk_::copy_n(bulk_::bound< grainsize> ((g.this_exec)), local_values, local_size, (stage.values) + local_offset); 
# 199
(g.wait()); 
# 201
bulk_::copy_n(bulk_::bound< tile_size> (g), stage.values, n, values_first); 
# 206
} 
#endif
# 209 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/detail/stable_merge_sort.hpp"
}
# 210
}
# 211
}}}}
# 24 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/sort.hpp"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 25
namespace bulk_ { 
# 27
namespace detail { 
# 29
namespace sort_detail { 
# 33
template< int i, int bound> 
# 34
struct stable_odd_even_transpose_sort_by_key_impl { 
# 36
template< class RandomAccessIterator1, class RandomAccessIterator2, class Compare> static void 
# 38
sort(RandomAccessIterator1 keys, RandomAccessIterator2 values, int n, Compare comp) 
# 39
{int volatile ___ = 1;(void)keys;(void)values;(void)n;(void)comp;
# 52
::exit(___);}
#if 0
# 39
{ 
# 40
for (int j = (1 & i); j < (bound - 1); j += 2) 
# 41
{ 
# 42
if (((j + 1) < n) && comp(keys[j + 1], keys[j])) 
# 43
{ 
# 44
using thrust::swap;
# 46
swap(keys[j], keys[j + 1]); 
# 47
swap(values[j], values[j + 1]); 
# 48
}  
# 49
}  
# 51
stable_odd_even_transpose_sort_by_key_impl< i + 1, bound> ::sort(keys, values, n, comp); 
# 52
} 
#endif
# 53 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/sort.hpp"
}; 
# 56
template< int i> struct stable_odd_even_transpose_sort_by_key_impl< i, i>  { 
# 58
template< class RandomAccessIterator1, class RandomAccessIterator2, class Compare> static void 
# 59
sort(RandomAccessIterator1, RandomAccessIterator2, int, Compare) {int volatile ___ = 1;::exit(___);}
#if 0
# 59
{ } 
#endif
# 60 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/sort.hpp"
}; 
# 63
template< std::size_t bound, std::size_t 
# 64
grainsize, class 
# 65
RandomAccessIterator1, class 
# 66
RandomAccessIterator2, class 
# 67
Compare> 
# 68
__attribute((always_inline)) __attribute__((unused)) inline void 
# 69
stable_odd_even_transpose_sort_by_key(const bounded< bound, agent< grainsize> >  &, RandomAccessIterator1 
# 70
keys_first, RandomAccessIterator1 keys_last, RandomAccessIterator2 
# 71
values_first, Compare 
# 72
comp) 
# 73
{int volatile ___ = 1;(void)keys_first;(void)keys_last;(void)values_first;(void)comp;
# 75
::exit(___);}
#if 0
# 73
{ 
# 74
stable_odd_even_transpose_sort_by_key_impl< 0, bound> ::sort(keys_first, values_first, keys_last - keys_first, comp); 
# 75
} 
#endif
# 78 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/sort.hpp"
template< int i, int bound> 
# 79
struct stable_odd_even_transpose_sort_impl { 
# 81
template< class RandomAccessIterator, class Compare> static void 
# 83
sort(RandomAccessIterator keys, int n, Compare comp) 
# 84
{int volatile ___ = 1;(void)keys;(void)n;(void)comp;
# 96
::exit(___);}
#if 0
# 84
{ 
# 85
for (int j = (1 & i); j < (bound - 1); j += 2) 
# 86
{ 
# 87
if (((j + 1) < n) && comp(keys[j + 1], keys[j])) 
# 88
{ 
# 89
using thrust::swap;
# 91
swap(keys[j], keys[j + 1]); 
# 92
}  
# 93
}  
# 95
stable_odd_even_transpose_sort_impl< i + 1, bound> ::sort(keys, n, comp); 
# 96
} 
#endif
# 97 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/sort.hpp"
}; 
# 100
template< int i> struct stable_odd_even_transpose_sort_impl< i, i>  { 
# 102
template< class RandomAccessIterator, class Compare> static void 
# 103
sort(RandomAccessIterator, int, Compare) {int volatile ___ = 1;::exit(___);}
#if 0
# 103
{ } 
#endif
# 104 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/sort.hpp"
}; 
# 107
template< std::size_t bound, std::size_t 
# 108
grainsize, class 
# 109
RandomAccessIterator, class 
# 110
Compare> 
# 111
__attribute((always_inline)) __attribute__((unused)) inline void 
# 112
stable_odd_even_transpose_sort(const bounded< bound, agent< grainsize> >  &, RandomAccessIterator 
# 113
first, RandomAccessIterator last, Compare 
# 114
comp) 
# 115
{int volatile ___ = 1;(void)first;(void)last;(void)comp;
# 117
::exit(___);}
#if 0
# 115
{ 
# 116
stable_odd_even_transpose_sort_impl< 0, bound> ::sort(first, last - first, comp); 
# 117
} 
#endif
# 120 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/sort.hpp"
}
# 121
}
# 124
template< std::size_t bound, std::size_t 
# 125
grainsize, class 
# 126
RandomAccessIterator1, class 
# 127
RandomAccessIterator2, class 
# 128
Compare> 
# 129
__attribute((always_inline)) __attribute__((unused)) inline void 
# 130
stable_sort_by_key(const bounded< bound, agent< grainsize> >  &exec, RandomAccessIterator1 
# 131
keys_first, RandomAccessIterator1 keys_last, RandomAccessIterator2 
# 132
values_first, Compare 
# 133
comp) 
# 134
{int volatile ___ = 1;(void)exec;(void)keys_first;(void)keys_last;(void)values_first;(void)comp;
# 136
::exit(___);}
#if 0
# 134
{ 
# 135
detail::sort_detail::stable_odd_even_transpose_sort_by_key(exec, keys_first, keys_last, values_first, comp); 
# 136
} 
#endif
# 139 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/sort.hpp"
template< std::size_t bound, std::size_t 
# 140
grainsize, class 
# 141
RandomAccessIterator, class 
# 142
Compare> 
# 143
__attribute((always_inline)) __attribute__((unused)) inline void 
# 144
stable_sort(const bounded< bound, agent< grainsize> >  &exec, RandomAccessIterator 
# 145
first, RandomAccessIterator last, Compare 
# 146
comp) 
# 147
{int volatile ___ = 1;(void)exec;(void)first;(void)last;(void)comp;
# 149
::exit(___);}
#if 0
# 147
{ 
# 148
detail::sort_detail::stable_odd_even_transpose_sort(exec, first, last, comp); 
# 149
} 
#endif
# 152 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/sort.hpp"
template< std::size_t bound, std::size_t groupsize, std::size_t grainsize, class 
# 153
RandomAccessIterator1, class 
# 154
RandomAccessIterator2, class 
# 155
Compare> __attribute__((unused)) typename thrust::detail::enable_if< bound <= (groupsize * grainsize)> ::type 
# 160
stable_sort_by_key(bounded< bound, concurrent_group< agent< grainsize> , groupsize> >  &g, RandomAccessIterator1 
# 161
keys_first, RandomAccessIterator1 keys_last, RandomAccessIterator2 
# 162
values_first, Compare 
# 163
comp) 
# 164
{int volatile ___ = 1;(void)g;(void)keys_first;(void)keys_last;(void)values_first;(void)comp;
# 166
::exit(___);}
#if 0
# 164
{ 
# 165
detail::stable_merge_sort_by_key(g, keys_first, keys_last, values_first, comp); 
# 166
} 
#endif
# 169 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/bulk/algorithm/sort.hpp"
}
# 170
}}}}
# 26 "/usr/local/cuda-8.0/include/thrust/detail/execute_with_allocator.h"
namespace thrust { 
# 28
namespace detail { 
# 31
template< class ToPointer, class FromPointer> ToPointer 
# 33
reinterpret_pointer_cast(FromPointer ptr) 
# 34
{ 
# 35
typedef typename pointer_element< ToPointer> ::type to_element; 
# 36
return (ToPointer)(reinterpret_cast< to_element *>(thrust::raw_pointer_cast(ptr))); 
# 37
} 
# 40
template< class Allocator, template< class >  class BaseSystem> 
# 41
struct execute_with_allocator : public BaseSystem< execute_with_allocator< Allocator, BaseSystem> >  { 
# 46
typedef BaseSystem< ::thrust::detail::execute_with_allocator< Allocator, BaseSystem> >  super_t; 
# 48
Allocator &m_alloc; 
# 51
execute_with_allocator(const super_t &super, Allocator &alloc) : super_t(super), m_alloc(alloc) 
# 54
{ } 
# 57
execute_with_allocator(Allocator &alloc) : m_alloc(alloc) 
# 59
{ } 
# 61
template< class T> friend inline pair< T *, long>  
# 64
get_temporary_buffer(execute_with_allocator &system, ::std::ptrdiff_t n) 
# 65
{ 
# 66
typedef allocator_traits< Allocator>  alloc_traits; 
# 67
typedef typename allocator_traits< Allocator> ::void_pointer void_pointer; 
# 68
typedef typename allocator_traits< Allocator> ::size_type size_type; 
# 69
typedef typename allocator_traits< Allocator> ::value_type value_type; 
# 72
size_type num_elements = thrust::detail::util::divide_ri(sizeof(T) * n, sizeof(value_type)); 
# 75
void_pointer ptr = alloc_traits::allocate(system.m_alloc, num_elements); 
# 78
return ::thrust::make_pair(detail::reinterpret_pointer_cast< T *> (ptr), n); 
# 79
} 
# 81
template< class Pointer> friend inline void 
# 82
return_temporary_buffer(execute_with_allocator &system, Pointer p) 
# 83
{ 
# 84
typedef allocator_traits< Allocator>  alloc_traits; 
# 85
typedef typename allocator_traits< Allocator> ::pointer pointer; 
# 88
pointer to_ptr = detail::reinterpret_pointer_cast< typename allocator_traits< Allocator> ::pointer> (p); 
# 89
alloc_traits::deallocate(system.m_alloc, to_ptr, 0); 
# 90
} 
# 91
}; 
# 94
}
# 95
}
# 24 "/usr/local/cuda-8.0/include/thrust/detail/seq.h"
namespace thrust { 
# 26
namespace detail { 
# 30
struct seq_t : public system::detail::sequential::execution_policy< seq_t>  { 
# 33
seq_t() : system::detail::sequential::execution_policy< seq_t> () { } 
# 36
template< class DerivedPolicy> 
# 38
seq_t(const thrust::execution_policy< DerivedPolicy>  &) : system::detail::sequential::execution_policy< seq_t> () 
# 40
{ } 
# 42
template< class Allocator> execute_with_allocator< Allocator, system::detail::sequential::execution_policy>  
# 44
operator()(Allocator &alloc) const 
# 45
{ 
# 46
return ((execute_with_allocator< Allocator, system::detail::sequential::execution_policy> )(alloc)); 
# 47
} 
# 48
}; 
# 51
}
# 57
static const detail::seq_t seq; 
# 61
}
# 23 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/execute_on_stream.h"
namespace thrust { 
# 25
namespace system { 
# 27
namespace cuda { 
# 29
namespace detail { 
# 34
inline cudaStream_t legacy_stream() 
# 35
{ 
# 39
return (cudaStream_t)1; 
# 41
} 
# 45
inline cudaStream_t default_stream() 
# 46
{ 
# 48
return legacy_stream(); 
# 49
} 
# 53
template< class DerivedPolicy> inline cudaStream_t 
# 55
stream(const execution_policy< DerivedPolicy>  &exec) 
# 56
{ 
# 57
return default_stream(); 
# 58
} 
# 62
template< class DerivedPolicy> 
# 63
class execute_on_stream_base : public execution_policy< DerivedPolicy>  { 
# 68
public: execute_on_stream_base() : m_stream(default_stream()) 
# 70
{ } 
# 73
execute_on_stream_base(::cudaStream_t stream) : m_stream(stream) 
# 75
{ } 
# 78
DerivedPolicy on(const ::cudaStream_t &s) const 
# 79
{ 
# 82
DerivedPolicy result = ::thrust::detail::derived_cast(*this); 
# 85
(result.set_stream(s)); 
# 87
return result; 
# 88
} 
# 93
friend inline ::cudaStream_t stream(const execute_on_stream_base &exec) 
# 94
{ 
# 95
return exec.m_stream; 
# 96
} 
# 99
private: void set_stream(const ::cudaStream_t &s) 
# 100
{ 
# 101
(m_stream) = s; 
# 102
} 
# 104
::cudaStream_t m_stream; 
# 105
}; 
# 109
class execute_on_stream : public execute_on_stream_base< execute_on_stream>  { 
# 112
typedef cuda::detail::execute_on_stream_base< execute_on_stream>  super_t; 
# 116
public: execute_on_stream(cudaStream_t stream) : super_t(stream) 
# 118
{ } 
# 119
}; 
# 122
}
# 123
}
# 124
}
# 125
}
# 31 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/for_each.inl"
namespace thrust { 
# 33
namespace system { 
# 35
namespace cuda { 
# 37
namespace detail { 
# 39
namespace for_each_n_detail { 
# 43
struct for_each_kernel { 
# 45
template< class Iterator, class Function, class Size> void 
# 47
operator()(bulk_::parallel_group< bulk_::concurrent_group<> >  &grid, Iterator first, Function f, Size n) 
# 48
{ 
# 49
Size grid_size = grid.size() * (grid.this_exec).size(); 
# 51
Size i = ((grid.this_exec).index() * (grid.this_exec).size()) + ((grid.this_exec).this_exec).index(); 
# 53
first += i; 
# 55
while (i < n) 
# 56
{ 
# 57
f(*first); 
# 58
i += grid_size; 
# 59
first += grid_size; 
# 60
}  
# 61
} 
# 62
}; 
# 65
template< class Size> bool 
# 67
use_wide_counter(Size n, unsigned narrow_grid_size) 
# 68
{ 
# 72
Size threshold = (static_cast< Size>(((2147483647) * 2U) + 1U)); 
# 74
bool result = (sizeof(Size) > sizeof(unsigned)) && (n > threshold); 
# 76
if (!result) 
# 77
{ 
# 79
unsigned narrow_n = static_cast< unsigned>(n); 
# 81
if (((narrow_n - 1U) + narrow_grid_size) < narrow_n) 
# 82
{ 
# 83
result = true; 
# 84
}  
# 85
}  
# 87
return result; 
# 88
} 
# 91
}
# 94
template< class DerivedPolicy, class 
# 95
RandomAccessIterator, class 
# 96
Size, class 
# 97
UnaryFunction> RandomAccessIterator 
# 99
for_each_n(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator 
# 100
first, Size 
# 101
n, UnaryFunction 
# 102
f) 
# 103
{ 
# 109
typedef thrust::detail::static_assert_test< sizeof(thrust::detail::STATIC_ASSERTION_FAILURE< (bool)(thrust::detail::depend_on_instantiation< RandomAccessIterator, true> ::value)> )>  thrust_static_assert_typedef_109 __attribute((unused)); 
# 111
struct workaround { 
# 114
static RandomAccessIterator parallel_path(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator first, Size n, UnaryFunction f) 
# 115
{ 
# 116
thrust::detail::wrapped_function< UnaryFunction, void>  wrapped_f(f); 
# 120
unsigned narrow_n = static_cast< unsigned>(n); 
# 121
unsigned narrow_num_groups = (0); 
# 122
unsigned narrow_group_size = (0); 
# 125
thrust::tie(narrow_num_groups, narrow_group_size) = bulk_::choose_sizes(bulk_::grid(), for_each_n_detail::for_each_kernel(), bulk_::root, first, wrapped_f, narrow_n); 
# 128
if (for_each_n_detail::use_wide_counter(n, narrow_num_groups * narrow_group_size)) 
# 129
{ 
# 130
Size num_groups = (0); 
# 131
Size group_size = (0); 
# 132
thrust::tie(num_groups, group_size) = bulk_::choose_sizes(bulk_::grid(), for_each_n_detail::for_each_kernel(), bulk_::root, first, wrapped_f, n); 
# 134
num_groups = thrust::min< Size> (num_groups, thrust::detail::util::divide_ri(n, group_size)); 
# 136
bulk_::async(bulk_::grid(num_groups, group_size, 0, stream(thrust::detail::derived_cast(exec))), for_each_n_detail::for_each_kernel(), bulk_::root, first, wrapped_f, n); 
# 137
} else 
# 139
{ 
# 141
narrow_num_groups = thrust::min< unsigned> (narrow_num_groups, thrust::detail::util::divide_ri(narrow_n, narrow_group_size)); 
# 143
bulk_::async(bulk_::grid(narrow_num_groups, narrow_group_size, 0, stream(thrust::detail::derived_cast(exec))), for_each_n_detail::for_each_kernel(), bulk_::root, first, wrapped_f, narrow_n); 
# 144
}  
# 146
return first + n; 
# 147
} 
# 150
static RandomAccessIterator sequential_path(execution_policy< DerivedPolicy>  &, RandomAccessIterator first, Size n, UnaryFunction f) 
# 151
{ 
# 152
return thrust::for_each_n(thrust::seq, first, n, f); 
# 153
} 
# 154
}; 
# 157
return (workaround::parallel_path)(exec, first, n, f); 
# 161
} 
# 164
template< class DerivedPolicy, class 
# 165
InputIterator, class 
# 166
UnaryFunction> InputIterator 
# 168
for_each(execution_policy< DerivedPolicy>  &exec, InputIterator 
# 169
first, InputIterator 
# 170
last, UnaryFunction 
# 171
f) 
# 172
{ 
# 173
return cuda::detail::for_each_n(exec, first, thrust::distance(first, last), f); 
# 174
} 
# 177
}
# 178
}
# 179
}
# 180
}
# 29 "/usr/local/cuda-8.0/include/thrust/detail/for_each.inl"
namespace thrust { 
# 33
template< class DerivedPolicy, class 
# 34
InputIterator, class 
# 35
UnaryFunction> InputIterator 
# 37
for_each(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator 
# 38
first, InputIterator 
# 39
last, UnaryFunction 
# 40
f) 
# 41
{ 
# 42
using system::detail::generic::for_each;
# 44
return for_each(detail::derived_cast(detail::strip_const(exec)), first, last, f); 
# 45
} 
# 48
template< class InputIterator, class 
# 49
UnaryFunction> InputIterator 
# 50
for_each(InputIterator first, InputIterator 
# 51
last, UnaryFunction 
# 52
f) 
# 53
{ 
# 54
using thrust::system::detail::generic::select_system;
# 55
typedef typename iterator_system< InputIterator> ::type System; 
# 57
System system; 
# 58
return thrust::for_each(select_system(system), first, last, f); 
# 59
} 
# 62
template< class DerivedPolicy, class InputIterator, class Size, class UnaryFunction> InputIterator 
# 64
for_each_n(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator 
# 65
first, Size 
# 66
n, UnaryFunction 
# 67
f) 
# 68
{ 
# 69
using system::detail::generic::for_each_n;
# 71
return for_each_n(detail::derived_cast(detail::strip_const(exec)), first, n, f); 
# 72
} 
# 75
template< class InputIterator, class 
# 76
Size, class 
# 77
UnaryFunction> InputIterator 
# 78
for_each_n(InputIterator first, Size 
# 79
n, UnaryFunction 
# 80
f) 
# 81
{ 
# 82
using thrust::system::detail::generic::select_system;
# 84
typedef typename iterator_system< InputIterator> ::type System; 
# 86
System system; 
# 87
return thrust::for_each_n(select_system(system), first, n, f); 
# 88
} 
# 91
}
# 26 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/transform.inl"
namespace thrust { 
# 28
namespace system { 
# 30
namespace detail { 
# 32
namespace generic { 
# 36
template< class DerivedPolicy, class 
# 37
InputIterator, class 
# 38
OutputIterator, class 
# 39
UnaryFunction> OutputIterator 
# 41
transform(execution_policy< DerivedPolicy>  &exec, InputIterator 
# 42
first, InputIterator 
# 43
last, OutputIterator 
# 44
result, UnaryFunction 
# 45
op) 
# 46
{ 
# 47
typedef thrust::detail::unary_transform_functor< UnaryFunction>  UnaryTransformFunctor; 
# 50
typedef tuple< InputIterator, OutputIterator, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type>  IteratorTuple; 
# 51
typedef zip_iterator< tuple< InputIterator, OutputIterator, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type> >  ZipIterator; 
# 53
ZipIterator zipped_result = thrust::for_each(exec, thrust::make_zip_iterator(thrust::make_tuple(first, result)), thrust::make_zip_iterator(thrust::make_tuple(last, result)), ((UnaryTransformFunctor)(op))); 
# 59
return thrust::get< 1> ((zipped_result.get_iterator_tuple())); 
# 60
} 
# 63
template< class DerivedPolicy, class 
# 64
InputIterator1, class 
# 65
InputIterator2, class 
# 66
OutputIterator, class 
# 67
BinaryFunction> OutputIterator 
# 69
transform(execution_policy< DerivedPolicy>  &exec, InputIterator1 
# 70
first1, InputIterator1 
# 71
last1, InputIterator2 
# 72
first2, OutputIterator 
# 73
result, BinaryFunction 
# 74
op) 
# 75
{ 
# 77
typedef thrust::detail::binary_transform_functor< BinaryFunction>  BinaryTransformFunctor; 
# 80
typedef tuple< InputIterator1, InputIterator2, OutputIterator, null_type, null_type, null_type, null_type, null_type, null_type, null_type>  IteratorTuple; 
# 81
typedef zip_iterator< tuple< InputIterator1, InputIterator2, OutputIterator, null_type, null_type, null_type, null_type, null_type, null_type, null_type> >  ZipIterator; 
# 83
ZipIterator zipped_result = thrust::for_each(exec, thrust::make_zip_iterator(thrust::make_tuple(first1, first2, result)), thrust::make_zip_iterator(thrust::make_tuple(last1, first2, result)), ((BinaryTransformFunctor)(op))); 
# 89
return thrust::get< 2> ((zipped_result.get_iterator_tuple())); 
# 90
} 
# 93
template< class DerivedPolicy, class 
# 94
InputIterator, class 
# 95
ForwardIterator, class 
# 96
UnaryFunction, class 
# 97
Predicate> ForwardIterator 
# 99
transform_if(execution_policy< DerivedPolicy>  &exec, InputIterator 
# 100
first, InputIterator 
# 101
last, ForwardIterator 
# 102
result, UnaryFunction 
# 103
unary_op, Predicate 
# 104
pred) 
# 105
{ 
# 106
typedef thrust::detail::unary_transform_if_functor< UnaryFunction, Predicate>  UnaryTransformIfFunctor; 
# 109
typedef tuple< InputIterator, ForwardIterator, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type>  IteratorTuple; 
# 110
typedef zip_iterator< tuple< InputIterator, ForwardIterator, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type> >  ZipIterator; 
# 112
ZipIterator zipped_result = thrust::for_each(exec, thrust::make_zip_iterator(thrust::make_tuple(first, result)), thrust::make_zip_iterator(thrust::make_tuple(last, result)), UnaryTransformIfFunctor(unary_op, pred)); 
# 118
return thrust::get< 1> ((zipped_result.get_iterator_tuple())); 
# 119
} 
# 122
template< class DerivedPolicy, class 
# 123
InputIterator1, class 
# 124
InputIterator2, class 
# 125
ForwardIterator, class 
# 126
UnaryFunction, class 
# 127
Predicate> ForwardIterator 
# 129
transform_if(execution_policy< DerivedPolicy>  &exec, InputIterator1 
# 130
first, InputIterator1 
# 131
last, InputIterator2 
# 132
stencil, ForwardIterator 
# 133
result, UnaryFunction 
# 134
unary_op, Predicate 
# 135
pred) 
# 136
{ 
# 137
typedef thrust::detail::unary_transform_if_with_stencil_functor< UnaryFunction, Predicate>  UnaryTransformIfFunctor; 
# 140
typedef tuple< InputIterator1, InputIterator2, ForwardIterator, null_type, null_type, null_type, null_type, null_type, null_type, null_type>  IteratorTuple; 
# 141
typedef zip_iterator< tuple< InputIterator1, InputIterator2, ForwardIterator, null_type, null_type, null_type, null_type, null_type, null_type, null_type> >  ZipIterator; 
# 143
ZipIterator zipped_result = thrust::for_each(exec, thrust::make_zip_iterator(thrust::make_tuple(first, stencil, result)), thrust::make_zip_iterator(thrust::make_tuple(last, stencil, result)), UnaryTransformIfFunctor(unary_op, pred)); 
# 149
return thrust::get< 2> ((zipped_result.get_iterator_tuple())); 
# 150
} 
# 153
template< class DerivedPolicy, class 
# 154
InputIterator1, class 
# 155
InputIterator2, class 
# 156
InputIterator3, class 
# 157
ForwardIterator, class 
# 158
BinaryFunction, class 
# 159
Predicate> ForwardIterator 
# 161
transform_if(execution_policy< DerivedPolicy>  &exec, InputIterator1 
# 162
first1, InputIterator1 
# 163
last1, InputIterator2 
# 164
first2, InputIterator3 
# 165
stencil, ForwardIterator 
# 166
result, BinaryFunction 
# 167
binary_op, Predicate 
# 168
pred) 
# 169
{ 
# 170
typedef thrust::detail::binary_transform_if_functor< BinaryFunction, Predicate>  BinaryTransformIfFunctor; 
# 173
typedef tuple< InputIterator1, InputIterator2, InputIterator3, ForwardIterator, null_type, null_type, null_type, null_type, null_type, null_type>  IteratorTuple; 
# 174
typedef zip_iterator< tuple< InputIterator1, InputIterator2, InputIterator3, ForwardIterator, null_type, null_type, null_type, null_type, null_type, null_type> >  ZipIterator; 
# 176
ZipIterator zipped_result = thrust::for_each(exec, thrust::make_zip_iterator(thrust::make_tuple(first1, first2, stencil, result)), thrust::make_zip_iterator(thrust::make_tuple(last1, first2, stencil, result)), BinaryTransformIfFunctor(binary_op, pred)); 
# 182
return thrust::get< 3> ((zipped_result.get_iterator_tuple())); 
# 183
} 
# 186
}
# 187
}
# 188
}
# 189
}
# 28 "/usr/local/cuda-8.0/include/thrust/detail/transform.inl"
namespace thrust { 
# 33
template< class DerivedPolicy, class 
# 34
InputIterator, class 
# 35
OutputIterator, class 
# 36
UnaryFunction> OutputIterator 
# 38
transform(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator 
# 39
first, InputIterator last, OutputIterator 
# 40
result, UnaryFunction 
# 41
op) 
# 42
{ 
# 43
using system::detail::generic::transform;
# 44
return transform(detail::derived_cast(detail::strip_const(exec)), first, last, result, op); 
# 45
} 
# 49
template< class DerivedPolicy, class 
# 50
InputIterator1, class 
# 51
InputIterator2, class 
# 52
OutputIterator, class 
# 53
BinaryFunction> OutputIterator 
# 55
transform(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator1 
# 56
first1, InputIterator1 last1, InputIterator2 
# 57
first2, OutputIterator 
# 58
result, BinaryFunction 
# 59
op) 
# 60
{ 
# 61
using system::detail::generic::transform;
# 62
return transform(detail::derived_cast(detail::strip_const(exec)), first1, last1, first2, result, op); 
# 63
} 
# 67
template< class DerivedPolicy, class 
# 68
InputIterator, class 
# 69
ForwardIterator, class 
# 70
UnaryFunction, class 
# 71
Predicate> ForwardIterator 
# 73
transform_if(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator 
# 74
first, InputIterator last, ForwardIterator 
# 75
result, UnaryFunction 
# 76
op, Predicate 
# 77
pred) 
# 78
{ 
# 79
using system::detail::generic::transform_if;
# 80
return transform_if(detail::derived_cast(detail::strip_const(exec)), first, last, result, op, pred); 
# 81
} 
# 85
template< class DerivedPolicy, class 
# 86
InputIterator1, class 
# 87
InputIterator2, class 
# 88
ForwardIterator, class 
# 89
UnaryFunction, class 
# 90
Predicate> ForwardIterator 
# 92
transform_if(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator1 
# 93
first, InputIterator1 last, InputIterator2 
# 94
stencil, ForwardIterator 
# 95
result, UnaryFunction 
# 96
op, Predicate 
# 97
pred) 
# 98
{ 
# 99
using system::detail::generic::transform_if;
# 100
return transform_if(detail::derived_cast(detail::strip_const(exec)), first, last, stencil, result, op, pred); 
# 101
} 
# 105
template< class DerivedPolicy, class 
# 106
InputIterator1, class 
# 107
InputIterator2, class 
# 108
InputIterator3, class 
# 109
ForwardIterator, class 
# 110
BinaryFunction, class 
# 111
Predicate> ForwardIterator 
# 113
transform_if(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator1 
# 114
first1, InputIterator1 last1, InputIterator2 
# 115
first2, InputIterator3 
# 116
stencil, ForwardIterator 
# 117
result, BinaryFunction 
# 118
binary_op, Predicate 
# 119
pred) 
# 120
{ 
# 121
using system::detail::generic::transform_if;
# 122
return transform_if(detail::derived_cast(detail::strip_const(exec)), first1, last1, first2, stencil, result, binary_op, pred); 
# 123
} 
# 126
template< class InputIterator, class 
# 127
OutputIterator, class 
# 128
UnaryFunction> OutputIterator 
# 129
transform(InputIterator first, InputIterator 
# 130
last, OutputIterator 
# 131
result, UnaryFunction 
# 132
op) 
# 133
{ 
# 134
using system::detail::generic::select_system;
# 136
typedef typename iterator_system< InputIterator> ::type System1; 
# 137
typedef typename iterator_system< OutputIterator> ::type System2; 
# 139
System1 system1; 
# 140
System2 system2; 
# 142
return thrust::transform(select_system(system1, system2), first, last, result, op); 
# 143
} 
# 146
template< class InputIterator1, class 
# 147
InputIterator2, class 
# 148
OutputIterator, class 
# 149
BinaryFunction> OutputIterator 
# 150
transform(InputIterator1 first1, InputIterator1 
# 151
last1, InputIterator2 
# 152
first2, OutputIterator 
# 153
result, BinaryFunction 
# 154
op) 
# 155
{ 
# 156
using system::detail::generic::select_system;
# 158
typedef typename iterator_system< InputIterator1> ::type System1; 
# 159
typedef typename iterator_system< InputIterator2> ::type System2; 
# 160
typedef typename iterator_system< OutputIterator> ::type System3; 
# 162
System1 system1; 
# 163
System2 system2; 
# 164
System3 system3; 
# 166
return thrust::transform(select_system(system1, system2, system3), first1, last1, first2, result, op); 
# 167
} 
# 170
template< class InputIterator, class 
# 171
ForwardIterator, class 
# 172
UnaryFunction, class 
# 173
Predicate> ForwardIterator 
# 174
transform_if(InputIterator first, InputIterator 
# 175
last, ForwardIterator 
# 176
result, UnaryFunction 
# 177
unary_op, Predicate 
# 178
pred) 
# 179
{ 
# 180
using system::detail::generic::select_system;
# 182
typedef typename iterator_system< InputIterator> ::type System1; 
# 183
typedef typename iterator_system< ForwardIterator> ::type System2; 
# 185
System1 system1; 
# 186
System2 system2; 
# 188
return thrust::transform_if(select_system(system1, system2), first, last, result, unary_op, pred); 
# 189
} 
# 192
template< class InputIterator1, class 
# 193
InputIterator2, class 
# 194
ForwardIterator, class 
# 195
UnaryFunction, class 
# 196
Predicate> ForwardIterator 
# 197
transform_if(InputIterator1 first, InputIterator1 
# 198
last, InputIterator2 
# 199
stencil, ForwardIterator 
# 200
result, UnaryFunction 
# 201
unary_op, Predicate 
# 202
pred) 
# 203
{ 
# 204
using system::detail::generic::select_system;
# 206
typedef typename iterator_system< InputIterator1> ::type System1; 
# 207
typedef typename iterator_system< InputIterator2> ::type System2; 
# 208
typedef typename iterator_system< ForwardIterator> ::type System3; 
# 210
System1 system1; 
# 211
System2 system2; 
# 212
System3 system3; 
# 214
return thrust::transform_if(select_system(system1, system2, system3), first, last, stencil, result, unary_op, pred); 
# 215
} 
# 218
template< class InputIterator1, class 
# 219
InputIterator2, class 
# 220
InputIterator3, class 
# 221
ForwardIterator, class 
# 222
BinaryFunction, class 
# 223
Predicate> ForwardIterator 
# 224
transform_if(InputIterator1 first1, InputIterator1 
# 225
last1, InputIterator2 
# 226
first2, InputIterator3 
# 227
stencil, ForwardIterator 
# 228
result, BinaryFunction 
# 229
binary_op, Predicate 
# 230
pred) 
# 231
{ 
# 232
using system::detail::generic::select_system;
# 234
typedef typename iterator_system< InputIterator1> ::type System1; 
# 235
typedef typename iterator_system< InputIterator2> ::type System2; 
# 236
typedef typename iterator_system< InputIterator3> ::type System3; 
# 237
typedef typename iterator_system< ForwardIterator> ::type System4; 
# 239
System1 system1; 
# 240
System2 system2; 
# 241
System3 system3; 
# 242
System4 system4; 
# 244
return thrust::transform_if(select_system(system1, system2, system3, system4), first1, last1, first2, stencil, result, binary_op, pred); 
# 245
} 
# 248
}
# 29 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/copy.inl"
namespace thrust { 
# 31
namespace system { 
# 33
namespace detail { 
# 35
namespace generic { 
# 39
template< class DerivedPolicy, class 
# 40
InputIterator, class 
# 41
OutputIterator> OutputIterator 
# 43
copy(execution_policy< DerivedPolicy>  &exec, InputIterator 
# 44
first, InputIterator 
# 45
last, OutputIterator 
# 46
result) 
# 47
{ 
# 48
typedef typename iterator_value< InputIterator> ::type T; 
# 49
return thrust::transform(exec, first, last, result, identity< typename iterator_value< InputIterator> ::type> ()); 
# 50
} 
# 53
template< class DerivedPolicy, class 
# 54
InputIterator, class 
# 55
Size, class 
# 56
OutputIterator> OutputIterator 
# 58
copy_n(execution_policy< DerivedPolicy>  &exec, InputIterator 
# 59
first, Size 
# 60
n, OutputIterator 
# 61
result) 
# 62
{ 
# 63
typedef typename iterator_value< InputIterator> ::type value_type; 
# 64
typedef identity< typename iterator_value< InputIterator> ::type>  xfrm_type; 
# 66
typedef thrust::detail::unary_transform_functor< identity< typename iterator_value< InputIterator> ::type> >  functor_type; 
# 68
typedef tuple< InputIterator, OutputIterator, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type>  iterator_tuple; 
# 69
typedef zip_iterator< tuple< InputIterator, OutputIterator, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type> >  zip_iter; 
# 71
zip_iter zipped = thrust::make_zip_iterator(thrust::make_tuple(first, result)); 
# 73
return thrust::get< 1> ((thrust::for_each_n(exec, zipped, n, ((functor_type)(xfrm_type()))).get_iterator_tuple())); 
# 74
} 
# 77
}
# 78
}
# 79
}
# 80
}
# 26 "/usr/local/cuda-8.0/include/thrust/system/detail/sequential/copy.h"
namespace thrust { 
# 28
namespace system { 
# 30
namespace detail { 
# 32
namespace sequential { 
# 36
template< class DerivedPolicy, class 
# 37
InputIterator, class 
# 38
OutputIterator> OutputIterator 
# 36
copy(execution_policy< DerivedPolicy>  & exec, InputIterator first, InputIterator last, OutputIterator result); 
# 46
template< class DerivedPolicy, class 
# 47
InputIterator, class 
# 48
Size, class 
# 49
OutputIterator> OutputIterator 
# 46
copy_n(execution_policy< DerivedPolicy>  & exec, InputIterator first, Size n, OutputIterator result); 
# 57
}
# 58
}
# 59
}
# 60
}
# 28 "/usr/local/cuda-8.0/include/thrust/detail/dispatch/is_trivial_copy.h"
namespace thrust { 
# 31
namespace detail { 
# 34
namespace dispatch { 
# 41
template< class FromIterator, class ToIterator> 
# 42
struct is_trivial_copy : public integral_constant< bool, is_same< typename iterator_value< FromIterator> ::type, typename iterator_value< ToIterator> ::type> ::value && is_trivial_iterator< FromIterator> ::value && is_trivial_iterator< ToIterator> ::value && has_trivial_assign< typename iterator_value< ToIterator> ::type> ::value>  { 
# 52
}; 
# 54
}
# 56
}
# 58
}
# 27 "/usr/local/cuda-8.0/include/thrust/system/detail/sequential/general_copy.h"
namespace thrust { 
# 29
namespace system { 
# 31
namespace detail { 
# 33
namespace sequential { 
# 35
namespace general_copy_detail { 
# 39
template< class T1, class T2> 
# 40
struct lazy_is_assignable : public thrust::detail::is_assignable< typename T1::type, typename T2::type>  { 
# 45
}; 
# 50
template< class InputIterator, class OutputIterator> 
# 51
struct reference_is_assignable : public thrust::detail::eval_if< thrust::detail::is_same< typename iterator_reference< OutputIterator> ::type, void> ::value, thrust::detail::integral_constant< bool, true> , lazy_is_assignable< iterator_reference< OutputIterator> , iterator_reference< InputIterator> > > ::type { 
# 62
}; 
# 69
template< class OutputIterator, class InputIterator> inline typename thrust::detail::enable_if< reference_is_assignable< InputIterator, OutputIterator> ::value> ::type 
# 74
iter_assign(OutputIterator dst, InputIterator src) 
# 75
{ 
# 76
(*dst) = (*src); 
# 77
} 
# 81
template< class OutputIterator, class InputIterator> inline typename thrust::detail::disable_if< reference_is_assignable< InputIterator, OutputIterator> ::value> ::type 
# 86
iter_assign(OutputIterator dst, InputIterator src) 
# 87
{ 
# 88
typedef typename iterator_value< InputIterator> ::type value_type; 
# 91
(*dst) = (static_cast< value_type>(*src)); 
# 92
} 
# 95
}
# 99
template< class InputIterator, class 
# 100
OutputIterator> OutputIterator 
# 102
general_copy(InputIterator first, InputIterator 
# 103
last, OutputIterator 
# 104
result) 
# 105
{ 
# 106
for (; first != last; (++first), (++result)) 
# 107
{ 
# 112
general_copy_detail::iter_assign(result, first); 
# 114
}  
# 116
return result; 
# 117
} 
# 121
template< class InputIterator, class 
# 122
Size, class 
# 123
OutputIterator> OutputIterator 
# 125
general_copy_n(InputIterator first, Size 
# 126
n, OutputIterator 
# 127
result) 
# 128
{ 
# 129
for (; n > ((Size)0); ((++first), (++result)), (--n)) 
# 130
{ 
# 135
general_copy_detail::iter_assign(result, first); 
# 137
}  
# 139
return result; 
# 140
} 
# 143
}
# 144
}
# 145
}
# 146
}
# 27 "/usr/local/cuda-8.0/include/thrust/system/detail/sequential/trivial_copy.h"
namespace thrust { 
# 29
namespace system { 
# 31
namespace detail { 
# 33
namespace sequential { 
# 37
template< class T> T *
# 39
trivial_copy_n(const T *first, std::ptrdiff_t 
# 40
n, T *
# 41
result) 
# 42
{ 
# 44
std::memmove(result, first, n * sizeof(T)); 
# 45
return result + n; 
# 49
} 
# 52
}
# 53
}
# 54
}
# 55
}
# 26 "/usr/local/cuda-8.0/include/thrust/system/detail/sequential/copy.inl"
namespace thrust { 
# 28
namespace system { 
# 30
namespace detail { 
# 32
namespace sequential { 
# 34
namespace copy_detail { 
# 39
template< class Pointer> typename thrust::detail::pointer_traits< Pointer> ::raw_pointer 
# 42
get(Pointer ptr) 
# 43
{ 
# 44
return thrust::detail::pointer_traits< Pointer> ::get(ptr); 
# 45
} 
# 49
template< class InputIterator, class 
# 50
OutputIterator> OutputIterator 
# 52
copy(InputIterator first, InputIterator 
# 53
last, OutputIterator 
# 54
result, thrust::detail::true_type) 
# 56
{ 
# 57
typedef typename iterator_difference< InputIterator> ::type Size; 
# 59
const Size n = last - first; 
# 60
sequential::trivial_copy_n(get(&(*first)), n, get(&(*result))); 
# 61
return result + n; 
# 62
} 
# 66
template< class InputIterator, class 
# 67
OutputIterator> OutputIterator 
# 69
copy(InputIterator first, InputIterator 
# 70
last, OutputIterator 
# 71
result, thrust::detail::false_type) 
# 73
{ 
# 74
return sequential::general_copy(first, last, result); 
# 75
} 
# 79
template< class InputIterator, class 
# 80
Size, class 
# 81
OutputIterator> OutputIterator 
# 83
copy_n(InputIterator first, Size 
# 84
n, OutputIterator 
# 85
result, thrust::detail::true_type) 
# 87
{ 
# 88
sequential::trivial_copy_n(get(&(*first)), n, get(&(*result))); 
# 89
return result + n; 
# 90
} 
# 93
template< class InputIterator, class 
# 94
Size, class 
# 95
OutputIterator> OutputIterator 
# 97
copy_n(InputIterator first, Size 
# 98
n, OutputIterator 
# 99
result, thrust::detail::false_type) 
# 101
{ 
# 102
return sequential::general_copy_n(first, n, result); 
# 103
} 
# 106
}
# 110
template< class DerivedPolicy, class 
# 111
InputIterator, class 
# 112
OutputIterator> OutputIterator 
# 114
copy(execution_policy< DerivedPolicy>  &, InputIterator 
# 115
first, InputIterator 
# 116
last, OutputIterator 
# 117
result) 
# 118
{ 
# 119
return copy_detail::copy(first, last, result, typename thrust::detail::dispatch::is_trivial_copy< InputIterator, OutputIterator> ::type()); 
# 121
} 
# 124
template< class DerivedPolicy, class 
# 125
InputIterator, class 
# 126
Size, class 
# 127
OutputIterator> OutputIterator 
# 129
copy_n(execution_policy< DerivedPolicy>  &, InputIterator 
# 130
first, Size 
# 131
n, OutputIterator 
# 132
result) 
# 133
{ 
# 134
return copy_detail::copy_n(first, n, result, typename thrust::detail::dispatch::is_trivial_copy< InputIterator, OutputIterator> ::type()); 
# 136
} 
# 139
}
# 140
}
# 141
}
# 142
}
# 23 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/copy.h"
namespace thrust { 
# 25
namespace system { 
# 27
namespace cuda { 
# 29
namespace detail { 
# 33
template< class DerivedPolicy, class 
# 34
InputIterator, class 
# 35
OutputIterator> OutputIterator 
# 33
copy(execution_policy< DerivedPolicy>  & exec, InputIterator first, InputIterator last, OutputIterator result); 
# 43
template< class System1, class 
# 44
System2, class 
# 45
InputIterator, class 
# 46
OutputIterator> OutputIterator 
# 43
copy(cross_system< System1, System2>  exec, InputIterator first, InputIterator last, OutputIterator result); 
# 53
template< class DerivedPolicy, class 
# 54
InputIterator, class 
# 55
Size, class 
# 56
OutputIterator> OutputIterator 
# 53
copy_n(execution_policy< DerivedPolicy>  & exec, InputIterator first, Size n, OutputIterator result); 
# 64
template< class System1, class 
# 65
System2, class 
# 66
InputIterator, class 
# 67
Size, class 
# 68
OutputIterator> OutputIterator 
# 64
copy_n(cross_system< System1, System2>  exec, InputIterator first, Size n, OutputIterator result); 
# 75
}
# 76
}
# 77
}
# 78
}
# 27 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/copy_device_to_device.h"
namespace thrust { 
# 29
namespace system { 
# 31
namespace cuda { 
# 33
namespace detail { 
# 37
template< class DerivedPolicy, class 
# 38
InputIterator, class 
# 39
OutputIterator> OutputIterator 
# 37
copy_device_to_device(execution_policy< DerivedPolicy>  & exec, InputIterator begin, InputIterator end, OutputIterator result); 
# 46
}
# 47
}
# 48
}
# 49
}
# 22 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/copy_cross_system.h"
namespace thrust { 
# 24
namespace system { 
# 26
namespace cuda { 
# 28
namespace detail { 
# 32
template< class System1, class 
# 33
System2, class 
# 34
InputIterator, class 
# 35
OutputIterator> OutputIterator 
# 32
copy_cross_system(cross_system< System1, System2>  systems, InputIterator begin, InputIterator end, OutputIterator result); 
# 42
template< class System1, class 
# 43
System2, class 
# 44
InputIterator, class 
# 45
Size, class 
# 46
OutputIterator> OutputIterator 
# 42
copy_cross_system_n(cross_system< System1, System2>  systems, InputIterator begin, Size n, OutputIterator result); 
# 53
}
# 54
}
# 55
}
# 56
}
# 24 "/usr/local/cuda-8.0/include/thrust/iterator/detail/tagged_iterator.h"
namespace thrust { 
# 26
namespace detail { 
# 29
template< class , class > class tagged_iterator; 
# 31
template< class Iterator, class Tag> 
# 32
struct tagged_iterator_base { 
# 42
typedef iterator_adaptor< tagged_iterator< Iterator, Tag> , Iterator, typename iterator_value< Iterator> ::type, Tag, typename iterator_traversal< Iterator> ::type, typename iterator_reference< Iterator> ::type, typename iterator_difference< Iterator> ::type>  type; 
# 43
}; 
# 45
template< class Iterator, class Tag> 
# 46
class tagged_iterator : public tagged_iterator_base< Iterator, Tag> ::type { 
# 50
typedef typename tagged_iterator_base< Iterator, Tag> ::type super_t; 
# 54
public: tagged_iterator() { } 
# 57
explicit tagged_iterator(Iterator x) : super_t(x) 
# 58
{ } 
# 59
}; 
# 63
template< class > struct is_trivial_iterator; 
# 66
template< class BaseIterator, class Tag> 
# 67
struct is_trivial_iterator< tagged_iterator< BaseIterator, Tag> >  : public is_trivial_iterator< BaseIterator>  { 
# 69
}; 
# 72
}
# 73
}
# 23 "/usr/local/cuda-8.0/include/thrust/detail/allocator/tagged_allocator.h"
namespace thrust { 
# 25
namespace detail { 
# 28
template< class T, class Tag, class Pointer> class tagged_allocator; 
# 30
template< class Tag, class Pointer> 
# 31
class tagged_allocator< void, Tag, Pointer>  { 
# 34
public: typedef void value_type; 
# 35
typedef typename pointer_traits< Pointer> ::template rebind< void> ::other pointer; 
# 36
typedef typename pointer_traits< Pointer> ::template rebind< const void> ::other const_pointer; 
# 37
typedef std::size_t size_type; 
# 38
typedef typename pointer_traits< Pointer> ::difference_type difference_type; 
# 39
typedef Tag system_type; 
# 41
template< class U> 
# 42
struct rebind { 
# 44
typedef detail::tagged_allocator< U, Tag, Pointer>  other; 
# 45
}; 
# 46
}; 
# 48
template< class T, class Tag, class Pointer> 
# 49
class tagged_allocator { 
# 52
public: typedef T value_type; 
# 53
typedef typename pointer_traits< Pointer> ::template rebind< T> ::other pointer; 
# 54
typedef typename pointer_traits< Pointer> ::template rebind< const T> ::other const_pointer; 
# 55
typedef typename iterator_reference< typename pointer_traits< Pointer> ::template rebind< T> ::other> ::type reference; 
# 56
typedef typename iterator_reference< typename pointer_traits< Pointer> ::template rebind< const T> ::other> ::type const_reference; 
# 57
typedef std::size_t size_type; 
# 58
typedef typename pointer_traits< typename pointer_traits< Pointer> ::template rebind< T> ::other> ::difference_type difference_type; 
# 59
typedef Tag system_type; 
# 61
template< class U> 
# 62
struct rebind { 
# 64
typedef detail::tagged_allocator< U, Tag, Pointer>  other; 
# 65
}; 
# 68
inline tagged_allocator(); 
# 71
inline tagged_allocator(const tagged_allocator &); 
# 73
template< class U, class OtherPointer> inline tagged_allocator(const detail::tagged_allocator< U, Tag, OtherPointer>  &); 
# 78
inline ~tagged_allocator(); 
# 81
pointer address(reference x) const; 
# 84
const_pointer address(const_reference x) const; 
# 86
size_type max_size() const; 
# 87
}; 
# 89
template< class T1, class Pointer1, class T2, class Pointer2, class Tag> bool operator==(const tagged_allocator< T1, Pointer1, Tag>  &, const tagged_allocator< T2, Pointer2, Tag>  &); 
# 93
template< class T1, class Pointer1, class T2, class Pointer2, class Tag> bool operator!=(const tagged_allocator< T1, Pointer1, Tag>  &, const tagged_allocator< T2, Pointer2, Tag>  &); 
# 97
}
# 98
}
# 21 "/usr/local/cuda-8.0/include/thrust/detail/allocator/tagged_allocator.inl"
namespace thrust { 
# 23
namespace detail { 
# 27
template< class T, class Tag, class Pointer> inline 
# 29
tagged_allocator< T, Tag, Pointer> ::tagged_allocator() 
# 30
{ } 
# 33
template< class T, class Tag, class Pointer> inline 
# 35
tagged_allocator< T, Tag, Pointer> ::tagged_allocator(const tagged_allocator &) 
# 36
{ } 
# 39
template< class T, class Tag, class Pointer> 
# 40
template< class U, class OtherPointer> inline 
# 42
tagged_allocator< T, Tag, Pointer> ::tagged_allocator(const detail::tagged_allocator< U, Tag, OtherPointer>  &) 
# 43
{ } 
# 46
template< class T, class Tag, class Pointer> inline 
# 48
tagged_allocator< T, Tag, Pointer> ::~tagged_allocator() 
# 49
{ } 
# 52
template< class T, class Tag, class Pointer> typename tagged_allocator< T, Tag, Pointer> ::pointer 
# 55
tagged_allocator< T, Tag, Pointer> ::address(reference x) const 
# 56
{ 
# 57
return &x; 
# 58
} 
# 61
template< class T, class Tag, class Pointer> typename tagged_allocator< T, Tag, Pointer> ::const_pointer 
# 64
tagged_allocator< T, Tag, Pointer> ::address(const_reference x) const 
# 65
{ 
# 66
return &x; 
# 67
} 
# 70
template< class T, class Tag, class Pointer> typename tagged_allocator< T, Tag, Pointer> ::size_type 
# 73
tagged_allocator< T, Tag, Pointer> ::max_size() const 
# 74
{ 
# 75
return std::numeric_limits< unsigned long> ::max() / sizeof(T); 
# 76
} 
# 79
template< class T1, class Pointer1, class T2, class Pointer2, class Tag> bool 
# 81
operator==(const tagged_allocator< T1, Pointer1, Tag>  &, const tagged_allocator< T2, Pointer2, Tag>  &) 
# 82
{ 
# 83
return true; 
# 84
} 
# 87
template< class T1, class Pointer1, class T2, class Pointer2, class Tag> bool 
# 89
operator!=(const tagged_allocator< T1, Pointer1, Tag>  &, const tagged_allocator< T2, Pointer2, Tag>  &) 
# 90
{ 
# 91
return false; 
# 92
} 
# 95
}
# 96
}
# 28 "/usr/local/cuda-8.0/include/thrust/detail/pointer.h"
namespace thrust { 
# 32
template< class Element, class Tag, class Reference = use_default, class Derived = use_default> class pointer; 
# 34
}
# 41
namespace thrust { 
# 44
template< class Element, class Tag, class Reference, class Derived> 
# 45
struct iterator_traits< pointer< Element, Tag, Reference, Derived> >  { 
# 48
private: typedef thrust::pointer< Element, Tag, Reference, Derived>  ptr; 
# 51
public: typedef typename thrust::pointer< Element, Tag, Reference, Derived> ::iterator_category iterator_category; 
# 52
typedef typename thrust::pointer< Element, Tag, Reference, Derived> ::value_type value_type; 
# 53
typedef typename thrust::pointer< Element, Tag, Reference, Derived> ::difference_type difference_type; 
# 55
typedef void pointer; 
# 56
typedef typename thrust::pointer< Element, Tag, Reference, Derived> ::reference reference; 
# 57
}; 
# 59
}
# 62
namespace thrust { 
# 65
namespace detail { 
# 69
template< class Element, class Tag, class Reference, class Derived> 
# 70
struct pointer_base { 
# 78
typedef typename eval_if< is_void< typename remove_const< Element> ::type> ::value, identity_< void> , remove_cv< Element> > ::type value_type; 
# 85
typedef typename eval_if< is_same< Derived, use_default> ::value, identity_< pointer< Element, Tag, Reference, Derived> > , identity_< Derived> > ::type derived_type; 
# 97
typedef typename eval_if< is_void< typename remove_const< Element> ::type> ::value, identity_< void> , eval_if< is_same< Reference, use_default> ::value, identity_< reference< Element, typename eval_if< is_same< Derived, use_default> ::value, identity_< pointer< Element, Tag, Reference, Derived> > , identity_< Derived> > ::type> > , identity_< Reference> > > ::type reference_arg; 
# 107
typedef iterator_adaptor< typename eval_if< is_same< Derived, use_default> ::value, identity_< pointer< Element, Tag, Reference, Derived> > , identity_< Derived> > ::type, Element *, typename eval_if< is_void< typename remove_const< Element> ::type> ::value, identity_< void> , remove_cv< Element> > ::type, Tag, random_access_traversal_tag, typename eval_if< is_void< typename remove_const< Element> ::type> ::value, identity_< void> , eval_if< is_same< Reference, use_default> ::value, identity_< reference< Element, typename eval_if< is_same< Derived, use_default> ::value, identity_< pointer< Element, Tag, Reference, Derived> > , identity_< Derived> > ::type> > , identity_< Reference> > > ::type, long>  type; 
# 108
}; 
# 111
}
# 121
template< class Element, class Tag, class Reference, class Derived> 
# 122
class pointer : public detail::pointer_base< Element, Tag, Reference, Derived> ::type { 
# 126
typedef typename ::thrust::detail::pointer_base< Element, Tag, Reference, Derived> ::type super_t; 
# 128
typedef typename ::thrust::detail::pointer_base< Element, Tag, Reference, Derived> ::derived_type derived_type; 
# 131
friend class iterator_core_access; 
# 134
typename ::thrust::detail::pointer_base< Element, Tag, Reference, Derived> ::type::reference dereference() const; 
# 137
using ::thrust::detail::pointer_base< Element, Tag, Reference, Derived> ::type::base;
# 138
using ::thrust::detail::pointer_base< Element, Tag, Reference, Derived> ::type::base_type;
# 141
public: typedef typename ::thrust::detail::pointer_base< Element, Tag, Reference, Derived> ::type::base_type raw_pointer; 
# 146
pointer(); 
# 150
template< class OtherElement> explicit pointer(OtherElement * ptr); 
# 156
template< class OtherPointer> pointer(const OtherPointer & other, typename ::thrust::detail::enable_if_pointer_is_convertible< OtherPointer, pointer> ::type * = 0); 
# 168
template< class OtherPointer> typename ::thrust::detail::enable_if_pointer_is_convertible< OtherPointer, pointer, typename ::thrust::detail::pointer_base< Element, Tag, Reference, Derived> ::derived_type &> ::type operator=(const OtherPointer & other); 
# 180
Element *get() const; 
# 181
}; 
# 184
template< class Element, class Tag, class Reference, class Derived, class 
# 185
charT, class traits> std::basic_ostream< charT, traits>  &
# 184
operator<<(std::basic_ostream< charT, traits>  & os, const pointer< Element, Tag, Reference, Derived>  & p); 
# 190
}
# 21 "/usr/local/cuda-8.0/include/thrust/detail/pointer.inl"
namespace thrust { 
# 25
template< class Element, class Tag, class Reference, class Derived> 
# 27
pointer< Element, Tag, Reference, Derived> ::pointer() : super_t(static_cast< Element *>(0)) 
# 29
{ } 
# 32
template< class Element, class Tag, class Reference, class Derived> 
# 33
template< class OtherElement> 
# 35
pointer< Element, Tag, Reference, Derived> ::pointer(OtherElement *other) : super_t(other) 
# 37
{ } 
# 40
template< class Element, class Tag, class Reference, class Derived> 
# 41
template< class OtherPointer> 
# 43
pointer< Element, Tag, Reference, Derived> ::pointer(const OtherPointer &other, typename ::thrust::detail::enable_if_pointer_is_convertible< OtherPointer, pointer> ::type *) : super_t(thrust::detail::pointer_traits< OtherPointer> ::get(other)) 
# 49
{ } 
# 52
template< class Element, class Tag, class Reference, class Derived> 
# 53
template< class OtherPointer> typename detail::enable_if_pointer_is_convertible< OtherPointer, pointer< Element, Tag, Reference, Derived> , typename detail::pointer_base< Element, Tag, Reference, Derived> ::derived_type &> ::type 
# 60
pointer< Element, Tag, Reference, Derived> ::operator=(const OtherPointer &other) 
# 61
{ 
# 62
super_t::base_reference() = thrust::detail::pointer_traits< OtherPointer> ::get(other); 
# 63
return static_cast< derived_type &>(*this); 
# 64
} 
# 67
template< class Element, class Tag, class Reference, class Derived> typename detail::pointer_base< Element, Tag, Reference, Derived> ::type::reference 
# 70
pointer< Element, Tag, Reference, Derived> ::dereference() const 
# 71
{ 
# 72
return (typename ::thrust::detail::pointer_base< Element, Tag, Reference, Derived> ::type::reference)(static_cast< const derived_type &>(*this)); 
# 73
} 
# 76
template< class Element, class Tag, class Reference, class Derived> Element *
# 78
pointer< Element, Tag, Reference, Derived> ::get() const 
# 79
{ 
# 80
return super_t::base(); 
# 81
} 
# 83
template< class Element, class Tag, class Reference, class Derived, class 
# 84
charT, class traits> std::basic_ostream< charT, traits>  &
# 86
operator<<(std::basic_ostream< charT, traits>  &os, const pointer< Element, Tag, Reference, Derived>  &
# 87
p) { 
# 88
return os << (p.get()); 
# 89
} 
# 91
namespace detail { 
# 146
}
# 149
}
# 26 "/usr/local/cuda-8.0/include/thrust/detail/reference.h"
namespace thrust { 
# 28
namespace detail { 
# 31
template< class > struct is_wrapped_reference; 
# 33
}
# 42
template< class Element, class Pointer, class Derived> 
# 43
class reference { 
# 50
typedef typename detail::eval_if< detail::is_same< Derived, use_default> ::value, detail::identity_< reference> , detail::identity_< Derived> > ::type derived_type; 
# 54
struct wrapped_reference_hint { }; 
# 55
template< class > friend struct detail::is_wrapped_reference; 
# 58
public: typedef Pointer pointer; 
# 59
typedef typename detail::remove_const< Element> ::type value_type; 
# 62
explicit reference(const pointer & ptr); 
# 64
template< class OtherElement, class OtherPointer, class OtherDerived> reference(const thrust::reference< OtherElement, OtherPointer, OtherDerived>  & other, typename detail::enable_if_convertible< typename thrust::reference< OtherElement, OtherPointer, OtherDerived> ::pointer, Pointer> ::type * = 0); 
# 73
derived_type &operator=(const reference & other); 
# 76
template< class OtherElement, class OtherPointer, class OtherDerived> derived_type &operator=(const thrust::reference< OtherElement, OtherPointer, OtherDerived>  & other); 
# 81
derived_type &operator=(const value_type & x); 
# 84
pointer operator&() const; 
# 87
operator value_type() const; 
# 90
void swap(derived_type & other); 
# 92
derived_type &operator++(); 
# 94
value_type operator++(int); 
# 97
derived_type &operator+=(const value_type & rhs); 
# 99
derived_type &operator--(); 
# 101
value_type operator--(int); 
# 104
derived_type &operator-=(const value_type & rhs); 
# 107
derived_type &operator*=(const value_type & rhs); 
# 110
derived_type &operator/=(const value_type & rhs); 
# 113
derived_type &operator%=(const value_type & rhs); 
# 116
derived_type &operator<<=(const value_type & rhs); 
# 119
derived_type &operator>>=(const value_type & rhs); 
# 122
derived_type &operator&=(const value_type & rhs); 
# 125
derived_type &operator|=(const value_type & rhs); 
# 128
derived_type &operator^=(const value_type & rhs); 
# 131
private: const pointer m_ptr; 
# 134
template< class OtherElement, class OtherPointer, class OtherDerived> friend class reference; 
# 136
template< class System> inline value_type strip_const_get_value(const System & system) const; 
# 140
template< class OtherPointer> inline void assign_from(OtherPointer src); 
# 145
template< class System1, class System2, class OtherPointer> inline void assign_from(System1 * system1, System2 * system2, OtherPointer src); 
# 149
template< class System, class OtherPointer> inline void strip_const_assign_value(const System & system, OtherPointer src); 
# 154
template< class System> inline void swap(System * system, derived_type & other); 
# 159
template< class System> inline value_type convert_to_value_type(System * system) const; 
# 162
}; 
# 165
template< class Element, class Pointer, class Derived, class 
# 166
charT, class traits> std::basic_ostream< charT, traits>  &
# 165
operator<<(std::basic_ostream< charT, traits>  & os, const reference< Element, Pointer, Derived>  & y); 
# 171
}
# 33 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/memory.h"
namespace thrust { 
# 35
namespace system { 
# 37
namespace detail { 
# 39
namespace generic { 
# 42
template< class DerivedPolicy, class Size> void malloc(execution_policy< DerivedPolicy>  &, Size); 
# 46
template< class T, class DerivedPolicy> pointer< T, DerivedPolicy, use_default, use_default>  malloc(execution_policy< DerivedPolicy>  & s, std::size_t n); 
# 50
template< class DerivedPolicy, class Pointer> void free(execution_policy< DerivedPolicy>  &, Pointer); 
# 54
template< class Pointer1, class Pointer2> void assign_value(tag, Pointer1, Pointer2); 
# 58
template< class DerivedPolicy, class Pointer> void get_value(execution_policy< DerivedPolicy>  &, Pointer); 
# 62
template< class Pointer1, class Pointer2> void iter_swap(tag, Pointer1, Pointer2); 
# 66
}
# 67
}
# 68
}
# 69
}
# 24 "/usr/local/cuda-8.0/include/thrust/system/detail/sequential/malloc_and_free.h"
namespace thrust { 
# 26
namespace system { 
# 28
namespace detail { 
# 30
namespace sequential { 
# 34
template< class DerivedPolicy> inline void *
# 36
malloc(execution_policy< DerivedPolicy>  &, std::size_t n) 
# 37
{ 
# 39
return std::malloc(n); 
# 43
} 
# 46
template< class DerivedPolicy, class Pointer> inline void 
# 48
free(execution_policy< DerivedPolicy>  &, Pointer ptr) 
# 49
{ 
# 51
std::free(thrust::raw_pointer_cast(ptr)); 
# 53
} 
# 56
}
# 57
}
# 58
}
# 59
}
# 23 "/usr/local/cuda-8.0/include/thrust/system/detail/bad_alloc.h"
namespace thrust { 
# 25
namespace system { 
# 27
namespace detail { 
# 31
class bad_alloc : public std::bad_alloc { 
# 35
public: bad_alloc(const std::string &w) : std::bad_alloc(), m_what() 
# 37
{ 
# 38
((m_what) = (this->std::bad_alloc::what())); 
# 39
((m_what) += (": ")); 
# 40
((m_what) += w); 
# 41
} 
# 43
virtual ~bad_alloc() throw() { } 
# 45
virtual const char *what() const throw() 
# 46
{ 
# 47
return (m_what).c_str(); 
# 48
} 
# 51
private: std::string m_what; 
# 52
}; 
# 54
}
# 55
}
# 56
}
# 24 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/throw_on_error.h"
namespace thrust { 
# 26
namespace system { 
# 28
namespace cuda { 
# 30
namespace detail { 
# 35
inline void throw_on_error(cudaError_t error, const char *message) 
# 36
{ 
# 37
thrust::system::cuda::detail::bulk_::detail::throw_on_error(error, message); 
# 38
} 
# 41
}
# 42
}
# 43
}
# 44
}
# 26 "/usr/local/cuda-8.0/include/thrust/detail/malloc_and_free.h"
namespace thrust { 
# 30
template< class DerivedPolicy> pointer< void, DerivedPolicy, use_default, use_default>  
# 32
malloc(const detail::execution_policy_base< DerivedPolicy>  &exec, std::size_t n) 
# 33
{ 
# 34
using system::detail::generic::malloc;
# 37
void *raw_ptr = static_cast< void *>(thrust::raw_pointer_cast(malloc(detail::derived_cast(detail::strip_const(exec)), n))); 
# 39
return ((pointer< void, DerivedPolicy, use_default, use_default> )(raw_ptr)); 
# 40
} 
# 43
template< class T, class DerivedPolicy> pointer< T, DerivedPolicy, use_default, use_default>  
# 45
malloc(const detail::execution_policy_base< DerivedPolicy>  &exec, std::size_t n) 
# 46
{ 
# 47
using system::detail::generic::malloc;
# 49
T *raw_ptr = static_cast< T *>(thrust::raw_pointer_cast(malloc< T> (detail::derived_cast(detail::strip_const(exec)), n))); 
# 51
return ((pointer< T, DerivedPolicy, use_default, use_default> )(raw_ptr)); 
# 52
} 
# 72
template< class DerivedPolicy, class Pointer> void 
# 74
free(const detail::execution_policy_base< DerivedPolicy>  &exec, Pointer ptr) 
# 75
{ 
# 76
using system::detail::generic::free;
# 78
free(detail::derived_cast(detail::strip_const(exec)), ptr); 
# 79
} 
# 84
}
# 31 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/malloc_and_free.h"
namespace thrust { 
# 33
namespace system { 
# 35
namespace cuda { 
# 37
namespace detail { 
# 43
template< class DerivedPolicy> void *
# 45
malloc(execution_policy< DerivedPolicy>  &, std::size_t n) 
# 46
{ 
# 47
void *result = (0); 
# 51
cudaError_t error = cudaMalloc(reinterpret_cast< void **>(&result), n); 
# 53
if (error) 
# 54
{ 
# 55
throw ((system::detail::bad_alloc)((thrust::cuda_category().message(error)).c_str())); 
# 56
}  
# 61
return result; 
# 62
} 
# 65
template< class DerivedPolicy, class Pointer> void 
# 67
free(execution_policy< DerivedPolicy>  &, Pointer ptr) 
# 68
{ 
# 71
throw_on_error(cudaFree(thrust::raw_pointer_cast(ptr)), "cudaFree in free"); 
# 75
} 
# 78
}
# 79
}
# 80
}
# 81
}
# 25 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/memory.inl"
namespace thrust { 
# 27
namespace system { 
# 29
namespace detail { 
# 31
namespace generic { 
# 35
template< class DerivedPolicy, class Size> void 
# 37
malloc(execution_policy< DerivedPolicy>  &, Size) 
# 38
{ 
# 40
typedef thrust::detail::static_assert_test< sizeof(thrust::detail::STATIC_ASSERTION_FAILURE< (bool)(thrust::detail::depend_on_instantiation< Size, false> ::value)> )>  thrust_static_assert_typedef_40 __attribute((unused)); 
# 41
} 
# 44
template< class T, class DerivedPolicy> pointer< T, DerivedPolicy, use_default, use_default>  
# 47
malloc(execution_policy< DerivedPolicy>  &exec, std::size_t n) 
# 48
{ 
# 49
pointer< void, DerivedPolicy, use_default, use_default>  void_ptr = thrust::malloc(exec, sizeof(T) * n); 
# 51
return ((pointer< T, DerivedPolicy, use_default, use_default> )(static_cast< T *>((void_ptr.get())))); 
# 52
} 
# 55
template< class DerivedPolicy, class Pointer> void 
# 57
free(execution_policy< DerivedPolicy>  &, Pointer) 
# 58
{ 
# 60
typedef thrust::detail::static_assert_test< sizeof(thrust::detail::STATIC_ASSERTION_FAILURE< (bool)(thrust::detail::depend_on_instantiation< Pointer, false> ::value)> )>  thrust_static_assert_typedef_60 __attribute((unused)); 
# 61
} 
# 64
template< class DerivedPolicy, class Pointer1, class Pointer2> void 
# 66
assign_value(execution_policy< DerivedPolicy>  &, Pointer1, Pointer2) 
# 67
{ 
# 69
typedef thrust::detail::static_assert_test< sizeof(thrust::detail::STATIC_ASSERTION_FAILURE< (bool)(thrust::detail::depend_on_instantiation< Pointer1, false> ::value)> )>  thrust_static_assert_typedef_69 __attribute((unused)); 
# 70
} 
# 73
template< class DerivedPolicy, class Pointer> void 
# 75
get_value(execution_policy< DerivedPolicy>  &, Pointer) 
# 76
{ 
# 78
typedef thrust::detail::static_assert_test< sizeof(thrust::detail::STATIC_ASSERTION_FAILURE< (bool)(thrust::detail::depend_on_instantiation< Pointer, false> ::value)> )>  thrust_static_assert_typedef_78 __attribute((unused)); 
# 79
} 
# 82
template< class Pointer1, class Pointer2> void 
# 84
iter_swap(tag, Pointer1, Pointer2) 
# 85
{ 
# 87
typedef thrust::detail::static_assert_test< sizeof(thrust::detail::STATIC_ASSERTION_FAILURE< (bool)(thrust::detail::depend_on_instantiation< Pointer1, false> ::value)> )>  thrust_static_assert_typedef_87 __attribute((unused)); 
# 88
} 
# 91
}
# 92
}
# 93
}
# 94
}
# 23 "/usr/local/cuda-8.0/include/thrust/system/detail/sequential/get_value.h"
namespace thrust { 
# 25
namespace system { 
# 27
namespace detail { 
# 29
namespace sequential { 
# 33
template< class DerivedPolicy, class Pointer> typename iterator_value< Pointer> ::type 
# 36
get_value(execution_policy< DerivedPolicy>  &, Pointer ptr) 
# 37
{ 
# 38
return *thrust::raw_pointer_cast(ptr); 
# 39
} 
# 42
}
# 43
}
# 44
}
# 45
}
# 24 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/assign_value.h"
namespace thrust { 
# 26
namespace system { 
# 28
namespace cuda { 
# 30
namespace detail { 
# 77
template< class DerivedPolicy, class Pointer1, class Pointer2> inline void 
# 79
assign_value(execution_policy< DerivedPolicy>  &exec, Pointer1 dst, Pointer2 src) 
# 80
{ 
# 82
struct war_nvbugs_881631 { 
# 84
static void host_path(execution_policy< DerivedPolicy>  &exec, Pointer1 dst, Pointer2 src) 
# 85
{ 
# 86
thrust::copy(exec, src, src + 1, dst); 
# 87
} 
# 89
static void device_path(execution_policy< DerivedPolicy>  &, Pointer1 dst, Pointer2 src) 
# 90
{int volatile ___ = 1;(void)dst;(void)src;
# 92
::exit(___);}
#if 0
# 90
{ 
# 91
(*thrust::raw_pointer_cast(dst)) = (*thrust::raw_pointer_cast(src)); 
# 92
} 
#endif
# 93 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/assign_value.h"
}; 
# 96
(war_nvbugs_881631::host_path)(exec, dst, src); 
# 100
} 
# 159
template< class System1, class System2, class Pointer1, class Pointer2> inline void 
# 161
assign_value(cross_system< System1, System2>  &systems, Pointer1 dst, Pointer2 src) 
# 162
{ 
# 164
struct war_nvbugs_881631 { 
# 166
static void host_path(cross_system< System1, System2>  &systems, Pointer1 dst, Pointer2 src) 
# 167
{ 
# 170
cross_system< System2, System1>  rotated_systems = (systems.rotate()); 
# 171
thrust::copy(rotated_systems, src, src + 1, dst); 
# 172
} 
# 174
static void device_path(cross_system< System1, System2>  &systems, Pointer1 dst, Pointer2 src) 
# 175
{int volatile ___ = 1;(void)systems;(void)dst;(void)src;
# 180
::exit(___);}
#if 0
# 175
{ 
# 178
tag cuda_tag; 
# 179
cuda::detail::assign_value(cuda_tag, dst, src); 
# 180
} 
#endif
# 181 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/assign_value.h"
}; 
# 186
(war_nvbugs_881631::host_path)(systems, dst, src); 
# 188
} 
# 194
}
# 195
}
# 196
}
# 197
}
# 25 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/get_value.h"
namespace thrust { 
# 27
namespace system { 
# 29
namespace cuda { 
# 31
namespace detail { 
# 36
namespace _GLOBAL__N__17_gpu_setup_cpp1_ii_524b47c1 { }; using namespace ::thrust::system::cuda::detail::_GLOBAL__N__17_gpu_setup_cpp1_ii_524b47c1; namespace _GLOBAL__N__17_gpu_setup_cpp1_ii_524b47c1 { 
# 39
template< class DerivedPolicy, class Pointer> inline typename iterator_value< Pointer> ::type 
# 42
get_value_msvc2005_war(execution_policy< DerivedPolicy>  &exec, Pointer ptr) 
# 43
{ 
# 44
typedef typename iterator_value< Pointer> ::type result_type; 
# 47
struct war_nvbugs_881631 { 
# 49
static result_type host_path(execution_policy< DerivedPolicy>  &exec, Pointer ptr) 
# 50
{ 
# 53
result_type result; 
# 55
host_system_tag host_tag; 
# 56
cross_system< cpp::detail::tag, DerivedPolicy>  systems(host_tag, exec); 
# 57
assign_value(systems, &result, ptr); 
# 59
return result; 
# 60
} 
# 62
static result_type device_path(execution_policy< DerivedPolicy>  &, Pointer ptr) 
# 63
{int volatile ___ = 1;(void)ptr;
# 66
::exit(___);}
#if 0
# 63
{ 
# 65
return *thrust::raw_pointer_cast(ptr); 
# 66
} 
#endif
# 67 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/get_value.h"
}; 
# 70
return (war_nvbugs_881631::host_path)(exec, ptr); 
# 74
} 
# 77
}
# 80
template< class DerivedPolicy, class Pointer> inline typename iterator_value< Pointer> ::type 
# 83
get_value(execution_policy< DerivedPolicy>  &exec, Pointer ptr) 
# 84
{ 
# 85
return get_value_msvc2005_war(exec, ptr); 
# 86
} 
# 89
}
# 90
}
# 91
}
# 92
}
# 23 "/usr/local/cuda-8.0/include/thrust/system/detail/sequential/assign_value.h"
namespace thrust { 
# 25
namespace system { 
# 27
namespace detail { 
# 29
namespace sequential { 
# 32
template< class DerivedPolicy, class Pointer1, class Pointer2> void 
# 34
assign_value(execution_policy< DerivedPolicy>  &, Pointer1 dst, Pointer2 src) 
# 35
{ 
# 36
(*thrust::raw_pointer_cast(dst)) = (*thrust::raw_pointer_cast(src)); 
# 37
} 
# 39
}
# 40
}
# 41
}
# 42
}
# 24 "/usr/local/cuda-8.0/include/thrust/system/detail/sequential/iter_swap.h"
namespace thrust { 
# 26
namespace system { 
# 28
namespace detail { 
# 30
namespace sequential { 
# 34
template< class Pointer1, class Pointer2> void 
# 36
iter_swap(tag, Pointer1 a, Pointer2 b) 
# 37
{ 
# 38
using thrust::swap;
# 39
swap(*thrust::raw_pointer_cast(a), *thrust::raw_pointer_cast(b)); 
# 40
} 
# 43
}
# 44
}
# 45
}
# 46
}
# 30 "/usr/local/cuda-8.0/include/thrust/swap.h"
namespace thrust { 
# 65
template< class Assignable1, class Assignable2> inline void swap(Assignable1 & a, Assignable2 & b); 
# 127
template< class DerivedPolicy, class 
# 128
ForwardIterator1, class 
# 129
ForwardIterator2> ForwardIterator2 
# 127
swap_ranges(const detail::execution_policy_base< DerivedPolicy>  & exec, ForwardIterator1 first1, ForwardIterator1 last1, ForwardIterator2 first2); 
# 177
template< class ForwardIterator1, class 
# 178
ForwardIterator2> ForwardIterator2 
# 177
swap_ranges(ForwardIterator1 first1, ForwardIterator1 last1, ForwardIterator2 first2); 
# 188
}
# 23 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/swap_ranges.h"
namespace thrust { 
# 25
namespace system { 
# 27
namespace detail { 
# 29
namespace generic { 
# 32
template< class DerivedPolicy, class 
# 33
ForwardIterator1, class 
# 34
ForwardIterator2> ForwardIterator2 
# 32
swap_ranges(execution_policy< DerivedPolicy>  & exec, ForwardIterator1 first1, ForwardIterator1 last1, ForwardIterator2 first2); 
# 41
}
# 42
}
# 43
}
# 44
}
# 24 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/swap_ranges.inl"
namespace thrust { 
# 26
namespace system { 
# 28
namespace detail { 
# 30
namespace generic { 
# 32
namespace detail { 
# 38
struct swap_pair_elements { 
# 40
template< class Tuple> void 
# 42
operator()(Tuple t) 
# 43
{ 
# 45
using thrust::swap;
# 46
swap(thrust::get< 0> (t), thrust::get< 1> (t)); 
# 47
} 
# 48
}; 
# 51
}
# 54
template< class DerivedPolicy, class 
# 55
ForwardIterator1, class 
# 56
ForwardIterator2> ForwardIterator2 
# 58
swap_ranges(execution_policy< DerivedPolicy>  &exec, ForwardIterator1 
# 59
first1, ForwardIterator1 
# 60
last1, ForwardIterator2 
# 61
first2) 
# 62
{ 
# 63
typedef tuple< ForwardIterator1, ForwardIterator2, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type>  IteratorTuple; 
# 64
typedef zip_iterator< tuple< ForwardIterator1, ForwardIterator2, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type> >  ZipIterator; 
# 66
ZipIterator result = thrust::for_each(exec, thrust::make_zip_iterator(thrust::make_tuple(first1, first2)), thrust::make_zip_iterator(thrust::make_tuple(last1, first2)), detail::swap_pair_elements()); 
# 70
return thrust::get< 1> ((result.get_iterator_tuple())); 
# 71
} 
# 74
}
# 75
}
# 76
}
# 77
}
# 28 "/usr/local/cuda-8.0/include/thrust/detail/swap_ranges.inl"
namespace thrust { 
# 33
template< class DerivedPolicy, class 
# 34
ForwardIterator1, class 
# 35
ForwardIterator2> ForwardIterator2 
# 37
swap_ranges(const detail::execution_policy_base< DerivedPolicy>  &exec, ForwardIterator1 
# 38
first1, ForwardIterator1 
# 39
last1, ForwardIterator2 
# 40
first2) 
# 41
{ 
# 42
using system::detail::generic::swap_ranges;
# 43
return swap_ranges(detail::derived_cast(detail::strip_const(exec)), first1, last1, first2); 
# 44
} 
# 47
template< class ForwardIterator1, class 
# 48
ForwardIterator2> ForwardIterator2 
# 49
swap_ranges(ForwardIterator1 first1, ForwardIterator1 
# 50
last1, ForwardIterator2 
# 51
first2) 
# 52
{ 
# 53
using system::detail::generic::select_system;
# 55
typedef typename iterator_system< ForwardIterator1> ::type System1; 
# 56
typedef typename iterator_system< ForwardIterator2> ::type System2; 
# 58
System1 system1; 
# 59
System2 system2; 
# 61
return thrust::swap_ranges(select_system(system1, system2), first1, last1, first2); 
# 62
} 
# 65
}
# 23 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/iter_swap.h"
namespace thrust { 
# 25
namespace system { 
# 27
namespace cuda { 
# 29
namespace detail { 
# 33
template< class Pointer1, class Pointer2> inline void 
# 35
iter_swap(tag, Pointer1 a, Pointer2 b) 
# 36
{ 
# 38
struct war_nvbugs_881631 { 
# 40
static void host_path(Pointer1 a, Pointer2 b) 
# 41
{ 
# 42
thrust::swap_ranges(a, a + 1, b); 
# 43
} 
# 45
static void device_path(Pointer1 a, Pointer2 b) 
# 46
{int volatile ___ = 1;(void)a;(void)b;
# 50
::exit(___);}
#if 0
# 46
{ 
# 47
using thrust::swap;
# 48
swap(*thrust::raw_pointer_cast(a), *thrust::raw_pointer_cast(b)); 
# 50
} 
#endif
# 51 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/iter_swap.h"
}; 
# 54
return (war_nvbugs_881631::host_path)(a, b); 
# 58
} 
# 61
}
# 62
}
# 63
}
# 64
}
# 28 "/usr/local/cuda-8.0/include/thrust/detail/reference.inl"
namespace thrust { 
# 32
template< class Element, class Pointer, class Derived> 
# 33
template< class OtherElement, class OtherPointer, class OtherDerived> 
# 35
reference< Element, Pointer, Derived> ::reference(const thrust::reference< OtherElement, OtherPointer, OtherDerived>  &other, typename detail::enable_if_convertible< typename thrust::reference< OtherElement, OtherPointer, OtherDerived> ::pointer, Pointer> ::type *) : m_ptr((other.m_ptr)) 
# 41
{ } 
# 44
template< class Element, class Pointer, class Derived> 
# 46
reference< Element, Pointer, Derived> ::reference(const pointer &ptr) : m_ptr(ptr) 
# 48
{ } 
# 51
template< class Element, class Pointer, class Derived> typename reference< Element, Pointer, Derived> ::pointer 
# 54
reference< Element, Pointer, Derived> ::operator&() const 
# 55
{ 
# 56
return m_ptr; 
# 57
} 
# 60
template< class Element, class Pointer, class Derived> typename reference< Element, Pointer, Derived> ::derived_type &
# 63
reference< Element, Pointer, Derived> ::operator=(const value_type &v) 
# 64
{ 
# 65
assign_from(&v); 
# 66
return static_cast< derived_type &>(*this); 
# 67
} 
# 70
template< class Element, class Pointer, class Derived> typename reference< Element, Pointer, Derived> ::derived_type &
# 73
reference< Element, Pointer, Derived> ::operator=(const reference &other) 
# 74
{ 
# 75
assign_from(&other); 
# 76
return static_cast< derived_type &>(*this); 
# 77
} 
# 80
template< class Element, class Pointer, class Derived> 
# 81
template< class OtherElement, class OtherPointer, class OtherDerived> typename reference< Element, Pointer, Derived> ::derived_type &
# 84
reference< Element, Pointer, Derived> ::operator=(const thrust::reference< OtherElement, OtherPointer, OtherDerived>  &other) 
# 85
{ 
# 86
assign_from(&other); 
# 87
return static_cast< derived_type &>(*this); 
# 88
} 
# 91
template< class Element, class Pointer, class Derived> 
# 92
template< class System> inline typename reference< Element, Pointer, Derived> ::value_type 
# 95
reference< Element, Pointer, Derived> ::convert_to_value_type(System *system) const 
# 96
{ 
# 97
using thrust::system::detail::generic::select_system;
# 98
return strip_const_get_value(select_system(*system)); 
# 99
} 
# 102
template< class Element, class Pointer, class Derived> 
# 104
reference< Element, Pointer, Derived> ::operator typename reference< Element, Pointer, Derived> ::value_type() const 
# 105
{ 
# 106
typedef typename iterator_system< Pointer> ::type System; 
# 112
System *system = (0); 
# 114
return convert_to_value_type(system); 
# 115
} 
# 118
template< class Element, class Pointer, class Derived> 
# 119
template< class System> inline typename reference< Element, Pointer, Derived> ::value_type 
# 122
reference< Element, Pointer, Derived> ::strip_const_get_value(const System &system) const 
# 123
{ 
# 124
System &non_const_system = const_cast< System &>(system); 
# 126
using thrust::system::detail::generic::get_value;
# 128
return get_value(detail::derived_cast(non_const_system), m_ptr); 
# 129
} 
# 132
template< class Element, class Pointer, class Derived> 
# 133
template< class System1, class System2, class OtherPointer> inline void 
# 135
reference< Element, Pointer, Derived> ::assign_from(System1 *system1, System2 *system2, OtherPointer src) 
# 136
{ 
# 137
using system::detail::generic::select_system;
# 139
strip_const_assign_value(select_system(*system1, *system2), src); 
# 140
} 
# 143
template< class Element, class Pointer, class Derived> 
# 144
template< class OtherPointer> inline void 
# 146
reference< Element, Pointer, Derived> ::assign_from(OtherPointer src) 
# 147
{ 
# 148
typedef typename iterator_system< Pointer> ::type System1; 
# 149
typedef typename iterator_system< OtherPointer> ::type System2; 
# 155
System1 *system1 = (0); 
# 156
System2 *system2 = (0); 
# 158
assign_from(system1, system2, src); 
# 159
} 
# 162
template< class Element, class Pointer, class Derived> 
# 163
template< class System, class OtherPointer> inline void 
# 165
reference< Element, Pointer, Derived> ::strip_const_assign_value(const System &system, OtherPointer src) 
# 166
{ 
# 167
System &non_const_system = const_cast< System &>(system); 
# 169
using thrust::system::detail::generic::assign_value;
# 171
assign_value(detail::derived_cast(non_const_system), m_ptr, src); 
# 172
} 
# 175
template< class Element, class Pointer, class Derived> 
# 176
template< class System> inline void 
# 178
reference< Element, Pointer, Derived> ::swap(System *system, derived_type &other) 
# 179
{ 
# 180
using thrust::system::detail::generic::select_system;
# 181
using thrust::system::detail::generic::iter_swap;
# 183
iter_swap(select_system(*system, *system), m_ptr, (other.m_ptr)); 
# 184
} 
# 187
template< class Element, class Pointer, class Derived> void 
# 189
reference< Element, Pointer, Derived> ::swap(derived_type &other) 
# 190
{ 
# 191
typedef typename iterator_system< Pointer> ::type System; 
# 197
System *system = (0); 
# 199
swap(system, other); 
# 200
} 
# 203
template< class Element, class Pointer, class Derived> typename reference< Element, Pointer, Derived> ::derived_type &
# 206
reference< Element, Pointer, Derived> ::operator++() 
# 207
{ 
# 208
value_type temp = *this; 
# 209
++temp; 
# 210
(*this) = temp; 
# 211
return static_cast< derived_type &>(*this); 
# 212
} 
# 215
template< class Element, class Pointer, class Derived> typename reference< Element, Pointer, Derived> ::value_type 
# 218
reference< Element, Pointer, Derived> ::operator++(int) 
# 219
{ 
# 220
value_type temp = *this; 
# 221
value_type result = temp++; 
# 222
(*this) = temp; 
# 223
return result; 
# 224
} 
# 227
template< class Element, class Pointer, class Derived> typename reference< Element, Pointer, Derived> ::derived_type &
# 230
reference< Element, Pointer, Derived> ::operator+=(const value_type &rhs) 
# 231
{ 
# 232
value_type temp = *this; 
# 233
temp += rhs; 
# 234
(*this) = temp; 
# 235
return static_cast< derived_type &>(*this); 
# 236
} 
# 238
template< class Element, class Pointer, class Derived> typename reference< Element, Pointer, Derived> ::derived_type &
# 241
reference< Element, Pointer, Derived> ::operator--() 
# 242
{ 
# 243
value_type temp = *this; 
# 244
--temp; 
# 245
(*this) = temp; 
# 246
return static_cast< derived_type &>(*this); 
# 247
} 
# 249
template< class Element, class Pointer, class Derived> typename reference< Element, Pointer, Derived> ::value_type 
# 252
reference< Element, Pointer, Derived> ::operator--(int) 
# 253
{ 
# 254
value_type temp = *this; 
# 255
value_type result = temp--; 
# 256
(*this) = temp; 
# 257
return result; 
# 258
} 
# 260
template< class Element, class Pointer, class Derived> typename reference< Element, Pointer, Derived> ::derived_type &
# 263
reference< Element, Pointer, Derived> ::operator-=(const value_type &rhs) 
# 264
{ 
# 265
value_type temp = *this; 
# 266
temp -= rhs; 
# 267
(*this) = temp; 
# 268
return static_cast< derived_type &>(*this); 
# 269
} 
# 271
template< class Element, class Pointer, class Derived> typename reference< Element, Pointer, Derived> ::derived_type &
# 274
reference< Element, Pointer, Derived> ::operator*=(const value_type &rhs) 
# 275
{ 
# 276
value_type temp = *this; 
# 277
temp *= rhs; 
# 278
(*this) = temp; 
# 279
return static_cast< derived_type &>(*this); 
# 280
} 
# 282
template< class Element, class Pointer, class Derived> typename reference< Element, Pointer, Derived> ::derived_type &
# 285
reference< Element, Pointer, Derived> ::operator/=(const value_type &rhs) 
# 286
{ 
# 287
value_type temp = *this; 
# 288
temp /= rhs; 
# 289
(*this) = temp; 
# 290
return static_cast< derived_type &>(*this); 
# 291
} 
# 293
template< class Element, class Pointer, class Derived> typename reference< Element, Pointer, Derived> ::derived_type &
# 296
reference< Element, Pointer, Derived> ::operator%=(const value_type &rhs) 
# 297
{ 
# 298
value_type temp = *this; 
# 299
temp %= rhs; 
# 300
(*this) = temp; 
# 301
return static_cast< derived_type &>(*this); 
# 302
} 
# 304
template< class Element, class Pointer, class Derived> typename reference< Element, Pointer, Derived> ::derived_type &
# 307
reference< Element, Pointer, Derived> ::operator<<=(const value_type &rhs) 
# 308
{ 
# 309
value_type temp = *this; 
# 310
temp <<= rhs; 
# 311
(*this) = temp; 
# 312
return static_cast< derived_type &>(*this); 
# 313
} 
# 315
template< class Element, class Pointer, class Derived> typename reference< Element, Pointer, Derived> ::derived_type &
# 318
reference< Element, Pointer, Derived> ::operator>>=(const value_type &rhs) 
# 319
{ 
# 320
value_type temp = *this; 
# 321
temp >>= rhs; 
# 322
(*this) = temp; 
# 323
return static_cast< derived_type &>(*this); 
# 324
} 
# 326
template< class Element, class Pointer, class Derived> typename reference< Element, Pointer, Derived> ::derived_type &
# 329
reference< Element, Pointer, Derived> ::operator&=(const value_type &rhs) 
# 330
{ 
# 331
value_type temp = *this; 
# 332
temp &= rhs; 
# 333
(*this) = temp; 
# 334
return static_cast< derived_type &>(*this); 
# 335
} 
# 337
template< class Element, class Pointer, class Derived> typename reference< Element, Pointer, Derived> ::derived_type &
# 340
reference< Element, Pointer, Derived> ::operator|=(const value_type &rhs) 
# 341
{ 
# 342
value_type temp = *this; 
# 343
temp |= rhs; 
# 344
(*this) = temp; 
# 345
return static_cast< derived_type &>(*this); 
# 346
} 
# 348
template< class Element, class Pointer, class Derived> typename reference< Element, Pointer, Derived> ::derived_type &
# 351
reference< Element, Pointer, Derived> ::operator^=(const value_type &rhs) 
# 352
{ 
# 353
value_type temp = *this; 
# 354
temp ^= rhs; 
# 355
(*this) = temp; 
# 356
return static_cast< derived_type &>(*this); 
# 357
} 
# 359
template< class Element, class Pointer, class Derived, class 
# 360
charT, class traits> std::basic_ostream< charT, traits>  &
# 362
operator<<(std::basic_ostream< charT, traits>  &os, const reference< Element, Pointer, Derived>  &
# 363
y) { 
# 364
typedef typename reference< Element, Pointer, Derived> ::value_type value_type; 
# 365
return os << (static_cast< value_type>(y)); 
# 366
} 
# 368
}
# 24 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/temporary_buffer.h"
namespace thrust { 
# 26
namespace system { 
# 28
namespace detail { 
# 30
namespace generic { 
# 34
template< class T, class DerivedPolicy> pair< pointer< T, DerivedPolicy, use_default, use_default> , typename pointer< T, DerivedPolicy, use_default, use_default> ::difference_type>  get_temporary_buffer(execution_policy< DerivedPolicy>  & exec, typename pointer< T, DerivedPolicy, use_default, use_default> ::difference_type n); 
# 40
template< class DerivedPolicy, class Pointer> void return_temporary_buffer(execution_policy< DerivedPolicy>  & exec, Pointer p); 
# 45
}
# 46
}
# 47
}
# 48
}
# 23 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/temporary_buffer.inl"
namespace thrust { 
# 25
namespace system { 
# 27
namespace detail { 
# 29
namespace generic { 
# 33
template< class T, class DerivedPolicy> pair< pointer< T, DerivedPolicy, use_default, use_default> , typename pointer< T, DerivedPolicy, use_default, use_default> ::difference_type>  
# 36
get_temporary_buffer(execution_policy< DerivedPolicy>  &exec, typename pointer< T, DerivedPolicy, use_default, use_default> ::difference_type n) 
# 37
{ 
# 38
pointer< T, DerivedPolicy, use_default, use_default>  ptr = thrust::malloc< T> (exec, n); 
# 41
if (!(ptr.get())) 
# 42
{ 
# 43
n = 0; 
# 44
}  
# 46
return thrust::make_pair(ptr, n); 
# 47
} 
# 50
template< class DerivedPolicy, class Pointer> void 
# 52
return_temporary_buffer(execution_policy< DerivedPolicy>  &exec, Pointer p) 
# 53
{ 
# 54
thrust::free(exec, p); 
# 55
} 
# 58
}
# 59
}
# 60
}
# 61
}
# 27 "/usr/local/cuda-8.0/include/thrust/detail/temporary_buffer.h"
namespace thrust { 
# 29
namespace detail { 
# 31
namespace get_temporary_buffer_detail { 
# 35
template< class T, class DerivedPolicy, class Pair> pair< pointer< T, DerivedPolicy, use_default, use_default> , typename pointer< T, DerivedPolicy, use_default, use_default> ::difference_type>  
# 38
down_cast_pair(Pair p) 
# 39
{ 
# 41
pointer< T, DerivedPolicy, use_default, use_default>  ptr = ((pointer< T, DerivedPolicy, use_default, use_default> )(static_cast< T *>(thrust::raw_pointer_cast((p.first))))); 
# 43
typedef pair< pointer< T, DerivedPolicy, use_default, use_default> , typename pointer< T, DerivedPolicy, use_default, use_default> ::difference_type>  result_type; 
# 44
return result_type(ptr, (p.second)); 
# 45
} 
# 48
}
# 49
}
# 53
template< class T, class DerivedPolicy> pair< pointer< T, DerivedPolicy, use_default, use_default> , typename pointer< T, DerivedPolicy, use_default, use_default> ::difference_type>  
# 56
get_temporary_buffer(const detail::execution_policy_base< DerivedPolicy>  &exec, typename pointer< T, DerivedPolicy, use_default, use_default> ::difference_type n) 
# 57
{ 
# 58
using system::detail::generic::get_temporary_buffer;
# 60
return detail::get_temporary_buffer_detail::down_cast_pair< T, DerivedPolicy> (get_temporary_buffer< T> (detail::derived_cast(detail::strip_const(exec)), n)); 
# 61
} 
# 65
template< class DerivedPolicy, class Pointer> void 
# 67
return_temporary_buffer(const detail::execution_policy_base< DerivedPolicy>  &exec, Pointer p) 
# 68
{ 
# 69
using system::detail::generic::return_temporary_buffer;
# 71
return return_temporary_buffer(detail::derived_cast(detail::strip_const(exec)), p); 
# 72
} 
# 75
}
# 31 "/usr/local/cuda-8.0/include/thrust/memory.h"
namespace thrust { 
# 303
template< class DerivedPolicy> pointer< void, DerivedPolicy, use_default, use_default>  malloc(const detail::execution_policy_base< DerivedPolicy>  & system, std::size_t n); 
# 341
template< class T, class DerivedPolicy> pointer< T, DerivedPolicy, use_default, use_default>  malloc(const detail::execution_policy_base< DerivedPolicy>  & system, std::size_t n); 
# 394
template< class T, class DerivedPolicy> pair< pointer< T, DerivedPolicy, use_default, use_default> , typename pointer< T, DerivedPolicy, use_default, use_default> ::difference_type>  get_temporary_buffer(const detail::execution_policy_base< DerivedPolicy>  & system, typename pointer< T, DerivedPolicy, use_default, use_default> ::difference_type n); 
# 437
template< class DerivedPolicy, class Pointer> void free(const detail::execution_policy_base< DerivedPolicy>  & system, Pointer ptr); 
# 483
template< class DerivedPolicy, class Pointer> void return_temporary_buffer(const detail::execution_policy_base< DerivedPolicy>  & system, Pointer p); 
# 499
template< class Pointer> inline typename detail::pointer_traits< Pointer> ::raw_pointer raw_pointer_cast(const Pointer & ptr); 
# 516
template< class T> inline typename detail::raw_reference< T> ::type raw_reference_cast(T & ref); 
# 533
template< class T> inline typename detail::raw_reference< const T> ::type raw_reference_cast(const T & ref); 
# 542
}
# 26 "/usr/local/cuda-8.0/include/thrust/detail/allocator/temporary_allocator.h"
namespace thrust { 
# 28
namespace detail { 
# 35
template< class T, class System> 
# 36
class temporary_allocator : public tagged_allocator< T, System, pointer< T, System, use_default, use_default> >  { 
# 44
typedef ::thrust::detail::tagged_allocator< T, System, ::thrust::pointer< T, System, ::thrust::use_default, ::thrust::use_default> >  super_t; 
# 46
System &m_system; 
# 49
public: typedef typename ::thrust::detail::tagged_allocator< T, System, ::thrust::pointer< T, System, ::thrust::use_default, ::thrust::use_default> > ::pointer pointer; 
# 50
typedef typename ::thrust::detail::tagged_allocator< T, System, ::thrust::pointer< T, System, ::thrust::use_default, ::thrust::use_default> > ::size_type size_type; 
# 53
temporary_allocator(const temporary_allocator &other) : super_t(), m_system(other.m_system) 
# 56
{ } 
# 59
explicit temporary_allocator(execution_policy< System>  &system) : super_t(), m_system(::thrust::detail::derived_cast(system)) 
# 62
{ } 
# 65
pointer allocate(size_type cnt); 
# 68
void deallocate(pointer p, size_type n); 
# 71
System &system() 
# 72
{ 
# 73
return m_system; 
# 74
} 
# 77
private: typedef pair< typename ::thrust::detail::tagged_allocator< T, System, ::thrust::pointer< T, System, ::thrust::use_default, ::thrust::use_default> > ::pointer, typename ::thrust::detail::tagged_allocator< T, System, ::thrust::pointer< T, System, ::thrust::use_default, ::thrust::use_default> > ::size_type>  pointer_and_size; 
# 78
}; 
# 81
}
# 82
}
# 65 "/usr/include/assert.h" 3
extern "C" {
# 68
extern void __assert_fail(const char * __assertion, const char * __file, unsigned __line, const char * __function) throw()
# 70
 __attribute((__noreturn__)); 
# 73
extern void __assert_perror_fail(int __errnum, const char * __file, unsigned __line, const char * __function) throw()
# 75
 __attribute((__noreturn__)); 
# 80
extern void __assert(const char * __assertion, const char * __file, int __line) throw()
# 81
 __attribute((__noreturn__)); 
# 84
}
# 22 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/terminate.h"
namespace thrust { 
# 24
namespace system { 
# 26
namespace cuda { 
# 28
namespace detail { 
# 33
__attribute__((unused)) inline void terminate() 
# 34
{int volatile ___ = 1;
# 36
::exit(___);}
#if 0
# 34
{ 
# 35
thrust::system::cuda::detail::bulk_::detail::terminate(); 
# 36
} 
#endif
# 40 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/terminate.h"
inline void terminate_with_message(const char *message) 
# 41
{ 
# 42
thrust::system::cuda::detail::bulk_::detail::terminate_with_message(message); 
# 43
} 
# 46
}
# 47
}
# 48
}
# 49
}
# 27 "/usr/local/cuda-8.0/include/thrust/detail/allocator/temporary_allocator.inl"
namespace thrust { 
# 29
namespace detail { 
# 33
template< class T, class System> typename temporary_allocator< T, System> ::pointer 
# 37
temporary_allocator< T, System> ::allocate(size_type cnt) 
# 38
{ 
# 39
pointer_and_size result = ::thrust::get_temporary_buffer< T> (system(), cnt); 
# 42
if ((result.second) < cnt) 
# 43
{ 
# 46
deallocate((result.first), cnt); 
# 49
throw ((::thrust::system::detail::bad_alloc)("temporary_buffer::allocate: get_temporary_buffer failed")); 
# 53
}  
# 55
return result.first; 
# 56
} 
# 59
template< class T, class System> void 
# 62
temporary_allocator< T, System> ::deallocate(pointer p, size_type n) 
# 63
{ 
# 64
return ::thrust::return_temporary_buffer(system(), p); 
# 65
} 
# 68
}
# 69
}
# 21 "/usr/local/cuda-8.0/include/thrust/detail/allocator/no_throw_allocator.h"
namespace thrust { 
# 23
namespace detail { 
# 26
template< class BaseAllocator> 
# 27
struct no_throw_allocator : public BaseAllocator { 
# 30
private: typedef BaseAllocator super_t; 
# 34
public: no_throw_allocator(const BaseAllocator &other = BaseAllocator()) : super_t(other) 
# 36
{ } 
# 38
template< class U> 
# 39
struct rebind { 
# 41
typedef ::thrust::detail::no_throw_allocator< typename BaseAllocator::template rebind< U> ::other>  other; 
# 42
}; 
# 45
void deallocate(typename BaseAllocator::pointer p, typename BaseAllocator::size_type n) 
# 46
{ 
# 48
try 
# 49
{ 
# 50
super_t::deallocate(p, n); 
# 51
} 
# 52
catch (...) 
# 53
{ 
# 55
}  
# 59
} 
# 62
bool operator==(const no_throw_allocator &other) { return BaseAllocator::operator==(other); } 
# 65
bool operator!=(const no_throw_allocator &other) { return BaseAllocator::operator!=(other); } 
# 66
}; 
# 68
}
# 69
}
# 31 "/usr/local/cuda-8.0/include/thrust/detail/temporary_array.h"
namespace thrust { 
# 33
namespace detail { 
# 37
template< class T, class System> 
# 38
class temporary_array : public contiguous_storage< T, no_throw_allocator< temporary_allocator< T, System> > >  { 
# 52
typedef ::thrust::detail::contiguous_storage< T, no_throw_allocator< temporary_allocator< T, System> > >  super_t; 
# 55
typedef no_throw_allocator< temporary_allocator< T, System> >  alloc_type; 
# 58
public: typedef typename ::thrust::detail::contiguous_storage< T, no_throw_allocator< temporary_allocator< T, System> > > ::size_type size_type; 
# 61
temporary_array(execution_policy< System>  & system); 
# 64
temporary_array(execution_policy< System>  & system, size_type n); 
# 68
temporary_array(int uninit, execution_policy< System>  & system, size_type n); 
# 70
template< class InputIterator> temporary_array(execution_policy< System>  & system, InputIterator first, size_type n); 
# 76
template< class InputIterator, class InputSystem> temporary_array(execution_policy< System>  & system, execution_policy< InputSystem>  & input_system, InputIterator first, size_type n); 
# 83
template< class InputIterator> temporary_array(execution_policy< System>  & system, InputIterator first, InputIterator last); 
# 89
template< class InputSystem, class InputIterator> temporary_array(execution_policy< System>  & system, execution_policy< InputSystem>  & input_system, InputIterator first, InputIterator last); 
# 97
~temporary_array(); 
# 98
}; 
# 102
template< class Iterator, class System> 
# 103
class tagged_iterator_range { 
# 106
public: typedef tagged_iterator< Iterator, System>  iterator; 
# 108
template< class Ignored1, class Ignored2> 
# 109
tagged_iterator_range(const Ignored1 &, const Ignored2 &, Iterator first, Iterator last) : m_begin(first), m_end(last) 
# 112
{ } 
# 114
iterator begin() const { return m_begin; } 
# 115
iterator end() const { return m_end; } 
# 118
private: iterator m_begin, m_end; 
# 119
}; 
# 125
template< class Iterator, class FromSystem, class ToSystem> 
# 126
struct move_to_system_base : public eval_if< is_convertible< FromSystem, ToSystem> ::value, identity_< tagged_iterator_range< Iterator, ToSystem> > , identity_< temporary_array< typename iterator_value< Iterator> ::type, ToSystem> > >  { 
# 142
}; 
# 145
template< class Iterator, class FromSystem, class ToSystem> 
# 146
class move_to_system : public move_to_system_base< Iterator, FromSystem, ToSystem> ::type { 
# 153
typedef typename move_to_system_base< Iterator, FromSystem, ToSystem> ::type super_t; 
# 156
public: move_to_system(execution_policy< FromSystem>  &from_system, execution_policy< ToSystem>  &
# 157
to_system, Iterator 
# 158
first, Iterator 
# 159
last) : super_t(to_system, from_system, first, last) 
# 160
{ } 
# 161
}; 
# 164
}
# 165
}
# 23 "/usr/local/cuda-8.0/include/thrust/detail/temporary_array.inl"
namespace thrust { 
# 26
namespace detail { 
# 28
namespace temporary_array_detail { 
# 32
template< class T> struct avoid_initialization : public has_trivial_copy_constructor< T>  { }; 
# 35
template< class T, class TemporaryArray, class Size> typename enable_if< avoid_initialization< T> ::value> ::type 
# 40
construct_values(TemporaryArray &, Size) 
# 42
{ 
# 44
} 
# 47
template< class T, class TemporaryArray, class Size> typename disable_if< avoid_initialization< T> ::value> ::type 
# 52
construct_values(TemporaryArray &a, Size 
# 53
n) 
# 54
{ 
# 55
(a.default_construct_n((a.begin()), n)); 
# 56
} 
# 59
}
# 62
template< class T, class System> 
# 65
temporary_array< T, System> ::temporary_array(execution_policy< System>  &system) : super_t(((alloc_type)(((temporary_allocator< T, System> )(system))))) 
# 67
{ 
# 68
} 
# 71
template< class T, class System> 
# 74
temporary_array< T, System> ::temporary_array(execution_policy< System>  &system, size_type n) : super_t(n, ((alloc_type)(((temporary_allocator< T, System> )(system))))) 
# 76
{ 
# 77
::thrust::detail::temporary_array_detail::construct_values< T> (*this, n); 
# 78
} 
# 81
template< class T, class System> 
# 84
temporary_array< T, System> ::temporary_array(int, execution_policy< System>  &system, size_type n) : super_t(n, ((alloc_type)(((temporary_allocator< T, System> )(system))))) 
# 86
{ 
# 88
; 
# 89
} 
# 92
template< class T, class System> 
# 93
template< class InputIterator> 
# 96
temporary_array< T, System> ::temporary_array(execution_policy< System>  &system, InputIterator 
# 97
first, size_type 
# 98
n) : super_t(((alloc_type)(((temporary_allocator< T, System> )(system))))) 
# 100
{ 
# 101
super_t::allocate(n); 
# 103
super_t::uninitialized_copy_n(system, first, n, super_t::begin()); 
# 104
} 
# 107
template< class T, class System> 
# 108
template< class InputIterator, class InputSystem> 
# 111
temporary_array< T, System> ::temporary_array(execution_policy< System>  &system, execution_policy< InputSystem>  &
# 112
input_system, InputIterator 
# 113
first, size_type 
# 114
n) : super_t(((alloc_type)(((temporary_allocator< T, System> )(system))))) 
# 116
{ 
# 117
super_t::allocate(n); 
# 119
super_t::uninitialized_copy_n(input_system, first, n, super_t::begin()); 
# 120
} 
# 123
template< class T, class System> 
# 124
template< class InputIterator> 
# 127
temporary_array< T, System> ::temporary_array(execution_policy< System>  &system, InputIterator 
# 128
first, InputIterator 
# 129
last) : super_t(((alloc_type)(((temporary_allocator< T, System> )(system))))) 
# 131
{ 
# 132
super_t::allocate(::thrust::distance(first, last)); 
# 134
super_t::uninitialized_copy(system, first, last, super_t::begin()); 
# 135
} 
# 138
template< class T, class System> 
# 139
template< class InputSystem, class InputIterator> 
# 142
temporary_array< T, System> ::temporary_array(execution_policy< System>  &system, execution_policy< InputSystem>  &
# 143
input_system, InputIterator 
# 144
first, InputIterator 
# 145
last) : super_t(((alloc_type)(((temporary_allocator< T, System> )(system))))) 
# 147
{ 
# 148
super_t::allocate(::thrust::distance(first, last)); 
# 150
super_t::uninitialized_copy(input_system, first, last, super_t::begin()); 
# 151
} 
# 154
template< class T, class System> 
# 157
temporary_array< T, System> ::~temporary_array() 
# 158
{ 
# 160
super_t::destroy(super_t::begin(), super_t::end()); 
# 161
} 
# 163
}
# 165
}
# 20 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/trivial_copy.h"
namespace thrust { 
# 22
namespace system { 
# 24
namespace cuda { 
# 26
namespace detail { 
# 30
template< class DerivedPolicy, class 
# 31
RandomAccessIterator1, class 
# 32
Size, class 
# 33
RandomAccessIterator2> void 
# 30
trivial_copy_n(execution_policy< DerivedPolicy>  & exec, RandomAccessIterator1 first, Size n, RandomAccessIterator2 result); 
# 41
template< class System1, class 
# 42
System2, class 
# 43
RandomAccessIterator1, class 
# 44
Size, class 
# 45
RandomAccessIterator2> void 
# 41
trivial_copy_n(cross_system< System1, System2>  & exec, RandomAccessIterator1 first, Size n, RandomAccessIterator2 result); 
# 52
}
# 53
}
# 54
}
# 55
}
# 20 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/trivial_copy.h"
namespace thrust { 
# 22
namespace system { 
# 24
namespace cuda { 
# 26
namespace detail { 
# 30
template< class DerivedPolicy, class 
# 31
RandomAccessIterator1, class 
# 32
Size, class 
# 33
RandomAccessIterator2> void 
# 30
trivial_copy_n(execution_policy< DerivedPolicy>  & exec, RandomAccessIterator1 first, Size n, RandomAccessIterator2 result); 
# 41
template< class System1, class 
# 42
System2, class 
# 43
RandomAccessIterator1, class 
# 44
Size, class 
# 45
RandomAccessIterator2> void 
# 41
trivial_copy_n(cross_system< System1, System2>  & exec, RandomAccessIterator1 first, Size n, RandomAccessIterator2 result); 
# 52
}
# 53
}
# 54
}
# 55
}
# 22 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/synchronize.h"
namespace thrust { 
# 24
namespace system { 
# 26
namespace cuda { 
# 28
namespace detail { 
# 33
inline void synchronize(const char * message = ""); 
# 36
inline void synchronize(cudaStream_t stream, const char * message = ""); 
# 40
inline void synchronize_if_enabled(const char * message = ""); 
# 44
}
# 45
}
# 46
}
# 47
}
# 22 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/synchronize.inl"
namespace thrust { 
# 24
namespace system { 
# 26
namespace cuda { 
# 28
namespace detail { 
# 33
inline void synchronize(const char *message) 
# 34
{ 
# 35
throw_on_error(cudaDeviceSynchronize(), message); 
# 36
} 
# 40
inline void synchronize(cudaStream_t stream, const char *message) 
# 41
{ 
# 43
throw_on_error(cudaStreamSynchronize(stream), message); 
# 47
} 
# 50
inline void synchronize_if_enabled(const char *message) 
# 51
{ 
# 58
(void)message; 
# 60
} 
# 63
}
# 64
}
# 65
}
# 66
}
# 32 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/trivial_copy.inl"
namespace thrust { 
# 34
namespace system { 
# 36
namespace cuda { 
# 38
namespace detail { 
# 40
namespace trivial_copy_detail { 
# 43
inline void checked_cudaMemcpyAsync(void *dst, const void *src, size_t count, cudaMemcpyKind kind, cudaStream_t stream) 
# 44
{ 
# 45
cudaError_t error = cudaMemcpyAsync(dst, src, count, kind, stream); 
# 46
if (error) 
# 47
{ 
# 48
throw system_error(error, thrust::cuda_category()); 
# 49
}  
# 50
} 
# 53
template< class System1, class 
# 54
System2> cudaMemcpyKind 
# 55
cuda_memcpy_kind(const execution_policy< System1>  &, const cpp::detail::execution_policy< System2>  &) 
# 57
{ 
# 58
return cudaMemcpyDeviceToHost; 
# 59
} 
# 62
template< class System1, class 
# 63
System2> cudaMemcpyKind 
# 64
cuda_memcpy_kind(const cpp::detail::execution_policy< System1>  &, const execution_policy< System2>  &) 
# 66
{ 
# 67
return cudaMemcpyHostToDevice; 
# 68
} 
# 70
template< class System> cudaMemcpyKind 
# 71
cuda_memcpy_kind(const execution_policy< System>  &, const execution_policy< System>  &) 
# 73
{ 
# 81
return cudaMemcpyDefault; 
# 83
} 
# 85
namespace _GLOBAL__N__17_gpu_setup_cpp1_ii_524b47c1 { }; using namespace ::thrust::system::cuda::detail::trivial_copy_detail::_GLOBAL__N__17_gpu_setup_cpp1_ii_524b47c1; namespace _GLOBAL__N__17_gpu_setup_cpp1_ii_524b47c1 { 
# 92
template< class T> bool 
# 93
is_valid_policy(const T &t) 
# 94
{ 
# 95
volatile size_t value = (reinterpret_cast< size_t>(&t)); 
# 96
if (value) 
# 97
{ 
# 98
if (value == (0)) 
# 99
{ 
# 100
fprintf(stderr, " clang WAR failed. Terminate.\n"); 
# 101
std::terminate(); 
# 102
}  
# 103
return true; 
# 104
}  
# 105
return false; 
# 106
} 
# 107
}
# 109
template< class System1, class 
# 110
System2> cudaStream_t 
# 111
cuda_memcpy_stream(const execution_policy< System1>  &exec, const cpp::detail::execution_policy< System2>  &) 
# 113
{ 
# 114
if (is_valid_policy(exec)) { 
# 115
return stream(derived_cast(exec)); }  
# 116
return legacy_stream(); 
# 117
} 
# 119
template< class System1, class 
# 120
System2> cudaStream_t 
# 121
cuda_memcpy_stream(const cpp::detail::execution_policy< System1>  &, const execution_policy< System2>  &
# 122
exec) 
# 123
{ 
# 124
if (is_valid_policy(exec)) { 
# 125
return stream(derived_cast(exec)); }  
# 126
return legacy_stream(); 
# 127
} 
# 130
template< class System> cudaStream_t 
# 131
cuda_memcpy_stream(const execution_policy< System>  &, const execution_policy< System>  &
# 132
exec) 
# 133
{ 
# 134
if (is_valid_policy(exec)) { 
# 135
return stream(derived_cast(exec)); }  
# 136
return legacy_stream(); 
# 137
} 
# 141
template< class System> cudaStream_t 
# 142
cuda_memcpy_stream(const execute_on_stream &exec, const execution_policy< System>  &) 
# 144
{ 
# 145
if (is_valid_policy(exec)) { 
# 146
return stream(exec); }  
# 147
return legacy_stream(); 
# 148
} 
# 154
}
# 157
template< class DerivedPolicy, class 
# 158
RandomAccessIterator1, class 
# 159
Size, class 
# 160
RandomAccessIterator2> void 
# 162
trivial_copy_n(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator1 
# 163
first, Size 
# 164
n, RandomAccessIterator2 
# 165
result) 
# 166
{ 
# 167
typedef typename iterator_value< RandomAccessIterator1> ::type T; 
# 170
void *dst = thrust::raw_pointer_cast(&(*result)); 
# 171
const void *src = thrust::raw_pointer_cast(&(*first)); 
# 178
cudaMemcpyKind kind = trivial_copy_detail::cuda_memcpy_kind(thrust::detail::derived_cast(exec), thrust::detail::derived_cast(exec)); 
# 179
trivial_copy_detail::checked_cudaMemcpyAsync(dst, src, n * sizeof(T), kind, stream(thrust::detail::derived_cast(exec))); 
# 183
} 
# 186
template< class System1, class 
# 187
System2, class 
# 188
RandomAccessIterator1, class 
# 189
Size, class 
# 190
RandomAccessIterator2> void 
# 191
trivial_copy_n(cross_system< System1, System2>  &systems, RandomAccessIterator1 
# 192
first, Size 
# 193
n, RandomAccessIterator2 
# 194
result) 
# 195
{ 
# 196
typedef typename iterator_value< RandomAccessIterator1> ::type T; 
# 198
void *dst = thrust::raw_pointer_cast(&(*result)); 
# 199
const void *src = thrust::raw_pointer_cast(&(*first)); 
# 201
cudaMemcpyKind kind = trivial_copy_detail::cuda_memcpy_kind(thrust::detail::derived_cast((systems.system1)), thrust::detail::derived_cast((systems.system2))); 
# 205
cudaStream_t s = trivial_copy_detail::cuda_memcpy_stream(derived_cast((systems.system1)), derived_cast((systems.system2))); 
# 206
trivial_copy_detail::checked_cudaMemcpyAsync(dst, src, n * sizeof(T), kind, s); 
# 207
synchronize(s, "failed synchronize in thrust::system::cuda::detail::trivial_copy_n"); 
# 208
} 
# 211
}
# 212
}
# 213
}
# 214
}
# 25 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/copy_cross_system.inl"
namespace thrust { 
# 27
namespace detail { 
# 31
template< class , class > class temporary_array; 
# 33
}
# 35
namespace system { 
# 37
namespace cuda { 
# 39
namespace detail { 
# 44
template< class System1, class 
# 45
System2, class 
# 46
InputIterator, class 
# 47
RandomAccessIterator> RandomAccessIterator 
# 48
copy_cross_system(cross_system< System1, System2>  systems, InputIterator 
# 49
begin, InputIterator 
# 50
end, RandomAccessIterator 
# 51
result, incrementable_traversal_tag, random_access_traversal_tag) 
# 54
{ 
# 59
typedef typename iterator_value< InputIterator> ::type InputType; 
# 62
thrust::detail::temporary_array< typename iterator_value< InputIterator> ::type, System1>  temp((systems.system1), begin, end); 
# 63
return thrust::copy(systems, (temp.begin()), (temp.end()), result); 
# 64
} 
# 66
template< class System1, class 
# 67
System2, class 
# 68
InputIterator, class 
# 69
Size, class 
# 70
RandomAccessIterator> RandomAccessIterator 
# 71
copy_cross_system_n(cross_system< System1, System2>  systems, InputIterator 
# 72
first, Size 
# 73
n, RandomAccessIterator 
# 74
result, incrementable_traversal_tag, random_access_traversal_tag) 
# 77
{ 
# 78
typedef typename iterator_value< InputIterator> ::type InputType; 
# 81
thrust::detail::temporary_array< typename iterator_value< InputIterator> ::type, System1>  temp((systems.system1), first, n); 
# 84
return copy_cross_system(systems, (temp.begin()), (temp.end()), result); 
# 85
} 
# 89
template< class System1, class 
# 90
System2, class 
# 91
RandomAccessIterator, class 
# 92
OutputIterator> OutputIterator 
# 93
copy_cross_system(cross_system< System1, System2>  systems, RandomAccessIterator 
# 94
begin, RandomAccessIterator 
# 95
end, OutputIterator 
# 96
result, random_access_traversal_tag, incrementable_traversal_tag) 
# 99
{ 
# 100
typedef typename iterator_value< RandomAccessIterator> ::type InputType; 
# 103
thrust::detail::temporary_array< typename iterator_value< RandomAccessIterator> ::type, System2>  temp((systems.system2), (systems.system1), begin, end); 
# 105
return thrust::copy((systems.system2), (temp.begin()), (temp.end()), result); 
# 106
} 
# 108
template< class System1, class 
# 109
System2, class 
# 110
RandomAccessIterator, class 
# 111
Size, class 
# 112
OutputIterator> OutputIterator 
# 113
copy_cross_system_n(cross_system< System1, System2>  systems, RandomAccessIterator 
# 114
first, Size 
# 115
n, OutputIterator 
# 116
result, random_access_traversal_tag, incrementable_traversal_tag) 
# 119
{ 
# 120
typedef typename iterator_value< RandomAccessIterator> ::type InputType; 
# 123
thrust::detail::temporary_array< typename iterator_value< RandomAccessIterator> ::type, System2>  temp((systems.system2), (systems.system1), first, n); 
# 126
return thrust::copy((systems.system2), (temp.begin()), (temp.end()), result); 
# 127
} 
# 131
template< class System1, class 
# 132
System2, class 
# 133
RandomAccessIterator1, class 
# 134
RandomAccessIterator2> RandomAccessIterator2 
# 135
copy_cross_system(cross_system< System1, System2>  systems, RandomAccessIterator1 
# 136
begin, RandomAccessIterator1 
# 137
end, RandomAccessIterator2 
# 138
result, random_access_traversal_tag, random_access_traversal_tag, thrust::detail::true_type) 
# 142
{ 
# 149
typename iterator_traits< RandomAccessIterator1> ::difference_type n = end - begin; 
# 151
cuda::detail::trivial_copy_n(systems, begin, n, result); 
# 153
return result + n; 
# 154
} 
# 157
namespace detail { 
# 161
template< class System1, class 
# 162
System2, class 
# 163
RandomAccessIterator1, class 
# 164
RandomAccessIterator2> RandomAccessIterator2 
# 165
non_trivial_random_access_copy_cross_system(cross_system< System1, System2>  systems, RandomAccessIterator1 
# 166
begin, RandomAccessIterator1 
# 167
end, RandomAccessIterator2 
# 168
result, thrust::detail::false_type) 
# 170
{ 
# 172
typedef typename iterator_value< RandomAccessIterator2> ::type OutputType; 
# 175
thrust::detail::temporary_array< typename iterator_value< RandomAccessIterator2> ::type, System1>  temp((systems.system1), begin, end); 
# 178
return copy_cross_system(systems, (temp.begin()), (temp.end()), result); 
# 179
} 
# 181
template< class System1, class 
# 182
System2, class 
# 183
RandomAccessIterator1, class 
# 184
RandomAccessIterator2> RandomAccessIterator2 
# 185
non_trivial_random_access_copy_cross_system(cross_system< System1, System2>  systems, RandomAccessIterator1 
# 186
begin, RandomAccessIterator1 
# 187
end, RandomAccessIterator2 
# 188
result, thrust::detail::true_type) 
# 190
{ 
# 191
typename iterator_difference< RandomAccessIterator1> ::type n = thrust::distance(begin, end); 
# 196
typedef typename iterator_value< RandomAccessIterator1> ::type InputType; 
# 197
thrust::detail::temporary_array< typename iterator_value< RandomAccessIterator1> ::type, System2>  temp(0, (systems.system2), n); 
# 204
cuda::detail::trivial_copy_n(systems, begin, n, (temp.begin())); 
# 207
return thrust::copy((systems.system2), (temp.begin()), (temp.end()), result); 
# 208
} 
# 210
}
# 214
template< class System1, class 
# 215
System2, class 
# 216
RandomAccessIterator1, class 
# 217
RandomAccessIterator2> RandomAccessIterator2 
# 218
copy_cross_system(cross_system< System1, System2>  systems, RandomAccessIterator1 
# 219
begin, RandomAccessIterator1 
# 220
end, RandomAccessIterator2 
# 221
result, random_access_traversal_tag, random_access_traversal_tag, thrust::detail::false_type) 
# 225
{ 
# 227
return detail::non_trivial_random_access_copy_cross_system(systems, begin, end, result, typename thrust::detail::is_trivial_iterator< RandomAccessIterator1> ::type()); 
# 229
} 
# 232
template< class System1, class 
# 233
System2, class 
# 234
RandomAccessIterator1, class 
# 235
RandomAccessIterator2> RandomAccessIterator2 
# 236
copy_cross_system(cross_system< System1, System2>  systems, RandomAccessIterator1 
# 237
begin, RandomAccessIterator1 
# 238
end, RandomAccessIterator2 
# 239
result, random_access_traversal_tag 
# 240
input_traversal, random_access_traversal_tag 
# 241
output_traversal) 
# 242
{ 
# 244
return copy_cross_system(systems, begin, end, result, input_traversal, output_traversal, typename thrust::detail::dispatch::is_trivial_copy< RandomAccessIterator1, RandomAccessIterator2> ::type()); 
# 246
} 
# 248
template< class System1, class 
# 249
System2, class 
# 250
RandomAccessIterator1, class 
# 251
Size, class 
# 252
RandomAccessIterator2> RandomAccessIterator2 
# 253
copy_cross_system_n(cross_system< System1, System2>  systems, RandomAccessIterator1 
# 254
first, Size 
# 255
n, RandomAccessIterator2 
# 256
result, random_access_traversal_tag 
# 257
input_traversal, random_access_traversal_tag 
# 258
output_traversal) 
# 259
{ 
# 261
return copy_cross_system(systems, first, first + n, result, input_traversal, output_traversal); 
# 262
} 
# 268
template< class System1, class 
# 269
System2, class 
# 270
InputIterator, class 
# 271
OutputIterator> OutputIterator 
# 272
copy_cross_system(cross_system< System1, System2>  systems, InputIterator 
# 273
begin, InputIterator 
# 274
end, OutputIterator 
# 275
result) 
# 276
{ 
# 277
return copy_cross_system(systems, begin, end, result, typename iterator_traversal< InputIterator> ::type(), typename iterator_traversal< OutputIterator> ::type()); 
# 280
} 
# 282
template< class System1, class 
# 283
System2, class 
# 284
InputIterator, class 
# 285
Size, class 
# 286
OutputIterator> OutputIterator 
# 287
copy_cross_system_n(cross_system< System1, System2>  systems, InputIterator 
# 288
begin, Size 
# 289
n, OutputIterator 
# 290
result) 
# 291
{ 
# 292
return copy_cross_system_n(systems, begin, n, result, typename iterator_traversal< InputIterator> ::type(), typename iterator_traversal< OutputIterator> ::type()); 
# 295
} 
# 297
}
# 298
}
# 299
}
# 300
}
# 20 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/trivial_copy.h"
namespace thrust { 
# 22
namespace system { 
# 24
namespace cuda { 
# 26
namespace detail { 
# 30
template< class DerivedPolicy, class 
# 31
RandomAccessIterator1, class 
# 32
Size, class 
# 33
RandomAccessIterator2> void 
# 30
trivial_copy_n(execution_policy< DerivedPolicy>  & exec, RandomAccessIterator1 first, Size n, RandomAccessIterator2 result); 
# 41
template< class System1, class 
# 42
System2, class 
# 43
RandomAccessIterator1, class 
# 44
Size, class 
# 45
RandomAccessIterator2> void 
# 41
trivial_copy_n(cross_system< System1, System2>  & exec, RandomAccessIterator1 first, Size n, RandomAccessIterator2 result); 
# 52
}
# 53
}
# 54
}
# 55
}
# 28 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/copy_device_to_device.inl"
namespace thrust { 
# 30
namespace system { 
# 32
namespace cuda { 
# 34
namespace detail { 
# 36
namespace detail { 
# 40
template< class DerivedPolicy, class 
# 41
InputIterator, class 
# 42
OutputIterator> OutputIterator 
# 44
copy_device_to_device(execution_policy< DerivedPolicy>  &exec, InputIterator 
# 45
begin, InputIterator 
# 46
end, OutputIterator 
# 47
result, thrust::detail::false_type) 
# 49
{ 
# 51
typedef typename iterator_traits< InputIterator> ::value_type InputType; 
# 54
return thrust::transform(exec, begin, end, result, identity< typename iterator_traits< InputIterator> ::value_type> ()); 
# 72
} 
# 75
template< class DerivedPolicy, class 
# 76
InputIterator, class 
# 77
OutputIterator> OutputIterator 
# 79
copy_device_to_device(execution_policy< DerivedPolicy>  &exec, InputIterator 
# 80
begin, InputIterator 
# 81
end, OutputIterator 
# 82
result, thrust::detail::true_type) 
# 84
{ 
# 89
typename iterator_traits< OutputIterator> ::difference_type n = end - begin; 
# 91
cuda::detail::trivial_copy_n(exec, begin, n, result); 
# 93
return result + n; 
# 94
} 
# 97
}
# 105
template< class DerivedPolicy, class 
# 106
InputIterator, class 
# 107
OutputIterator> OutputIterator 
# 109
copy_device_to_device(execution_policy< DerivedPolicy>  &exec, InputIterator 
# 110
begin, InputIterator 
# 111
end, OutputIterator 
# 112
result) 
# 113
{ 
# 114
typedef typename iterator_traits< InputIterator> ::value_type InputType; 
# 115
typedef typename iterator_traits< OutputIterator> ::value_type OutputType; 
# 117
const bool use_trivial_copy = (thrust::detail::is_same< typename iterator_traits< InputIterator> ::value_type, typename iterator_traits< OutputIterator> ::value_type> ::value && thrust::detail::is_trivial_iterator< InputIterator> ::value && thrust::detail::is_trivial_iterator< OutputIterator> ::value); 
# 123
(void)use_trivial_copy; 
# 125
return detail::copy_device_to_device(exec, begin, end, result, thrust::detail::integral_constant< bool, use_trivial_copy> ()); 
# 127
} 
# 130
}
# 131
}
# 132
}
# 133
}
# 22 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/copy.inl"
namespace thrust { 
# 24
namespace system { 
# 26
namespace cuda { 
# 28
namespace detail { 
# 32
template< class System, class 
# 33
InputIterator, class 
# 34
OutputIterator> OutputIterator 
# 36
copy(execution_policy< System>  &system, InputIterator 
# 37
first, InputIterator 
# 38
last, OutputIterator 
# 39
result) 
# 40
{ 
# 41
return cuda::detail::copy_device_to_device(system, first, last, result); 
# 42
} 
# 45
template< class System1, class 
# 46
System2, class 
# 47
InputIterator, class 
# 48
OutputIterator> OutputIterator 
# 49
copy(cross_system< System1, System2>  systems, InputIterator 
# 50
first, InputIterator 
# 51
last, OutputIterator 
# 52
result) 
# 53
{ 
# 54
return cuda::detail::copy_cross_system(systems, first, last, result); 
# 55
} 
# 58
template< class System, class 
# 59
InputIterator, class 
# 60
Size, class 
# 61
OutputIterator> OutputIterator 
# 63
copy_n(execution_policy< System>  &system, InputIterator 
# 64
first, Size 
# 65
n, OutputIterator 
# 66
result) 
# 67
{ 
# 68
return cuda::detail::copy_device_to_device(system, first, first + n, result); 
# 69
} 
# 72
template< class System1, class 
# 73
System2, class 
# 74
InputIterator, class 
# 75
Size, class 
# 76
OutputIterator> OutputIterator 
# 77
copy_n(cross_system< System1, System2>  systems, InputIterator 
# 78
first, Size 
# 79
n, OutputIterator 
# 80
result) 
# 81
{ 
# 82
return cuda::detail::copy_cross_system_n(systems, first, n, result); 
# 83
} 
# 86
}
# 87
}
# 88
}
# 89
}
# 24 "/usr/local/cuda-8.0/include/thrust/detail/copy.inl"
namespace thrust { 
# 29
template< class DerivedPolicy, class InputIterator, class OutputIterator> OutputIterator 
# 31
copy(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator 
# 32
first, InputIterator 
# 33
last, OutputIterator 
# 34
result) 
# 35
{ 
# 36
using system::detail::generic::copy;
# 37
return copy(detail::derived_cast(detail::strip_const(exec)), first, last, result); 
# 38
} 
# 42
template< class DerivedPolicy, class InputIterator, class Size, class OutputIterator> OutputIterator 
# 44
copy_n(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator 
# 45
first, Size 
# 46
n, OutputIterator 
# 47
result) 
# 48
{ 
# 49
using system::detail::generic::copy_n;
# 50
return copy_n(detail::derived_cast(detail::strip_const(exec)), first, n, result); 
# 51
} 
# 54
namespace detail { 
# 59
template< class System1, class 
# 60
System2, class 
# 61
InputIterator, class 
# 62
OutputIterator> OutputIterator 
# 64
two_system_copy(const execution_policy< System1>  &system1, const execution_policy< System2>  &
# 65
system2, InputIterator 
# 66
first, InputIterator 
# 67
last, OutputIterator 
# 68
result) 
# 69
{ 
# 70
using system::detail::generic::select_system;
# 72
return thrust::copy(select_system(detail::derived_cast(detail::strip_const(system1)), detail::derived_cast(detail::strip_const(system2))), first, last, result); 
# 73
} 
# 77
template< class System1, class 
# 78
System2, class 
# 79
InputIterator, class 
# 80
Size, class 
# 81
OutputIterator> OutputIterator 
# 83
two_system_copy_n(const execution_policy< System1>  &system1, const execution_policy< System2>  &
# 84
system2, InputIterator 
# 85
first, Size 
# 86
n, OutputIterator 
# 87
result) 
# 88
{ 
# 89
using system::detail::generic::select_system;
# 91
return thrust::copy_n(select_system(detail::derived_cast(detail::strip_const(system1)), detail::derived_cast(detail::strip_const(system2))), first, n, result); 
# 92
} 
# 95
}
# 98
template< class InputIterator, class 
# 99
OutputIterator> OutputIterator 
# 100
copy(InputIterator first, InputIterator 
# 101
last, OutputIterator 
# 102
result) 
# 103
{ 
# 104
typedef typename iterator_system< InputIterator> ::type System1; 
# 105
typedef typename iterator_system< OutputIterator> ::type System2; 
# 107
System1 system1; 
# 108
System2 system2; 
# 110
return detail::two_system_copy(system1, system2, first, last, result); 
# 111
} 
# 114
template< class InputIterator, class 
# 115
Size, class 
# 116
OutputIterator> OutputIterator 
# 117
copy_n(InputIterator first, Size 
# 118
n, OutputIterator 
# 119
result) 
# 120
{ 
# 121
typedef typename iterator_system< InputIterator> ::type System1; 
# 122
typedef typename iterator_system< OutputIterator> ::type System2; 
# 124
System1 system1; 
# 125
System2 system2; 
# 127
return detail::two_system_copy_n(system1, system2, first, n, result); 
# 128
} 
# 131
}
# 29 "/usr/local/cuda-8.0/include/thrust/detail/allocator/copy_construct_range.inl"
namespace thrust { 
# 31
namespace detail { 
# 33
namespace allocator_traits_detail { 
# 37
template< class Allocator, class InputType, class OutputType> 
# 38
struct copy_construct_with_allocator { 
# 40
Allocator &a; 
# 43
copy_construct_with_allocator(Allocator &a) : a(a) 
# 45
{ } 
# 47
template< class Tuple> void 
# 49
operator()(Tuple t) 
# 50
{ 
# 51
const InputType &in = thrust::get< 0> (t); 
# 52
OutputType &out = thrust::get< 1> (t); 
# 54
allocator_traits< Allocator> ::construct(a, &out, in); 
# 55
} 
# 56
}; 
# 63
template< class Allocator, class T> 
# 64
struct needs_copy_construct_via_allocator : public integral_constant< bool, has_member_construct2< Allocator, T, T> ::value || (!has_trivial_copy_constructor< T> ::value)>  { 
# 69
}; 
# 74
template< class U, class T> 
# 75
struct needs_copy_construct_via_allocator< std::allocator< U> , T>  : public integral_constant< bool, !has_trivial_copy_constructor< T> ::value>  { 
# 80
}; 
# 87
template< class Allocator, class FromSystem, class ToSystem, class InputIterator, class Pointer> typename enable_if_convertible< FromSystem, ToSystem, Pointer> ::type 
# 94
uninitialized_copy_with_allocator(Allocator &a, const execution_policy< FromSystem>  &
# 95
from_system, const execution_policy< ToSystem>  &
# 96
to_system, InputIterator 
# 97
first, InputIterator 
# 98
last, Pointer 
# 99
result) 
# 100
{ 
# 102
typedef tuple< InputIterator, Pointer, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type>  IteratorTuple; 
# 103
typedef zip_iterator< tuple< InputIterator, Pointer, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type> >  ZipIterator; 
# 105
ZipIterator begin = thrust::make_zip_iterator(thrust::make_tuple(first, result)); 
# 106
ZipIterator end = begin; 
# 109
const typename iterator_difference< InputIterator> ::type n = thrust::distance(first, last); 
# 110
thrust::advance(end, n); 
# 113
typedef typename iterator_traits< InputIterator> ::value_type InputType; 
# 114
typedef typename iterator_traits< Pointer> ::value_type OutputType; 
# 118
thrust::for_each(to_system, begin, end, ((copy_construct_with_allocator< Allocator, typename iterator_traits< InputIterator> ::value_type, typename iterator_traits< Pointer> ::value_type> )(a))); 
# 121
return thrust::get< 1> ((end.get_iterator_tuple())); 
# 122
} 
# 129
template< class Allocator, class FromSystem, class ToSystem, class InputIterator, class Size, class Pointer> typename enable_if_convertible< FromSystem, ToSystem, Pointer> ::type 
# 136
uninitialized_copy_with_allocator_n(Allocator &a, const execution_policy< FromSystem>  &
# 137
from_system, const execution_policy< ToSystem>  &
# 138
to_system, InputIterator 
# 139
first, Size 
# 140
n, Pointer 
# 141
result) 
# 142
{ 
# 144
typedef tuple< InputIterator, Pointer, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type>  IteratorTuple; 
# 145
typedef zip_iterator< tuple< InputIterator, Pointer, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type> >  ZipIterator; 
# 147
ZipIterator begin = thrust::make_zip_iterator(thrust::make_tuple(first, result)); 
# 150
typedef typename iterator_traits< InputIterator> ::value_type InputType; 
# 151
typedef typename iterator_traits< Pointer> ::value_type OutputType; 
# 155
ZipIterator end = thrust::for_each_n(to_system, begin, n, ((copy_construct_with_allocator< Allocator, typename iterator_traits< InputIterator> ::value_type, typename iterator_traits< Pointer> ::value_type> )(a))); 
# 158
return thrust::get< 1> ((end.get_iterator_tuple())); 
# 159
} 
# 162
template< class Allocator, class FromSystem, class ToSystem, class InputIterator, class Pointer> typename disable_if_convertible< FromSystem, ToSystem, Pointer> ::type 
# 169
uninitialized_copy_with_allocator(Allocator &, const execution_policy< FromSystem>  &
# 170
from_system, const execution_policy< ToSystem>  &
# 171
to_system, InputIterator 
# 172
first, InputIterator 
# 173
last, Pointer 
# 174
result) 
# 175
{ 
# 178
return detail::two_system_copy(from_system, to_system, first, last, result); 
# 179
} 
# 182
template< class Allocator, class FromSystem, class ToSystem, class InputIterator, class Size, class Pointer> typename disable_if_convertible< FromSystem, ToSystem, Pointer> ::type 
# 189
uninitialized_copy_with_allocator_n(Allocator &, const execution_policy< FromSystem>  &
# 190
from_system, const execution_policy< ToSystem>  &
# 191
to_system, InputIterator 
# 192
first, Size 
# 193
n, Pointer 
# 194
result) 
# 195
{ 
# 198
return detail::two_system_copy_n(from_system, to_system, first, n, result); 
# 199
} 
# 202
template< class FromSystem, class Allocator, class InputIterator, class Pointer> typename disable_if< needs_copy_construct_via_allocator< Allocator, typename pointer_element< Pointer> ::type> ::value, Pointer> ::type 
# 211
copy_construct_range(execution_policy< FromSystem>  &from_system, Allocator &
# 212
a, InputIterator 
# 213
first, InputIterator 
# 214
last, Pointer 
# 215
result) 
# 216
{ 
# 218
return detail::two_system_copy(from_system, allocator_system< Allocator> ::get(a), first, last, result); 
# 219
} 
# 222
template< class FromSystem, class Allocator, class InputIterator, class Size, class Pointer> typename disable_if< needs_copy_construct_via_allocator< Allocator, typename pointer_element< Pointer> ::type> ::value, Pointer> ::type 
# 231
copy_construct_range_n(execution_policy< FromSystem>  &from_system, Allocator &
# 232
a, InputIterator 
# 233
first, Size 
# 234
n, Pointer 
# 235
result) 
# 236
{ 
# 238
return detail::two_system_copy_n(from_system, allocator_system< Allocator> ::get(a), first, n, result); 
# 239
} 
# 242
template< class FromSystem, class Allocator, class InputIterator, class Pointer> typename enable_if< needs_copy_construct_via_allocator< Allocator, typename pointer_element< Pointer> ::type> ::value, Pointer> ::type 
# 251
copy_construct_range(execution_policy< FromSystem>  &from_system, Allocator &
# 252
a, InputIterator 
# 253
first, InputIterator 
# 254
last, Pointer 
# 255
result) 
# 256
{ 
# 257
return uninitialized_copy_with_allocator(a, from_system, allocator_system< Allocator> ::get(a), first, last, result); 
# 258
} 
# 261
template< class FromSystem, class Allocator, class InputIterator, class Size, class Pointer> typename enable_if< needs_copy_construct_via_allocator< Allocator, typename pointer_element< Pointer> ::type> ::value, Pointer> ::type 
# 270
copy_construct_range_n(execution_policy< FromSystem>  &from_system, Allocator &
# 271
a, InputIterator 
# 272
first, Size 
# 273
n, Pointer 
# 274
result) 
# 275
{ 
# 276
return uninitialized_copy_with_allocator_n(a, from_system, allocator_system< Allocator> ::get(a), first, n, result); 
# 277
} 
# 280
}
# 283
template< class System, class Allocator, class InputIterator, class Pointer> Pointer 
# 285
copy_construct_range(execution_policy< System>  &from_system, Allocator &
# 286
a, InputIterator 
# 287
first, InputIterator 
# 288
last, Pointer 
# 289
result) 
# 290
{ 
# 291
return allocator_traits_detail::copy_construct_range(from_system, a, first, last, result); 
# 292
} 
# 295
template< class System, class Allocator, class InputIterator, class Size, class Pointer> Pointer 
# 297
copy_construct_range_n(execution_policy< System>  &from_system, Allocator &
# 298
a, InputIterator 
# 299
first, Size 
# 300
n, Pointer 
# 301
result) 
# 302
{ 
# 303
return allocator_traits_detail::copy_construct_range_n(from_system, a, first, n, result); 
# 304
} 
# 307
}
# 308
}
# 21 "/usr/local/cuda-8.0/include/thrust/detail/allocator/default_construct_range.h"
namespace thrust { 
# 23
namespace detail { 
# 27
template< class Allocator, class Pointer, class Size> inline void default_construct_range(Allocator & a, Pointer p, Size n); 
# 32
}
# 33
}
# 27 "/usr/local/cuda-8.0/include/thrust/uninitialized_fill.h"
namespace thrust { 
# 90
template< class DerivedPolicy, class ForwardIterator, class T> void uninitialized_fill(const detail::execution_policy_base< DerivedPolicy>  & exec, ForwardIterator first, ForwardIterator last, const T & x); 
# 146
template< class ForwardIterator, class T> void uninitialized_fill(ForwardIterator first, ForwardIterator last, const T & x); 
# 206
template< class DerivedPolicy, class ForwardIterator, class Size, class T> ForwardIterator uninitialized_fill_n(const detail::execution_policy_base< DerivedPolicy>  & exec, ForwardIterator first, Size n, const T & x); 
# 263
template< class ForwardIterator, class Size, class T> ForwardIterator uninitialized_fill_n(ForwardIterator first, Size n, const T & x); 
# 272
}
# 23 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/uninitialized_fill.h"
namespace thrust { 
# 25
namespace system { 
# 27
namespace detail { 
# 29
namespace generic { 
# 32
template< class DerivedPolicy, class 
# 33
ForwardIterator, class 
# 34
T> void 
# 32
uninitialized_fill(execution_policy< DerivedPolicy>  & exec, ForwardIterator first, ForwardIterator last, const T & x); 
# 41
template< class DerivedPolicy, class 
# 42
ForwardIterator, class 
# 43
Size, class 
# 44
T> ForwardIterator 
# 41
uninitialized_fill_n(execution_policy< DerivedPolicy>  & exec, ForwardIterator first, Size n, const T & x); 
# 51
}
# 52
}
# 53
}
# 54
}
# 27 "/usr/local/cuda-8.0/include/thrust/fill.h"
namespace thrust { 
# 74
template< class DerivedPolicy, class ForwardIterator, class T> void fill(const detail::execution_policy_base< DerivedPolicy>  & exec, ForwardIterator first, ForwardIterator last, const T & value); 
# 113
template< class ForwardIterator, class T> void fill(ForwardIterator first, ForwardIterator last, const T & value); 
# 156
template< class DerivedPolicy, class OutputIterator, class Size, class T> OutputIterator fill_n(const detail::execution_policy_base< DerivedPolicy>  & exec, OutputIterator first, Size n, const T & value); 
# 195
template< class OutputIterator, class Size, class T> OutputIterator fill_n(OutputIterator first, Size n, const T & value); 
# 206
}
# 27 "/usr/local/cuda-8.0/include/thrust/generate.h"
namespace thrust { 
# 72
template< class DerivedPolicy, class 
# 73
ForwardIterator, class 
# 74
Generator> void 
# 72
generate(const detail::execution_policy_base< DerivedPolicy>  & exec, ForwardIterator first, ForwardIterator last, Generator gen); 
# 114
template< class ForwardIterator, class 
# 115
Generator> void 
# 114
generate(ForwardIterator first, ForwardIterator last, Generator gen); 
# 157
template< class DerivedPolicy, class 
# 158
OutputIterator, class 
# 159
Size, class 
# 160
Generator> OutputIterator 
# 157
generate_n(const detail::execution_policy_base< DerivedPolicy>  & exec, OutputIterator first, Size n, Generator gen); 
# 199
template< class OutputIterator, class 
# 200
Size, class 
# 201
Generator> OutputIterator 
# 199
generate_n(OutputIterator first, Size n, Generator gen); 
# 210
}
# 23 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/generate.h"
namespace thrust { 
# 25
namespace system { 
# 27
namespace detail { 
# 29
namespace generic { 
# 32
template< class ExecutionPolicy, class 
# 33
ForwardIterator, class 
# 34
Generator> void 
# 32
generate(execution_policy< ExecutionPolicy>  & exec, ForwardIterator first, ForwardIterator last, Generator gen); 
# 41
template< class ExecutionPolicy, class 
# 42
OutputIterator, class 
# 43
Size, class 
# 44
Generator> OutputIterator 
# 41
generate_n(execution_policy< ExecutionPolicy>  & exec, OutputIterator first, Size n, Generator gen); 
# 51
}
# 52
}
# 53
}
# 54
}
# 23 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/generate.inl"
namespace thrust { 
# 25
namespace system { 
# 27
namespace detail { 
# 29
namespace generic { 
# 32
template< class ExecutionPolicy, class 
# 33
ForwardIterator, class 
# 34
Generator> void 
# 36
generate(execution_policy< ExecutionPolicy>  &exec, ForwardIterator 
# 37
first, ForwardIterator 
# 38
last, Generator 
# 39
gen) 
# 40
{ 
# 41
thrust::for_each(exec, first, last, (typename thrust::detail::generate_functor< ExecutionPolicy, Generator> ::type)gen); 
# 42
} 
# 44
template< class ExecutionPolicy, class 
# 45
OutputIterator, class 
# 46
Size, class 
# 47
Generator> OutputIterator 
# 49
generate_n(execution_policy< ExecutionPolicy>  &exec, OutputIterator 
# 50
first, Size 
# 51
n, Generator 
# 52
gen) 
# 53
{ 
# 54
return thrust::for_each_n(exec, first, n, (typename thrust::detail::generate_functor< ExecutionPolicy, Generator> ::type)gen); 
# 55
} 
# 57
}
# 58
}
# 59
}
# 60
}
# 29 "/usr/local/cuda-8.0/include/thrust/detail/generate.inl"
namespace thrust { 
# 34
template< class DerivedPolicy, class 
# 35
ForwardIterator, class 
# 36
Generator> void 
# 38
generate(const detail::execution_policy_base< DerivedPolicy>  &exec, ForwardIterator 
# 39
first, ForwardIterator 
# 40
last, Generator 
# 41
gen) 
# 42
{ 
# 43
using system::detail::generic::generate;
# 44
return generate(detail::derived_cast(detail::strip_const(exec)), first, last, gen); 
# 45
} 
# 49
template< class DerivedPolicy, class 
# 50
OutputIterator, class 
# 51
Size, class 
# 52
Generator> OutputIterator 
# 54
generate_n(const detail::execution_policy_base< DerivedPolicy>  &exec, OutputIterator 
# 55
first, Size 
# 56
n, Generator 
# 57
gen) 
# 58
{ 
# 59
using system::detail::generic::generate_n;
# 60
return generate_n(detail::derived_cast(detail::strip_const(exec)), first, n, gen); 
# 61
} 
# 64
template< class ForwardIterator, class 
# 65
Generator> void 
# 66
generate(ForwardIterator first, ForwardIterator 
# 67
last, Generator 
# 68
gen) 
# 69
{ 
# 70
using thrust::system::detail::generic::select_system;
# 72
typedef typename iterator_system< ForwardIterator> ::type System; 
# 74
System system; 
# 76
return thrust::generate(select_system(system), first, last, gen); 
# 77
} 
# 80
template< class OutputIterator, class 
# 81
Size, class 
# 82
Generator> OutputIterator 
# 83
generate_n(OutputIterator first, Size 
# 84
n, Generator 
# 85
gen) 
# 86
{ 
# 87
using thrust::system::detail::generic::select_system;
# 89
typedef typename iterator_system< OutputIterator> ::type System; 
# 91
System system; 
# 93
return thrust::generate_n(select_system(system), first, n, gen); 
# 94
} 
# 97
}
# 23 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/fill.h"
namespace thrust { 
# 25
namespace system { 
# 27
namespace detail { 
# 29
namespace generic { 
# 33
template< class DerivedPolicy, class OutputIterator, class Size, class T> OutputIterator 
# 35
fill_n(execution_policy< DerivedPolicy>  &exec, OutputIterator 
# 36
first, Size 
# 37
n, const T &
# 38
value) 
# 39
{ 
# 41
return thrust::generate_n(exec, first, n, ((thrust::detail::fill_functor< T> )(value))); 
# 42
} 
# 44
template< class DerivedPolicy, class ForwardIterator, class T> void 
# 46
fill(execution_policy< DerivedPolicy>  &exec, ForwardIterator 
# 47
first, ForwardIterator 
# 48
last, const T &
# 49
value) 
# 50
{ 
# 52
thrust::generate(exec, first, last, ((thrust::detail::fill_functor< T> )(value))); 
# 53
} 
# 56
}
# 57
}
# 58
}
# 59
}
# 28 "/usr/local/cuda-8.0/include/thrust/detail/fill.inl"
namespace thrust { 
# 33
template< class DerivedPolicy, class ForwardIterator, class T> void 
# 35
fill(const detail::execution_policy_base< DerivedPolicy>  &exec, ForwardIterator 
# 36
first, ForwardIterator 
# 37
last, const T &
# 38
value) 
# 39
{ 
# 40
using system::detail::generic::fill;
# 41
return fill(detail::derived_cast(detail::strip_const(exec)), first, last, value); 
# 42
} 
# 46
template< class DerivedPolicy, class OutputIterator, class Size, class T> OutputIterator 
# 48
fill_n(const detail::execution_policy_base< DerivedPolicy>  &exec, OutputIterator 
# 49
first, Size 
# 50
n, const T &
# 51
value) 
# 52
{ 
# 53
using system::detail::generic::fill_n;
# 54
return fill_n(detail::derived_cast(detail::strip_const(exec)), first, n, value); 
# 55
} 
# 58
template< class ForwardIterator, class T> void 
# 60
fill(ForwardIterator first, ForwardIterator 
# 61
last, const T &
# 62
value) 
# 63
{ 
# 64
using thrust::system::detail::generic::select_system;
# 66
typedef typename iterator_system< ForwardIterator> ::type System; 
# 68
System system; 
# 70
thrust::fill(select_system(system), first, last, value); 
# 71
} 
# 74
template< class OutputIterator, class Size, class T> OutputIterator 
# 76
fill_n(OutputIterator first, Size 
# 77
n, const T &
# 78
value) 
# 79
{ 
# 80
using thrust::system::detail::generic::select_system;
# 82
typedef typename iterator_system< OutputIterator> ::type System; 
# 84
System system; 
# 86
return thrust::fill_n(select_system(system), first, n, value); 
# 87
} 
# 90
}
# 24 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/uninitialized_fill.inl"
namespace thrust { 
# 26
namespace system { 
# 28
namespace detail { 
# 30
namespace generic { 
# 32
namespace detail { 
# 35
template< class DerivedPolicy, class 
# 36
ForwardIterator, class 
# 37
T> void 
# 39
uninitialized_fill(execution_policy< DerivedPolicy>  &exec, ForwardIterator 
# 40
first, ForwardIterator 
# 41
last, const T &
# 42
x, thrust::detail::true_type) 
# 44
{ 
# 45
thrust::fill(exec, first, last, x); 
# 46
} 
# 48
template< class DerivedPolicy, class 
# 49
ForwardIterator, class 
# 50
T> void 
# 52
uninitialized_fill(execution_policy< DerivedPolicy>  &exec, ForwardIterator 
# 53
first, ForwardIterator 
# 54
last, const T &
# 55
x, thrust::detail::false_type) 
# 57
{ 
# 58
typedef typename iterator_traits< ForwardIterator> ::value_type ValueType; 
# 60
thrust::for_each(exec, first, last, ((thrust::detail::uninitialized_fill_functor< typename iterator_traits< ForwardIterator> ::value_type> )(x))); 
# 61
} 
# 63
template< class DerivedPolicy, class 
# 64
ForwardIterator, class 
# 65
Size, class 
# 66
T> ForwardIterator 
# 68
uninitialized_fill_n(execution_policy< DerivedPolicy>  &exec, ForwardIterator 
# 69
first, Size 
# 70
n, const T &
# 71
x, thrust::detail::true_type) 
# 73
{ 
# 74
return thrust::fill_n(exec, first, n, x); 
# 75
} 
# 77
template< class DerivedPolicy, class 
# 78
ForwardIterator, class 
# 79
Size, class 
# 80
T> ForwardIterator 
# 82
uninitialized_fill_n(execution_policy< DerivedPolicy>  &exec, ForwardIterator 
# 83
first, Size 
# 84
n, const T &
# 85
x, thrust::detail::false_type) 
# 87
{ 
# 88
typedef typename iterator_traits< ForwardIterator> ::value_type ValueType; 
# 90
return thrust::for_each_n(exec, first, n, ((thrust::detail::uninitialized_fill_functor< typename iterator_traits< ForwardIterator> ::value_type> )(x))); 
# 91
} 
# 93
}
# 95
template< class DerivedPolicy, class 
# 96
ForwardIterator, class 
# 97
T> void 
# 99
uninitialized_fill(execution_policy< DerivedPolicy>  &exec, ForwardIterator 
# 100
first, ForwardIterator 
# 101
last, const T &
# 102
x) 
# 103
{ 
# 104
typedef typename iterator_traits< ForwardIterator> ::value_type ValueType; 
# 106
typedef thrust::detail::has_trivial_copy_constructor< typename iterator_traits< ForwardIterator> ::value_type>  ValueTypeHasTrivialCopyConstructor; 
# 108
detail::uninitialized_fill(exec, first, last, x, ValueTypeHasTrivialCopyConstructor()); 
# 110
} 
# 112
template< class DerivedPolicy, class 
# 113
ForwardIterator, class 
# 114
Size, class 
# 115
T> ForwardIterator 
# 117
uninitialized_fill_n(execution_policy< DerivedPolicy>  &exec, ForwardIterator 
# 118
first, Size 
# 119
n, const T &
# 120
x) 
# 121
{ 
# 122
typedef typename iterator_traits< ForwardIterator> ::value_type ValueType; 
# 124
typedef thrust::detail::has_trivial_copy_constructor< typename iterator_traits< ForwardIterator> ::value_type>  ValueTypeHasTrivialCopyConstructor; 
# 126
return detail::uninitialized_fill_n(exec, first, n, x, ValueTypeHasTrivialCopyConstructor()); 
# 128
} 
# 130
}
# 131
}
# 132
}
# 133
}
# 28 "/usr/local/cuda-8.0/include/thrust/detail/uninitialized_fill.inl"
namespace thrust { 
# 33
template< class DerivedPolicy, class ForwardIterator, class T> void 
# 35
uninitialized_fill(const detail::execution_policy_base< DerivedPolicy>  &exec, ForwardIterator 
# 36
first, ForwardIterator 
# 37
last, const T &
# 38
x) 
# 39
{ 
# 40
using system::detail::generic::uninitialized_fill;
# 41
return uninitialized_fill(detail::derived_cast(detail::strip_const(exec)), first, last, x); 
# 42
} 
# 46
template< class DerivedPolicy, class ForwardIterator, class Size, class T> ForwardIterator 
# 48
uninitialized_fill_n(const detail::execution_policy_base< DerivedPolicy>  &exec, ForwardIterator 
# 49
first, Size 
# 50
n, const T &
# 51
x) 
# 52
{ 
# 53
using system::detail::generic::uninitialized_fill_n;
# 54
return uninitialized_fill_n(detail::derived_cast(detail::strip_const(exec)), first, n, x); 
# 55
} 
# 58
template< class ForwardIterator, class 
# 59
T> void 
# 60
uninitialized_fill(ForwardIterator first, ForwardIterator 
# 61
last, const T &
# 62
x) 
# 63
{ 
# 64
using thrust::system::detail::generic::select_system;
# 66
typedef typename iterator_system< ForwardIterator> ::type System; 
# 68
System system; 
# 70
thrust::uninitialized_fill(select_system(system), first, last, x); 
# 71
} 
# 74
template< class ForwardIterator, class 
# 75
Size, class 
# 76
T> ForwardIterator 
# 77
uninitialized_fill_n(ForwardIterator first, Size 
# 78
n, const T &
# 79
x) 
# 80
{ 
# 81
using thrust::system::detail::generic::select_system;
# 83
typedef typename iterator_system< ForwardIterator> ::type System; 
# 85
System system; 
# 87
return thrust::uninitialized_fill_n(select_system(system), first, n, x); 
# 88
} 
# 91
}
# 24 "/usr/local/cuda-8.0/include/thrust/detail/allocator/default_construct_range.inl"
namespace thrust { 
# 26
namespace detail { 
# 28
namespace allocator_traits_detail { 
# 32
template< class Allocator> 
# 33
struct construct1_via_allocator { 
# 35
Allocator &a; 
# 38
construct1_via_allocator(Allocator &a) : a(a) 
# 40
{ } 
# 42
template< class T> void 
# 44
operator()(T &x) 
# 45
{ 
# 46
allocator_traits< Allocator> ::construct(a, &x); 
# 47
} 
# 48
}; 
# 52
template< class Allocator, class T> 
# 53
struct needs_default_construct_via_allocator : public or_< has_member_construct1< Allocator, T> , not_< has_trivial_constructor< T> > >  { 
# 58
}; 
# 64
template< class U, class T> 
# 65
struct needs_default_construct_via_allocator< std::allocator< U> , T>  : public not_< has_trivial_constructor< T> >  { 
# 67
}; 
# 70
template< class Allocator, class Pointer, class Size> typename enable_if< needs_default_construct_via_allocator< Allocator, typename pointer_element< Pointer> ::type> ::value> ::type 
# 78
default_construct_range(Allocator &a, Pointer p, Size n) 
# 79
{ 
# 80
thrust::for_each_n(allocator_system< Allocator> ::get(a), p, n, ((construct1_via_allocator< Allocator> )(a))); 
# 81
} 
# 84
template< class Allocator, class Pointer, class Size> typename disable_if< needs_default_construct_via_allocator< Allocator, typename pointer_element< Pointer> ::type> ::value> ::type 
# 92
default_construct_range(Allocator &a, Pointer p, Size n) 
# 93
{ 
# 94
thrust::uninitialized_fill_n(allocator_system< Allocator> ::get(a), p, n, typename pointer_element< Pointer> ::type()); 
# 95
} 
# 98
}
# 101
template< class Allocator, class Pointer, class Size> inline void 
# 103
default_construct_range(Allocator &a, Pointer p, Size n) 
# 104
{ 
# 105
return allocator_traits_detail::default_construct_range(a, p, n); 
# 106
} 
# 109
}
# 110
}
# 21 "/usr/local/cuda-8.0/include/thrust/detail/allocator/destroy_range.h"
namespace thrust { 
# 23
namespace detail { 
# 26
template< class Allocator, class Pointer, class Size> inline void destroy_range(Allocator & a, Pointer p, Size n); 
# 30
}
# 31
}
# 23 "/usr/local/cuda-8.0/include/thrust/detail/allocator/destroy_range.inl"
namespace thrust { 
# 25
namespace detail { 
# 27
namespace allocator_traits_detail { 
# 38
template< class Allocator, class T> 
# 39
struct has_effectful_member_destroy : public has_member_destroy< Allocator, T>  { 
# 41
}; 
# 44
template< class U, class T> 
# 45
struct has_effectful_member_destroy< std::allocator< U> , T>  : public false_type { 
# 47
}; 
# 50
template< class Allocator, class Pointer> 
# 51
struct enable_if_destroy_range_case1 : public enable_if< has_effectful_member_destroy< Allocator, typename pointer_element< Pointer> ::type> ::value>  { 
# 58
}; 
# 61
template< class Allocator, class Pointer> 
# 62
struct enable_if_destroy_range_case2 : public enable_if< (!has_effectful_member_destroy< Allocator, typename pointer_element< Pointer> ::type> ::value) && (!has_trivial_destructor< typename pointer_element< Pointer> ::type> ::value)>  { 
# 72
}; 
# 75
template< class Allocator, class Pointer> 
# 76
struct enable_if_destroy_range_case3 : public enable_if< (!has_effectful_member_destroy< Allocator, typename pointer_element< Pointer> ::type> ::value) && has_trivial_destructor< typename pointer_element< Pointer> ::type> ::value>  { 
# 86
}; 
# 90
template< class Allocator> 
# 91
struct destroy_via_allocator { 
# 93
Allocator &a; 
# 96
destroy_via_allocator(Allocator &a) : a(a) 
# 98
{ } 
# 100
template< class T> void 
# 102
operator()(T &x) 
# 103
{ 
# 104
allocator_traits< Allocator> ::destroy(a, &x); 
# 105
} 
# 106
}; 
# 110
template< class Allocator, class Pointer, class Size> typename enable_if_destroy_range_case1< Allocator, Pointer> ::type 
# 113
destroy_range(Allocator &a, Pointer p, Size n) 
# 114
{ 
# 115
thrust::for_each_n(allocator_system< Allocator> ::get(a), p, n, ((destroy_via_allocator< Allocator> )(a))); 
# 116
} 
# 120
struct gozer { 
# 123
template< class T> void 
# 125
operator()(T &x) 
# 126
{ 
# 127
(x.~T()); 
# 128
} 
# 129
}; 
# 132
template< class Allocator, class Pointer, class Size> typename enable_if_destroy_range_case2< Allocator, Pointer> ::type 
# 135
destroy_range(Allocator &a, Pointer p, Size n) 
# 136
{ 
# 137
thrust::for_each_n(allocator_system< Allocator> ::get(a), p, n, gozer()); 
# 138
} 
# 142
template< class Allocator, class Pointer, class Size> typename enable_if_destroy_range_case3< Allocator, Pointer> ::type 
# 145
destroy_range(Allocator &, Pointer, Size) 
# 146
{ 
# 148
} 
# 151
}
# 154
template< class Allocator, class Pointer, class Size> inline void 
# 156
destroy_range(Allocator &a, Pointer p, Size n) 
# 157
{ 
# 158
return allocator_traits_detail::destroy_range(a, p, n); 
# 159
} 
# 162
}
# 163
}
# 21 "/usr/local/cuda-8.0/include/thrust/detail/allocator/fill_construct_range.h"
namespace thrust { 
# 23
namespace detail { 
# 27
template< class Allocator, class Pointer, class Size, class T> inline void fill_construct_range(Allocator & a, Pointer p, Size n, const T & value); 
# 32
}
# 33
}
# 25 "/usr/local/cuda-8.0/include/thrust/detail/allocator/fill_construct_range.inl"
namespace thrust { 
# 27
namespace detail { 
# 29
namespace allocator_traits_detail { 
# 38
template< class Allocator, class T, class Arg1> 
# 39
struct has_effectful_member_construct2 : public has_member_construct2< Allocator, T, Arg1>  { 
# 41
}; 
# 44
template< class U, class T, class Arg1> 
# 45
struct has_effectful_member_construct2< std::allocator< U> , T, Arg1>  : public false_type { 
# 47
}; 
# 50
template< class Allocator, class Arg1> 
# 51
struct construct2_via_allocator { 
# 53
Allocator &a; 
# 54
Arg1 arg; 
# 57
construct2_via_allocator(Allocator &a, const Arg1 &arg) : a(a), arg(arg) 
# 59
{ } 
# 61
template< class T> void 
# 63
operator()(T &x) 
# 64
{ 
# 65
allocator_traits< Allocator> ::construct(a, &x, arg); 
# 66
} 
# 67
}; 
# 70
template< class Allocator, class Pointer, class Size, class T> typename enable_if< has_effectful_member_construct2< Allocator, typename pointer_element< Pointer> ::type, T> ::value> ::type 
# 79
fill_construct_range(Allocator &a, Pointer p, Size n, const T &value) 
# 80
{ 
# 81
thrust::for_each_n(allocator_system< Allocator> ::get(a), p, n, construct2_via_allocator< Allocator, T> (a, value)); 
# 82
} 
# 85
template< class Allocator, class Pointer, class Size, class T> typename disable_if< has_effectful_member_construct2< Allocator, typename pointer_element< Pointer> ::type, T> ::value> ::type 
# 94
fill_construct_range(Allocator &a, Pointer p, Size n, const T &value) 
# 95
{ 
# 96
thrust::uninitialized_fill_n(allocator_system< Allocator> ::get(a), p, n, value); 
# 97
} 
# 100
}
# 103
template< class Alloc, class Pointer, class Size, class T> inline void 
# 105
fill_construct_range(Alloc &a, Pointer p, Size n, const T &value) 
# 106
{ 
# 107
return allocator_traits_detail::fill_construct_range(a, p, n, value); 
# 108
} 
# 111
}
# 112
}
# 28 "/usr/local/cuda-8.0/include/thrust/detail/contiguous_storage.inl"
namespace thrust { 
# 31
namespace detail { 
# 35
template< class T, class Alloc> 
# 38
contiguous_storage< T, Alloc> ::contiguous_storage(const Alloc &alloc) : m_allocator(alloc), m_begin((pointer)(static_cast< T *>(0))), m_size(0) 
# 42
{ 
# 43
; 
# 44
} 
# 47
template< class T, class Alloc> 
# 50
contiguous_storage< T, Alloc> ::contiguous_storage(size_type n, const Alloc &alloc) : m_allocator(alloc), m_begin((pointer)(static_cast< T *>(0))), m_size(0) 
# 54
{ 
# 55
allocate(n); 
# 56
} 
# 59
template< class T, class Alloc> 
# 62
contiguous_storage< T, Alloc> ::~contiguous_storage() 
# 63
{ 
# 64
deallocate(); 
# 65
} 
# 67
template< class T, class Alloc> typename contiguous_storage< T, Alloc> ::size_type 
# 71
contiguous_storage< T, Alloc> ::size() const 
# 72
{ 
# 73
return m_size; 
# 74
} 
# 76
template< class T, class Alloc> typename contiguous_storage< T, Alloc> ::size_type 
# 80
contiguous_storage< T, Alloc> ::max_size() const 
# 81
{ 
# 82
return alloc_traits::max_size(m_allocator); 
# 83
} 
# 85
template< class T, class Alloc> typename contiguous_storage< T, Alloc> ::iterator 
# 89
contiguous_storage< T, Alloc> ::begin() 
# 90
{ 
# 91
return m_begin; 
# 92
} 
# 94
template< class T, class Alloc> typename contiguous_storage< T, Alloc> ::const_iterator 
# 98
contiguous_storage< T, Alloc> ::begin() const 
# 99
{ 
# 100
return m_begin; 
# 101
} 
# 103
template< class T, class Alloc> typename contiguous_storage< T, Alloc> ::iterator 
# 107
contiguous_storage< T, Alloc> ::end() 
# 108
{ 
# 109
return (m_begin) + size(); 
# 110
} 
# 112
template< class T, class Alloc> typename contiguous_storage< T, Alloc> ::const_iterator 
# 116
contiguous_storage< T, Alloc> ::end() const 
# 117
{ 
# 118
return (m_begin) + size(); 
# 119
} 
# 121
template< class T, class Alloc> typename contiguous_storage< T, Alloc> ::reference 
# 125
contiguous_storage< T, Alloc> ::operator[](size_type n) 
# 126
{ 
# 127
return (m_begin)[n]; 
# 128
} 
# 130
template< class T, class Alloc> typename contiguous_storage< T, Alloc> ::const_reference 
# 134
contiguous_storage< T, Alloc> ::operator[](size_type n) const 
# 135
{ 
# 136
return (m_begin)[n]; 
# 137
} 
# 139
template< class T, class Alloc> typename contiguous_storage< T, Alloc> ::allocator_type 
# 143
contiguous_storage< T, Alloc> ::get_allocator() const 
# 144
{ 
# 145
return m_allocator; 
# 146
} 
# 148
template< class T, class Alloc> void 
# 151
contiguous_storage< T, Alloc> ::allocate(size_type n) 
# 152
{ 
# 153
if (n > 0) 
# 154
{ 
# 155
(m_begin) = ((iterator)(alloc_traits::allocate(m_allocator, n))); 
# 156
(m_size) = n; 
# 157
} else 
# 159
{ 
# 160
(m_begin) = ((iterator)((pointer)(static_cast< T *>(0)))); 
# 161
(m_size) = 0; 
# 162
}  
# 163
} 
# 165
template< class T, class Alloc> void 
# 168
contiguous_storage< T, Alloc> ::deallocate() 
# 169
{ 
# 170
if (size() > 0) 
# 171
{ 
# 172
alloc_traits::deallocate(m_allocator, ((m_begin).base()), size()); 
# 173
(m_begin) = ((iterator)((pointer)(static_cast< T *>(0)))); 
# 174
(m_size) = 0; 
# 175
}  
# 176
} 
# 178
template< class T, class Alloc> void 
# 181
contiguous_storage< T, Alloc> ::swap(contiguous_storage &x) 
# 182
{ 
# 183
thrust::swap(m_begin, x.m_begin); 
# 184
thrust::swap(m_size, x.m_size); 
# 186
thrust::swap(m_allocator, x.m_allocator); 
# 187
} 
# 189
template< class T, class Alloc> void 
# 192
contiguous_storage< T, Alloc> ::default_construct_n(iterator first, size_type n) 
# 193
{ 
# 194
default_construct_range(m_allocator, (first.base()), n); 
# 195
} 
# 197
template< class T, class Alloc> void 
# 200
contiguous_storage< T, Alloc> ::uninitialized_fill_n(iterator first, size_type n, const value_type &x) 
# 201
{ 
# 202
fill_construct_range(m_allocator, (first.base()), n, x); 
# 203
} 
# 205
template< class T, class Alloc> 
# 206
template< class System, class InputIterator> typename contiguous_storage< T, Alloc> ::iterator 
# 210
contiguous_storage< T, Alloc> ::uninitialized_copy(execution_policy< System>  &from_system, InputIterator first, InputIterator last, iterator result) 
# 211
{ 
# 212
return ((iterator)(copy_construct_range(from_system, m_allocator, first, last, (result.base())))); 
# 213
} 
# 215
template< class T, class Alloc> 
# 216
template< class InputIterator> typename contiguous_storage< T, Alloc> ::iterator 
# 220
contiguous_storage< T, Alloc> ::uninitialized_copy(InputIterator first, InputIterator last, iterator result) 
# 221
{ 
# 223
typename iterator_system< InputIterator> ::type from_system; 
# 225
return ((iterator)(copy_construct_range(from_system, m_allocator, first, last, (result.base())))); 
# 226
} 
# 228
template< class T, class Alloc> 
# 229
template< class System, class InputIterator, class Size> typename contiguous_storage< T, Alloc> ::iterator 
# 233
contiguous_storage< T, Alloc> ::uninitialized_copy_n(execution_policy< System>  &from_system, InputIterator first, Size n, iterator result) 
# 234
{ 
# 235
return ((iterator)(copy_construct_range_n(from_system, m_allocator, first, n, (result.base())))); 
# 236
} 
# 238
template< class T, class Alloc> 
# 239
template< class InputIterator, class Size> typename contiguous_storage< T, Alloc> ::iterator 
# 243
contiguous_storage< T, Alloc> ::uninitialized_copy_n(InputIterator first, Size n, iterator result) 
# 244
{ 
# 246
typename iterator_system< InputIterator> ::type from_system; 
# 248
return ((iterator)(copy_construct_range_n(from_system, m_allocator, first, n, (result.base())))); 
# 249
} 
# 251
template< class T, class Alloc> void 
# 254
contiguous_storage< T, Alloc> ::destroy(iterator first, iterator last) 
# 255
{ 
# 256
destroy_range(m_allocator, (first.base()), last - first); 
# 257
} 
# 259
}
# 261
template< class T, class Alloc> void 
# 263
swap(detail::contiguous_storage< T, Alloc>  &lhs, detail::contiguous_storage< T, Alloc>  &rhs) 
# 264
{ 
# 265
(lhs.swap(rhs)); 
# 266
} 
# 268
}
# 66 "/usr/include/c++/4.8.2/bits/stl_vector.h" 3
namespace std __attribute((__visibility__("default"))) { 
# 71
template< class _Tp, class _Alloc> 
# 72
struct _Vector_base { 
# 75
typedef typename __gnu_cxx::__alloc_traits< _Alloc> ::template rebind< _Tp> ::other _Tp_alloc_type; 
# 77
typedef typename __gnu_cxx::__alloc_traits< typename __gnu_cxx::__alloc_traits< _Alloc> ::template rebind< _Tp> ::other> ::pointer pointer; 
# 79
struct _Vector_impl : public _Tp_alloc_type { 
# 82
typename ::std::_Vector_base< _Tp, _Alloc> ::pointer _M_start; 
# 83
typename ::std::_Vector_base< _Tp, _Alloc> ::pointer _M_finish; 
# 84
typename ::std::_Vector_base< _Tp, _Alloc> ::pointer _M_end_of_storage; 
# 86
_Vector_impl() : ::std::_Vector_base< _Tp, _Alloc> ::_Tp_alloc_type(), _M_start(0), _M_finish(0), _M_end_of_storage(0) 
# 88
{ } 
# 90
_Vector_impl(const typename ::std::_Vector_base< _Tp, _Alloc> ::_Tp_alloc_type &__a) : ::std::_Vector_base< _Tp, _Alloc> ::_Tp_alloc_type(__a), _M_start(0), _M_finish(0), _M_end_of_storage(0) 
# 92
{ } 
# 101
void _M_swap_data(_Vector_impl &__x) 
# 102
{ 
# 103
::std::swap(_M_start, __x._M_start); 
# 104
::std::swap(_M_finish, __x._M_finish); 
# 105
::std::swap(_M_end_of_storage, __x._M_end_of_storage); 
# 106
} 
# 107
}; 
# 110
typedef _Alloc allocator_type; 
# 113
_Tp_alloc_type &_M_get_Tp_allocator() 
# 114
{ return *(static_cast< _Tp_alloc_type *>(&(this->_M_impl))); } 
# 117
const _Tp_alloc_type &_M_get_Tp_allocator() const 
# 118
{ return *(static_cast< const _Tp_alloc_type *>(&(this->_M_impl))); } 
# 121
allocator_type get_allocator() const 
# 122
{ return (allocator_type)this->_M_get_Tp_allocator(); } 
# 124
_Vector_base() : _M_impl() 
# 125
{ } 
# 127
_Vector_base(const allocator_type &__a) : _M_impl(__a) 
# 128
{ } 
# 130
_Vector_base(size_t __n) : _M_impl() 
# 132
{ _M_create_storage(__n); } 
# 134
_Vector_base(size_t __n, const allocator_type &__a) : _M_impl(__a) 
# 136
{ _M_create_storage(__n); } 
# 159
~_Vector_base() 
# 160
{ _M_deallocate(((this->_M_impl)._M_start), ((this->_M_impl)._M_end_of_storage) - ((this->_M_impl)._M_start)); 
# 161
} 
# 164
_Vector_impl _M_impl; 
# 167
pointer _M_allocate(size_t __n) 
# 168
{ return (__n != (0)) ? ((_M_impl).allocate(__n)) : 0; } 
# 171
void _M_deallocate(pointer __p, size_t __n) 
# 172
{ 
# 173
if (__p) { 
# 174
((_M_impl).deallocate(__p, __n)); }  
# 175
} 
# 179
private: void _M_create_storage(size_t __n) 
# 180
{ 
# 181
((this->_M_impl)._M_start) = this->_M_allocate(__n); 
# 182
((this->_M_impl)._M_finish) = ((this->_M_impl)._M_start); 
# 183
((this->_M_impl)._M_end_of_storage) = (((this->_M_impl)._M_start) + __n); 
# 184
} 
# 185
}; 
# 209
template< class _Tp, class _Alloc = allocator< _Tp> > 
# 210
class vector : protected _Vector_base< _Tp, _Alloc>  { 
# 213
typedef typename _Alloc::value_type _Alloc_value_type; 
# 217
typedef ::std::_Vector_base< _Tp, _Alloc>  _Base; 
# 218
typedef typename ::std::_Vector_base< _Tp, _Alloc> ::_Tp_alloc_type _Tp_alloc_type; 
# 219
typedef ::__gnu_cxx::__alloc_traits< typename ::std::_Vector_base< _Tp, _Alloc> ::_Tp_alloc_type>  _Alloc_traits; 
# 222
public: typedef _Tp value_type; 
# 223
typedef typename ::std::_Vector_base< _Tp, _Alloc> ::pointer pointer; 
# 224
typedef typename ::__gnu_cxx::__alloc_traits< typename ::std::_Vector_base< _Tp, _Alloc> ::_Tp_alloc_type> ::const_pointer const_pointer; 
# 225
typedef typename ::__gnu_cxx::__alloc_traits< typename ::std::_Vector_base< _Tp, _Alloc> ::_Tp_alloc_type> ::reference reference; 
# 226
typedef typename ::__gnu_cxx::__alloc_traits< typename ::std::_Vector_base< _Tp, _Alloc> ::_Tp_alloc_type> ::const_reference const_reference; 
# 227
typedef ::__gnu_cxx::__normal_iterator< typename ::std::_Vector_base< _Tp, _Alloc> ::pointer, vector>  iterator; 
# 229
typedef ::__gnu_cxx::__normal_iterator< typename ::__gnu_cxx::__alloc_traits< typename ::std::_Vector_base< _Tp, _Alloc> ::_Tp_alloc_type> ::const_pointer, vector>  const_iterator; 
# 230
typedef ::std::reverse_iterator< ::__gnu_cxx::__normal_iterator< typename ::__gnu_cxx::__alloc_traits< typename ::std::_Vector_base< _Tp, _Alloc> ::_Tp_alloc_type> ::const_pointer, vector> >  const_reverse_iterator; 
# 231
typedef ::std::reverse_iterator< ::__gnu_cxx::__normal_iterator< typename ::std::_Vector_base< _Tp, _Alloc> ::pointer, vector> >  reverse_iterator; 
# 232
typedef ::std::size_t size_type; 
# 233
typedef ::std::ptrdiff_t difference_type; 
# 234
typedef _Alloc allocator_type; 
# 237
protected: using ::std::_Vector_base< _Tp, _Alloc> ::_M_allocate;
# 238
using ::std::_Vector_base< _Tp, _Alloc> ::_M_deallocate;
# 239
using ::std::_Vector_base< _Tp, _Alloc> ::_M_impl;
# 240
using ::std::_Vector_base< _Tp, _Alloc> ::_M_get_Tp_allocator;
# 248
public: vector() : _Base() 
# 249
{ } 
# 256
explicit vector(const allocator_type &__a) : _Base(__a) 
# 257
{ } 
# 295
explicit vector(size_type __n, const value_type &__value = value_type(), const allocator_type &
# 296
__a = allocator_type()) : _Base(__n, __a) 
# 298
{ _M_fill_initialize(__n, __value); } 
# 310
vector(const vector &__x) : _Base(__x.size(), _Alloc_traits::_S_select_on_copy((__x._M_get_Tp_allocator()))) 
# 313
{ ((this->_M_impl)._M_finish) = ::std::__uninitialized_copy_a(__x.begin(), __x.end(), ((this->_M_impl)._M_start), _M_get_Tp_allocator()); 
# 317
} 
# 397
template< class _InputIterator> 
# 398
vector(_InputIterator __first, _InputIterator __last, const allocator_type &
# 399
__a = allocator_type()) : _Base(__a) 
# 401
{ 
# 403
typedef typename __is_integer< _InputIterator> ::__type _Integral; 
# 404
_M_initialize_dispatch(__first, __last, _Integral()); 
# 405
} 
# 414
~vector() 
# 415
{ ::std::_Destroy(((this->_M_impl)._M_start), ((this->_M_impl)._M_finish), _M_get_Tp_allocator()); 
# 416
} 
# 427
vector &operator=(const vector & __x); 
# 479
void assign(size_type __n, const value_type &__val) 
# 480
{ _M_fill_assign(__n, __val); } 
# 501
template< class _InputIterator> void 
# 503
assign(_InputIterator __first, _InputIterator __last) 
# 504
{ 
# 506
typedef typename __is_integer< _InputIterator> ::__type _Integral; 
# 507
_M_assign_dispatch(__first, __last, _Integral()); 
# 508
} 
# 529
using ::std::_Vector_base< _Tp, _Alloc> ::get_allocator;
# 538
iterator begin() 
# 539
{ return ((iterator)(((this->_M_impl)._M_start))); } 
# 547
const_iterator begin() const 
# 548
{ return ((const_iterator)(((this->_M_impl)._M_start))); } 
# 556
iterator end() 
# 557
{ return ((iterator)(((this->_M_impl)._M_finish))); } 
# 565
const_iterator end() const 
# 566
{ return ((const_iterator)(((this->_M_impl)._M_finish))); } 
# 574
reverse_iterator rbegin() 
# 575
{ return ((reverse_iterator)(this->end())); } 
# 583
const_reverse_iterator rbegin() const 
# 584
{ return ((const_reverse_iterator)(this->end())); } 
# 592
reverse_iterator rend() 
# 593
{ return ((reverse_iterator)(this->begin())); } 
# 601
const_reverse_iterator rend() const 
# 602
{ return ((const_reverse_iterator)(this->begin())); } 
# 645
size_type size() const 
# 646
{ return (size_type)(((this->_M_impl)._M_finish) - ((this->_M_impl)._M_start)); } 
# 650
size_type max_size() const 
# 651
{ return _Alloc_traits::max_size(_M_get_Tp_allocator()); } 
# 704
void resize(size_type __new_size, value_type __x = value_type()) 
# 705
{ 
# 706
if (__new_size > size()) { 
# 707
insert(this->end(), __new_size - size(), __x); } else { 
# 708
if (__new_size < size()) { 
# 709
_M_erase_at_end(((this->_M_impl)._M_start) + __new_size); }  }  
# 710
} 
# 725
size_type capacity() const 
# 726
{ return (size_type)(((this->_M_impl)._M_end_of_storage) - ((this->_M_impl)._M_start)); 
# 727
} 
# 734
bool empty() const 
# 735
{ return this->begin() == this->end(); } 
# 755
void reserve(size_type __n); 
# 770
reference operator[](size_type __n) 
# 771
{ return *(((this->_M_impl)._M_start) + __n); } 
# 785
const_reference operator[](size_type __n) const 
# 786
{ return *(((this->_M_impl)._M_start) + __n); } 
# 791
protected: void _M_range_check(size_type __n) const 
# 792
{ 
# 793
if (__n >= this->size()) { 
# 794
__throw_out_of_range("vector::_M_range_check"); }  
# 795
} 
# 810
public: reference at(size_type __n) 
# 811
{ 
# 812
_M_range_check(__n); 
# 813
return (*this)[__n]; 
# 814
} 
# 828
const_reference at(size_type __n) const 
# 829
{ 
# 830
_M_range_check(__n); 
# 831
return (*this)[__n]; 
# 832
} 
# 839
reference front() 
# 840
{ return *this->begin(); } 
# 847
const_reference front() const 
# 848
{ return *this->begin(); } 
# 855
reference back() 
# 856
{ return *(this->end() - 1); } 
# 863
const_reference back() const 
# 864
{ return *(this->end() - 1); } 
# 878
pointer data() 
# 879
{ return ::std::__addressof(this->front()); } 
# 886
const_pointer data() const 
# 887
{ return ::std::__addressof(this->front()); } 
# 901
void push_back(const value_type &__x) 
# 902
{ 
# 903
if (((this->_M_impl)._M_finish) != ((this->_M_impl)._M_end_of_storage)) 
# 904
{ 
# 905
_Alloc_traits::construct((this->_M_impl), ((this->_M_impl)._M_finish), __x); 
# 907
++((this->_M_impl)._M_finish); 
# 908
} else { 
# 913
_M_insert_aux(this->end(), __x); }  
# 915
} 
# 937
void pop_back() 
# 938
{ 
# 939
--((this->_M_impl)._M_finish); 
# 940
_Alloc_traits::destroy((this->_M_impl), ((this->_M_impl)._M_finish)); 
# 941
} 
# 973
iterator insert(iterator __position, const value_type & __x); 
# 1023
void insert(iterator __position, size_type __n, const value_type &__x) 
# 1024
{ _M_fill_insert(__position, __n, __x); } 
# 1048
template< class _InputIterator> void 
# 1050
insert(iterator __position, _InputIterator __first, _InputIterator 
# 1051
__last) 
# 1052
{ 
# 1054
typedef typename __is_integer< _InputIterator> ::__type _Integral; 
# 1055
_M_insert_dispatch(__position, __first, __last, _Integral()); 
# 1056
} 
# 1075
iterator erase(iterator __position); 
# 1096
iterator erase(iterator __first, iterator __last); 
# 1108
void swap(vector &__x) 
# 1112
{ 
# 1113
((this->_M_impl)._M_swap_data((__x._M_impl))); 
# 1114
_Alloc_traits::_S_on_swap(_M_get_Tp_allocator(), (__x._M_get_Tp_allocator())); 
# 1116
} 
# 1125
void clear() 
# 1126
{ _M_erase_at_end(((this->_M_impl)._M_start)); } 
# 1135
protected: 
# 1133
template< class _ForwardIterator> pointer 
# 1135
_M_allocate_and_copy(size_type __n, _ForwardIterator 
# 1136
__first, _ForwardIterator __last) 
# 1137
{ 
# 1138
pointer __result = (this->_M_allocate(__n)); 
# 1139
try 
# 1140
{ 
# 1141
::std::__uninitialized_copy_a(__first, __last, __result, _M_get_Tp_allocator()); 
# 1143
return __result; 
# 1144
} 
# 1145
catch (...) 
# 1146
{ 
# 1147
_M_deallocate(__result, __n); 
# 1148
throw; 
# 1149
}  
# 1150
} 
# 1159
template< class _Integer> void 
# 1161
_M_initialize_dispatch(_Integer __n, _Integer __value, ::std::__true_type) 
# 1162
{ 
# 1163
((this->_M_impl)._M_start) = _M_allocate(static_cast< size_type>(__n)); 
# 1164
((this->_M_impl)._M_end_of_storage) = (((this->_M_impl)._M_start) + (static_cast< size_type>(__n))); 
# 1166
_M_fill_initialize(static_cast< size_type>(__n), __value); 
# 1167
} 
# 1170
template< class _InputIterator> void 
# 1172
_M_initialize_dispatch(_InputIterator __first, _InputIterator __last, ::std::__false_type) 
# 1174
{ 
# 1176
typedef typename iterator_traits< _InputIterator> ::iterator_category _IterCategory; 
# 1177
_M_range_initialize(__first, __last, _IterCategory()); 
# 1178
} 
# 1181
template< class _InputIterator> void 
# 1183
_M_range_initialize(_InputIterator __first, _InputIterator 
# 1184
__last, ::std::input_iterator_tag) 
# 1185
{ 
# 1186
for (; __first != __last; ++__first) { 
# 1190
push_back(*__first); }  
# 1192
} 
# 1195
template< class _ForwardIterator> void 
# 1197
_M_range_initialize(_ForwardIterator __first, _ForwardIterator 
# 1198
__last, ::std::forward_iterator_tag) 
# 1199
{ 
# 1200
const size_type __n = ::std::distance(__first, __last); 
# 1201
((this->_M_impl)._M_start) = (this->_M_allocate(__n)); 
# 1202
((this->_M_impl)._M_end_of_storage) = (((this->_M_impl)._M_start) + __n); 
# 1203
((this->_M_impl)._M_finish) = ::std::__uninitialized_copy_a(__first, __last, ((this->_M_impl)._M_start), _M_get_Tp_allocator()); 
# 1207
} 
# 1212
void _M_fill_initialize(size_type __n, const value_type &__value) 
# 1213
{ 
# 1214
::std::__uninitialized_fill_n_a(((this->_M_impl)._M_start), __n, __value, _M_get_Tp_allocator()); 
# 1216
((this->_M_impl)._M_finish) = ((this->_M_impl)._M_end_of_storage); 
# 1217
} 
# 1237
template< class _Integer> void 
# 1239
_M_assign_dispatch(_Integer __n, _Integer __val, ::std::__true_type) 
# 1240
{ _M_fill_assign(__n, __val); } 
# 1243
template< class _InputIterator> void 
# 1245
_M_assign_dispatch(_InputIterator __first, _InputIterator __last, ::std::__false_type) 
# 1247
{ 
# 1249
typedef typename iterator_traits< _InputIterator> ::iterator_category _IterCategory; 
# 1250
_M_assign_aux(__first, __last, _IterCategory()); 
# 1251
} 
# 1254
template< class _InputIterator> void _M_assign_aux(_InputIterator __first, _InputIterator __last, ::std::input_iterator_tag); 
# 1260
template< class _ForwardIterator> void _M_assign_aux(_ForwardIterator __first, _ForwardIterator __last, ::std::forward_iterator_tag); 
# 1268
void _M_fill_assign(size_type __n, const value_type & __val); 
# 1277
template< class _Integer> void 
# 1279
_M_insert_dispatch(iterator __pos, _Integer __n, _Integer __val, ::std::__true_type) 
# 1281
{ _M_fill_insert(__pos, __n, __val); } 
# 1284
template< class _InputIterator> void 
# 1286
_M_insert_dispatch(iterator __pos, _InputIterator __first, _InputIterator 
# 1287
__last, ::std::__false_type) 
# 1288
{ 
# 1290
typedef typename iterator_traits< _InputIterator> ::iterator_category _IterCategory; 
# 1291
_M_range_insert(__pos, __first, __last, _IterCategory()); 
# 1292
} 
# 1295
template< class _InputIterator> void _M_range_insert(iterator __pos, _InputIterator __first, _InputIterator __last, ::std::input_iterator_tag); 
# 1301
template< class _ForwardIterator> void _M_range_insert(iterator __pos, _ForwardIterator __first, _ForwardIterator __last, ::std::forward_iterator_tag); 
# 1309
void _M_fill_insert(iterator __pos, size_type __n, const value_type & __x); 
# 1323
void _M_insert_aux(iterator __position, const value_type & __x); 
# 1336
size_type _M_check_len(size_type __n, const char *__s) const 
# 1337
{ 
# 1338
if ((max_size() - size()) < __n) { 
# 1339
__throw_length_error(__s); }  
# 1341
const size_type __len = size() + ::std::max(size(), __n); 
# 1342
return ((__len < size()) || (__len > max_size())) ? max_size() : __len; 
# 1343
} 
# 1350
void _M_erase_at_end(pointer __pos) 
# 1351
{ 
# 1352
::std::_Destroy(__pos, ((this->_M_impl)._M_finish), _M_get_Tp_allocator()); 
# 1353
((this->_M_impl)._M_finish) = __pos; 
# 1354
} 
# 1389
}; 
# 1402
template< class _Tp, class _Alloc> inline bool 
# 1404
operator==(const vector< _Tp, _Alloc>  &__x, const vector< _Tp, _Alloc>  &__y) 
# 1405
{ return ((__x.size()) == (__y.size())) && std::equal((__x.begin()), (__x.end()), (__y.begin())); 
# 1406
} 
# 1419
template< class _Tp, class _Alloc> inline bool 
# 1421
operator<(const vector< _Tp, _Alloc>  &__x, const vector< _Tp, _Alloc>  &__y) 
# 1422
{ return std::lexicographical_compare((__x.begin()), (__x.end()), (__y.begin()), (__y.end())); 
# 1423
} 
# 1426
template< class _Tp, class _Alloc> inline bool 
# 1428
operator!=(const vector< _Tp, _Alloc>  &__x, const vector< _Tp, _Alloc>  &__y) 
# 1429
{ return !(__x == __y); } 
# 1432
template< class _Tp, class _Alloc> inline bool 
# 1434
operator>(const vector< _Tp, _Alloc>  &__x, const vector< _Tp, _Alloc>  &__y) 
# 1435
{ return __y < __x; } 
# 1438
template< class _Tp, class _Alloc> inline bool 
# 1440
operator<=(const vector< _Tp, _Alloc>  &__x, const vector< _Tp, _Alloc>  &__y) 
# 1441
{ return !(__y < __x); } 
# 1444
template< class _Tp, class _Alloc> inline bool 
# 1446
operator>=(const vector< _Tp, _Alloc>  &__x, const vector< _Tp, _Alloc>  &__y) 
# 1447
{ return !(__x < __y); } 
# 1450
template< class _Tp, class _Alloc> inline void 
# 1452
swap(vector< _Tp, _Alloc>  &__x, vector< _Tp, _Alloc>  &__y) 
# 1453
{ (__x.swap(__y)); } 
# 1456
}
# 63 "/usr/include/c++/4.8.2/bits/stl_bvector.h" 3
namespace std __attribute((__visibility__("default"))) { 
# 67
typedef unsigned long _Bit_type; 
# 68
enum { _S_word_bit = 64}; 
# 70
struct _Bit_reference { 
# 72
_Bit_type *_M_p; 
# 73
_Bit_type _M_mask; 
# 75
_Bit_reference(_Bit_type *__x, _Bit_type __y) : _M_p(__x), _M_mask(__y) 
# 76
{ } 
# 78
_Bit_reference() : _M_p((0)), _M_mask((0)) { } 
# 80
operator bool() const 
# 81
{ return !(!((*(_M_p)) & (_M_mask))); } 
# 84
_Bit_reference &operator=(bool __x) 
# 85
{ 
# 86
if (__x) { 
# 87
(*(_M_p)) |= (_M_mask); } else { 
# 89
(*(_M_p)) &= (~(_M_mask)); }  
# 90
return *this; 
# 91
} 
# 94
_Bit_reference &operator=(const _Bit_reference &__x) 
# 95
{ return ((*this) = ((bool)__x)); } 
# 98
bool operator==(const _Bit_reference &__x) const 
# 99
{ return ((bool)(*this)) == ((bool)__x); } 
# 102
bool operator<(const _Bit_reference &__x) const 
# 103
{ return (!((bool)(*this))) && ((bool)__x); } 
# 106
void flip() 
# 107
{ (*(_M_p)) ^= (_M_mask); } 
# 108
}; 
# 136
struct _Bit_iterator_base : public iterator< random_access_iterator_tag, bool>  { 
# 139
_Bit_type *_M_p; 
# 140
unsigned _M_offset; 
# 142
_Bit_iterator_base(_Bit_type *__x, unsigned __y) : _M_p(__x), _M_offset(__y) 
# 143
{ } 
# 146
void _M_bump_up() 
# 147
{ 
# 148
if (((_M_offset)++) == (((int)_S_word_bit) - 1)) 
# 149
{ 
# 150
(_M_offset) = (0); 
# 151
++(_M_p); 
# 152
}  
# 153
} 
# 156
void _M_bump_down() 
# 157
{ 
# 158
if (((_M_offset)--) == (0)) 
# 159
{ 
# 160
(_M_offset) = (((int)_S_word_bit) - 1); 
# 161
--(_M_p); 
# 162
}  
# 163
} 
# 166
void _M_incr(ptrdiff_t __i) 
# 167
{ 
# 168
difference_type __n = __i + (_M_offset); 
# 169
(_M_p) += (__n / ((int)_S_word_bit)); 
# 170
__n = (__n % ((int)_S_word_bit)); 
# 171
if (__n < (0)) 
# 172
{ 
# 173
__n += ((int)_S_word_bit); 
# 174
--(_M_p); 
# 175
}  
# 176
(_M_offset) = (static_cast< unsigned>(__n)); 
# 177
} 
# 180
bool operator==(const _Bit_iterator_base &__i) const 
# 181
{ return ((_M_p) == (__i._M_p)) && ((_M_offset) == (__i._M_offset)); } 
# 184
bool operator<(const _Bit_iterator_base &__i) const 
# 185
{ 
# 186
return ((_M_p) < (__i._M_p)) || (((_M_p) == (__i._M_p)) && ((_M_offset) < (__i._M_offset))); 
# 188
} 
# 191
bool operator!=(const _Bit_iterator_base &__i) const 
# 192
{ return !((*this) == __i); } 
# 195
bool operator>(const _Bit_iterator_base &__i) const 
# 196
{ return (__i < (*this)); } 
# 199
bool operator<=(const _Bit_iterator_base &__i) const 
# 200
{ return !(__i < (*this)); } 
# 203
bool operator>=(const _Bit_iterator_base &__i) const 
# 204
{ return !((*this) < __i); } 
# 205
}; 
# 208
inline ptrdiff_t operator-(const _Bit_iterator_base &__x, const _Bit_iterator_base &__y) 
# 209
{ 
# 210
return ((((int)_S_word_bit) * ((__x._M_p) - (__y._M_p))) + (__x._M_offset)) - (__y._M_offset); 
# 212
} 
# 214
struct _Bit_iterator : public _Bit_iterator_base { 
# 216
typedef _Bit_reference reference; 
# 217
typedef _Bit_reference *pointer; 
# 218
typedef _Bit_iterator iterator; 
# 220
_Bit_iterator() : _Bit_iterator_base(0, 0) { } 
# 222
_Bit_iterator(_Bit_type *__x, unsigned __y) : _Bit_iterator_base(__x, __y) 
# 223
{ } 
# 226
reference operator*() const 
# 227
{ return reference(_M_p, 1UL << (_M_offset)); } 
# 230
iterator &operator++() 
# 231
{ 
# 232
this->_M_bump_up(); 
# 233
return *this; 
# 234
} 
# 237
iterator operator++(int) 
# 238
{ 
# 239
iterator __tmp = *this; 
# 240
this->_M_bump_up(); 
# 241
return __tmp; 
# 242
} 
# 245
iterator &operator--() 
# 246
{ 
# 247
this->_M_bump_down(); 
# 248
return *this; 
# 249
} 
# 252
iterator operator--(int) 
# 253
{ 
# 254
iterator __tmp = *this; 
# 255
this->_M_bump_down(); 
# 256
return __tmp; 
# 257
} 
# 260
iterator &operator+=(difference_type __i) 
# 261
{ 
# 262
this->_M_incr(__i); 
# 263
return *this; 
# 264
} 
# 267
iterator &operator-=(difference_type __i) 
# 268
{ 
# 269
((*this) += (-__i)); 
# 270
return *this; 
# 271
} 
# 274
iterator operator+(difference_type __i) const 
# 275
{ 
# 276
iterator __tmp = *this; 
# 277
return (__tmp += __i); 
# 278
} 
# 281
iterator operator-(difference_type __i) const 
# 282
{ 
# 283
iterator __tmp = *this; 
# 284
return (__tmp -= __i); 
# 285
} 
# 288
reference operator[](difference_type __i) const 
# 289
{ return (*(((*this) + __i))); } 
# 290
}; 
# 293
inline _Bit_iterator operator+(ptrdiff_t __n, const _Bit_iterator &__x) 
# 294
{ return (__x + __n); } 
# 296
struct _Bit_const_iterator : public _Bit_iterator_base { 
# 298
typedef bool reference; 
# 299
typedef bool const_reference; 
# 300
typedef const bool *pointer; 
# 301
typedef _Bit_const_iterator const_iterator; 
# 303
_Bit_const_iterator() : _Bit_iterator_base(0, 0) { } 
# 305
_Bit_const_iterator(_Bit_type *__x, unsigned __y) : _Bit_iterator_base(__x, __y) 
# 306
{ } 
# 308
_Bit_const_iterator(const _Bit_iterator &__x) : _Bit_iterator_base(__x._M_p, __x._M_offset) 
# 309
{ } 
# 312
const_reference operator*() const 
# 313
{ return _Bit_reference(_M_p, 1UL << (_M_offset)); } 
# 316
const_iterator &operator++() 
# 317
{ 
# 318
this->_M_bump_up(); 
# 319
return *this; 
# 320
} 
# 323
const_iterator operator++(int) 
# 324
{ 
# 325
const_iterator __tmp = *this; 
# 326
this->_M_bump_up(); 
# 327
return __tmp; 
# 328
} 
# 331
const_iterator &operator--() 
# 332
{ 
# 333
this->_M_bump_down(); 
# 334
return *this; 
# 335
} 
# 338
const_iterator operator--(int) 
# 339
{ 
# 340
const_iterator __tmp = *this; 
# 341
this->_M_bump_down(); 
# 342
return __tmp; 
# 343
} 
# 346
const_iterator &operator+=(difference_type __i) 
# 347
{ 
# 348
this->_M_incr(__i); 
# 349
return *this; 
# 350
} 
# 353
const_iterator &operator-=(difference_type __i) 
# 354
{ 
# 355
((*this) += (-__i)); 
# 356
return *this; 
# 357
} 
# 360
const_iterator operator+(difference_type __i) const 
# 361
{ 
# 362
const_iterator __tmp = *this; 
# 363
return (__tmp += __i); 
# 364
} 
# 367
const_iterator operator-(difference_type __i) const 
# 368
{ 
# 369
const_iterator __tmp = *this; 
# 370
return (__tmp -= __i); 
# 371
} 
# 374
const_reference operator[](difference_type __i) const 
# 375
{ return (*(((*this) + __i))); } 
# 376
}; 
# 379
inline _Bit_const_iterator operator+(ptrdiff_t __n, const _Bit_const_iterator &__x) 
# 380
{ return (__x + __n); } 
# 383
inline void __fill_bvector(_Bit_iterator __first, _Bit_iterator __last, bool __x) 
# 384
{ 
# 385
for (; (__first != __last); (++__first)) { 
# 386
(((*__first)) = __x); }  
# 387
} 
# 390
inline void fill(_Bit_iterator __first, _Bit_iterator __last, const bool &__x) 
# 391
{ 
# 392
if ((__first._M_p) != (__last._M_p)) 
# 393
{ 
# 394
std::fill((__first._M_p) + 1, __last._M_p, __x ? ~0 : 0); 
# 395
__fill_bvector(__first, _Bit_iterator((__first._M_p) + 1, 0), __x); 
# 396
__fill_bvector(_Bit_iterator(__last._M_p, 0), __last, __x); 
# 397
} else { 
# 399
__fill_bvector(__first, __last, __x); }  
# 400
} 
# 402
template< class _Alloc> 
# 403
struct _Bvector_base { 
# 406
typedef typename _Alloc::template rebind< unsigned long> ::other _Bit_alloc_type; 
# 408
struct _Bvector_impl : public _Bit_alloc_type { 
# 411
::std::_Bit_iterator _M_start; 
# 412
::std::_Bit_iterator _M_finish; 
# 413
::std::_Bit_type *_M_end_of_storage; 
# 415
_Bvector_impl() : ::std::_Bvector_base< _Alloc> ::_Bit_alloc_type(), _M_start(), _M_finish(), _M_end_of_storage((0)) 
# 417
{ } 
# 419
_Bvector_impl(const typename ::std::_Bvector_base< _Alloc> ::_Bit_alloc_type &__a) : ::std::_Bvector_base< _Alloc> ::_Bit_alloc_type(__a), _M_start(), _M_finish(), _M_end_of_storage((0)) 
# 421
{ } 
# 429
}; 
# 432
typedef _Alloc allocator_type; 
# 435
_Bit_alloc_type &_M_get_Bit_allocator() 
# 436
{ return *(static_cast< _Bit_alloc_type *>(&(this->_M_impl))); } 
# 439
const _Bit_alloc_type &_M_get_Bit_allocator() const 
# 440
{ return *(static_cast< const _Bit_alloc_type *>(&(this->_M_impl))); } 
# 443
allocator_type get_allocator() const 
# 444
{ return (allocator_type)this->_M_get_Bit_allocator(); } 
# 446
_Bvector_base() : _M_impl() 
# 447
{ } 
# 449
_Bvector_base(const allocator_type &__a) : _M_impl(__a) 
# 450
{ } 
# 465
~_Bvector_base() 
# 466
{ this->_M_deallocate(); } 
# 469
protected: _Bvector_impl _M_impl; 
# 472
_Bit_type *_M_allocate(size_t __n) 
# 473
{ return ((_M_impl).allocate((_S_nword)(__n))); } 
# 476
void _M_deallocate() 
# 477
{ 
# 478
if (((_M_impl)._M_start)._M_p) { 
# 479
((_M_impl).deallocate((((_M_impl)._M_start)._M_p), ((_M_impl)._M_end_of_storage) - (((_M_impl)._M_start)._M_p))); }  
# 481
} 
# 484
static size_t _S_nword(size_t __n) 
# 485
{ return ((__n + ((int)_S_word_bit)) - (1)) / ((int)_S_word_bit); } 
# 486
}; 
# 489
}
# 494
namespace std __attribute((__visibility__("default"))) { 
# 517
template< class _Alloc> 
# 518
class vector< bool, _Alloc>  : protected _Bvector_base< _Alloc>  { 
# 520
typedef ::std::_Bvector_base< _Alloc>  _Base; 
# 527
public: typedef bool value_type; 
# 528
typedef ::std::size_t size_type; 
# 529
typedef ::std::ptrdiff_t difference_type; 
# 530
typedef ::std::_Bit_reference reference; 
# 531
typedef bool const_reference; 
# 532
typedef ::std::_Bit_reference *pointer; 
# 533
typedef const bool *const_pointer; 
# 534
typedef ::std::_Bit_iterator iterator; 
# 535
typedef ::std::_Bit_const_iterator const_iterator; 
# 536
typedef ::std::reverse_iterator< ::std::_Bit_const_iterator>  const_reverse_iterator; 
# 537
typedef ::std::reverse_iterator< ::std::_Bit_iterator>  reverse_iterator; 
# 538
typedef _Alloc allocator_type; 
# 540
allocator_type get_allocator() const 
# 541
{ return _Base::get_allocator(); } 
# 544
protected: using ::std::_Bvector_base< _Alloc> ::_M_allocate;
# 545
using ::std::_Bvector_base< _Alloc> ::_M_deallocate;
# 546
using ::std::_Bvector_base< _Alloc> ::_S_nword;
# 547
using ::std::_Bvector_base< _Alloc> ::_M_get_Bit_allocator;
# 550
public: vector() : _Base() 
# 551
{ } 
# 554
explicit vector(const allocator_type &__a) : _Base(__a) 
# 555
{ } 
# 573
explicit vector(size_type __n, const bool &__value = ((bool)0), const allocator_type &
# 574
__a = allocator_type()) : _Base(__a) 
# 576
{ 
# 577
_M_initialize(__n); 
# 578
::std::fill((((this->_M_impl)._M_start)._M_p), ((this->_M_impl)._M_end_of_storage), __value ? ~0 : 0); 
# 580
} 
# 583
vector(const ::std::vector< bool, _Alloc>  &__x) : _Base((__x._M_get_Bit_allocator())) 
# 585
{ 
# 586
_M_initialize(__x.size()); 
# 587
_M_copy_aligned(__x.begin(), __x.end(), ((this->_M_impl)._M_start)); 
# 588
} 
# 611
template< class _InputIterator> 
# 612
vector(_InputIterator __first, _InputIterator __last, const allocator_type &
# 613
__a = allocator_type()) : _Base(__a) 
# 615
{ 
# 616
typedef typename __is_integer< _InputIterator> ::__type _Integral; 
# 617
_M_initialize_dispatch(__first, __last, _Integral()); 
# 618
} 
# 621
~vector() { } 
# 624
::std::vector< bool, _Alloc>  &operator=(const ::std::vector< bool, _Alloc>  &__x) 
# 625
{ 
# 626
if ((&__x) == this) { 
# 627
return *this; }  
# 628
if (__x.size() > capacity()) 
# 629
{ 
# 630
(this->_M_deallocate()); 
# 631
_M_initialize(__x.size()); 
# 632
}  
# 633
((this->_M_impl)._M_finish) = _M_copy_aligned(__x.begin(), __x.end(), this->begin()); 
# 635
return *this; 
# 636
} 
# 662
void assign(size_type __n, const bool &__x) 
# 663
{ _M_fill_assign(__n, __x); } 
# 672
template< class _InputIterator> void 
# 674
assign(_InputIterator __first, _InputIterator __last) 
# 675
{ 
# 676
typedef typename __is_integer< _InputIterator> ::__type _Integral; 
# 677
_M_assign_dispatch(__first, __last, _Integral()); 
# 678
} 
# 688
iterator begin() 
# 689
{ return ((this->_M_impl)._M_start); } 
# 692
const_iterator begin() const 
# 693
{ return ((this->_M_impl)._M_start); } 
# 696
iterator end() 
# 697
{ return ((this->_M_impl)._M_finish); } 
# 700
const_iterator end() const 
# 701
{ return ((this->_M_impl)._M_finish); } 
# 704
reverse_iterator rbegin() 
# 705
{ return ((reverse_iterator)(this->end())); } 
# 708
const_reverse_iterator rbegin() const 
# 709
{ return ((const_reverse_iterator)(this->end())); } 
# 712
reverse_iterator rend() 
# 713
{ return ((reverse_iterator)(this->begin())); } 
# 716
const_reverse_iterator rend() const 
# 717
{ return ((const_reverse_iterator)(this->begin())); } 
# 738
size_type size() const 
# 739
{ return (size_type)(((this->end()) - (this->begin()))); } 
# 742
size_type max_size() const 
# 743
{ 
# 744
const size_type __isize = ((::__gnu_cxx::__numeric_traits_integer< long> ::__max - ((int)_S_word_bit)) + (1)); 
# 747
const size_type __asize = (_M_get_Bit_allocator().max_size()); 
# 748
return (__asize <= (__isize / ((int)_S_word_bit))) ? __asize * ((int)_S_word_bit) : __isize; 
# 750
} 
# 753
size_type capacity() const 
# 754
{ return (size_type)((const_iterator(((this->_M_impl)._M_end_of_storage), 0) - (this->begin()))); 
# 755
} 
# 758
bool empty() const 
# 759
{ return ((this->begin()) == (this->end())); } 
# 762
reference operator[](size_type __n) 
# 763
{ 
# 764
return (*iterator((((this->_M_impl)._M_start)._M_p) + (__n / ((int)_S_word_bit)), __n % ((int)_S_word_bit))); 
# 766
} 
# 769
const_reference operator[](size_type __n) const 
# 770
{ 
# 771
return (*const_iterator((((this->_M_impl)._M_start)._M_p) + (__n / ((int)_S_word_bit)), __n % ((int)_S_word_bit))); 
# 773
} 
# 777
protected: void _M_range_check(size_type __n) const 
# 778
{ 
# 779
if (__n >= this->size()) { 
# 780
__throw_out_of_range("vector<bool>::_M_range_check"); }  
# 781
} 
# 785
public: reference at(size_type __n) 
# 786
{ _M_range_check(__n); return (*this)[__n]; } 
# 789
const_reference at(size_type __n) const 
# 790
{ _M_range_check(__n); return (*this)[__n]; } 
# 793
void reserve(size_type __n) 
# 794
{ 
# 795
if (__n > max_size()) { 
# 796
__throw_length_error("vector::reserve"); }  
# 797
if (capacity() < __n) { 
# 798
_M_reallocate(__n); }  
# 799
} 
# 802
reference front() 
# 803
{ return (*(this->begin())); } 
# 806
const_reference front() const 
# 807
{ return (*(this->begin())); } 
# 810
reference back() 
# 811
{ return (*(((this->end()) - (1)))); } 
# 814
const_reference back() const 
# 815
{ return (*(((this->end()) - (1)))); } 
# 823
void data() { } 
# 826
void push_back(bool __x) 
# 827
{ 
# 828
if ((((this->_M_impl)._M_finish)._M_p) != ((this->_M_impl)._M_end_of_storage)) { 
# 829
(*(((this->_M_impl)._M_finish)++)) = __x; } else { 
# 831
_M_insert_aux(this->end(), __x); }  
# 832
} 
# 835
void swap(::std::vector< bool, _Alloc>  &__x) 
# 836
{ 
# 837
::std::swap(((this->_M_impl)._M_start), ((__x._M_impl)._M_start)); 
# 838
::std::swap(((this->_M_impl)._M_finish), ((__x._M_impl)._M_finish)); 
# 839
::std::swap(((this->_M_impl)._M_end_of_storage), ((__x._M_impl)._M_end_of_storage)); 
# 844
std::__alloc_swap< typename ::std::_Bvector_base< _Alloc> ::_Bit_alloc_type> ::_S_do_it(_M_get_Bit_allocator(), (__x._M_get_Bit_allocator())); 
# 846
} 
# 850
static void swap(reference __x, reference __y) 
# 851
{ 
# 852
bool __tmp = __x; 
# 853
(__x = __y); 
# 854
(__y = __tmp); 
# 855
} 
# 858
iterator insert(iterator __position, const bool &__x = ((bool)0)) 
# 859
{ 
# 860
const difference_type __n = (__position - (this->begin())); 
# 861
if (((((this->_M_impl)._M_finish)._M_p) != ((this->_M_impl)._M_end_of_storage)) && (__position == (this->end()))) { 
# 863
(*(((this->_M_impl)._M_finish)++)) = __x; } else { 
# 865
_M_insert_aux(__position, __x); }  
# 866
return ((this->begin()) + __n); 
# 867
} 
# 877
template< class _InputIterator> void 
# 879
insert(iterator __position, _InputIterator 
# 880
__first, _InputIterator __last) 
# 881
{ 
# 882
typedef typename __is_integer< _InputIterator> ::__type _Integral; 
# 883
_M_insert_dispatch(__position, __first, __last, _Integral()); 
# 884
} 
# 888
void insert(iterator __position, size_type __n, const bool &__x) 
# 889
{ _M_fill_insert(__position, __n, __x); } 
# 897
void pop_back() 
# 898
{ --((this->_M_impl)._M_finish); } 
# 901
iterator erase(iterator __position) 
# 902
{ 
# 903
if ((((__position + (1))) != (this->end()))) { 
# 904
::std::copy((__position + (1)), this->end(), __position); }  
# 905
--((this->_M_impl)._M_finish); 
# 906
return __position; 
# 907
} 
# 910
iterator erase(iterator __first, iterator __last) 
# 911
{ 
# 912
if ((__first != __last)) { 
# 913
_M_erase_at_end(::std::copy(__last, this->end(), __first)); }  
# 914
return __first; 
# 915
} 
# 918
void resize(size_type __new_size, bool __x = ((bool)0)) 
# 919
{ 
# 920
if (__new_size < size()) { 
# 921
_M_erase_at_end(((this->begin()) + ((difference_type)__new_size))); } else { 
# 923
insert(this->end(), __new_size - size(), __x); }  
# 924
} 
# 933
void flip() 
# 934
{ 
# 935
for (::std::_Bit_type *__p = ((((this->_M_impl)._M_start)._M_p)); __p != ((this->_M_impl)._M_end_of_storage); ++__p) { 
# 937
(*__p) = (~(*__p)); }  
# 938
} 
# 941
void clear() 
# 942
{ _M_erase_at_end(this->begin()); } 
# 948
protected: iterator _M_copy_aligned(const_iterator __first, const_iterator __last, iterator 
# 949
__result) 
# 950
{ 
# 951
::std::_Bit_type *__q = std::copy(__first._M_p, __last._M_p, __result._M_p); 
# 952
return std::copy(const_iterator(__last._M_p, 0), __last, iterator(__q, 0)); 
# 954
} 
# 957
void _M_initialize(size_type __n) 
# 958
{ 
# 959
::std::_Bit_type *__q = (this->_M_allocate(__n)); 
# 960
((this->_M_impl)._M_end_of_storage) = (__q + _S_nword(__n)); 
# 961
((this->_M_impl)._M_start) = iterator(__q, 0); 
# 962
((this->_M_impl)._M_finish) = (((this->_M_impl)._M_start) + ((difference_type)__n)); 
# 963
} 
# 966
void _M_reallocate(size_type __n); 
# 977
template< class _Integer> void 
# 979
_M_initialize_dispatch(_Integer __n, _Integer __x, ::std::__true_type) 
# 980
{ 
# 981
_M_initialize(static_cast< size_type>(__n)); 
# 982
::std::fill((((this->_M_impl)._M_start)._M_p), ((this->_M_impl)._M_end_of_storage), (__x) ? ~0 : 0); 
# 984
} 
# 986
template< class _InputIterator> void 
# 988
_M_initialize_dispatch(_InputIterator __first, _InputIterator __last, ::std::__false_type) 
# 990
{ _M_initialize_range(__first, __last, ::std::__iterator_category(__first)); 
# 991
} 
# 993
template< class _InputIterator> void 
# 995
_M_initialize_range(_InputIterator __first, _InputIterator __last, ::std::input_iterator_tag) 
# 997
{ 
# 998
for (; __first != __last; ++__first) { 
# 999
push_back(*__first); }  
# 1000
} 
# 1002
template< class _ForwardIterator> void 
# 1004
_M_initialize_range(_ForwardIterator __first, _ForwardIterator __last, ::std::forward_iterator_tag) 
# 1006
{ 
# 1007
const size_type __n = ::std::distance(__first, __last); 
# 1008
_M_initialize(__n); 
# 1009
::std::copy(__first, __last, ((this->_M_impl)._M_start)); 
# 1010
} 
# 1014
template< class _Integer> void 
# 1016
_M_assign_dispatch(_Integer __n, _Integer __val, ::std::__true_type) 
# 1017
{ _M_fill_assign(__n, __val); } 
# 1019
template< class _InputIterator> void 
# 1021
_M_assign_dispatch(_InputIterator __first, _InputIterator __last, ::std::__false_type) 
# 1023
{ _M_assign_aux(__first, __last, ::std::__iterator_category(__first)); } 
# 1026
void _M_fill_assign(::std::size_t __n, bool __x) 
# 1027
{ 
# 1028
if (__n > size()) 
# 1029
{ 
# 1030
::std::fill((((this->_M_impl)._M_start)._M_p), ((this->_M_impl)._M_end_of_storage), __x ? ~0 : 0); 
# 1032
insert(this->end(), __n - size(), __x); 
# 1033
} else 
# 1035
{ 
# 1036
_M_erase_at_end(((this->begin()) + __n)); 
# 1037
::std::fill((((this->_M_impl)._M_start)._M_p), ((this->_M_impl)._M_end_of_storage), __x ? ~0 : 0); 
# 1039
}  
# 1040
} 
# 1042
template< class _InputIterator> void 
# 1044
_M_assign_aux(_InputIterator __first, _InputIterator __last, ::std::input_iterator_tag) 
# 1046
{ 
# 1047
iterator __cur = this->begin(); 
# 1048
for (; (__first != __last) && (__cur != (this->end())); (++__cur), (++__first)) { 
# 1049
(*__cur) = (*__first); }  
# 1050
if (__first == __last) { 
# 1051
_M_erase_at_end(__cur); } else { 
# 1053
insert(this->end(), __first, __last); }  
# 1054
} 
# 1056
template< class _ForwardIterator> void 
# 1058
_M_assign_aux(_ForwardIterator __first, _ForwardIterator __last, ::std::forward_iterator_tag) 
# 1060
{ 
# 1061
const size_type __len = ::std::distance(__first, __last); 
# 1062
if (__len < size()) { 
# 1063
_M_erase_at_end(::std::copy(__first, __last, this->begin())); } else 
# 1065
{ 
# 1066
_ForwardIterator __mid = __first; 
# 1067
::std::advance(__mid, size()); 
# 1068
::std::copy(__first, __mid, this->begin()); 
# 1069
insert(this->end(), __mid, __last); 
# 1070
}  
# 1071
} 
# 1077
template< class _Integer> void 
# 1079
_M_insert_dispatch(iterator __pos, _Integer __n, _Integer __x, ::std::__true_type) 
# 1081
{ _M_fill_insert(__pos, __n, __x); } 
# 1083
template< class _InputIterator> void 
# 1085
_M_insert_dispatch(iterator __pos, _InputIterator 
# 1086
__first, _InputIterator __last, ::std::__false_type) 
# 1088
{ _M_insert_range(__pos, __first, __last, ::std::__iterator_category(__first)); 
# 1089
} 
# 1092
void _M_fill_insert(iterator __position, size_type __n, bool __x); 
# 1094
template< class _InputIterator> void 
# 1096
_M_insert_range(iterator __pos, _InputIterator __first, _InputIterator 
# 1097
__last, ::std::input_iterator_tag) 
# 1098
{ 
# 1099
for (; __first != __last; ++__first) 
# 1100
{ 
# 1101
__pos = insert(__pos, *__first); 
# 1102
(++__pos); 
# 1103
}  
# 1104
} 
# 1106
template< class _ForwardIterator> void _M_insert_range(iterator __position, _ForwardIterator __first, _ForwardIterator __last, ::std::forward_iterator_tag); 
# 1112
void _M_insert_aux(iterator __position, bool __x); 
# 1115
size_type _M_check_len(size_type __n, const char *__s) const 
# 1116
{ 
# 1117
if ((max_size() - size()) < __n) { 
# 1118
__throw_length_error(__s); }  
# 1120
const size_type __len = size() + ::std::max(size(), __n); 
# 1121
return ((__len < size()) || (__len > max_size())) ? max_size() : __len; 
# 1122
} 
# 1125
void _M_erase_at_end(iterator __pos) 
# 1126
{ ((this->_M_impl)._M_finish) = __pos; } 
# 1127
}; 
# 1130
}
# 59 "/usr/include/c++/4.8.2/bits/vector.tcc" 3
namespace std __attribute((__visibility__("default"))) { 
# 63
template< class _Tp, class _Alloc> void 
# 66
vector< _Tp, _Alloc> ::reserve(size_type __n) 
# 67
{ 
# 68
if (__n > this->max_size()) { 
# 69
__throw_length_error("vector::reserve"); }  
# 70
if (this->capacity() < __n) 
# 71
{ 
# 72
const size_type __old_size = size(); 
# 73
pointer __tmp = _M_allocate_and_copy(__n, ((this->_M_impl)._M_start), ((this->_M_impl)._M_finish)); 
# 76
::std::_Destroy(((this->_M_impl)._M_start), ((this->_M_impl)._M_finish), _M_get_Tp_allocator()); 
# 78
_M_deallocate(((this->_M_impl)._M_start), ((this->_M_impl)._M_end_of_storage) - ((this->_M_impl)._M_start)); 
# 81
((this->_M_impl)._M_start) = __tmp; 
# 82
((this->_M_impl)._M_finish) = (__tmp + __old_size); 
# 83
((this->_M_impl)._M_end_of_storage) = (((this->_M_impl)._M_start) + __n); 
# 84
}  
# 85
} 
# 105
template< class _Tp, class _Alloc> typename vector< _Tp, _Alloc> ::iterator 
# 108
vector< _Tp, _Alloc> ::insert(iterator __position, const value_type &__x) 
# 109
{ 
# 110
const size_type __n = __position - this->begin(); 
# 111
if ((((this->_M_impl)._M_finish) != ((this->_M_impl)._M_end_of_storage)) && (__position == this->end())) 
# 113
{ 
# 114
_Alloc_traits::construct((this->_M_impl), ((this->_M_impl)._M_finish), __x); 
# 115
++((this->_M_impl)._M_finish); 
# 116
} else 
# 118
{ 
# 127
_M_insert_aux(__position, __x); 
# 128
}  
# 129
return ((iterator)(((this->_M_impl)._M_start) + __n)); 
# 130
} 
# 132
template< class _Tp, class _Alloc> typename vector< _Tp, _Alloc> ::iterator 
# 135
vector< _Tp, _Alloc> ::erase(iterator __position) 
# 136
{ 
# 137
if ((__position + 1) != this->end()) { 
# 138
::std::copy(__position + 1, this->end(), __position); }  
# 139
--((this->_M_impl)._M_finish); 
# 140
_Alloc_traits::destroy((this->_M_impl), ((this->_M_impl)._M_finish)); 
# 141
return __position; 
# 142
} 
# 144
template< class _Tp, class _Alloc> typename vector< _Tp, _Alloc> ::iterator 
# 147
vector< _Tp, _Alloc> ::erase(iterator __first, iterator __last) 
# 148
{ 
# 149
if (__first != __last) 
# 150
{ 
# 151
if (__last != this->end()) { 
# 152
::std::copy(__last, this->end(), __first); }  
# 153
_M_erase_at_end((__first.base()) + (this->end() - __last)); 
# 154
}  
# 155
return __first; 
# 156
} 
# 158
template< class _Tp, class _Alloc> vector< _Tp, _Alloc>  &
# 161
vector< _Tp, _Alloc> ::operator=(const vector &__x) 
# 162
{ 
# 163
if ((&__x) != this) 
# 164
{ 
# 184
const size_type __xlen = __x.size(); 
# 185
if (__xlen > capacity()) 
# 186
{ 
# 187
pointer __tmp = _M_allocate_and_copy(__xlen, __x.begin(), __x.end()); 
# 189
::std::_Destroy(((this->_M_impl)._M_start), ((this->_M_impl)._M_finish), _M_get_Tp_allocator()); 
# 191
_M_deallocate(((this->_M_impl)._M_start), ((this->_M_impl)._M_end_of_storage) - ((this->_M_impl)._M_start)); 
# 194
((this->_M_impl)._M_start) = __tmp; 
# 195
((this->_M_impl)._M_end_of_storage) = (((this->_M_impl)._M_start) + __xlen); 
# 196
} else { 
# 197
if (size() >= __xlen) 
# 198
{ 
# 199
::std::_Destroy(::std::copy(__x.begin(), __x.end(), this->begin()), this->end(), _M_get_Tp_allocator()); 
# 201
} else 
# 203
{ 
# 204
::std::copy(((__x._M_impl)._M_start), ((__x._M_impl)._M_start) + size(), ((this->_M_impl)._M_start)); 
# 206
::std::__uninitialized_copy_a(((__x._M_impl)._M_start) + size(), ((__x._M_impl)._M_finish), ((this->_M_impl)._M_finish), _M_get_Tp_allocator()); 
# 210
}  }  
# 211
((this->_M_impl)._M_finish) = (((this->_M_impl)._M_start) + __xlen); 
# 212
}  
# 213
return *this; 
# 214
} 
# 216
template< class _Tp, class _Alloc> void 
# 219
vector< _Tp, _Alloc> ::_M_fill_assign(::std::size_t __n, const value_type &__val) 
# 220
{ 
# 221
if (__n > capacity()) 
# 222
{ 
# 223
vector __tmp(__n, __val, _M_get_Tp_allocator()); 
# 224
__tmp.swap(*this); 
# 225
} else { 
# 226
if (__n > size()) 
# 227
{ 
# 228
::std::fill(this->begin(), this->end(), __val); 
# 229
::std::__uninitialized_fill_n_a(((this->_M_impl)._M_finish), __n - size(), __val, _M_get_Tp_allocator()); 
# 232
((this->_M_impl)._M_finish) += (__n - size()); 
# 233
} else { 
# 235
_M_erase_at_end(::std::fill_n(((this->_M_impl)._M_start), __n, __val)); }  }  
# 236
} 
# 238
template< class _Tp, class _Alloc> 
# 239
template< class _InputIterator> void 
# 242
vector< _Tp, _Alloc> ::_M_assign_aux(_InputIterator __first, _InputIterator __last, ::std::input_iterator_tag) 
# 244
{ 
# 245
pointer __cur(((this->_M_impl)._M_start)); 
# 246
for (; (__first != __last) && (__cur != ((this->_M_impl)._M_finish)); (++__cur), (++__first)) { 
# 248
(*__cur) = (*__first); }  
# 249
if (__first == __last) { 
# 250
_M_erase_at_end(__cur); } else { 
# 252
insert(this->end(), __first, __last); }  
# 253
} 
# 255
template< class _Tp, class _Alloc> 
# 256
template< class _ForwardIterator> void 
# 259
vector< _Tp, _Alloc> ::_M_assign_aux(_ForwardIterator __first, _ForwardIterator __last, ::std::forward_iterator_tag) 
# 261
{ 
# 262
const size_type __len = ::std::distance(__first, __last); 
# 264
if (__len > capacity()) 
# 265
{ 
# 266
pointer __tmp(_M_allocate_and_copy(__len, __first, __last)); 
# 267
::std::_Destroy(((this->_M_impl)._M_start), ((this->_M_impl)._M_finish), _M_get_Tp_allocator()); 
# 269
_M_deallocate(((this->_M_impl)._M_start), ((this->_M_impl)._M_end_of_storage) - ((this->_M_impl)._M_start)); 
# 272
((this->_M_impl)._M_start) = __tmp; 
# 273
((this->_M_impl)._M_finish) = (((this->_M_impl)._M_start) + __len); 
# 274
((this->_M_impl)._M_end_of_storage) = ((this->_M_impl)._M_finish); 
# 275
} else { 
# 276
if (size() >= __len) { 
# 277
_M_erase_at_end(::std::copy(__first, __last, ((this->_M_impl)._M_start))); } else 
# 279
{ 
# 280
_ForwardIterator __mid = __first; 
# 281
::std::advance(__mid, size()); 
# 282
::std::copy(__first, __mid, ((this->_M_impl)._M_start)); 
# 283
((this->_M_impl)._M_finish) = ::std::__uninitialized_copy_a(__mid, __last, ((this->_M_impl)._M_finish), _M_get_Tp_allocator()); 
# 287
}  }  
# 288
} 
# 316
template< class _Tp, class _Alloc> void 
# 319
vector< _Tp, _Alloc> ::_M_insert_aux(iterator __position, const _Tp &__x) 
# 321
{ 
# 322
if (((this->_M_impl)._M_finish) != ((this->_M_impl)._M_end_of_storage)) 
# 323
{ 
# 324
_Alloc_traits::construct((this->_M_impl), ((this->_M_impl)._M_finish), *(((this->_M_impl)._M_finish) - 1)); 
# 327
++((this->_M_impl)._M_finish); 
# 329
_Tp __x_copy = __x; 
# 331
::std::copy_backward((__position.base()), ((this->_M_impl)._M_finish) - 2, ((this->_M_impl)._M_finish) - 1); 
# 335
(*__position) = __x_copy; 
# 339
} else 
# 341
{ 
# 342
const size_type __len = _M_check_len((size_type)1, "vector::_M_insert_aux"); 
# 344
const size_type __elems_before = __position - this->begin(); 
# 345
pointer __new_start((this->_M_allocate(__len))); 
# 346
pointer __new_finish(__new_start); 
# 347
try 
# 348
{ 
# 353
_Alloc_traits::construct((this->_M_impl), __new_start + __elems_before, __x); 
# 360
__new_finish = 0; 
# 362
__new_finish = ::std::__uninitialized_move_if_noexcept_a(((this->_M_impl)._M_start), (__position.base()), __new_start, _M_get_Tp_allocator()); 
# 367
++__new_finish; 
# 369
__new_finish = ::std::__uninitialized_move_if_noexcept_a((__position.base()), ((this->_M_impl)._M_finish), __new_finish, _M_get_Tp_allocator()); 
# 373
} 
# 374
catch (...) 
# 375
{ 
# 376
if (!__new_finish) { 
# 377
_Alloc_traits::destroy((this->_M_impl), __new_start + __elems_before); } else { 
# 380
::std::_Destroy(__new_start, __new_finish, _M_get_Tp_allocator()); }  
# 381
_M_deallocate(__new_start, __len); 
# 382
throw; 
# 383
}  
# 384
::std::_Destroy(((this->_M_impl)._M_start), ((this->_M_impl)._M_finish), _M_get_Tp_allocator()); 
# 386
_M_deallocate(((this->_M_impl)._M_start), ((this->_M_impl)._M_end_of_storage) - ((this->_M_impl)._M_start)); 
# 389
((this->_M_impl)._M_start) = __new_start; 
# 390
((this->_M_impl)._M_finish) = __new_finish; 
# 391
((this->_M_impl)._M_end_of_storage) = (__new_start + __len); 
# 392
}  
# 393
} 
# 439
template< class _Tp, class _Alloc> void 
# 442
vector< _Tp, _Alloc> ::_M_fill_insert(iterator __position, size_type __n, const value_type &__x) 
# 443
{ 
# 444
if (__n != (0)) 
# 445
{ 
# 446
if (((size_type)(((this->_M_impl)._M_end_of_storage) - ((this->_M_impl)._M_finish))) >= __n) 
# 448
{ 
# 449
value_type __x_copy = __x; 
# 450
const size_type __elems_after = this->end() - __position; 
# 451
pointer __old_finish(((this->_M_impl)._M_finish)); 
# 452
if (__elems_after > __n) 
# 453
{ 
# 454
::std::__uninitialized_move_a(((this->_M_impl)._M_finish) - __n, ((this->_M_impl)._M_finish), ((this->_M_impl)._M_finish), _M_get_Tp_allocator()); 
# 458
((this->_M_impl)._M_finish) += __n; 
# 459
::std::copy_backward((__position.base()), __old_finish - __n, __old_finish); 
# 461
::std::fill((__position.base()), (__position.base()) + __n, __x_copy); 
# 463
} else 
# 465
{ 
# 466
::std::__uninitialized_fill_n_a(((this->_M_impl)._M_finish), __n - __elems_after, __x_copy, _M_get_Tp_allocator()); 
# 470
((this->_M_impl)._M_finish) += (__n - __elems_after); 
# 471
::std::__uninitialized_move_a((__position.base()), __old_finish, ((this->_M_impl)._M_finish), _M_get_Tp_allocator()); 
# 474
((this->_M_impl)._M_finish) += __elems_after; 
# 475
::std::fill((__position.base()), __old_finish, __x_copy); 
# 476
}  
# 477
} else 
# 479
{ 
# 480
const size_type __len = _M_check_len(__n, "vector::_M_fill_insert"); 
# 482
const size_type __elems_before = __position - this->begin(); 
# 483
pointer __new_start((this->_M_allocate(__len))); 
# 484
pointer __new_finish(__new_start); 
# 485
try 
# 486
{ 
# 488
::std::__uninitialized_fill_n_a(__new_start + __elems_before, __n, __x, _M_get_Tp_allocator()); 
# 491
__new_finish = 0; 
# 493
__new_finish = ::std::__uninitialized_move_if_noexcept_a(((this->_M_impl)._M_start), (__position.base()), __new_start, _M_get_Tp_allocator()); 
# 498
__new_finish += __n; 
# 500
__new_finish = ::std::__uninitialized_move_if_noexcept_a((__position.base()), ((this->_M_impl)._M_finish), __new_finish, _M_get_Tp_allocator()); 
# 504
} 
# 505
catch (...) 
# 506
{ 
# 507
if (!__new_finish) { 
# 508
::std::_Destroy(__new_start + __elems_before, (__new_start + __elems_before) + __n, _M_get_Tp_allocator()); } else { 
# 512
::std::_Destroy(__new_start, __new_finish, _M_get_Tp_allocator()); }  
# 514
_M_deallocate(__new_start, __len); 
# 515
throw; 
# 516
}  
# 517
::std::_Destroy(((this->_M_impl)._M_start), ((this->_M_impl)._M_finish), _M_get_Tp_allocator()); 
# 519
_M_deallocate(((this->_M_impl)._M_start), ((this->_M_impl)._M_end_of_storage) - ((this->_M_impl)._M_start)); 
# 522
((this->_M_impl)._M_start) = __new_start; 
# 523
((this->_M_impl)._M_finish) = __new_finish; 
# 524
((this->_M_impl)._M_end_of_storage) = (__new_start + __len); 
# 525
}  
# 526
}  
# 527
} 
# 591
template< class _Tp, class _Alloc> 
# 592
template< class _InputIterator> void 
# 595
vector< _Tp, _Alloc> ::_M_range_insert(iterator __pos, _InputIterator __first, _InputIterator 
# 596
__last, ::std::input_iterator_tag) 
# 597
{ 
# 598
for (; __first != __last; ++__first) 
# 599
{ 
# 600
__pos = insert(__pos, *__first); 
# 601
++__pos; 
# 602
}  
# 603
} 
# 605
template< class _Tp, class _Alloc> 
# 606
template< class _ForwardIterator> void 
# 609
vector< _Tp, _Alloc> ::_M_range_insert(iterator __position, _ForwardIterator __first, _ForwardIterator 
# 610
__last, ::std::forward_iterator_tag) 
# 611
{ 
# 612
if (__first != __last) 
# 613
{ 
# 614
const size_type __n = ::std::distance(__first, __last); 
# 615
if (((size_type)(((this->_M_impl)._M_end_of_storage) - ((this->_M_impl)._M_finish))) >= __n) 
# 617
{ 
# 618
const size_type __elems_after = this->end() - __position; 
# 619
pointer __old_finish(((this->_M_impl)._M_finish)); 
# 620
if (__elems_after > __n) 
# 621
{ 
# 622
::std::__uninitialized_move_a(((this->_M_impl)._M_finish) - __n, ((this->_M_impl)._M_finish), ((this->_M_impl)._M_finish), _M_get_Tp_allocator()); 
# 626
((this->_M_impl)._M_finish) += __n; 
# 627
::std::copy_backward((__position.base()), __old_finish - __n, __old_finish); 
# 629
::std::copy(__first, __last, __position); 
# 630
} else 
# 632
{ 
# 633
_ForwardIterator __mid = __first; 
# 634
::std::advance(__mid, __elems_after); 
# 635
::std::__uninitialized_copy_a(__mid, __last, ((this->_M_impl)._M_finish), _M_get_Tp_allocator()); 
# 638
((this->_M_impl)._M_finish) += (__n - __elems_after); 
# 639
::std::__uninitialized_move_a((__position.base()), __old_finish, ((this->_M_impl)._M_finish), _M_get_Tp_allocator()); 
# 643
((this->_M_impl)._M_finish) += __elems_after; 
# 644
::std::copy(__first, __mid, __position); 
# 645
}  
# 646
} else 
# 648
{ 
# 649
const size_type __len = _M_check_len(__n, "vector::_M_range_insert"); 
# 651
pointer __new_start((this->_M_allocate(__len))); 
# 652
pointer __new_finish(__new_start); 
# 653
try 
# 654
{ 
# 655
__new_finish = ::std::__uninitialized_move_if_noexcept_a(((this->_M_impl)._M_start), (__position.base()), __new_start, _M_get_Tp_allocator()); 
# 659
__new_finish = ::std::__uninitialized_copy_a(__first, __last, __new_finish, _M_get_Tp_allocator()); 
# 663
__new_finish = ::std::__uninitialized_move_if_noexcept_a((__position.base()), ((this->_M_impl)._M_finish), __new_finish, _M_get_Tp_allocator()); 
# 667
} 
# 668
catch (...) 
# 669
{ 
# 670
::std::_Destroy(__new_start, __new_finish, _M_get_Tp_allocator()); 
# 672
_M_deallocate(__new_start, __len); 
# 673
throw; 
# 674
}  
# 675
::std::_Destroy(((this->_M_impl)._M_start), ((this->_M_impl)._M_finish), _M_get_Tp_allocator()); 
# 677
_M_deallocate(((this->_M_impl)._M_start), ((this->_M_impl)._M_end_of_storage) - ((this->_M_impl)._M_start)); 
# 680
((this->_M_impl)._M_start) = __new_start; 
# 681
((this->_M_impl)._M_finish) = __new_finish; 
# 682
((this->_M_impl)._M_end_of_storage) = (__new_start + __len); 
# 683
}  
# 684
}  
# 685
} 
# 689
template< class _Alloc> void 
# 692
vector< bool, _Alloc> ::_M_reallocate(size_type __n) 
# 693
{ 
# 694
::std::_Bit_type *__q = (this->_M_allocate(__n)); 
# 695
((this->_M_impl)._M_finish) = _M_copy_aligned(this->begin(), this->end(), iterator(__q, 0)); 
# 697
(this->_M_deallocate()); 
# 698
((this->_M_impl)._M_start) = iterator(__q, 0); 
# 699
((this->_M_impl)._M_end_of_storage) = (__q + _S_nword(__n)); 
# 700
} 
# 702
template< class _Alloc> void 
# 705
vector< bool, _Alloc> ::_M_fill_insert(iterator __position, size_type __n, bool __x) 
# 706
{ 
# 707
if (__n == (0)) { 
# 708
return; }  
# 709
if ((capacity() - size()) >= __n) 
# 710
{ 
# 711
::std::copy_backward(__position, this->end(), ((this->_M_impl)._M_finish) + ((difference_type)__n)); 
# 713
std::fill(__position, (__position + ((difference_type)__n)), __x); 
# 714
((this->_M_impl)._M_finish) += ((difference_type)__n); 
# 715
} else 
# 717
{ 
# 718
const size_type __len = _M_check_len(__n, "vector<bool>::_M_fill_insert"); 
# 720
::std::_Bit_type *__q = (this->_M_allocate(__len)); 
# 721
iterator __i = _M_copy_aligned(this->begin(), __position, iterator(__q, 0)); 
# 723
std::fill(__i, (__i + ((difference_type)__n)), __x); 
# 724
((this->_M_impl)._M_finish) = ::std::copy(__position, this->end(), (__i + ((difference_type)__n))); 
# 726
(this->_M_deallocate()); 
# 727
((this->_M_impl)._M_end_of_storage) = (__q + _S_nword(__len)); 
# 728
((this->_M_impl)._M_start) = iterator(__q, 0); 
# 729
}  
# 730
} 
# 732
template< class _Alloc> 
# 733
template< class _ForwardIterator> void 
# 736
vector< bool, _Alloc> ::_M_insert_range(iterator __position, _ForwardIterator __first, _ForwardIterator 
# 737
__last, ::std::forward_iterator_tag) 
# 738
{ 
# 739
if (__first != __last) 
# 740
{ 
# 741
size_type __n = ::std::distance(__first, __last); 
# 742
if ((capacity() - size()) >= __n) 
# 743
{ 
# 744
::std::copy_backward(__position, this->end(), ((this->_M_impl)._M_finish) + ((difference_type)__n)); 
# 747
::std::copy(__first, __last, __position); 
# 748
((this->_M_impl)._M_finish) += ((difference_type)__n); 
# 749
} else 
# 751
{ 
# 752
const size_type __len = _M_check_len(__n, "vector<bool>::_M_insert_range"); 
# 754
::std::_Bit_type *__q = (this->_M_allocate(__len)); 
# 755
iterator __i = _M_copy_aligned(this->begin(), __position, iterator(__q, 0)); 
# 757
__i = ::std::copy(__first, __last, __i); 
# 758
((this->_M_impl)._M_finish) = ::std::copy(__position, this->end(), __i); 
# 759
(this->_M_deallocate()); 
# 760
((this->_M_impl)._M_end_of_storage) = (__q + _S_nword(__len)); 
# 761
((this->_M_impl)._M_start) = iterator(__q, 0); 
# 762
}  
# 763
}  
# 764
} 
# 766
template< class _Alloc> void 
# 769
vector< bool, _Alloc> ::_M_insert_aux(iterator __position, bool __x) 
# 770
{ 
# 771
if ((((this->_M_impl)._M_finish)._M_p) != ((this->_M_impl)._M_end_of_storage)) 
# 772
{ 
# 773
::std::copy_backward(__position, ((this->_M_impl)._M_finish), ((this->_M_impl)._M_finish) + 1); 
# 775
(((*__position)) = __x); 
# 776
++((this->_M_impl)._M_finish); 
# 777
} else 
# 779
{ 
# 780
const size_type __len = _M_check_len((size_type)1, "vector<bool>::_M_insert_aux"); 
# 782
::std::_Bit_type *__q = (this->_M_allocate(__len)); 
# 783
iterator __i = _M_copy_aligned(this->begin(), __position, iterator(__q, 0)); 
# 785
(((*(__i++))) = __x); 
# 786
((this->_M_impl)._M_finish) = ::std::copy(__position, this->end(), __i); 
# 787
(this->_M_deallocate()); 
# 788
((this->_M_impl)._M_end_of_storage) = (__q + _S_nword(__len)); 
# 789
((this->_M_impl)._M_start) = iterator(__q, 0); 
# 790
}  
# 791
} 
# 812
}
# 32 "/usr/local/cuda-8.0/include/thrust/detail/vector_base.h"
namespace thrust { 
# 35
namespace detail { 
# 38
template< class T, class Alloc> 
# 39
class vector_base { 
# 42
typedef contiguous_storage< T, Alloc>  storage_type; 
# 46
public: typedef typename contiguous_storage< T, Alloc> ::value_type value_type; 
# 47
typedef typename contiguous_storage< T, Alloc> ::pointer pointer; 
# 48
typedef typename contiguous_storage< T, Alloc> ::const_pointer const_pointer; 
# 49
typedef typename contiguous_storage< T, Alloc> ::reference reference; 
# 50
typedef typename contiguous_storage< T, Alloc> ::const_reference const_reference; 
# 51
typedef typename contiguous_storage< T, Alloc> ::size_type size_type; 
# 52
typedef typename contiguous_storage< T, Alloc> ::difference_type difference_type; 
# 53
typedef typename contiguous_storage< T, Alloc> ::allocator_type allocator_type; 
# 55
typedef typename contiguous_storage< T, Alloc> ::iterator iterator; 
# 56
typedef typename contiguous_storage< T, Alloc> ::const_iterator const_iterator; 
# 58
typedef thrust::reverse_iterator< typename contiguous_storage< T, Alloc> ::iterator>  reverse_iterator; 
# 59
typedef thrust::reverse_iterator< typename contiguous_storage< T, Alloc> ::const_iterator>  const_reverse_iterator; 
# 63
vector_base(); 
# 69
explicit vector_base(size_type n); 
# 76
explicit vector_base(size_type n, const value_type & value); 
# 81
vector_base(const vector_base & v); 
# 86
vector_base &operator=(const vector_base & v); 
# 92
template< class OtherT, class OtherAlloc> vector_base(const detail::vector_base< OtherT, OtherAlloc>  & v); 
# 99
template< class OtherT, class OtherAlloc> vector_base &operator=(const detail::vector_base< OtherT, OtherAlloc>  & v); 
# 108
template< class OtherT, class OtherAlloc> vector_base(const std::vector< OtherT, OtherAlloc>  & v); 
# 117
template< class OtherT, class OtherAlloc> vector_base &operator=(const std::vector< OtherT, OtherAlloc>  & v); 
# 124
template< class InputIterator> vector_base(InputIterator first, InputIterator last); 
# 129
~vector_base(); 
# 140
void resize(size_type new_size); 
# 152
void resize(size_type new_size, const value_type & x); 
# 156
size_type size() const; 
# 161
size_type max_size() const; 
# 169
void reserve(size_type n); 
# 174
size_type capacity() const; 
# 179
void shrink_to_fit(); 
# 189
reference operator[](size_type n); 
# 199
const_reference operator[](size_type n) const; 
# 205
iterator begin(); 
# 211
const_iterator begin() const; 
# 217
const_iterator cbegin() const; 
# 224
reverse_iterator rbegin(); 
# 231
const_reverse_iterator rbegin() const; 
# 238
const_reverse_iterator crbegin() const; 
# 244
iterator end(); 
# 250
const_iterator end() const; 
# 256
const_iterator cend() const; 
# 262
reverse_iterator rend(); 
# 268
const_reverse_iterator rend() const; 
# 274
const_reverse_iterator crend() const; 
# 280
const_reference front() const; 
# 286
reference front(); 
# 292
const_reference back() const; 
# 298
reference back(); 
# 303
pointer data(); 
# 308
const_pointer data() const; 
# 312
void clear(); 
# 317
bool empty() const; 
# 322
void push_back(const value_type & x); 
# 327
void pop_back(); 
# 332
void swap(vector_base & v); 
# 339
iterator erase(iterator pos); 
# 347
iterator erase(iterator first, iterator last); 
# 355
iterator insert(iterator position, const T & x); 
# 363
void insert(iterator position, size_type n, const T & x); 
# 374
template< class InputIterator> void insert(iterator position, InputIterator first, InputIterator last); 
# 382
void assign(size_type n, const T & x); 
# 390
template< class InputIterator> void assign(InputIterator first, InputIterator last); 
# 396
allocator_type get_allocator() const; 
# 400
protected: storage_type m_storage; 
# 403
size_type m_size; 
# 407
private: template< class IteratorOrIntegralType> void init_dispatch(IteratorOrIntegralType begin, IteratorOrIntegralType end, false_type); 
# 410
template< class IteratorOrIntegralType> void init_dispatch(IteratorOrIntegralType n, IteratorOrIntegralType value, true_type); 
# 413
template< class InputIterator> void range_init(InputIterator first, InputIterator last); 
# 416
template< class InputIterator> void range_init(InputIterator first, InputIterator last, incrementable_traversal_tag); 
# 419
template< class ForwardIterator> void range_init(ForwardIterator first, ForwardIterator last, random_access_traversal_tag); 
# 422
void default_init(size_type n); 
# 424
void fill_init(size_type n, const T & x); 
# 427
template< class InputIteratorOrIntegralType> void insert_dispatch(iterator position, InputIteratorOrIntegralType first, InputIteratorOrIntegralType last, false_type); 
# 431
template< class InputIteratorOrIntegralType> void insert_dispatch(iterator position, InputIteratorOrIntegralType n, InputIteratorOrIntegralType x, true_type); 
# 435
void append(size_type n); 
# 438
void fill_insert(iterator position, size_type n, const T & x); 
# 441
template< class InputIterator> void copy_insert(iterator position, InputIterator first, InputIterator last); 
# 445
template< class InputIterator> void assign_dispatch(InputIterator first, InputIterator last, false_type); 
# 449
template< class Integral> void assign_dispatch(Integral n, Integral x, true_type); 
# 453
template< class InputIterator> void range_assign(InputIterator first, InputIterator last); 
# 457
template< class RandomAccessIterator> void range_assign(RandomAccessIterator first, RandomAccessIterator last, random_access_traversal_tag); 
# 461
template< class InputIterator> void range_assign(InputIterator first, InputIterator last, incrementable_traversal_tag); 
# 465
void fill_assign(size_type n, const T & x); 
# 468
template< class ForwardIterator> void allocate_and_copy(size_type requested_size, ForwardIterator first, ForwardIterator last, storage_type & new_storage); 
# 472
}; 
# 474
}
# 484
template< class T, class Alloc> void swap(detail::vector_base< T, Alloc>  & a, detail::vector_base< T, Alloc>  & b); 
# 495
template< class T1, class Alloc1, class 
# 496
T2, class Alloc2> bool 
# 495
operator==(const detail::vector_base< T1, Alloc1>  & lhs, const detail::vector_base< T2, Alloc2>  & rhs); 
# 500
template< class T1, class Alloc1, class 
# 501
T2, class Alloc2> bool 
# 500
operator==(const detail::vector_base< T1, Alloc1>  & lhs, const std::vector< T2, Alloc2>  & rhs); 
# 505
template< class T1, class Alloc1, class 
# 506
T2, class Alloc2> bool 
# 505
operator==(const std::vector< T1, Alloc1>  & lhs, const detail::vector_base< T2, Alloc2>  & rhs); 
# 516
template< class T1, class Alloc1, class 
# 517
T2, class Alloc2> bool 
# 516
operator!=(const detail::vector_base< T1, Alloc1>  & lhs, const detail::vector_base< T2, Alloc2>  & rhs); 
# 521
template< class T1, class Alloc1, class 
# 522
T2, class Alloc2> bool 
# 521
operator!=(const detail::vector_base< T1, Alloc1>  & lhs, const std::vector< T2, Alloc2>  & rhs); 
# 526
template< class T1, class Alloc1, class 
# 527
T2, class Alloc2> bool 
# 526
operator!=(const std::vector< T1, Alloc1>  & lhs, const detail::vector_base< T2, Alloc2>  & rhs); 
# 531
}
# 26 "/usr/local/cuda-8.0/include/thrust/detail/overlapped_copy.h"
namespace thrust { 
# 28
namespace detail { 
# 32
template< class InputIterator, class 
# 33
OutputIterator> OutputIterator 
# 34
sequential_copy(InputIterator first, InputIterator 
# 35
last, OutputIterator 
# 36
result) 
# 37
{ 
# 38
for (; first != last; (++first), (++result)) 
# 39
{ 
# 40
(*result) = (*first); 
# 41
}  
# 43
return result; 
# 44
} 
# 47
template< class BidirectionalIterator1, class 
# 48
BidirectionalIterator2> BidirectionalIterator2 
# 49
sequential_copy_backward(BidirectionalIterator1 first, BidirectionalIterator1 
# 50
last, BidirectionalIterator2 
# 51
result) 
# 52
{ 
# 55
while (first != last) 
# 56
{ 
# 57
(*(--result)) = (*(--last)); 
# 58
}  
# 60
return result; 
# 61
} 
# 64
namespace dispatch { 
# 68
template< class DerivedPolicy, class 
# 69
RandomAccessIterator1, class 
# 70
RandomAccessIterator2> RandomAccessIterator2 
# 71
overlapped_copy(system::cpp::detail::execution_policy< DerivedPolicy>  &, RandomAccessIterator1 
# 72
first, RandomAccessIterator1 
# 73
last, RandomAccessIterator2 
# 74
result) 
# 75
{ 
# 76
if ((first < last) && (first <= result) && (result < last)) 
# 77
{ 
# 80
detail::sequential_copy_backward(first, last, result + (last - first)); 
# 81
result += (last - first); 
# 82
} else 
# 84
{ 
# 87
result = detail::sequential_copy(first, last, result); 
# 88
}  
# 90
return result; 
# 91
} 
# 94
template< class DerivedPolicy, class 
# 95
RandomAccessIterator1, class 
# 96
RandomAccessIterator2> RandomAccessIterator2 
# 97
overlapped_copy(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator1 
# 98
first, RandomAccessIterator1 
# 99
last, RandomAccessIterator2 
# 100
result) 
# 101
{ 
# 102
typedef typename iterator_value< RandomAccessIterator1> ::type value_type; 
# 105
temporary_array< typename iterator_value< RandomAccessIterator1> ::type, DerivedPolicy>  temp(exec, first, last); 
# 106
return thrust::copy(exec, (temp.begin()), (temp.end()), result); 
# 107
} 
# 109
}
# 112
template< class RandomAccessIterator1, class 
# 113
RandomAccessIterator2> RandomAccessIterator2 
# 114
overlapped_copy(RandomAccessIterator1 first, RandomAccessIterator1 
# 115
last, RandomAccessIterator2 
# 116
result) 
# 117
{ 
# 118
typedef typename iterator_system< RandomAccessIterator2> ::type System1; 
# 119
typedef typename iterator_system< RandomAccessIterator2> ::type System2; 
# 121
typedef typename minimum_system< typename iterator_system< RandomAccessIterator2> ::type, typename iterator_system< RandomAccessIterator2> ::type> ::type System; 
# 124
System system; 
# 126
return dispatch::overlapped_copy(system, first, last, result); 
# 127
} 
# 129
}
# 130
}
# 27 "/usr/local/cuda-8.0/include/thrust/equal.h"
namespace thrust { 
# 79
template< class DerivedPolicy, class InputIterator1, class InputIterator2> bool equal(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator1 first1, InputIterator1 last1, InputIterator2 first2); 
# 119
template< class InputIterator1, class InputIterator2> bool equal(InputIterator1 first1, InputIterator1 last1, InputIterator2 first2); 
# 175
template< class DerivedPolicy, class InputIterator1, class InputIterator2, class BinaryPredicate> bool equal(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator1 first1, InputIterator1 last1, InputIterator2 first2, BinaryPredicate binary_pred); 
# 225
template< class InputIterator1, class InputIterator2, class 
# 226
BinaryPredicate> bool 
# 225
equal(InputIterator1 first1, InputIterator1 last1, InputIterator2 first2, BinaryPredicate binary_pred); 
# 235
}
# 22 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/equal.h"
namespace thrust { 
# 24
namespace system { 
# 26
namespace detail { 
# 28
namespace generic { 
# 32
template< class DerivedPolicy, class InputIterator1, class InputIterator2> bool equal(execution_policy< DerivedPolicy>  & exec, InputIterator1 first1, InputIterator1 last1, InputIterator2 first2); 
# 37
template< class DerivedPolicy, class InputIterator1, class InputIterator2, class BinaryPredicate> bool equal(execution_policy< DerivedPolicy>  & exec, InputIterator1 first1, InputIterator1 last1, InputIterator2 first2, BinaryPredicate binary_pred); 
# 42
}
# 43
}
# 44
}
# 45
}
# 28 "/usr/local/cuda-8.0/include/thrust/mismatch.h"
namespace thrust { 
# 89
template< class DerivedPolicy, class InputIterator1, class InputIterator2> pair< InputIterator1, InputIterator2>  mismatch(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator1 first1, InputIterator1 last1, InputIterator2 first2); 
# 140
template< class InputIterator1, class InputIterator2> pair< InputIterator1, InputIterator2>  mismatch(InputIterator1 first1, InputIterator1 last1, InputIterator2 first2); 
# 195
template< class DerivedPolicy, class InputIterator1, class InputIterator2, class BinaryPredicate> pair< InputIterator1, InputIterator2>  mismatch(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator1 first1, InputIterator1 last1, InputIterator2 first2, BinaryPredicate pred); 
# 248
template< class InputIterator1, class InputIterator2, class BinaryPredicate> pair< InputIterator1, InputIterator2>  mismatch(InputIterator1 first1, InputIterator1 last1, InputIterator2 first2, BinaryPredicate pred); 
# 257
}
# 23 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/mismatch.h"
namespace thrust { 
# 25
namespace system { 
# 27
namespace detail { 
# 29
namespace generic { 
# 33
template< class DerivedPolicy, class InputIterator1, class InputIterator2> pair< InputIterator1, InputIterator2>  mismatch(execution_policy< DerivedPolicy>  & exec, InputIterator1 first1, InputIterator1 last1, InputIterator2 first2); 
# 42
template< class DerivedPolicy, class InputIterator1, class InputIterator2, class BinaryPredicate> pair< InputIterator1, InputIterator2>  mismatch(execution_policy< DerivedPolicy>  & exec, InputIterator1 first1, InputIterator1 last1, InputIterator2 first2, BinaryPredicate pred); 
# 52
}
# 53
}
# 54
}
# 55
}
# 27 "/usr/local/cuda-8.0/include/thrust/find.h"
namespace thrust { 
# 79
template< class DerivedPolicy, class InputIterator, class T> InputIterator find(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator first, InputIterator last, const T & value); 
# 121
template< class InputIterator, class T> InputIterator find(InputIterator first, InputIterator last, const T & value); 
# 186
template< class DerivedPolicy, class InputIterator, class Predicate> InputIterator find_if(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator first, InputIterator last, Predicate pred); 
# 247
template< class InputIterator, class Predicate> InputIterator find_if(InputIterator first, InputIterator last, Predicate pred); 
# 312
template< class DerivedPolicy, class InputIterator, class Predicate> InputIterator find_if_not(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator first, InputIterator last, Predicate pred); 
# 373
template< class InputIterator, class Predicate> InputIterator find_if_not(InputIterator first, InputIterator last, Predicate pred); 
# 382
}
# 23 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/find.h"
namespace thrust { 
# 25
namespace system { 
# 27
namespace detail { 
# 29
namespace generic { 
# 33
template< class DerivedPolicy, class InputIterator, class T> InputIterator find(execution_policy< DerivedPolicy>  & exec, InputIterator first, InputIterator last, const T & value); 
# 41
template< class DerivedPolicy, class InputIterator, class Predicate> InputIterator find_if(execution_policy< DerivedPolicy>  & exec, InputIterator first, InputIterator last, Predicate pred); 
# 49
template< class DerivedPolicy, class InputIterator, class Predicate> InputIterator find_if_not(execution_policy< DerivedPolicy>  & exec, InputIterator first, InputIterator last, Predicate pred); 
# 57
}
# 58
}
# 59
}
# 60
}
# 29 "/usr/local/cuda-8.0/include/thrust/reduce.h"
namespace thrust { 
# 82
template< class DerivedPolicy, class InputIterator> typename iterator_traits< InputIterator> ::value_type reduce(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator first, InputIterator last); 
# 127
template< class InputIterator> typename iterator_traits< InputIterator> ::value_type reduce(InputIterator first, InputIterator last); 
# 176
template< class DerivedPolicy, class InputIterator, class T> T reduce(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator first, InputIterator last, T init); 
# 223
template< class InputIterator, class T> T reduce(InputIterator first, InputIterator last, T init); 
# 281
template< class DerivedPolicy, class 
# 282
InputIterator, class 
# 283
T, class 
# 284
BinaryFunction> T 
# 281
reduce(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator first, InputIterator last, T init, BinaryFunction binary_op); 
# 338
template< class InputIterator, class 
# 339
T, class 
# 340
BinaryFunction> T 
# 338
reduce(InputIterator first, InputIterator last, T init, BinaryFunction binary_op); 
# 402
template< class DerivedPolicy, class 
# 403
InputIterator1, class 
# 404
InputIterator2, class 
# 405
OutputIterator1, class 
# 406
OutputIterator2> pair< OutputIterator1, OutputIterator2>  
# 402
reduce_by_key(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator1 keys_first, InputIterator1 keys_last, InputIterator2 values_first, OutputIterator1 keys_output, OutputIterator2 values_output); 
# 466
template< class InputIterator1, class 
# 467
InputIterator2, class 
# 468
OutputIterator1, class 
# 469
OutputIterator2> pair< OutputIterator1, OutputIterator2>  
# 466
reduce_by_key(InputIterator1 keys_first, InputIterator1 keys_last, InputIterator2 values_first, OutputIterator1 keys_output, OutputIterator2 values_output); 
# 536
template< class DerivedPolicy, class 
# 537
InputIterator1, class 
# 538
InputIterator2, class 
# 539
OutputIterator1, class 
# 540
OutputIterator2, class 
# 541
BinaryPredicate> pair< OutputIterator1, OutputIterator2>  
# 536
reduce_by_key(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator1 keys_first, InputIterator1 keys_last, InputIterator2 values_first, OutputIterator1 keys_output, OutputIterator2 values_output, BinaryPredicate binary_pred); 
# 605
template< class InputIterator1, class 
# 606
InputIterator2, class 
# 607
OutputIterator1, class 
# 608
OutputIterator2, class 
# 609
BinaryPredicate> pair< OutputIterator1, OutputIterator2>  
# 605
reduce_by_key(InputIterator1 keys_first, InputIterator1 keys_last, InputIterator2 values_first, OutputIterator1 keys_output, OutputIterator2 values_output, BinaryPredicate binary_pred); 
# 684
template< class DerivedPolicy, class 
# 685
InputIterator1, class 
# 686
InputIterator2, class 
# 687
OutputIterator1, class 
# 688
OutputIterator2, class 
# 689
BinaryPredicate, class 
# 690
BinaryFunction> pair< OutputIterator1, OutputIterator2>  
# 684
reduce_by_key(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator1 keys_first, InputIterator1 keys_last, InputIterator2 values_first, OutputIterator1 keys_output, OutputIterator2 values_output, BinaryPredicate binary_pred, BinaryFunction binary_op); 
# 762
template< class InputIterator1, class 
# 763
InputIterator2, class 
# 764
OutputIterator1, class 
# 765
OutputIterator2, class 
# 766
BinaryPredicate, class 
# 767
BinaryFunction> pair< OutputIterator1, OutputIterator2>  
# 762
reduce_by_key(InputIterator1 keys_first, InputIterator1 keys_last, InputIterator2 values_first, OutputIterator1 keys_output, OutputIterator2 values_output, BinaryPredicate binary_pred, BinaryFunction binary_op); 
# 782
}
# 24 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/reduce.h"
namespace thrust { 
# 26
namespace system { 
# 28
namespace detail { 
# 30
namespace generic { 
# 34
template< class DerivedPolicy, class InputIterator> typename iterator_traits< InputIterator> ::value_type reduce(execution_policy< DerivedPolicy>  & exec, InputIterator first, InputIterator last); 
# 40
template< class DerivedPolicy, class InputIterator, class T> T reduce(execution_policy< DerivedPolicy>  & exec, InputIterator first, InputIterator last, T init); 
# 45
template< class DerivedPolicy, class 
# 46
InputIterator, class 
# 47
T, class 
# 48
BinaryFunction> T 
# 45
reduce(execution_policy< DerivedPolicy>  & exec, InputIterator first, InputIterator last, T init, BinaryFunction binary_op); 
# 53
}
# 54
}
# 55
}
# 56
}
# 25 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/reduce.inl"
namespace thrust { 
# 27
namespace system { 
# 29
namespace detail { 
# 31
namespace generic { 
# 35
template< class ExecutionPolicy, class InputIterator> typename iterator_traits< InputIterator> ::value_type 
# 38
reduce(execution_policy< ExecutionPolicy>  &exec, InputIterator first, InputIterator last) 
# 39
{ 
# 40
typedef typename iterator_value< InputIterator> ::type InputType; 
# 43
return thrust::reduce(exec, first, last, (InputType)0); 
# 44
} 
# 47
template< class ExecutionPolicy, class InputIterator, class T> T 
# 49
reduce(execution_policy< ExecutionPolicy>  &exec, InputIterator first, InputIterator last, T init) 
# 50
{ 
# 52
return thrust::reduce(exec, first, last, init, plus< T> ()); 
# 53
} 
# 56
template< class ExecutionPolicy, class 
# 57
RandomAccessIterator, class 
# 58
OutputType, class 
# 59
BinaryFunction> OutputType 
# 61
reduce(execution_policy< ExecutionPolicy>  &exec, RandomAccessIterator 
# 62
first, RandomAccessIterator 
# 63
last, OutputType 
# 64
init, BinaryFunction 
# 65
binary_op) 
# 66
{ 
# 68
typedef thrust::detail::static_assert_test< sizeof(thrust::detail::STATIC_ASSERTION_FAILURE< (bool)(thrust::detail::depend_on_instantiation< RandomAccessIterator, false> ::value)> )>  thrust_static_assert_typedef_68 __attribute((unused)); 
# 69
return OutputType(); 
# 70
} 
# 73
}
# 74
}
# 75
}
# 76
}
# 24 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/reduce_by_key.h"
namespace thrust { 
# 26
namespace system { 
# 28
namespace detail { 
# 30
namespace generic { 
# 34
template< class DerivedPolicy, class 
# 35
InputIterator1, class 
# 36
InputIterator2, class 
# 37
OutputIterator1, class 
# 38
OutputIterator2> pair< OutputIterator1, OutputIterator2>  
# 34
reduce_by_key(execution_policy< DerivedPolicy>  & exec, InputIterator1 keys_first, InputIterator1 keys_last, InputIterator2 values_first, OutputIterator1 keys_output, OutputIterator2 values_output); 
# 48
template< class DerivedPolicy, class 
# 49
InputIterator1, class 
# 50
InputIterator2, class 
# 51
OutputIterator1, class 
# 52
OutputIterator2, class 
# 53
BinaryPredicate> pair< OutputIterator1, OutputIterator2>  
# 48
reduce_by_key(execution_policy< DerivedPolicy>  & exec, InputIterator1 keys_first, InputIterator1 keys_last, InputIterator2 values_first, OutputIterator1 keys_output, OutputIterator2 values_output, BinaryPredicate binary_pred); 
# 64
template< class DerivedPolicy, class 
# 65
InputIterator1, class 
# 66
InputIterator2, class 
# 67
OutputIterator1, class 
# 68
OutputIterator2, class 
# 69
BinaryPredicate, class 
# 70
BinaryFunction> pair< OutputIterator1, OutputIterator2>  
# 64
reduce_by_key(execution_policy< DerivedPolicy>  & exec, InputIterator1 keys_first, InputIterator1 keys_last, InputIterator2 values_first, OutputIterator1 keys_output, OutputIterator2 values_output, BinaryPredicate binary_pred, BinaryFunction binary_op); 
# 83
}
# 84
}
# 85
}
# 86
}
# 27 "/usr/local/cuda-8.0/include/thrust/scatter.h"
namespace thrust { 
# 89
template< class DerivedPolicy, class 
# 90
InputIterator1, class 
# 91
InputIterator2, class 
# 92
RandomAccessIterator> void 
# 89
scatter(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator1 first, InputIterator1 last, InputIterator2 map, RandomAccessIterator result); 
# 147
template< class InputIterator1, class 
# 148
InputIterator2, class 
# 149
RandomAccessIterator> void 
# 147
scatter(InputIterator1 first, InputIterator1 last, InputIterator2 map, RandomAccessIterator result); 
# 203
template< class DerivedPolicy, class 
# 204
InputIterator1, class 
# 205
InputIterator2, class 
# 206
InputIterator3, class 
# 207
RandomAccessIterator> void 
# 203
scatter_if(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator1 first, InputIterator1 last, InputIterator2 map, InputIterator3 stencil, RandomAccessIterator output); 
# 259
template< class InputIterator1, class 
# 260
InputIterator2, class 
# 261
InputIterator3, class 
# 262
RandomAccessIterator> void 
# 259
scatter_if(InputIterator1 first, InputIterator1 last, InputIterator2 map, InputIterator3 stencil, RandomAccessIterator output); 
# 331
template< class DerivedPolicy, class 
# 332
InputIterator1, class 
# 333
InputIterator2, class 
# 334
InputIterator3, class 
# 335
RandomAccessIterator, class 
# 336
Predicate> void 
# 331
scatter_if(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator1 first, InputIterator1 last, InputIterator2 map, InputIterator3 stencil, RandomAccessIterator output, Predicate pred); 
# 403
template< class InputIterator1, class 
# 404
InputIterator2, class 
# 405
InputIterator3, class 
# 406
RandomAccessIterator, class 
# 407
Predicate> void 
# 403
scatter_if(InputIterator1 first, InputIterator1 last, InputIterator2 map, InputIterator3 stencil, RandomAccessIterator output, Predicate pred); 
# 420
}
# 23 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/scatter.h"
namespace thrust { 
# 25
namespace system { 
# 27
namespace detail { 
# 29
namespace generic { 
# 33
template< class DerivedPolicy, class 
# 34
InputIterator1, class 
# 35
InputIterator2, class 
# 36
RandomAccessIterator> void 
# 33
scatter(execution_policy< DerivedPolicy>  & exec, InputIterator1 first, InputIterator1 last, InputIterator2 map, RandomAccessIterator output); 
# 45
template< class DerivedPolicy, class 
# 46
InputIterator1, class 
# 47
InputIterator2, class 
# 48
InputIterator3, class 
# 49
RandomAccessIterator> void 
# 45
scatter_if(execution_policy< DerivedPolicy>  & exec, InputIterator1 first, InputIterator1 last, InputIterator2 map, InputIterator3 stencil, RandomAccessIterator output); 
# 59
template< class DerivedPolicy, class 
# 60
InputIterator1, class 
# 61
InputIterator2, class 
# 62
InputIterator3, class 
# 63
RandomAccessIterator, class 
# 64
Predicate> void 
# 59
scatter_if(execution_policy< DerivedPolicy>  & exec, InputIterator1 first, InputIterator1 last, InputIterator2 map, InputIterator3 stencil, RandomAccessIterator output, Predicate pred); 
# 75
}
# 76
}
# 77
}
# 78
}
# 24 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/scatter.inl"
namespace thrust { 
# 26
namespace system { 
# 28
namespace detail { 
# 30
namespace generic { 
# 34
template< class DerivedPolicy, class 
# 35
InputIterator1, class 
# 36
InputIterator2, class 
# 37
RandomAccessIterator> void 
# 39
scatter(execution_policy< DerivedPolicy>  &exec, InputIterator1 
# 40
first, InputIterator1 
# 41
last, InputIterator2 
# 42
map, RandomAccessIterator 
# 43
output) 
# 44
{ 
# 45
thrust::transform(exec, first, last, thrust::make_permutation_iterator(output, map), identity< typename iterator_value< InputIterator1> ::type> ()); 
# 50
} 
# 53
template< class DerivedPolicy, class 
# 54
InputIterator1, class 
# 55
InputIterator2, class 
# 56
InputIterator3, class 
# 57
RandomAccessIterator> void 
# 59
scatter_if(execution_policy< DerivedPolicy>  &exec, InputIterator1 
# 60
first, InputIterator1 
# 61
last, InputIterator2 
# 62
map, InputIterator3 
# 63
stencil, RandomAccessIterator 
# 64
output) 
# 65
{ 
# 67
typedef typename iterator_value< InputIterator3> ::type StencilType; 
# 68
thrust::scatter_if(exec, first, last, map, stencil, output, identity< typename iterator_value< InputIterator3> ::type> ()); 
# 69
} 
# 72
template< class DerivedPolicy, class 
# 73
InputIterator1, class 
# 74
InputIterator2, class 
# 75
InputIterator3, class 
# 76
RandomAccessIterator, class 
# 77
Predicate> void 
# 79
scatter_if(execution_policy< DerivedPolicy>  &exec, InputIterator1 
# 80
first, InputIterator1 
# 81
last, InputIterator2 
# 82
map, InputIterator3 
# 83
stencil, RandomAccessIterator 
# 84
output, Predicate 
# 85
pred) 
# 86
{ 
# 87
typedef typename iterator_value< InputIterator1> ::type InputType; 
# 88
thrust::transform_if(exec, first, last, stencil, thrust::make_permutation_iterator(output, map), identity< typename iterator_value< InputIterator1> ::type> (), pred); 
# 89
} 
# 92
}
# 93
}
# 94
}
# 95
}
# 28 "/usr/local/cuda-8.0/include/thrust/detail/scatter.inl"
namespace thrust { 
# 33
template< class DerivedPolicy, class 
# 34
InputIterator1, class 
# 35
InputIterator2, class 
# 36
RandomAccessIterator> void 
# 38
scatter(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator1 
# 39
first, InputIterator1 
# 40
last, InputIterator2 
# 41
map, RandomAccessIterator 
# 42
output) 
# 43
{ 
# 44
using system::detail::generic::scatter;
# 45
return scatter(detail::derived_cast(detail::strip_const(exec)), first, last, map, output); 
# 46
} 
# 50
template< class DerivedPolicy, class 
# 51
InputIterator1, class 
# 52
InputIterator2, class 
# 53
InputIterator3, class 
# 54
RandomAccessIterator> void 
# 56
scatter_if(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator1 
# 57
first, InputIterator1 
# 58
last, InputIterator2 
# 59
map, InputIterator3 
# 60
stencil, RandomAccessIterator 
# 61
output) 
# 62
{ 
# 63
using system::detail::generic::scatter_if;
# 64
return scatter_if(detail::derived_cast(detail::strip_const(exec)), first, last, map, stencil, output); 
# 65
} 
# 69
template< class DerivedPolicy, class 
# 70
InputIterator1, class 
# 71
InputIterator2, class 
# 72
InputIterator3, class 
# 73
RandomAccessIterator, class 
# 74
Predicate> void 
# 76
scatter_if(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator1 
# 77
first, InputIterator1 
# 78
last, InputIterator2 
# 79
map, InputIterator3 
# 80
stencil, RandomAccessIterator 
# 81
output, Predicate 
# 82
pred) 
# 83
{ 
# 84
using system::detail::generic::scatter_if;
# 85
return scatter_if(detail::derived_cast(detail::strip_const(exec)), first, last, map, stencil, output, pred); 
# 86
} 
# 89
template< class InputIterator1, class 
# 90
InputIterator2, class 
# 91
RandomAccessIterator> void 
# 92
scatter(InputIterator1 first, InputIterator1 
# 93
last, InputIterator2 
# 94
map, RandomAccessIterator 
# 95
output) 
# 96
{ 
# 97
using system::detail::generic::select_system;
# 99
typedef typename iterator_system< InputIterator1> ::type System1; 
# 100
typedef typename iterator_system< InputIterator2> ::type System2; 
# 101
typedef typename iterator_system< RandomAccessIterator> ::type System3; 
# 103
System1 system1; 
# 104
System2 system2; 
# 105
System3 system3; 
# 107
return thrust::scatter(select_system(system1, system2, system3), first, last, map, output); 
# 108
} 
# 111
template< class InputIterator1, class 
# 112
InputIterator2, class 
# 113
InputIterator3, class 
# 114
RandomAccessIterator> void 
# 115
scatter_if(InputIterator1 first, InputIterator1 
# 116
last, InputIterator2 
# 117
map, InputIterator3 
# 118
stencil, RandomAccessIterator 
# 119
output) 
# 120
{ 
# 121
using system::detail::generic::select_system;
# 123
typedef typename iterator_system< InputIterator1> ::type System1; 
# 124
typedef typename iterator_system< InputIterator2> ::type System2; 
# 125
typedef typename iterator_system< InputIterator3> ::type System3; 
# 126
typedef typename iterator_system< RandomAccessIterator> ::type System4; 
# 128
System1 system1; 
# 129
System2 system2; 
# 130
System3 system3; 
# 131
System4 system4; 
# 133
return thrust::scatter_if(select_system(system1, system2, system3, system4), first, last, map, stencil, output); 
# 134
} 
# 137
template< class InputIterator1, class 
# 138
InputIterator2, class 
# 139
InputIterator3, class 
# 140
RandomAccessIterator, class 
# 141
Predicate> void 
# 142
scatter_if(InputIterator1 first, InputIterator1 
# 143
last, InputIterator2 
# 144
map, InputIterator3 
# 145
stencil, RandomAccessIterator 
# 146
output, Predicate 
# 147
pred) 
# 148
{ 
# 149
using system::detail::generic::select_system;
# 151
typedef typename iterator_system< InputIterator1> ::type System1; 
# 152
typedef typename iterator_system< InputIterator2> ::type System2; 
# 153
typedef typename iterator_system< InputIterator3> ::type System3; 
# 154
typedef typename iterator_system< RandomAccessIterator> ::type System4; 
# 156
System1 system1; 
# 157
System2 system2; 
# 158
System3 system3; 
# 159
System4 system4; 
# 161
return thrust::scatter_if(select_system(system1, system2, system3, system4), first, last, map, stencil, output, pred); 
# 162
} 
# 165
}
# 27 "/usr/local/cuda-8.0/include/thrust/scan.h"
namespace thrust { 
# 93
template< class DerivedPolicy, class 
# 94
InputIterator, class 
# 95
OutputIterator> OutputIterator 
# 93
inclusive_scan(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator first, InputIterator last, OutputIterator result); 
# 148
template< class InputIterator, class 
# 149
OutputIterator> OutputIterator 
# 148
inclusive_scan(InputIterator first, InputIterator last, OutputIterator result); 
# 203
template< class DerivedPolicy, class 
# 204
InputIterator, class 
# 205
OutputIterator, class 
# 206
AssociativeOperator> OutputIterator 
# 203
inclusive_scan(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator first, InputIterator last, OutputIterator result, AssociativeOperator binary_op); 
# 258
template< class InputIterator, class 
# 259
OutputIterator, class 
# 260
AssociativeOperator> OutputIterator 
# 258
inclusive_scan(InputIterator first, InputIterator last, OutputIterator result, AssociativeOperator binary_op); 
# 313
template< class DerivedPolicy, class 
# 314
InputIterator, class 
# 315
OutputIterator> OutputIterator 
# 313
exclusive_scan(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator first, InputIterator last, OutputIterator result); 
# 362
template< class InputIterator, class 
# 363
OutputIterator> OutputIterator 
# 362
exclusive_scan(InputIterator first, InputIterator last, OutputIterator result); 
# 414
template< class DerivedPolicy, class 
# 415
InputIterator, class 
# 416
OutputIterator, class 
# 417
T> OutputIterator 
# 414
exclusive_scan(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator first, InputIterator last, OutputIterator result, T init); 
# 465
template< class InputIterator, class 
# 466
OutputIterator, class 
# 467
T> OutputIterator 
# 465
exclusive_scan(InputIterator first, InputIterator last, OutputIterator result, T init); 
# 528
template< class DerivedPolicy, class 
# 529
InputIterator, class 
# 530
OutputIterator, class 
# 531
T, class 
# 532
AssociativeOperator> OutputIterator 
# 528
exclusive_scan(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator first, InputIterator last, OutputIterator result, T init, AssociativeOperator binary_op); 
# 589
template< class InputIterator, class 
# 590
OutputIterator, class 
# 591
T, class 
# 592
AssociativeOperator> OutputIterator 
# 589
exclusive_scan(InputIterator first, InputIterator last, OutputIterator result, T init, AssociativeOperator binary_op); 
# 663
template< class DerivedPolicy, class 
# 664
InputIterator1, class 
# 665
InputIterator2, class 
# 666
OutputIterator> OutputIterator 
# 663
inclusive_scan_by_key(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator1 first1, InputIterator1 last1, InputIterator2 first2, OutputIterator result); 
# 725
template< class InputIterator1, class 
# 726
InputIterator2, class 
# 727
OutputIterator> OutputIterator 
# 725
inclusive_scan_by_key(InputIterator1 first1, InputIterator1 last1, InputIterator2 first2, OutputIterator result); 
# 796
template< class DerivedPolicy, class 
# 797
InputIterator1, class 
# 798
InputIterator2, class 
# 799
OutputIterator, class 
# 800
BinaryPredicate> OutputIterator 
# 796
inclusive_scan_by_key(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator1 first1, InputIterator1 last1, InputIterator2 first2, OutputIterator result, BinaryPredicate binary_pred); 
# 865
template< class InputIterator1, class 
# 866
InputIterator2, class 
# 867
OutputIterator, class 
# 868
BinaryPredicate> OutputIterator 
# 865
inclusive_scan_by_key(InputIterator1 first1, InputIterator1 last1, InputIterator2 first2, OutputIterator result, BinaryPredicate binary_pred); 
# 943
template< class DerivedPolicy, class 
# 944
InputIterator1, class 
# 945
InputIterator2, class 
# 946
OutputIterator, class 
# 947
BinaryPredicate, class 
# 948
AssociativeOperator> OutputIterator 
# 943
inclusive_scan_by_key(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator1 first1, InputIterator1 last1, InputIterator2 first2, OutputIterator result, BinaryPredicate binary_pred, AssociativeOperator binary_op); 
# 1019
template< class InputIterator1, class 
# 1020
InputIterator2, class 
# 1021
OutputIterator, class 
# 1022
BinaryPredicate, class 
# 1023
AssociativeOperator> OutputIterator 
# 1019
inclusive_scan_by_key(InputIterator1 first1, InputIterator1 last1, InputIterator2 first2, OutputIterator result, BinaryPredicate binary_pred, AssociativeOperator binary_op); 
# 1079
template< class DerivedPolicy, class 
# 1080
InputIterator1, class 
# 1081
InputIterator2, class 
# 1082
OutputIterator> OutputIterator 
# 1079
exclusive_scan_by_key(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator1 first1, InputIterator1 last1, InputIterator2 first2, OutputIterator result); 
# 1132
template< class InputIterator1, class 
# 1133
InputIterator2, class 
# 1134
OutputIterator> OutputIterator 
# 1132
exclusive_scan_by_key(InputIterator1 first1, InputIterator1 last1, InputIterator2 first2, OutputIterator result); 
# 1187
template< class DerivedPolicy, class 
# 1188
InputIterator1, class 
# 1189
InputIterator2, class 
# 1190
OutputIterator, class 
# 1191
T> OutputIterator 
# 1187
exclusive_scan_by_key(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator1 first1, InputIterator1 last1, InputIterator2 first2, OutputIterator result, T init); 
# 1241
template< class InputIterator1, class 
# 1242
InputIterator2, class 
# 1243
OutputIterator, class 
# 1244
T> OutputIterator 
# 1241
exclusive_scan_by_key(InputIterator1 first1, InputIterator1 last1, InputIterator2 first2, OutputIterator result, T init); 
# 1306
template< class DerivedPolicy, class 
# 1307
InputIterator1, class 
# 1308
InputIterator2, class 
# 1309
OutputIterator, class 
# 1310
T, class 
# 1311
BinaryPredicate> OutputIterator 
# 1306
exclusive_scan_by_key(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator1 first1, InputIterator1 last1, InputIterator2 first2, OutputIterator result, T init, BinaryPredicate binary_pred); 
# 1370
template< class InputIterator1, class 
# 1371
InputIterator2, class 
# 1372
OutputIterator, class 
# 1373
T, class 
# 1374
BinaryPredicate> OutputIterator 
# 1370
exclusive_scan_by_key(InputIterator1 first1, InputIterator1 last1, InputIterator2 first2, OutputIterator result, T init, BinaryPredicate binary_pred); 
# 1455
template< class DerivedPolicy, class 
# 1456
InputIterator1, class 
# 1457
InputIterator2, class 
# 1458
OutputIterator, class 
# 1459
T, class 
# 1460
BinaryPredicate, class 
# 1461
AssociativeOperator> OutputIterator 
# 1455
exclusive_scan_by_key(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator1 first1, InputIterator1 last1, InputIterator2 first2, OutputIterator result, T init, BinaryPredicate binary_pred, AssociativeOperator binary_op); 
# 1538
template< class InputIterator1, class 
# 1539
InputIterator2, class 
# 1540
OutputIterator, class 
# 1541
T, class 
# 1542
BinaryPredicate, class 
# 1543
AssociativeOperator> OutputIterator 
# 1538
exclusive_scan_by_key(InputIterator1 first1, InputIterator1 last1, InputIterator2 first2, OutputIterator result, T init, BinaryPredicate binary_pred, AssociativeOperator binary_op); 
# 1561
}
# 23 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/scan.h"
namespace thrust { 
# 25
namespace system { 
# 27
namespace detail { 
# 29
namespace generic { 
# 33
template< class ExecutionPolicy, class 
# 34
InputIterator, class 
# 35
OutputIterator> OutputIterator 
# 33
inclusive_scan(execution_policy< ExecutionPolicy>  & exec, InputIterator first, InputIterator last, OutputIterator result); 
# 44
template< class ExecutionPolicy, class 
# 45
InputIterator, class 
# 46
OutputIterator, class 
# 47
BinaryFunction> OutputIterator 
# 44
inclusive_scan(execution_policy< ExecutionPolicy>  & exec, InputIterator first, InputIterator last, OutputIterator result, BinaryFunction binary_op); 
# 56
template< class ExecutionPolicy, class 
# 57
InputIterator, class 
# 58
OutputIterator> OutputIterator 
# 56
exclusive_scan(execution_policy< ExecutionPolicy>  & exec, InputIterator first, InputIterator last, OutputIterator result); 
# 66
template< class ExecutionPolicy, class 
# 67
InputIterator, class 
# 68
OutputIterator, class 
# 69
T> OutputIterator 
# 66
exclusive_scan(execution_policy< ExecutionPolicy>  & exec, InputIterator first, InputIterator last, OutputIterator result, T init); 
# 79
template< class ExecutionPolicy, class 
# 80
InputIterator, class 
# 81
OutputIterator, class 
# 82
T, class 
# 83
BinaryFunction> OutputIterator 
# 79
exclusive_scan(execution_policy< ExecutionPolicy>  & exec, InputIterator first, InputIterator last, OutputIterator result, T init, BinaryFunction binary_op); 
# 93
}
# 94
}
# 95
}
# 96
}
# 29 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/scan.inl"
namespace thrust { 
# 31
namespace system { 
# 33
namespace detail { 
# 35
namespace generic { 
# 39
template< class ExecutionPolicy, class 
# 40
InputIterator, class 
# 41
OutputIterator> OutputIterator 
# 43
inclusive_scan(execution_policy< ExecutionPolicy>  &exec, InputIterator 
# 44
first, InputIterator 
# 45
last, OutputIterator 
# 46
result) 
# 47
{ 
# 59
typedef typename thrust::detail::eval_if< thrust::detail::is_output_iterator< OutputIterator> ::value, iterator_value< InputIterator> , iterator_value< OutputIterator> > ::type ValueType; 
# 62
return thrust::inclusive_scan(exec, first, last, result, plus< typename thrust::detail::eval_if< thrust::detail::is_output_iterator< OutputIterator> ::value, iterator_value< InputIterator> , iterator_value< OutputIterator> > ::type> ()); 
# 63
} 
# 66
template< class ExecutionPolicy, class 
# 67
InputIterator, class 
# 68
OutputIterator> OutputIterator 
# 70
exclusive_scan(execution_policy< ExecutionPolicy>  &exec, InputIterator 
# 71
first, InputIterator 
# 72
last, OutputIterator 
# 73
result) 
# 74
{ 
# 86
typedef typename thrust::detail::eval_if< thrust::detail::is_output_iterator< OutputIterator> ::value, iterator_value< InputIterator> , iterator_value< OutputIterator> > ::type ValueType; 
# 89
return thrust::exclusive_scan(exec, first, last, result, (ValueType)0); 
# 90
} 
# 93
template< class ExecutionPolicy, class 
# 94
InputIterator, class 
# 95
OutputIterator, class 
# 96
T> OutputIterator 
# 98
exclusive_scan(execution_policy< ExecutionPolicy>  &exec, InputIterator 
# 99
first, InputIterator 
# 100
last, OutputIterator 
# 101
result, T 
# 102
init) 
# 103
{ 
# 105
return thrust::exclusive_scan(exec, first, last, result, init, plus< T> ()); 
# 106
} 
# 109
template< class ExecutionPolicy, class 
# 110
InputIterator, class 
# 111
OutputIterator, class 
# 112
BinaryFunction> OutputIterator 
# 114
inclusive_scan(execution_policy< ExecutionPolicy>  &exec, InputIterator 
# 115
first, InputIterator 
# 116
last, OutputIterator 
# 117
result, BinaryFunction 
# 118
binary_op) 
# 119
{ 
# 121
typedef thrust::detail::static_assert_test< sizeof(thrust::detail::STATIC_ASSERTION_FAILURE< (bool)(thrust::detail::depend_on_instantiation< InputIterator, false> ::value)> )>  thrust_static_assert_typedef_121 __attribute((unused)); 
# 122
return result; 
# 123
} 
# 126
template< class ExecutionPolicy, class 
# 127
InputIterator, class 
# 128
OutputIterator, class 
# 129
T, class 
# 130
BinaryFunction> OutputIterator 
# 132
exclusive_scan(execution_policy< ExecutionPolicy>  &exec, InputIterator 
# 133
first, InputIterator 
# 134
last, OutputIterator 
# 135
result, T 
# 136
init, BinaryFunction 
# 137
binary_op) 
# 138
{ 
# 140
typedef thrust::detail::static_assert_test< sizeof(thrust::detail::STATIC_ASSERTION_FAILURE< (bool)(thrust::detail::depend_on_instantiation< InputIterator, false> ::value)> )>  thrust_static_assert_typedef_140 __attribute((unused)); 
# 141
return result; 
# 142
} 
# 145
}
# 146
}
# 147
}
# 148
}
# 27 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/scan_by_key.h"
namespace thrust { 
# 29
namespace system { 
# 31
namespace detail { 
# 33
namespace generic { 
# 37
template< class DerivedPolicy, class 
# 38
InputIterator1, class 
# 39
InputIterator2, class 
# 40
OutputIterator> OutputIterator 
# 37
inclusive_scan_by_key(execution_policy< DerivedPolicy>  & exec, InputIterator1 first1, InputIterator1 last1, InputIterator2 first2, OutputIterator result); 
# 49
template< class DerivedPolicy, class 
# 50
InputIterator1, class 
# 51
InputIterator2, class 
# 52
OutputIterator, class 
# 53
BinaryPredicate> OutputIterator 
# 49
inclusive_scan_by_key(execution_policy< DerivedPolicy>  & exec, InputIterator1 first1, InputIterator1 last1, InputIterator2 first2, OutputIterator result, BinaryPredicate binary_pred); 
# 63
template< class DerivedPolicy, class 
# 64
InputIterator1, class 
# 65
InputIterator2, class 
# 66
OutputIterator, class 
# 67
BinaryPredicate, class 
# 68
AssociativeOperator> OutputIterator 
# 63
inclusive_scan_by_key(execution_policy< DerivedPolicy>  & exec, InputIterator1 first1, InputIterator1 last1, InputIterator2 first2, OutputIterator result, BinaryPredicate binary_pred, AssociativeOperator binary_op); 
# 79
template< class DerivedPolicy, class 
# 80
InputIterator1, class 
# 81
InputIterator2, class 
# 82
OutputIterator> OutputIterator 
# 79
exclusive_scan_by_key(execution_policy< DerivedPolicy>  & exec, InputIterator1 first1, InputIterator1 last1, InputIterator2 first2, OutputIterator result); 
# 91
template< class DerivedPolicy, class 
# 92
InputIterator1, class 
# 93
InputIterator2, class 
# 94
OutputIterator, class 
# 95
T> OutputIterator 
# 91
exclusive_scan_by_key(execution_policy< DerivedPolicy>  & exec, InputIterator1 first1, InputIterator1 last1, InputIterator2 first2, OutputIterator result, T init); 
# 105
template< class DerivedPolicy, class 
# 106
InputIterator1, class 
# 107
InputIterator2, class 
# 108
OutputIterator, class 
# 109
T, class 
# 110
BinaryPredicate> OutputIterator 
# 105
exclusive_scan_by_key(execution_policy< DerivedPolicy>  & exec, InputIterator1 first1, InputIterator1 last1, InputIterator2 first2, OutputIterator result, T init, BinaryPredicate binary_pred); 
# 121
template< class DerivedPolicy, class 
# 122
InputIterator1, class 
# 123
InputIterator2, class 
# 124
OutputIterator, class 
# 125
T, class 
# 126
BinaryPredicate, class 
# 127
AssociativeOperator> OutputIterator 
# 121
exclusive_scan_by_key(execution_policy< DerivedPolicy>  & exec, InputIterator1 first1, InputIterator1 last1, InputIterator2 first2, OutputIterator result, T init, BinaryPredicate binary_pred, AssociativeOperator binary_op); 
# 138
}
# 139
}
# 140
}
# 141
}
# 27 "/usr/local/cuda-8.0/include/thrust/replace.h"
namespace thrust { 
# 86
template< class DerivedPolicy, class ForwardIterator, class T> void replace(const detail::execution_policy_base< DerivedPolicy>  & exec, ForwardIterator first, ForwardIterator last, const T & old_value, const T & new_value); 
# 136
template< class ForwardIterator, class T> void replace(ForwardIterator first, ForwardIterator last, const T & old_value, const T & new_value); 
# 200
template< class DerivedPolicy, class ForwardIterator, class Predicate, class T> void replace_if(const detail::execution_policy_base< DerivedPolicy>  & exec, ForwardIterator first, ForwardIterator last, Predicate pred, const T & new_value); 
# 261
template< class ForwardIterator, class Predicate, class T> void replace_if(ForwardIterator first, ForwardIterator last, Predicate pred, const T & new_value); 
# 334
template< class DerivedPolicy, class ForwardIterator, class InputIterator, class Predicate, class T> void replace_if(const detail::execution_policy_base< DerivedPolicy>  & exec, ForwardIterator first, ForwardIterator last, InputIterator stencil, Predicate pred, const T & new_value); 
# 404
template< class ForwardIterator, class InputIterator, class Predicate, class T> void replace_if(ForwardIterator first, ForwardIterator last, InputIterator stencil, Predicate pred, const T & new_value); 
# 463
template< class DerivedPolicy, class InputIterator, class OutputIterator, class T> OutputIterator replace_copy(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator first, InputIterator last, OutputIterator result, const T & old_value, const T & new_value); 
# 519
template< class InputIterator, class OutputIterator, class T> OutputIterator replace_copy(InputIterator first, InputIterator last, OutputIterator result, const T & old_value, const T & new_value); 
# 588
template< class DerivedPolicy, class InputIterator, class OutputIterator, class Predicate, class T> OutputIterator replace_copy_if(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator first, InputIterator last, OutputIterator result, Predicate pred, const T & new_value); 
# 655
template< class InputIterator, class OutputIterator, class Predicate, class T> OutputIterator replace_copy_if(InputIterator first, InputIterator last, OutputIterator result, Predicate pred, const T & new_value); 
# 732
template< class DerivedPolicy, class InputIterator1, class InputIterator2, class OutputIterator, class Predicate, class T> OutputIterator replace_copy_if(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator1 first, InputIterator1 last, InputIterator2 stencil, OutputIterator result, Predicate pred, const T & new_value); 
# 807
template< class InputIterator1, class InputIterator2, class OutputIterator, class Predicate, class T> OutputIterator replace_copy_if(InputIterator1 first, InputIterator1 last, InputIterator2 stencil, OutputIterator result, Predicate pred, const T & new_value); 
# 820
}
# 23 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/replace.h"
namespace thrust { 
# 25
namespace system { 
# 27
namespace detail { 
# 29
namespace generic { 
# 33
template< class DerivedPolicy, class InputIterator, class OutputIterator, class Predicate, class T> OutputIterator replace_copy_if(execution_policy< DerivedPolicy>  & exec, InputIterator first, InputIterator last, OutputIterator result, Predicate pred, const T & new_value); 
# 43
template< class DerivedPolicy, class InputIterator1, class InputIterator2, class OutputIterator, class Predicate, class T> OutputIterator replace_copy_if(execution_policy< DerivedPolicy>  & exec, InputIterator1 first, InputIterator1 last, InputIterator2 stencil, OutputIterator result, Predicate pred, const T & new_value); 
# 54
template< class DerivedPolicy, class InputIterator, class OutputIterator, class T> OutputIterator replace_copy(execution_policy< DerivedPolicy>  & exec, InputIterator first, InputIterator last, OutputIterator result, const T & old_value, const T & new_value); 
# 64
template< class DerivedPolicy, class ForwardIterator, class Predicate, class T> void replace_if(execution_policy< DerivedPolicy>  & exec, ForwardIterator first, ForwardIterator last, Predicate pred, const T & new_value); 
# 73
template< class DerivedPolicy, class ForwardIterator, class InputIterator, class Predicate, class T> void replace_if(execution_policy< DerivedPolicy>  & exec, ForwardIterator first, ForwardIterator last, InputIterator stencil, Predicate pred, const T & new_value); 
# 83
template< class DerivedPolicy, class ForwardIterator, class T> void replace(execution_policy< DerivedPolicy>  & exec, ForwardIterator first, ForwardIterator last, const T & old_value, const T & new_value); 
# 92
}
# 93
}
# 94
}
# 95
}
# 23 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/replace.inl"
namespace thrust { 
# 25
namespace system { 
# 27
namespace detail { 
# 29
namespace generic { 
# 31
namespace detail { 
# 37
template< class Predicate, class NewType, class OutputType> 
# 38
struct new_value_if { 
# 41
new_value_if(Predicate p, NewType nv) : pred(p), new_value(nv) { } 
# 43
template< class InputType> OutputType 
# 45
operator()(const InputType &x) const 
# 46
{ 
# 47
return ((pred)(x)) ? new_value : x; 
# 48
} 
# 52
template< class InputType, class PredicateArgumentType> OutputType 
# 54
operator()(const InputType &x, const PredicateArgumentType &y) 
# 55
{ 
# 56
return ((pred)(y)) ? new_value : x; 
# 57
} 
# 59
Predicate pred; 
# 60
NewType new_value; 
# 61
}; 
# 65
template< class T> 
# 66
struct constant_unary { 
# 69
constant_unary(T _c) : c(_c) { } 
# 71
template< class U> T 
# 73
operator()(U &x) 
# 74
{ 
# 75
return c; 
# 76
} 
# 78
T c; 
# 79
}; 
# 82
}
# 85
template< class DerivedPolicy, class InputIterator, class OutputIterator, class Predicate, class T> OutputIterator 
# 87
replace_copy_if(execution_policy< DerivedPolicy>  &exec, InputIterator 
# 88
first, InputIterator 
# 89
last, OutputIterator 
# 90
result, Predicate 
# 91
pred, const T &
# 92
new_value) 
# 93
{ 
# 94
typedef typename iterator_traits< OutputIterator> ::value_type OutputType; 
# 96
detail::new_value_if< Predicate, T, typename iterator_traits< OutputIterator> ::value_type>  op(pred, new_value); 
# 97
return thrust::transform(exec, first, last, result, op); 
# 98
} 
# 101
template< class DerivedPolicy, class InputIterator1, class InputIterator2, class OutputIterator, class Predicate, class T> OutputIterator 
# 103
replace_copy_if(execution_policy< DerivedPolicy>  &exec, InputIterator1 
# 104
first, InputIterator1 
# 105
last, InputIterator2 
# 106
stencil, OutputIterator 
# 107
result, Predicate 
# 108
pred, const T &
# 109
new_value) 
# 110
{ 
# 111
typedef typename iterator_traits< OutputIterator> ::value_type OutputType; 
# 113
detail::new_value_if< Predicate, T, typename iterator_traits< OutputIterator> ::value_type>  op(pred, new_value); 
# 114
return thrust::transform(exec, first, last, stencil, result, op); 
# 115
} 
# 118
template< class DerivedPolicy, class InputIterator, class OutputIterator, class T> OutputIterator 
# 120
replace_copy(execution_policy< DerivedPolicy>  &exec, InputIterator 
# 121
first, InputIterator 
# 122
last, OutputIterator 
# 123
result, const T &
# 124
old_value, const T &
# 125
new_value) 
# 126
{ 
# 127
thrust::detail::equal_to_value< T>  pred(old_value); 
# 128
return thrust::replace_copy_if(exec, first, last, result, pred, new_value); 
# 129
} 
# 132
template< class DerivedPolicy, class ForwardIterator, class Predicate, class T> void 
# 134
replace_if(execution_policy< DerivedPolicy>  &exec, ForwardIterator 
# 135
first, ForwardIterator 
# 136
last, Predicate 
# 137
pred, const T &
# 138
new_value) 
# 139
{ 
# 140
detail::constant_unary< T>  f(new_value); 
# 141
thrust::transform_if(exec, first, last, first, first, f, pred); 
# 142
} 
# 145
template< class DerivedPolicy, class ForwardIterator, class InputIterator, class Predicate, class T> void 
# 147
replace_if(execution_policy< DerivedPolicy>  &exec, ForwardIterator 
# 148
first, ForwardIterator 
# 149
last, InputIterator 
# 150
stencil, Predicate 
# 151
pred, const T &
# 152
new_value) 
# 153
{ 
# 154
detail::constant_unary< T>  f(new_value); 
# 155
thrust::transform_if(exec, first, last, stencil, first, f, pred); 
# 156
} 
# 159
template< class DerivedPolicy, class ForwardIterator, class T> void 
# 161
replace(execution_policy< DerivedPolicy>  &exec, ForwardIterator 
# 162
first, ForwardIterator 
# 163
last, const T &
# 164
old_value, const T &
# 165
new_value) 
# 166
{ 
# 167
thrust::detail::equal_to_value< T>  pred(old_value); 
# 168
return thrust::replace_if(exec, first, last, pred, new_value); 
# 169
} 
# 172
}
# 173
}
# 174
}
# 175
}
# 29 "/usr/local/cuda-8.0/include/thrust/detail/replace.inl"
namespace thrust { 
# 34
template< class DerivedPolicy, class ForwardIterator, class T> void 
# 36
replace(const detail::execution_policy_base< DerivedPolicy>  &exec, ForwardIterator 
# 37
first, ForwardIterator last, const T &
# 38
old_value, const T &
# 39
new_value) 
# 40
{ 
# 41
using system::detail::generic::replace;
# 42
return replace(detail::derived_cast(detail::strip_const(exec)), first, last, old_value, new_value); 
# 43
} 
# 47
template< class DerivedPolicy, class ForwardIterator, class Predicate, class T> void 
# 49
replace_if(const detail::execution_policy_base< DerivedPolicy>  &exec, ForwardIterator 
# 50
first, ForwardIterator last, Predicate 
# 51
pred, const T &
# 52
new_value) 
# 53
{ 
# 54
using system::detail::generic::replace_if;
# 55
return replace_if(detail::derived_cast(detail::strip_const(exec)), first, last, pred, new_value); 
# 56
} 
# 60
template< class DerivedPolicy, class ForwardIterator, class InputIterator, class Predicate, class T> void 
# 62
replace_if(const detail::execution_policy_base< DerivedPolicy>  &exec, ForwardIterator 
# 63
first, ForwardIterator last, InputIterator 
# 64
stencil, Predicate 
# 65
pred, const T &
# 66
new_value) 
# 67
{ 
# 68
using system::detail::generic::replace_if;
# 69
return replace_if(detail::derived_cast(detail::strip_const(exec)), first, last, stencil, pred, new_value); 
# 70
} 
# 74
template< class DerivedPolicy, class InputIterator, class OutputIterator, class T> OutputIterator 
# 76
replace_copy(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator 
# 77
first, InputIterator last, OutputIterator 
# 78
result, const T &
# 79
old_value, const T &
# 80
new_value) 
# 81
{ 
# 82
using system::detail::generic::replace_copy;
# 83
return replace_copy(detail::derived_cast(detail::strip_const(exec)), first, last, result, old_value, new_value); 
# 84
} 
# 88
template< class DerivedPolicy, class InputIterator, class OutputIterator, class Predicate, class T> OutputIterator 
# 90
replace_copy_if(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator 
# 91
first, InputIterator last, OutputIterator 
# 92
result, Predicate 
# 93
pred, const T &
# 94
new_value) 
# 95
{ 
# 96
using system::detail::generic::replace_copy_if;
# 97
return replace_copy_if(detail::derived_cast(detail::strip_const(exec)), first, last, result, pred, new_value); 
# 98
} 
# 102
template< class DerivedPolicy, class InputIterator1, class InputIterator2, class OutputIterator, class Predicate, class T> OutputIterator 
# 104
replace_copy_if(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator1 
# 105
first, InputIterator1 last, InputIterator2 
# 106
stencil, OutputIterator 
# 107
result, Predicate 
# 108
pred, const T &
# 109
new_value) 
# 110
{ 
# 111
using system::detail::generic::replace_copy_if;
# 112
return replace_copy_if(detail::derived_cast(detail::strip_const(exec)), first, last, stencil, result, pred, new_value); 
# 113
} 
# 116
template< class InputIterator, class OutputIterator, class Predicate, class T> OutputIterator 
# 117
replace_copy_if(InputIterator first, InputIterator last, OutputIterator 
# 118
result, Predicate 
# 119
pred, const T &
# 120
new_value) 
# 121
{ 
# 122
using system::detail::generic::select_system;
# 124
typedef typename iterator_system< InputIterator> ::type System1; 
# 125
typedef typename iterator_system< OutputIterator> ::type System2; 
# 127
System1 system1; 
# 128
System2 system2; 
# 130
return thrust::replace_copy_if(select_system(system1, system2), first, last, result, pred, new_value); 
# 131
} 
# 134
template< class InputIterator1, class InputIterator2, class OutputIterator, class Predicate, class T> OutputIterator 
# 135
replace_copy_if(InputIterator1 first, InputIterator1 last, InputIterator2 
# 136
stencil, OutputIterator 
# 137
result, Predicate 
# 138
pred, const T &
# 139
new_value) 
# 140
{ 
# 141
using system::detail::generic::select_system;
# 143
typedef typename iterator_system< InputIterator1> ::type System1; 
# 144
typedef typename iterator_system< InputIterator2> ::type System2; 
# 145
typedef typename iterator_system< OutputIterator> ::type System3; 
# 147
System1 system1; 
# 148
System2 system2; 
# 149
System3 system3; 
# 151
return thrust::replace_copy_if(select_system(system1, system2, system3), first, last, stencil, result, pred, new_value); 
# 152
} 
# 155
template< class InputIterator, class OutputIterator, class T> OutputIterator 
# 156
replace_copy(InputIterator first, InputIterator last, OutputIterator 
# 157
result, const T &
# 158
old_value, const T &
# 159
new_value) 
# 160
{ 
# 161
using system::detail::generic::select_system;
# 163
typedef typename iterator_system< InputIterator> ::type System1; 
# 164
typedef typename iterator_system< OutputIterator> ::type System2; 
# 166
System1 system1; 
# 167
System2 system2; 
# 169
return thrust::replace_copy(select_system(system1, system2), first, last, result, old_value, new_value); 
# 170
} 
# 173
template< class ForwardIterator, class Predicate, class T> void 
# 174
replace_if(ForwardIterator first, ForwardIterator last, Predicate 
# 175
pred, const T &
# 176
new_value) 
# 177
{ 
# 178
using thrust::system::detail::generic::select_system;
# 180
typedef typename iterator_system< ForwardIterator> ::type System; 
# 182
System system; 
# 184
return thrust::replace_if(select_system(system), first, last, pred, new_value); 
# 185
} 
# 188
template< class ForwardIterator, class InputIterator, class Predicate, class T> void 
# 189
replace_if(ForwardIterator first, ForwardIterator last, InputIterator 
# 190
stencil, Predicate 
# 191
pred, const T &
# 192
new_value) 
# 193
{ 
# 194
using system::detail::generic::select_system;
# 196
typedef typename iterator_system< ForwardIterator> ::type System1; 
# 197
typedef typename iterator_system< InputIterator> ::type System2; 
# 199
System1 system1; 
# 200
System2 system2; 
# 202
return thrust::replace_if(select_system(system1, system2), first, last, stencil, pred, new_value); 
# 203
} 
# 206
template< class ForwardIterator, class T> void 
# 207
replace(ForwardIterator first, ForwardIterator last, const T &
# 208
old_value, const T &
# 209
new_value) 
# 210
{ 
# 211
using thrust::system::detail::generic::select_system;
# 213
typedef typename iterator_system< ForwardIterator> ::type System; 
# 215
System system; 
# 217
return thrust::replace(select_system(system), first, last, old_value, new_value); 
# 218
} 
# 221
}
# 29 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/scan_by_key.inl"
namespace thrust { 
# 31
namespace system { 
# 33
namespace detail { 
# 35
namespace generic { 
# 37
namespace detail { 
# 41
template< class OutputType, class HeadFlagType, class AssociativeOperator> 
# 42
struct segmented_scan_functor { 
# 44
AssociativeOperator binary_op; 
# 46
typedef tuple< OutputType, HeadFlagType, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type>  result_type; 
# 49
segmented_scan_functor(AssociativeOperator _binary_op) : binary_op(_binary_op) { } 
# 52
result_type operator()(result_type a, result_type b) 
# 53
{ 
# 54
return result_type((thrust::get< 1> (b)) ? thrust::get< 0> (b) : (binary_op)(thrust::get< 0> (a), thrust::get< 0> (b)), thrust::get< 1> (a) | thrust::get< 1> (b)); 
# 56
} 
# 57
}; 
# 60
}
# 63
template< class DerivedPolicy, class 
# 64
InputIterator1, class 
# 65
InputIterator2, class 
# 66
OutputIterator> OutputIterator 
# 68
inclusive_scan_by_key(execution_policy< DerivedPolicy>  &exec, InputIterator1 
# 69
first1, InputIterator1 
# 70
last1, InputIterator2 
# 71
first2, OutputIterator 
# 72
result) 
# 73
{ 
# 74
typedef typename iterator_traits< InputIterator1> ::value_type InputType1; 
# 75
return thrust::inclusive_scan_by_key(exec, first1, last1, first2, result, equal_to< typename iterator_traits< InputIterator1> ::value_type> ()); 
# 76
} 
# 79
template< class DerivedPolicy, class 
# 80
InputIterator1, class 
# 81
InputIterator2, class 
# 82
OutputIterator, class 
# 83
BinaryPredicate> OutputIterator 
# 85
inclusive_scan_by_key(execution_policy< DerivedPolicy>  &exec, InputIterator1 
# 86
first1, InputIterator1 
# 87
last1, InputIterator2 
# 88
first2, OutputIterator 
# 89
result, BinaryPredicate 
# 90
binary_pred) 
# 91
{ 
# 92
typedef typename iterator_traits< OutputIterator> ::value_type OutputType; 
# 93
return thrust::inclusive_scan_by_key(exec, first1, last1, first2, result, binary_pred, plus< typename iterator_traits< OutputIterator> ::value_type> ()); 
# 94
} 
# 97
template< class DerivedPolicy, class 
# 98
InputIterator1, class 
# 99
InputIterator2, class 
# 100
OutputIterator, class 
# 101
BinaryPredicate, class 
# 102
AssociativeOperator> OutputIterator 
# 104
inclusive_scan_by_key(execution_policy< DerivedPolicy>  &exec, InputIterator1 
# 105
first1, InputIterator1 
# 106
last1, InputIterator2 
# 107
first2, OutputIterator 
# 108
result, BinaryPredicate 
# 109
binary_pred, AssociativeOperator 
# 110
binary_op) 
# 111
{ 
# 112
typedef typename iterator_traits< OutputIterator> ::value_type OutputType; 
# 113
typedef unsigned HeadFlagType; 
# 115
const size_t n = last1 - first1; 
# 117
if (n != (0)) 
# 118
{ 
# 120
thrust::detail::temporary_array< unsigned, DerivedPolicy>  flags(exec, n); 
# 121
(flags[0]) = 1; thrust::transform(exec, first1, last1 - 1, first1 + 1, (flags.begin()) + 1, thrust::detail::not2(binary_pred)); 
# 128
thrust::inclusive_scan(exec, thrust::make_zip_iterator(thrust::make_tuple(first2, (flags.begin()))), thrust::make_zip_iterator(thrust::make_tuple(first2, (flags.begin()))) + n, thrust::make_zip_iterator(thrust::make_tuple(result, (flags.begin()))), ((detail::segmented_scan_functor< typename iterator_traits< OutputIterator> ::value_type, unsigned, AssociativeOperator> )(binary_op))); 
# 133
}  
# 135
return result + n; 
# 136
} 
# 139
template< class DerivedPolicy, class 
# 140
InputIterator1, class 
# 141
InputIterator2, class 
# 142
OutputIterator> OutputIterator 
# 144
exclusive_scan_by_key(execution_policy< DerivedPolicy>  &exec, InputIterator1 
# 145
first1, InputIterator1 
# 146
last1, InputIterator2 
# 147
first2, OutputIterator 
# 148
result) 
# 149
{ 
# 150
typedef typename iterator_traits< OutputIterator> ::value_type OutputType; 
# 151
return thrust::exclusive_scan_by_key(exec, first1, last1, first2, result, (OutputType)0); 
# 152
} 
# 155
template< class DerivedPolicy, class 
# 156
InputIterator1, class 
# 157
InputIterator2, class 
# 158
OutputIterator, class 
# 159
T> OutputIterator 
# 161
exclusive_scan_by_key(execution_policy< DerivedPolicy>  &exec, InputIterator1 
# 162
first1, InputIterator1 
# 163
last1, InputIterator2 
# 164
first2, OutputIterator 
# 165
result, T 
# 166
init) 
# 167
{ 
# 168
typedef typename iterator_traits< InputIterator1> ::value_type InputType1; 
# 169
return thrust::exclusive_scan_by_key(exec, first1, last1, first2, result, init, equal_to< typename iterator_traits< InputIterator1> ::value_type> ()); 
# 170
} 
# 173
template< class DerivedPolicy, class 
# 174
InputIterator1, class 
# 175
InputIterator2, class 
# 176
OutputIterator, class 
# 177
T, class 
# 178
BinaryPredicate> OutputIterator 
# 180
exclusive_scan_by_key(execution_policy< DerivedPolicy>  &exec, InputIterator1 
# 181
first1, InputIterator1 
# 182
last1, InputIterator2 
# 183
first2, OutputIterator 
# 184
result, T 
# 185
init, BinaryPredicate 
# 186
binary_pred) 
# 187
{ 
# 188
typedef typename iterator_traits< OutputIterator> ::value_type OutputType; 
# 189
return thrust::exclusive_scan_by_key(exec, first1, last1, first2, result, init, binary_pred, plus< typename iterator_traits< OutputIterator> ::value_type> ()); 
# 190
} 
# 193
template< class DerivedPolicy, class 
# 194
InputIterator1, class 
# 195
InputIterator2, class 
# 196
OutputIterator, class 
# 197
T, class 
# 198
BinaryPredicate, class 
# 199
AssociativeOperator> OutputIterator 
# 201
exclusive_scan_by_key(execution_policy< DerivedPolicy>  &exec, InputIterator1 
# 202
first1, InputIterator1 
# 203
last1, InputIterator2 
# 204
first2, OutputIterator 
# 205
result, T 
# 206
init, BinaryPredicate 
# 207
binary_pred, AssociativeOperator 
# 208
binary_op) 
# 209
{ 
# 210
typedef typename iterator_traits< OutputIterator> ::value_type OutputType; 
# 211
typedef unsigned HeadFlagType; 
# 213
const size_t n = last1 - first1; 
# 215
if (n != (0)) 
# 216
{ 
# 217
InputIterator2 last2 = first2 + n; 
# 220
thrust::detail::temporary_array< unsigned, DerivedPolicy>  flags(exec, n); 
# 221
(flags[0]) = 1; thrust::transform(exec, first1, last1 - 1, first1 + 1, (flags.begin()) + 1, thrust::detail::not2(binary_pred)); 
# 224
thrust::detail::temporary_array< typename iterator_traits< OutputIterator> ::value_type, DerivedPolicy>  temp(exec, n); 
# 225
thrust::replace_copy_if(exec, first2, last2 - 1, (flags.begin()) + 1, (temp.begin()) + 1, negate< unsigned> (), init); 
# 226
(temp[0]) = init; 
# 233
thrust::inclusive_scan(exec, thrust::make_zip_iterator(thrust::make_tuple((temp.begin()), (flags.begin()))), thrust::make_zip_iterator(thrust::make_tuple((temp.begin()), (flags.begin()))) + n, thrust::make_zip_iterator(thrust::make_tuple(result, (flags.begin()))), ((detail::segmented_scan_functor< typename iterator_traits< OutputIterator> ::value_type, unsigned, AssociativeOperator> )(binary_op))); 
# 238
}  
# 240
return result + n; 
# 241
} 
# 244
}
# 245
}
# 246
}
# 247
}
# 32 "/usr/local/cuda-8.0/include/thrust/system/detail/sequential/scan.h"
namespace thrust { 
# 34
namespace system { 
# 36
namespace detail { 
# 38
namespace sequential { 
# 43
template< class DerivedPolicy, class 
# 44
InputIterator, class 
# 45
OutputIterator, class 
# 46
BinaryFunction> OutputIterator 
# 48
inclusive_scan(execution_policy< DerivedPolicy>  &, InputIterator 
# 49
first, InputIterator 
# 50
last, OutputIterator 
# 51
result, BinaryFunction 
# 52
binary_op) 
# 53
{ 
# 66
using namespace thrust::detail;
# 76
typedef typename thrust::detail::eval_if< thrust::detail::has_result_type< BinaryFunction> ::value, thrust::detail::result_type< BinaryFunction> , thrust::detail::eval_if< thrust::detail::is_output_iterator< OutputIterator> ::value, iterator_value< InputIterator> , iterator_value< OutputIterator> > > ::type ValueType; 
# 82
thrust::detail::wrapped_function< BinaryFunction, typename thrust::detail::eval_if< thrust::detail::has_result_type< BinaryFunction> ::value, thrust::detail::result_type< BinaryFunction> , thrust::detail::eval_if< thrust::detail::is_output_iterator< OutputIterator> ::value, iterator_value< InputIterator> , iterator_value< OutputIterator> > > ::type>  wrapped_binary_op(binary_op); 
# 84
if (first != last) 
# 85
{ 
# 86
ValueType sum = *first; 
# 88
(*result) = sum; 
# 90
for ((++first), (++result); first != last; (++first), (++result)) { 
# 91
(*result) = (sum = wrapped_binary_op(sum, *first)); }  
# 92
}  
# 94
return result; 
# 95
} 
# 99
template< class DerivedPolicy, class 
# 100
InputIterator, class 
# 101
OutputIterator, class 
# 102
T, class 
# 103
BinaryFunction> OutputIterator 
# 105
exclusive_scan(execution_policy< DerivedPolicy>  &, InputIterator 
# 106
first, InputIterator 
# 107
last, OutputIterator 
# 108
result, T 
# 109
init, BinaryFunction 
# 110
binary_op) 
# 111
{ 
# 124
using namespace thrust::detail;
# 134
typedef typename thrust::detail::eval_if< thrust::detail::has_result_type< BinaryFunction> ::value, thrust::detail::result_type< BinaryFunction> , thrust::detail::eval_if< thrust::detail::is_output_iterator< OutputIterator> ::value, iterator_value< InputIterator> , iterator_value< OutputIterator> > > ::type ValueType; 
# 136
if (first != last) 
# 137
{ 
# 138
ValueType tmp = *first; 
# 139
ValueType sum = init; 
# 141
(*result) = sum; 
# 142
sum = binary_op(sum, tmp); 
# 144
for ((++first), (++result); first != last; (++first), (++result)) 
# 145
{ 
# 146
tmp = (*first); 
# 147
(*result) = sum; 
# 148
sum = binary_op(sum, tmp); 
# 149
}  
# 150
}  
# 152
return result; 
# 153
} 
# 156
}
# 157
}
# 158
}
# 159
}
# 27 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/scan.h"
namespace thrust { 
# 29
namespace system { 
# 31
namespace cuda { 
# 33
namespace detail { 
# 37
template< class DerivedPolicy, class 
# 38
InputIterator, class 
# 39
OutputIterator, class 
# 40
AssociativeOperator> OutputIterator 
# 37
inclusive_scan(execution_policy< DerivedPolicy>  & exec, InputIterator first, InputIterator last, OutputIterator result, AssociativeOperator binary_op); 
# 49
template< class DerivedPolicy, class 
# 50
InputIterator, class 
# 51
OutputIterator, class 
# 52
T, class 
# 53
AssociativeOperator> OutputIterator 
# 49
exclusive_scan(execution_policy< DerivedPolicy>  & exec, InputIterator first, InputIterator last, OutputIterator result, T init, AssociativeOperator binary_op); 
# 63
}
# 64
}
# 65
}
# 66
}
# 22 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/decomposition.h"
namespace thrust { 
# 24
namespace system { 
# 26
namespace cuda { 
# 28
namespace detail { 
# 32
template< class Size> 
# 33
class trivial_decomposition { 
# 36
public: typedef Size size_type; 
# 38
typedef pair< Size, Size>  range; 
# 41
trivial_decomposition() : m_n(0) 
# 43
{ } 
# 46
trivial_decomposition(size_type n) : m_n(n) 
# 48
{ } 
# 51
range operator[](size_type) const 
# 52
{ 
# 53
return range(0, n()); 
# 54
} 
# 57
size_type size() const 
# 58
{ 
# 59
return 1; 
# 60
} 
# 64
size_type n() const 
# 65
{ 
# 66
return m_n; 
# 67
} 
# 70
private: Size m_n; 
# 71
}; 
# 74
template< class Size> trivial_decomposition< Size>  
# 76
make_trivial_decomposition(Size n) 
# 77
{ 
# 78
return ((trivial_decomposition< Size> )(n)); 
# 79
} 
# 82
template< class Size> 
# 83
class blocked_decomposition { 
# 86
public: typedef Size size_type; 
# 88
typedef pair< Size, Size>  range; 
# 91
blocked_decomposition() : m_n(0), m_block_size(0), m_num_partitions(0) 
# 95
{ } 
# 98
blocked_decomposition(size_type n, Size block_size) : m_n(n), m_block_size(block_size), m_num_partitions(((n + block_size) - 1) / block_size) 
# 102
{ } 
# 105
range operator[](size_type i) const 
# 106
{ 
# 107
size_type first = i * (m_block_size); 
# 108
size_type last = thrust::min(m_n, first + (m_block_size)); 
# 110
return range(first, last); 
# 111
} 
# 114
size_type size() const 
# 115
{ 
# 116
return m_num_partitions; 
# 117
} 
# 121
size_type n() const 
# 122
{ 
# 123
return m_n; 
# 124
} 
# 127
private: Size m_n; 
# 128
Size m_block_size; 
# 129
Size m_num_partitions; 
# 130
}; 
# 133
template< class Size> blocked_decomposition< Size>  
# 135
make_blocked_decomposition(Size n, Size block_size) 
# 136
{ 
# 137
return blocked_decomposition< Size> (n, block_size); 
# 138
} 
# 141
template< class Size> 
# 142
class uniform_decomposition : public blocked_decomposition< Size>  { 
# 146
typedef ::thrust::system::cuda::detail::blocked_decomposition< Size>  super_t; 
# 150
public: uniform_decomposition() : super_t() 
# 152
{ } 
# 155
uniform_decomposition(Size n, Size num_partitions) : super_t(n, n / num_partitions) 
# 157
{ } 
# 158
}; 
# 161
template< class Size> uniform_decomposition< Size>  
# 163
make_uniform_decomposition(Size n, Size num_partitions) 
# 164
{ 
# 165
return uniform_decomposition< Size> (n, num_partitions); 
# 166
} 
# 169
template< class Size> 
# 170
class aligned_decomposition { 
# 173
public: typedef Size size_type; 
# 175
typedef pair< Size, Size>  range; 
# 178
aligned_decomposition() : m_n(0), m_num_partitions(0), m_tile_size(0) 
# 182
{ } 
# 185
aligned_decomposition(Size n, Size num_partitions, Size aligned_size) : m_n(n), m_num_partitions(num_partitions), m_tile_size(aligned_size) 
# 189
{ 
# 190
size_type num_tiles = ((n + (m_tile_size)) - 1) / (m_tile_size); 
# 192
(m_num_tiles_per_partition) = (num_tiles / size()); 
# 193
(m_last_partial_tile_size) = (num_tiles % size()); 
# 194
} 
# 197
range operator[](Size i) const 
# 198
{ 
# 199
range result = range_in_tiles(i); 
# 200
(result.first) *= (m_tile_size); 
# 201
(result.second) = thrust::min< size_type> (m_n, (result.second) * (m_tile_size)); 
# 202
return result; 
# 203
} 
# 206
size_type size() const 
# 207
{ 
# 208
return m_num_partitions; 
# 209
} 
# 213
size_type n() const 
# 214
{ 
# 215
return m_n; 
# 216
} 
# 220
private: range range_in_tiles(size_type i) const 
# 221
{ 
# 222
range result; 
# 224
(result.first) = ((m_num_tiles_per_partition) * i); 
# 225
(result.first) += thrust::min< size_type> (i, m_last_partial_tile_size); 
# 227
(result.second) = (((result.first) + (m_num_tiles_per_partition)) + (i < (m_last_partial_tile_size))); 
# 229
return result; 
# 230
} 
# 232
size_type m_n; 
# 233
size_type m_num_partitions; 
# 234
size_type m_num_tiles_per_partition; 
# 235
size_type m_tile_size; 
# 236
size_type m_last_partial_tile_size; 
# 237
}; 
# 240
template< class Size> aligned_decomposition< Size>  
# 242
make_aligned_decomposition(Size n, Size num_partitions, Size aligned_size) 
# 243
{ 
# 244
return aligned_decomposition< Size> (n, num_partitions, aligned_size); 
# 245
} 
# 248
}
# 249
}
# 250
}
# 251
}
# 31 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/scan.inl"
namespace thrust { 
# 33
namespace system { 
# 35
namespace cuda { 
# 37
namespace detail { 
# 39
namespace scan_detail { 
# 43
struct inclusive_scan_n { 
# 45
template< class ConcurrentGroup, class InputIterator, class Size, class OutputIterator, class T, class BinaryFunction> void 
# 46
operator()(ConcurrentGroup &this_group, InputIterator first, Size n, OutputIterator result, T init, BinaryFunction binary_op) 
# 47
{int volatile ___ = 1;(void)this_group;(void)first;(void)n;(void)result;(void)init;(void)binary_op;
# 49
::exit(___);}
#if 0
# 47
{ 
# 48
bulk_::inclusive_scan(this_group, first, first + n, result, init, binary_op); 
# 49
} 
#endif
# 52 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/scan.inl"
template< class ConcurrentGroup, class InputIterator, class Size, class OutputIterator, class BinaryFunction> void 
# 53
operator()(ConcurrentGroup &this_group, InputIterator first, Size n, OutputIterator result, BinaryFunction binary_op) 
# 54
{int volatile ___ = 1;(void)this_group;(void)first;(void)n;(void)result;(void)binary_op;
# 56
::exit(___);}
#if 0
# 54
{ 
# 55
bulk_::inclusive_scan(this_group, first, first + n, result, binary_op); 
# 56
} 
#endif
# 57 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/scan.inl"
}; 
# 60
struct exclusive_scan_n { 
# 62
template< class ConcurrentGroup, class InputIterator, class Size, class OutputIterator, class T, class BinaryFunction> void 
# 63
operator()(ConcurrentGroup &this_group, InputIterator first, Size n, OutputIterator result, T init, BinaryFunction binary_op) 
# 64
{int volatile ___ = 1;(void)this_group;(void)first;(void)n;(void)result;(void)init;(void)binary_op;
# 66
::exit(___);}
#if 0
# 64
{ 
# 65
bulk_::exclusive_scan(this_group, first, first + n, result, init, binary_op); 
# 66
} 
#endif
# 67 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/scan.inl"
}; 
# 70
struct inclusive_downsweep { 
# 72
template< class ConcurrentGroup, class RandomAccessIterator1, class Decomposition, class RandomAccessIterator2, class RandomAccessIterator3, class BinaryFunction> void 
# 73
operator()(ConcurrentGroup &this_group, RandomAccessIterator1 
# 74
first, Decomposition 
# 75
decomp, RandomAccessIterator2 
# 76
carries_first, RandomAccessIterator3 
# 77
result, BinaryFunction 
# 78
binary_op) 
# 79
{int volatile ___ = 1;(void)this_group;(void)first;(void)decomp;(void)carries_first;(void)result;(void)binary_op;
# 96
::exit(___);}
#if 0
# 79
{ 
# 80
typename Decomposition::range range = decomp[(this_group.index())]; 
# 82
RandomAccessIterator1 last = first + (range.second); 
# 83
first += (range.first); 
# 84
result += (range.first); 
# 86
if ((this_group.index()) == 0) 
# 87
{ 
# 88
bulk_::inclusive_scan(this_group, first, last, result, binary_op); 
# 89
} else 
# 91
{ 
# 92
typename iterator_value< RandomAccessIterator2> ::type carry = carries_first[(this_group.index()) - 1]; 
# 94
bulk_::inclusive_scan(this_group, first, last, result, carry, binary_op); 
# 95
}  
# 96
} 
#endif
# 97 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/scan.inl"
}; 
# 100
struct exclusive_downsweep { 
# 102
template< class ConcurrentGroup, class RandomAccessIterator1, class Decomposition, class RandomAccessIterator2, class RandomAccessIterator3, class BinaryFunction> void 
# 103
operator()(ConcurrentGroup &this_group, RandomAccessIterator1 
# 104
first, Decomposition 
# 105
decomp, RandomAccessIterator2 
# 106
carries_first, RandomAccessIterator3 
# 107
result, BinaryFunction 
# 108
binary_op) 
# 109
{int volatile ___ = 1;(void)this_group;(void)first;(void)decomp;(void)carries_first;(void)result;(void)binary_op;
# 119
::exit(___);}
#if 0
# 109
{ 
# 110
typename Decomposition::range range = decomp[(this_group.index())]; 
# 112
RandomAccessIterator1 last = first + (range.second); 
# 113
first += (range.first); 
# 114
result += (range.first); 
# 116
typename iterator_value< RandomAccessIterator2> ::type carry = carries_first[(this_group.index())]; 
# 118
bulk_::exclusive_scan(this_group, first, last, result, carry, binary_op); 
# 119
} 
#endif
# 120 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/scan.inl"
}; 
# 123
template< class T> struct accumulate_tiles_tuning_impl; 
# 126
template<> struct accumulate_tiles_tuning_impl< int>  { 
# 129
static const int groupsize = 128; 
# 130
static const int grainsize = 9; 
# 131
}; 
# 134
template<> struct accumulate_tiles_tuning_impl< double>  { 
# 137
static const int groupsize = 128; 
# 138
static const int grainsize = 9; 
# 139
}; 
# 143
template< class T> 
# 144
struct accumulate_tiles_tuning { 
# 146
static const int groupsize = ((sizeof(T) <= sizeof(int)) ? accumulate_tiles_tuning_impl< int> ::groupsize : ((sizeof(T) <= ((2) * sizeof(int))) ? accumulate_tiles_tuning_impl< double> ::groupsize : 128)); 
# 151
static const int grainsize = ((sizeof(T) <= sizeof(int)) ? accumulate_tiles_tuning_impl< int> ::grainsize : ((sizeof(T) <= ((2) * sizeof(int))) ? accumulate_tiles_tuning_impl< double> ::grainsize : 3)); 
# 155
}; 
# 159
template< class T1, class T2> 
# 160
struct accumulate_tiles_tuning< tuple< T1, T2, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type> >  { 
# 163
static const int groupsize = 128; 
# 164
static const int grainsize = (((sizeof(T1) + sizeof(T2)) <= ((2) * sizeof(double))) ? 5 : 3); 
# 165
}; 
# 171
struct accumulate_tiles { 
# 173
template< class ConcurrentGroup, class RandomAccessIterator1, class Decomposition, class RandomAccessIterator2, class BinaryFunction> void 
# 174
operator()(ConcurrentGroup &this_group, RandomAccessIterator1 
# 175
first, Decomposition 
# 176
decomp, RandomAccessIterator2 
# 177
result, BinaryFunction 
# 178
binary_op) 
# 179
{int volatile ___ = 1;(void)this_group;(void)first;(void)decomp;(void)result;(void)binary_op;
# 197
::exit(___);}
#if 0
# 179
{ 
# 180
typedef typename iterator_value< RandomAccessIterator1> ::type value_type; 
# 182
typename Decomposition::range range = decomp[(this_group.index())]; 
# 184
const bool commutative = (thrust::detail::is_commutative< BinaryFunction> ::value); 
# 187
value_type init = commutative ? first[(range.second) - 1] : (first[range.first]); 
# 189
value_type sum = commutative ? bulk_::accumulate(this_group, first + (range.first), (first + (range.second)) - 1, init, binary_op) : bulk_::accumulate(this_group, (first + (range.first)) + 1, first + (range.second), init, binary_op); 
# 193
if (((this_group.this_exec).index()) == 0) 
# 194
{ 
# 195
(result[(this_group.index())]) = sum; 
# 196
}  
# 197
} 
#endif
# 198 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/scan.inl"
}; 
# 201
template< class DerivedPolicy, class 
# 202
InputIterator, class 
# 203
OutputIterator, class 
# 204
AssociativeOperator> OutputIterator 
# 206
inclusive_scan(execution_policy< DerivedPolicy>  &exec, InputIterator 
# 207
first, InputIterator 
# 208
last, OutputIterator 
# 209
result, AssociativeOperator 
# 210
binary_op) 
# 211
{ 
# 216
typedef typename bulk_::detail::scan_detail::scan_intermediate< InputIterator, OutputIterator, AssociativeOperator> ::type intermediate_type; 
# 218
typedef typename iterator_difference< InputIterator> ::type Size; 
# 220
Size n = last - first; 
# 222
cudaStream_t s = stream(thrust::detail::derived_cast(exec)); 
# 224
const Size threshold_of_parallelism = (20000); 
# 226
if (n < threshold_of_parallelism) 
# 227
{ 
# 228
const Size groupsize = ((sizeof(intermediate_type) <= ((2) * sizeof(int))) ? 512 : ((sizeof(intermediate_type) <= ((4) * sizeof(int))) ? 256 : 128)); 
# 233
typedef bulk_::detail::scan_detail::scan_buffer< groupsize, 3UL, InputIterator, OutputIterator, AssociativeOperator>  heap_type; 
# 234
Size heap_size = (sizeof(heap_type)); 
# 235
bulk_::async(bulk_::grid< groupsize, 3> (1, heap_size, s), inclusive_scan_n(), bulk_::root.this_exec, first, n, result, binary_op); 
# 238
(void)groupsize; 
# 239
} else 
# 241
{ 
# 242
const Size groupsize = (scan_detail::accumulate_tiles_tuning< typename bulk_::detail::scan_detail::scan_intermediate< InputIterator, OutputIterator, AssociativeOperator> ::type> ::groupsize); 
# 243
const Size grainsize = (scan_detail::accumulate_tiles_tuning< typename bulk_::detail::scan_detail::scan_intermediate< InputIterator, OutputIterator, AssociativeOperator> ::type> ::grainsize); 
# 245
const Size tile_size = groupsize * grainsize; 
# 246
Size num_tiles = ((n + tile_size) - 1) / tile_size; 
# 249
Size subscription = (20); 
# 250
Size num_groups = thrust::min< typename iterator_difference< InputIterator> ::type> (subscription * bulk_::concurrent_group<> ::hardware_concurrency(), num_tiles); 
# 252
aligned_decomposition< typename iterator_difference< InputIterator> ::type>  decomp(n, num_groups, tile_size); 
# 254
thrust::detail::temporary_array< typename bulk_::detail::scan_detail::scan_intermediate< InputIterator, OutputIterator, AssociativeOperator> ::type, DerivedPolicy>  carries(exec, num_groups); 
# 258
Size heap_size = groupsize * sizeof(intermediate_type); 
# 259
bulk_::async(bulk_::grid< groupsize, grainsize> (num_groups, heap_size, s), accumulate_tiles(), bulk_::root.this_exec, first, decomp, (carries.begin()), binary_op); 
# 263
const Size groupsize2 = ((sizeof(intermediate_type) <= ((2) * sizeof(int))) ? 256 : 128); 
# 264
const Size grainsize2 = (3); 
# 265
typedef bulk_::detail::scan_detail::scan_buffer< groupsize2, grainsize2, InputIterator, OutputIterator, AssociativeOperator>  heap_type2; 
# 266
heap_size = sizeof(heap_type2); 
# 267
bulk_::async(bulk_::grid< groupsize2, grainsize2> (1, heap_size, s), inclusive_scan_n(), bulk_::root.this_exec, (carries.begin()), num_groups, (carries.begin()), binary_op); 
# 274
typedef bulk_::detail::scan_detail::scan_buffer< groupsize, grainsize, InputIterator, OutputIterator, AssociativeOperator>  heap_type3; 
# 275
heap_size = sizeof(heap_type3); 
# 276
bulk_::async(bulk_::grid< groupsize, grainsize> (num_groups, heap_size, s), inclusive_downsweep(), bulk_::root.this_exec, first, decomp, (carries.begin()), result, binary_op); 
# 279
(void)groupsize2; 
# 280
(void)grainsize2; 
# 281
}  
# 283
return result + n; 
# 284
} 
# 287
template< class DerivedPolicy, class 
# 288
InputIterator, class 
# 289
OutputIterator, class 
# 290
T, class 
# 291
AssociativeOperator> OutputIterator 
# 293
exclusive_scan(execution_policy< DerivedPolicy>  &exec, InputIterator 
# 294
first, InputIterator 
# 295
last, OutputIterator 
# 296
result, T 
# 297
init, AssociativeOperator 
# 298
binary_op) 
# 299
{ 
# 304
typedef typename bulk_::detail::scan_detail::scan_intermediate< InputIterator, OutputIterator, AssociativeOperator> ::type intermediate_type; 
# 306
typedef typename iterator_difference< InputIterator> ::type Size; 
# 308
Size n = last - first; 
# 310
cudaStream_t s = stream(thrust::detail::derived_cast(exec)); 
# 312
const Size threshold_of_parallelism = (20000); 
# 314
if (n < threshold_of_parallelism) 
# 315
{ 
# 316
const Size groupsize = ((sizeof(intermediate_type) <= ((2) * sizeof(int))) ? 512 : ((sizeof(intermediate_type) <= ((4) * sizeof(int))) ? 256 : 128)); 
# 321
typedef bulk_::detail::scan_detail::scan_buffer< groupsize, 3UL, InputIterator, OutputIterator, AssociativeOperator>  heap_type; 
# 322
Size heap_size = (sizeof(heap_type)); 
# 323
bulk_::async(bulk_::grid< groupsize, 3> (1, heap_size, s), exclusive_scan_n(), bulk_::root.this_exec, first, n, result, init, binary_op); 
# 326
(void)groupsize; 
# 327
} else 
# 329
{ 
# 330
const Size groupsize = (scan_detail::accumulate_tiles_tuning< typename bulk_::detail::scan_detail::scan_intermediate< InputIterator, OutputIterator, AssociativeOperator> ::type> ::groupsize); 
# 331
const Size grainsize = (scan_detail::accumulate_tiles_tuning< typename bulk_::detail::scan_detail::scan_intermediate< InputIterator, OutputIterator, AssociativeOperator> ::type> ::grainsize); 
# 333
const Size tile_size = groupsize * grainsize; 
# 334
Size num_tiles = ((n + tile_size) - 1) / tile_size; 
# 337
Size subscription = (20); 
# 338
Size num_groups = thrust::min< typename iterator_difference< InputIterator> ::type> (subscription * bulk_::concurrent_group<> ::hardware_concurrency(), num_tiles); 
# 340
aligned_decomposition< typename iterator_difference< InputIterator> ::type>  decomp(n, num_groups, tile_size); 
# 342
thrust::detail::temporary_array< typename bulk_::detail::scan_detail::scan_intermediate< InputIterator, OutputIterator, AssociativeOperator> ::type, DerivedPolicy>  carries(exec, num_groups); 
# 346
Size heap_size = groupsize * sizeof(intermediate_type); 
# 347
bulk_::async(bulk_::grid< groupsize, grainsize> (num_groups, heap_size, s), accumulate_tiles(), bulk_::root.this_exec, first, decomp, (carries.begin()), binary_op); 
# 351
const Size groupsize2 = ((sizeof(intermediate_type) <= ((2) * sizeof(int))) ? 256 : 128); 
# 352
const Size grainsize2 = (3); 
# 354
typedef bulk_::detail::scan_detail::scan_buffer< groupsize2, grainsize2, InputIterator, OutputIterator, AssociativeOperator>  heap_type2; 
# 355
heap_size = sizeof(heap_type2); 
# 356
bulk_::async(bulk_::grid< groupsize2, grainsize2> (1, heap_size, s), exclusive_scan_n(), bulk_::root.this_exec, (carries.begin()), num_groups, (carries.begin()), init, binary_op); 
# 363
typedef bulk_::detail::scan_detail::scan_buffer< groupsize, grainsize, InputIterator, OutputIterator, AssociativeOperator>  heap_type3; 
# 364
heap_size = sizeof(heap_type3); 
# 365
bulk_::async(bulk_::grid< groupsize, grainsize> (num_groups, heap_size, s), exclusive_downsweep(), bulk_::root.this_exec, first, decomp, (carries.begin()), result, binary_op); 
# 368
(void)groupsize2; 
# 369
(void)grainsize2; 
# 370
}  
# 372
return result + n; 
# 373
} 
# 376
}
# 379
template< class DerivedPolicy, class 
# 380
InputIterator, class 
# 381
OutputIterator, class 
# 382
AssociativeOperator> OutputIterator 
# 384
inclusive_scan(execution_policy< DerivedPolicy>  &exec, InputIterator 
# 385
first, InputIterator 
# 386
last, OutputIterator 
# 387
result, AssociativeOperator 
# 388
binary_op) 
# 389
{ 
# 395
typedef thrust::detail::static_assert_test< sizeof(thrust::detail::STATIC_ASSERTION_FAILURE< (bool)(thrust::detail::depend_on_instantiation< InputIterator, true> ::value)> )>  thrust_static_assert_typedef_395 __attribute((unused)); 
# 397
struct workaround { 
# 400
static OutputIterator parallel_path(execution_policy< DerivedPolicy>  &exec, InputIterator 
# 401
first, InputIterator 
# 402
last, OutputIterator 
# 403
result, AssociativeOperator 
# 404
binary_op) 
# 405
{ 
# 406
return scan_detail::inclusive_scan(exec, first, last, result, binary_op); 
# 407
} 
# 410
static OutputIterator sequential_path(execution_policy< DerivedPolicy>  &, InputIterator 
# 411
first, InputIterator 
# 412
last, OutputIterator 
# 413
result, AssociativeOperator 
# 414
binary_op) 
# 415
{ 
# 416
return thrust::inclusive_scan(thrust::seq, first, last, result, binary_op); 
# 417
} 
# 418
}; 
# 421
return (workaround::parallel_path)(exec, first, last, result, binary_op); 
# 425
} 
# 428
template< class DerivedPolicy, class 
# 429
InputIterator, class 
# 430
OutputIterator, class 
# 431
T, class 
# 432
AssociativeOperator> OutputIterator 
# 434
exclusive_scan(execution_policy< DerivedPolicy>  &exec, InputIterator 
# 435
first, InputIterator 
# 436
last, OutputIterator 
# 437
result, T 
# 438
init, AssociativeOperator 
# 439
binary_op) 
# 440
{ 
# 446
typedef thrust::detail::static_assert_test< sizeof(thrust::detail::STATIC_ASSERTION_FAILURE< (bool)(thrust::detail::depend_on_instantiation< InputIterator, true> ::value)> )>  thrust_static_assert_typedef_446 __attribute((unused)); 
# 448
struct workaround { 
# 451
static OutputIterator parallel_path(execution_policy< DerivedPolicy>  &exec, InputIterator 
# 452
first, InputIterator 
# 453
last, OutputIterator 
# 454
result, T 
# 455
init, AssociativeOperator 
# 456
binary_op) 
# 457
{ 
# 458
return scan_detail::exclusive_scan(exec, first, last, result, init, binary_op); 
# 459
} 
# 462
static OutputIterator sequential_path(execution_policy< DerivedPolicy>  &, InputIterator 
# 463
first, InputIterator 
# 464
last, OutputIterator 
# 465
result, T 
# 466
init, AssociativeOperator 
# 467
binary_op) 
# 468
{ 
# 469
return thrust::exclusive_scan(thrust::seq, first, last, result, init, binary_op); 
# 470
} 
# 471
}; 
# 474
return (workaround::parallel_path)(exec, first, last, result, init, binary_op); 
# 478
} 
# 481
}
# 482
}
# 483
}
# 484
}
# 29 "/usr/local/cuda-8.0/include/thrust/system/detail/sequential/scan_by_key.h"
namespace thrust { 
# 31
namespace system { 
# 33
namespace detail { 
# 35
namespace sequential { 
# 40
template< class DerivedPolicy, class 
# 41
InputIterator1, class 
# 42
InputIterator2, class 
# 43
OutputIterator, class 
# 44
BinaryPredicate, class 
# 45
BinaryFunction> OutputIterator 
# 47
inclusive_scan_by_key(execution_policy< DerivedPolicy>  &, InputIterator1 
# 48
first1, InputIterator1 
# 49
last1, InputIterator2 
# 50
first2, OutputIterator 
# 51
result, BinaryPredicate 
# 52
binary_pred, BinaryFunction 
# 53
binary_op) 
# 54
{ 
# 55
typedef typename iterator_traits< InputIterator1> ::value_type KeyType; 
# 56
typedef typename iterator_traits< OutputIterator> ::value_type ValueType; 
# 62
thrust::detail::wrapped_function< BinaryFunction, typename iterator_traits< OutputIterator> ::value_type>  wrapped_binary_op(binary_op); 
# 64
if (first1 != last1) 
# 65
{ 
# 66
KeyType prev_key = *first1; 
# 67
ValueType prev_value = *first2; 
# 69
(*result) = prev_value; 
# 71
for (((++first1), (++first2)), (++result); first1 != last1; ((++first1), (++first2)), (++result)) 
# 74
{ 
# 75
KeyType key = *first1; 
# 77
if (binary_pred(prev_key, key)) { 
# 78
(*result) = (prev_value = wrapped_binary_op(prev_value, *first2)); } else { 
# 80
(*result) = (prev_value = (*first2)); }  
# 82
prev_key = key; 
# 83
}  
# 84
}  
# 86
return result; 
# 87
} 
# 91
template< class DerivedPolicy, class 
# 92
InputIterator1, class 
# 93
InputIterator2, class 
# 94
OutputIterator, class 
# 95
T, class 
# 96
BinaryPredicate, class 
# 97
BinaryFunction> OutputIterator 
# 99
exclusive_scan_by_key(execution_policy< DerivedPolicy>  &, InputIterator1 
# 100
first1, InputIterator1 
# 101
last1, InputIterator2 
# 102
first2, OutputIterator 
# 103
result, T 
# 104
init, BinaryPredicate 
# 105
binary_pred, BinaryFunction 
# 106
binary_op) 
# 107
{ 
# 108
typedef typename iterator_traits< InputIterator1> ::value_type KeyType; 
# 109
typedef typename iterator_traits< OutputIterator> ::value_type ValueType; 
# 111
if (first1 != last1) 
# 112
{ 
# 113
KeyType temp_key = *first1; 
# 114
ValueType temp_value = *first2; 
# 116
ValueType next = init; 
# 119
(*result) = next; 
# 121
next = binary_op(next, temp_value); 
# 123
for (((++first1), (++first2)), (++result); first1 != last1; ((++first1), (++first2)), (++result)) 
# 126
{ 
# 127
KeyType key = *first1; 
# 130
temp_value = (*first2); 
# 132
if (!binary_pred(temp_key, key)) { 
# 133
next = init; }  
# 135
(*result) = next; 
# 136
next = binary_op(next, temp_value); 
# 138
temp_key = key; 
# 139
}  
# 140
}  
# 142
return result; 
# 143
} 
# 146
}
# 147
}
# 148
}
# 149
}
# 31 "/usr/local/cuda-8.0/include/thrust/detail/scan.inl"
namespace thrust { 
# 36
template< class DerivedPolicy, class 
# 37
InputIterator, class 
# 38
OutputIterator> OutputIterator 
# 40
inclusive_scan(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator 
# 41
first, InputIterator 
# 42
last, OutputIterator 
# 43
result) 
# 44
{ 
# 45
using system::detail::generic::inclusive_scan;
# 46
return inclusive_scan(detail::derived_cast(detail::strip_const(exec)), first, last, result); 
# 47
} 
# 51
template< class DerivedPolicy, class 
# 52
InputIterator, class 
# 53
OutputIterator, class 
# 54
AssociativeOperator> OutputIterator 
# 56
inclusive_scan(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator 
# 57
first, InputIterator 
# 58
last, OutputIterator 
# 59
result, AssociativeOperator 
# 60
binary_op) 
# 61
{ 
# 62
using system::detail::generic::inclusive_scan;
# 63
return inclusive_scan(detail::derived_cast(detail::strip_const(exec)), first, last, result, binary_op); 
# 64
} 
# 68
template< class DerivedPolicy, class 
# 69
InputIterator, class 
# 70
OutputIterator> OutputIterator 
# 72
exclusive_scan(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator 
# 73
first, InputIterator 
# 74
last, OutputIterator 
# 75
result) 
# 76
{ 
# 77
using system::detail::generic::exclusive_scan;
# 78
return exclusive_scan(detail::derived_cast(detail::strip_const(exec)), first, last, result); 
# 79
} 
# 83
template< class DerivedPolicy, class 
# 84
InputIterator, class 
# 85
OutputIterator, class 
# 86
T> OutputIterator 
# 88
exclusive_scan(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator 
# 89
first, InputIterator 
# 90
last, OutputIterator 
# 91
result, T 
# 92
init) 
# 93
{ 
# 94
using system::detail::generic::exclusive_scan;
# 95
return exclusive_scan(detail::derived_cast(detail::strip_const(exec)), first, last, result, init); 
# 96
} 
# 100
template< class DerivedPolicy, class 
# 101
InputIterator, class 
# 102
OutputIterator, class 
# 103
T, class 
# 104
AssociativeOperator> OutputIterator 
# 106
exclusive_scan(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator 
# 107
first, InputIterator 
# 108
last, OutputIterator 
# 109
result, T 
# 110
init, AssociativeOperator 
# 111
binary_op) 
# 112
{ 
# 113
using system::detail::generic::exclusive_scan;
# 114
return exclusive_scan(detail::derived_cast(detail::strip_const(exec)), first, last, result, init, binary_op); 
# 115
} 
# 119
template< class DerivedPolicy, class 
# 120
InputIterator1, class 
# 121
InputIterator2, class 
# 122
OutputIterator> OutputIterator 
# 124
inclusive_scan_by_key(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator1 
# 125
first1, InputIterator1 
# 126
last1, InputIterator2 
# 127
first2, OutputIterator 
# 128
result) 
# 129
{ 
# 130
using system::detail::generic::inclusive_scan_by_key;
# 131
return inclusive_scan_by_key(detail::derived_cast(detail::strip_const(exec)), first1, last1, first2, result); 
# 132
} 
# 136
template< class DerivedPolicy, class 
# 137
InputIterator1, class 
# 138
InputIterator2, class 
# 139
OutputIterator, class 
# 140
BinaryPredicate> OutputIterator 
# 142
inclusive_scan_by_key(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator1 
# 143
first1, InputIterator1 
# 144
last1, InputIterator2 
# 145
first2, OutputIterator 
# 146
result, BinaryPredicate 
# 147
binary_pred) 
# 148
{ 
# 149
using system::detail::generic::inclusive_scan_by_key;
# 150
return inclusive_scan_by_key(detail::derived_cast(detail::strip_const(exec)), first1, last1, first2, result, binary_pred); 
# 151
} 
# 155
template< class DerivedPolicy, class 
# 156
InputIterator1, class 
# 157
InputIterator2, class 
# 158
OutputIterator, class 
# 159
BinaryPredicate, class 
# 160
AssociativeOperator> OutputIterator 
# 162
inclusive_scan_by_key(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator1 
# 163
first1, InputIterator1 
# 164
last1, InputIterator2 
# 165
first2, OutputIterator 
# 166
result, BinaryPredicate 
# 167
binary_pred, AssociativeOperator 
# 168
binary_op) 
# 169
{ 
# 170
using system::detail::generic::inclusive_scan_by_key;
# 171
return inclusive_scan_by_key(detail::derived_cast(detail::strip_const(exec)), first1, last1, first2, result, binary_pred, binary_op); 
# 172
} 
# 176
template< class DerivedPolicy, class 
# 177
InputIterator1, class 
# 178
InputIterator2, class 
# 179
OutputIterator> OutputIterator 
# 181
exclusive_scan_by_key(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator1 
# 182
first1, InputIterator1 
# 183
last1, InputIterator2 
# 184
first2, OutputIterator 
# 185
result) 
# 186
{ 
# 187
using system::detail::generic::exclusive_scan_by_key;
# 188
return exclusive_scan_by_key(detail::derived_cast(detail::strip_const(exec)), first1, last1, first2, result); 
# 189
} 
# 193
template< class DerivedPolicy, class 
# 194
InputIterator1, class 
# 195
InputIterator2, class 
# 196
OutputIterator, class 
# 197
T> OutputIterator 
# 199
exclusive_scan_by_key(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator1 
# 200
first1, InputIterator1 
# 201
last1, InputIterator2 
# 202
first2, OutputIterator 
# 203
result, T 
# 204
init) 
# 205
{ 
# 206
using system::detail::generic::exclusive_scan_by_key;
# 207
return exclusive_scan_by_key(detail::derived_cast(detail::strip_const(exec)), first1, last1, first2, result, init); 
# 208
} 
# 212
template< class DerivedPolicy, class 
# 213
InputIterator1, class 
# 214
InputIterator2, class 
# 215
OutputIterator, class 
# 216
T, class 
# 217
BinaryPredicate> OutputIterator 
# 219
exclusive_scan_by_key(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator1 
# 220
first1, InputIterator1 
# 221
last1, InputIterator2 
# 222
first2, OutputIterator 
# 223
result, T 
# 224
init, BinaryPredicate 
# 225
binary_pred) 
# 226
{ 
# 227
using system::detail::generic::exclusive_scan_by_key;
# 228
return exclusive_scan_by_key(detail::derived_cast(detail::strip_const(exec)), first1, last1, first2, result, init, binary_pred); 
# 229
} 
# 233
template< class DerivedPolicy, class 
# 234
InputIterator1, class 
# 235
InputIterator2, class 
# 236
OutputIterator, class 
# 237
T, class 
# 238
BinaryPredicate, class 
# 239
AssociativeOperator> OutputIterator 
# 241
exclusive_scan_by_key(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator1 
# 242
first1, InputIterator1 
# 243
last1, InputIterator2 
# 244
first2, OutputIterator 
# 245
result, T 
# 246
init, BinaryPredicate 
# 247
binary_pred, AssociativeOperator 
# 248
binary_op) 
# 249
{ 
# 250
using system::detail::generic::exclusive_scan_by_key;
# 251
return exclusive_scan_by_key(detail::derived_cast(detail::strip_const(exec)), first1, last1, first2, result, init, binary_pred, binary_op); 
# 252
} 
# 255
template< class InputIterator, class 
# 256
OutputIterator> OutputIterator 
# 257
inclusive_scan(InputIterator first, InputIterator 
# 258
last, OutputIterator 
# 259
result) 
# 260
{ 
# 261
using system::detail::generic::select_system;
# 263
typedef typename iterator_system< InputIterator> ::type System1; 
# 264
typedef typename iterator_system< OutputIterator> ::type System2; 
# 266
System1 system1; 
# 267
System2 system2; 
# 269
return thrust::inclusive_scan(select_system(system1, system2), first, last, result); 
# 270
} 
# 273
template< class InputIterator, class 
# 274
OutputIterator, class 
# 275
BinaryFunction> OutputIterator 
# 276
inclusive_scan(InputIterator first, InputIterator 
# 277
last, OutputIterator 
# 278
result, BinaryFunction 
# 279
binary_op) 
# 280
{ 
# 281
using system::detail::generic::select_system;
# 283
typedef typename iterator_system< InputIterator> ::type System1; 
# 284
typedef typename iterator_system< OutputIterator> ::type System2; 
# 286
System1 system1; 
# 287
System2 system2; 
# 289
return thrust::inclusive_scan(select_system(system1, system2), first, last, result, binary_op); 
# 290
} 
# 293
template< class InputIterator, class 
# 294
OutputIterator> OutputIterator 
# 295
exclusive_scan(InputIterator first, InputIterator 
# 296
last, OutputIterator 
# 297
result) 
# 298
{ 
# 299
using system::detail::generic::select_system;
# 301
typedef typename iterator_system< InputIterator> ::type System1; 
# 302
typedef typename iterator_system< OutputIterator> ::type System2; 
# 304
System1 system1; 
# 305
System2 system2; 
# 307
return thrust::exclusive_scan(select_system(system1, system2), first, last, result); 
# 308
} 
# 311
template< class InputIterator, class 
# 312
OutputIterator, class 
# 313
T> OutputIterator 
# 314
exclusive_scan(InputIterator first, InputIterator 
# 315
last, OutputIterator 
# 316
result, T 
# 317
init) 
# 318
{ 
# 319
using system::detail::generic::select_system;
# 321
typedef typename iterator_system< InputIterator> ::type System1; 
# 322
typedef typename iterator_system< OutputIterator> ::type System2; 
# 324
System1 system1; 
# 325
System2 system2; 
# 327
return thrust::exclusive_scan(select_system(system1, system2), first, last, result, init); 
# 328
} 
# 331
template< class InputIterator, class 
# 332
OutputIterator, class 
# 333
T, class 
# 334
BinaryFunction> OutputIterator 
# 335
exclusive_scan(InputIterator first, InputIterator 
# 336
last, OutputIterator 
# 337
result, T 
# 338
init, BinaryFunction 
# 339
binary_op) 
# 340
{ 
# 341
using system::detail::generic::select_system;
# 343
typedef typename iterator_system< InputIterator> ::type System1; 
# 344
typedef typename iterator_system< OutputIterator> ::type System2; 
# 346
System1 system1; 
# 347
System2 system2; 
# 349
return thrust::exclusive_scan(select_system(system1, system2), first, last, result, init, binary_op); 
# 350
} 
# 353
template< class InputIterator1, class 
# 354
InputIterator2, class 
# 355
OutputIterator> OutputIterator 
# 356
inclusive_scan_by_key(InputIterator1 first1, InputIterator1 
# 357
last1, InputIterator2 
# 358
first2, OutputIterator 
# 359
result) 
# 360
{ 
# 361
using system::detail::generic::select_system;
# 363
typedef typename iterator_system< InputIterator1> ::type System1; 
# 364
typedef typename iterator_system< InputIterator2> ::type System2; 
# 365
typedef typename iterator_system< OutputIterator> ::type System3; 
# 367
System1 system1; 
# 368
System2 system2; 
# 369
System3 system3; 
# 371
return thrust::inclusive_scan_by_key(select_system(system1, system2, system3), first1, last1, first2, result); 
# 372
} 
# 375
template< class InputIterator1, class 
# 376
InputIterator2, class 
# 377
OutputIterator, class 
# 378
BinaryPredicate> OutputIterator 
# 379
inclusive_scan_by_key(InputIterator1 first1, InputIterator1 
# 380
last1, InputIterator2 
# 381
first2, OutputIterator 
# 382
result, BinaryPredicate 
# 383
binary_pred) 
# 384
{ 
# 385
using system::detail::generic::select_system;
# 387
typedef typename iterator_system< InputIterator1> ::type System1; 
# 388
typedef typename iterator_system< InputIterator2> ::type System2; 
# 389
typedef typename iterator_system< OutputIterator> ::type System3; 
# 391
System1 system1; 
# 392
System2 system2; 
# 393
System3 system3; 
# 395
return thrust::inclusive_scan_by_key(select_system(system1, system2, system3), first1, last1, first2, result, binary_pred); 
# 396
} 
# 399
template< class InputIterator1, class 
# 400
InputIterator2, class 
# 401
OutputIterator, class 
# 402
BinaryPredicate, class 
# 403
AssociativeOperator> OutputIterator 
# 404
inclusive_scan_by_key(InputIterator1 first1, InputIterator1 
# 405
last1, InputIterator2 
# 406
first2, OutputIterator 
# 407
result, BinaryPredicate 
# 408
binary_pred, AssociativeOperator 
# 409
binary_op) 
# 410
{ 
# 411
using system::detail::generic::select_system;
# 413
typedef typename iterator_system< InputIterator1> ::type System1; 
# 414
typedef typename iterator_system< InputIterator2> ::type System2; 
# 415
typedef typename iterator_system< OutputIterator> ::type System3; 
# 417
System1 system1; 
# 418
System2 system2; 
# 419
System3 system3; 
# 421
return thrust::inclusive_scan_by_key(select_system(system1, system2, system3), first1, last1, first2, result, binary_pred, binary_op); 
# 422
} 
# 425
template< class InputIterator1, class 
# 426
InputIterator2, class 
# 427
OutputIterator> OutputIterator 
# 428
exclusive_scan_by_key(InputIterator1 first1, InputIterator1 
# 429
last1, InputIterator2 
# 430
first2, OutputIterator 
# 431
result) 
# 432
{ 
# 433
using system::detail::generic::select_system;
# 435
typedef typename iterator_system< InputIterator1> ::type System1; 
# 436
typedef typename iterator_system< InputIterator2> ::type System2; 
# 437
typedef typename iterator_system< OutputIterator> ::type System3; 
# 439
System1 system1; 
# 440
System2 system2; 
# 441
System3 system3; 
# 443
return thrust::exclusive_scan_by_key(select_system(system1, system2, system3), first1, last1, first2, result); 
# 444
} 
# 447
template< class InputIterator1, class 
# 448
InputIterator2, class 
# 449
OutputIterator, class 
# 450
T> OutputIterator 
# 451
exclusive_scan_by_key(InputIterator1 first1, InputIterator1 
# 452
last1, InputIterator2 
# 453
first2, OutputIterator 
# 454
result, T 
# 455
init) 
# 456
{ 
# 457
using system::detail::generic::select_system;
# 459
typedef typename iterator_system< InputIterator1> ::type System1; 
# 460
typedef typename iterator_system< InputIterator2> ::type System2; 
# 461
typedef typename iterator_system< OutputIterator> ::type System3; 
# 463
System1 system1; 
# 464
System2 system2; 
# 465
System3 system3; 
# 467
return thrust::exclusive_scan_by_key(select_system(system1, system2, system3), first1, last1, first2, result, init); 
# 468
} 
# 471
template< class InputIterator1, class 
# 472
InputIterator2, class 
# 473
OutputIterator, class 
# 474
T, class 
# 475
BinaryPredicate> OutputIterator 
# 476
exclusive_scan_by_key(InputIterator1 first1, InputIterator1 
# 477
last1, InputIterator2 
# 478
first2, OutputIterator 
# 479
result, T 
# 480
init, BinaryPredicate 
# 481
binary_pred) 
# 482
{ 
# 483
using system::detail::generic::select_system;
# 485
typedef typename iterator_system< InputIterator1> ::type System1; 
# 486
typedef typename iterator_system< InputIterator2> ::type System2; 
# 487
typedef typename iterator_system< OutputIterator> ::type System3; 
# 489
System1 system1; 
# 490
System2 system2; 
# 491
System3 system3; 
# 493
return thrust::exclusive_scan_by_key(select_system(system1, system2, system3), first1, last1, first2, result, init, binary_pred); 
# 494
} 
# 497
template< class InputIterator1, class 
# 498
InputIterator2, class 
# 499
OutputIterator, class 
# 500
T, class 
# 501
BinaryPredicate, class 
# 502
AssociativeOperator> OutputIterator 
# 503
exclusive_scan_by_key(InputIterator1 first1, InputIterator1 
# 504
last1, InputIterator2 
# 505
first2, OutputIterator 
# 506
result, T 
# 507
init, BinaryPredicate 
# 508
binary_pred, AssociativeOperator 
# 509
binary_op) 
# 510
{ 
# 511
using system::detail::generic::select_system;
# 513
typedef typename iterator_system< InputIterator1> ::type System1; 
# 514
typedef typename iterator_system< InputIterator2> ::type System2; 
# 515
typedef typename iterator_system< OutputIterator> ::type System3; 
# 517
System1 system1; 
# 518
System2 system2; 
# 519
System3 system3; 
# 521
return thrust::exclusive_scan_by_key(select_system(system1, system2, system3), first1, last1, first2, result, init, binary_pred, binary_op); 
# 522
} 
# 525
}
# 38 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/reduce_by_key.inl"
namespace thrust { 
# 40
namespace system { 
# 42
namespace detail { 
# 44
namespace generic { 
# 46
namespace detail { 
# 50
template< class ValueType, class TailFlagType, class AssociativeOperator> 
# 51
struct reduce_by_key_functor { 
# 53
AssociativeOperator binary_op; 
# 55
typedef tuple< ValueType, TailFlagType, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type>  result_type; 
# 58
reduce_by_key_functor(AssociativeOperator _binary_op) : binary_op(_binary_op) { } 
# 61
result_type operator()(result_type a, result_type b) 
# 62
{ 
# 63
return result_type((thrust::get< 1> (b)) ? thrust::get< 0> (b) : (binary_op)(thrust::get< 0> (a), thrust::get< 0> (b)), thrust::get< 1> (a) | thrust::get< 1> (b)); 
# 65
} 
# 66
}; 
# 69
}
# 72
template< class ExecutionPolicy, class 
# 73
InputIterator1, class 
# 74
InputIterator2, class 
# 75
OutputIterator1, class 
# 76
OutputIterator2, class 
# 77
BinaryPredicate, class 
# 78
BinaryFunction> pair< OutputIterator1, OutputIterator2>  
# 81
reduce_by_key(execution_policy< ExecutionPolicy>  &exec, InputIterator1 
# 82
keys_first, InputIterator1 
# 83
keys_last, InputIterator2 
# 84
values_first, OutputIterator1 
# 85
keys_output, OutputIterator2 
# 86
values_output, BinaryPredicate 
# 87
binary_pred, BinaryFunction 
# 88
binary_op) 
# 89
{ 
# 90
typedef typename iterator_traits< InputIterator1> ::difference_type difference_type; 
# 92
typedef unsigned FlagType; 
# 114
typedef typename thrust::detail::eval_if< thrust::detail::has_result_type< BinaryFunction> ::value, thrust::detail::result_type< BinaryFunction> , thrust::detail::eval_if< thrust::detail::is_output_iterator< OutputIterator2> ::value, iterator_value< InputIterator2> , iterator_value< OutputIterator2> > > ::type ValueType; 
# 116
if (keys_first == keys_last) { 
# 117
return thrust::make_pair(keys_output, values_output); }  
# 120
difference_type n = keys_last - keys_first; 
# 122
InputIterator2 values_last = values_first + n; 
# 125
thrust::detail::temporary_array< unsigned, ExecutionPolicy>  head_flags(exec, n); 
# 126
thrust::transform(exec, keys_first, keys_last - 1, keys_first + 1, (head_flags.begin()) + 1, thrust::detail::not2(binary_pred)); 
# 127
(head_flags[0]) = 1; 
# 130
thrust::detail::temporary_array< unsigned, ExecutionPolicy>  tail_flags(exec, n); 
# 131
thrust::transform(exec, keys_first, keys_last - 1, keys_first + 1, (tail_flags.begin()), thrust::detail::not2(binary_pred)); 
# 132
(tail_flags[n - 1]) = 1; 
# 135
thrust::detail::temporary_array< typename thrust::detail::eval_if< thrust::detail::has_result_type< BinaryFunction> ::value, thrust::detail::result_type< BinaryFunction> , thrust::detail::eval_if< thrust::detail::is_output_iterator< OutputIterator2> ::value, iterator_value< InputIterator2> , iterator_value< OutputIterator2> > > ::type, ExecutionPolicy>  scanned_values(exec, n); 
# 136
thrust::detail::temporary_array< unsigned, ExecutionPolicy>  scanned_tail_flags(exec, n); 
# 138
thrust::inclusive_scan(exec, thrust::make_zip_iterator(thrust::make_tuple(values_first, (head_flags.begin()))), thrust::make_zip_iterator(thrust::make_tuple(values_last, (head_flags.end()))), thrust::make_zip_iterator(thrust::make_tuple((scanned_values.begin()), (scanned_tail_flags.begin()))), ((detail::reduce_by_key_functor< typename thrust::detail::eval_if< thrust::detail::has_result_type< BinaryFunction> ::value, thrust::detail::result_type< BinaryFunction> , thrust::detail::eval_if< thrust::detail::is_output_iterator< OutputIterator2> ::value, iterator_value< InputIterator2> , iterator_value< OutputIterator2> > > ::type, unsigned, BinaryFunction> )(binary_op))); 
# 145
thrust::exclusive_scan(exec, (tail_flags.begin()), (tail_flags.end()), (scanned_tail_flags.begin()), (FlagType)0, plus< unsigned> ()); 
# 148
FlagType N = (scanned_tail_flags[n - 1]) + 1; 
# 151
thrust::scatter_if(exec, keys_first, keys_last, (scanned_tail_flags.begin()), (head_flags.begin()), keys_output); 
# 152
thrust::scatter_if(exec, (scanned_values.begin()), (scanned_values.end()), (scanned_tail_flags.begin()), (tail_flags.begin()), values_output); 
# 154
return thrust::make_pair(keys_output + N, values_output + N); 
# 155
} 
# 158
template< class ExecutionPolicy, class 
# 159
InputIterator1, class 
# 160
InputIterator2, class 
# 161
OutputIterator1, class 
# 162
OutputIterator2> pair< OutputIterator1, OutputIterator2>  
# 165
reduce_by_key(execution_policy< ExecutionPolicy>  &exec, InputIterator1 
# 166
keys_first, InputIterator1 
# 167
keys_last, InputIterator2 
# 168
values_first, OutputIterator1 
# 169
keys_output, OutputIterator2 
# 170
values_output) 
# 171
{ 
# 172
typedef typename iterator_value< InputIterator1> ::type KeyType; 
# 175
return thrust::reduce_by_key(exec, keys_first, keys_last, values_first, keys_output, values_output, equal_to< typename iterator_value< InputIterator1> ::type> ()); 
# 176
} 
# 179
template< class ExecutionPolicy, class 
# 180
InputIterator1, class 
# 181
InputIterator2, class 
# 182
OutputIterator1, class 
# 183
OutputIterator2, class 
# 184
BinaryPredicate> pair< OutputIterator1, OutputIterator2>  
# 187
reduce_by_key(execution_policy< ExecutionPolicy>  &exec, InputIterator1 
# 188
keys_first, InputIterator1 
# 189
keys_last, InputIterator2 
# 190
values_first, OutputIterator1 
# 191
keys_output, OutputIterator2 
# 192
values_output, BinaryPredicate 
# 193
binary_pred) 
# 194
{ 
# 199
typedef typename thrust::detail::eval_if< thrust::detail::is_output_iterator< OutputIterator2> ::value, iterator_value< InputIterator2> , iterator_value< OutputIterator2> > ::type T; 
# 202
return thrust::reduce_by_key(exec, keys_first, keys_last, values_first, keys_output, values_output, binary_pred, plus< typename thrust::detail::eval_if< thrust::detail::is_output_iterator< OutputIterator2> ::value, iterator_value< InputIterator2> , iterator_value< OutputIterator2> > ::type> ()); 
# 209
} 
# 212
}
# 213
}
# 214
}
# 215
}
# 28 "/usr/local/cuda-8.0/include/thrust/system/detail/sequential/reduce.h"
namespace thrust { 
# 30
namespace system { 
# 32
namespace detail { 
# 34
namespace sequential { 
# 39
template< class DerivedPolicy, class 
# 40
InputIterator, class 
# 41
OutputType, class 
# 42
BinaryFunction> OutputType 
# 44
reduce(execution_policy< DerivedPolicy>  &, InputIterator 
# 45
begin, InputIterator 
# 46
end, OutputType 
# 47
init, BinaryFunction 
# 48
binary_op) 
# 49
{ 
# 54
thrust::detail::wrapped_function< BinaryFunction, OutputType>  wrapped_binary_op(binary_op); 
# 57
OutputType result = init; 
# 59
while (begin != end) 
# 60
{ 
# 61
result = wrapped_binary_op(result, *begin); 
# 62
++begin; 
# 63
}  
# 65
return result; 
# 66
} 
# 69
}
# 70
}
# 71
}
# 72
}
# 27 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/reduce.h"
namespace thrust { 
# 29
namespace system { 
# 31
namespace cuda { 
# 33
namespace detail { 
# 37
template< class DerivedPolicy, class 
# 38
InputIterator, class 
# 39
OutputType, class 
# 40
BinaryFunction> OutputType 
# 37
reduce(execution_policy< DerivedPolicy>  & exec, InputIterator first, InputIterator last, OutputType init, BinaryFunction binary_op); 
# 49
}
# 50
}
# 51
}
# 52
}
# 32 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/reduce.inl"
namespace thrust { 
# 34
namespace system { 
# 36
namespace cuda { 
# 38
namespace detail { 
# 40
namespace reduce_detail { 
# 44
struct reduce_partitions { 
# 46
template< class ConcurrentGroup, class Iterator1, class Iterator2, class T, class BinaryOperation> void 
# 48
operator()(ConcurrentGroup &this_group, Iterator1 first, Iterator1 last, Iterator2 result, T init, BinaryOperation binary_op) 
# 49
{int volatile ___ = 1;(void)this_group;(void)first;(void)last;(void)result;(void)init;(void)binary_op;
# 56
::exit(___);}
#if 0
# 49
{ 
# 50
T sum = bulk_::reduce(this_group, first, last, init, binary_op); 
# 52
if (((this_group.this_exec).index()) == 0) 
# 53
{ 
# 54
(*result) = sum; 
# 55
}  
# 56
} 
#endif
# 58 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/reduce.inl"
template< class ConcurrentGroup, class Iterator1, class Iterator2, class BinaryOperation> void 
# 60
operator()(ConcurrentGroup &this_group, Iterator1 first, Iterator1 last, Iterator2 result, BinaryOperation binary_op) 
# 61
{int volatile ___ = 1;(void)this_group;(void)first;(void)last;(void)result;(void)binary_op;
# 65
::exit(___);}
#if 0
# 61
{ 
# 63
typename iterator_value< Iterator2> ::type init = thrust::raw_reference_cast(last[-1]); 
# 64
(*this)(this_group, first, last - 1, result, init, binary_op); 
# 65
} 
#endif
# 68 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/reduce.inl"
template< class ConcurrentGroup, class Iterator1, class Decomposition, class Iterator2, class T, class BinaryFunction> void 
# 70
operator()(ConcurrentGroup &this_group, Iterator1 first, Decomposition decomp, Iterator2 result, T init, BinaryFunction binary_op) 
# 71
{int volatile ___ = 1;(void)this_group;(void)first;(void)decomp;(void)result;(void)init;(void)binary_op;
# 85
::exit(___);}
#if 0
# 71
{ 
# 72
typename Decomposition::range range = decomp[(this_group.index())]; 
# 74
Iterator1 last = first + (range.second); 
# 75
first += (range.first); 
# 77
if ((this_group.index()) != 0) 
# 78
{ 
# 80
init = thrust::raw_reference_cast(last[-1]); 
# 81
--last; 
# 82
}  
# 84
(*this)(this_group, first, last, result + (this_group.index()), init, binary_op); 
# 85
} 
#endif
# 86 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/reduce.inl"
}; 
# 89
template< class DerivedPolicy, class 
# 90
InputIterator, class 
# 91
OutputType, class 
# 92
BinaryFunction> OutputType 
# 94
tuned_reduce(execution_policy< DerivedPolicy>  &exec, InputIterator 
# 95
first, InputIterator 
# 96
last, OutputType 
# 97
init, BinaryFunction 
# 98
binary_op) 
# 99
{ 
# 100
typedef typename iterator_difference< InputIterator> ::type size_type; 
# 102
const size_type n = last - first; 
# 104
if (n <= 0) { return init; }  
# 106
cudaStream_t s = stream(thrust::detail::derived_cast(exec)); 
# 108
const size_type groupsize = (128); 
# 109
const size_type grainsize = (7); 
# 110
const size_type tile_size = groupsize * grainsize; 
# 111
const size_type num_tiles = ((n + tile_size) - 1) / tile_size; 
# 112
const size_type subscription = (10); 
# 117
bulk_::concurrent_group< bulk_::agent< grainsize> , groupsize>  g; 
# 119
const size_type num_groups = thrust::min< typename iterator_difference< InputIterator> ::type> (subscription * (g.hardware_concurrency()), num_tiles); 
# 121
aligned_decomposition< typename iterator_difference< InputIterator> ::type>  decomp(n, num_groups, tile_size); 
# 123
thrust::detail::temporary_array< OutputType, DerivedPolicy>  partial_sums(exec, (decomp.size())); 
# 126
(bulk_::async(bulk_::par(s, g, (decomp.size())), reduce_partitions(), bulk_::root.this_exec, first, decomp, (partial_sums.begin()), init, binary_op).wait()); 
# 128
if ((partial_sums.size()) > 1) 
# 129
{ 
# 131
bulk_::async(bulk_::par(s, g, 1), reduce_partitions(), bulk_::root.this_exec, (partial_sums.begin()), (partial_sums.end()), (partial_sums.begin()), binary_op); 
# 132
}  
# 134
return get_value(exec, &(partial_sums[0])); 
# 135
} 
# 138
template< class DerivedPolicy, class 
# 139
InputIterator, class 
# 140
OutputType, class 
# 141
BinaryFunction> OutputType 
# 143
general_reduce(execution_policy< DerivedPolicy>  &exec, InputIterator 
# 144
first, InputIterator 
# 145
last, OutputType 
# 146
init, BinaryFunction 
# 147
binary_op) 
# 148
{ 
# 149
typedef typename iterator_difference< InputIterator> ::type size_type; 
# 151
const size_type n = last - first; 
# 153
if (n <= 0) { return init; }  
# 155
cudaStream_t s = stream(thrust::detail::derived_cast(exec)); 
# 157
typedef thrust::detail::temporary_array< OutputType, DerivedPolicy>  temporary_array; 
# 160
size_type num_groups = (0); 
# 161
size_type group_size = (0); 
# 163
thrust::tie(num_groups, group_size) = bulk_::choose_sizes(bulk_::grid(), reduce_partitions(), bulk_::root.this_exec, first, uniform_decomposition< typename iterator_difference< InputIterator> ::type> (), typename thrust::detail::temporary_array< OutputType, DerivedPolicy> ::iterator(), init, binary_op); 
# 165
num_groups = thrust::min< typename iterator_difference< InputIterator> ::type> (num_groups, thrust::detail::util::divide_ri(n, group_size)); 
# 167
uniform_decomposition< typename iterator_difference< InputIterator> ::type>  decomp(n, num_groups); 
# 168
temporary_array partial_sums(exec, (decomp.size())); 
# 171
bulk_::async(bulk_::grid((decomp.size()), group_size, bulk_::use_default, s), reduce_partitions(), bulk_::root.this_exec, first, decomp, (partial_sums.begin()), init, binary_op); 
# 173
if ((partial_sums.size()) > 1) 
# 174
{ 
# 176
thrust::tie(num_groups, group_size) = bulk_::choose_sizes(bulk_::grid(1), reduce_partitions(), bulk_::root.this_exec, (partial_sums.begin()), (partial_sums.end()), (partial_sums.begin()), binary_op); 
# 179
bulk_::async(bulk_::grid(num_groups, group_size, bulk_::use_default, s), reduce_partitions(), bulk_::root.this_exec, (partial_sums.begin()), (partial_sums.end()), (partial_sums.begin()), binary_op); 
# 180
}  
# 182
return get_value(exec, &(partial_sums[0])); 
# 183
} 
# 187
template< class DerivedPolicy, class 
# 188
InputIterator, class 
# 189
OutputType, class 
# 190
BinaryFunction> typename thrust::detail::enable_if< thrust::detail::is_arithmetic< OutputType> ::value, OutputType> ::type 
# 196
reduce(execution_policy< DerivedPolicy>  &exec, InputIterator 
# 197
first, InputIterator 
# 198
last, OutputType 
# 199
init, BinaryFunction 
# 200
binary_op) 
# 201
{ 
# 202
return reduce_detail::tuned_reduce(exec, first, last, init, binary_op); 
# 203
} 
# 207
template< class DerivedPolicy, class 
# 208
InputIterator, class 
# 209
OutputType, class 
# 210
BinaryFunction> typename thrust::detail::disable_if< thrust::detail::is_arithmetic< OutputType> ::value, OutputType> ::type 
# 216
reduce(execution_policy< DerivedPolicy>  &exec, InputIterator 
# 217
first, InputIterator 
# 218
last, OutputType 
# 219
init, BinaryFunction 
# 220
binary_op) 
# 221
{ 
# 222
return reduce_detail::general_reduce(exec, first, last, init, binary_op); 
# 223
} 
# 227
}
# 230
template< class DerivedPolicy, class 
# 231
InputIterator, class 
# 232
OutputType, class 
# 233
BinaryFunction> OutputType 
# 235
reduce(execution_policy< DerivedPolicy>  &exec, InputIterator 
# 236
first, InputIterator 
# 237
last, OutputType 
# 238
init, BinaryFunction 
# 239
binary_op) 
# 240
{ 
# 246
typedef thrust::detail::static_assert_test< sizeof(thrust::detail::STATIC_ASSERTION_FAILURE< (bool)(thrust::detail::depend_on_instantiation< InputIterator, true> ::value)> )>  thrust_static_assert_typedef_246 __attribute((unused)); 
# 248
struct workaround { 
# 251
static OutputType parallel_path(execution_policy< DerivedPolicy>  &exec, InputIterator 
# 252
first, InputIterator 
# 253
last, OutputType 
# 254
init, BinaryFunction 
# 255
binary_op) 
# 256
{ 
# 257
return reduce_detail::reduce(exec, first, last, init, binary_op); 
# 258
} 
# 261
static OutputType sequential_path(execution_policy< DerivedPolicy>  &, InputIterator 
# 262
first, InputIterator 
# 263
last, OutputType 
# 264
init, BinaryFunction 
# 265
binary_op) 
# 266
{ 
# 267
return thrust::reduce(thrust::seq, first, last, init, binary_op); 
# 268
} 
# 269
}; 
# 272
return (workaround::parallel_path)(exec, first, last, init, binary_op); 
# 276
} 
# 279
}
# 280
}
# 281
}
# 282
}
# 24 "/usr/local/cuda-8.0/include/thrust/detail/type_traits/algorithm/intermediate_type_from_function_and_iterators.h"
namespace thrust { 
# 27
namespace detail { 
# 44
template< class InputIterator, class OutputIterator, class Function> 
# 45
struct intermediate_type_from_function_and_iterators : public eval_if< has_result_type< Function> ::value, result_type< Function> , eval_if< is_output_iterator< OutputIterator> ::value, iterator_value< InputIterator> , iterator_value< OutputIterator> > >  { 
# 56
}; 
# 58
}
# 60
}
# 25 "/usr/local/cuda-8.0/include/thrust/system/detail/sequential/reduce_by_key.h"
namespace thrust { 
# 27
namespace system { 
# 29
namespace detail { 
# 31
namespace sequential { 
# 36
template< class DerivedPolicy, class 
# 37
InputIterator1, class 
# 38
InputIterator2, class 
# 39
OutputIterator1, class 
# 40
OutputIterator2, class 
# 41
BinaryPredicate, class 
# 42
BinaryFunction> pair< OutputIterator1, OutputIterator2>  
# 45
reduce_by_key(execution_policy< DerivedPolicy>  &, InputIterator1 
# 46
keys_first, InputIterator1 
# 47
keys_last, InputIterator2 
# 48
values_first, OutputIterator1 
# 49
keys_output, OutputIterator2 
# 50
values_output, BinaryPredicate 
# 51
binary_pred, BinaryFunction 
# 52
binary_op) 
# 53
{ 
# 54
typedef typename iterator_traits< InputIterator1> ::value_type InputKeyType; 
# 55
typedef typename iterator_traits< InputIterator2> ::value_type InputValueType; 
# 61
typedef typename thrust::detail::intermediate_type_from_function_and_iterators< InputIterator2, OutputIterator2, BinaryFunction> ::type TemporaryType; 
# 63
if (keys_first != keys_last) 
# 64
{ 
# 65
InputKeyType temp_key = *keys_first; 
# 66
TemporaryType temp_value = *values_first; 
# 68
for ((++keys_first), (++values_first); keys_first != keys_last; (++keys_first), (++values_first)) 
# 71
{ 
# 72
InputKeyType key = *keys_first; 
# 73
InputValueType value = *values_first; 
# 75
if (binary_pred(temp_key, key)) 
# 76
{ 
# 77
temp_value = binary_op(temp_value, value); 
# 78
} else 
# 80
{ 
# 81
(*keys_output) = temp_key; 
# 82
(*values_output) = temp_value; 
# 84
++keys_output; 
# 85
++values_output; 
# 87
temp_key = key; 
# 88
temp_value = value; 
# 89
}  
# 90
}  
# 92
(*keys_output) = temp_key; 
# 93
(*values_output) = temp_value; 
# 95
++keys_output; 
# 96
++values_output; 
# 97
}  
# 99
return thrust::make_pair(keys_output, values_output); 
# 100
} 
# 103
}
# 104
}
# 105
}
# 106
}
# 27 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/reduce_by_key.h"
namespace thrust { 
# 29
namespace system { 
# 31
namespace cuda { 
# 33
namespace detail { 
# 37
template< class DerivedPolicy, class 
# 38
InputIterator1, class 
# 39
InputIterator2, class 
# 40
OutputIterator1, class 
# 41
OutputIterator2, class 
# 42
BinaryPredicate, class 
# 43
BinaryFunction> pair< OutputIterator1, OutputIterator2>  
# 37
reduce_by_key(execution_policy< DerivedPolicy>  & exec, InputIterator1 keys_first, InputIterator1 keys_last, InputIterator2 values_first, OutputIterator1 keys_output, OutputIterator2 values_output, BinaryPredicate binary_pred, BinaryFunction binary_op); 
# 56
}
# 57
}
# 58
}
# 59
}
# 22 "/usr/local/cuda-8.0/include/thrust/iterator/detail/constant_iterator_base.h"
namespace thrust { 
# 26
template< class , class , class > class constant_iterator; 
# 28
namespace detail { 
# 31
template< class Value, class 
# 32
Incrementable, class 
# 33
System> 
# 34
struct constant_iterator_base { 
# 36
typedef Value value_type; 
# 43
typedef value_type reference; 
# 49
typedef typename ia_dflt_help< Incrementable, identity_< signed int> > ::type incrementable; 
# 55
typedef counting_iterator< typename ia_dflt_help< Incrementable, identity_< signed int> > ::type, System, random_access_traversal_tag>  base_iterator; 
# 64
typedef iterator_adaptor< constant_iterator< Value, Incrementable, System> , counting_iterator< typename ia_dflt_help< Incrementable, identity_< signed int> > ::type, System, random_access_traversal_tag> , Value, typename iterator_system< counting_iterator< typename ia_dflt_help< Incrementable, identity_< signed int> > ::type, System, random_access_traversal_tag> > ::type, typename iterator_traversal< counting_iterator< typename ia_dflt_help< Incrementable, identity_< signed int> > ::type, System, random_access_traversal_tag> > ::type, Value>  type; 
# 65
}; 
# 67
}
# 69
}
# 29 "/usr/local/cuda-8.0/include/thrust/iterator/constant_iterator.h"
namespace thrust { 
# 96
template< class Value, class 
# 97
Incrementable = use_default, class 
# 98
System = use_default> 
# 99
class constant_iterator : public detail::constant_iterator_base< Value, Incrementable, System> ::type { 
# 104
friend class iterator_core_access; 
# 105
typedef typename ::thrust::detail::constant_iterator_base< Value, Incrementable, System> ::type super_t; 
# 106
typedef typename ::thrust::detail::constant_iterator_base< Value, Incrementable, System> ::incrementable incrementable; 
# 107
typedef typename ::thrust::detail::constant_iterator_base< Value, Incrementable, System> ::base_iterator base_iterator; 
# 110
public: typedef typename ::thrust::detail::constant_iterator_base< Value, Incrementable, System> ::type::reference reference; 
# 111
typedef typename ::thrust::detail::constant_iterator_base< Value, Incrementable, System> ::type::value_type value_type; 
# 120
constant_iterator() : super_t(), m_value() 
# 121
{ } 
# 129
constant_iterator(const constant_iterator &rhs) : super_t((rhs.base())), m_value(rhs.m_value) 
# 130
{ } 
# 137
template< class OtherSystem> 
# 139
constant_iterator(const ::thrust::constant_iterator< Value, Incrementable, OtherSystem>  &rhs, typename ::thrust::detail::enable_if_convertible< typename iterator_system< ::thrust::constant_iterator< Value, Incrementable, OtherSystem> > ::type, typename iterator_system< typename ::thrust::detail::constant_iterator_base< Value, Incrementable, System> ::type> ::type> ::type * = 0) : super_t((rhs.base())), m_value((rhs.value())) 
# 144
{ } 
# 156
constant_iterator(const value_type &v, const incrementable &i = incrementable()) : super_t((base_iterator)i), m_value(v) 
# 157
{ } 
# 167
template< class OtherValue, class OtherIncrementable> 
# 169
constant_iterator(const OtherValue &v, const OtherIncrementable &i = incrementable()) : super_t((base_iterator)i), m_value(v) 
# 170
{ } 
# 176
const Value &value() const 
# 177
{ return m_value; } 
# 184
protected: const Value &value_reference() const 
# 185
{ return m_value; } 
# 188
Value &value_reference() 
# 189
{ return m_value; } 
# 193
private: reference dereference() const 
# 194
{ 
# 195
return m_value; 
# 196
} 
# 199
Value m_value; 
# 203
}; 
# 220
template< class V, class I> inline constant_iterator< V, I>  
# 222
make_constant_iterator(V x, I i = ((int)0)) 
# 223
{ 
# 224
return constant_iterator< V, I> (x, i); 
# 225
} 
# 237
template< class V> inline constant_iterator< V>  
# 239
make_constant_iterator(V x) 
# 240
{ 
# 241
return constant_iterator< V> (x, 0); 
# 242
} 
# 250
}
# 25 "/usr/local/cuda-8.0/include/thrust/iterator/detail/discard_iterator_base.h"
namespace thrust { 
# 29
template< class > class discard_iterator; 
# 31
namespace detail { 
# 35
template< class System> 
# 36
struct discard_iterator_base { 
# 40
typedef any_assign value_type; 
# 41
typedef any_assign &reference; 
# 42
typedef std::ptrdiff_t incrementable; 
# 48
typedef counting_iterator< long, System, random_access_traversal_tag>  base_iterator; 
# 57
typedef iterator_adaptor< discard_iterator< System> , counting_iterator< long, System, random_access_traversal_tag> , any_assign, typename iterator_system< counting_iterator< long, System, random_access_traversal_tag> > ::type, typename iterator_traversal< counting_iterator< long, System, random_access_traversal_tag> > ::type, any_assign &>  type; 
# 58
}; 
# 61
}
# 63
}
# 30 "/usr/local/cuda-8.0/include/thrust/iterator/discard_iterator.h"
namespace thrust { 
# 93
template< class System = use_default> 
# 94
class discard_iterator : public detail::discard_iterator_base< System> ::type { 
# 99
friend class iterator_core_access; 
# 100
typedef typename ::thrust::detail::discard_iterator_base< System> ::type super_t; 
# 101
typedef typename ::thrust::detail::discard_iterator_base< System> ::incrementable incrementable; 
# 102
typedef typename ::thrust::detail::discard_iterator_base< System> ::base_iterator base_iterator; 
# 105
public: typedef typename ::thrust::detail::discard_iterator_base< System> ::type::reference reference; 
# 106
typedef typename ::thrust::detail::discard_iterator_base< System> ::type::value_type value_type; 
# 116
discard_iterator(const discard_iterator &rhs) : super_t((rhs.base())) 
# 117
{ } 
# 127
discard_iterator(const incrementable &i = incrementable()) : super_t((base_iterator)i) 
# 128
{ } 
# 135
private: reference dereference() const 
# 136
{ 
# 137
return m_element; 
# 138
} 
# 140
mutable value_type m_element; 
# 144
}; 
# 157
inline discard_iterator<>  make_discard_iterator(iterator_adaptor< discard_iterator<> , counting_iterator< long, use_default, random_access_traversal_tag> , detail::any_assign, any_system_tag, random_access_traversal_tag, detail::any_assign &> ::difference_type i = (iterator_adaptor< discard_iterator<> , counting_iterator< long, use_default, random_access_traversal_tag> , detail::any_assign, any_system_tag, random_access_traversal_tag, detail::any_assign &> ::difference_type)0) 
# 158
{ 
# 159
return ((discard_iterator<> )(i)); 
# 160
} 
# 168
}
# 27 "/usr/local/cuda-8.0/include/thrust/detail/range/head_flags.h"
namespace thrust { 
# 29
namespace detail { 
# 33
template< class RandomAccessIterator, class 
# 34
BinaryPredicate = thrust::equal_to< typename iterator_value< RandomAccessIterator> ::type> , class 
# 35
ValueType = bool, class 
# 36
IndexType = typename iterator_difference< RandomAccessIterator> ::type> 
# 37
class head_flags_with_init { 
# 39
typedef typename iterator_value< RandomAccessIterator> ::type init_type; 
# 44
public: struct head_flag_functor { 
# 46
BinaryPredicate binary_pred; 
# 47
init_type init; 
# 48
IndexType n; 
# 50
typedef ValueType result_type; 
# 53
head_flag_functor(init_type init, IndexType n) : binary_pred(), init(init), n(n) 
# 55
{ } 
# 58
head_flag_functor(init_type init, IndexType n, BinaryPredicate binary_pred) : binary_pred(binary_pred), init(init), n(n) 
# 60
{ } 
# 62
template< class Tuple> 
# 63
__attribute((always_inline)) result_type 
# 64
operator()(const Tuple &t) 
# 65
{ 
# 66
const IndexType i = thrust::get< 0> (t); 
# 68
if (i == 0) 
# 69
{ 
# 70
return !(binary_pred)(init, thrust::get< 1> (t)); 
# 71
}  
# 73
return !(binary_pred)(thrust::get< 1> (t), thrust::get< 2> (t)); 
# 74
} 
# 75
}; 
# 77
typedef thrust::counting_iterator< IndexType>  counting_iterator; 
# 83
typedef transform_iterator< head_flag_functor, zip_iterator< tuple< thrust::counting_iterator< IndexType> , RandomAccessIterator, RandomAccessIterator, null_type, null_type, null_type, null_type, null_type, null_type, null_type> > >  iterator; 
# 87
head_flags_with_init(RandomAccessIterator first, RandomAccessIterator last, init_type init) : m_begin(thrust::make_transform_iterator(thrust::make_zip_iterator(thrust::make_tuple(((thrust::counting_iterator< IndexType> )(0)), first, first - 1)), head_flag_functor(init, last - first))), m_end((m_begin) + (last - first)) 
# 91
{ } 
# 95
head_flags_with_init(RandomAccessIterator first, RandomAccessIterator last, init_type init, BinaryPredicate binary_pred) : m_begin(thrust::make_transform_iterator(thrust::make_zip_iterator(thrust::make_tuple(((thrust::counting_iterator< IndexType> )(0)), first, first - 1)), head_flag_functor(init, last - first, binary_pred))), m_end((m_begin) + (last - first)) 
# 99
{ } 
# 102
iterator begin() const 
# 103
{ 
# 104
return m_begin; 
# 105
} 
# 108
iterator end() const 
# 109
{ 
# 110
return m_end; 
# 111
} 
# 113
template< class OtherIndex> typename transform_iterator< head_flag_functor, zip_iterator< tuple< thrust::counting_iterator< IndexType> , RandomAccessIterator, RandomAccessIterator, null_type, null_type, null_type, null_type, null_type, null_type, null_type> > > ::reference 
# 115
operator[](OtherIndex i) 
# 116
{ 
# 117
return *(begin() + i); 
# 118
} 
# 121
private: iterator m_begin, m_end; 
# 122
}; 
# 126
template< class RandomAccessIterator, class 
# 127
BinaryPredicate = thrust::equal_to< typename iterator_value< RandomAccessIterator> ::type> , class 
# 128
ValueType = bool, class 
# 129
IndexType = typename iterator_difference< RandomAccessIterator> ::type> 
# 130
class head_flags { 
# 135
public: struct head_flag_functor { 
# 137
BinaryPredicate binary_pred; 
# 138
IndexType n; 
# 140
typedef ValueType result_type; 
# 143
head_flag_functor(IndexType n) : binary_pred(), n(n) 
# 145
{ } 
# 148
head_flag_functor(IndexType n, BinaryPredicate binary_pred) : binary_pred(binary_pred), n(n) 
# 150
{ } 
# 152
template< class Tuple> 
# 153
__attribute((always_inline)) result_type 
# 154
operator()(const Tuple &t) 
# 155
{ 
# 156
const IndexType i = thrust::get< 0> (t); 
# 160
return (i == 0) || (!(binary_pred)(thrust::get< 1> (t), thrust::get< 2> (t))); 
# 161
} 
# 162
}; 
# 164
typedef thrust::counting_iterator< IndexType>  counting_iterator; 
# 170
typedef transform_iterator< head_flag_functor, zip_iterator< tuple< thrust::counting_iterator< IndexType> , RandomAccessIterator, RandomAccessIterator, null_type, null_type, null_type, null_type, null_type, null_type, null_type> > >  iterator; 
# 173
head_flags(RandomAccessIterator first, RandomAccessIterator last) : m_begin(thrust::make_transform_iterator(thrust::make_zip_iterator(thrust::make_tuple(((thrust::counting_iterator< IndexType> )(0)), first, first - 1)), (head_flag_functor)(last - first))), m_end((m_begin) + (last - first)) 
# 177
{ } 
# 180
head_flags(RandomAccessIterator first, RandomAccessIterator last, BinaryPredicate binary_pred) : m_begin(thrust::make_transform_iterator(thrust::make_zip_iterator(thrust::make_tuple(((thrust::counting_iterator< IndexType> )(0)), first, first - 1)), head_flag_functor(last - first, binary_pred))), m_end((m_begin) + (last - first)) 
# 184
{ } 
# 187
iterator begin() const 
# 188
{ 
# 189
return m_begin; 
# 190
} 
# 193
iterator end() const 
# 194
{ 
# 195
return m_end; 
# 196
} 
# 198
template< class OtherIndex> typename transform_iterator< head_flag_functor, zip_iterator< tuple< thrust::counting_iterator< IndexType> , RandomAccessIterator, RandomAccessIterator, null_type, null_type, null_type, null_type, null_type, null_type, null_type> > > ::reference 
# 200
operator[](OtherIndex i) 
# 201
{ 
# 202
return *(begin() + i); 
# 203
} 
# 206
private: iterator m_begin, m_end; 
# 207
}; 
# 210
template< class RandomAccessIterator, class BinaryPredicate> head_flags< RandomAccessIterator, BinaryPredicate>  
# 213
make_head_flags(RandomAccessIterator first, RandomAccessIterator last, BinaryPredicate binary_pred) 
# 214
{ 
# 215
return head_flags< RandomAccessIterator, BinaryPredicate> (first, last, binary_pred); 
# 216
} 
# 219
template< class RandomAccessIterator> head_flags< RandomAccessIterator>  
# 222
make_head_flags(RandomAccessIterator first, RandomAccessIterator last) 
# 223
{ 
# 224
return head_flags< RandomAccessIterator> (first, last); 
# 225
} 
# 228
}
# 229
}
# 26 "/usr/local/cuda-8.0/include/thrust/detail/range/tail_flags.h"
namespace thrust { 
# 28
namespace detail { 
# 32
template< class RandomAccessIterator, class 
# 33
BinaryPredicate = thrust::equal_to< typename iterator_value< RandomAccessIterator> ::type> , class 
# 34
ValueType = bool, class 
# 35
IndexType = typename iterator_difference< RandomAccessIterator> ::type> 
# 36
class tail_flags { 
# 41
public: struct tail_flag_functor { 
# 43
BinaryPredicate binary_pred; 
# 44
RandomAccessIterator iter; 
# 45
IndexType n; 
# 47
typedef ValueType result_type; 
# 50
tail_flag_functor(RandomAccessIterator first, RandomAccessIterator last) : binary_pred(), iter(first), n(last - first) 
# 52
{ } 
# 55
tail_flag_functor(RandomAccessIterator first, RandomAccessIterator last, BinaryPredicate binary_pred) : binary_pred(binary_pred), iter(first), n(last - first) 
# 57
{ } 
# 59
__attribute((always_inline)) result_type 
# 60
operator()(const IndexType &i) 
# 61
{ 
# 62
return (i == ((n) - 1)) || (!(binary_pred)((iter)[i], (iter)[i + 1])); 
# 63
} 
# 64
}; 
# 66
typedef thrust::counting_iterator< IndexType>  counting_iterator; 
# 72
typedef transform_iterator< tail_flag_functor, thrust::counting_iterator< IndexType> >  iterator; 
# 76
tail_flags(RandomAccessIterator first, RandomAccessIterator last) : m_begin(thrust::make_transform_iterator(((thrust::counting_iterator< IndexType> )(0)), tail_flag_functor(first, last))), m_end((m_begin) + (last - first)) 
# 80
{ } 
# 84
tail_flags(RandomAccessIterator first, RandomAccessIterator last, BinaryPredicate binary_pred) : m_begin(thrust::make_transform_iterator(((thrust::counting_iterator< IndexType> )(0)), tail_flag_functor(first, last, binary_pred))), m_end((m_begin) + (last - first)) 
# 88
{ } 
# 91
iterator begin() const 
# 92
{ 
# 93
return m_begin; 
# 94
} 
# 97
iterator end() const 
# 98
{ 
# 99
return m_end; 
# 100
} 
# 102
template< class OtherIndex> typename transform_iterator< tail_flag_functor, thrust::counting_iterator< IndexType> > ::reference 
# 104
operator[](OtherIndex i) 
# 105
{ 
# 106
return *(begin() + i); 
# 107
} 
# 110
private: iterator m_begin, m_end; 
# 111
}; 
# 114
template< class RandomAccessIterator, class BinaryPredicate> tail_flags< RandomAccessIterator, BinaryPredicate>  
# 117
make_tail_flags(RandomAccessIterator first, RandomAccessIterator last, BinaryPredicate binary_pred) 
# 118
{ 
# 119
return tail_flags< RandomAccessIterator, BinaryPredicate> (first, last, binary_pred); 
# 120
} 
# 123
template< class RandomAccessIterator> tail_flags< RandomAccessIterator>  
# 126
make_tail_flags(RandomAccessIterator first, RandomAccessIterator last) 
# 127
{ 
# 128
return tail_flags< RandomAccessIterator> (first, last); 
# 129
} 
# 132
}
# 133
}
# 9 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/reduce_intervals.hpp"
namespace thrust { 
# 11
namespace system { 
# 13
namespace cuda { 
# 15
namespace detail { 
# 17
namespace reduce_intervals_detail { 
# 21
struct reduce_intervals_kernel { 
# 23
template< std::size_t groupsize, std::size_t grainsize, class RandomAccessIterator1, class Decomposition, class RandomAccessIterator2, class BinaryFunction> void 
# 24
operator()(bulk_::concurrent_group< bulk_::agent< grainsize> , groupsize>  &this_group, RandomAccessIterator1 
# 25
first, Decomposition 
# 26
decomp, RandomAccessIterator2 
# 27
result, BinaryFunction 
# 28
binary_op) 
# 29
{int volatile ___ = 1;(void)this_group;(void)first;(void)decomp;(void)result;(void)binary_op;
# 42
::exit(___);}
#if 0
# 29
{ 
# 30
typedef typename iterator_value< RandomAccessIterator1> ::type value_type; 
# 32
typename Decomposition::range rng = decomp[(this_group.index())]; 
# 34
value_type init = first[(rng.second) - 1]; 
# 36
value_type sum = bulk_::reduce(this_group, first + (rng.first), (first + (rng.second)) - 1, init, binary_op); 
# 38
if (((this_group.this_exec).index()) == 0) 
# 39
{ 
# 40
(result[(this_group.index())]) = sum; 
# 41
}  
# 42
} 
#endif
# 43 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/reduce_intervals.hpp"
}; 
# 46
}
# 49
template< class DerivedPolicy, class RandomAccessIterator1, class Decomposition, class RandomAccessIterator2, class BinaryFunction> RandomAccessIterator2 
# 51
reduce_intervals_(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator1 first, Decomposition decomp, RandomAccessIterator2 result, BinaryFunction binary_op) 
# 52
{ 
# 53
typedef typename iterator_value< RandomAccessIterator2> ::type result_type; 
# 54
const size_t groupsize = (128); 
# 55
size_t heap_size = (groupsize * sizeof(result_type)); 
# 56
bulk_::async(bulk_::grid< 128UL, 7> ((decomp.size()), heap_size, stream(thrust::detail::derived_cast(exec))), reduce_intervals_detail::reduce_intervals_kernel(), bulk_::root.this_exec, first, decomp, result, binary_op); 
# 58
return result + (decomp.size()); 
# 59
} 
# 62
template< class DerivedPolicy, class RandomAccessIterator1, class Size, class RandomAccessIterator2, class BinaryFunction> RandomAccessIterator2 
# 64
reduce_intervals_(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator1 first, RandomAccessIterator1 last, Size interval_size, RandomAccessIterator2 result, BinaryFunction binary_op) 
# 65
{ 
# 66
return cuda::detail::reduce_intervals_(exec, first, make_blocked_decomposition< Size> (last - first, interval_size), result, binary_op); 
# 67
} 
# 70
}
# 71
}
# 72
}
# 73
}
# 34 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/reduce_by_key.inl"
namespace thrust { 
# 36
namespace system { 
# 38
namespace cuda { 
# 40
namespace detail { 
# 42
namespace reduce_by_key_detail { 
# 46
struct reduce_by_key_kernel { 
# 48
template< class ConcurrentGroup, class 
# 49
RandomAccessIterator1, class 
# 50
Decomposition, class 
# 51
RandomAccessIterator2, class 
# 52
RandomAccessIterator3, class 
# 53
RandomAccessIterator4, class 
# 54
RandomAccessIterator5, class 
# 55
RandomAccessIterator6, class 
# 56
RandomAccessIterator7, class 
# 57
BinaryPredicate, class 
# 58
BinaryFunction> pair< RandomAccessIterator3, RandomAccessIterator4>  
# 61
operator()(ConcurrentGroup &g, RandomAccessIterator1 
# 62
keys_first, Decomposition 
# 63
decomp, RandomAccessIterator2 
# 64
values_first, RandomAccessIterator3 
# 65
keys_result, RandomAccessIterator4 
# 66
values_result, RandomAccessIterator5 
# 67
interval_output_offsets, RandomAccessIterator6 
# 68
interval_values, RandomAccessIterator7 
# 69
is_carry, tuple< BinaryPredicate, BinaryFunction, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type>  
# 72
pred_and_binary_op) 
# 73
{int volatile ___ = 1;(void)g;(void)keys_first;(void)decomp;(void)values_first;(void)keys_result;(void)values_result;(void)interval_output_offsets;(void)interval_values;(void)is_carry;(void)pred_and_binary_op;
# 124
::exit(___);}
#if 0
# 73
{ 
# 74
typedef typename iterator_value< RandomAccessIterator1> ::type key_type; 
# 75
typedef typename iterator_value< RandomAccessIterator2> ::type value_type; 
# 77
BinaryPredicate pred = thrust::get< 0> (pred_and_binary_op); 
# 78
BinaryFunction binary_op = thrust::get< 1> (pred_and_binary_op); 
# 80
thrust::detail::tail_flags< RandomAccessIterator1, BinaryPredicate>  tail_flags(keys_first, keys_first + (decomp.n()), pred); 
# 82
typename Decomposition::size_type input_first, input_last; 
# 83
thrust::tie(input_first, input_last) = (decomp[(g.index())]); 
# 85
typename Decomposition::size_type output_first = ((g.index()) == 0) ? 0 : (interval_output_offsets[(g.index()) - 1]); 
# 87
key_type init_key = keys_first[input_first]; 
# 88
value_type init_value = values_first[input_first]; 
# 91
thrust::tie(keys_result, values_result, init_key, init_value) = bulk_::reduce_by_key(g, (keys_first + input_first) + 1, keys_first + input_last, (values_first + input_first) + 1, keys_result + output_first, values_result + output_first, init_key, init_value, pred, binary_op); 
# 103
if (((g.this_exec).index()) == 0) 
# 104
{ 
# 105
bool interval_has_carry = !(tail_flags[input_last - 1]); 
# 107
if (interval_has_carry) 
# 108
{ 
# 109
(interval_values[(g.index())]) = init_value; 
# 110
} else 
# 112
{ 
# 113
(*keys_result) = init_key; 
# 114
(*values_result) = init_value; 
# 116
++keys_result; 
# 117
++values_result; 
# 118
}  
# 120
(is_carry[(g.index())]) = interval_has_carry; 
# 121
}  
# 123
return thrust::make_pair(keys_result, values_result); 
# 124
} 
#endif
# 127 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/reduce_by_key.inl"
template< class ConcurrentGroup, class 
# 128
RandomAccessIterator1, class 
# 129
RandomAccessIterator2, class 
# 130
RandomAccessIterator3, class 
# 131
RandomAccessIterator4, class 
# 132
BinaryPredicate, class 
# 133
BinaryFunction, class 
# 134
Iterator> void 
# 136
operator()(ConcurrentGroup &g, RandomAccessIterator1 
# 137
keys_first, RandomAccessIterator1 
# 138
keys_last, RandomAccessIterator2 
# 139
values_first, RandomAccessIterator3 
# 140
keys_result, RandomAccessIterator4 
# 141
values_result, BinaryPredicate 
# 142
pred, BinaryFunction 
# 143
binary_op, Iterator 
# 144
result_size) 
# 145
{int volatile ___ = 1;(void)g;(void)keys_first;(void)keys_last;(void)values_first;(void)keys_result;(void)values_result;(void)pred;(void)binary_op;(void)result_size;
# 159
::exit(___);}
#if 0
# 145
{ 
# 146
RandomAccessIterator3 old_keys_result = keys_result; 
# 148
thrust::tie(keys_result, values_result) = operator()(g, keys_first, make_trivial_decomposition(keys_last - keys_first), values_first, keys_result, values_result, thrust::make_constant_iterator< int> (0), thrust::make_discard_iterator(), thrust::make_discard_iterator(), thrust::make_tuple(pred, binary_op)); 
# 155
if (((g.this_exec).index()) == 0) 
# 156
{ 
# 157
(*result_size) = (keys_result - old_keys_result); 
# 158
}  
# 159
} 
#endif
# 160 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/reduce_by_key.inl"
}; 
# 163
struct tuple_and { 
# 165
typedef bool result_type; 
# 167
template< class Tuple> bool 
# 169
operator()(Tuple t) 
# 170
{ 
# 171
return thrust::get< 0> (t) && thrust::get< 1> (t); 
# 172
} 
# 173
}; 
# 176
template< class DerivedPolicy, class 
# 177
Iterator1, class 
# 178
Iterator2, class 
# 179
Iterator3, class 
# 180
Iterator4, class 
# 181
BinaryFunction> void 
# 183
sum_tail_carries(execution_policy< DerivedPolicy>  &exec, Iterator1 
# 184
interval_values_first, Iterator1 
# 185
interval_values_last, Iterator2 
# 186
interval_output_offsets_first, Iterator2 
# 187
interval_output_offsets_last, Iterator3 
# 188
is_carry, Iterator4 
# 189
values_result, BinaryFunction 
# 190
binary_op) 
# 191
{ 
# 192
typedef thrust::zip_iterator< tuple< Iterator2, Iterator3, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type> >  zip_iterator; 
# 194
thrust::detail::tail_flags< thrust::zip_iterator< tuple< Iterator2, Iterator3, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type> > >  tail_flags(thrust::make_zip_iterator(thrust::make_tuple(interval_output_offsets_first, is_carry)), thrust::make_zip_iterator(thrust::make_tuple(interval_output_offsets_last, is_carry))); 
# 200
thrust::transform_if(exec, interval_values_first, interval_values_last, thrust::make_permutation_iterator(values_result, interval_output_offsets_first), thrust::make_transform_iterator(thrust::make_zip_iterator(thrust::make_tuple((tail_flags.begin()), is_carry)), tuple_and()), thrust::make_permutation_iterator(values_result, interval_output_offsets_first), binary_op, identity< bool> ()); 
# 207
} 
# 210
template< class InputIterator, class OutputIterator, class BinaryFunction> 
# 211
struct intermediate_type : public thrust::detail::eval_if< thrust::detail::has_result_type< BinaryFunction> ::value, thrust::detail::result_type< BinaryFunction> , thrust::detail::eval_if< thrust::detail::is_output_iterator< OutputIterator> ::value, iterator_value< InputIterator> , iterator_value< OutputIterator> > >  { 
# 221
}; 
# 224
template< class Size, class 
# 225
DerivedPolicy, class 
# 226
InputIterator1, class 
# 227
InputIterator2, class 
# 228
OutputIterator1, class 
# 229
OutputIterator2, class 
# 230
BinaryPredicate, class 
# 231
BinaryFunction> pair< OutputIterator1, OutputIterator2>  
# 234
reduce_by_key(execution_policy< DerivedPolicy>  &exec, InputIterator1 
# 235
keys_first, InputIterator1 
# 236
keys_last, InputIterator2 
# 237
values_first, OutputIterator1 
# 238
keys_result, OutputIterator2 
# 239
values_result, BinaryPredicate 
# 240
binary_pred, BinaryFunction 
# 241
binary_op) 
# 242
{ 
# 243
typedef typename iterator_difference< InputIterator1> ::type difference_type; 
# 244
typedef typename iterator_value< InputIterator2> ::type value_type; 
# 245
typedef Size size_type; 
# 247
const difference_type n = keys_last - keys_first; 
# 249
if (n <= 0) { return thrust::make_pair(keys_result, values_result); }  
# 251
const size_type threshold_of_parallelism = (20000); 
# 253
if (n <= threshold_of_parallelism) 
# 254
{ 
# 255
thrust::detail::temporary_array< Size, DerivedPolicy>  result_size_storage(exec, 1); 
# 260
const int groupsize = ((sizeof(value_type) <= sizeof(int)) ? 512 : ((sizeof(value_type) <= ((2) * sizeof(int))) ? 256 : 128)); 
# 265
const int grainsize = ((sizeof(value_type) == sizeof(int)) ? 3 : 5); 
# 267
size_type heap_size = ((groupsize * grainsize) * (sizeof(size_type) + sizeof(value_type))); 
# 268
bulk_::async(bulk_::grid< groupsize, grainsize> (1, heap_size, stream(thrust::detail::derived_cast(exec))), reduce_by_key_kernel(), bulk_::root.this_exec, keys_first, keys_last, values_first, keys_result, values_result, binary_pred, binary_op, (result_size_storage.begin())); 
# 271
size_type result_size = get_value(exec, &(result_size_storage[0])); 
# 273
return thrust::make_pair(keys_result + result_size, values_result + result_size); 
# 274
}  
# 278
typedef typename reduce_by_key_detail::intermediate_type< InputIterator2, OutputIterator2, BinaryFunction> ::type intermediate_type; 
# 280
const size_type groupsize = (128); 
# 281
const size_type grainsize = (5); 
# 282
size_type tile_size = groupsize * grainsize; 
# 284
const size_type interval_size = threshold_of_parallelism; 
# 286
size_type subscription = (100); 
# 287
size_type num_groups = thrust::min< Size> (subscription * bulk_::concurrent_group<> ::hardware_concurrency(), ((n + interval_size) - 1) / interval_size); 
# 288
aligned_decomposition< Size>  decomp(n, num_groups, tile_size); 
# 295
thrust::detail::tail_flags< InputIterator1, BinaryPredicate, Size>  tail_flags(keys_first, keys_last, binary_pred); 
# 297
thrust::detail::temporary_array< Size, DerivedPolicy>  interval_output_offsets(exec, (decomp.size())); 
# 299
reduce_intervals_(exec, (tail_flags.begin()), decomp, (interval_output_offsets.begin()), plus< Size> ()); 
# 302
thrust::inclusive_scan(exec, (interval_output_offsets.begin()), (interval_output_offsets.end()), (interval_output_offsets.begin())); 
# 305
thrust::detail::temporary_array< bool, DerivedPolicy>  is_carry(exec, (decomp.size())); 
# 306
thrust::detail::temporary_array< typename reduce_by_key_detail::intermediate_type< InputIterator2, OutputIterator2, BinaryFunction> ::type, DerivedPolicy>  interval_values(exec, (decomp.size())); 
# 308
size_type heap_size = tile_size * (sizeof(size_type) + sizeof(value_type)); 
# 309
bulk_::async(bulk_::grid< groupsize, grainsize> ((decomp.size()), heap_size, stream(thrust::detail::derived_cast(exec))), reduce_by_key_kernel(), bulk_::root.this_exec, keys_first, decomp, values_first, keys_result, values_result, (interval_output_offsets.begin()), (interval_values.begin()), (is_carry.begin()), thrust::make_tuple(binary_pred, binary_op)); 
# 314
thrust::inclusive_scan_by_key(exec, thrust::make_zip_iterator(thrust::make_tuple((interval_output_offsets.begin()), (is_carry.begin()))), thrust::make_zip_iterator(thrust::make_tuple((interval_output_offsets.end()), (is_carry.end()))), (interval_values.begin()), (interval_values.begin()), equal_to< tuple< Size, bool, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type> > (), binary_op); 
# 323
reduce_by_key_detail::sum_tail_carries(exec, (interval_values.begin()), (interval_values.end()), (interval_output_offsets.begin()), (interval_output_offsets.end()), (is_carry.begin()), values_result, binary_op); 
# 330
difference_type result_size = interval_output_offsets[(interval_output_offsets.size()) - 1]; 
# 332
return thrust::make_pair(keys_result + result_size, values_result + result_size); 
# 333
} 
# 336
template< class DerivedPolicy, class 
# 337
InputIterator1, class 
# 338
InputIterator2, class 
# 339
OutputIterator1, class 
# 340
OutputIterator2, class 
# 341
BinaryPredicate, class 
# 342
BinaryFunction> pair< OutputIterator1, OutputIterator2>  
# 345
reduce_by_key(execution_policy< DerivedPolicy>  &exec, InputIterator1 
# 346
keys_first, InputIterator1 
# 347
keys_last, InputIterator2 
# 348
values_first, OutputIterator1 
# 349
keys_result, OutputIterator2 
# 350
values_result, BinaryPredicate 
# 351
binary_pred, BinaryFunction 
# 352
binary_op) 
# 353
{ 
# 354
pair< OutputIterator1, OutputIterator2>  result(keys_result, values_result); 
# 356
typedef typename iterator_difference< InputIterator1> ::type difference_type; 
# 360
if ((keys_last - keys_first) <= (static_cast< difference_type>(((2147483647) * 2U) + 1U))) 
# 361
{ 
# 362
result = reduce_by_key_detail::reduce_by_key< unsigned> (exec, keys_first, keys_last, values_first, keys_result, values_result, binary_pred, binary_op); 
# 369
} else 
# 371
{ 
# 372
result = reduce_by_key_detail::reduce_by_key< typename iterator_difference< InputIterator1> ::type> (exec, keys_first, keys_last, values_first, keys_result, values_result, binary_pred, binary_op); 
# 379
}  
# 381
return result; 
# 382
} 
# 385
}
# 388
template< class DerivedPolicy, class 
# 389
InputIterator1, class 
# 390
InputIterator2, class 
# 391
OutputIterator1, class 
# 392
OutputIterator2, class 
# 393
BinaryPredicate, class 
# 394
BinaryFunction> pair< OutputIterator1, OutputIterator2>  
# 397
reduce_by_key(execution_policy< DerivedPolicy>  &exec, InputIterator1 
# 398
keys_first, InputIterator1 
# 399
keys_last, InputIterator2 
# 400
values_first, OutputIterator1 
# 401
keys_result, OutputIterator2 
# 402
values_result, BinaryPredicate 
# 403
binary_pred, BinaryFunction 
# 404
binary_op) 
# 405
{ 
# 411
typedef thrust::detail::static_assert_test< sizeof(thrust::detail::STATIC_ASSERTION_FAILURE< (bool)(thrust::detail::depend_on_instantiation< InputIterator1, true> ::value)> )>  thrust_static_assert_typedef_411 __attribute((unused)); 
# 413
struct workaround { 
# 417
static pair< OutputIterator1, OutputIterator2>  parallel_path(execution_policy< DerivedPolicy>  &exec, InputIterator1 
# 418
keys_first, InputIterator1 
# 419
keys_last, InputIterator2 
# 420
values_first, OutputIterator1 
# 421
keys_result, OutputIterator2 
# 422
values_result, BinaryPredicate 
# 423
binary_pred, BinaryFunction 
# 424
binary_op) 
# 425
{ 
# 426
return reduce_by_key_detail::reduce_by_key(exec, keys_first, keys_last, values_first, keys_result, values_result, binary_pred, binary_op); 
# 427
} 
# 431
static pair< OutputIterator1, OutputIterator2>  sequential_path(execution_policy< DerivedPolicy>  &, InputIterator1 
# 432
keys_first, InputIterator1 
# 433
keys_last, InputIterator2 
# 434
values_first, OutputIterator1 
# 435
keys_result, OutputIterator2 
# 436
values_result, BinaryPredicate 
# 437
binary_pred, BinaryFunction 
# 438
binary_op) 
# 439
{ 
# 440
return thrust::reduce_by_key(thrust::seq, keys_first, keys_last, values_first, keys_result, values_result, binary_pred, binary_op); 
# 441
} 
# 442
}; 
# 445
return (workaround::parallel_path)(exec, keys_first, keys_last, values_first, keys_result, values_result, binary_pred, binary_op); 
# 449
} 
# 452
}
# 453
}
# 454
}
# 455
}
# 30 "/usr/local/cuda-8.0/include/thrust/detail/reduce.inl"
namespace thrust { 
# 35
template< class DerivedPolicy, class InputIterator> typename iterator_traits< InputIterator> ::value_type 
# 38
reduce(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator first, InputIterator last) 
# 39
{ 
# 40
using system::detail::generic::reduce;
# 41
return reduce(detail::derived_cast(detail::strip_const(exec)), first, last); 
# 42
} 
# 46
template< class DerivedPolicy, class InputIterator, class T> T 
# 48
reduce(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator 
# 49
first, InputIterator 
# 50
last, T 
# 51
init) 
# 52
{ 
# 53
using system::detail::generic::reduce;
# 54
return reduce(detail::derived_cast(detail::strip_const(exec)), first, last, init); 
# 55
} 
# 59
template< class DerivedPolicy, class 
# 60
InputIterator, class 
# 61
T, class 
# 62
BinaryFunction> T 
# 64
reduce(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator 
# 65
first, InputIterator 
# 66
last, T 
# 67
init, BinaryFunction 
# 68
binary_op) 
# 69
{ 
# 70
using system::detail::generic::reduce;
# 71
return reduce(detail::derived_cast(detail::strip_const(exec)), first, last, init, binary_op); 
# 72
} 
# 76
template< class DerivedPolicy, class 
# 77
InputIterator1, class 
# 78
InputIterator2, class 
# 79
OutputIterator1, class 
# 80
OutputIterator2> pair< OutputIterator1, OutputIterator2>  
# 83
reduce_by_key(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator1 
# 84
keys_first, InputIterator1 
# 85
keys_last, InputIterator2 
# 86
values_first, OutputIterator1 
# 87
keys_output, OutputIterator2 
# 88
values_output) 
# 89
{ 
# 90
using system::detail::generic::reduce_by_key;
# 91
return reduce_by_key(detail::derived_cast(detail::strip_const(exec)), keys_first, keys_last, values_first, keys_output, values_output); 
# 92
} 
# 96
template< class DerivedPolicy, class 
# 97
InputIterator1, class 
# 98
InputIterator2, class 
# 99
OutputIterator1, class 
# 100
OutputIterator2, class 
# 101
BinaryPredicate> pair< OutputIterator1, OutputIterator2>  
# 104
reduce_by_key(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator1 
# 105
keys_first, InputIterator1 
# 106
keys_last, InputIterator2 
# 107
values_first, OutputIterator1 
# 108
keys_output, OutputIterator2 
# 109
values_output, BinaryPredicate 
# 110
binary_pred) 
# 111
{ 
# 112
using system::detail::generic::reduce_by_key;
# 113
return reduce_by_key(detail::derived_cast(detail::strip_const(exec)), keys_first, keys_last, values_first, keys_output, values_output, binary_pred); 
# 114
} 
# 118
template< class DerivedPolicy, class 
# 119
InputIterator1, class 
# 120
InputIterator2, class 
# 121
OutputIterator1, class 
# 122
OutputIterator2, class 
# 123
BinaryPredicate, class 
# 124
BinaryFunction> pair< OutputIterator1, OutputIterator2>  
# 127
reduce_by_key(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator1 
# 128
keys_first, InputIterator1 
# 129
keys_last, InputIterator2 
# 130
values_first, OutputIterator1 
# 131
keys_output, OutputIterator2 
# 132
values_output, BinaryPredicate 
# 133
binary_pred, BinaryFunction 
# 134
binary_op) 
# 135
{ 
# 136
using system::detail::generic::reduce_by_key;
# 137
return reduce_by_key(detail::derived_cast(detail::strip_const(exec)), keys_first, keys_last, values_first, keys_output, values_output, binary_pred, binary_op); 
# 138
} 
# 141
template< class InputIterator> typename iterator_traits< InputIterator> ::value_type 
# 143
reduce(InputIterator first, InputIterator 
# 144
last) 
# 145
{ 
# 146
using thrust::system::detail::generic::select_system;
# 148
typedef typename iterator_system< InputIterator> ::type System; 
# 150
System system; 
# 152
return thrust::reduce(select_system(system), first, last); 
# 153
} 
# 156
template< class InputIterator, class 
# 157
T> T 
# 158
reduce(InputIterator first, InputIterator 
# 159
last, T 
# 160
init) 
# 161
{ 
# 162
using thrust::system::detail::generic::select_system;
# 164
typedef typename iterator_system< InputIterator> ::type System; 
# 166
System system; 
# 168
return thrust::reduce(select_system(system), first, last, init); 
# 169
} 
# 172
template< class InputIterator, class 
# 173
T, class 
# 174
BinaryFunction> T 
# 175
reduce(InputIterator first, InputIterator 
# 176
last, T 
# 177
init, BinaryFunction 
# 178
binary_op) 
# 179
{ 
# 180
using thrust::system::detail::generic::select_system;
# 182
typedef typename iterator_system< InputIterator> ::type System; 
# 184
System system; 
# 186
return thrust::reduce(select_system(system), first, last, init, binary_op); 
# 187
} 
# 190
template< class InputIterator1, class 
# 191
InputIterator2, class 
# 192
OutputIterator1, class 
# 193
OutputIterator2> pair< OutputIterator1, OutputIterator2>  
# 195
reduce_by_key(InputIterator1 keys_first, InputIterator1 
# 196
keys_last, InputIterator2 
# 197
values_first, OutputIterator1 
# 198
keys_output, OutputIterator2 
# 199
values_output) 
# 200
{ 
# 201
using system::detail::generic::select_system;
# 203
typedef typename iterator_system< InputIterator1> ::type System1; 
# 204
typedef typename iterator_system< InputIterator2> ::type System2; 
# 205
typedef typename iterator_system< OutputIterator1> ::type System3; 
# 206
typedef typename iterator_system< OutputIterator2> ::type System4; 
# 208
System1 system1; 
# 209
System2 system2; 
# 210
System3 system3; 
# 211
System4 system4; 
# 213
return thrust::reduce_by_key(select_system(system1, system2, system3, system4), keys_first, keys_last, values_first, keys_output, values_output); 
# 214
} 
# 217
template< class InputIterator1, class 
# 218
InputIterator2, class 
# 219
OutputIterator1, class 
# 220
OutputIterator2, class 
# 221
BinaryPredicate> pair< OutputIterator1, OutputIterator2>  
# 223
reduce_by_key(InputIterator1 keys_first, InputIterator1 
# 224
keys_last, InputIterator2 
# 225
values_first, OutputIterator1 
# 226
keys_output, OutputIterator2 
# 227
values_output, BinaryPredicate 
# 228
binary_pred) 
# 229
{ 
# 230
using system::detail::generic::select_system;
# 232
typedef typename iterator_system< InputIterator1> ::type System1; 
# 233
typedef typename iterator_system< InputIterator2> ::type System2; 
# 234
typedef typename iterator_system< OutputIterator1> ::type System3; 
# 235
typedef typename iterator_system< OutputIterator2> ::type System4; 
# 237
System1 system1; 
# 238
System2 system2; 
# 239
System3 system3; 
# 240
System4 system4; 
# 242
return thrust::reduce_by_key(select_system(system1, system2, system3, system4), keys_first, keys_last, values_first, keys_output, values_output, binary_pred); 
# 243
} 
# 246
template< class InputIterator1, class 
# 247
InputIterator2, class 
# 248
OutputIterator1, class 
# 249
OutputIterator2, class 
# 250
BinaryPredicate, class 
# 251
BinaryFunction> pair< OutputIterator1, OutputIterator2>  
# 253
reduce_by_key(InputIterator1 keys_first, InputIterator1 
# 254
keys_last, InputIterator2 
# 255
values_first, OutputIterator1 
# 256
keys_output, OutputIterator2 
# 257
values_output, BinaryPredicate 
# 258
binary_pred, BinaryFunction 
# 259
binary_op) 
# 260
{ 
# 261
using system::detail::generic::select_system;
# 263
typedef typename iterator_system< InputIterator1> ::type System1; 
# 264
typedef typename iterator_system< InputIterator2> ::type System2; 
# 265
typedef typename iterator_system< OutputIterator1> ::type System3; 
# 266
typedef typename iterator_system< OutputIterator2> ::type System4; 
# 268
System1 system1; 
# 269
System2 system2; 
# 270
System3 system3; 
# 271
System4 system4; 
# 273
return thrust::reduce_by_key(select_system(system1, system2, system3, system4), keys_first, keys_last, values_first, keys_output, values_output, binary_pred, binary_op); 
# 274
} 
# 277
}
# 31 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/find.inl"
namespace thrust { 
# 33
namespace system { 
# 35
namespace detail { 
# 37
namespace generic { 
# 41
template< class DerivedPolicy, class InputIterator, class T> InputIterator 
# 43
find(execution_policy< DerivedPolicy>  &exec, InputIterator 
# 44
first, InputIterator 
# 45
last, const T &
# 46
value) 
# 47
{ 
# 49
return thrust::find_if(exec, first, last, ((thrust::detail::equal_to_value< T> )(value))); 
# 50
} 
# 53
template< class TupleType> 
# 54
struct find_if_functor { 
# 57
TupleType operator()(const TupleType &lhs, const TupleType &rhs) const 
# 58
{ 
# 60
if (thrust::get< 0> (lhs) && thrust::get< 0> (rhs)) 
# 61
{ 
# 62
return TupleType(true, (thrust::min)(thrust::get< 1> (lhs), thrust::get< 1> (rhs))); 
# 63
} else { 
# 64
if (thrust::get< 0> (lhs)) 
# 65
{ 
# 66
return lhs; 
# 67
} else 
# 69
{ 
# 70
return rhs; 
# 71
}  }  
# 72
} 
# 73
}; 
# 76
template< class DerivedPolicy, class InputIterator, class Predicate> InputIterator 
# 78
find_if(execution_policy< DerivedPolicy>  &exec, InputIterator 
# 79
first, InputIterator 
# 80
last, Predicate 
# 81
pred) 
# 82
{ 
# 83
typedef typename iterator_traits< InputIterator> ::difference_type difference_type; 
# 84
typedef tuple< bool, typename iterator_traits< InputIterator> ::difference_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type>  result_type; 
# 87
if (first == last) { return last; }  
# 89
const difference_type n = thrust::distance(first, last); 
# 95
const difference_type interval_threshold = (1 << 20); 
# 96
const difference_type interval_size = (thrust::min)(interval_threshold, n); 
# 99
typedef transform_iterator< Predicate, InputIterator, bool>  XfrmIterator; 
# 100
typedef tuple< transform_iterator< Predicate, InputIterator, bool> , counting_iterator< typename iterator_traits< InputIterator> ::difference_type> , null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type>  IteratorTuple; 
# 101
typedef zip_iterator< tuple< transform_iterator< Predicate, InputIterator, bool> , counting_iterator< typename iterator_traits< InputIterator> ::difference_type> , null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type> >  ZipIterator; 
# 103
IteratorTuple iter_tuple = thrust::make_tuple(XfrmIterator(first, pred), ((counting_iterator< typename iterator_traits< InputIterator> ::difference_type> )(0))); 
# 106
ZipIterator begin = thrust::make_zip_iterator(iter_tuple); 
# 107
ZipIterator end = begin + n; 
# 109
for (ZipIterator interval_begin = begin; interval_begin < end; interval_begin += interval_size) 
# 110
{ 
# 111
ZipIterator interval_end = interval_begin + interval_size; 
# 112
if (end < interval_end) 
# 113
{ 
# 114
interval_end = end; 
# 115
}  
# 117
result_type result = thrust::reduce(exec, interval_begin, interval_end, result_type(false, interval_end - begin), find_if_functor< tuple< bool, typename iterator_traits< InputIterator> ::difference_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type> > ()); 
# 123
if (thrust::get< 0> (result)) 
# 124
{ 
# 125
return first + thrust::get< 1> (result); 
# 126
}  
# 127
}  
# 130
return first + n; 
# 131
} 
# 134
template< class DerivedPolicy, class InputIterator, class Predicate> InputIterator 
# 136
find_if_not(execution_policy< DerivedPolicy>  &exec, InputIterator 
# 137
first, InputIterator 
# 138
last, Predicate 
# 139
pred) 
# 140
{ 
# 141
return thrust::find_if(exec, first, last, thrust::detail::not1(pred)); 
# 142
} 
# 145
}
# 146
}
# 147
}
# 148
}
# 28 "/usr/local/cuda-8.0/include/thrust/system/detail/sequential/find.h"
namespace thrust { 
# 30
namespace system { 
# 32
namespace detail { 
# 34
namespace sequential { 
# 39
template< class DerivedPolicy, class 
# 40
InputIterator, class 
# 41
Predicate> InputIterator 
# 43
find_if(execution_policy< DerivedPolicy>  &, InputIterator 
# 44
first, InputIterator 
# 45
last, Predicate 
# 46
pred) 
# 47
{ 
# 52
thrust::detail::wrapped_function< Predicate, bool>  wrapped_pred(pred); 
# 54
while (first != last) 
# 55
{ 
# 56
if (wrapped_pred(*first)) { 
# 57
return first; }  
# 59
++first; 
# 60
}  
# 63
return first; 
# 64
} 
# 67
}
# 68
}
# 69
}
# 70
}
# 28 "/usr/local/cuda-8.0/include/thrust/detail/find.inl"
namespace thrust { 
# 33
template< class DerivedPolicy, class InputIterator, class T> InputIterator 
# 35
find(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator 
# 36
first, InputIterator 
# 37
last, const T &
# 38
value) 
# 39
{ 
# 40
using system::detail::generic::find;
# 41
return find(detail::derived_cast(detail::strip_const(exec)), first, last, value); 
# 42
} 
# 46
template< class DerivedPolicy, class InputIterator, class Predicate> InputIterator 
# 48
find_if(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator 
# 49
first, InputIterator 
# 50
last, Predicate 
# 51
pred) 
# 52
{ 
# 53
using system::detail::generic::find_if;
# 54
return find_if(detail::derived_cast(detail::strip_const(exec)), first, last, pred); 
# 55
} 
# 59
template< class DerivedPolicy, class InputIterator, class Predicate> InputIterator 
# 61
find_if_not(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator 
# 62
first, InputIterator 
# 63
last, Predicate 
# 64
pred) 
# 65
{ 
# 66
using system::detail::generic::find_if_not;
# 67
return find_if_not(detail::derived_cast(detail::strip_const(exec)), first, last, pred); 
# 68
} 
# 71
template< class InputIterator, class T> InputIterator 
# 72
find(InputIterator first, InputIterator 
# 73
last, const T &
# 74
value) 
# 75
{ 
# 76
using thrust::system::detail::generic::select_system;
# 78
typedef typename iterator_system< InputIterator> ::type System; 
# 80
System system; 
# 82
return thrust::find(select_system(system), first, last, value); 
# 83
} 
# 85
template< class InputIterator, class Predicate> InputIterator 
# 86
find_if(InputIterator first, InputIterator 
# 87
last, Predicate 
# 88
pred) 
# 89
{ 
# 90
using thrust::system::detail::generic::select_system;
# 92
typedef typename iterator_system< InputIterator> ::type System; 
# 94
System system; 
# 96
return thrust::find_if(select_system(system), first, last, pred); 
# 97
} 
# 99
template< class InputIterator, class Predicate> InputIterator 
# 100
find_if_not(InputIterator first, InputIterator 
# 101
last, Predicate 
# 102
pred) 
# 103
{ 
# 104
using thrust::system::detail::generic::select_system;
# 106
typedef typename iterator_system< InputIterator> ::type System; 
# 108
System system; 
# 110
return thrust::find_if_not(select_system(system), first, last, pred); 
# 111
} 
# 114
}
# 23 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/mismatch.inl"
namespace thrust { 
# 25
namespace system { 
# 27
namespace detail { 
# 29
namespace generic { 
# 33
template< class DerivedPolicy, class InputIterator1, class InputIterator2> pair< InputIterator1, InputIterator2>  
# 36
mismatch(execution_policy< DerivedPolicy>  &exec, InputIterator1 
# 37
first1, InputIterator1 
# 38
last1, InputIterator2 
# 39
first2) 
# 40
{ 
# 41
typedef typename iterator_value< InputIterator1> ::type InputType1; 
# 44
return thrust::mismatch(exec, first1, last1, first2, thrust::detail::equal_to< typename iterator_value< InputIterator1> ::type> ()); 
# 45
} 
# 48
template< class DerivedPolicy, class InputIterator1, class InputIterator2, class BinaryPredicate> pair< InputIterator1, InputIterator2>  
# 51
mismatch(execution_policy< DerivedPolicy>  &exec, InputIterator1 
# 52
first1, InputIterator1 
# 53
last1, InputIterator2 
# 54
first2, BinaryPredicate 
# 55
pred) 
# 56
{ 
# 58
typedef tuple< InputIterator1, InputIterator2, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type>  IteratorTuple; 
# 59
typedef zip_iterator< tuple< InputIterator1, InputIterator2, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type> >  ZipIterator; 
# 61
ZipIterator zipped_first = thrust::make_zip_iterator(thrust::make_tuple(first1, first2)); 
# 62
ZipIterator zipped_last = thrust::make_zip_iterator(thrust::make_tuple(last1, first2)); 
# 64
ZipIterator result = thrust::find_if_not(exec, zipped_first, zipped_last, ((thrust::detail::tuple_binary_predicate< BinaryPredicate> )(pred))); 
# 66
return thrust::make_pair(thrust::get< 0> ((result.get_iterator_tuple())), thrust::get< 1> ((result.get_iterator_tuple()))); 
# 68
} 
# 71
}
# 72
}
# 73
}
# 74
}
# 30 "/usr/local/cuda-8.0/include/thrust/detail/mismatch.inl"
namespace thrust { 
# 35
template< class DerivedPolicy, class InputIterator1, class InputIterator2> pair< InputIterator1, InputIterator2>  
# 37
mismatch(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator1 
# 38
first1, InputIterator1 
# 39
last1, InputIterator2 
# 40
first2) 
# 41
{ 
# 42
using system::detail::generic::mismatch;
# 43
return mismatch(detail::derived_cast(detail::strip_const(exec)), first1, last1, first2); 
# 44
} 
# 48
template< class DerivedPolicy, class InputIterator1, class InputIterator2, class BinaryPredicate> pair< InputIterator1, InputIterator2>  
# 50
mismatch(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator1 
# 51
first1, InputIterator1 
# 52
last1, InputIterator2 
# 53
first2, BinaryPredicate 
# 54
pred) 
# 55
{ 
# 56
using system::detail::generic::mismatch;
# 57
return mismatch(detail::derived_cast(detail::strip_const(exec)), first1, last1, first2, pred); 
# 58
} 
# 61
template< class InputIterator1, class InputIterator2> pair< InputIterator1, InputIterator2>  
# 62
mismatch(InputIterator1 first1, InputIterator1 
# 63
last1, InputIterator2 
# 64
first2) 
# 65
{ 
# 66
using system::detail::generic::select_system;
# 68
typedef typename iterator_system< InputIterator1> ::type System1; 
# 69
typedef typename iterator_system< InputIterator2> ::type System2; 
# 71
System1 system1; 
# 72
System2 system2; 
# 74
return thrust::mismatch(select_system(system1, system2), first1, last1, first2); 
# 75
} 
# 78
template< class InputIterator1, class InputIterator2, class BinaryPredicate> pair< InputIterator1, InputIterator2>  
# 79
mismatch(InputIterator1 first1, InputIterator1 
# 80
last1, InputIterator2 
# 81
first2, BinaryPredicate 
# 82
pred) 
# 83
{ 
# 84
using system::detail::generic::select_system;
# 86
typedef typename iterator_system< InputIterator1> ::type System1; 
# 87
typedef typename iterator_system< InputIterator2> ::type System2; 
# 89
System1 system1; 
# 90
System2 system2; 
# 92
return thrust::mismatch(select_system(system1, system2), first1, last1, first2, pred); 
# 93
} 
# 96
}
# 23 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/equal.inl"
namespace thrust { 
# 25
namespace system { 
# 27
namespace detail { 
# 29
namespace generic { 
# 33
template< class DerivedPolicy, class InputIterator1, class InputIterator2> bool 
# 35
equal(execution_policy< DerivedPolicy>  &exec, InputIterator1 first1, InputIterator1 last1, InputIterator2 first2) 
# 36
{ 
# 37
typedef typename iterator_traits< InputIterator1> ::value_type InputType1; 
# 39
return thrust::equal(exec, first1, last1, first2, thrust::detail::equal_to< typename iterator_traits< InputIterator1> ::value_type> ()); 
# 40
} 
# 46
template< class DerivedPolicy, class InputIterator1, class InputIterator2, class BinaryPredicate> bool 
# 48
equal(execution_policy< DerivedPolicy>  &exec, InputIterator1 first1, InputIterator1 last1, InputIterator2 first2, BinaryPredicate binary_pred) 
# 49
{ 
# 50
return (thrust::mismatch(exec, first1, last1, first2, binary_pred).first) == last1; 
# 51
} 
# 54
}
# 55
}
# 56
}
# 57
}
# 28 "/usr/local/cuda-8.0/include/thrust/detail/equal.inl"
namespace thrust { 
# 33
template< class System, class InputIterator1, class InputIterator2> bool 
# 35
equal(const detail::execution_policy_base< System>  &system, InputIterator1 first1, InputIterator1 last1, InputIterator2 first2) 
# 36
{ 
# 37
using thrust::system::detail::generic::equal;
# 38
return equal(detail::derived_cast(detail::strip_const(system)), first1, last1, first2); 
# 39
} 
# 43
template< class System, class InputIterator1, class InputIterator2, class BinaryPredicate> bool 
# 45
equal(const detail::execution_policy_base< System>  &system, InputIterator1 first1, InputIterator1 last1, InputIterator2 first2, BinaryPredicate binary_pred) 
# 46
{ 
# 47
using thrust::system::detail::generic::equal;
# 48
return equal(detail::derived_cast(detail::strip_const(system)), first1, last1, first2, binary_pred); 
# 49
} 
# 52
template< class InputIterator1, class InputIterator2> bool 
# 53
equal(InputIterator1 first1, InputIterator1 last1, InputIterator2 
# 54
first2) 
# 55
{ 
# 56
using system::detail::generic::select_system;
# 58
typedef typename iterator_system< InputIterator1> ::type System1; 
# 59
typedef typename iterator_system< InputIterator2> ::type System2; 
# 61
System1 system1; 
# 62
System2 system2; 
# 64
return thrust::equal(select_system(system1, system2), first1, last1, first2); 
# 65
} 
# 68
template< class InputIterator1, class InputIterator2, class 
# 69
BinaryPredicate> bool 
# 70
equal(InputIterator1 first1, InputIterator1 last1, InputIterator2 
# 71
first2, BinaryPredicate binary_pred) 
# 72
{ 
# 73
using system::detail::generic::select_system;
# 75
typedef typename iterator_system< InputIterator1> ::type System1; 
# 76
typedef typename iterator_system< InputIterator2> ::type System2; 
# 78
System1 system1; 
# 79
System2 system2; 
# 81
return thrust::equal(select_system(system1, system2), first1, last1, first2, binary_pred); 
# 82
} 
# 85
}
# 35 "/usr/local/cuda-8.0/include/thrust/detail/vector_base.inl"
namespace thrust { 
# 38
namespace detail { 
# 41
template< class T, class Alloc> 
# 43
vector_base< T, Alloc> ::vector_base() : m_storage(), m_size(0) 
# 46
{ 
# 47
; 
# 48
} 
# 50
template< class T, class Alloc> 
# 52
vector_base< T, Alloc> ::vector_base(size_type n) : m_storage(), m_size(0) 
# 55
{ 
# 56
default_init(n); 
# 57
} 
# 59
template< class T, class Alloc> 
# 61
vector_base< T, Alloc> ::vector_base(size_type n, const value_type &value) : m_storage(), m_size(0) 
# 64
{ 
# 65
fill_init(n, value); 
# 66
} 
# 68
template< class T, class Alloc> 
# 70
vector_base< T, Alloc> ::vector_base(const vector_base &v) : m_storage(), m_size(0) 
# 73
{ 
# 74
range_init(v.begin(), v.end()); 
# 75
} 
# 77
template< class T, class Alloc> vector_base< T, Alloc>  &
# 80
vector_base< T, Alloc> ::operator=(const vector_base &v) 
# 81
{ 
# 82
if (this != (&v)) 
# 83
{ 
# 84
assign(v.begin(), v.end()); 
# 85
}  
# 87
return *this; 
# 88
} 
# 90
template< class T, class Alloc> 
# 91
template< class OtherT, class OtherAlloc> 
# 93
vector_base< T, Alloc> ::vector_base(const detail::vector_base< OtherT, OtherAlloc>  &v) : m_storage(), m_size(0) 
# 96
{ 
# 97
range_init((v.begin()), (v.end())); 
# 98
} 
# 100
template< class T, class Alloc> 
# 101
template< class OtherT, class OtherAlloc> vector_base< T, Alloc>  &
# 104
vector_base< T, Alloc> ::operator=(const detail::vector_base< OtherT, OtherAlloc>  &v) 
# 105
{ 
# 106
assign((v.begin()), (v.end())); 
# 108
return *this; 
# 109
} 
# 111
template< class T, class Alloc> 
# 112
template< class OtherT, class OtherAlloc> 
# 114
vector_base< T, Alloc> ::vector_base(const std::vector< OtherT, OtherAlloc>  &v) : m_storage(), m_size(0) 
# 117
{ 
# 118
range_init((v.begin()), (v.end())); 
# 119
} 
# 121
template< class T, class Alloc> 
# 122
template< class OtherT, class OtherAlloc> vector_base< T, Alloc>  &
# 125
vector_base< T, Alloc> ::operator=(const std::vector< OtherT, OtherAlloc>  &v) 
# 126
{ 
# 127
assign((v.begin()), (v.end())); 
# 129
return *this; 
# 130
} 
# 132
template< class T, class Alloc> 
# 133
template< class IteratorOrIntegralType> void 
# 135
vector_base< T, Alloc> ::init_dispatch(IteratorOrIntegralType n, IteratorOrIntegralType 
# 136
value, true_type) 
# 138
{ 
# 139
fill_init(n, value); 
# 140
} 
# 142
template< class T, class Alloc> void 
# 144
vector_base< T, Alloc> ::default_init(size_type n) 
# 145
{ 
# 146
if (n > 0) 
# 147
{ 
# 148
((m_storage).allocate(n)); 
# 149
(m_size) = n; 
# 151
((m_storage).default_construct_n(this->begin(), size())); 
# 152
}  
# 153
} 
# 155
template< class T, class Alloc> void 
# 157
vector_base< T, Alloc> ::fill_init(size_type n, const T &x) 
# 158
{ 
# 159
if (n > 0) 
# 160
{ 
# 161
((m_storage).allocate(n)); 
# 162
(m_size) = n; 
# 164
((m_storage).uninitialized_fill_n(this->begin(), size(), x)); 
# 165
}  
# 166
} 
# 168
template< class T, class Alloc> 
# 169
template< class InputIterator> void 
# 171
vector_base< T, Alloc> ::init_dispatch(InputIterator first, InputIterator 
# 172
last, false_type) 
# 174
{ 
# 175
range_init(first, last); 
# 176
} 
# 178
template< class T, class Alloc> 
# 179
template< class InputIterator> void 
# 181
vector_base< T, Alloc> ::range_init(InputIterator first, InputIterator 
# 182
last) 
# 183
{ 
# 184
range_init(first, last, typename iterator_traversal< InputIterator> ::type()); 
# 186
} 
# 188
template< class T, class Alloc> 
# 189
template< class InputIterator> void 
# 191
vector_base< T, Alloc> ::range_init(InputIterator first, InputIterator 
# 192
last, incrementable_traversal_tag) 
# 194
{ 
# 195
for (; first != last; ++first) { 
# 196
push_back(*first); }  
# 197
} 
# 199
template< class T, class Alloc> 
# 200
template< class ForwardIterator> void 
# 202
vector_base< T, Alloc> ::range_init(ForwardIterator first, ForwardIterator 
# 203
last, random_access_traversal_tag) 
# 205
{ 
# 206
size_type new_size = thrust::distance(first, last); 
# 208
allocate_and_copy(new_size, first, last, m_storage); 
# 209
(m_size) = new_size; 
# 210
} 
# 212
template< class T, class Alloc> 
# 213
template< class InputIterator> 
# 215
vector_base< T, Alloc> ::vector_base(InputIterator first, InputIterator 
# 216
last) : m_storage(), m_size(0) 
# 219
{ 
# 222
typedef is_integral< InputIterator>  Integer; 
# 224
init_dispatch(first, last, Integer()); 
# 225
} 
# 227
template< class T, class Alloc> void 
# 229
vector_base< T, Alloc> ::resize(size_type new_size) 
# 230
{ 
# 231
if (new_size < size()) 
# 232
{ 
# 233
iterator new_end = this->begin(); 
# 234
thrust::advance(new_end, new_size); 
# 235
erase(new_end, this->end()); 
# 236
} else 
# 238
{ 
# 239
append(new_size - size()); 
# 240
}  
# 241
} 
# 243
template< class T, class Alloc> void 
# 245
vector_base< T, Alloc> ::resize(size_type new_size, const value_type &x) 
# 246
{ 
# 247
if (new_size < size()) 
# 248
{ 
# 249
iterator new_end = this->begin(); 
# 250
thrust::advance(new_end, new_size); 
# 251
erase(new_end, this->end()); 
# 252
} else 
# 254
{ 
# 255
insert(this->end(), new_size - size(), x); 
# 256
}  
# 257
} 
# 259
template< class T, class Alloc> typename vector_base< T, Alloc> ::size_type 
# 262
vector_base< T, Alloc> ::size() const 
# 263
{ 
# 264
return m_size; 
# 265
} 
# 267
template< class T, class Alloc> typename vector_base< T, Alloc> ::size_type 
# 270
vector_base< T, Alloc> ::max_size() const 
# 271
{ 
# 272
return ((m_storage).max_size()); 
# 273
} 
# 275
template< class T, class Alloc> void 
# 277
vector_base< T, Alloc> ::reserve(size_type n) 
# 278
{ 
# 279
if (n > capacity()) 
# 280
{ 
# 281
allocate_and_copy(n, this->begin(), this->end(), m_storage); 
# 282
}  
# 283
} 
# 285
template< class T, class Alloc> typename vector_base< T, Alloc> ::size_type 
# 288
vector_base< T, Alloc> ::capacity() const 
# 289
{ 
# 290
return ((m_storage).size()); 
# 291
} 
# 293
template< class T, class Alloc> void 
# 295
vector_base< T, Alloc> ::shrink_to_fit() 
# 296
{ 
# 298
((vector_base)(*this)).swap(*this); 
# 299
} 
# 301
template< class T, class Alloc> typename vector_base< T, Alloc> ::reference 
# 304
vector_base< T, Alloc> ::operator[](const typename contiguous_storage< T, Alloc> ::size_type n) 
# 305
{ 
# 306
return (m_storage)[n]; 
# 307
} 
# 309
template< class T, class Alloc> typename vector_base< T, Alloc> ::const_reference 
# 312
vector_base< T, Alloc> ::operator[](const typename contiguous_storage< T, Alloc> ::size_type n) const 
# 313
{ 
# 314
return (m_storage)[n]; 
# 315
} 
# 317
template< class T, class Alloc> typename vector_base< T, Alloc> ::iterator 
# 320
vector_base< T, Alloc> ::begin() 
# 321
{ 
# 322
return ((m_storage).begin()); 
# 323
} 
# 325
template< class T, class Alloc> typename vector_base< T, Alloc> ::const_iterator 
# 328
vector_base< T, Alloc> ::begin() const 
# 329
{ 
# 330
return ((m_storage).begin()); 
# 331
} 
# 333
template< class T, class Alloc> typename vector_base< T, Alloc> ::const_iterator 
# 336
vector_base< T, Alloc> ::cbegin() const 
# 337
{ 
# 338
return this->begin(); 
# 339
} 
# 341
template< class T, class Alloc> typename vector_base< T, Alloc> ::reverse_iterator 
# 344
vector_base< T, Alloc> ::rbegin() 
# 345
{ 
# 346
return ((reverse_iterator)(this->end())); 
# 347
} 
# 349
template< class T, class Alloc> typename vector_base< T, Alloc> ::const_reverse_iterator 
# 352
vector_base< T, Alloc> ::rbegin() const 
# 353
{ 
# 354
return ((const_reverse_iterator)(this->end())); 
# 355
} 
# 357
template< class T, class Alloc> typename vector_base< T, Alloc> ::const_reverse_iterator 
# 360
vector_base< T, Alloc> ::crbegin() const 
# 361
{ 
# 362
return this->rbegin(); 
# 363
} 
# 365
template< class T, class Alloc> typename vector_base< T, Alloc> ::iterator 
# 368
vector_base< T, Alloc> ::end() 
# 369
{ 
# 370
iterator result = this->begin(); 
# 371
thrust::advance(result, size()); 
# 372
return result; 
# 373
} 
# 375
template< class T, class Alloc> typename vector_base< T, Alloc> ::const_iterator 
# 378
vector_base< T, Alloc> ::end() const 
# 379
{ 
# 380
const_iterator result = this->begin(); 
# 381
thrust::advance(result, size()); 
# 382
return result; 
# 383
} 
# 385
template< class T, class Alloc> typename vector_base< T, Alloc> ::const_iterator 
# 388
vector_base< T, Alloc> ::cend() const 
# 389
{ 
# 390
return this->end(); 
# 391
} 
# 393
template< class T, class Alloc> typename vector_base< T, Alloc> ::reverse_iterator 
# 396
vector_base< T, Alloc> ::rend() 
# 397
{ 
# 398
return ((reverse_iterator)(this->begin())); 
# 399
} 
# 401
template< class T, class Alloc> typename vector_base< T, Alloc> ::const_reverse_iterator 
# 404
vector_base< T, Alloc> ::rend() const 
# 405
{ 
# 406
return ((const_reverse_iterator)(this->begin())); 
# 407
} 
# 409
template< class T, class Alloc> typename vector_base< T, Alloc> ::const_reverse_iterator 
# 412
vector_base< T, Alloc> ::crend() const 
# 413
{ 
# 414
return this->rend(); 
# 415
} 
# 417
template< class T, class Alloc> typename vector_base< T, Alloc> ::const_reference 
# 420
vector_base< T, Alloc> ::front() const 
# 421
{ 
# 422
return *this->begin(); 
# 423
} 
# 425
template< class T, class Alloc> typename vector_base< T, Alloc> ::reference 
# 428
vector_base< T, Alloc> ::front() 
# 429
{ 
# 430
return *this->begin(); 
# 431
} 
# 433
template< class T, class Alloc> typename vector_base< T, Alloc> ::const_reference 
# 436
vector_base< T, Alloc> ::back() const 
# 437
{ 
# 438
const_iterator ptr_to_back = this->end(); 
# 439
--ptr_to_back; 
# 440
return *ptr_to_back; 
# 441
} 
# 443
template< class T, class Alloc> typename vector_base< T, Alloc> ::reference 
# 446
vector_base< T, Alloc> ::back() 
# 447
{ 
# 448
iterator ptr_to_back = this->end(); 
# 449
--ptr_to_back; 
# 450
return *ptr_to_back; 
# 451
} 
# 453
template< class T, class Alloc> typename vector_base< T, Alloc> ::pointer 
# 456
vector_base< T, Alloc> ::data() 
# 457
{ 
# 458
return &this->front(); 
# 459
} 
# 461
template< class T, class Alloc> typename vector_base< T, Alloc> ::const_pointer 
# 464
vector_base< T, Alloc> ::data() const 
# 465
{ 
# 466
return &this->front(); 
# 467
} 
# 469
template< class T, class Alloc> 
# 471
vector_base< T, Alloc> ::~vector_base() 
# 472
{ 
# 474
((m_storage).destroy(this->begin(), this->end())); 
# 475
} 
# 477
template< class T, class Alloc> void 
# 479
vector_base< T, Alloc> ::clear() 
# 480
{ 
# 481
erase(this->begin(), this->end()); 
# 482
} 
# 484
template< class T, class Alloc> bool 
# 486
vector_base< T, Alloc> ::empty() const 
# 487
{ 
# 488
return size() == 0; 
# 489
} 
# 491
template< class T, class Alloc> void 
# 493
vector_base< T, Alloc> ::push_back(const value_type &x) 
# 494
{ 
# 495
insert(this->end(), x); 
# 496
} 
# 498
template< class T, class Alloc> void 
# 500
vector_base< T, Alloc> ::pop_back() 
# 501
{ 
# 502
iterator e = this->end(); 
# 503
iterator ptr_to_back = e; 
# 504
--ptr_to_back; 
# 505
((m_storage).destroy(ptr_to_back, e)); 
# 506
--(m_size); 
# 507
} 
# 509
template< class T, class Alloc> typename vector_base< T, Alloc> ::iterator 
# 511
vector_base< T, Alloc> ::erase(iterator pos) 
# 512
{ 
# 513
iterator end = pos; 
# 514
++end; 
# 515
return erase(pos, end); 
# 516
} 
# 518
template< class T, class Alloc> typename vector_base< T, Alloc> ::iterator 
# 520
vector_base< T, Alloc> ::erase(iterator first, iterator last) 
# 521
{ 
# 524
iterator i = detail::overlapped_copy(last, this->end(), first); 
# 527
((m_storage).destroy(i, this->end())); 
# 530
(m_size) -= (last - first); 
# 534
return first; 
# 535
} 
# 537
template< class T, class Alloc> void 
# 539
vector_base< T, Alloc> ::swap(vector_base &v) 
# 540
{ 
# 541
thrust::swap(m_storage, v.m_storage); 
# 542
thrust::swap(m_size, v.m_size); 
# 543
} 
# 545
template< class T, class Alloc> void 
# 547
vector_base< T, Alloc> ::assign(size_type n, const T &x) 
# 548
{ 
# 549
fill_assign(n, x); 
# 550
} 
# 552
template< class T, class Alloc> 
# 553
template< class InputIterator> void 
# 555
vector_base< T, Alloc> ::assign(InputIterator first, InputIterator last) 
# 556
{ 
# 559
typedef is_integral< InputIterator>  integral; 
# 561
assign_dispatch(first, last, integral()); 
# 562
} 
# 564
template< class T, class Alloc> typename vector_base< T, Alloc> ::allocator_type 
# 567
vector_base< T, Alloc> ::get_allocator() const 
# 568
{ 
# 569
return ((m_storage).get_allocator()); 
# 570
} 
# 572
template< class T, class Alloc> typename vector_base< T, Alloc> ::iterator 
# 575
vector_base< T, Alloc> ::insert(iterator position, const T &x) 
# 576
{ 
# 578
size_type index = thrust::distance(this->begin(), position); 
# 581
insert(position, 1, x); 
# 584
iterator result = this->begin(); 
# 585
thrust::advance(result, index); 
# 586
return result; 
# 587
} 
# 589
template< class T, class Alloc> void 
# 591
vector_base< T, Alloc> ::insert(iterator position, size_type n, const T &x) 
# 592
{ 
# 593
fill_insert(position, n, x); 
# 594
} 
# 596
template< class T, class Alloc> 
# 597
template< class InputIterator> void 
# 599
vector_base< T, Alloc> ::insert(iterator position, InputIterator first, InputIterator last) 
# 600
{ 
# 603
typedef is_integral< InputIterator>  integral; 
# 605
insert_dispatch(position, first, last, integral()); 
# 606
} 
# 608
template< class T, class Alloc> 
# 609
template< class InputIterator> void 
# 611
vector_base< T, Alloc> ::assign_dispatch(InputIterator first, InputIterator last, false_type) 
# 612
{ 
# 613
range_assign(first, last); 
# 614
} 
# 616
template< class T, class Alloc> 
# 617
template< class Integral> void 
# 619
vector_base< T, Alloc> ::assign_dispatch(Integral n, Integral x, true_type) 
# 620
{ 
# 621
fill_assign(n, x); 
# 622
} 
# 624
template< class T, class Alloc> 
# 625
template< class InputIterator> void 
# 627
vector_base< T, Alloc> ::insert_dispatch(iterator position, InputIterator first, InputIterator last, false_type) 
# 628
{ 
# 629
copy_insert(position, first, last); 
# 630
} 
# 632
template< class T, class Alloc> 
# 633
template< class Integral> void 
# 635
vector_base< T, Alloc> ::insert_dispatch(iterator position, Integral n, Integral x, true_type) 
# 636
{ 
# 637
fill_insert(position, n, x); 
# 638
} 
# 640
template< class T, class Alloc> 
# 641
template< class ForwardIterator> void 
# 643
vector_base< T, Alloc> ::copy_insert(iterator position, ForwardIterator 
# 644
first, ForwardIterator 
# 645
last) 
# 646
{ 
# 647
if (first != last) 
# 648
{ 
# 650
const size_type num_new_elements = thrust::distance(first, last); 
# 651
if ((capacity() - size()) >= num_new_elements) 
# 652
{ 
# 655
const size_type num_displaced_elements = this->end() - position; 
# 656
iterator old_end = this->end(); 
# 658
if (num_displaced_elements > num_new_elements) 
# 659
{ 
# 662
((m_storage).uninitialized_copy(this->end() - num_new_elements, this->end(), this->end())); 
# 665
(m_size) += num_new_elements; 
# 669
const size_type copy_length = (old_end - num_new_elements) - position; 
# 670
detail::overlapped_copy(position, old_end - num_new_elements, old_end - copy_length); 
# 673
thrust::copy(first, last, position); 
# 674
} else 
# 676
{ 
# 677
ForwardIterator mid = first; 
# 678
thrust::advance(mid, num_displaced_elements); 
# 681
((m_storage).uninitialized_copy(mid, last, this->end())); 
# 684
(m_size) += (num_new_elements - num_displaced_elements); 
# 687
((m_storage).uninitialized_copy(position, old_end, this->end())); 
# 690
(m_size) += num_displaced_elements; 
# 693
thrust::copy(first, mid, position); 
# 694
}  
# 695
} else 
# 697
{ 
# 698
const size_type old_size = size(); 
# 701
size_type new_capacity = old_size + thrust::max(old_size, num_new_elements); 
# 704
new_capacity = thrust::max< size_type> (new_capacity, 2 * capacity()); 
# 707
new_capacity = thrust::min< size_type> (new_capacity, max_size()); 
# 709
if (new_capacity > max_size()) 
# 710
{ 
# 711
throw ((std::length_error)("insert(): insertion exceeds max_size().")); 
# 712
}  
# 714
storage_type new_storage(new_capacity); 
# 717
iterator new_end = (new_storage.begin()); 
# 719
try 
# 720
{ 
# 723
new_end = ((m_storage).uninitialized_copy(this->begin(), position, (new_storage.begin()))); 
# 726
new_end = ((m_storage).uninitialized_copy(first, last, new_end)); 
# 730
new_end = ((m_storage).uninitialized_copy(position, this->end(), new_end)); 
# 731
} 
# 732
catch (...) 
# 733
{ 
# 735
((m_storage).destroy((new_storage.begin()), new_end)); 
# 736
(new_storage.deallocate()); 
# 739
throw; 
# 740
}  
# 743
((m_storage).destroy(this->begin(), this->end())); 
# 746
((m_storage).swap(new_storage)); 
# 747
(m_size) = (old_size + num_new_elements); 
# 748
}  
# 749
}  
# 750
} 
# 752
template< class T, class Alloc> void 
# 754
vector_base< T, Alloc> ::append(size_type n) 
# 755
{ 
# 756
if (n != 0) 
# 757
{ 
# 758
if ((capacity() - size()) >= n) 
# 759
{ 
# 763
((m_storage).default_construct_n(this->end(), n)); 
# 766
(m_size) += n; 
# 767
} else 
# 769
{ 
# 770
const size_type old_size = size(); 
# 773
size_type new_capacity = old_size + thrust::max(old_size, n); 
# 776
new_capacity = thrust::max< size_type> (new_capacity, 2 * capacity()); 
# 779
new_capacity = thrust::min< size_type> (new_capacity, max_size()); 
# 782
storage_type new_storage(new_capacity); 
# 785
iterator new_end = (new_storage.begin()); 
# 787
try 
# 788
{ 
# 790
new_end = ((m_storage).uninitialized_copy(this->begin(), this->end(), (new_storage.begin()))); 
# 793
((m_storage).default_construct_n(new_end, n)); 
# 794
new_end += n; 
# 795
} 
# 796
catch (...) 
# 797
{ 
# 799
((m_storage).destroy((new_storage.begin()), new_end)); 
# 800
(new_storage.deallocate()); 
# 803
throw; 
# 804
}  
# 807
((m_storage).destroy(this->begin(), this->end())); 
# 810
((m_storage).swap(new_storage)); 
# 811
(m_size) = (old_size + n); 
# 812
}  
# 813
}  
# 814
} 
# 816
template< class T, class Alloc> void 
# 818
vector_base< T, Alloc> ::fill_insert(iterator position, size_type n, const T &x) 
# 819
{ 
# 820
if (n != 0) 
# 821
{ 
# 822
if ((capacity() - size()) >= n) 
# 823
{ 
# 826
const size_type num_displaced_elements = this->end() - position; 
# 827
iterator old_end = this->end(); 
# 829
if (num_displaced_elements > n) 
# 830
{ 
# 833
((m_storage).uninitialized_copy(this->end() - n, this->end(), this->end())); 
# 836
(m_size) += n; 
# 840
const size_type copy_length = (old_end - n) - position; 
# 841
detail::overlapped_copy(position, old_end - n, old_end - copy_length); 
# 844
thrust::fill_n(position, n, x); 
# 845
} else 
# 847
{ 
# 849
((m_storage).uninitialized_fill_n(this->end(), n - num_displaced_elements, x)); 
# 852
(m_size) += (n - num_displaced_elements); 
# 855
((m_storage).uninitialized_copy(position, old_end, this->end())); 
# 858
(m_size) += num_displaced_elements; 
# 861
thrust::fill(position, old_end, x); 
# 862
}  
# 863
} else 
# 865
{ 
# 866
const size_type old_size = size(); 
# 869
size_type new_capacity = old_size + thrust::max(old_size, n); 
# 872
new_capacity = thrust::max< size_type> (new_capacity, 2 * capacity()); 
# 875
new_capacity = thrust::min< size_type> (new_capacity, max_size()); 
# 877
if (new_capacity > max_size()) 
# 878
{ 
# 879
throw ((std::length_error)("insert(): insertion exceeds max_size().")); 
# 880
}  
# 882
storage_type new_storage(new_capacity); 
# 885
iterator new_end = (new_storage.begin()); 
# 887
try 
# 888
{ 
# 891
new_end = ((m_storage).uninitialized_copy(this->begin(), position, (new_storage.begin()))); 
# 894
((m_storage).uninitialized_fill_n(new_end, n, x)); 
# 895
new_end += n; 
# 899
new_end = ((m_storage).uninitialized_copy(position, this->end(), new_end)); 
# 900
} 
# 901
catch (...) 
# 902
{ 
# 904
((m_storage).destroy((new_storage.begin()), new_end)); 
# 905
(new_storage.deallocate()); 
# 908
throw; 
# 909
}  
# 912
((m_storage).destroy(this->begin(), this->end())); 
# 915
((m_storage).swap(new_storage)); 
# 916
(m_size) = (old_size + n); 
# 917
}  
# 918
}  
# 919
} 
# 921
template< class T, class Alloc> 
# 922
template< class InputIterator> void 
# 924
vector_base< T, Alloc> ::range_assign(InputIterator first, InputIterator 
# 925
last) 
# 926
{ 
# 928
range_assign(first, last, typename iterator_traversal< InputIterator> ::type()); 
# 930
} 
# 932
template< class T, class Alloc> 
# 933
template< class InputIterator> void 
# 935
vector_base< T, Alloc> ::range_assign(InputIterator first, InputIterator 
# 936
last, incrementable_traversal_tag) 
# 938
{ 
# 939
iterator current(this->begin()); 
# 942
for (; (first != last) && (current != this->end()); (++current), (++first)) 
# 943
{ 
# 944
(*current) = (*first); 
# 945
}  
# 949
if (first == last) 
# 950
{ 
# 952
erase(current, this->end()); 
# 953
} else 
# 955
{ 
# 957
insert(this->end(), first, last); 
# 958
}  
# 959
} 
# 961
template< class T, class Alloc> 
# 962
template< class RandomAccessIterator> void 
# 964
vector_base< T, Alloc> ::range_assign(RandomAccessIterator first, RandomAccessIterator 
# 965
last, random_access_traversal_tag) 
# 967
{ 
# 968
const size_type n = thrust::distance(first, last); 
# 970
if (n > capacity()) 
# 971
{ 
# 972
storage_type new_storage; 
# 973
allocate_and_copy(n, first, last, new_storage); 
# 976
((m_storage).destroy(this->begin(), this->end())); 
# 979
((m_storage).swap(new_storage)); 
# 980
(m_size) = n; 
# 981
} else { 
# 982
if (size() >= n) 
# 983
{ 
# 985
iterator new_end = thrust::copy(first, last, this->begin()); 
# 988
((m_storage).destroy(new_end, this->end())); 
# 991
(m_size) = n; 
# 992
} else 
# 994
{ 
# 1002
RandomAccessIterator mid = first; 
# 1003
thrust::advance(mid, size()); 
# 1004
thrust::copy(first, mid, this->begin()); 
# 1007
((m_storage).uninitialized_copy(mid, last, this->end())); 
# 1010
(m_size) = n; 
# 1011
}  }  
# 1012
} 
# 1014
template< class T, class Alloc> void 
# 1016
vector_base< T, Alloc> ::fill_assign(size_type n, const T &x) 
# 1017
{ 
# 1018
if (n > capacity()) 
# 1019
{ 
# 1022
vector_base temp(n, x); 
# 1023
temp.swap(*this); 
# 1024
} else { 
# 1025
if (n > size()) 
# 1026
{ 
# 1028
thrust::fill(this->begin(), this->end(), x); 
# 1031
((m_storage).uninitialized_fill_n(this->end(), n - size(), x)); 
# 1034
(m_size) += (n - size()); 
# 1035
} else 
# 1037
{ 
# 1039
iterator new_end = thrust::fill_n(this->begin(), n, x); 
# 1042
erase(new_end, this->end()); 
# 1043
}  }  
# 1044
} 
# 1046
template< class T, class Alloc> 
# 1047
template< class ForwardIterator> void 
# 1049
vector_base< T, Alloc> ::allocate_and_copy(size_type requested_size, ForwardIterator 
# 1050
first, ForwardIterator last, storage_type &
# 1051
new_storage) 
# 1052
{ 
# 1053
if (requested_size == 0) 
# 1054
{ 
# 1055
(new_storage.deallocate()); 
# 1056
return; 
# 1057
}  
# 1060
size_type allocated_size = thrust::max< size_type> (requested_size, 2 * capacity()); 
# 1063
allocated_size = thrust::min< size_type> (allocated_size, max_size()); 
# 1065
if (requested_size > allocated_size) 
# 1066
{ 
# 1067
throw ((std::length_error)("assignment exceeds max_size().")); 
# 1068
}  
# 1070
(new_storage.allocate(allocated_size)); 
# 1072
try 
# 1073
{ 
# 1075
((m_storage).uninitialized_copy(first, last, (new_storage.begin()))); 
# 1076
} 
# 1077
catch (...) 
# 1078
{ 
# 1081
iterator new_storage_end = (new_storage.begin()); 
# 1082
thrust::advance(new_storage_end, requested_size); 
# 1083
((m_storage).destroy((new_storage.begin()), new_storage_end)); 
# 1084
(new_storage.deallocate()); 
# 1087
throw; 
# 1088
}  
# 1089
} 
# 1092
}
# 1094
template< class T, class Alloc> void 
# 1095
swap(detail::vector_base< T, Alloc>  &a, detail::vector_base< T, Alloc>  &
# 1096
b) 
# 1097
{ 
# 1098
(a.swap(b)); 
# 1099
} 
# 1103
namespace detail { 
# 1107
template< class InputIterator1, class InputIterator2> bool 
# 1108
vector_equal(InputIterator1 first1, InputIterator1 last1, InputIterator2 
# 1109
first2, true_type) 
# 1111
{ 
# 1112
return thrust::equal(first1, last1, first2); 
# 1113
} 
# 1116
template< class InputIterator1, class InputIterator2> bool 
# 1117
vector_equal(InputIterator1 first1, InputIterator1 last1, InputIterator2 
# 1118
first2, false_type) 
# 1120
{ 
# 1121
typename iterator_difference< InputIterator1> ::type n = thrust::distance(first1, last1); 
# 1123
typedef typename iterator_system< InputIterator1> ::type FromSystem1; 
# 1124
typedef typename iterator_system< InputIterator2> ::type FromSystem2; 
# 1128
FromSystem1 from_system1; 
# 1129
FromSystem2 from_system2; 
# 1130
host_system_tag to_system; 
# 1131
move_to_system< InputIterator1, typename iterator_system< InputIterator1> ::type, system::cpp::detail::tag>  rng1(from_system1, to_system, first1, last1); 
# 1132
move_to_system< InputIterator2, typename iterator_system< InputIterator2> ::type, system::cpp::detail::tag>  rng2(from_system2, to_system, first2, first2 + n); 
# 1134
return thrust::equal((rng1.begin()), (rng1.end()), (rng2.begin())); 
# 1135
} 
# 1137
template< class InputIterator1, class InputIterator2> bool 
# 1138
vector_equal(InputIterator1 first1, InputIterator1 last1, InputIterator2 
# 1139
first2) 
# 1140
{ 
# 1141
typedef typename iterator_system< InputIterator1> ::type system1; 
# 1142
typedef typename iterator_system< InputIterator2> ::type system2; 
# 1145
return vector_equal(first1, last1, first2, is_same< typename iterator_system< InputIterator1> ::type, typename iterator_system< InputIterator2> ::type> ()); 
# 1147
} 
# 1149
}
# 1154
template< class T1, class Alloc1, class 
# 1155
T2, class Alloc2> bool 
# 1156
operator==(const detail::vector_base< T1, Alloc1>  &lhs, const detail::vector_base< T2, Alloc2>  &
# 1157
rhs) 
# 1158
{ 
# 1159
return ((lhs.size()) == (rhs.size())) && detail::vector_equal((lhs.begin()), (lhs.end()), (rhs.begin())); 
# 1160
} 
# 1162
template< class T1, class Alloc1, class 
# 1163
T2, class Alloc2> bool 
# 1164
operator==(const detail::vector_base< T1, Alloc1>  &lhs, const std::vector< T2, Alloc2>  &
# 1165
rhs) 
# 1166
{ 
# 1167
return ((lhs.size()) == (rhs.size())) && detail::vector_equal((lhs.begin()), (lhs.end()), (rhs.begin())); 
# 1168
} 
# 1170
template< class T1, class Alloc1, class 
# 1171
T2, class Alloc2> bool 
# 1172
operator==(const std::vector< T1, Alloc1>  &lhs, const detail::vector_base< T2, Alloc2>  &
# 1173
rhs) 
# 1174
{ 
# 1175
return ((lhs.size()) == (rhs.size())) && detail::vector_equal((lhs.begin()), (lhs.end()), (rhs.begin())); 
# 1176
} 
# 1178
template< class T1, class Alloc1, class 
# 1179
T2, class Alloc2> bool 
# 1180
operator!=(const detail::vector_base< T1, Alloc1>  &lhs, const detail::vector_base< T2, Alloc2>  &
# 1181
rhs) 
# 1182
{ 
# 1183
return !(lhs == rhs); 
# 1184
} 
# 1186
template< class T1, class Alloc1, class 
# 1187
T2, class Alloc2> bool 
# 1188
operator!=(const detail::vector_base< T1, Alloc1>  &lhs, const std::vector< T2, Alloc2>  &
# 1189
rhs) 
# 1190
{ 
# 1191
return !(lhs == rhs); 
# 1192
} 
# 1194
template< class T1, class Alloc1, class 
# 1195
T2, class Alloc2> bool 
# 1196
operator!=(const std::vector< T1, Alloc1>  &lhs, const detail::vector_base< T2, Alloc2>  &
# 1197
rhs) 
# 1198
{ 
# 1199
return !(lhs == rhs); 
# 1200
} 
# 1202
}
# 29 "/usr/local/cuda-8.0/include/thrust/host_vector.h"
namespace thrust { 
# 33
template< class T, class Alloc> class device_vector; 
# 51
template< class T, class Alloc = std::allocator< T> > 
# 52
class host_vector : public detail::vector_base< T, Alloc>  { 
# 56
typedef ::thrust::detail::vector_base< T, Alloc>  Parent; 
# 61
public: typedef typename ::thrust::detail::vector_base< T, Alloc> ::size_type size_type; 
# 62
typedef typename ::thrust::detail::vector_base< T, Alloc> ::value_type value_type; 
# 69
host_vector() : Parent() 
# 70
{ } 
# 77
~host_vector() { } 
# 84
explicit host_vector(size_type n) : Parent(n) 
# 85
{ } 
# 93
explicit host_vector(size_type n, const value_type &value) : Parent(n, value) 
# 94
{ } 
# 100
host_vector(const host_vector &v) : Parent(v) 
# 101
{ } 
# 107
host_vector &operator=(const host_vector &v) 
# 108
{ ::thrust::detail::vector_base< T, Alloc> ::operator=(v); return *this; } 
# 113
template< class OtherT, class OtherAlloc> 
# 115
host_vector(const ::thrust::host_vector< OtherT, OtherAlloc>  &v) : Parent(v) 
# 116
{ } 
# 121
template< class OtherT, class OtherAlloc> host_vector &
# 123
operator=(const ::thrust::host_vector< OtherT, OtherAlloc>  &v) 
# 124
{ ::thrust::detail::vector_base< T, Alloc> ::operator=(v); return *this; } 
# 129
template< class OtherT, class OtherAlloc> 
# 131
host_vector(const ::std::vector< OtherT, OtherAlloc>  &v) : Parent(v) 
# 132
{ } 
# 137
template< class OtherT, class OtherAlloc> host_vector &
# 139
operator=(const ::std::vector< OtherT, OtherAlloc>  &v) 
# 140
{ ::thrust::detail::vector_base< T, Alloc> ::operator=(v); return *this; } 
# 145
template< class OtherT, class OtherAlloc> host_vector(const device_vector< OtherT, OtherAlloc>  & v); 
# 152
template< class OtherT, class OtherAlloc> host_vector &
# 154
operator=(const device_vector< OtherT, OtherAlloc>  &v) 
# 155
{ ::thrust::detail::vector_base< T, Alloc> ::operator=(v); return *this; } 
# 161
template< class InputIterator> 
# 163
host_vector(InputIterator first, InputIterator last) : Parent(first, last) 
# 164
{ } 
# 425
}; 
# 430
}
# 24 "/usr/local/cuda-8.0/include/thrust/detail/host_vector.inl"
namespace thrust { 
# 27
template< class T, class Alloc> 
# 28
template< class OtherT, class OtherAlloc> 
# 31
host_vector< T, Alloc> ::host_vector(const device_vector< OtherT, OtherAlloc>  &v) : Parent(v) 
# 33
{ 
# 34
; 
# 35
} 
# 37
}
# 31 "/usr/local/cuda-8.0/include/thrust/memory.h"
namespace thrust { 
# 303
template< class DerivedPolicy> pointer< void, DerivedPolicy, use_default, use_default>  malloc(const detail::execution_policy_base< DerivedPolicy>  & system, std::size_t n); 
# 341
template< class T, class DerivedPolicy> pointer< T, DerivedPolicy, use_default, use_default>  malloc(const detail::execution_policy_base< DerivedPolicy>  & system, std::size_t n); 
# 394
template< class T, class DerivedPolicy> pair< pointer< T, DerivedPolicy, use_default, use_default> , typename pointer< T, DerivedPolicy, use_default, use_default> ::difference_type>  get_temporary_buffer(const detail::execution_policy_base< DerivedPolicy>  & system, typename pointer< T, DerivedPolicy, use_default, use_default> ::difference_type n); 
# 437
template< class DerivedPolicy, class Pointer> void free(const detail::execution_policy_base< DerivedPolicy>  & system, Pointer ptr); 
# 483
template< class DerivedPolicy, class Pointer> void return_temporary_buffer(const detail::execution_policy_base< DerivedPolicy>  & system, Pointer p); 
# 499
template< class Pointer> inline typename detail::pointer_traits< Pointer> ::raw_pointer raw_pointer_cast(const Pointer & ptr); 
# 516
template< class T> inline typename detail::raw_reference< T> ::type raw_reference_cast(T & ref); 
# 533
template< class T> inline typename detail::raw_reference< const T> ::type raw_reference_cast(const T & ref); 
# 542
}
# 27 "/usr/local/cuda-8.0/include/thrust/device_ptr.h"
namespace thrust { 
# 37
template< class T> class device_reference; 
# 60
template< class T> 
# 61
class device_ptr : public pointer< T, system::cuda::detail::tag, device_reference< T> , device_ptr< T> >  { 
# 75
typedef ::thrust::pointer< T, ::thrust::system::cuda::detail::tag, device_reference< T> , ::thrust::device_ptr< T> >  super_t; 
# 81
public: device_ptr() : super_t() { } 
# 89
template< class OtherT> explicit 
# 91
device_ptr(OtherT *ptr) : super_t(ptr) { } 
# 96
template< class OtherT> 
# 98
device_ptr(const ::thrust::device_ptr< OtherT>  &other) : super_t(other) { } 
# 104
template< class OtherT> device_ptr &
# 106
operator=(const ::thrust::device_ptr< OtherT>  &other) 
# 107
{ 
# 108
::thrust::pointer< T, ::thrust::system::cuda::detail::tag, device_reference< T> , ::thrust::device_ptr< T> > ::operator=(other); 
# 109
return *this; 
# 110
} 
# 121
}; 
# 153
template< class T> inline device_ptr< T>  device_pointer_cast(T * ptr); 
# 163
template< class T> inline device_ptr< T>  device_pointer_cast(const device_ptr< T>  & ptr); 
# 170
}
# 29 "/usr/local/cuda-8.0/include/thrust/device_reference.h"
namespace thrust { 
# 185
template< class T> 
# 186
class device_reference : public reference< T, device_ptr< T> , device_reference< T> >  { 
# 198
typedef ::thrust::reference< T, device_ptr< T> , ::thrust::device_reference< T> >  super_t; 
# 203
public: typedef typename ::thrust::reference< T, device_ptr< T> , ::thrust::device_reference< T> > ::value_type value_type; 
# 207
typedef typename ::thrust::reference< T, device_ptr< T> , ::thrust::device_reference< T> > ::pointer pointer; 
# 239
template< class OtherT> 
# 241
device_reference(const ::thrust::device_reference< OtherT>  &other, typename ::thrust::detail::enable_if_convertible< typename ::thrust::device_reference< OtherT> ::pointer, typename ::thrust::reference< T, device_ptr< T> , ::thrust::device_reference< T> > ::pointer> ::type * = 0) : super_t(other) 
# 247
{ } 
# 279
explicit device_reference(const pointer &ptr) : super_t(ptr) 
# 281
{ } 
# 290
template< class OtherT> device_reference &operator=(const ::thrust::device_reference< OtherT>  & other); 
# 301
device_reference &operator=(const value_type & x); 
# 953
}; 
# 959
template< class T> void swap(device_reference< T>  & x, device_reference< T>  & y); 
# 980
}
# 25 "/usr/local/cuda-8.0/include/thrust/detail/device_reference.inl"
namespace thrust { 
# 28
template< class T> 
# 29
template< class OtherT> device_reference< T>  &
# 32
device_reference< T> ::operator=(const ::thrust::device_reference< OtherT>  &other) 
# 33
{ 
# 34
return ::thrust::reference< T, device_ptr< T> , ::thrust::device_reference< T> > ::operator=(other); 
# 35
} 
# 37
template< class T> device_reference< T>  &
# 40
device_reference< T> ::operator=(const value_type &x) 
# 41
{ 
# 42
return ::thrust::reference< T, device_ptr< T> , ::thrust::device_reference< T> > ::operator=(x); 
# 43
} 
# 45
template< class T> void 
# 47
swap(device_reference< T>  &a, device_reference< T>  &b) 
# 48
{ 
# 49
(a.swap(b)); 
# 50
} 
# 52
}
# 27 "/usr/local/cuda-8.0/include/thrust/detail/device_ptr.inl"
namespace thrust { 
# 30
template< class T> inline device_ptr< T>  
# 31
device_pointer_cast(T *ptr) 
# 32
{ 
# 33
return ((device_ptr< T> )(ptr)); 
# 34
} 
# 36
template< class T> inline device_ptr< T>  
# 37
device_pointer_cast(const device_ptr< T>  &ptr) 
# 38
{ 
# 39
return ptr; 
# 40
} 
# 43
namespace detail { 
# 46
template< class T> 
# 47
struct is_device_ptr< device_ptr< T> >  : public true_type { 
# 50
}; 
# 63
}
# 64
}
# 28 "/usr/local/cuda-8.0/include/thrust/device_malloc.h"
namespace thrust { 
# 64
inline device_ptr< void>  device_malloc(const std::size_t n); 
# 94
template< class T> inline device_ptr< T>  device_malloc(const std::size_t n); 
# 100
}
# 28 "/usr/local/cuda-8.0/include/thrust/detail/device_malloc.inl"
namespace thrust { 
# 32
inline device_ptr< void>  device_malloc(const std::size_t n) 
# 33
{ 
# 34
using thrust::system::detail::generic::select_system;
# 36
typedef detail::iterator_category_to_system< detail::iterator_category_with_system_and_traversal< random_access_device_iterator_tag, thrust::system::cuda::detail::tag, random_access_traversal_tag> > ::type system; 
# 39
system s; 
# 41
return ((device_ptr< void> )(thrust::malloc(s, n).get())); 
# 42
} 
# 45
template< class T> inline device_ptr< T>  
# 46
device_malloc(const std::size_t n) 
# 47
{ 
# 48
using thrust::system::detail::generic::select_system;
# 50
typedef detail::iterator_category_to_system< detail::iterator_category_with_system_and_traversal< random_access_device_iterator_tag, thrust::system::cuda::detail::tag, random_access_traversal_tag> > ::type system; 
# 53
system s; 
# 55
return ((device_ptr< T> )((thrust::malloc< T> (s, n).get()))); 
# 56
} 
# 59
}
# 27 "/usr/local/cuda-8.0/include/thrust/device_free.h"
namespace thrust { 
# 60
inline void device_free(device_ptr< void>  ptr); 
# 65
}
# 28 "/usr/local/cuda-8.0/include/thrust/detail/device_free.inl"
namespace thrust { 
# 31
inline void device_free(device_ptr< void>  ptr) 
# 32
{ 
# 33
using thrust::system::detail::generic::select_system;
# 35
typedef detail::iterator_category_to_system< detail::iterator_category_with_system_and_traversal< random_access_device_iterator_tag, thrust::system::cuda::detail::tag, random_access_traversal_tag> > ::type system; 
# 38
system s; 
# 40
thrust::free(s, ptr); 
# 41
} 
# 43
}
# 32 "/usr/local/cuda-8.0/include/thrust/device_malloc_allocator.h"
namespace thrust { 
# 36
template< class > class device_ptr; 
# 37
template< class T> inline device_ptr< T>  device_malloc(const std::size_t n); 
# 52
template< class T> 
# 53
class device_malloc_allocator { 
# 57
public: typedef T value_type; 
# 60
typedef device_ptr< T>  pointer; 
# 63
typedef device_ptr< const T>  const_pointer; 
# 66
typedef device_reference< T>  reference; 
# 69
typedef device_reference< const T>  const_reference; 
# 72
typedef std::size_t size_type; 
# 75
typedef typename device_ptr< T> ::difference_type difference_type; 
# 82
template< class U> 
# 83
struct rebind { 
# 87
typedef thrust::device_malloc_allocator< U>  other; 
# 88
}; 
# 92
device_malloc_allocator() { } 
# 96
~device_malloc_allocator() { } 
# 100
device_malloc_allocator(const device_malloc_allocator &) { } 
# 103
template< class U> 
# 105
device_malloc_allocator(const thrust::device_malloc_allocator< U>  &) { } 
# 111
pointer address(reference r) { return &r; } 
# 117
const_pointer address(const_reference r) { return &r; } 
# 125
pointer allocate(size_type cnt, const_pointer = ((const_pointer)(static_cast< T *>(0)))) 
# 127
{ 
# 128
if (cnt > this->max_size()) 
# 129
{ 
# 130
throw std::bad_alloc(); 
# 131
}  
# 133
return ((pointer)(device_malloc< T> (cnt))); 
# 134
} 
# 143
void deallocate(pointer p, size_type cnt) 
# 144
{ 
# 146
(void)cnt; 
# 148
device_free(p); 
# 149
} 
# 154
size_type max_size() const 
# 155
{ 
# 156
return std::numeric_limits< unsigned long> ::max() / sizeof(T); 
# 157
} 
# 163
bool operator==(const device_malloc_allocator &) { return true; } 
# 169
bool operator!=(const device_malloc_allocator &a) { return !operator==(a); } 
# 170
}; 
# 175
}
# 29 "/usr/local/cuda-8.0/include/thrust/device_vector.h"
namespace thrust { 
# 33
template< class T, class Alloc> class host_vector; 
# 51
template< class T, class Alloc = device_malloc_allocator< T> > 
# 52
class device_vector : public detail::vector_base< T, Alloc>  { 
# 56
typedef ::thrust::detail::vector_base< T, Alloc>  Parent; 
# 61
public: typedef typename ::thrust::detail::vector_base< T, Alloc> ::size_type size_type; 
# 62
typedef typename ::thrust::detail::vector_base< T, Alloc> ::value_type value_type; 
# 69
device_vector() : Parent() 
# 70
{ } 
# 77
~device_vector() { } 
# 84
explicit device_vector(size_type n) : Parent(n) 
# 85
{ } 
# 93
explicit device_vector(size_type n, const value_type &value) : Parent(n, value) 
# 94
{ } 
# 100
device_vector(const device_vector &v) : Parent(v) 
# 101
{ } 
# 106
template< class OtherT, class OtherAlloc> 
# 108
device_vector(const ::thrust::device_vector< OtherT, OtherAlloc>  &v) : Parent(v) 
# 109
{int *volatile ___ = 0;(void)v;::free(___);}
#if 0
# 109
{ } 
#endif
# 114 "/usr/local/cuda-8.0/include/thrust/device_vector.h"
template< class OtherT, class OtherAlloc> device_vector &
# 116
operator=(const ::thrust::device_vector< OtherT, OtherAlloc>  &v) 
# 117
{int volatile ___ = 1;(void)v;::exit(___);}
#if 0
# 117
{ ::thrust::detail::vector_base< T, Alloc> ::operator=(v); return *this; } 
#endif
# 122 "/usr/local/cuda-8.0/include/thrust/device_vector.h"
template< class OtherT, class OtherAlloc> 
# 124
device_vector(const ::std::vector< OtherT, OtherAlloc>  &v) : Parent(v) 
# 125
{ } 
# 130
template< class OtherT, class OtherAlloc> device_vector &
# 132
operator=(const ::std::vector< OtherT, OtherAlloc>  &v) 
# 133
{ ::thrust::detail::vector_base< T, Alloc> ::operator=(v); return *this; } 
# 138
template< class OtherT, class OtherAlloc> device_vector(const host_vector< OtherT, OtherAlloc>  & v); 
# 145
template< class OtherT, class OtherAlloc> device_vector &
# 147
operator=(const host_vector< OtherT, OtherAlloc>  &v) 
# 148
{ ::thrust::detail::vector_base< T, Alloc> ::operator=(v); return *this; } 
# 154
template< class InputIterator> 
# 156
device_vector(InputIterator first, InputIterator last) : Parent(first, last) 
# 157
{ } 
# 418
}; 
# 423
}
# 24 "/usr/local/cuda-8.0/include/thrust/detail/device_vector.inl"
namespace thrust { 
# 27
template< class T, class Alloc> 
# 28
template< class OtherT, class OtherAlloc> 
# 31
device_vector< T, Alloc> ::device_vector(const host_vector< OtherT, OtherAlloc>  &v) : Parent(v) 
# 33
{ 
# 34
; 
# 35
} 
# 37
}
# 27 "/usr/local/cuda-8.0/include/thrust/sort.h"
namespace thrust { 
# 77
template< class DerivedPolicy, class RandomAccessIterator> void sort(const detail::execution_policy_base< DerivedPolicy>  & exec, RandomAccessIterator first, RandomAccessIterator last); 
# 119
template< class RandomAccessIterator> void sort(RandomAccessIterator first, RandomAccessIterator last); 
# 167
template< class DerivedPolicy, class 
# 168
RandomAccessIterator, class 
# 169
StrictWeakOrdering> void 
# 167
sort(const detail::execution_policy_base< DerivedPolicy>  & exec, RandomAccessIterator first, RandomAccessIterator last, StrictWeakOrdering comp); 
# 215
template< class RandomAccessIterator, class 
# 216
StrictWeakOrdering> void 
# 215
sort(RandomAccessIterator first, RandomAccessIterator last, StrictWeakOrdering comp); 
# 267
template< class DerivedPolicy, class RandomAccessIterator> void stable_sort(const detail::execution_policy_base< DerivedPolicy>  & exec, RandomAccessIterator first, RandomAccessIterator last); 
# 313
template< class RandomAccessIterator> void stable_sort(RandomAccessIterator first, RandomAccessIterator last); 
# 365
template< class DerivedPolicy, class 
# 366
RandomAccessIterator, class 
# 367
StrictWeakOrdering> void 
# 365
stable_sort(const detail::execution_policy_base< DerivedPolicy>  & exec, RandomAccessIterator first, RandomAccessIterator last, StrictWeakOrdering comp); 
# 417
template< class RandomAccessIterator, class 
# 418
StrictWeakOrdering> void 
# 417
stable_sort(RandomAccessIterator first, RandomAccessIterator last, StrictWeakOrdering comp); 
# 483
template< class DerivedPolicy, class 
# 484
RandomAccessIterator1, class 
# 485
RandomAccessIterator2> void 
# 483
sort_by_key(const detail::execution_policy_base< DerivedPolicy>  & exec, RandomAccessIterator1 keys_first, RandomAccessIterator1 keys_last, RandomAccessIterator2 values_first); 
# 541
template< class RandomAccessIterator1, class 
# 542
RandomAccessIterator2> void 
# 541
sort_by_key(RandomAccessIterator1 keys_first, RandomAccessIterator1 keys_last, RandomAccessIterator2 values_first); 
# 604
template< class DerivedPolicy, class 
# 605
RandomAccessIterator1, class 
# 606
RandomAccessIterator2, class 
# 607
StrictWeakOrdering> void 
# 604
sort_by_key(const detail::execution_policy_base< DerivedPolicy>  & exec, RandomAccessIterator1 keys_first, RandomAccessIterator1 keys_last, RandomAccessIterator2 values_first, StrictWeakOrdering comp); 
# 667
template< class RandomAccessIterator1, class 
# 668
RandomAccessIterator2, class 
# 669
StrictWeakOrdering> void 
# 667
sort_by_key(RandomAccessIterator1 keys_first, RandomAccessIterator1 keys_last, RandomAccessIterator2 values_first, StrictWeakOrdering comp); 
# 732
template< class DerivedPolicy, class 
# 733
RandomAccessIterator1, class 
# 734
RandomAccessIterator2> void 
# 732
stable_sort_by_key(const detail::execution_policy_base< DerivedPolicy>  & exec, RandomAccessIterator1 keys_first, RandomAccessIterator1 keys_last, RandomAccessIterator2 values_first); 
# 792
template< class RandomAccessIterator1, class 
# 793
RandomAccessIterator2> void 
# 792
stable_sort_by_key(RandomAccessIterator1 keys_first, RandomAccessIterator1 keys_last, RandomAccessIterator2 values_first); 
# 858
template< class DerivedPolicy, class 
# 859
RandomAccessIterator1, class 
# 860
RandomAccessIterator2, class 
# 861
StrictWeakOrdering> void 
# 858
stable_sort_by_key(const detail::execution_policy_base< DerivedPolicy>  & exec, RandomAccessIterator1 keys_first, RandomAccessIterator1 keys_last, RandomAccessIterator2 values_first, StrictWeakOrdering comp); 
# 924
template< class RandomAccessIterator1, class 
# 925
RandomAccessIterator2, class 
# 926
StrictWeakOrdering> void 
# 924
stable_sort_by_key(RandomAccessIterator1 keys_first, RandomAccessIterator1 keys_last, RandomAccessIterator2 values_first, StrictWeakOrdering comp); 
# 999
template< class DerivedPolicy, class ForwardIterator> bool is_sorted(const detail::execution_policy_base< DerivedPolicy>  & exec, ForwardIterator first, ForwardIterator last); 
# 1055
template< class ForwardIterator> bool is_sorted(ForwardIterator first, ForwardIterator last); 
# 1114
template< class DerivedPolicy, class ForwardIterator, class Compare> bool is_sorted(const detail::execution_policy_base< DerivedPolicy>  & exec, ForwardIterator first, ForwardIterator last, Compare comp); 
# 1170
template< class ForwardIterator, class Compare> bool is_sorted(ForwardIterator first, ForwardIterator last, Compare comp); 
# 1215
template< class DerivedPolicy, class ForwardIterator> ForwardIterator is_sorted_until(const detail::execution_policy_base< DerivedPolicy>  & exec, ForwardIterator first, ForwardIterator last); 
# 1255
template< class ForwardIterator> ForwardIterator is_sorted_until(ForwardIterator first, ForwardIterator last); 
# 1303
template< class DerivedPolicy, class ForwardIterator, class Compare> ForwardIterator is_sorted_until(const detail::execution_policy_base< DerivedPolicy>  & exec, ForwardIterator first, ForwardIterator last, Compare comp); 
# 1348
template< class ForwardIterator, class Compare> ForwardIterator is_sorted_until(ForwardIterator first, ForwardIterator last, Compare comp); 
# 1359
}
# 22 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/sort.h"
namespace thrust { 
# 24
namespace system { 
# 26
namespace detail { 
# 28
namespace generic { 
# 32
template< class DerivedPolicy, class 
# 33
RandomAccessIterator> void 
# 32
sort(execution_policy< DerivedPolicy>  & exec, RandomAccessIterator first, RandomAccessIterator last); 
# 40
template< class DerivedPolicy, class 
# 41
RandomAccessIterator, class 
# 42
StrictWeakOrdering> void 
# 40
sort(execution_policy< DerivedPolicy>  & exec, RandomAccessIterator first, RandomAccessIterator last, StrictWeakOrdering comp); 
# 50
template< class DerivedPolicy, class 
# 51
RandomAccessIterator1, class 
# 52
RandomAccessIterator2> void 
# 50
sort_by_key(execution_policy< DerivedPolicy>  & exec, RandomAccessIterator1 keys_first, RandomAccessIterator1 keys_last, RandomAccessIterator2 values_first); 
# 60
template< class DerivedPolicy, class 
# 61
RandomAccessIterator1, class 
# 62
RandomAccessIterator2, class 
# 63
StrictWeakOrdering> void 
# 60
sort_by_key(execution_policy< DerivedPolicy>  & exec, RandomAccessIterator1 keys_first, RandomAccessIterator1 keys_last, RandomAccessIterator2 values_first, StrictWeakOrdering comp); 
# 72
template< class DerivedPolicy, class 
# 73
RandomAccessIterator> void 
# 72
stable_sort(execution_policy< DerivedPolicy>  & exec, RandomAccessIterator first, RandomAccessIterator last); 
# 81
template< class DerivedPolicy, class 
# 82
RandomAccessIterator, class 
# 83
StrictWeakOrdering> void 
# 81
stable_sort(execution_policy< DerivedPolicy>  & exec, RandomAccessIterator first, RandomAccessIterator last, StrictWeakOrdering comp); 
# 91
template< class DerivedPolicy, class 
# 92
RandomAccessIterator1, class 
# 93
RandomAccessIterator2> void 
# 91
stable_sort_by_key(execution_policy< DerivedPolicy>  & exec, RandomAccessIterator1 keys_first, RandomAccessIterator1 keys_last, RandomAccessIterator2 values_first); 
# 102
template< class DerivedPolicy, class 
# 103
RandomAccessIterator1, class 
# 104
RandomAccessIterator2, class 
# 105
StrictWeakOrdering> void 
# 102
stable_sort_by_key(execution_policy< DerivedPolicy>  & exec, RandomAccessIterator1 keys_first, RandomAccessIterator1 keys_last, RandomAccessIterator2 values_first, StrictWeakOrdering comp); 
# 114
template< class DerivedPolicy, class ForwardIterator> bool is_sorted(execution_policy< DerivedPolicy>  & exec, ForwardIterator first, ForwardIterator last); 
# 121
template< class DerivedPolicy, class 
# 122
ForwardIterator, class 
# 123
Compare> bool 
# 121
is_sorted(execution_policy< DerivedPolicy>  & exec, ForwardIterator first, ForwardIterator last, Compare comp); 
# 131
template< class DerivedPolicy, class ForwardIterator> ForwardIterator is_sorted_until(execution_policy< DerivedPolicy>  & exec, ForwardIterator first, ForwardIterator last); 
# 138
template< class DerivedPolicy, class 
# 139
ForwardIterator, class 
# 140
Compare> ForwardIterator 
# 138
is_sorted_until(execution_policy< DerivedPolicy>  & exec, ForwardIterator first, ForwardIterator last, Compare comp); 
# 148
}
# 149
}
# 150
}
# 151
}
# 31 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/sort.inl"
namespace thrust { 
# 33
namespace system { 
# 35
namespace detail { 
# 37
namespace generic { 
# 41
template< class DerivedPolicy, class 
# 42
RandomAccessIterator> void 
# 44
sort(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator 
# 45
first, RandomAccessIterator 
# 46
last) 
# 47
{ 
# 48
typedef typename iterator_value< RandomAccessIterator> ::type value_type; 
# 49
thrust::sort(exec, first, last, less< typename iterator_value< RandomAccessIterator> ::type> ()); 
# 50
} 
# 53
template< class DerivedPolicy, class 
# 54
RandomAccessIterator, class 
# 55
StrictWeakOrdering> void 
# 57
sort(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator 
# 58
first, RandomAccessIterator 
# 59
last, StrictWeakOrdering 
# 60
comp) 
# 61
{ 
# 63
thrust::stable_sort(exec, first, last, comp); 
# 64
} 
# 67
template< class DerivedPolicy, class 
# 68
RandomAccessIterator1, class 
# 69
RandomAccessIterator2> void 
# 71
sort_by_key(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator1 
# 72
keys_first, RandomAccessIterator1 
# 73
keys_last, RandomAccessIterator2 
# 74
values_first) 
# 75
{ 
# 76
typedef typename iterator_value< RandomAccessIterator1> ::type value_type; 
# 77
thrust::sort_by_key(exec, keys_first, keys_last, values_first, less< typename iterator_value< RandomAccessIterator1> ::type> ()); 
# 78
} 
# 81
template< class DerivedPolicy, class 
# 82
RandomAccessIterator1, class 
# 83
RandomAccessIterator2, class 
# 84
StrictWeakOrdering> void 
# 86
sort_by_key(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator1 
# 87
keys_first, RandomAccessIterator1 
# 88
keys_last, RandomAccessIterator2 
# 89
values_first, StrictWeakOrdering 
# 90
comp) 
# 91
{ 
# 93
thrust::stable_sort_by_key(exec, keys_first, keys_last, values_first, comp); 
# 94
} 
# 97
template< class DerivedPolicy, class 
# 98
RandomAccessIterator> void 
# 100
stable_sort(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator 
# 101
first, RandomAccessIterator 
# 102
last) 
# 103
{ 
# 104
typedef typename iterator_value< RandomAccessIterator> ::type value_type; 
# 105
thrust::stable_sort(exec, first, last, less< typename iterator_value< RandomAccessIterator> ::type> ()); 
# 106
} 
# 109
template< class DerivedPolicy, class 
# 110
RandomAccessIterator1, class 
# 111
RandomAccessIterator2> void 
# 113
stable_sort_by_key(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator1 
# 114
keys_first, RandomAccessIterator1 
# 115
keys_last, RandomAccessIterator2 
# 116
values_first) 
# 117
{ 
# 118
typedef typename iterator_value< RandomAccessIterator1> ::type value_type; 
# 119
thrust::stable_sort_by_key(exec, keys_first, keys_last, values_first, less< typename iterator_value< RandomAccessIterator1> ::type> ()); 
# 120
} 
# 123
template< class DerivedPolicy, class ForwardIterator> bool 
# 125
is_sorted(execution_policy< DerivedPolicy>  &exec, ForwardIterator 
# 126
first, ForwardIterator 
# 127
last) 
# 128
{ 
# 129
return thrust::is_sorted_until(exec, first, last) == last; 
# 130
} 
# 133
template< class DerivedPolicy, class 
# 134
ForwardIterator, class 
# 135
Compare> bool 
# 137
is_sorted(execution_policy< DerivedPolicy>  &exec, ForwardIterator 
# 138
first, ForwardIterator 
# 139
last, Compare 
# 140
comp) 
# 141
{ 
# 142
return thrust::is_sorted_until(exec, first, last, comp) == last; 
# 143
} 
# 146
template< class DerivedPolicy, class ForwardIterator> ForwardIterator 
# 148
is_sorted_until(execution_policy< DerivedPolicy>  &exec, ForwardIterator 
# 149
first, ForwardIterator 
# 150
last) 
# 151
{ 
# 152
typedef typename iterator_value< ForwardIterator> ::type InputType; 
# 154
return thrust::is_sorted_until(exec, first, last, less< typename iterator_value< ForwardIterator> ::type> ()); 
# 155
} 
# 158
template< class DerivedPolicy, class 
# 159
ForwardIterator, class 
# 160
Compare> ForwardIterator 
# 162
is_sorted_until(execution_policy< DerivedPolicy>  &exec, ForwardIterator 
# 163
first, ForwardIterator 
# 164
last, Compare 
# 165
comp) 
# 166
{ 
# 167
if (thrust::distance(first, last) < 2) { return last; }  
# 169
typedef tuple< ForwardIterator, ForwardIterator, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type>  IteratorTuple; 
# 170
typedef zip_iterator< tuple< ForwardIterator, ForwardIterator, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type> >  ZipIterator; 
# 172
ForwardIterator first_plus_one = first; 
# 173
thrust::advance(first_plus_one, 1); 
# 175
ZipIterator zipped_first = thrust::make_zip_iterator(thrust::make_tuple(first_plus_one, first)); 
# 176
ZipIterator zipped_last = thrust::make_zip_iterator(thrust::make_tuple(last, first)); 
# 178
return thrust::get< 0> ((thrust::find_if(exec, zipped_first, zipped_last, ((thrust::detail::tuple_binary_predicate< Compare> )(comp))).get_iterator_tuple())); 
# 179
} 
# 182
template< class DerivedPolicy, class 
# 183
RandomAccessIterator, class 
# 184
StrictWeakOrdering> void 
# 186
stable_sort(execution_policy< DerivedPolicy>  &, RandomAccessIterator 
# 187
first, RandomAccessIterator 
# 188
last, StrictWeakOrdering 
# 189
comp) 
# 190
{ 
# 192
typedef thrust::detail::static_assert_test< sizeof(thrust::detail::STATIC_ASSERTION_FAILURE< (bool)(thrust::detail::depend_on_instantiation< RandomAccessIterator, false> ::value)> )>  thrust_static_assert_typedef_192 __attribute((unused)); 
# 193
} 
# 196
template< class DerivedPolicy, class 
# 197
RandomAccessIterator1, class 
# 198
RandomAccessIterator2, class 
# 199
StrictWeakOrdering> void 
# 201
stable_sort_by_key(execution_policy< DerivedPolicy>  &, RandomAccessIterator1 
# 202
keys_first, RandomAccessIterator1 
# 203
keys_last, RandomAccessIterator2 
# 204
values_first, StrictWeakOrdering 
# 205
comp) 
# 206
{ 
# 208
typedef thrust::detail::static_assert_test< sizeof(thrust::detail::STATIC_ASSERTION_FAILURE< (bool)(thrust::detail::depend_on_instantiation< RandomAccessIterator1, false> ::value)> )>  thrust_static_assert_typedef_208 __attribute((unused)); 
# 209
} 
# 212
}
# 213
}
# 214
}
# 215
}
# 26 "/usr/local/cuda-8.0/include/thrust/system/detail/sequential/sort.h"
namespace thrust { 
# 28
namespace system { 
# 30
namespace detail { 
# 32
namespace sequential { 
# 36
template< class DerivedPolicy, class 
# 37
RandomAccessIterator, class 
# 38
StrictWeakOrdering> void 
# 36
stable_sort(execution_policy< DerivedPolicy>  & exec, RandomAccessIterator first, RandomAccessIterator last, StrictWeakOrdering comp); 
# 46
template< class DerivedPolicy, class 
# 47
RandomAccessIterator1, class 
# 48
RandomAccessIterator2, class 
# 49
StrictWeakOrdering> void 
# 46
stable_sort_by_key(execution_policy< DerivedPolicy>  & exec, RandomAccessIterator1 first1, RandomAccessIterator1 last1, RandomAccessIterator2 first2, StrictWeakOrdering comp); 
# 58
}
# 59
}
# 60
}
# 61
}
# 27 "/usr/local/cuda-8.0/include/thrust/reverse.h"
namespace thrust { 
# 69
template< class DerivedPolicy, class BidirectionalIterator> void reverse(const detail::execution_policy_base< DerivedPolicy>  & exec, BidirectionalIterator first, BidirectionalIterator last); 
# 103
template< class BidirectionalIterator> void reverse(BidirectionalIterator first, BidirectionalIterator last); 
# 154
template< class DerivedPolicy, class BidirectionalIterator, class OutputIterator> OutputIterator reverse_copy(const detail::execution_policy_base< DerivedPolicy>  & exec, BidirectionalIterator first, BidirectionalIterator last, OutputIterator result); 
# 202
template< class BidirectionalIterator, class OutputIterator> OutputIterator reverse_copy(BidirectionalIterator first, BidirectionalIterator last, OutputIterator result); 
# 212
}
# 23 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/reverse.h"
namespace thrust { 
# 25
namespace system { 
# 27
namespace detail { 
# 29
namespace generic { 
# 33
template< class DerivedPolicy, class BidirectionalIterator> void reverse(execution_policy< DerivedPolicy>  & exec, BidirectionalIterator first, BidirectionalIterator last); 
# 40
template< class DerivedPolicy, class 
# 41
BidirectionalIterator, class 
# 42
OutputIterator> OutputIterator 
# 40
reverse_copy(execution_policy< DerivedPolicy>  & exec, BidirectionalIterator first, BidirectionalIterator last, OutputIterator result); 
# 50
}
# 51
}
# 52
}
# 53
}
# 26 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/reverse.inl"
namespace thrust { 
# 28
namespace system { 
# 30
namespace detail { 
# 32
namespace generic { 
# 36
template< class ExecutionPolicy, class BidirectionalIterator> void 
# 38
reverse(execution_policy< ExecutionPolicy>  &exec, BidirectionalIterator 
# 39
first, BidirectionalIterator 
# 40
last) 
# 41
{ 
# 42
typedef typename iterator_difference< BidirectionalIterator> ::type difference_type; 
# 45
difference_type N = thrust::distance(first, last); 
# 46
BidirectionalIterator mid(first); 
# 47
thrust::advance(mid, N / 2); 
# 50
thrust::swap_ranges(exec, first, mid, thrust::make_reverse_iterator(last)); 
# 51
} 
# 54
template< class ExecutionPolicy, class 
# 55
BidirectionalIterator, class 
# 56
OutputIterator> OutputIterator 
# 58
reverse_copy(execution_policy< ExecutionPolicy>  &exec, BidirectionalIterator 
# 59
first, BidirectionalIterator 
# 60
last, OutputIterator 
# 61
result) 
# 62
{ 
# 63
return thrust::copy(exec, thrust::make_reverse_iterator(last), thrust::make_reverse_iterator(first), result); 
# 67
} 
# 70
}
# 71
}
# 72
}
# 73
}
# 29 "/usr/local/cuda-8.0/include/thrust/detail/reverse.inl"
namespace thrust { 
# 34
template< class DerivedPolicy, class BidirectionalIterator> void 
# 36
reverse(const detail::execution_policy_base< DerivedPolicy>  &exec, BidirectionalIterator 
# 37
first, BidirectionalIterator 
# 38
last) 
# 39
{ 
# 40
using system::detail::generic::reverse;
# 41
return reverse(detail::derived_cast(detail::strip_const(exec)), first, last); 
# 42
} 
# 46
template< class DerivedPolicy, class BidirectionalIterator, class OutputIterator> OutputIterator 
# 48
reverse_copy(const detail::execution_policy_base< DerivedPolicy>  &exec, BidirectionalIterator 
# 49
first, BidirectionalIterator 
# 50
last, OutputIterator 
# 51
result) 
# 52
{ 
# 53
using system::detail::generic::reverse_copy;
# 54
return reverse_copy(detail::derived_cast(detail::strip_const(exec)), first, last, result); 
# 55
} 
# 58
template< class BidirectionalIterator> void 
# 59
reverse(BidirectionalIterator first, BidirectionalIterator 
# 60
last) 
# 61
{ 
# 62
using thrust::system::detail::generic::select_system;
# 64
typedef typename iterator_system< BidirectionalIterator> ::type System; 
# 66
System system; 
# 68
return thrust::reverse(select_system(system), first, last); 
# 69
} 
# 72
template< class BidirectionalIterator, class 
# 73
OutputIterator> OutputIterator 
# 74
reverse_copy(BidirectionalIterator first, BidirectionalIterator 
# 75
last, OutputIterator 
# 76
result) 
# 77
{ 
# 78
using system::detail::generic::select_system;
# 80
typedef typename iterator_system< BidirectionalIterator> ::type System1; 
# 81
typedef typename iterator_system< OutputIterator> ::type System2; 
# 83
System1 system1; 
# 84
System2 system2; 
# 86
return thrust::reverse_copy(select_system(system1, system2), first, last, result); 
# 87
} 
# 90
}
# 22 "/usr/local/cuda-8.0/include/thrust/system/detail/sequential/stable_merge_sort.h"
namespace thrust { 
# 24
namespace system { 
# 26
namespace detail { 
# 28
namespace sequential { 
# 32
template< class DerivedPolicy, class 
# 33
RandomAccessIterator, class 
# 34
StrictWeakOrdering> void 
# 32
stable_merge_sort(execution_policy< DerivedPolicy>  & exec, RandomAccessIterator begin, RandomAccessIterator end, StrictWeakOrdering comp); 
# 42
template< class DerivedPolicy, class 
# 43
RandomAccessIterator1, class 
# 44
RandomAccessIterator2, class 
# 45
StrictWeakOrdering> void 
# 42
stable_merge_sort_by_key(execution_policy< DerivedPolicy>  & exec, RandomAccessIterator1 keys_begin, RandomAccessIterator1 keys_end, RandomAccessIterator2 values_begin, StrictWeakOrdering comp); 
# 54
}
# 55
}
# 56
}
# 57
}
# 27 "/usr/local/cuda-8.0/include/thrust/merge.h"
namespace thrust { 
# 98
template< class DerivedPolicy, class 
# 99
InputIterator1, class 
# 100
InputIterator2, class 
# 101
OutputIterator> OutputIterator 
# 98
merge(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator1 first1, InputIterator1 last1, InputIterator2 first2, InputIterator2 last2, OutputIterator result); 
# 163
template< class InputIterator1, class 
# 164
InputIterator2, class 
# 165
OutputIterator> OutputIterator 
# 163
merge(InputIterator1 first1, InputIterator1 last1, InputIterator2 first2, InputIterator2 last2, OutputIterator result); 
# 233
template< class DerivedPolicy, class 
# 234
InputIterator1, class 
# 235
InputIterator2, class 
# 236
OutputIterator, class 
# 237
StrictWeakCompare> OutputIterator 
# 233
merge(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator1 first1, InputIterator1 last1, InputIterator2 first2, InputIterator2 last2, OutputIterator result, StrictWeakCompare comp); 
# 299
template< class InputIterator1, class 
# 300
InputIterator2, class 
# 301
OutputIterator, class 
# 302
StrictWeakCompare> OutputIterator 
# 299
merge(InputIterator1 first1, InputIterator1 last1, InputIterator2 first2, InputIterator2 last2, OutputIterator result, StrictWeakCompare comp); 
# 396
template< class DerivedPolicy, class InputIterator1, class InputIterator2, class InputIterator3, class InputIterator4, class OutputIterator1, class OutputIterator2> pair< OutputIterator1, OutputIterator2>  merge_by_key(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator1 keys_first1, InputIterator1 keys_last1, InputIterator2 keys_first2, InputIterator2 keys_last2, InputIterator3 values_first1, InputIterator4 values_first2, OutputIterator1 keys_result, OutputIterator2 values_result); 
# 482
template< class InputIterator1, class InputIterator2, class InputIterator3, class InputIterator4, class OutputIterator1, class OutputIterator2> pair< OutputIterator1, OutputIterator2>  merge_by_key(InputIterator1 keys_first1, InputIterator1 keys_last1, InputIterator2 keys_first2, InputIterator2 keys_last2, InputIterator3 values_first1, InputIterator4 values_first2, OutputIterator1 keys_result, OutputIterator2 values_result); 
# 577
template< class DerivedPolicy, class InputIterator1, class InputIterator2, class InputIterator3, class InputIterator4, class OutputIterator1, class OutputIterator2, class Compare> pair< OutputIterator1, OutputIterator2>  merge_by_key(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator1 keys_first1, InputIterator1 keys_last1, InputIterator2 keys_first2, InputIterator2 keys_last2, InputIterator3 values_first1, InputIterator4 values_first2, OutputIterator1 keys_result, OutputIterator2 values_result, Compare comp); 
# 664
template< class InputIterator1, class InputIterator2, class InputIterator3, class InputIterator4, class OutputIterator1, class OutputIterator2, class StrictWeakCompare> pair< OutputIterator1, OutputIterator2>  merge_by_key(InputIterator1 keys_first1, InputIterator1 keys_last1, InputIterator2 keys_first2, InputIterator2 keys_last2, InputIterator3 values_first1, InputIterator4 values_first2, OutputIterator1 keys_result, OutputIterator2 values_result, StrictWeakCompare comp); 
# 677
}
# 23 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/merge.h"
namespace thrust { 
# 25
namespace system { 
# 27
namespace detail { 
# 29
namespace generic { 
# 34
template< class DerivedPolicy, class 
# 35
InputIterator1, class 
# 36
InputIterator2, class 
# 37
OutputIterator, class 
# 38
StrictWeakOrdering> OutputIterator 
# 34
merge(execution_policy< DerivedPolicy>  & exec, InputIterator1 first1, InputIterator1 last1, InputIterator2 first2, InputIterator2 last2, OutputIterator result, StrictWeakOrdering comp); 
# 49
template< class DerivedPolicy, class 
# 50
InputIterator1, class 
# 51
InputIterator2, class 
# 52
OutputIterator> OutputIterator 
# 49
merge(execution_policy< DerivedPolicy>  & exec, InputIterator1 first1, InputIterator1 last1, InputIterator2 first2, InputIterator2 last2, OutputIterator result); 
# 62
template< class DerivedPolicy, class InputIterator1, class InputIterator2, class InputIterator3, class InputIterator4, class OutputIterator1, class OutputIterator2, class Compare> pair< OutputIterator1, OutputIterator2>  merge_by_key(execution_policy< DerivedPolicy>  & exec, InputIterator1 keys_first1, InputIterator1 keys_last1, InputIterator2 keys_first2, InputIterator2 keys_last2, InputIterator3 values_first1, InputIterator4 values_first2, OutputIterator1 keys_result, OutputIterator2 values_result, Compare comp); 
# 74
template< class DerivedPolicy, class InputIterator1, class InputIterator2, class InputIterator3, class InputIterator4, class OutputIterator1, class OutputIterator2> pair< OutputIterator1, OutputIterator2>  merge_by_key(execution_policy< DerivedPolicy>  & exec, InputIterator1 keys_first1, InputIterator1 keys_last1, InputIterator2 keys_first2, InputIterator2 keys_last2, InputIterator3 values_first1, InputIterator4 values_first2, OutputIterator1 keys_result, OutputIterator2 values_result); 
# 85
}
# 86
}
# 87
}
# 88
}
# 28 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/merge.inl"
namespace thrust { 
# 30
namespace system { 
# 32
namespace detail { 
# 34
namespace generic { 
# 38
template< class DerivedPolicy, class 
# 39
InputIterator1, class 
# 40
InputIterator2, class 
# 41
OutputIterator, class 
# 42
StrictWeakOrdering> OutputIterator 
# 44
merge(execution_policy< DerivedPolicy>  &exec, InputIterator1 
# 45
first1, InputIterator1 
# 46
last1, InputIterator2 
# 47
first2, InputIterator2 
# 48
last2, OutputIterator 
# 49
result, StrictWeakOrdering 
# 50
comp) 
# 51
{ 
# 53
typedef thrust::detail::static_assert_test< sizeof(thrust::detail::STATIC_ASSERTION_FAILURE< (bool)(thrust::detail::depend_on_instantiation< InputIterator1, false> ::value)> )>  thrust_static_assert_typedef_53 __attribute((unused)); 
# 54
return result; 
# 55
} 
# 58
template< class DerivedPolicy, class 
# 59
InputIterator1, class 
# 60
InputIterator2, class 
# 61
OutputIterator> OutputIterator 
# 63
merge(execution_policy< DerivedPolicy>  &exec, InputIterator1 
# 64
first1, InputIterator1 
# 65
last1, InputIterator2 
# 66
first2, InputIterator2 
# 67
last2, OutputIterator 
# 68
result) 
# 69
{ 
# 70
typedef typename iterator_value< InputIterator1> ::type value_type; 
# 71
return thrust::merge(exec, first1, last1, first2, last2, result, less< typename iterator_value< InputIterator1> ::type> ()); 
# 72
} 
# 75
template< class DerivedPolicy, class InputIterator1, class InputIterator2, class InputIterator3, class InputIterator4, class OutputIterator1, class OutputIterator2, class Compare> pair< OutputIterator1, OutputIterator2>  
# 78
merge_by_key(execution_policy< DerivedPolicy>  &exec, InputIterator1 
# 79
keys_first1, InputIterator1 keys_last1, InputIterator2 
# 80
keys_first2, InputIterator2 keys_last2, InputIterator3 
# 81
values_first1, InputIterator4 values_first2, OutputIterator1 
# 82
keys_result, OutputIterator2 
# 83
values_result, Compare 
# 84
comp) 
# 85
{ 
# 86
typedef tuple< InputIterator1, InputIterator3, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type>  iterator_tuple1; 
# 87
typedef tuple< InputIterator2, InputIterator4, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type>  iterator_tuple2; 
# 88
typedef tuple< OutputIterator1, OutputIterator2, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type>  iterator_tuple3; 
# 90
typedef zip_iterator< tuple< InputIterator1, InputIterator3, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type> >  zip_iterator1; 
# 91
typedef zip_iterator< tuple< InputIterator2, InputIterator4, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type> >  zip_iterator2; 
# 92
typedef zip_iterator< tuple< OutputIterator1, OutputIterator2, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type> >  zip_iterator3; 
# 94
zip_iterator1 zipped_first1 = thrust::make_zip_iterator(thrust::make_tuple(keys_first1, values_first1)); 
# 95
zip_iterator1 zipped_last1 = thrust::make_zip_iterator(thrust::make_tuple(keys_last1, values_first1)); 
# 97
zip_iterator2 zipped_first2 = thrust::make_zip_iterator(thrust::make_tuple(keys_first2, values_first2)); 
# 98
zip_iterator2 zipped_last2 = thrust::make_zip_iterator(thrust::make_tuple(keys_last2, values_first2)); 
# 100
zip_iterator3 zipped_result = thrust::make_zip_iterator(thrust::make_tuple(keys_result, values_result)); 
# 102
thrust::detail::compare_first< Compare>  comp_first(comp); 
# 104
iterator_tuple3 result = (thrust::merge(exec, zipped_first1, zipped_last1, zipped_first2, zipped_last2, zipped_result, comp_first).get_iterator_tuple()); 
# 106
return thrust::make_pair(thrust::get< 0> (result), thrust::get< 1> (result)); 
# 107
} 
# 110
template< class DerivedPolicy, class InputIterator1, class InputIterator2, class InputIterator3, class InputIterator4, class OutputIterator1, class OutputIterator2> pair< OutputIterator1, OutputIterator2>  
# 113
merge_by_key(execution_policy< DerivedPolicy>  &exec, InputIterator1 
# 114
keys_first1, InputIterator1 keys_last1, InputIterator2 
# 115
keys_first2, InputIterator2 keys_last2, InputIterator3 
# 116
values_first1, InputIterator4 values_first2, OutputIterator1 
# 117
keys_result, OutputIterator2 
# 118
values_result) 
# 119
{ 
# 120
typedef typename iterator_value< InputIterator1> ::type value_type; 
# 121
return thrust::merge_by_key(exec, keys_first1, keys_last1, keys_first2, keys_last2, values_first1, values_first2, keys_result, values_result, less< typename iterator_value< InputIterator1> ::type> ()); 
# 122
} 
# 125
}
# 126
}
# 127
}
# 128
}
# 27 "/usr/local/cuda-8.0/include/thrust/system/detail/sequential/merge.h"
namespace thrust { 
# 29
namespace system { 
# 31
namespace detail { 
# 33
namespace sequential { 
# 37
template< class DerivedPolicy, class 
# 38
InputIterator1, class 
# 39
InputIterator2, class 
# 40
OutputIterator, class 
# 41
StrictWeakOrdering> OutputIterator 
# 37
merge(execution_policy< DerivedPolicy>  & exec, InputIterator1 first1, InputIterator1 last1, InputIterator2 first2, InputIterator2 last2, OutputIterator result, StrictWeakOrdering comp); 
# 52
template< class DerivedPolicy, class 
# 53
InputIterator1, class 
# 54
InputIterator2, class 
# 55
InputIterator3, class 
# 56
InputIterator4, class 
# 57
OutputIterator1, class 
# 58
OutputIterator2, class 
# 59
StrictWeakOrdering> pair< OutputIterator1, OutputIterator2>  
# 52
merge_by_key(execution_policy< DerivedPolicy>  & exec, InputIterator1 keys_first1, InputIterator1 keys_last1, InputIterator2 keys_first2, InputIterator2 keys_last2, InputIterator3 values_first1, InputIterator4 values_first2, OutputIterator1 keys_result, OutputIterator2 values_result, StrictWeakOrdering comp); 
# 74
}
# 75
}
# 76
}
# 77
}
# 23 "/usr/local/cuda-8.0/include/thrust/system/detail/sequential/merge.inl"
namespace thrust { 
# 25
namespace system { 
# 27
namespace detail { 
# 29
namespace sequential { 
# 34
template< class DerivedPolicy, class 
# 35
InputIterator1, class 
# 36
InputIterator2, class 
# 37
OutputIterator, class 
# 38
StrictWeakOrdering> OutputIterator 
# 40
merge(execution_policy< DerivedPolicy>  &exec, InputIterator1 
# 41
first1, InputIterator1 
# 42
last1, InputIterator2 
# 43
first2, InputIterator2 
# 44
last2, OutputIterator 
# 45
result, StrictWeakOrdering 
# 46
comp) 
# 47
{ 
# 52
thrust::detail::wrapped_function< StrictWeakOrdering, bool>  wrapped_comp(comp); 
# 54
while ((first1 != last1) && (first2 != last2)) 
# 55
{ 
# 56
if (wrapped_comp(*first2, *first1)) 
# 57
{ 
# 58
(*result) = (*first2); 
# 59
++first2; 
# 60
} else 
# 62
{ 
# 63
(*result) = (*first1); 
# 64
++first1; 
# 65
}  
# 67
++result; 
# 68
}  
# 70
return thrust::copy(exec, first2, last2, thrust::copy(exec, first1, last1, result)); 
# 71
} 
# 75
template< class DerivedPolicy, class 
# 76
InputIterator1, class 
# 77
InputIterator2, class 
# 78
InputIterator3, class 
# 79
InputIterator4, class 
# 80
OutputIterator1, class 
# 81
OutputIterator2, class 
# 82
StrictWeakOrdering> pair< OutputIterator1, OutputIterator2>  
# 85
merge_by_key(execution_policy< DerivedPolicy>  &exec, InputIterator1 
# 86
keys_first1, InputIterator1 
# 87
keys_last1, InputIterator2 
# 88
keys_first2, InputIterator2 
# 89
keys_last2, InputIterator3 
# 90
values_first1, InputIterator4 
# 91
values_first2, OutputIterator1 
# 92
keys_result, OutputIterator2 
# 93
values_result, StrictWeakOrdering 
# 94
comp) 
# 95
{ 
# 100
thrust::detail::wrapped_function< StrictWeakOrdering, bool>  wrapped_comp(comp); 
# 102
while ((keys_first1 != keys_last1) && (keys_first2 != keys_last2)) 
# 103
{ 
# 104
if (!wrapped_comp(*keys_first2, *keys_first1)) 
# 105
{ 
# 107
(*keys_result) = (*keys_first1); 
# 108
(*values_result) = (*values_first1); 
# 109
++keys_first1; 
# 110
++values_first1; 
# 111
} else 
# 113
{ 
# 115
(*keys_result) = (*keys_first2); 
# 116
(*values_result) = (*values_first2); 
# 117
++keys_first2; 
# 118
++values_first2; 
# 119
}  
# 121
++keys_result; 
# 122
++values_result; 
# 123
}  
# 125
while (keys_first1 != keys_last1) 
# 126
{ 
# 127
(*keys_result) = (*keys_first1); 
# 128
(*values_result) = (*values_first1); 
# 129
++keys_first1; 
# 130
++values_first1; 
# 131
++keys_result; 
# 132
++values_result; 
# 133
}  
# 135
while (keys_first2 != keys_last2) 
# 136
{ 
# 137
(*keys_result) = (*keys_first2); 
# 138
(*values_result) = (*values_first2); 
# 139
++keys_first2; 
# 140
++values_first2; 
# 141
++keys_result; 
# 142
++values_result; 
# 143
}  
# 145
return thrust::make_pair(keys_result, values_result); 
# 146
} 
# 149
}
# 150
}
# 151
}
# 152
}
# 22 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/merge.h"
namespace thrust { 
# 24
namespace system { 
# 26
namespace cuda { 
# 28
namespace detail { 
# 32
template< class DerivedPolicy, class 
# 33
RandomAccessIterator1, class 
# 34
RandomAccessIterator2, class 
# 35
RandomAccessIterator3, class 
# 36
StrictWeakOrdering> RandomAccessIterator3 
# 32
merge(execution_policy< DerivedPolicy>  & exec, RandomAccessIterator1 first1, RandomAccessIterator1 last1, RandomAccessIterator2 first2, RandomAccessIterator2 last2, RandomAccessIterator3 result, StrictWeakOrdering comp); 
# 47
}
# 48
}
# 49
}
# 50
}
# 27 "/usr/local/cuda-8.0/include/thrust/tabulate.h"
namespace thrust { 
# 75
template< class DerivedPolicy, class ForwardIterator, class UnaryOperation> void tabulate(const detail::execution_policy_base< DerivedPolicy>  & exec, ForwardIterator first, ForwardIterator last, UnaryOperation unary_op); 
# 116
template< class ForwardIterator, class UnaryOperation> void tabulate(ForwardIterator first, ForwardIterator last, UnaryOperation unary_op); 
# 126
}
# 23 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/tabulate.h"
namespace thrust { 
# 25
namespace system { 
# 27
namespace detail { 
# 29
namespace generic { 
# 33
template< class DerivedPolicy, class 
# 34
ForwardIterator, class 
# 35
UnaryOperation> void 
# 33
tabulate(execution_policy< DerivedPolicy>  & exec, ForwardIterator first, ForwardIterator last, UnaryOperation unary_op); 
# 43
}
# 44
}
# 45
}
# 46
}
# 24 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/tabulate.inl"
namespace thrust { 
# 26
namespace system { 
# 28
namespace detail { 
# 30
namespace generic { 
# 34
template< class DerivedPolicy, class 
# 35
ForwardIterator, class 
# 36
UnaryOperation> void 
# 38
tabulate(execution_policy< DerivedPolicy>  &exec, ForwardIterator 
# 39
first, ForwardIterator 
# 40
last, UnaryOperation 
# 41
unary_op) 
# 42
{ 
# 43
typedef typename iterator_difference< ForwardIterator> ::type difference_type; 
# 49
counting_iterator< typename iterator_difference< ForwardIterator> ::type, use_default, use_default, typename iterator_difference< ForwardIterator> ::type>  iter(0); 
# 51
thrust::transform(exec, iter, iter + thrust::distance(first, last), first, unary_op); 
# 52
} 
# 55
}
# 56
}
# 57
}
# 58
}
# 24 "/usr/local/cuda-8.0/include/thrust/detail/tabulate.inl"
namespace thrust { 
# 29
template< class DerivedPolicy, class ForwardIterator, class UnaryOperation> void 
# 31
tabulate(const detail::execution_policy_base< DerivedPolicy>  &exec, ForwardIterator 
# 32
first, ForwardIterator 
# 33
last, UnaryOperation 
# 34
unary_op) 
# 35
{ 
# 36
using system::detail::generic::tabulate;
# 37
return tabulate(detail::derived_cast(detail::strip_const(exec)), first, last, unary_op); 
# 38
} 
# 41
template< class ForwardIterator, class UnaryOperation> void 
# 42
tabulate(ForwardIterator first, ForwardIterator 
# 43
last, UnaryOperation 
# 44
unary_op) 
# 45
{ 
# 46
using thrust::system::detail::generic::select_system;
# 48
typedef typename iterator_system< ForwardIterator> ::type System; 
# 50
System system; 
# 52
return thrust::tabulate(select_system(system), first, last, unary_op); 
# 53
} 
# 56
}
# 28 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/merge.inl"
namespace thrust { 
# 30
namespace system { 
# 32
namespace cuda { 
# 34
namespace detail { 
# 36
namespace merge_detail { 
# 40
template< std::size_t groupsize, std::size_t grainsize, class RandomAccessIterator1, class Size, class RandomAccessIterator2, class RandomAccessIterator3, class RandomAccessIterator4, class Compare> __attribute__((unused)) RandomAccessIterator4 
# 43
staged_merge(bulk_::concurrent_group< bulk_::agent< grainsize> , groupsize>  &exec, RandomAccessIterator1 
# 44
first1, Size n1, RandomAccessIterator2 
# 45
first2, Size n2, RandomAccessIterator3 
# 46
stage, RandomAccessIterator4 
# 47
result, Compare 
# 48
comp) 
# 49
{int volatile ___ = 1;(void)exec;(void)first1;(void)n1;(void)first2;(void)n2;(void)stage;(void)result;(void)comp;
# 64
::exit(___);}
#if 0
# 49
{ 
# 51
bulk_::copy_n(bulk_::bound< groupsize * grainsize> (exec), thrust::detail::make_join_iterator(first1, n1, first2), n1 + n2, stage); 
# 57
bulk_::inplace_merge(bulk_::bound< groupsize * grainsize> (exec), stage, stage + n1, (stage + n1) + n2, comp); 
# 63
return bulk_::copy_n(exec, stage, n1 + n2, result); 
# 64
} 
#endif
# 67 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/merge.inl"
struct merge_kernel { 
# 69
template< std::size_t groupsize, std::size_t grainsize, class RandomAccessIterator1, class Size, class RandomAccessIterator2, class RandomAccessIterator3, class RandomAccessIterator4, class Compare> void 
# 71
operator()(bulk_::concurrent_group< bulk_::agent< grainsize> , groupsize>  &g, RandomAccessIterator1 
# 72
first1, Size n1, RandomAccessIterator2 
# 73
first2, Size n2, RandomAccessIterator3 
# 74
merge_paths_first, RandomAccessIterator4 
# 75
result, Compare 
# 76
comp) 
# 77
{int volatile ___ = 1;(void)g;(void)first1;(void)n1;(void)first2;(void)n2;(void)merge_paths_first;(void)result;(void)comp;
# 125
::exit(___);}
#if 0
# 77
{ 
# 78
typedef int size_type; 
# 80
size_type elements_per_group = (g.size()) * ((g.this_exec).grainsize()); 
# 83
size_type mp0 = merge_paths_first[(g.index())]; 
# 84
size_type mp1 = merge_paths_first[(g.index()) + 1]; 
# 85
size_type diag = elements_per_group * (g.index()); 
# 87
size_type local_size1 = mp1 - mp0; 
# 88
size_type local_size2 = ((thrust::min< int> (n1 + n2, diag + elements_per_group) - mp1) - diag) + mp0; 
# 90
first1 += mp0; 
# 91
first2 += (diag - mp0); 
# 92
result += (elements_per_group * (g.index())); 
# 95
typedef typename iterator_value< RandomAccessIterator1> ::type value_type; 
# 122
__attribute__((unused)) static bulk_::uninitialized_array< typename iterator_value< RandomAccessIterator1> ::type, groupsize * grainsize>  stage; 
# 123
staged_merge(g, first1, local_size1, first2, local_size2, (stage.data()), result, comp); 
# 125
} 
#endif
# 126 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/merge.inl"
}; 
# 129
template< class Size, class RandomAccessIterator1, class RandomAccessIterator2, class Compare> 
# 130
struct locate_merge_path { 
# 132
Size partition_size; 
# 133
RandomAccessIterator1 first1, last1; 
# 134
RandomAccessIterator2 first2, last2; 
# 135
Compare comp; 
# 138
locate_merge_path(Size partition_size, RandomAccessIterator1 first1, RandomAccessIterator1 last1, RandomAccessIterator2 first2, RandomAccessIterator2 last2, Compare comp) : partition_size(partition_size), first1(first1), last1(last1), first2(first2), last2(last2), comp(comp) 
# 143
{ } 
# 145
template< class Index> Size 
# 147
operator()(Index i) 
# 148
{int volatile ___ = 1;(void)i;
# 153
::exit(___);}
#if 0
# 148
{ 
# 149
Size n1 = (last1) - (first1); 
# 150
Size n2 = (last2) - (first2); 
# 151
Size diag = thrust::min< Size> ((partition_size) * i, n1 + n2); 
# 152
return bulk_::merge_path(first1, n1, first2, n2, diag, comp); 
# 153
} 
#endif
# 154 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/merge.inl"
}; 
# 157
template< class DerivedPolicy, class 
# 158
RandomAccessIterator1, class 
# 159
RandomAccessIterator2, class 
# 160
RandomAccessIterator3, class 
# 161
Compare> RandomAccessIterator3 
# 163
merge(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator1 
# 164
first1, RandomAccessIterator1 
# 165
last1, RandomAccessIterator2 
# 166
first2, RandomAccessIterator2 
# 167
last2, RandomAccessIterator3 
# 168
result, Compare 
# 169
comp) 
# 170
{ 
# 171
typedef typename iterator_value< RandomAccessIterator1> ::type value_type; 
# 172
typedef typename iterator_difference< RandomAccessIterator1> ::type difference_type; 
# 173
typedef int size_type; 
# 176
const size_type groupsize = ((sizeof(value_type) == sizeof(int)) ? 256 : (256 + 32)); 
# 177
const size_type grainsize = ((sizeof(value_type) == sizeof(int)) ? 9 : 5); 
# 179
const size_type tile_size = (groupsize * grainsize); 
# 181
difference_type n = (last1 - first1) + (last2 - first2); 
# 182
difference_type num_groups = ((n + tile_size) - 1) / tile_size; 
# 184
thrust::detail::temporary_array< int, DerivedPolicy>  merge_paths(exec, num_groups + 1); 
# 186
thrust::tabulate(exec, (merge_paths.begin()), (merge_paths.end()), locate_merge_path< int, RandomAccessIterator1, RandomAccessIterator2, Compare> (tile_size, first1, last1, first2, last2, comp)); 
# 189
size_type heap_size = (tile_size * sizeof(value_type)); 
# 190
bulk_::concurrent_group< bulk_::agent< grainsize> , groupsize>  g(heap_size); 
# 191
bulk_::async(bulk_::par(stream(thrust::detail::derived_cast(exec)), g, num_groups), merge_kernel(), bulk_::root.this_exec, first1, last1 - first1, first2, last2 - first2, (merge_paths.begin()), result, comp); 
# 193
return result + n; 
# 194
} 
# 197
}
# 200
template< class DerivedPolicy, class 
# 201
RandomAccessIterator1, class 
# 202
RandomAccessIterator2, class 
# 203
RandomAccessIterator3, class 
# 204
Compare> RandomAccessIterator3 
# 206
merge(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator1 
# 207
first1, RandomAccessIterator1 
# 208
last1, RandomAccessIterator2 
# 209
first2, RandomAccessIterator2 
# 210
last2, RandomAccessIterator3 
# 211
result, Compare 
# 212
comp) 
# 213
{ 
# 219
typedef thrust::detail::static_assert_test< sizeof(thrust::detail::STATIC_ASSERTION_FAILURE< (bool)(thrust::detail::depend_on_instantiation< RandomAccessIterator1, true> ::value)> )>  thrust_static_assert_typedef_219 __attribute((unused)); 
# 221
struct workaround { 
# 224
static RandomAccessIterator3 parallel_path(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator1 
# 225
first1, RandomAccessIterator1 
# 226
last1, RandomAccessIterator2 
# 227
first2, RandomAccessIterator2 
# 228
last2, RandomAccessIterator3 
# 229
result, Compare 
# 230
comp) 
# 231
{ 
# 232
return merge_detail::merge(exec, first1, last1, first2, last2, result, comp); 
# 233
} 
# 236
static RandomAccessIterator3 sequential_path(execution_policy< DerivedPolicy>  &, RandomAccessIterator1 
# 237
first1, RandomAccessIterator1 
# 238
last1, RandomAccessIterator2 
# 239
first2, RandomAccessIterator2 
# 240
last2, RandomAccessIterator3 
# 241
result, Compare 
# 242
comp) 
# 243
{ 
# 244
return thrust::merge(thrust::seq, first1, last1, first2, last2, result, comp); 
# 245
} 
# 246
}; 
# 249
return (workaround::parallel_path)(exec, first1, last1, first2, last2, result, comp); 
# 253
} 
# 256
}
# 257
}
# 258
}
# 259
}
# 27 "/usr/local/cuda-8.0/include/thrust/detail/merge.inl"
namespace thrust { 
# 32
template< class DerivedPolicy, class 
# 33
InputIterator1, class 
# 34
InputIterator2, class 
# 35
OutputIterator> OutputIterator 
# 37
merge(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator1 
# 38
first1, InputIterator1 
# 39
last1, InputIterator2 
# 40
first2, InputIterator2 
# 41
last2, OutputIterator 
# 42
result) 
# 43
{ 
# 44
using system::detail::generic::merge;
# 45
return merge(detail::derived_cast(detail::strip_const(exec)), first1, last1, first2, last2, result); 
# 46
} 
# 50
template< class DerivedPolicy, class 
# 51
InputIterator1, class 
# 52
InputIterator2, class 
# 53
OutputIterator, class 
# 54
StrictWeakCompare> OutputIterator 
# 56
merge(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator1 
# 57
first1, InputIterator1 
# 58
last1, InputIterator2 
# 59
first2, InputIterator2 
# 60
last2, OutputIterator 
# 61
result, StrictWeakCompare 
# 62
comp) 
# 63
{ 
# 64
using system::detail::generic::merge;
# 65
return merge(detail::derived_cast(detail::strip_const(exec)), first1, last1, first2, last2, result, comp); 
# 66
} 
# 70
template< class DerivedPolicy, class InputIterator1, class InputIterator2, class InputIterator3, class InputIterator4, class OutputIterator1, class OutputIterator2> pair< OutputIterator1, OutputIterator2>  
# 73
merge_by_key(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator1 
# 74
keys_first1, InputIterator1 keys_last1, InputIterator2 
# 75
keys_first2, InputIterator2 keys_last2, InputIterator3 
# 76
values_first1, InputIterator4 values_first2, OutputIterator1 
# 77
keys_result, OutputIterator2 
# 78
values_result) 
# 79
{ 
# 80
using system::detail::generic::merge_by_key;
# 81
return merge_by_key(detail::derived_cast(detail::strip_const(exec)), keys_first1, keys_last1, keys_first2, keys_last2, values_first1, values_first2, keys_result, values_result); 
# 82
} 
# 86
template< class DerivedPolicy, class InputIterator1, class InputIterator2, class InputIterator3, class InputIterator4, class OutputIterator1, class OutputIterator2, class Compare> pair< OutputIterator1, OutputIterator2>  
# 89
merge_by_key(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator1 
# 90
keys_first1, InputIterator1 keys_last1, InputIterator2 
# 91
keys_first2, InputIterator2 keys_last2, InputIterator3 
# 92
values_first1, InputIterator4 values_first2, OutputIterator1 
# 93
keys_result, OutputIterator2 
# 94
values_result, Compare 
# 95
comp) 
# 96
{ 
# 97
using system::detail::generic::merge_by_key;
# 98
return merge_by_key(detail::derived_cast(detail::strip_const(exec)), keys_first1, keys_last1, keys_first2, keys_last2, values_first1, values_first2, keys_result, values_result, comp); 
# 99
} 
# 102
template< class InputIterator1, class 
# 103
InputIterator2, class 
# 104
OutputIterator, class 
# 105
StrictWeakOrdering> OutputIterator 
# 106
merge(InputIterator1 first1, InputIterator1 
# 107
last1, InputIterator2 
# 108
first2, InputIterator2 
# 109
last2, OutputIterator 
# 110
result, StrictWeakOrdering 
# 111
comp) 
# 112
{ 
# 113
using system::detail::generic::select_system;
# 115
typedef typename iterator_system< InputIterator1> ::type System1; 
# 116
typedef typename iterator_system< InputIterator2> ::type System2; 
# 117
typedef typename iterator_system< OutputIterator> ::type System3; 
# 119
System1 system1; 
# 120
System2 system2; 
# 121
System3 system3; 
# 123
return thrust::merge(select_system(system1, system2, system3), first1, last1, first2, last2, result, comp); 
# 124
} 
# 127
template< class InputIterator1, class 
# 128
InputIterator2, class 
# 129
OutputIterator> OutputIterator 
# 130
merge(InputIterator1 first1, InputIterator1 
# 131
last1, InputIterator2 
# 132
first2, InputIterator2 
# 133
last2, OutputIterator 
# 134
result) 
# 135
{ 
# 136
using system::detail::generic::select_system;
# 138
typedef typename iterator_system< InputIterator1> ::type System1; 
# 139
typedef typename iterator_system< InputIterator2> ::type System2; 
# 140
typedef typename iterator_system< OutputIterator> ::type System3; 
# 142
System1 system1; 
# 143
System2 system2; 
# 144
System3 system3; 
# 146
return thrust::merge(select_system(system1, system2, system3), first1, last1, first2, last2, result); 
# 147
} 
# 150
template< class InputIterator1, class 
# 151
InputIterator2, class 
# 152
InputIterator3, class 
# 153
InputIterator4, class 
# 154
OutputIterator1, class 
# 155
OutputIterator2, class 
# 156
StrictWeakOrdering> pair< OutputIterator1, OutputIterator2>  
# 158
merge_by_key(InputIterator1 keys_first1, InputIterator1 
# 159
keys_last1, InputIterator2 
# 160
keys_first2, InputIterator2 
# 161
keys_last2, InputIterator3 
# 162
values_first1, InputIterator4 
# 163
values_first2, OutputIterator1 
# 164
keys_result, OutputIterator2 
# 165
values_result, StrictWeakOrdering 
# 166
comp) 
# 167
{ 
# 168
using system::detail::generic::select_system;
# 170
typedef typename iterator_system< InputIterator1> ::type System1; 
# 171
typedef typename iterator_system< InputIterator2> ::type System2; 
# 172
typedef typename iterator_system< InputIterator3> ::type System3; 
# 173
typedef typename iterator_system< InputIterator4> ::type System4; 
# 174
typedef typename iterator_system< OutputIterator1> ::type System5; 
# 175
typedef typename iterator_system< OutputIterator2> ::type System6; 
# 177
System1 system1; 
# 178
System2 system2; 
# 179
System3 system3; 
# 180
System4 system4; 
# 181
System5 system5; 
# 182
System6 system6; 
# 184
return thrust::merge_by_key(select_system(system1, system2, system3, system4, system5, system6), keys_first1, keys_last1, keys_first2, keys_last2, values_first1, values_first2, keys_result, values_result, comp); 
# 185
} 
# 188
template< class InputIterator1, class 
# 189
InputIterator2, class 
# 190
InputIterator3, class 
# 191
InputIterator4, class 
# 192
OutputIterator1, class 
# 193
OutputIterator2> pair< OutputIterator1, OutputIterator2>  
# 195
merge_by_key(InputIterator1 keys_first1, InputIterator1 
# 196
keys_last1, InputIterator2 
# 197
keys_first2, InputIterator2 
# 198
keys_last2, InputIterator3 
# 199
values_first1, InputIterator4 
# 200
values_first2, OutputIterator1 
# 201
keys_result, OutputIterator2 
# 202
values_result) 
# 203
{ 
# 204
using system::detail::generic::select_system;
# 206
typedef typename iterator_system< InputIterator1> ::type System1; 
# 207
typedef typename iterator_system< InputIterator2> ::type System2; 
# 208
typedef typename iterator_system< InputIterator3> ::type System3; 
# 209
typedef typename iterator_system< InputIterator4> ::type System4; 
# 210
typedef typename iterator_system< OutputIterator1> ::type System5; 
# 211
typedef typename iterator_system< OutputIterator2> ::type System6; 
# 213
System1 system1; 
# 214
System2 system2; 
# 215
System3 system3; 
# 216
System4 system4; 
# 217
System5 system5; 
# 218
System6 system6; 
# 220
return thrust::merge_by_key(select_system(system1, system2, system3, system4, system5, system6), keys_first1, keys_last1, keys_first2, keys_last2, values_first1, values_first2, keys_result, values_result); 
# 221
} 
# 224
}
# 21 "/usr/local/cuda-8.0/include/thrust/system/detail/sequential/copy_backward.h"
namespace thrust { 
# 23
namespace system { 
# 25
namespace detail { 
# 27
namespace sequential { 
# 32
template< class BidirectionalIterator1, class 
# 33
BidirectionalIterator2> BidirectionalIterator2 
# 35
copy_backward(BidirectionalIterator1 first, BidirectionalIterator1 
# 36
last, BidirectionalIterator2 
# 37
result) 
# 38
{ 
# 39
while (first != last) 
# 40
{ 
# 41
--last; 
# 42
--result; 
# 43
(*result) = (*last); 
# 44
}  
# 46
return result; 
# 47
} 
# 50
}
# 51
}
# 52
}
# 53
}
# 25 "/usr/local/cuda-8.0/include/thrust/system/detail/sequential/insertion_sort.h"
namespace thrust { 
# 27
namespace system { 
# 29
namespace detail { 
# 31
namespace sequential { 
# 36
template< class RandomAccessIterator, class 
# 37
StrictWeakOrdering> void 
# 39
insertion_sort(RandomAccessIterator first, RandomAccessIterator 
# 40
last, StrictWeakOrdering 
# 41
comp) 
# 42
{ 
# 43
typedef typename iterator_value< RandomAccessIterator> ::type value_type; 
# 45
if (first == last) { return; }  
# 51
thrust::detail::wrapped_function< StrictWeakOrdering, bool>  wrapped_comp(comp); 
# 53
for (RandomAccessIterator i = first + 1; i != last; ++i) 
# 54
{ 
# 55
value_type tmp = *i; 
# 57
if (wrapped_comp(tmp, *first)) 
# 58
{ 
# 60
sequential::copy_backward(first, i, i + 1); 
# 62
(*first) = tmp; 
# 63
} else 
# 65
{ 
# 67
RandomAccessIterator j = i; 
# 68
RandomAccessIterator k = i - 1; 
# 70
while (wrapped_comp(tmp, *k)) 
# 71
{ 
# 72
(*j) = (*k); 
# 73
j = k; 
# 74
--k; 
# 75
}  
# 77
(*j) = tmp; 
# 78
}  
# 79
}  
# 80
} 
# 84
template< class RandomAccessIterator1, class 
# 85
RandomAccessIterator2, class 
# 86
StrictWeakOrdering> void 
# 88
insertion_sort_by_key(RandomAccessIterator1 first1, RandomAccessIterator1 
# 89
last1, RandomAccessIterator2 
# 90
first2, StrictWeakOrdering 
# 91
comp) 
# 92
{ 
# 93
typedef typename iterator_value< RandomAccessIterator1> ::type value_type1; 
# 94
typedef typename iterator_value< RandomAccessIterator2> ::type value_type2; 
# 96
if (first1 == last1) { return; }  
# 102
thrust::detail::wrapped_function< StrictWeakOrdering, bool>  wrapped_comp(comp); 
# 104
RandomAccessIterator1 i1 = first1 + 1; 
# 105
RandomAccessIterator2 i2 = first2 + 1; 
# 107
for (; i1 != last1; (++i1), (++i2)) 
# 108
{ 
# 109
value_type1 tmp1 = *i1; 
# 110
value_type2 tmp2 = *i2; 
# 112
if (wrapped_comp(tmp1, *first1)) 
# 113
{ 
# 115
sequential::copy_backward(first1, i1, i1 + 1); 
# 116
sequential::copy_backward(first2, i2, i2 + 1); 
# 118
(*first1) = tmp1; 
# 119
(*first2) = tmp2; 
# 120
} else 
# 122
{ 
# 124
RandomAccessIterator1 j1 = i1; 
# 125
RandomAccessIterator1 k1 = i1 - 1; 
# 127
RandomAccessIterator2 j2 = i2; 
# 128
RandomAccessIterator2 k2 = i2 - 1; 
# 130
while (wrapped_comp(tmp1, *k1)) 
# 131
{ 
# 132
(*j1) = (*k1); 
# 133
(*j2) = (*k2); 
# 135
j1 = k1; 
# 136
j2 = k2; 
# 138
--k1; 
# 139
--k2; 
# 140
}  
# 142
(*j1) = tmp1; 
# 143
(*j2) = tmp2; 
# 144
}  
# 145
}  
# 146
} 
# 149
}
# 150
}
# 151
}
# 152
}
# 24 "/usr/local/cuda-8.0/include/thrust/system/detail/sequential/stable_merge_sort.inl"
namespace thrust { 
# 26
namespace system { 
# 28
namespace detail { 
# 30
namespace sequential { 
# 32
namespace stable_merge_sort_detail { 
# 36
template< class DerivedPolicy, class 
# 37
RandomAccessIterator, class 
# 38
StrictWeakOrdering> void 
# 40
inplace_merge(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator 
# 41
first, RandomAccessIterator 
# 42
middle, RandomAccessIterator 
# 43
last, StrictWeakOrdering 
# 44
comp) 
# 45
{ 
# 46
typedef typename iterator_value< RandomAccessIterator> ::type value_type; 
# 48
thrust::detail::temporary_array< typename iterator_value< RandomAccessIterator> ::type, DerivedPolicy>  a(exec, first, middle); 
# 49
thrust::detail::temporary_array< typename iterator_value< RandomAccessIterator> ::type, DerivedPolicy>  b(exec, middle, last); 
# 51
thrust::merge(exec, (a.begin()), (a.end()), (b.begin()), (b.end()), first, comp); 
# 52
} 
# 55
template< class DerivedPolicy, class 
# 56
RandomAccessIterator1, class 
# 57
RandomAccessIterator2, class 
# 58
StrictWeakOrdering> void 
# 60
inplace_merge_by_key(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator1 
# 61
first1, RandomAccessIterator1 
# 62
middle1, RandomAccessIterator1 
# 63
last1, RandomAccessIterator2 
# 64
first2, StrictWeakOrdering 
# 65
comp) 
# 66
{ 
# 67
typedef typename iterator_value< RandomAccessIterator1> ::type value_type1; 
# 68
typedef typename iterator_value< RandomAccessIterator2> ::type value_type2; 
# 70
RandomAccessIterator2 middle2 = first2 + (middle1 - first1); 
# 71
RandomAccessIterator2 last2 = first2 + (last1 - first1); 
# 73
thrust::detail::temporary_array< typename iterator_value< RandomAccessIterator1> ::type, DerivedPolicy>  lhs1(exec, first1, middle1); 
# 74
thrust::detail::temporary_array< typename iterator_value< RandomAccessIterator1> ::type, DerivedPolicy>  rhs1(exec, middle1, last1); 
# 75
thrust::detail::temporary_array< typename iterator_value< RandomAccessIterator2> ::type, DerivedPolicy>  lhs2(exec, first2, middle2); 
# 76
thrust::detail::temporary_array< typename iterator_value< RandomAccessIterator2> ::type, DerivedPolicy>  rhs2(exec, middle2, last2); 
# 78
thrust::merge_by_key(exec, (lhs1.begin()), (lhs1.end()), (rhs1.begin()), (rhs1.end()), (lhs2.begin()), (rhs2.begin()), first1, first2, comp); 
# 84
} 
# 87
template< class RandomAccessIterator, class 
# 88
Size, class 
# 89
StrictWeakOrdering> void 
# 91
insertion_sort_each(RandomAccessIterator first, RandomAccessIterator 
# 92
last, Size 
# 93
partition_size, StrictWeakOrdering 
# 94
comp) 
# 95
{ 
# 96
if (partition_size > 1) 
# 97
{ 
# 98
for (; first < last; first += partition_size) 
# 99
{ 
# 100
RandomAccessIterator partition_last = thrust::min(last, first + partition_size); 
# 102
sequential::insertion_sort(first, partition_last, comp); 
# 103
}  
# 104
}  
# 105
} 
# 108
template< class RandomAccessIterator1, class 
# 109
RandomAccessIterator2, class 
# 110
Size, class 
# 111
StrictWeakOrdering> void 
# 113
insertion_sort_each_by_key(RandomAccessIterator1 keys_first, RandomAccessIterator1 
# 114
keys_last, RandomAccessIterator2 
# 115
values_first, Size 
# 116
partition_size, StrictWeakOrdering 
# 117
comp) 
# 118
{ 
# 119
if (partition_size > 1) 
# 120
{ 
# 121
for (; keys_first < keys_last; (keys_first += partition_size), (values_first += partition_size)) 
# 122
{ 
# 123
RandomAccessIterator1 keys_partition_last = thrust::min(keys_last, keys_first + partition_size); 
# 125
sequential::insertion_sort_by_key(keys_first, keys_partition_last, values_first, comp); 
# 126
}  
# 127
}  
# 128
} 
# 131
template< class DerivedPolicy, class 
# 132
RandomAccessIterator1, class 
# 133
Size, class 
# 134
RandomAccessIterator2, class 
# 135
StrictWeakOrdering> void 
# 137
merge_adjacent_partitions(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator1 
# 138
first, RandomAccessIterator1 
# 139
last, Size 
# 140
partition_size, RandomAccessIterator2 
# 141
result, StrictWeakOrdering 
# 142
comp) 
# 143
{ 
# 144
for (; first < last; (first += (2 * partition_size)), (result += (2 * partition_size))) 
# 145
{ 
# 146
RandomAccessIterator1 interval_middle = thrust::min(last, first + partition_size); 
# 147
RandomAccessIterator1 interval_last = thrust::min(last, interval_middle + partition_size); 
# 149
thrust::merge(exec, first, interval_middle, interval_middle, interval_last, result, comp); 
# 154
}  
# 155
} 
# 158
template< class DerivedPolicy, class 
# 159
RandomAccessIterator1, class 
# 160
RandomAccessIterator2, class 
# 161
Size, class 
# 162
RandomAccessIterator3, class 
# 163
RandomAccessIterator4, class 
# 164
StrictWeakOrdering> void 
# 166
merge_adjacent_partitions_by_key(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator1 
# 167
keys_first, RandomAccessIterator1 
# 168
keys_last, RandomAccessIterator2 
# 169
values_first, Size 
# 170
partition_size, RandomAccessIterator3 
# 171
keys_result, RandomAccessIterator4 
# 172
values_result, StrictWeakOrdering 
# 173
comp) 
# 174
{ 
# 175
Size stride = 2 * partition_size; 
# 177
for (; keys_first < keys_last; (((keys_first += stride), (values_first += stride)), (keys_result += stride)), (values_result += stride)) 
# 180
{ 
# 181
RandomAccessIterator1 keys_interval_middle = thrust::min(keys_last, keys_first + partition_size); 
# 182
RandomAccessIterator1 keys_interval_last = thrust::min(keys_last, keys_interval_middle + partition_size); 
# 184
RandomAccessIterator2 values_first2 = values_first + (keys_interval_middle - keys_first); 
# 186
thrust::merge_by_key(exec, keys_first, keys_interval_middle, keys_interval_middle, keys_interval_last, values_first, values_first2, keys_result, values_result, comp); 
# 194
}  
# 195
} 
# 198
template< class DerivedPolicy, class 
# 199
RandomAccessIterator, class 
# 200
StrictWeakOrdering> void 
# 202
iterative_stable_merge_sort(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator 
# 203
first, RandomAccessIterator 
# 204
last, StrictWeakOrdering 
# 205
comp) 
# 206
{ 
# 207
typedef typename iterator_value< RandomAccessIterator> ::type value_type; 
# 208
typedef typename iterator_difference< RandomAccessIterator> ::type difference_type; 
# 210
difference_type n = last - first; 
# 212
thrust::detail::temporary_array< typename iterator_value< RandomAccessIterator> ::type, DerivedPolicy>  temp(exec, n); 
# 215
difference_type partition_size = (32); 
# 216
insertion_sort_each(first, last, partition_size, comp); 
# 219
bool ping = true; 
# 222
for (; partition_size < n; (partition_size *= 2), (ping = (!ping))) 
# 225
{ 
# 226
if (ping) 
# 227
{ 
# 228
merge_adjacent_partitions(exec, first, last, partition_size, (temp.begin()), comp); 
# 229
} else 
# 231
{ 
# 232
merge_adjacent_partitions(exec, (temp.begin()), (temp.end()), partition_size, first, comp); 
# 233
}  
# 234
}  
# 236
if (!ping) 
# 237
{ 
# 238
thrust::copy(exec, (temp.begin()), (temp.end()), first); 
# 239
}  
# 240
} 
# 243
template< class DerivedPolicy, class 
# 244
RandomAccessIterator1, class 
# 245
RandomAccessIterator2, class 
# 246
StrictWeakOrdering> void 
# 248
iterative_stable_merge_sort_by_key(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator1 
# 249
keys_first, RandomAccessIterator1 
# 250
keys_last, RandomAccessIterator2 
# 251
values_first, StrictWeakOrdering 
# 252
comp) 
# 253
{ 
# 254
typedef typename iterator_value< RandomAccessIterator1> ::type value_type1; 
# 255
typedef typename iterator_value< RandomAccessIterator2> ::type value_type2; 
# 256
typedef typename iterator_difference< RandomAccessIterator1> ::type difference_type; 
# 258
difference_type n = keys_last - keys_first; 
# 260
thrust::detail::temporary_array< typename iterator_value< RandomAccessIterator1> ::type, DerivedPolicy>  keys_temp(exec, n); 
# 261
thrust::detail::temporary_array< typename iterator_value< RandomAccessIterator2> ::type, DerivedPolicy>  values_temp(exec, n); 
# 264
difference_type partition_size = (32); 
# 265
insertion_sort_each_by_key(keys_first, keys_last, values_first, partition_size, comp); 
# 268
bool ping = true; 
# 271
for (; partition_size < n; (partition_size *= 2), (ping = (!ping))) 
# 274
{ 
# 275
if (ping) 
# 276
{ 
# 277
merge_adjacent_partitions_by_key(exec, keys_first, keys_last, values_first, partition_size, (keys_temp.begin()), (values_temp.begin()), comp); 
# 278
} else 
# 280
{ 
# 281
merge_adjacent_partitions_by_key(exec, (keys_temp.begin()), (keys_temp.end()), (values_temp.begin()), partition_size, keys_first, values_first, comp); 
# 282
}  
# 283
}  
# 285
if (!ping) 
# 286
{ 
# 287
thrust::copy(exec, (keys_temp.begin()), (keys_temp.end()), keys_first); 
# 288
thrust::copy(exec, (values_temp.begin()), (values_temp.end()), values_first); 
# 289
}  
# 290
} 
# 293
template< class DerivedPolicy, class 
# 294
RandomAccessIterator, class 
# 295
StrictWeakOrdering> void 
# 297
recursive_stable_merge_sort(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator 
# 298
first, RandomAccessIterator 
# 299
last, StrictWeakOrdering 
# 300
comp) 
# 301
{ 
# 302
if ((last - first) <= 32) 
# 303
{ 
# 304
sequential::insertion_sort(first, last, comp); 
# 305
} else 
# 307
{ 
# 308
RandomAccessIterator middle = first + ((last - first) / 2); 
# 310
stable_merge_sort_detail::recursive_stable_merge_sort(exec, first, middle, comp); 
# 311
stable_merge_sort_detail::recursive_stable_merge_sort(exec, middle, last, comp); 
# 312
stable_merge_sort_detail::inplace_merge(exec, first, middle, last, comp); 
# 313
}  
# 314
} 
# 317
template< class DerivedPolicy, class 
# 318
RandomAccessIterator1, class 
# 319
RandomAccessIterator2, class 
# 320
StrictWeakOrdering> void 
# 322
recursive_stable_merge_sort_by_key(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator1 
# 323
first1, RandomAccessIterator1 
# 324
last1, RandomAccessIterator2 
# 325
first2, StrictWeakOrdering 
# 326
comp) 
# 327
{ 
# 328
if ((last1 - first1) <= 32) 
# 329
{ 
# 330
sequential::insertion_sort_by_key(first1, last1, first2, comp); 
# 331
} else 
# 333
{ 
# 334
RandomAccessIterator1 middle1 = first1 + ((last1 - first1) / 2); 
# 335
RandomAccessIterator2 middle2 = first2 + ((last1 - first1) / 2); 
# 337
stable_merge_sort_detail::recursive_stable_merge_sort_by_key(exec, first1, middle1, first2, comp); 
# 338
stable_merge_sort_detail::recursive_stable_merge_sort_by_key(exec, middle1, last1, middle2, comp); 
# 339
stable_merge_sort_detail::inplace_merge_by_key(exec, first1, middle1, last1, first2, comp); 
# 340
}  
# 341
} 
# 344
}
# 347
template< class DerivedPolicy, class 
# 348
RandomAccessIterator, class 
# 349
StrictWeakOrdering> void 
# 351
stable_merge_sort(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator 
# 352
first, RandomAccessIterator 
# 353
last, StrictWeakOrdering 
# 354
comp) 
# 355
{ 
# 360
stable_merge_sort_detail::recursive_stable_merge_sort(exec, first, last, comp); 
# 362
} 
# 365
template< class DerivedPolicy, class 
# 366
RandomAccessIterator1, class 
# 367
RandomAccessIterator2, class 
# 368
StrictWeakOrdering> void 
# 370
stable_merge_sort_by_key(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator1 
# 371
first1, RandomAccessIterator1 
# 372
last1, RandomAccessIterator2 
# 373
first2, StrictWeakOrdering 
# 374
comp) 
# 375
{ 
# 380
stable_merge_sort_detail::recursive_stable_merge_sort_by_key(exec, first1, last1, first2, comp); 
# 382
} 
# 385
}
# 386
}
# 387
}
# 388
}
# 22 "/usr/local/cuda-8.0/include/thrust/system/detail/sequential/stable_primitive_sort.h"
namespace thrust { 
# 24
namespace system { 
# 26
namespace detail { 
# 28
namespace sequential { 
# 32
template< class DerivedPolicy, class 
# 33
RandomAccessIterator> void 
# 32
stable_primitive_sort(execution_policy< DerivedPolicy>  & exec, RandomAccessIterator first, RandomAccessIterator last); 
# 40
template< class DerivedPolicy, class 
# 41
RandomAccessIterator1, class 
# 42
RandomAccessIterator2> void 
# 40
stable_primitive_sort_by_key(execution_policy< DerivedPolicy>  & exec, RandomAccessIterator1 keys_first, RandomAccessIterator1 keys_last, RandomAccessIterator2 values_first); 
# 50
}
# 51
}
# 52
}
# 53
}
# 22 "/usr/local/cuda-8.0/include/thrust/system/detail/sequential/stable_radix_sort.h"
namespace thrust { 
# 24
namespace system { 
# 26
namespace detail { 
# 28
namespace sequential { 
# 32
template< class DerivedPolicy, class 
# 33
RandomAccessIterator> void 
# 32
stable_radix_sort(execution_policy< DerivedPolicy>  & exec, RandomAccessIterator begin, RandomAccessIterator end); 
# 40
template< class DerivedPolicy, class 
# 41
RandomAccessIterator1, class 
# 42
RandomAccessIterator2> void 
# 40
stable_radix_sort_by_key(execution_policy< DerivedPolicy>  & exec, RandomAccessIterator1 keys_begin, RandomAccessIterator1 keys_end, RandomAccessIterator2 values_begin); 
# 50
}
# 51
}
# 52
}
# 53
}
# 27 "/usr/local/cuda-8.0/include/thrust/copy.h"
namespace thrust { 
# 83
template< class DerivedPolicy, class InputIterator, class OutputIterator> OutputIterator copy(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator first, InputIterator last, OutputIterator result); 
# 136
template< class DerivedPolicy, class InputIterator, class Size, class OutputIterator> OutputIterator copy_n(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator first, Size n, OutputIterator result); 
# 185
template< class InputIterator, class OutputIterator> OutputIterator copy(InputIterator first, InputIterator last, OutputIterator result); 
# 230
template< class InputIterator, class Size, class OutputIterator> OutputIterator copy_n(InputIterator first, Size n, OutputIterator result); 
# 299
template< class DerivedPolicy, class InputIterator, class OutputIterator, class Predicate> OutputIterator copy_if(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator first, InputIterator last, OutputIterator result, Predicate pred); 
# 360
template< class InputIterator, class 
# 361
OutputIterator, class 
# 362
Predicate> OutputIterator 
# 360
copy_if(InputIterator first, InputIterator last, OutputIterator result, Predicate pred); 
# 430
template< class DerivedPolicy, class InputIterator1, class InputIterator2, class OutputIterator, class Predicate> OutputIterator copy_if(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator1 first, InputIterator1 last, InputIterator2 stencil, OutputIterator result, Predicate pred); 
# 496
template< class InputIterator1, class 
# 497
InputIterator2, class 
# 498
OutputIterator, class 
# 499
Predicate> OutputIterator 
# 496
copy_if(InputIterator1 first, InputIterator1 last, InputIterator2 stencil, OutputIterator result, Predicate pred); 
# 509
}
# 22 "/usr/local/cuda-8.0/include/thrust/detail/copy_if.h"
namespace thrust { 
# 26
template< class DerivedPolicy, class 
# 27
InputIterator, class 
# 28
OutputIterator, class 
# 29
Predicate> OutputIterator 
# 26
copy_if(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator first, InputIterator last, OutputIterator result, Predicate pred); 
# 38
template< class DerivedPolicy, class 
# 39
InputIterator1, class 
# 40
InputIterator2, class 
# 41
OutputIterator, class 
# 42
Predicate> OutputIterator 
# 38
copy_if(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator1 first, InputIterator1 last, InputIterator2 stencil, OutputIterator result, Predicate pred); 
# 52
template< class InputIterator, class 
# 53
OutputIterator, class 
# 54
Predicate> OutputIterator 
# 52
copy_if(InputIterator first, InputIterator last, OutputIterator result, Predicate pred); 
# 61
template< class InputIterator1, class 
# 62
InputIterator2, class 
# 63
OutputIterator, class 
# 64
Predicate> OutputIterator 
# 61
copy_if(InputIterator1 first, InputIterator1 last, InputIterator2 stencil, OutputIterator result, Predicate pred); 
# 72
}
# 22 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/copy_if.h"
namespace thrust { 
# 24
namespace system { 
# 26
namespace detail { 
# 28
namespace generic { 
# 32
template< class DerivedPolicy, class 
# 33
InputIterator, class 
# 34
OutputIterator, class 
# 35
Predicate> OutputIterator 
# 32
copy_if(execution_policy< DerivedPolicy>  & exec, InputIterator first, InputIterator last, OutputIterator result, Predicate pred); 
# 44
template< class DerivedPolicy, class 
# 45
InputIterator1, class 
# 46
InputIterator2, class 
# 47
OutputIterator, class 
# 48
Predicate> OutputIterator 
# 44
copy_if(execution_policy< DerivedPolicy>  & exec, InputIterator1 first, InputIterator1 last, InputIterator2 stencil, OutputIterator result, Predicate pred); 
# 58
}
# 59
}
# 60
}
# 61
}
# 35 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/copy_if.inl"
namespace thrust { 
# 37
namespace system { 
# 39
namespace detail { 
# 41
namespace generic { 
# 43
namespace detail { 
# 47
template< class IndexType, class 
# 48
DerivedPolicy, class 
# 49
InputIterator1, class 
# 50
InputIterator2, class 
# 51
OutputIterator, class 
# 52
Predicate> OutputIterator 
# 54
copy_if(execution_policy< DerivedPolicy>  &exec, InputIterator1 
# 55
first, InputIterator1 
# 56
last, InputIterator2 
# 57
stencil, OutputIterator 
# 58
result, Predicate 
# 59
pred) 
# 60
{ 
# 61
IndexType n = thrust::distance(first, last); ; 
# 64
thrust::detail::temporary_array< IndexType, DerivedPolicy>  predicates(exec, n); 
# 65
thrust::transform(exec, stencil, stencil + n, (predicates.begin()), ((thrust::detail::predicate_to_integral< Predicate, IndexType> )(pred))); 
# 72
thrust::detail::temporary_array< IndexType, DerivedPolicy>  scatter_indices(exec, n); 
# 73
thrust::exclusive_scan(exec, (predicates.begin()), (predicates.end()), (scatter_indices.begin()), static_cast< IndexType>(0), plus< IndexType> ()); 
# 81
thrust::scatter_if(exec, first, last, (scatter_indices.begin()), (predicates.begin()), result, identity< IndexType> ()); 
# 90
IndexType output_size = (scatter_indices[n - 1]) + (predicates[n - 1]); 
# 92
return result + output_size; 
# 93
} 
# 96
}
# 99
template< class DerivedPolicy, class 
# 100
InputIterator, class 
# 101
OutputIterator, class 
# 102
Predicate> OutputIterator 
# 104
copy_if(execution_policy< DerivedPolicy>  &exec, InputIterator 
# 105
first, InputIterator 
# 106
last, OutputIterator 
# 107
result, Predicate 
# 108
pred) 
# 109
{ 
# 114
return thrust::copy_if(exec, first, last, first, result, pred); 
# 115
} 
# 118
template< class DerivedPolicy, class 
# 119
InputIterator1, class 
# 120
InputIterator2, class 
# 121
OutputIterator, class 
# 122
Predicate> OutputIterator 
# 124
copy_if(execution_policy< DerivedPolicy>  &exec, InputIterator1 
# 125
first, InputIterator1 
# 126
last, InputIterator2 
# 127
stencil, OutputIterator 
# 128
result, Predicate 
# 129
pred) 
# 130
{ 
# 131
typedef typename iterator_traits< InputIterator1> ::difference_type difference_type; 
# 134
if (first == last) { 
# 135
return result; }  
# 137
difference_type n = thrust::distance(first, last); 
# 141
typename thrust::detail::make_unsigned< typename iterator_traits< InputIterator1> ::difference_type> ::type unsigned_n(n); 
# 144
if ((sizeof(difference_type) > sizeof(unsigned)) && (unsigned_n > thrust::detail::integer_traits< unsigned> ::const_max)) 
# 145
{ 
# 146
result = detail::copy_if< typename iterator_traits< InputIterator1> ::difference_type> (exec, first, last, stencil, result, pred); 
# 147
} else 
# 149
{ 
# 150
result = detail::copy_if< unsigned> (exec, first, last, stencil, result, pred); 
# 151
}  
# 153
return result; 
# 154
} 
# 157
}
# 158
}
# 159
}
# 160
}
# 27 "/usr/local/cuda-8.0/include/thrust/system/detail/sequential/copy_if.h"
namespace thrust { 
# 29
namespace system { 
# 31
namespace detail { 
# 33
namespace sequential { 
# 38
template< class DerivedPolicy, class 
# 39
InputIterator1, class 
# 40
InputIterator2, class 
# 41
OutputIterator, class 
# 42
Predicate> OutputIterator 
# 44
copy_if(execution_policy< DerivedPolicy>  &, InputIterator1 
# 45
first, InputIterator1 
# 46
last, InputIterator2 
# 47
stencil, OutputIterator 
# 48
result, Predicate 
# 49
pred) 
# 50
{ 
# 51
thrust::detail::wrapped_function< Predicate, bool>  wrapped_pred(pred); 
# 53
while (first != last) 
# 54
{ 
# 55
if (wrapped_pred(*stencil)) 
# 56
{ 
# 57
(*result) = (*first); 
# 58
++result; 
# 59
}  
# 61
++first; 
# 62
++stencil; 
# 63
}  
# 65
return result; 
# 66
} 
# 69
}
# 70
}
# 71
}
# 72
}
# 22 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/copy_if.h"
namespace thrust { 
# 24
namespace system { 
# 26
namespace cuda { 
# 28
namespace detail { 
# 32
template< class DerivedPolicy, class 
# 33
InputIterator1, class 
# 34
InputIterator2, class 
# 35
OutputIterator, class 
# 36
Predicate> OutputIterator 
# 32
copy_if(execution_policy< DerivedPolicy>  & exec, InputIterator1 first, InputIterator1 last, InputIterator2 stencil, OutputIterator result, Predicate pred); 
# 46
}
# 47
}
# 48
}
# 49
}
# 21 "/usr/local/cuda-8.0/include/thrust/system/detail/internal/decompose.h"
namespace thrust { 
# 23
namespace system { 
# 25
namespace detail { 
# 27
namespace internal { 
# 30
template< class IndexType> 
# 31
class index_range { 
# 34
public: typedef IndexType index_type; 
# 37
index_range(index_type begin, index_type end) : m_begin(begin), m_end(end) { } 
# 40
index_type begin() const { return m_begin; } 
# 43
index_type end() const { return m_end; } 
# 46
index_type size() const { return (m_end) - (m_begin); } 
# 49
private: index_type m_begin; 
# 50
index_type m_end; 
# 51
}; 
# 53
template< class IndexType> 
# 54
class uniform_decomposition { 
# 57
public: typedef IndexType index_type; 
# 58
typedef index_range< IndexType>  range_type; 
# 61
uniform_decomposition(index_type N, index_type granularity, index_type max_intervals) : m_N(N), m_intervals(((N + granularity) - 1) / granularity), m_threshold(0), m_small_interval(granularity), m_large_interval(0) 
# 67
{ 
# 68
if ((m_intervals) > max_intervals) 
# 69
{ 
# 70
(m_small_interval) = (granularity * ((m_intervals) / max_intervals)); 
# 71
(m_large_interval) = ((m_small_interval) + granularity); 
# 72
(m_threshold) = ((m_intervals) % max_intervals); 
# 73
(m_intervals) = max_intervals; 
# 74
}  
# 75
} 
# 78
index_range< IndexType>  operator[](const index_type &i) const 
# 79
{ 
# 80
if (i < (m_threshold)) 
# 81
{ 
# 82
index_type begin = (m_large_interval) * i; 
# 83
index_type end = begin + (m_large_interval); 
# 84
return range_type(begin, end); 
# 85
} else 
# 87
{ 
# 88
index_type begin = ((m_large_interval) * (m_threshold)) + ((m_small_interval) * (i - (m_threshold))); 
# 89
index_type end = ((begin + (m_small_interval)) < (m_N)) ? begin + (m_small_interval) : (m_N); 
# 90
return range_type(begin, end); 
# 91
}  
# 92
} 
# 95
index_type size() const 
# 96
{ 
# 97
return m_intervals; 
# 98
} 
# 102
private: index_type m_N; 
# 103
index_type m_intervals; 
# 104
index_type m_threshold; 
# 105
index_type m_small_interval; 
# 106
index_type m_large_interval; 
# 107
}; 
# 110
}
# 111
}
# 112
}
# 113
}
# 27 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/default_decomposition.h"
namespace thrust { 
# 29
namespace system { 
# 31
namespace cuda { 
# 33
namespace detail { 
# 37
template< class IndexType> system::detail::internal::uniform_decomposition< IndexType>  default_decomposition(IndexType n); 
# 42
}
# 43
}
# 44
}
# 45
}
# 22 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cuda_launch_config.h"
namespace thrust { 
# 24
namespace system { 
# 26
namespace cuda { 
# 28
namespace detail { 
# 34
struct device_properties_t { 
# 38
int major; 
# 39
int maxGridSize[3]; 
# 40
int maxThreadsPerBlock; 
# 41
int maxThreadsPerMultiProcessor; 
# 42
int minor; 
# 43
int multiProcessorCount; 
# 44
int regsPerBlock; 
# 45
size_t sharedMemPerBlock; 
# 46
int warpSize; 
# 47
}; 
# 52
struct function_attributes_t { 
# 56
size_t constSizeBytes; 
# 57
size_t localSizeBytes; 
# 58
int maxThreadsPerBlock; 
# 59
int numRegs; 
# 60
int ptxVersion; 
# 61
size_t sharedSizeBytes; 
# 62
}; 
# 74
inline std::size_t block_size_with_maximum_potential_occupancy(const function_attributes_t & attributes, const device_properties_t & properties); 
# 88
template< class UnaryFunction> inline std::size_t block_size_with_maximum_potential_occupancy(const function_attributes_t & attributes, const device_properties_t & properties, UnaryFunction block_size_to_dynamic_smem_size); 
# 103
inline size_t proportional_smem_allocation(const device_properties_t & properties, const function_attributes_t & attributes, size_t blocks_per_processor); 
# 108
template< class UnaryFunction> inline size_t max_blocksize_subject_to_smem_usage(const device_properties_t & properties, const function_attributes_t & attributes, UnaryFunction blocksize_to_dynamic_smem_usage); 
# 116
namespace cuda_launch_config_detail { 
# 119
using std::size_t;
# 121
namespace util { 
# 125
template< class T> inline T 
# 127
min_(const T &lhs, const T &rhs) 
# 128
{ 
# 129
return (rhs < lhs) ? rhs : lhs; 
# 130
} 
# 133
template< class T> 
# 134
struct zero_function { 
# 137
T operator()(T) 
# 138
{ 
# 139
return 0; 
# 140
} 
# 141
}; 
# 145
template< class L, class R> inline L 
# 146
divide_ri(const L x, const R y) 
# 147
{ 
# 148
return (x + (y - 1)) / y; 
# 149
} 
# 152
template< class L, class R> inline L 
# 153
divide_rz(const L x, const R y) 
# 154
{ 
# 155
return x / y; 
# 156
} 
# 159
template< class L, class R> inline L 
# 160
round_i(const L x, const R y) { return y * divide_ri(x, y); } 
# 163
template< class L, class R> inline L 
# 164
round_z(const L x, const R y) { return y * divide_rz(x, y); } 
# 166
}
# 172
inline std::size_t smem_allocation_unit(const device_properties_t &properties) 
# 173
{ 
# 174
switch (properties.major) 
# 175
{ 
# 176
case 1:  return 512; 
# 177
case 2:  return 128; 
# 178
case 3:  return 256; 
# 179
default:  return 256; 
# 180
}  
# 181
} 
# 186
inline int reg_allocation_unit(const device_properties_t &properties, const std::size_t regsPerThread) 
# 187
{ 
# 188
switch (properties.major) 
# 189
{ 
# 190
case 1:  return ((properties.minor) <= 1) ? 256 : 512; 
# 191
case 2:  switch (regsPerThread) 
# 192
{ 
# 193
case 21:  
# 194
case 22:  
# 195
case 29:  
# 196
case 30:  
# 197
case 37:  
# 198
case 38:  
# 199
case 45:  
# 200
case 46:  
# 201
return 128; 
# 202
default:  
# 203
return 64; 
# 204
}  
# 205
case 3:  return 256; 
# 206
default:  return 256; 
# 207
}  
# 208
} 
# 213
inline std::size_t warp_allocation_multiple(const device_properties_t &properties) 
# 214
{ 
# 215
return ((properties.major) <= 1) ? 2 : 1; 
# 216
} 
# 220
inline std::size_t num_sides_per_multiprocessor(const device_properties_t &properties) 
# 221
{ 
# 222
switch (properties.major) 
# 223
{ 
# 224
case 1:  return 1; 
# 225
case 2:  return 2; 
# 226
case 3:  return 4; 
# 227
default:  return 4; 
# 228
}  
# 229
} 
# 233
inline std::size_t max_blocks_per_multiprocessor(const device_properties_t &properties) 
# 234
{ 
# 235
return ((properties.major) <= 2) ? 8 : 16; 
# 236
} 
# 240
inline std::size_t max_active_blocks_per_multiprocessor(const device_properties_t &properties, const function_attributes_t &
# 241
attributes, std::size_t 
# 242
CTA_SIZE, std::size_t 
# 243
dynamic_smem_bytes) 
# 244
{ 
# 251
const std::size_t maxThreadsPerSM = properties.maxThreadsPerMultiProcessor; 
# 252
const std::size_t maxBlocksPerSM = max_blocks_per_multiprocessor(properties); 
# 255
const std::size_t ctaLimitThreads = (CTA_SIZE <= ((std::size_t)(properties.maxThreadsPerBlock))) ? maxThreadsPerSM / CTA_SIZE : (0); 
# 256
const std::size_t ctaLimitBlocks = maxBlocksPerSM; 
# 261
const std::size_t smemAllocationUnit = smem_allocation_unit(properties); 
# 262
const std::size_t smemBytes = (attributes.sharedSizeBytes) + dynamic_smem_bytes; 
# 263
const std::size_t smemPerCTA = util::round_i(smemBytes, smemAllocationUnit); 
# 266
const std::size_t ctaLimitSMem = (smemPerCTA > (0)) ? (properties.sharedMemPerBlock) / smemPerCTA : maxBlocksPerSM; 
# 271
const int regAllocationUnit = reg_allocation_unit(properties, attributes.numRegs); 
# 272
const std::size_t warpAllocationMultiple = warp_allocation_multiple(properties); 
# 273
const std::size_t numWarps = util::round_i(util::divide_ri(CTA_SIZE, properties.warpSize), warpAllocationMultiple); 
# 276
std::size_t ctaLimitRegs; 
# 277
if ((properties.major) <= 1) 
# 278
{ 
# 281
const std::size_t regsPerCTA = util::round_i(((attributes.numRegs) * (properties.warpSize)) * numWarps, regAllocationUnit); 
# 282
ctaLimitRegs = ((regsPerCTA > (0)) ? (properties.regsPerBlock) / regsPerCTA : maxBlocksPerSM); 
# 283
} else 
# 285
{ 
# 288
const std::size_t regsPerWarp = util::round_i((attributes.numRegs) * (properties.warpSize), regAllocationUnit); 
# 289
const std::size_t numSides = num_sides_per_multiprocessor(properties); 
# 290
const std::size_t numRegsPerSide = (properties.regsPerBlock) / numSides; 
# 291
ctaLimitRegs = ((regsPerWarp > (0)) ? ((numRegsPerSide / regsPerWarp) * numSides) / numWarps : maxBlocksPerSM); 
# 292
}  
# 297
return util::min_(ctaLimitRegs, util::min_(ctaLimitSMem, util::min_(ctaLimitThreads, ctaLimitBlocks))); 
# 298
} 
# 301
}
# 304
template< class UnaryFunction> inline std::size_t 
# 306
block_size_with_maximum_potential_occupancy(const function_attributes_t &attributes, const device_properties_t &
# 307
properties, UnaryFunction 
# 308
block_size_to_dynamic_smem_size) 
# 309
{ 
# 310
size_t max_occupancy = properties.maxThreadsPerMultiProcessor; 
# 311
size_t largest_blocksize = cuda_launch_config_detail::util::min_(properties.maxThreadsPerBlock, attributes.maxThreadsPerBlock); 
# 312
size_t granularity = properties.warpSize; 
# 313
size_t max_blocksize = (0); 
# 314
size_t highest_occupancy = (0); 
# 316
for (size_t blocksize = largest_blocksize; blocksize != (0); blocksize -= granularity) 
# 317
{ 
# 318
size_t occupancy = blocksize * cuda_launch_config_detail::max_active_blocks_per_multiprocessor(properties, attributes, blocksize, block_size_to_dynamic_smem_size(blocksize)); 
# 320
if (occupancy > highest_occupancy) 
# 321
{ 
# 322
max_blocksize = blocksize; 
# 323
highest_occupancy = occupancy; 
# 324
}  
# 327
if (highest_occupancy == max_occupancy) { 
# 328
break; }  
# 329
}  
# 331
return max_blocksize; 
# 332
} 
# 336
inline std::size_t block_size_with_maximum_potential_occupancy(const function_attributes_t &attributes, const device_properties_t &
# 337
properties) 
# 338
{ 
# 339
return block_size_with_maximum_potential_occupancy(attributes, properties, cuda_launch_config_detail::util::zero_function< unsigned long> ()); 
# 340
} 
# 344
inline size_t proportional_smem_allocation(const device_properties_t &properties, const function_attributes_t &
# 345
attributes, size_t 
# 346
blocks_per_processor) 
# 347
{ 
# 348
size_t smem_per_processor = properties.sharedMemPerBlock; 
# 349
size_t smem_allocation_unit = cuda_launch_config_detail::smem_allocation_unit(properties); 
# 351
size_t total_smem_per_block = cuda_launch_config_detail::util::round_z(smem_per_processor / blocks_per_processor, smem_allocation_unit); 
# 352
size_t static_smem_per_block = attributes.sharedSizeBytes; 
# 354
return total_smem_per_block - static_smem_per_block; 
# 355
} 
# 358
template< class UnaryFunction> inline size_t 
# 360
max_blocksize_subject_to_smem_usage(const device_properties_t &properties, const function_attributes_t &
# 361
attributes, UnaryFunction 
# 362
blocksize_to_dynamic_smem_usage) 
# 363
{ 
# 364
size_t largest_blocksize = (thrust::min)(properties.maxThreadsPerBlock, attributes.maxThreadsPerBlock); 
# 365
size_t granularity = properties.warpSize; 
# 367
for (int blocksize = largest_blocksize; blocksize > 0; blocksize -= granularity) 
# 368
{ 
# 369
size_t total_smem_usage = blocksize_to_dynamic_smem_usage(blocksize) + (attributes.sharedSizeBytes); 
# 371
if (total_smem_usage <= (properties.sharedMemPerBlock)) 
# 372
{ 
# 373
return blocksize; 
# 374
}  
# 375
}  
# 377
return 0; 
# 378
} 
# 381
}
# 382
}
# 383
}
# 384
}
# 34 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/runtime_introspection.h"
namespace thrust { 
# 36
namespace system { 
# 38
namespace cuda { 
# 40
namespace detail { 
# 47
inline int current_device(); 
# 54
inline device_properties_t device_properties(int device_id); 
# 61
inline device_properties_t device_properties(); 
# 67
template< class KernelFunction> inline function_attributes_t function_attributes(KernelFunction kernel); 
# 77
inline size_t compute_capability(const device_properties_t & properties); 
# 85
inline size_t compute_capability(); 
# 88
}
# 89
}
# 90
}
# 91
}
# 26 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/runtime_introspection.inl"
namespace thrust { 
# 28
namespace system { 
# 30
namespace cuda { 
# 32
namespace detail { 
# 34
namespace runtime_introspection_detail { 
# 39
inline void uncached_device_properties(device_properties_t &p, int device_id) 
# 40
{ 
# 42
cudaDeviceProp properties; 
# 44
cudaError_t error = cudaGetDeviceProperties(&properties, device_id); 
# 46
throw_on_error(error, "cudaGetDeviceProperties in get_device_properties"); 
# 49
device_properties_t temp = {properties.major, {(properties.maxGridSize)[0], (properties.maxGridSize)[1], (properties.maxGridSize)[2]}, properties.maxThreadsPerBlock, properties.maxThreadsPerMultiProcessor, properties.minor, properties.multiProcessorCount, properties.regsPerBlock, properties.sharedMemPerBlock, properties.warpSize}; 
# 65
p = temp; 
# 85
} 
# 88
inline void cached_device_properties(device_properties_t &p, int device_id) 
# 89
{ 
# 92
static const int max_num_devices = 16; 
# 94
static bool properties_exist[max_num_devices] = {(0)}; 
# 95
static device_properties_t device_properties[max_num_devices] = {}; 
# 97
if (device_id >= max_num_devices) 
# 98
{ 
# 99
uncached_device_properties(p, device_id); 
# 100
}  
# 102
if (!((properties_exist)[device_id])) 
# 103
{ 
# 104
uncached_device_properties((device_properties)[device_id], device_id); 
# 108
__sync_synchronize(); 
# 110
((properties_exist)[device_id]) = true; 
# 111
}  
# 113
p = ((device_properties)[device_id]); 
# 114
} 
# 117
}
# 121
inline device_properties_t device_properties(int device_id) 
# 122
{ 
# 123
device_properties_t result; 
# 125
runtime_introspection_detail::cached_device_properties(result, device_id); 
# 129
return result; 
# 130
} 
# 134
inline int current_device() 
# 135
{ 
# 136
int result = (-1); 
# 139
cudaError_t error = cudaGetDevice(&result); 
# 141
throw_on_error(error, "cudaGetDevice in current_device"); 
# 143
if (result < 0) 
# 144
{ 
# 145
throw_on_error(cudaErrorNoDevice, "cudaGetDevice in current_device"); 
# 146
}  
# 151
return result; 
# 152
} 
# 156
inline device_properties_t device_properties() 
# 157
{ 
# 158
return device_properties(current_device()); 
# 159
} 
# 162
template< class KernelFunction> inline function_attributes_t 
# 164
function_attributes(KernelFunction kernel) 
# 165
{ 
# 167
cudaFuncAttributes attributes; 
# 169
typedef void (*fun_ptr_type)(void); 
# 171
fun_ptr_type fun_ptr = reinterpret_cast< fun_ptr_type>(kernel); 
# 172
throw_on_error(cudaFuncGetAttributes(&attributes, reinterpret_cast< void *>(fun_ptr)), "cudaFuncGetAttributes in function_attributes"); 
# 175
function_attributes_t result = {attributes.constSizeBytes, attributes.localSizeBytes, attributes.maxThreadsPerBlock, attributes.numRegs, attributes.ptxVersion, attributes.sharedSizeBytes}; 
# 187
return result; 
# 188
} 
# 192
inline size_t compute_capability(const device_properties_t &properties) 
# 193
{ 
# 194
return (10 * (properties.major)) + (properties.minor); 
# 195
} 
# 199
inline size_t compute_capability() 
# 200
{ 
# 201
return compute_capability(device_properties()); 
# 202
} 
# 205
}
# 206
}
# 207
}
# 208
}
# 20 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/default_decomposition.inl"
namespace thrust { 
# 22
namespace system { 
# 24
namespace cuda { 
# 26
namespace detail { 
# 30
template< class IndexType> system::detail::internal::uniform_decomposition< IndexType>  
# 32
default_decomposition(IndexType n) 
# 33
{ 
# 35
device_properties_t properties = device_properties(); 
# 36
return system::detail::internal::uniform_decomposition< IndexType> (n, properties.maxThreadsPerBlock, 10 * (properties.multiProcessorCount)); 
# 37
} 
# 40
}
# 41
}
# 42
}
# 43
}
# 27 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/reduce_intervals.h"
namespace thrust { 
# 29
namespace system { 
# 31
namespace cuda { 
# 33
namespace detail { 
# 37
template< class DerivedPolicy, class 
# 38
InputIterator, class 
# 39
OutputIterator, class 
# 40
BinaryFunction, class 
# 41
Decomposition> void 
# 37
reduce_intervals(execution_policy< DerivedPolicy>  & exec, InputIterator input, OutputIterator output, BinaryFunction binary_op, Decomposition decomp); 
# 50
}
# 51
}
# 52
}
# 53
}
# 22 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/extern_shared_ptr.h"
namespace thrust { 
# 24
namespace system { 
# 26
namespace cuda { 
# 28
namespace detail { 
# 31
template< class T> 
# 32
class extern_shared_ptr { 
# 39
public: operator T *() 
# 40
{int volatile ___ = 1;
# 43
::exit(___);}
#if 0
# 40
{ 
# 41
__attribute__((unused)) extern int4 smem[]; 
# 42
return reinterpret_cast< T *>(smem); 
# 43
} 
#endif
# 46 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/extern_shared_ptr.h"
operator const T *() const 
# 47
{int volatile ___ = 1;
# 50
::exit(___);}
#if 0
# 47
{ 
# 48
__attribute__((unused)) extern int4 smem[]; 
# 49
return reinterpret_cast< const T *>(smem); 
# 50
} 
#endif
# 52 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/extern_shared_ptr.h"
}; 
# 54
}
# 55
}
# 56
}
# 57
}
# 22 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/block/reduce.h"
namespace thrust { 
# 24
namespace system { 
# 26
namespace cuda { 
# 28
namespace detail { 
# 30
namespace block { 
# 37
template< class Context, class ValueIterator, class BinaryFunction> 
# 38
__attribute((always_inline)) __attribute__((unused)) inline void 
# 39
reduce_n(Context context, ValueIterator data, unsigned n, BinaryFunction binary_op) 
# 40
{int volatile ___ = 1;(void)context;(void)data;(void)n;(void)binary_op;
# 60
::exit(___);}
#if 0
# 40
{ 
# 41
if ((context.block_dimension()) < n) 
# 42
{ 
# 43
for (unsigned i = (context.block_dimension()) + (context.thread_index()); i < n; i += (context.block_dimension())) { 
# 44
(data[(context.thread_index())]) = binary_op(data[(context.thread_index())], data[i]); }  
# 46
(context.barrier()); 
# 47
}  
# 49
while (n > (1)) 
# 50
{ 
# 51
unsigned half = n / (2); 
# 53
if ((context.thread_index()) < half) { 
# 54
(data[(context.thread_index())]) = binary_op(data[(context.thread_index())], data[(n - (context.thread_index())) - 1]); }  
# 56
(context.barrier()); 
# 58
n = (n - half); 
# 59
}  
# 60
} 
#endif
# 62 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/block/reduce.h"
} namespace __T0 = block;
# 63
}
# 64
}
# 65
}
# 66
}
# 24 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/detail/launch_closure.h"
namespace thrust { 
# 26
namespace system { 
# 28
namespace cuda { 
# 30
namespace detail { 
# 32
namespace detail { 
# 36
template< unsigned _ThreadsPerBlock = 0U, unsigned 
# 37
_BlocksPerMultiprocessor = 0U> 
# 38
struct launch_bounds { 
# 40
typedef thrust::detail::integral_constant< unsigned, _ThreadsPerBlock>  ThreadsPerBlock; 
# 41
typedef thrust::detail::integral_constant< unsigned, _BlocksPerMultiprocessor>  BlocksPerMultiprocessor; 
# 42
}; 
# 45
struct thread_array : public launch_bounds<>  { 
# 49
__attribute((always_inline)) unsigned thread_index() const {int volatile ___ = 1;::exit(___);}
#if 0
# 49
{ return __device_builtin_variable_threadIdx.x; } 
#endif
# 50 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/detail/launch_closure.h"
__attribute((always_inline)) unsigned thread_count() const {int volatile ___ = 1;::exit(___);}
#if 0
# 50
{ return (__device_builtin_variable_blockDim.x) * (__device_builtin_variable_gridDim.x); } 
#endif
# 55 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/detail/launch_closure.h"
}; 
# 58
struct blocked_thread_array : public launch_bounds<>  { 
# 62
__attribute((always_inline)) unsigned thread_index() const {int volatile ___ = 1;::exit(___);}
#if 0
# 62
{ return __device_builtin_variable_threadIdx.x; } 
#endif
# 63 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/detail/launch_closure.h"
__attribute((always_inline)) unsigned block_dimension() const {int volatile ___ = 1;::exit(___);}
#if 0
# 63
{ return __device_builtin_variable_blockDim.x; } 
#endif
# 64 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/detail/launch_closure.h"
__attribute((always_inline)) unsigned block_index() const {int volatile ___ = 1;::exit(___);}
#if 0
# 64
{ return __device_builtin_variable_blockIdx.x; } 
#endif
# 65 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/detail/launch_closure.h"
__attribute((always_inline)) unsigned grid_dimension() const {int volatile ___ = 1;::exit(___);}
#if 0
# 65
{ return __device_builtin_variable_gridDim.x; } 
#endif
# 66 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/detail/launch_closure.h"
__attribute((always_inline)) unsigned linear_index() const {int volatile ___ = 1;::exit(___);}
#if 0
# 66
{ return (this->block_dimension() * this->block_index()) + this->thread_index(); } 
#endif
# 67 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/detail/launch_closure.h"
__attribute((always_inline)) void barrier() {int volatile ___ = 1;::exit(___);}
#if 0
# 67
{ __syncthreads(); } 
#endif
# 76 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/detail/launch_closure.h"
}; 
# 79
template< unsigned _ThreadsPerBlock> 
# 80
struct statically_blocked_thread_array : public launch_bounds< _ThreadsPerBlock, 1U>  { 
# 84
__attribute((always_inline)) unsigned thread_index() const {int volatile ___ = 1;::exit(___);}
#if 0
# 84
{ return __device_builtin_variable_threadIdx.x; } 
#endif
# 85 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/detail/launch_closure.h"
__attribute((always_inline)) unsigned block_dimension() const {int volatile ___ = 1;::exit(___);}
#if 0
# 85
{ return _ThreadsPerBlock; } 
#endif
# 86 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/detail/launch_closure.h"
__attribute((always_inline)) unsigned block_index() const {int volatile ___ = 1;::exit(___);}
#if 0
# 86
{ return __device_builtin_variable_blockIdx.x; } 
#endif
# 87 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/detail/launch_closure.h"
__attribute((always_inline)) unsigned grid_dimension() const {int volatile ___ = 1;::exit(___);}
#if 0
# 87
{ return __device_builtin_variable_gridDim.x; } 
#endif
# 88 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/detail/launch_closure.h"
__attribute((always_inline)) unsigned linear_index() const {int volatile ___ = 1;::exit(___);}
#if 0
# 88
{ return (block_dimension() * block_index()) + thread_index(); } 
#endif
# 89 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/detail/launch_closure.h"
__attribute((always_inline)) void barrier() {int volatile ___ = 1;::exit(___);}
#if 0
# 89
{ __syncthreads(); } 
#endif
# 98 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/detail/launch_closure.h"
}; 
# 100
template< class DerivedPolicy, class Closure, class Size> void launch_closure(execution_policy< DerivedPolicy>  & exec, Closure f, Size num_blocks); 
# 104
template< class DerivedPolicy, class Closure, class Size1, class Size2> void launch_closure(execution_policy< DerivedPolicy>  & exec, Closure f, Size1 num_blocks, Size2 block_size); 
# 108
template< class DerivedPolicy, class Closure, class Size1, class Size2, class Size3> void launch_closure(execution_policy< DerivedPolicy>  & exec, Closure f, Size1 num_blocks, Size2 block_size, Size3 smem_size); 
# 115
template< class Closure> function_attributes_t closure_attributes(); 
# 120
}
# 121
}
# 122
}
# 123
}
# 124
}
# 24 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/detail/launch_calculator.h"
namespace thrust { 
# 26
namespace system { 
# 28
namespace cuda { 
# 30
namespace detail { 
# 32
namespace detail { 
# 35
template< class Closure> 
# 36
class launch_calculator { 
# 38
device_properties_t properties; 
# 39
function_attributes_t attributes; 
# 44
public: launch_calculator(); 
# 47
launch_calculator(const device_properties_t & properties, const function_attributes_t & attributes); 
# 50
tuple< unsigned long, unsigned long, unsigned long, null_type, null_type, null_type, null_type, null_type, null_type, null_type>  with_variable_block_size() const; 
# 52
template< class UnaryFunction> tuple< unsigned long, unsigned long, unsigned long, null_type, null_type, null_type, null_type, null_type, null_type, null_type>  with_variable_block_size(UnaryFunction block_size_to_smem_size) const; 
# 57
tuple< unsigned long, unsigned long, unsigned long, null_type, null_type, null_type, null_type, null_type, null_type, null_type>  with_variable_block_size_available_smem() const; 
# 67
private: pair< unsigned long, unsigned long>  default_block_configuration() const; 
# 77
template< class UnaryFunction> pair< unsigned long, unsigned long>  default_block_configuration(UnaryFunction block_size_to_smem_size) const; 
# 80
}; 
# 82
}
# 83
}
# 84
}
# 85
}
# 86
}
# 24 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/detail/launch_calculator.inl"
namespace thrust { 
# 26
namespace system { 
# 28
namespace cuda { 
# 30
namespace detail { 
# 32
namespace detail { 
# 35
template< class Closure> 
# 37
launch_calculator< Closure> ::launch_calculator() : properties(device_properties()), attributes(closure_attributes< Closure> ()) 
# 40
{ } 
# 42
template< class Closure> 
# 44
launch_calculator< Closure> ::launch_calculator(const device_properties_t &properties, const function_attributes_t &attributes) : properties(properties), attributes(attributes) 
# 47
{ } 
# 49
template< class Closure> 
# 50
template< class UnaryFunction> pair< unsigned long, unsigned long>  
# 52
launch_calculator< Closure> ::default_block_configuration(UnaryFunction block_size_to_smem_size) const 
# 53
{ 
# 55
std::size_t num_threads_per_block = block_size_with_maximum_potential_occupancy(attributes, properties, block_size_to_smem_size); 
# 58
std::size_t num_blocks_per_multiprocessor = ((properties).maxThreadsPerMultiProcessor) / num_threads_per_block; 
# 60
return thrust::make_pair(num_threads_per_block, num_blocks_per_multiprocessor); 
# 61
} 
# 64
template< class Closure> pair< unsigned long, unsigned long>  
# 66
launch_calculator< Closure> ::default_block_configuration() const 
# 67
{ 
# 69
std::size_t num_threads_per_block = block_size_with_maximum_potential_occupancy(attributes, properties); 
# 72
std::size_t num_blocks_per_multiprocessor = ((properties).maxThreadsPerMultiProcessor) / num_threads_per_block; 
# 74
return thrust::make_pair(num_threads_per_block, num_blocks_per_multiprocessor); 
# 75
} 
# 77
template< class Closure> tuple< unsigned long, unsigned long, unsigned long, null_type, null_type, null_type, null_type, null_type, null_type, null_type>  
# 79
launch_calculator< Closure> ::with_variable_block_size() const 
# 80
{ 
# 81
pair< unsigned long, unsigned long>  config = default_block_configuration(); 
# 82
return tuple< unsigned long, unsigned long, unsigned long, null_type, null_type, null_type, null_type, null_type, null_type, null_type> ((config.second) * ((properties).multiProcessorCount), config.first, 0); 
# 83
} 
# 85
template< class Closure> 
# 86
template< class UnaryFunction> tuple< unsigned long, unsigned long, unsigned long, null_type, null_type, null_type, null_type, null_type, null_type, null_type>  
# 88
launch_calculator< Closure> ::with_variable_block_size(UnaryFunction block_size_to_smem_size) const 
# 89
{ 
# 90
pair< unsigned long, unsigned long>  config = default_block_configuration(block_size_to_smem_size); 
# 91
return tuple< unsigned long, unsigned long, unsigned long, null_type, null_type, null_type, null_type, null_type, null_type, null_type> ((config.second) * ((properties).multiProcessorCount), config.first, block_size_to_smem_size(config.first)); 
# 92
} 
# 94
template< class Closure> tuple< unsigned long, unsigned long, unsigned long, null_type, null_type, null_type, null_type, null_type, null_type, null_type>  
# 96
launch_calculator< Closure> ::with_variable_block_size_available_smem() const 
# 97
{ 
# 98
pair< unsigned long, unsigned long>  config = default_block_configuration(); 
# 99
size_t smem_per_block = proportional_smem_allocation(properties, attributes, config.second); 
# 100
return tuple< unsigned long, unsigned long, unsigned long, null_type, null_type, null_type, null_type, null_type, null_type, null_type> ((config.second) * ((properties).multiProcessorCount), config.first, smem_per_block); 
# 101
} 
# 103
}
# 104
}
# 105
}
# 106
}
# 107
}
# 19 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/detail/alignment.h"
namespace thrust { 
# 21
namespace system { 
# 23
namespace cuda { 
# 25
namespace detail { 
# 27
namespace detail { 
# 29
namespace alignment_of_detail { 
# 33
template< class T> class alignment_of_impl; 
# 35
template< class T, std::size_t size_diff> 
# 36
struct helper { 
# 38
static const std::size_t value = size_diff; 
# 39
}; 
# 41
template< class T> 
# 42
class helper< T, 0>  { 
# 45
public: static const std::size_t value = (alignment_of_impl< T> ::value); 
# 46
}; 
# 48
template< class T> 
# 49
class alignment_of_impl { 
# 52
struct big { T x; char c; }; 
# 55
public: static const std::size_t value = (helper< big, sizeof(big) - sizeof(T)> ::value); 
# 56
}; 
# 59
}
# 62
template< class T> 
# 63
struct alignment_of : public alignment_of_detail::alignment_of_impl< T>  { 
# 65
}; 
# 68
template< std::size_t Align> struct aligned_type; 
# 193
template< std::size_t Align> struct aligned_type { 
# 195
struct __attribute((aligned(Align))) type { }; 
# 196
}; 
# 206
template< std::size_t Len, std::size_t Align> 
# 207
struct aligned_storage { 
# 209
union type { 
# 211
unsigned char data[Len]; 
# 213
typename aligned_type< Align> ::type align; 
# 214
}; 
# 215
}; 
# 218
}
# 219
}
# 220
}
# 221
}
# 222
}
# 28 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/detail/launch_closure.inl"
namespace thrust { 
# 30
namespace detail { 
# 34
template< class , class > class temporary_array; 
# 36
}
# 38
namespace system { 
# 40
namespace cuda { 
# 42
namespace detail { 
# 44
namespace detail { 
# 48
template< class Closure> static void 
# 50
__wrapper__device_stub_launch_closure_by_value(Closure &f) {exit(1);}
#if 0
# 51
{ 
# 52
f(); 
# 53
} 
#endif
# 48 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/detail/launch_closure.inl"
template< class Closure> void 
# 50
launch_closure_by_value(Closure f) 
# 51
{__wrapper__device_stub_launch_closure_by_value<Closure>(f);
# 53
return;}
#if 0
# 51
{ 
# 52
f(); 
# 53
} 
#endif
# 55 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/detail/launch_closure.inl"
template< class Closure> static void 
# 57
__wrapper__device_stub_launch_closure_by_pointer(const Closure *&f) {exit(1);}
#if 0
# 58
{ 
# 60
Closure f_reg = *f; 
# 61
f_reg(); 
# 62
} 
#endif
# 55 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/detail/launch_closure.inl"
template< class Closure> void 
# 57
launch_closure_by_pointer(const Closure *f) 
# 58
{__wrapper__device_stub_launch_closure_by_pointer<Closure>(f);
# 62
return;}
#if 0
# 58
{ 
# 60
Closure f_reg = *f; 
# 61
f_reg(); 
# 62
} 
#endif
# 72 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/detail/launch_closure.inl"
template< class Closure, bool 
# 73
launch_by_value = sizeof(Closure) <= (256)> 
# 74
struct closure_launcher_base { 
# 76
typedef void (*launch_function_t)(Closure); 
# 79
static launch_function_t get_launch_function() 
# 80
{ 
# 81
return &launch_closure_by_value< Closure> ; 
# 82
} 
# 84
template< class DerivedPolicy, class Size1, class Size2, class Size3> static void 
# 86
launch(execution_policy< DerivedPolicy>  &exec, Closure f, Size1 num_blocks, Size2 block_size, Size3 smem_size) 
# 87
{ 
# 89
launch_function_t kernel = (get_launch_function)(); 
# 93
if (num_blocks > 0) 
# 94
{ 
# 96
(cudaConfigureCall((unsigned)num_blocks, (unsigned)block_size, (unsigned)smem_size, stream(thrust::detail::derived_cast(exec)))) ? (void)0 : kernel(f); 
# 104
synchronize_if_enabled("launch_closure_by_value"); 
# 105
}  
# 108
} 
# 109
}; 
# 112
template< class Closure> 
# 113
struct closure_launcher_base< Closure, false>  { 
# 115
typedef void (*launch_function_t)(const Closure *); 
# 118
static launch_function_t get_launch_function() 
# 119
{ 
# 120
return &launch_closure_by_pointer< Closure> ; 
# 121
} 
# 123
template< class DerivedPolicy, class Size1, class Size2, class Size3> static void 
# 125
launch(execution_policy< DerivedPolicy>  &exec, Closure f, Size1 num_blocks, Size2 block_size, Size3 smem_size) 
# 126
{ 
# 128
launch_function_t kernel = (get_launch_function)(); 
# 132
if (num_blocks > 0) 
# 133
{ 
# 135
host_system_tag host_tag; 
# 136
thrust::detail::temporary_array< Closure, DerivedPolicy>  closure_storage(exec, host_tag, &f, (&f) + 1); 
# 139
(cudaConfigureCall((unsigned)num_blocks, (unsigned)block_size, (unsigned)smem_size, stream(thrust::detail::derived_cast(exec)))) ? (void)0 : kernel(((&(closure_storage[0])).get)()); 
# 140
synchronize_if_enabled("launch_closure_by_pointer"); 
# 141
}  
# 144
} 
# 145
}; 
# 148
template< class Closure> 
# 149
struct closure_launcher : public closure_launcher_base< Closure>  { 
# 152
typedef ::thrust::system::cuda::detail::detail::closure_launcher_base< Closure>  super_t; 
# 155
static const ::thrust::system::cuda::detail::device_properties_t &device_properties() 
# 156
{ 
# 157
return (device_properties)(); 
# 158
} 
# 161
static ::thrust::system::cuda::detail::function_attributes_t function_attributes() 
# 162
{ 
# 163
return ::thrust::system::cuda::detail::function_attributes(super_t::get_launch_function()); 
# 164
} 
# 166
template< class DerivedPolicy, class Size1, class Size2, class Size3> static void 
# 168
launch(execution_policy< DerivedPolicy>  &exec, Closure f, Size1 num_blocks, Size2 block_size, Size3 smem_size) 
# 169
{ 
# 170
super_t::launch(exec, f, num_blocks, block_size, smem_size); 
# 171
} 
# 172
}; 
# 174
template< class DerivedPolicy, class Closure, class Size> void 
# 176
launch_closure(execution_policy< DerivedPolicy>  &exec, Closure f, Size num_blocks) 
# 177
{ 
# 178
launch_calculator< Closure>  calculator; 
# 179
launch_closure(exec, f, num_blocks, thrust::get< 1> ((calculator.with_variable_block_size()))); 
# 180
} 
# 182
template< class DerivedPolicy, class Closure, class Size1, class Size2> void 
# 184
launch_closure(execution_policy< DerivedPolicy>  &exec, Closure f, Size1 num_blocks, Size2 block_size) 
# 185
{ 
# 186
launch_closure(exec, f, num_blocks, block_size, 0U); 
# 187
} 
# 189
template< class DerivedPolicy, class Closure, class Size1, class Size2, class Size3> void 
# 191
launch_closure(execution_policy< DerivedPolicy>  &exec, Closure f, Size1 num_blocks, Size2 block_size, Size3 smem_size) 
# 192
{ 
# 193
closure_launcher< Closure> ::launch(exec, f, num_blocks, block_size, smem_size); 
# 194
} 
# 197
namespace closure_attributes_detail { 
# 201
template< class Closure> inline function_attributes_t 
# 203
uncached_closure_attributes() 
# 204
{ 
# 205
typedef closure_launcher< Closure>  Launcher; 
# 206
return cuda::detail::function_attributes(Launcher::get_launch_function()); 
# 207
} 
# 210
template< class Closure> function_attributes_t 
# 211
cached_closure_attributes() 
# 212
{ 
# 215
static const int max_num_devices = 16; 
# 217
static bool attributes_exist[max_num_devices] = {(0)}; 
# 218
static function_attributes_t function_attributes[max_num_devices] = {}; 
# 221
int device_id = current_device(); 
# 223
if (device_id >= max_num_devices) 
# 224
{ 
# 225
return uncached_closure_attributes< Closure> (); 
# 226
}  
# 228
if (!((attributes_exist)[device_id])) 
# 229
{ 
# 230
((function_attributes)[device_id]) = uncached_closure_attributes< Closure> (); 
# 234
__sync_synchronize(); 
# 236
((attributes_exist)[device_id]) = true; 
# 237
}  
# 239
return (function_attributes)[device_id]; 
# 240
} 
# 243
}
# 246
template< class Closure> function_attributes_t 
# 248
closure_attributes() 
# 249
{ 
# 251
return closure_attributes_detail::cached_closure_attributes< Closure> (); 
# 255
} 
# 257
}
# 258
}
# 259
}
# 260
}
# 261
}
# 29 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/reduce_intervals.inl"
namespace thrust { 
# 31
namespace system { 
# 33
namespace cuda { 
# 35
namespace detail { 
# 39
template< class InputIterator, class 
# 40
OutputIterator, class 
# 41
BinaryFunction, class 
# 42
Decomposition, class 
# 43
Context> 
# 44
struct commutative_reduce_intervals_closure { 
# 46
InputIterator input; 
# 47
OutputIterator output; 
# 48
BinaryFunction binary_op; 
# 49
Decomposition decomposition; 
# 50
unsigned shared_array_size; 
# 52
typedef Context context_type; 
# 53
context_type context; 
# 56
commutative_reduce_intervals_closure(InputIterator input, OutputIterator output, BinaryFunction binary_op, Decomposition decomposition, unsigned shared_array_size, Context context = Context()) : input(input), output(output), binary_op(binary_op), decomposition(decomposition), shared_array_size(shared_array_size), context(context) 
# 57
{ } 
# 59
__attribute((always_inline)) void 
# 60
operator()() 
# 61
{int volatile ___ = 1;
# 152
::exit(___);}
#if 0
# 61
{ 
# 62
typedef typename iterator_value< OutputIterator> ::type OutputType; 
# 63
extern_shared_ptr< typename iterator_value< OutputIterator> ::type>  shared_array; 
# 65
typedef typename Decomposition::index_type index_type; 
# 68
system::detail::internal::index_range< typename Decomposition::index_type>  range = (decomposition)[((context).block_index())]; 
# 70
index_type i = (range.begin()) + ((context).thread_index()); 
# 72
(input) += i; 
# 74
if ((range.size()) < ((context).block_dimension())) 
# 75
{ 
# 77
if (((context).thread_index()) < thrust::min< typename Decomposition::index_type> (shared_array_size, (range.size()))) 
# 78
{ 
# 79
OutputType sum = *(input); 
# 81
i += (shared_array_size); 
# 82
(input) += (shared_array_size); 
# 84
while (i < (range.end())) 
# 85
{ 
# 86
OutputType val = *(input); 
# 88
sum = (binary_op)(sum, val); 
# 90
i += (shared_array_size); 
# 91
(input) += (shared_array_size); 
# 92
}  
# 94
(shared_array[((context).thread_index())]) = sum; 
# 95
}  
# 96
} else 
# 98
{ 
# 100
OutputType sum = *(input); 
# 102
i += ((context).block_dimension()); 
# 103
(input) += ((context).block_dimension()); 
# 105
while (i < (range.end())) 
# 106
{ 
# 107
OutputType val = *(input); 
# 109
sum = (binary_op)(sum, val); 
# 111
i += ((context).block_dimension()); 
# 112
(input) += ((context).block_dimension()); 
# 113
}  
# 116
if (((context).thread_index()) < (shared_array_size)) 
# 117
{ 
# 118
(shared_array[((context).thread_index())]) = sum; 
# 119
}  
# 122
if (((context).block_dimension()) > (shared_array_size)) 
# 123
{ 
# 124
unsigned lb = shared_array_size; 
# 125
unsigned ub = (shared_array_size) + lb; 
# 127
while (lb < ((context).block_dimension())) 
# 128
{ 
# 129
((context).barrier()); 
# 131
if ((lb <= ((context).thread_index())) && (((context).thread_index()) < ub)) 
# 132
{ 
# 133
OutputType tmp = shared_array[((context).thread_index()) - lb]; 
# 134
(shared_array[((context).thread_index()) - lb]) = (binary_op)(tmp, sum); 
# 135
}  
# 137
lb += (shared_array_size); 
# 138
ub += (shared_array_size); 
# 139
}  
# 140
}  
# 141
}  
# 143
((context).barrier()); 
# 145
__T0::reduce_n(context, shared_array, thrust::min< typename Decomposition::index_type> ((range.size()), shared_array_size), binary_op); 
# 147
if (((context).thread_index()) == 0) 
# 148
{ 
# 149
(output) += ((context).block_index()); 
# 150
(*(output)) = (shared_array[0]); 
# 151
}  
# 152
} 
#endif
# 153 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/reduce_intervals.inl"
}; 
# 159
template< class ExecutionPolicy, class 
# 160
InputIterator, class 
# 161
OutputIterator, class 
# 162
BinaryFunction, class 
# 163
Decomposition> void 
# 165
reduce_intervals(execution_policy< ExecutionPolicy>  &exec, InputIterator 
# 166
input, OutputIterator 
# 167
output, BinaryFunction 
# 168
binary_op, Decomposition 
# 169
decomp) 
# 170
{ 
# 176
typedef thrust::detail::static_assert_test< sizeof(thrust::detail::STATIC_ASSERTION_FAILURE< (bool)(thrust::detail::depend_on_instantiation< InputIterator, true> ::value)> )>  thrust_static_assert_typedef_176 __attribute((unused)); 
# 178
if ((decomp.size()) == 0) 
# 179
{ 
# 180
return; 
# 181
}  
# 185
typedef detail::blocked_thread_array Context; 
# 186
typedef commutative_reduce_intervals_closure< InputIterator, OutputIterator, BinaryFunction, Decomposition, detail::blocked_thread_array>  Closure; 
# 187
typedef typename iterator_value< OutputIterator> ::type OutputType; 
# 189
detail::launch_calculator< commutative_reduce_intervals_closure< InputIterator, OutputIterator, BinaryFunction, Decomposition, detail::blocked_thread_array> >  calculator; 
# 191
tuple< unsigned long, unsigned long, unsigned long, null_type, null_type, null_type, null_type, null_type, null_type, null_type>  config = (calculator.with_variable_block_size_available_smem()); 
# 194
size_t block_size = thrust::get< 1> (config); 
# 195
size_t max_memory = thrust::get< 2> (config); 
# 198
size_t shared_array_size = thrust::min(max_memory / sizeof(OutputType), block_size); 
# 199
size_t shared_array_bytes = sizeof(OutputType) * shared_array_size; 
# 203
Closure closure(input, output, binary_op, decomp, shared_array_size); 
# 204
detail::launch_closure(exec, closure, (decomp.size()), block_size, shared_array_bytes); 
# 205
} 
# 211
}
# 212
}
# 213
}
# 214
}
# 22 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/block/inclusive_scan.h"
namespace thrust { 
# 24
namespace system { 
# 26
namespace cuda { 
# 28
namespace detail { 
# 30
namespace block { 
# 33
template< class Context, class 
# 34
InputIterator, class 
# 35
BinaryFunction> 
# 36
__attribute((always_inline)) __attribute__((unused)) inline void 
# 37
inclusive_scan(Context context, InputIterator 
# 38
first, BinaryFunction 
# 39
binary_op) 
# 40
{int volatile ___ = 1;(void)context;(void)first;(void)binary_op;
# 58
::exit(___);}
#if 0
# 40
{ 
# 43
const unsigned block_size = (Context::ThreadsPerBlock::value); 
# 45
typename iterator_value< InputIterator> ::type val = first[(context.thread_index())]; 
# 47
if (block_size > (1)) { if ((context.thread_index()) >= 1) { val = binary_op(first[(context.thread_index()) - 1], val); }  (context.barrier()); (first[(context.thread_index())]) = val; (context.barrier()); }  
# 48
if (block_size > (2)) { if ((context.thread_index()) >= 2) { val = binary_op(first[(context.thread_index()) - 2], val); }  (context.barrier()); (first[(context.thread_index())]) = val; (context.barrier()); }  
# 49
if (block_size > (4)) { if ((context.thread_index()) >= 4) { val = binary_op(first[(context.thread_index()) - 4], val); }  (context.barrier()); (first[(context.thread_index())]) = val; (context.barrier()); }  
# 50
if (block_size > (8)) { if ((context.thread_index()) >= 8) { val = binary_op(first[(context.thread_index()) - 8], val); }  (context.barrier()); (first[(context.thread_index())]) = val; (context.barrier()); }  
# 51
if (block_size > (16)) { if ((context.thread_index()) >= 16) { val = binary_op(first[(context.thread_index()) - 16], val); }  (context.barrier()); (first[(context.thread_index())]) = val; (context.barrier()); }  
# 52
if (block_size > (32)) { if ((context.thread_index()) >= 32) { val = binary_op(first[(context.thread_index()) - 32], val); }  (context.barrier()); (first[(context.thread_index())]) = val; (context.barrier()); }  
# 53
if (block_size > (64)) { if ((context.thread_index()) >= 64) { val = binary_op(first[(context.thread_index()) - 64], val); }  (context.barrier()); (first[(context.thread_index())]) = val; (context.barrier()); }  
# 54
if (block_size > (128)) { if ((context.thread_index()) >= 128) { val = binary_op(first[(context.thread_index()) - 128], val); }  (context.barrier()); (first[(context.thread_index())]) = val; (context.barrier()); }  
# 55
if (block_size > (256)) { if ((context.thread_index()) >= 256) { val = binary_op(first[(context.thread_index()) - 256], val); }  (context.barrier()); (first[(context.thread_index())]) = val; (context.barrier()); }  
# 56
if (block_size > (512)) { if ((context.thread_index()) >= 512) { val = binary_op(first[(context.thread_index()) - 512], val); }  (context.barrier()); (first[(context.thread_index())]) = val; (context.barrier()); }  
# 57
if (block_size > (1024)) { if ((context.thread_index()) >= 1024) { val = binary_op(first[(context.thread_index()) - 1024], val); }  (context.barrier()); (first[(context.thread_index())]) = val; (context.barrier()); }  
# 58
} 
#endif
# 61 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/block/inclusive_scan.h"
template< class Context, class 
# 62
InputIterator, class 
# 63
Size, class 
# 64
BinaryFunction> 
# 65
__attribute((always_inline)) __attribute__((unused)) inline void 
# 66
inclusive_scan_n(Context context, InputIterator 
# 67
first, Size 
# 68
n, BinaryFunction 
# 69
binary_op) 
# 70
{int volatile ___ = 1;(void)context;(void)first;(void)n;(void)binary_op;
# 85
::exit(___);}
#if 0
# 70
{ 
# 72
typename iterator_value< InputIterator> ::type val = first[(context.thread_index())]; 
# 74
for (unsigned i = (1); i < n; i <<= 1) 
# 75
{ 
# 76
if (((context.thread_index()) < n) && ((context.thread_index()) >= i)) { 
# 77
val = binary_op(first[(context.thread_index()) - i], val); }  
# 79
(context.barrier()); 
# 81
(first[(context.thread_index())]) = val; 
# 83
(context.barrier()); 
# 84
}  
# 85
} 
#endif
# 88 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/block/inclusive_scan.h"
template< class Context, class 
# 89
InputIterator1, class 
# 90
InputIterator2, class 
# 91
BinaryFunction> 
# 92
__attribute((always_inline)) __attribute__((unused)) inline void 
# 93
inclusive_scan_by_flag(Context context, InputIterator1 
# 94
first1, InputIterator2 
# 95
first2, BinaryFunction 
# 96
binary_op) 
# 97
{int volatile ___ = 1;(void)context;(void)first1;(void)first2;(void)binary_op;
# 116
::exit(___);}
#if 0
# 97
{ 
# 100
const unsigned block_size = (Context::ThreadsPerBlock::value); 
# 102
typename iterator_value< InputIterator1> ::type flg = first1[(context.thread_index())]; 
# 103
typename iterator_value< InputIterator2> ::type val = first2[(context.thread_index())]; 
# 105
if (block_size > (1)) { if ((context.thread_index()) >= 1) { if (!flg) { flg |= (first1[(context.thread_index()) - 1]); val = binary_op(first2[(context.thread_index()) - 1], val); }  }  (context.barrier()); (first1[(context.thread_index())]) = flg; (first2[(context.thread_index())]) = val; (context.barrier()); }  
# 106
if (block_size > (2)) { if ((context.thread_index()) >= 2) { if (!flg) { flg |= (first1[(context.thread_index()) - 2]); val = binary_op(first2[(context.thread_index()) - 2], val); }  }  (context.barrier()); (first1[(context.thread_index())]) = flg; (first2[(context.thread_index())]) = val; (context.barrier()); }  
# 107
if (block_size > (4)) { if ((context.thread_index()) >= 4) { if (!flg) { flg |= (first1[(context.thread_index()) - 4]); val = binary_op(first2[(context.thread_index()) - 4], val); }  }  (context.barrier()); (first1[(context.thread_index())]) = flg; (first2[(context.thread_index())]) = val; (context.barrier()); }  
# 108
if (block_size > (8)) { if ((context.thread_index()) >= 8) { if (!flg) { flg |= (first1[(context.thread_index()) - 8]); val = binary_op(first2[(context.thread_index()) - 8], val); }  }  (context.barrier()); (first1[(context.thread_index())]) = flg; (first2[(context.thread_index())]) = val; (context.barrier()); }  
# 109
if (block_size > (16)) { if ((context.thread_index()) >= 16) { if (!flg) { flg |= (first1[(context.thread_index()) - 16]); val = binary_op(first2[(context.thread_index()) - 16], val); }  }  (context.barrier()); (first1[(context.thread_index())]) = flg; (first2[(context.thread_index())]) = val; (context.barrier()); }  
# 110
if (block_size > (32)) { if ((context.thread_index()) >= 32) { if (!flg) { flg |= (first1[(context.thread_index()) - 32]); val = binary_op(first2[(context.thread_index()) - 32], val); }  }  (context.barrier()); (first1[(context.thread_index())]) = flg; (first2[(context.thread_index())]) = val; (context.barrier()); }  
# 111
if (block_size > (64)) { if ((context.thread_index()) >= 64) { if (!flg) { flg |= (first1[(context.thread_index()) - 64]); val = binary_op(first2[(context.thread_index()) - 64], val); }  }  (context.barrier()); (first1[(context.thread_index())]) = flg; (first2[(context.thread_index())]) = val; (context.barrier()); }  
# 112
if (block_size > (128)) { if ((context.thread_index()) >= 128) { if (!flg) { flg |= (first1[(context.thread_index()) - 128]); val = binary_op(first2[(context.thread_index()) - 128], val); }  }  (context.barrier()); (first1[(context.thread_index())]) = flg; (first2[(context.thread_index())]) = val; (context.barrier()); }  
# 113
if (block_size > (256)) { if ((context.thread_index()) >= 256) { if (!flg) { flg |= (first1[(context.thread_index()) - 256]); val = binary_op(first2[(context.thread_index()) - 256], val); }  }  (context.barrier()); (first1[(context.thread_index())]) = flg; (first2[(context.thread_index())]) = val; (context.barrier()); }  
# 114
if (block_size > (512)) { if ((context.thread_index()) >= 512) { if (!flg) { flg |= (first1[(context.thread_index()) - 512]); val = binary_op(first2[(context.thread_index()) - 512], val); }  }  (context.barrier()); (first1[(context.thread_index())]) = flg; (first2[(context.thread_index())]) = val; (context.barrier()); }  
# 115
if (block_size > (1024)) { if ((context.thread_index()) >= 1024) { if (!flg) { flg |= (first1[(context.thread_index()) - 1024]); val = binary_op(first2[(context.thread_index()) - 1024], val); }  }  (context.barrier()); (first1[(context.thread_index())]) = flg; (first2[(context.thread_index())]) = val; (context.barrier()); }  
# 116
} 
#endif
# 119 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/block/inclusive_scan.h"
template< class Context, class 
# 120
InputIterator1, class 
# 121
InputIterator2, class 
# 122
Size, class 
# 123
BinaryFunction> 
# 124
__attribute((always_inline)) __attribute__((unused)) inline void 
# 125
inclusive_scan_by_flag_n(Context context, InputIterator1 
# 126
first1, InputIterator2 
# 127
first2, Size 
# 128
n, BinaryFunction 
# 129
binary_op) 
# 130
{int volatile ___ = 1;(void)context;(void)first1;(void)first2;(void)n;(void)binary_op;
# 153
::exit(___);}
#if 0
# 130
{ 
# 132
typename iterator_value< InputIterator1> ::type flg = first1[(context.thread_index())]; 
# 133
typename iterator_value< InputIterator2> ::type val = first2[(context.thread_index())]; 
# 135
for (unsigned i = (1); i < n; i <<= 1) 
# 136
{ 
# 137
if (((context.thread_index()) < n) && ((context.thread_index()) >= i)) 
# 138
{ 
# 139
if (!flg) 
# 140
{ 
# 141
flg |= (first1[(context.thread_index()) - i]); 
# 142
val = binary_op(first2[(context.thread_index()) - i], val); 
# 143
}  
# 144
}  
# 146
(context.barrier()); 
# 148
(first1[(context.thread_index())]) = flg; 
# 149
(first2[(context.thread_index())]) = val; 
# 151
(context.barrier()); 
# 152
}  
# 153
} 
#endif
# 156 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/block/inclusive_scan.h"
template< class Context, class RandomAccessIterator, class BinaryFunction> 
# 157
__attribute((always_inline)) __attribute__((unused)) inline void 
# 158
inplace_inclusive_scan(Context &ctx, RandomAccessIterator first, BinaryFunction op) 
# 159
{int volatile ___ = 1;(void)ctx;(void)first;(void)op;
# 175
::exit(___);}
#if 0
# 159
{ 
# 160
typename iterator_value< RandomAccessIterator> ::type x = first[(ctx.thread_index())]; 
# 162
for (unsigned offset = (1); offset < (ctx.block_dimension()); offset *= (2)) 
# 163
{ 
# 164
if ((ctx.thread_index()) >= offset) 
# 165
{ 
# 166
x = op(first[(ctx.thread_index()) - offset], x); 
# 167
}  
# 169
(ctx.barrier()); 
# 171
(first[(ctx.thread_index())]) = x; 
# 173
(ctx.barrier()); 
# 174
}  
# 175
} 
#endif
# 178 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/block/inclusive_scan.h"
template< class Context, class RandomAccessIterator> 
# 179
__attribute((always_inline)) __attribute__((unused)) inline void 
# 180
inplace_inclusive_scan(Context &ctx, RandomAccessIterator first) 
# 181
{int volatile ___ = 1;(void)ctx;(void)first;
# 183
::exit(___);}
#if 0
# 181
{ 
# 182
block::inplace_inclusive_scan(ctx, first, plus< typename iterator_value< RandomAccessIterator> ::type> ()); 
# 183
} 
#endif
# 186 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/block/inclusive_scan.h"
} namespace __T0 = block;
# 187
}
# 188
}
# 189
}
# 190
}
# 39 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/copy_if.inl"
namespace thrust { 
# 41
namespace system { 
# 43
namespace cuda { 
# 45
namespace detail { 
# 47
namespace copy_if_detail { 
# 51
template< class InputIterator1, class 
# 52
InputIterator2, class 
# 53
InputIterator3, class 
# 54
Decomposition, class 
# 55
OutputIterator, class 
# 56
Context> 
# 57
struct copy_if_intervals_closure { 
# 59
InputIterator1 input; 
# 60
InputIterator2 stencil; 
# 61
InputIterator3 offsets; 
# 62
Decomposition decomp; 
# 63
OutputIterator output; 
# 65
typedef Context context_type; 
# 66
context_type context; 
# 69
copy_if_intervals_closure(InputIterator1 input, InputIterator2 
# 70
stencil, InputIterator3 
# 71
offsets, Decomposition 
# 72
decomp, OutputIterator 
# 73
output, Context 
# 74
context = Context()) : input(input), stencil(stencil), offsets(offsets), decomp(decomp), output(output), context(context) 
# 75
{ } 
# 77
__attribute((always_inline)) void 
# 78
operator()() 
# 79
{int volatile ___ = 1;
# 162
::exit(___);}
#if 0
# 79
{ 
# 80
typedef unsigned PredicateType; 
# 82
const unsigned CTA_SIZE = (context_type::ThreadsPerBlock::value); 
# 84
plus< unsigned>  binary_op; 
# 86
__attribute__((unused)) static PredicateType sdata[CTA_SIZE]; ((context).barrier()); 
# 88
typedef typename Decomposition::index_type IndexType; 
# 91
system::detail::internal::index_range< typename Decomposition::index_type>  range = (decomp)[((context).block_index())]; 
# 93
IndexType base = (range.begin()); 
# 95
PredicateType predicate = (0); 
# 98
(input) += (base + ((context).thread_index())); 
# 99
(stencil) += (base + ((context).thread_index())); 
# 102
if (((context).block_index()) != 0) 
# 103
{ 
# 104
InputIterator3 temp = (offsets) + (((context).block_index()) - 1); 
# 105
(output) += (*temp); 
# 106
}  
# 109
while ((base + CTA_SIZE) <= (range.end())) 
# 110
{ 
# 112
(sdata[((context).thread_index())]) = (predicate = (*(stencil))); 
# 114
((context).barrier()); 
# 117
__T0::inclusive_scan(context, sdata, binary_op); 
# 120
if (predicate) 
# 121
{ 
# 122
OutputIterator temp2 = (output) + ((sdata[((context).thread_index())]) - 1); 
# 123
(*temp2) = (*(input)); 
# 124
}  
# 127
base += CTA_SIZE; 
# 128
(input) += CTA_SIZE; 
# 129
(stencil) += CTA_SIZE; 
# 132
(output) += ((sdata)[CTA_SIZE - (1)]); 
# 134
((context).barrier()); 
# 135
}  
# 138
if (base < (range.end())) 
# 139
{ 
# 141
if ((base + ((context).thread_index())) < (range.end())) 
# 142
{ 
# 143
(sdata[((context).thread_index())]) = (predicate = (*(stencil))); 
# 144
} else 
# 146
{ 
# 147
(sdata[((context).thread_index())]) = (predicate = (0)); 
# 148
}  
# 150
((context).barrier()); 
# 153
__T0::inclusive_scan(context, sdata, binary_op); 
# 156
if (predicate) 
# 157
{ 
# 158
OutputIterator temp2 = (output) + ((sdata[((context).thread_index())]) - 1); 
# 159
(*temp2) = (*(input)); 
# 160
}  
# 161
}  
# 162
} 
#endif
# 163 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/copy_if.inl"
}; 
# 166
template< class DerivedPolicy, class 
# 167
InputIterator1, class 
# 168
InputIterator2, class 
# 169
OutputIterator, class 
# 170
Predicate> OutputIterator 
# 172
copy_if(execution_policy< DerivedPolicy>  &exec, InputIterator1 
# 173
first, InputIterator1 
# 174
last, InputIterator2 
# 175
stencil, OutputIterator 
# 176
output, Predicate 
# 177
pred) 
# 178
{ 
# 179
typedef typename iterator_difference< InputIterator1> ::type IndexType; 
# 181
if (first == last) 
# 182
{ 
# 183
return output; 
# 184
}  
# 186
typedef system::detail::internal::uniform_decomposition< typename iterator_difference< InputIterator1> ::type>  Decomposition; 
# 187
typedef thrust::detail::temporary_array< typename iterator_difference< InputIterator1> ::type, DerivedPolicy>  IndexArray; 
# 189
Decomposition decomp = default_decomposition(last - first); 
# 192
IndexArray block_results(exec, (decomp.size())); 
# 195
typedef thrust::detail::predicate_to_integral< Predicate, typename iterator_difference< InputIterator1> ::type>  PredicateToIndexTransform; 
# 196
typedef transform_iterator< thrust::detail::predicate_to_integral< Predicate, typename iterator_difference< InputIterator1> ::type> , InputIterator2, typename iterator_difference< InputIterator1> ::type>  PredicateToIndexIterator; 
# 198
PredicateToIndexIterator predicate_stencil(stencil, ((PredicateToIndexTransform)(pred))); 
# 201
cuda::detail::reduce_intervals(exec, predicate_stencil, (block_results.begin()), plus< typename iterator_difference< InputIterator1> ::type> (), decomp); 
# 204
thrust::inclusive_scan(exec, (block_results.begin()), (block_results.end()), (block_results.begin()), plus< typename iterator_difference< InputIterator1> ::type> ()); 
# 207
const unsigned ThreadsPerBlock = (256); 
# 208
typedef typename thrust::detail::temporary_array< typename iterator_difference< InputIterator1> ::type, DerivedPolicy> ::iterator InputIterator3; 
# 209
typedef detail::statically_blocked_thread_array< 256U>  Context; 
# 210
typedef copy_if_intervals_closure< InputIterator1, transform_iterator< thrust::detail::predicate_to_integral< Predicate, typename iterator_difference< InputIterator1> ::type> , InputIterator2, typename iterator_difference< InputIterator1> ::type> , typename thrust::detail::temporary_array< typename iterator_difference< InputIterator1> ::type, DerivedPolicy> ::iterator, system::detail::internal::uniform_decomposition< typename iterator_difference< InputIterator1> ::type> , OutputIterator, detail::statically_blocked_thread_array< 256U> >  Closure; 
# 211
Closure closure(first, predicate_stencil, (block_results.begin()), decomp, output); 
# 212
detail::launch_closure(exec, closure, (decomp.size()), ThreadsPerBlock); 
# 214
return output + get_value(exec, &(block_results[(decomp.size()) - 1])); 
# 215
} 
# 218
}
# 221
template< class DerivedPolicy, class 
# 222
InputIterator1, class 
# 223
InputIterator2, class 
# 224
OutputIterator, class 
# 225
Predicate> OutputIterator 
# 227
copy_if(execution_policy< DerivedPolicy>  &exec, InputIterator1 
# 228
first, InputIterator1 
# 229
last, InputIterator2 
# 230
stencil, OutputIterator 
# 231
output, Predicate 
# 232
pred) 
# 233
{ 
# 239
typedef thrust::detail::static_assert_test< sizeof(thrust::detail::STATIC_ASSERTION_FAILURE< (bool)(thrust::detail::depend_on_instantiation< InputIterator1, true> ::value)> )>  thrust_static_assert_typedef_239 __attribute((unused)); 
# 241
struct workaround { 
# 244
static OutputIterator parallel_path(execution_policy< DerivedPolicy>  &exec, InputIterator1 
# 245
first, InputIterator1 
# 246
last, InputIterator2 
# 247
stencil, OutputIterator 
# 248
output, Predicate 
# 249
pred) 
# 250
{ 
# 251
return copy_if_detail::copy_if(exec, first, last, stencil, output, pred); 
# 252
} 
# 255
static OutputIterator sequential_path(execution_policy< DerivedPolicy>  &, InputIterator1 
# 256
first, InputIterator1 
# 257
last, InputIterator2 
# 258
stencil, OutputIterator 
# 259
output, Predicate 
# 260
pred) 
# 261
{ 
# 262
return thrust::copy_if(thrust::seq, first, last, stencil, output, pred); 
# 263
} 
# 264
}; 
# 267
return (workaround::parallel_path)(exec, first, last, stencil, output, pred); 
# 271
} 
# 274
}
# 275
}
# 276
}
# 277
}
# 24 "/usr/local/cuda-8.0/include/thrust/detail/copy_if.inl"
namespace thrust { 
# 29
template< class DerivedPolicy, class 
# 30
InputIterator, class 
# 31
OutputIterator, class 
# 32
Predicate> OutputIterator 
# 34
copy_if(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator 
# 35
first, InputIterator 
# 36
last, OutputIterator 
# 37
result, Predicate 
# 38
pred) 
# 39
{ 
# 40
using system::detail::generic::copy_if;
# 41
return copy_if(detail::derived_cast(detail::strip_const(exec)), first, last, result, pred); 
# 42
} 
# 46
template< class DerivedPolicy, class 
# 47
InputIterator1, class 
# 48
InputIterator2, class 
# 49
OutputIterator, class 
# 50
Predicate> OutputIterator 
# 52
copy_if(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator1 
# 53
first, InputIterator1 
# 54
last, InputIterator2 
# 55
stencil, OutputIterator 
# 56
result, Predicate 
# 57
pred) 
# 58
{ 
# 59
using system::detail::generic::copy_if;
# 60
return copy_if(detail::derived_cast(detail::strip_const(exec)), first, last, stencil, result, pred); 
# 61
} 
# 64
template< class InputIterator, class 
# 65
OutputIterator, class 
# 66
Predicate> OutputIterator 
# 67
copy_if(InputIterator first, InputIterator 
# 68
last, OutputIterator 
# 69
result, Predicate 
# 70
pred) 
# 71
{ 
# 72
using system::detail::generic::select_system;
# 74
typedef typename iterator_system< InputIterator> ::type System1; 
# 75
typedef typename iterator_system< OutputIterator> ::type System2; 
# 77
System1 system1; 
# 78
System2 system2; 
# 80
return thrust::copy_if(select_system(system1, system2), first, last, result, pred); 
# 81
} 
# 84
template< class InputIterator1, class 
# 85
InputIterator2, class 
# 86
OutputIterator, class 
# 87
Predicate> OutputIterator 
# 88
copy_if(InputIterator1 first, InputIterator1 
# 89
last, InputIterator2 
# 90
stencil, OutputIterator 
# 91
result, Predicate 
# 92
pred) 
# 93
{ 
# 94
using system::detail::generic::select_system;
# 96
typedef typename iterator_system< InputIterator1> ::type System1; 
# 97
typedef typename iterator_system< InputIterator2> ::type System2; 
# 98
typedef typename iterator_system< OutputIterator> ::type System3; 
# 100
System1 system1; 
# 101
System2 system2; 
# 102
System3 system3; 
# 104
return thrust::copy_if(select_system(system1, system2, system3), first, last, stencil, result, pred); 
# 105
} 
# 108
}
# 29 "/usr/local/cuda-8.0/include/thrust/system/detail/sequential/stable_radix_sort.inl"
namespace thrust { 
# 31
namespace system { 
# 33
namespace detail { 
# 35
namespace sequential { 
# 37
namespace radix_sort_detail { 
# 41
template< class T> 
# 42
struct RadixEncoder : public identity< T>  { 
# 43
}; 
# 47
template<> struct RadixEncoder< char>  : public unary_function< char, unsigned char>  { 
# 50
unsigned char operator()(char x) const 
# 51
{ 
# 52
if (std::numeric_limits< char> ::is_signed) 
# 53
{ 
# 54
return x ^ ((static_cast< unsigned char>(1)) << (((8) * sizeof(unsigned char)) - (1))); 
# 55
} else 
# 57
{ 
# 58
return x; 
# 59
}  
# 60
} 
# 61
}; 
# 64
template<> struct RadixEncoder< signed char>  : public unary_function< signed char, unsigned char>  { 
# 67
unsigned char operator()(signed char x) const 
# 68
{ 
# 69
return x ^ ((static_cast< unsigned char>(1)) << (((8) * sizeof(unsigned char)) - (1))); 
# 70
} 
# 71
}; 
# 74
template<> struct RadixEncoder< short>  : public unary_function< short, unsigned short>  { 
# 77
unsigned short operator()(short x) const 
# 78
{ 
# 79
return x ^ ((static_cast< unsigned short>(1)) << (((8) * sizeof(unsigned short)) - (1))); 
# 80
} 
# 81
}; 
# 84
template<> struct RadixEncoder< int>  : public unary_function< int, unsigned>  { 
# 87
unsigned long operator()(long x) const 
# 88
{ 
# 89
return x ^ ((static_cast< unsigned>(1)) << (((8) * sizeof(unsigned)) - (1))); 
# 90
} 
# 91
}; 
# 94
template<> struct RadixEncoder< long>  : public unary_function< long, unsigned long>  { 
# 97
unsigned long operator()(long x) const 
# 98
{ 
# 99
return x ^ ((static_cast< unsigned long>(1)) << (((8) * sizeof(unsigned long)) - (1))); 
# 100
} 
# 101
}; 
# 104
template<> struct RadixEncoder< long long>  : public unary_function< long long, unsigned long long>  { 
# 107
unsigned long long operator()(long long x) const 
# 108
{ 
# 109
return x ^ ((static_cast< unsigned long long>(1)) << (((8) * sizeof(unsigned long long)) - (1))); 
# 110
} 
# 111
}; 
# 115
template<> struct RadixEncoder< float>  : public unary_function< float, unsigned>  { 
# 118
thrust::detail::uint32_t operator()(float x) const 
# 119
{ 
# 120
union { float f; thrust::detail::uint32_t i; } u; 
# 121
(u.f) = x; 
# 122
thrust::detail::uint32_t mask = (-(static_cast< thrust::detail::int32_t>((u.i) >> 31))) | ((static_cast< thrust::detail::uint32_t>(1)) << 31); 
# 123
return (u.i) ^ mask; 
# 124
} 
# 125
}; 
# 128
template<> struct RadixEncoder< double>  : public unary_function< double, unsigned long>  { 
# 131
thrust::detail::uint64_t operator()(double x) const 
# 132
{ 
# 133
union { double f; thrust::detail::uint64_t i; } u; 
# 134
(u.f) = x; 
# 135
thrust::detail::uint64_t mask = (-(static_cast< thrust::detail::int64_t>((u.i) >> 63))) | ((static_cast< thrust::detail::uint64_t>(1)) << 63); 
# 136
return (u.i) ^ mask; 
# 137
} 
# 138
}; 
# 142
template< unsigned RadixBits, class KeyType> 
# 143
struct bucket_functor { 
# 145
typedef RadixEncoder< KeyType>  Encoder; 
# 146
typedef typename RadixEncoder< KeyType> ::result_type EncodedType; 
# 147
typedef size_t result_type; 
# 148
static const EncodedType BitMask = (static_cast< EncodedType>((1 << RadixBits) - 1)); 
# 150
Encoder encode; 
# 151
EncodedType bit_shift; 
# 152
size_t *histogram; 
# 155
bucket_functor(EncodedType bit_shift, size_t *histogram) : encode(), bit_shift(bit_shift), histogram(histogram) 
# 159
{ } 
# 162
size_t operator()(KeyType key) 
# 163
{ 
# 164
const EncodedType x = (encode)(key); 
# 167
return ((histogram)[(x >> (bit_shift)) & BitMask])++; 
# 168
} 
# 169
}; 
# 172
template< unsigned RadixBits, class 
# 173
DerivedPolicy, class 
# 174
RandomAccessIterator1, class 
# 175
RandomAccessIterator2, class 
# 176
Integer> inline void 
# 178
radix_shuffle_n(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator1 
# 179
first, const size_t 
# 180
n, RandomAccessIterator2 
# 181
result, Integer 
# 182
bit_shift, size_t *
# 183
histogram) 
# 184
{ 
# 185
typedef typename iterator_value< RandomAccessIterator1> ::type KeyType; 
# 188
thrust::scatter(exec, first, first + n, thrust::make_transform_iterator(first, bucket_functor< RadixBits, typename iterator_value< RandomAccessIterator1> ::type> (bit_shift, histogram)), result); 
# 192
} 
# 195
template< unsigned RadixBits, class 
# 196
DerivedPolicy, class 
# 197
RandomAccessIterator1, class 
# 198
RandomAccessIterator2, class 
# 199
RandomAccessIterator3, class 
# 200
RandomAccessIterator4, class 
# 201
Integer> void 
# 203
radix_shuffle_n(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator1 
# 204
keys_first, RandomAccessIterator2 
# 205
values_first, const size_t 
# 206
n, RandomAccessIterator3 
# 207
keys_result, RandomAccessIterator4 
# 208
values_result, Integer 
# 209
bit_shift, size_t *
# 210
histogram) 
# 211
{ 
# 212
typedef typename iterator_value< RandomAccessIterator1> ::type KeyType; 
# 215
thrust::scatter(exec, thrust::make_zip_iterator(thrust::make_tuple(keys_first, values_first)), thrust::make_zip_iterator(thrust::make_tuple(keys_first + n, values_first + n)), thrust::make_transform_iterator(keys_first, bucket_functor< RadixBits, typename iterator_value< RandomAccessIterator1> ::type> (bit_shift, histogram)), thrust::make_zip_iterator(thrust::make_tuple(keys_result, values_result))); 
# 220
} 
# 223
template< unsigned RadixBits, bool 
# 224
HasValues, class 
# 225
DerivedPolicy, class 
# 226
RandomAccessIterator1, class 
# 227
RandomAccessIterator2, class 
# 228
RandomAccessIterator3, class 
# 229
RandomAccessIterator4> void 
# 231
radix_sort(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator1 
# 232
keys1, RandomAccessIterator2 
# 233
keys2, RandomAccessIterator3 
# 234
vals1, RandomAccessIterator4 
# 235
vals2, const size_t 
# 236
N) 
# 237
{ 
# 238
typedef typename iterator_value< RandomAccessIterator1> ::type KeyType; 
# 240
typedef RadixEncoder< typename iterator_value< RandomAccessIterator1> ::type>  Encoder; 
# 241
typedef typename RadixEncoder< typename iterator_value< RandomAccessIterator1> ::type> ::result_type EncodedType; 
# 243
const unsigned NumHistograms = ((((8) * sizeof(EncodedType)) + (RadixBits - (1))) / (RadixBits)); 
# 244
const unsigned HistogramSize = (1 << RadixBits); 
# 246
const EncodedType BitMask = (static_cast< EncodedType>((1 << RadixBits) - 1)); 
# 248
Encoder encode; 
# 251
size_t histograms[NumHistograms][HistogramSize] = {{(0)}}; 
# 254
bool skip_shuffle[NumHistograms] = {false}; 
# 257
bool flip = false; 
# 260
for (size_t i = (0); i < N; i++) 
# 261
{ 
# 262
const EncodedType x = encode(keys1[i]); 
# 264
for (unsigned j = (0); j < NumHistograms; j++) 
# 265
{ 
# 266
const EncodedType BitShift = RadixBits * j; 
# 267
(((histograms)[j])[(x >> BitShift) & BitMask])++; 
# 268
}  
# 269
}  
# 272
for (unsigned i = (0); i < NumHistograms; i++) 
# 273
{ 
# 274
size_t sum = (0); 
# 276
for (unsigned j = (0); j < HistogramSize; j++) 
# 277
{ 
# 278
size_t bin = ((histograms)[i])[j]; 
# 280
if (bin == N) { 
# 281
((skip_shuffle)[i]) = true; }  
# 283
(((histograms)[i])[j]) = sum; 
# 285
sum = (sum + bin); 
# 286
}  
# 287
}  
# 290
for (unsigned i = (0); i < NumHistograms; i++) 
# 291
{ 
# 292
const EncodedType BitShift = static_cast< EncodedType>(RadixBits * i); 
# 294
if (!((skip_shuffle)[i])) 
# 295
{ 
# 296
if (flip) 
# 297
{ 
# 298
if (HasValues) 
# 299
{ 
# 300
radix_shuffle_n< RadixBits> (exec, keys2, vals2, N, keys1, vals1, BitShift, (histograms)[i]); 
# 301
} else 
# 303
{ 
# 304
radix_shuffle_n< RadixBits> (exec, keys2, N, keys1, BitShift, (histograms)[i]); 
# 305
}  
# 306
} else 
# 308
{ 
# 309
if (HasValues) 
# 310
{ 
# 311
radix_shuffle_n< RadixBits> (exec, keys1, vals1, N, keys2, vals2, BitShift, (histograms)[i]); 
# 312
} else 
# 314
{ 
# 315
radix_shuffle_n< RadixBits> (exec, keys1, N, keys2, BitShift, (histograms)[i]); 
# 316
}  
# 317
}  
# 319
flip = (flip ? false : true); 
# 320
}  
# 321
}  
# 324
if (flip) 
# 325
{ 
# 326
thrust::copy(exec, keys2, keys2 + N, keys1); 
# 328
if (HasValues) 
# 329
{ 
# 330
thrust::copy(exec, vals2, vals2 + N, vals1); 
# 331
}  
# 332
}  
# 333
} 
# 338
template< size_t KeySize> 
# 339
struct radix_sort_dispatcher { 
# 341
}; 
# 344
template<> struct radix_sort_dispatcher< 1UL>  { 
# 346
template< class DerivedPolicy, class 
# 347
RandomAccessIterator1, class 
# 348
RandomAccessIterator2> void 
# 350
operator()(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator1 
# 351
keys1, RandomAccessIterator2 keys2, const size_t 
# 352
N) 
# 353
{ 
# 354
radix_sort_detail::radix_sort< 8, false> (exec, keys1, keys2, static_cast< int *>(0), static_cast< int *>(0), N); 
# 355
} 
# 357
template< class DerivedPolicy, class 
# 358
RandomAccessIterator1, class 
# 359
RandomAccessIterator2, class 
# 360
RandomAccessIterator3, class 
# 361
RandomAccessIterator4> void 
# 363
operator()(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator1 
# 364
keys1, RandomAccessIterator2 keys2, RandomAccessIterator3 
# 365
vals1, RandomAccessIterator4 vals2, const size_t 
# 366
N) 
# 367
{ 
# 368
radix_sort_detail::radix_sort< 8, true> (exec, keys1, keys2, vals1, vals2, N); 
# 369
} 
# 370
}; 
# 374
template<> struct radix_sort_dispatcher< 2UL>  { 
# 376
template< class DerivedPolicy, class 
# 377
RandomAccessIterator1, class 
# 378
RandomAccessIterator2> void 
# 380
operator()(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator1 
# 381
keys1, RandomAccessIterator2 keys2, const size_t 
# 382
N) 
# 383
{ 
# 388
const bool condition = N < (1 << 16); 
# 390
if (condition) 
# 391
{ 
# 392
radix_sort_detail::radix_sort< 8, false> (exec, keys1, keys2, static_cast< int *>(0), static_cast< int *>(0), N); 
# 393
} else 
# 395
{ 
# 396
radix_sort_detail::radix_sort< 16, false> (exec, keys1, keys2, static_cast< int *>(0), static_cast< int *>(0), N); 
# 397
}  
# 398
} 
# 401
template< class DerivedPolicy, class 
# 402
RandomAccessIterator1, class 
# 403
RandomAccessIterator2, class 
# 404
RandomAccessIterator3, class 
# 405
RandomAccessIterator4> void 
# 407
operator()(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator1 
# 408
keys1, RandomAccessIterator2 keys2, RandomAccessIterator3 
# 409
vals1, RandomAccessIterator4 vals2, const size_t 
# 410
N) 
# 411
{ 
# 416
const bool condition = N < (1 << 15); 
# 418
if (condition) 
# 419
{ 
# 420
radix_sort_detail::radix_sort< 8, true> (exec, keys1, keys2, vals1, vals2, N); 
# 421
} else 
# 423
{ 
# 424
radix_sort_detail::radix_sort< 16, true> (exec, keys1, keys2, vals1, vals2, N); 
# 425
}  
# 426
} 
# 427
}; 
# 431
template<> struct radix_sort_dispatcher< 4UL>  { 
# 433
template< class DerivedPolicy, class 
# 434
RandomAccessIterator1, class 
# 435
RandomAccessIterator2> void 
# 437
operator()(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator1 
# 438
keys1, RandomAccessIterator2 keys2, const size_t 
# 439
N) 
# 440
{ 
# 441
if (N < (1 << 22)) 
# 442
{ 
# 443
radix_sort_detail::radix_sort< 8, false> (exec, keys1, keys2, static_cast< int *>(0), static_cast< int *>(0), N); 
# 444
} else 
# 446
{ 
# 447
radix_sort_detail::radix_sort< 4, false> (exec, keys1, keys2, static_cast< int *>(0), static_cast< int *>(0), N); 
# 448
}  
# 449
} 
# 451
template< class DerivedPolicy, class 
# 452
RandomAccessIterator1, class 
# 453
RandomAccessIterator2, class 
# 454
RandomAccessIterator3, class 
# 455
RandomAccessIterator4> void 
# 457
operator()(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator1 
# 458
keys1, RandomAccessIterator2 keys2, RandomAccessIterator3 
# 459
vals1, RandomAccessIterator4 vals2, const size_t 
# 460
N) 
# 461
{ 
# 462
if (N < (1 << 22)) 
# 463
{ 
# 464
radix_sort_detail::radix_sort< 8, true> (exec, keys1, keys2, vals1, vals2, N); 
# 465
} else 
# 467
{ 
# 468
radix_sort_detail::radix_sort< 3, true> (exec, keys1, keys2, vals1, vals2, N); 
# 469
}  
# 470
} 
# 471
}; 
# 475
template<> struct radix_sort_dispatcher< 8UL>  { 
# 477
template< class DerivedPolicy, class 
# 478
RandomAccessIterator1, class 
# 479
RandomAccessIterator2> void 
# 481
operator()(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator1 
# 482
keys1, RandomAccessIterator2 keys2, const size_t 
# 483
N) 
# 484
{ 
# 485
if (N < (1 << 21)) 
# 486
{ 
# 487
radix_sort_detail::radix_sort< 8, false> (exec, keys1, keys2, static_cast< int *>(0), static_cast< int *>(0), N); 
# 488
} else 
# 490
{ 
# 491
radix_sort_detail::radix_sort< 4, false> (exec, keys1, keys2, static_cast< int *>(0), static_cast< int *>(0), N); 
# 492
}  
# 493
} 
# 495
template< class DerivedPolicy, class 
# 496
RandomAccessIterator1, class 
# 497
RandomAccessIterator2, class 
# 498
RandomAccessIterator3, class 
# 499
RandomAccessIterator4> void 
# 501
operator()(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator1 
# 502
keys1, RandomAccessIterator2 keys2, RandomAccessIterator3 
# 503
vals1, RandomAccessIterator4 vals2, const size_t 
# 504
N) 
# 505
{ 
# 506
if (N < (1 << 21)) 
# 507
{ 
# 508
radix_sort_detail::radix_sort< 8, true> (exec, keys1, keys2, vals1, vals2, N); 
# 509
} else 
# 511
{ 
# 512
radix_sort_detail::radix_sort< 3, true> (exec, keys1, keys2, vals1, vals2, N); 
# 513
}  
# 514
} 
# 515
}; 
# 518
template< class DerivedPolicy, class 
# 519
RandomAccessIterator1, class 
# 520
RandomAccessIterator2> void 
# 522
radix_sort(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator1 
# 523
keys1, RandomAccessIterator2 
# 524
keys2, const size_t 
# 525
N) 
# 526
{ 
# 527
typedef typename iterator_value< RandomAccessIterator1> ::type KeyType; 
# 528
radix_sort_dispatcher< sizeof(typename iterator_value< RandomAccessIterator1> ::type)> ()(exec, keys1, keys2, N); 
# 529
} 
# 532
template< class DerivedPolicy, class 
# 533
RandomAccessIterator1, class 
# 534
RandomAccessIterator2, class 
# 535
RandomAccessIterator3, class 
# 536
RandomAccessIterator4> void 
# 538
radix_sort(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator1 
# 539
keys1, RandomAccessIterator2 
# 540
keys2, RandomAccessIterator3 
# 541
vals1, RandomAccessIterator4 
# 542
vals2, const size_t 
# 543
N) 
# 544
{ 
# 545
typedef typename iterator_value< RandomAccessIterator1> ::type KeyType; 
# 546
radix_sort_dispatcher< sizeof(typename iterator_value< RandomAccessIterator1> ::type)> ()(exec, keys1, keys2, vals1, vals2, N); 
# 547
} 
# 550
}
# 553
template< class DerivedPolicy, class 
# 554
RandomAccessIterator> void 
# 556
stable_radix_sort(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator 
# 557
first, RandomAccessIterator 
# 558
last) 
# 559
{ 
# 560
typedef typename iterator_value< RandomAccessIterator> ::type KeyType; 
# 562
size_t N = last - first; 
# 564
thrust::detail::temporary_array< typename iterator_value< RandomAccessIterator> ::type, DerivedPolicy>  temp(exec, N); 
# 566
radix_sort_detail::radix_sort(exec, first, (temp.begin()), N); 
# 567
} 
# 570
template< class DerivedPolicy, class 
# 571
RandomAccessIterator1, class 
# 572
RandomAccessIterator2> void 
# 574
stable_radix_sort_by_key(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator1 
# 575
first1, RandomAccessIterator1 
# 576
last1, RandomAccessIterator2 
# 577
first2) 
# 578
{ 
# 579
typedef typename iterator_value< RandomAccessIterator1> ::type KeyType; 
# 580
typedef typename iterator_value< RandomAccessIterator2> ::type ValueType; 
# 582
size_t N = last1 - first1; 
# 584
thrust::detail::temporary_array< typename iterator_value< RandomAccessIterator1> ::type, DerivedPolicy>  temp1(exec, N); 
# 585
thrust::detail::temporary_array< typename iterator_value< RandomAccessIterator2> ::type, DerivedPolicy>  temp2(exec, N); 
# 587
radix_sort_detail::radix_sort(exec, first1, (temp1.begin()), first2, (temp2.begin()), N); 
# 588
} 
# 591
}
# 592
}
# 593
}
# 594
}
# 30 "/usr/local/cuda-8.0/include/thrust/system/detail/sequential/partition.h"
namespace thrust { 
# 32
namespace detail { 
# 37
template< class , class > class temporary_array; 
# 40
}
# 42
namespace system { 
# 44
namespace detail { 
# 46
namespace sequential { 
# 51
template< class ForwardIterator1, class 
# 52
ForwardIterator2> void 
# 54
iter_swap(ForwardIterator1 iter1, ForwardIterator2 iter2) 
# 55
{ 
# 57
using namespace thrust::detail;
# 59
typedef typename iterator_value< ForwardIterator1> ::type T; 
# 61
T temp = *iter1; 
# 62
(*iter1) = (*iter2); 
# 63
(*iter2) = temp; 
# 64
} 
# 68
template< class DerivedPolicy, class 
# 69
ForwardIterator, class 
# 70
Predicate> ForwardIterator 
# 72
partition(execution_policy< DerivedPolicy>  &, ForwardIterator 
# 73
first, ForwardIterator 
# 74
last, Predicate 
# 75
pred) 
# 76
{ 
# 77
if (first == last) { 
# 78
return first; }  
# 84
thrust::detail::wrapped_function< Predicate, bool>  wrapped_pred(pred); 
# 86
while (wrapped_pred(*first)) 
# 87
{ 
# 88
if ((++first) == last) { 
# 89
return first; }  
# 90
}  
# 92
ForwardIterator next = first; 
# 94
while ((++next) != last) 
# 95
{ 
# 96
if (wrapped_pred(*next)) 
# 97
{ 
# 98
iter_swap(first, next); 
# 99
++first; 
# 100
}  
# 101
}  
# 103
return first; 
# 104
} 
# 108
template< class DerivedPolicy, class 
# 109
ForwardIterator, class 
# 110
InputIterator, class 
# 111
Predicate> ForwardIterator 
# 113
partition(execution_policy< DerivedPolicy>  &, ForwardIterator 
# 114
first, ForwardIterator 
# 115
last, InputIterator 
# 116
stencil_first, Predicate 
# 117
pred) 
# 118
{ 
# 119
if (first == last) { 
# 120
return first; }  
# 126
thrust::detail::wrapped_function< Predicate, bool>  wrapped_pred(pred); 
# 128
while (wrapped_pred(*stencil_first)) 
# 129
{ 
# 130
++stencil_first; 
# 131
if ((++first) == last) 
# 132
{ 
# 133
return first; 
# 134
}  
# 135
}  
# 137
ForwardIterator next = first; 
# 140
++stencil_first; 
# 142
while ((++next) != last) 
# 143
{ 
# 144
if (wrapped_pred(*stencil_first)) 
# 145
{ 
# 146
iter_swap(first, next); 
# 147
++first; 
# 148
}  
# 150
++stencil_first; 
# 151
}  
# 153
return first; 
# 154
} 
# 158
template< class DerivedPolicy, class 
# 159
ForwardIterator, class 
# 160
Predicate> ForwardIterator 
# 162
stable_partition(execution_policy< DerivedPolicy>  &exec, ForwardIterator 
# 163
first, ForwardIterator 
# 164
last, Predicate 
# 165
pred) 
# 166
{ 
# 171
thrust::detail::wrapped_function< Predicate, bool>  wrapped_pred(pred); 
# 173
typedef typename iterator_value< ForwardIterator> ::type T; 
# 175
typedef thrust::detail::temporary_array< typename iterator_value< ForwardIterator> ::type, DerivedPolicy>  TempRange; 
# 176
typedef typename thrust::detail::temporary_array< typename iterator_value< ForwardIterator> ::type, DerivedPolicy> ::iterator TempIterator; 
# 178
TempRange temp(exec, first, last); 
# 180
for (TempIterator iter = (temp.begin()); iter != (temp.end()); ++iter) 
# 181
{ 
# 182
if (wrapped_pred(*iter)) 
# 183
{ 
# 184
(*first) = (*iter); 
# 185
++first; 
# 186
}  
# 187
}  
# 189
ForwardIterator middle = first; 
# 191
for (TempIterator iter = (temp.begin()); iter != (temp.end()); ++iter) 
# 192
{ 
# 193
if (!wrapped_pred(*iter)) 
# 194
{ 
# 195
(*first) = (*iter); 
# 196
++first; 
# 197
}  
# 198
}  
# 200
return middle; 
# 201
} 
# 205
template< class DerivedPolicy, class 
# 206
ForwardIterator, class 
# 207
InputIterator, class 
# 208
Predicate> ForwardIterator 
# 210
stable_partition(execution_policy< DerivedPolicy>  &exec, ForwardIterator 
# 211
first, ForwardIterator 
# 212
last, InputIterator 
# 213
stencil, Predicate 
# 214
pred) 
# 215
{ 
# 220
thrust::detail::wrapped_function< Predicate, bool>  wrapped_pred(pred); 
# 222
typedef typename iterator_value< ForwardIterator> ::type T; 
# 224
typedef thrust::detail::temporary_array< typename iterator_value< ForwardIterator> ::type, DerivedPolicy>  TempRange; 
# 225
typedef typename thrust::detail::temporary_array< typename iterator_value< ForwardIterator> ::type, DerivedPolicy> ::iterator TempIterator; 
# 227
TempRange temp(exec, first, last); 
# 229
InputIterator stencil_iter = stencil; 
# 230
for (TempIterator iter = (temp.begin()); iter != (temp.end()); (++iter), (++stencil_iter)) 
# 231
{ 
# 232
if (wrapped_pred(*stencil_iter)) 
# 233
{ 
# 234
(*first) = (*iter); 
# 235
++first; 
# 236
}  
# 237
}  
# 239
ForwardIterator middle = first; 
# 240
stencil_iter = stencil; 
# 242
for (TempIterator iter = (temp.begin()); iter != (temp.end()); (++iter), (++stencil_iter)) 
# 243
{ 
# 244
if (!wrapped_pred(*stencil_iter)) 
# 245
{ 
# 246
(*first) = (*iter); 
# 247
++first; 
# 248
}  
# 249
}  
# 251
return middle; 
# 252
} 
# 256
template< class DerivedPolicy, class 
# 257
InputIterator, class 
# 258
OutputIterator1, class 
# 259
OutputIterator2, class 
# 260
Predicate> pair< OutputIterator1, OutputIterator2>  
# 263
stable_partition_copy(execution_policy< DerivedPolicy>  &, InputIterator 
# 264
first, InputIterator 
# 265
last, OutputIterator1 
# 266
out_true, OutputIterator2 
# 267
out_false, Predicate 
# 268
pred) 
# 269
{ 
# 274
thrust::detail::wrapped_function< Predicate, bool>  wrapped_pred(pred); 
# 276
for (; first != last; ++first) 
# 277
{ 
# 278
if (wrapped_pred(*first)) 
# 279
{ 
# 280
(*out_true) = (*first); 
# 281
++out_true; 
# 282
} else 
# 284
{ 
# 285
(*out_false) = (*first); 
# 286
++out_false; 
# 287
}  
# 288
}  
# 290
return thrust::make_pair(out_true, out_false); 
# 291
} 
# 295
template< class DerivedPolicy, class 
# 296
InputIterator1, class 
# 297
InputIterator2, class 
# 298
OutputIterator1, class 
# 299
OutputIterator2, class 
# 300
Predicate> pair< OutputIterator1, OutputIterator2>  
# 303
stable_partition_copy(execution_policy< DerivedPolicy>  &, InputIterator1 
# 304
first, InputIterator1 
# 305
last, InputIterator2 
# 306
stencil, OutputIterator1 
# 307
out_true, OutputIterator2 
# 308
out_false, Predicate 
# 309
pred) 
# 310
{ 
# 315
thrust::detail::wrapped_function< Predicate, bool>  wrapped_pred(pred); 
# 317
for (; first != last; (++first), (++stencil)) 
# 318
{ 
# 319
if (wrapped_pred(*stencil)) 
# 320
{ 
# 321
(*out_true) = (*first); 
# 322
++out_true; 
# 323
} else 
# 325
{ 
# 326
(*out_false) = (*first); 
# 327
++out_false; 
# 328
}  
# 329
}  
# 331
return thrust::make_pair(out_true, out_false); 
# 332
} 
# 335
}
# 336
}
# 337
}
# 338
}
# 27 "/usr/local/cuda-8.0/include/thrust/system/detail/sequential/stable_primitive_sort.inl"
namespace thrust { 
# 29
namespace system { 
# 31
namespace detail { 
# 33
namespace sequential { 
# 35
namespace stable_primitive_sort_detail { 
# 39
template< class Iterator> 
# 40
struct enable_if_bool_sort : public thrust::detail::enable_if< thrust::detail::is_same< bool, typename iterator_value< Iterator> ::type> ::value>  { 
# 47
}; 
# 50
template< class Iterator> 
# 51
struct disable_if_bool_sort : public thrust::detail::disable_if< thrust::detail::is_same< bool, typename iterator_value< Iterator> ::type> ::value>  { 
# 58
}; 
# 62
template< class DerivedPolicy, class 
# 63
RandomAccessIterator> typename enable_if_bool_sort< RandomAccessIterator> ::type 
# 66
stable_primitive_sort(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator 
# 67
first, RandomAccessIterator last) 
# 68
{ 
# 71
sequential::stable_partition(exec, first, last, logical_not< bool> ()); 
# 72
} 
# 75
template< class DerivedPolicy, class 
# 76
RandomAccessIterator> typename disable_if_bool_sort< RandomAccessIterator> ::type 
# 79
stable_primitive_sort(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator 
# 80
first, RandomAccessIterator last) 
# 81
{ 
# 83
sequential::stable_radix_sort(exec, first, last); 
# 84
} 
# 87
struct logical_not_first { 
# 89
template< class Tuple> bool 
# 91
operator()(Tuple t) 
# 92
{ 
# 93
return !thrust::get< 0> (t); 
# 94
} 
# 95
}; 
# 98
template< class DerivedPolicy, class 
# 99
RandomAccessIterator1, class 
# 100
RandomAccessIterator2> typename enable_if_bool_sort< RandomAccessIterator1> ::type 
# 103
stable_primitive_sort_by_key(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator1 
# 104
keys_first, RandomAccessIterator1 keys_last, RandomAccessIterator2 
# 105
values_first) 
# 106
{ 
# 109
sequential::stable_partition(exec, thrust::make_zip_iterator(thrust::make_tuple(keys_first, values_first)), thrust::make_zip_iterator(thrust::make_tuple(keys_last, values_first)), logical_not_first()); 
# 113
} 
# 116
template< class DerivedPolicy, class 
# 117
RandomAccessIterator1, class 
# 118
RandomAccessIterator2> typename disable_if_bool_sort< RandomAccessIterator1> ::type 
# 121
stable_primitive_sort_by_key(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator1 
# 122
keys_first, RandomAccessIterator1 keys_last, RandomAccessIterator2 
# 123
values_first) 
# 124
{ 
# 126
sequential::stable_radix_sort_by_key(exec, keys_first, keys_last, values_first); 
# 127
} 
# 130
}
# 133
template< class DerivedPolicy, class 
# 134
RandomAccessIterator> void 
# 136
stable_primitive_sort(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator 
# 137
first, RandomAccessIterator 
# 138
last) 
# 139
{ 
# 140
stable_primitive_sort_detail::stable_primitive_sort(exec, first, last); 
# 141
} 
# 144
template< class DerivedPolicy, class 
# 145
RandomAccessIterator1, class 
# 146
RandomAccessIterator2> void 
# 148
stable_primitive_sort_by_key(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator1 
# 149
keys_first, RandomAccessIterator1 
# 150
keys_last, RandomAccessIterator2 
# 151
values_first) 
# 152
{ 
# 153
stable_primitive_sort_detail::stable_primitive_sort_by_key(exec, keys_first, keys_last, values_first); 
# 154
} 
# 157
}
# 158
}
# 159
}
# 160
}
# 24 "/usr/local/cuda-8.0/include/thrust/system/detail/sequential/sort.inl"
namespace thrust { 
# 26
namespace system { 
# 28
namespace detail { 
# 30
namespace sequential { 
# 32
namespace sort_detail { 
# 41
template< class KeyType, class Compare> 
# 42
struct needs_reverse : public thrust::detail::integral_constant< bool, thrust::detail::is_same< Compare, greater< KeyType> > ::value>  { 
# 47
}; 
# 50
template< class DerivedPolicy, class 
# 51
RandomAccessIterator, class 
# 52
StrictWeakOrdering> void 
# 54
stable_sort(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator 
# 55
first, RandomAccessIterator 
# 56
last, StrictWeakOrdering 
# 57
comp, thrust::detail::true_type) 
# 59
{ 
# 60
sequential::stable_primitive_sort(exec, first, last); 
# 63
typedef typename iterator_traits< RandomAccessIterator> ::value_type KeyType; 
# 65
if (needs_reverse< typename iterator_traits< RandomAccessIterator> ::value_type, StrictWeakOrdering> ::value) 
# 66
{ 
# 67
thrust::reverse(exec, first, last); 
# 68
}  
# 69
} 
# 72
template< class DerivedPolicy, class 
# 73
RandomAccessIterator1, class 
# 74
RandomAccessIterator2, class 
# 75
StrictWeakOrdering> void 
# 77
stable_sort_by_key(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator1 
# 78
first1, RandomAccessIterator1 
# 79
last1, RandomAccessIterator2 
# 80
first2, StrictWeakOrdering 
# 81
comp, thrust::detail::true_type) 
# 83
{ 
# 85
typedef typename iterator_traits< RandomAccessIterator1> ::value_type KeyType; 
# 88
if (needs_reverse< typename iterator_traits< RandomAccessIterator1> ::value_type, StrictWeakOrdering> ::value) 
# 89
{ 
# 90
thrust::reverse(exec, first1, last1); 
# 91
thrust::reverse(exec, first2, first2 + (last1 - first1)); 
# 92
}  
# 94
sequential::stable_primitive_sort_by_key(exec, first1, last1, first2); 
# 96
if (needs_reverse< typename iterator_traits< RandomAccessIterator1> ::value_type, StrictWeakOrdering> ::value) 
# 97
{ 
# 98
thrust::reverse(exec, first1, last1); 
# 99
thrust::reverse(exec, first2, first2 + (last1 - first1)); 
# 100
}  
# 101
} 
# 109
template< class DerivedPolicy, class 
# 110
RandomAccessIterator, class 
# 111
StrictWeakOrdering> void 
# 113
stable_sort(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator 
# 114
first, RandomAccessIterator 
# 115
last, StrictWeakOrdering 
# 116
comp, thrust::detail::false_type) 
# 118
{ 
# 119
sequential::stable_merge_sort(exec, first, last, comp); 
# 120
} 
# 123
template< class DerivedPolicy, class 
# 124
RandomAccessIterator1, class 
# 125
RandomAccessIterator2, class 
# 126
StrictWeakOrdering> void 
# 128
stable_sort_by_key(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator1 
# 129
first1, RandomAccessIterator1 
# 130
last1, RandomAccessIterator2 
# 131
first2, StrictWeakOrdering 
# 132
comp, thrust::detail::false_type) 
# 134
{ 
# 135
sequential::stable_merge_sort_by_key(exec, first1, last1, first2, comp); 
# 136
} 
# 139
template< class KeyType, class Compare> 
# 140
struct use_primitive_sort : public thrust::detail::and_< thrust::detail::is_arithmetic< KeyType> , thrust::detail::or_< thrust::detail::is_same< Compare, less< KeyType> > , thrust::detail::is_same< Compare, greater< KeyType> > > >  { 
# 148
}; 
# 151
}
# 154
template< class DerivedPolicy, class 
# 155
RandomAccessIterator, class 
# 156
StrictWeakOrdering> void 
# 158
stable_sort(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator 
# 159
first, RandomAccessIterator 
# 160
last, StrictWeakOrdering 
# 161
comp) 
# 162
{ 
# 163
typedef typename iterator_traits< RandomAccessIterator> ::value_type KeyType; 
# 167
sort_detail::use_primitive_sort< typename iterator_traits< RandomAccessIterator> ::value_type, StrictWeakOrdering>  use_primitive_sort; 
# 172
sort_detail::stable_sort(exec, first, last, comp, use_primitive_sort); 
# 173
} 
# 176
template< class DerivedPolicy, class 
# 177
RandomAccessIterator1, class 
# 178
RandomAccessIterator2, class 
# 179
StrictWeakOrdering> void 
# 181
stable_sort_by_key(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator1 
# 182
first1, RandomAccessIterator1 
# 183
last1, RandomAccessIterator2 
# 184
first2, StrictWeakOrdering 
# 185
comp) 
# 186
{ 
# 187
typedef typename iterator_traits< RandomAccessIterator1> ::value_type KeyType; 
# 191
sort_detail::use_primitive_sort< typename iterator_traits< RandomAccessIterator1> ::value_type, StrictWeakOrdering>  use_primitive_sort; 
# 196
sort_detail::stable_sort_by_key(exec, first1, last1, first2, comp, use_primitive_sort); 
# 197
} 
# 200
}
# 201
}
# 202
}
# 203
}
# 22 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/sort.h"
namespace thrust { 
# 24
namespace system { 
# 26
namespace cuda { 
# 28
namespace detail { 
# 32
template< class DerivedPolicy, class 
# 33
RandomAccessIterator, class 
# 34
StrictWeakOrdering> void 
# 32
stable_sort(execution_policy< DerivedPolicy>  & exec, RandomAccessIterator first, RandomAccessIterator last, StrictWeakOrdering comp); 
# 42
template< class DerivedPolicy, class 
# 43
RandomAccessIterator1, class 
# 44
RandomAccessIterator2, class 
# 45
StrictWeakOrdering> void 
# 42
stable_sort_by_key(execution_policy< DerivedPolicy>  & exec, RandomAccessIterator1 keys_first, RandomAccessIterator1 keys_last, RandomAccessIterator2 values_first, StrictWeakOrdering comp); 
# 54
}
# 55
}
# 56
}
# 57
}
# 27 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/detail/stable_merge_sort.h"
namespace thrust { 
# 29
namespace system { 
# 31
namespace cuda { 
# 33
namespace detail { 
# 35
namespace detail { 
# 38
template< class DerivedPolicy, class 
# 39
RandomAccessIterator, class 
# 40
StrictWeakOrdering> void 
# 38
stable_merge_sort(execution_policy< DerivedPolicy>  & exec, RandomAccessIterator first, RandomAccessIterator last, StrictWeakOrdering comp); 
# 47
template< class DerivedPolicy, class 
# 48
RandomAccessIterator1, class 
# 49
RandomAccessIterator2, class 
# 50
StrictWeakOrdering> void 
# 47
stable_merge_sort_by_key(execution_policy< DerivedPolicy>  & exec, RandomAccessIterator1 keys_begin, RandomAccessIterator1 keys_end, RandomAccessIterator2 values_begin, StrictWeakOrdering comp); 
# 58
}
# 59
}
# 60
}
# 61
}
# 62
}
# 22 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/detail/stable_sort_each.h"
namespace thrust { 
# 24
namespace system { 
# 26
namespace cuda { 
# 28
namespace detail { 
# 30
namespace detail { 
# 34
template< unsigned work_per_thread, class 
# 35
DerivedPolicy, class 
# 36
Context, class 
# 37
RandomAccessIterator1, class 
# 38
Pointer, class 
# 39
RandomAccessIterator2, class 
# 40
Compare> void 
# 34
stable_sort_each_copy(execution_policy< DerivedPolicy>  & exec, Context context, unsigned block_size, RandomAccessIterator1 first, RandomAccessIterator1 last, Pointer vitual_smem, RandomAccessIterator2 result, Compare comp); 
# 51
}
# 52
}
# 53
}
# 54
}
# 55
}
# 32 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/block/copy.h"
namespace thrust { 
# 34
namespace system { 
# 36
namespace cuda { 
# 38
namespace detail { 
# 40
namespace block { 
# 43
namespace trivial_copy_detail { 
# 47
template< class Size> __attribute__((unused)) inline pair< Size, Size>  
# 48
quotient_and_remainder(Size n, Size d) 
# 49
{int volatile ___ = 1;(void)n;(void)d;
# 53
::exit(___);}
#if 0
# 49
{ 
# 50
Size quotient = n / d; 
# 51
Size remainder = n - (d * quotient); 
# 52
return thrust::make_pair(quotient, remainder); 
# 53
} 
#endif
# 57 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/block/copy.h"
template< class Context, class 
# 58
T> 
# 59
__attribute((always_inline)) __attribute__((unused)) inline void 
# 60
aligned_copy(Context context, T *dst, const T *src, unsigned num_elements) 
# 61
{int volatile ___ = 1;(void)context;(void)dst;(void)src;(void)num_elements;
# 68
::exit(___);}
#if 0
# 61
{ 
# 62
for (unsigned i = (context.thread_index()); i < num_elements; i += (context.block_dimension())) 
# 65
{ 
# 66
(dst[i]) = (src[i]); 
# 67
}  
# 68
} 
#endif
# 71 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/block/copy.h"
}
# 74
template< class Context> 
# 75
__attribute((always_inline)) __attribute__((unused)) inline void 
# 76
trivial_copy(Context context, void *destination_, const void *source_, size_t num_bytes) 
# 77
{int volatile ___ = 1;(void)context;(void)destination_;(void)source_;(void)num_bytes;
# 125
::exit(___);}
#if 0
# 77
{ 
# 79
char *destination = reinterpret_cast< char *>(destination_); 
# 80
const char *source = reinterpret_cast< const char *>(source_); 
# 93
if ((((reinterpret_cast< size_t>(destination)) % sizeof(uint2)) != (0)) || (((reinterpret_cast< size_t>(source)) % sizeof(uint2)) != (0))) 
# 94
{ 
# 95
for (unsigned i = (context.thread_index()); i < num_bytes; i += (context.block_dimension())) 
# 96
{ 
# 97
(destination[i]) = (source[i]); 
# 98
}  
# 99
} else 
# 101
{ 
# 106
const pair< unsigned long, unsigned long>  num_wide_elements_and_remainder_bytes = trivial_copy_detail::quotient_and_remainder(num_bytes, sizeof(int2)); 
# 109
trivial_copy_detail::aligned_copy(context, reinterpret_cast< int2 *>(destination), reinterpret_cast< const int2 *>(source), num_wide_elements_and_remainder_bytes.first); 
# 120
const char *remainder_first = reinterpret_cast< const char *>(source + (sizeof(int2) * (num_wide_elements_and_remainder_bytes.first))); 
# 121
char *remainder_result = reinterpret_cast< char *>(destination + (sizeof(int2) * (num_wide_elements_and_remainder_bytes.first))); 
# 123
trivial_copy_detail::aligned_copy(context, remainder_result, remainder_first, num_wide_elements_and_remainder_bytes.second); 
# 124
}  
# 125
} 
#endif
# 128 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/block/copy.h"
namespace detail { 
# 130
namespace dispatch { 
# 133
template< class Context, class 
# 134
RandomAccessIterator1, class 
# 135
RandomAccessIterator2> 
# 136
__attribute((always_inline)) __attribute__((unused)) inline RandomAccessIterator2 
# 137
copy(Context context, RandomAccessIterator1 
# 138
first, RandomAccessIterator1 
# 139
last, RandomAccessIterator2 
# 140
result, thrust::detail::true_type 
# 141
is_trivial_copy) 
# 142
{int volatile ___ = 1;(void)context;(void)first;(void)last;(void)result;(void)is_trivial_copy;
# 151
::exit(___);}
#if 0
# 142
{ 
# 143
typedef typename iterator_value< RandomAccessIterator1> ::type T; 
# 145
const T *src = (&thrust::raw_reference_cast(*first)); 
# 146
T *dst = (&thrust::raw_reference_cast(*result)); 
# 148
size_t n = last - first; 
# 149
block::trivial_copy(context, dst, src, n * sizeof(T)); 
# 150
return result + n; 
# 151
} 
#endif
# 153 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/block/copy.h"
template< class Context, class 
# 154
RandomAccessIterator1, class 
# 155
RandomAccessIterator2> 
# 156
__attribute((always_inline)) __attribute__((unused)) inline RandomAccessIterator2 
# 157
copy(Context context, RandomAccessIterator1 
# 158
first, RandomAccessIterator1 
# 159
last, RandomAccessIterator2 
# 160
result, thrust::detail::false_type 
# 161
is_trivial_copy) 
# 162
{int volatile ___ = 1;(void)context;(void)first;(void)last;(void)result;(void)is_trivial_copy;
# 178
::exit(___);}
#if 0
# 162
{ 
# 163
RandomAccessIterator2 end_of_output = result + (last - first); 
# 166
first += (context.thread_index()); 
# 167
result += (context.thread_index()); 
# 169
for (; first < last; (first += (context.block_dimension())), (result += (context.block_dimension()))) 
# 173
{ 
# 174
thrust::raw_reference_cast(*result) = thrust::raw_reference_cast(*first); 
# 175
}  
# 177
return end_of_output; 
# 178
} 
#endif
# 180 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/block/copy.h"
}
# 181
}
# 183
template< class Context, class 
# 184
RandomAccessIterator1, class 
# 185
RandomAccessIterator2> 
# 186
__attribute((always_inline)) __attribute__((unused)) inline RandomAccessIterator2 
# 187
copy(Context context, RandomAccessIterator1 
# 188
first, RandomAccessIterator1 
# 189
last, RandomAccessIterator2 
# 190
result) 
# 191
{int volatile ___ = 1;(void)context;(void)first;(void)last;(void)result;
# 200
::exit(___);}
#if 0
# 191
{ 
# 192
return detail::dispatch::copy(context, first, last, result, thrust::detail::false_type()); 
# 200
} 
#endif
# 203 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/block/copy.h"
template< class Context, class RandomAccessIterator1, class Size, class RandomAccessIterator2> __attribute__((unused)) inline RandomAccessIterator2 
# 205
async_copy_n(Context &ctx, RandomAccessIterator1 first, Size n, RandomAccessIterator2 result) 
# 206
{int volatile ___ = 1;(void)ctx;(void)first;(void)n;(void)result;
# 213
::exit(___);}
#if 0
# 206
{ 
# 207
for (Size i = (ctx.thread_index()); i < n; i += (ctx.block_dimension())) 
# 208
{ 
# 209
thrust::raw_reference_cast(result[i]) = thrust::raw_reference_cast(first[i]); 
# 210
}  
# 212
return result + n; 
# 213
} 
#endif
# 216 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/block/copy.h"
template< class Context, class RandomAccessIterator1, class Size, class RandomAccessIterator2> __attribute__((unused)) inline RandomAccessIterator2 
# 218
copy_n(Context &ctx, RandomAccessIterator1 first, Size n, RandomAccessIterator2 result) 
# 219
{int volatile ___ = 1;(void)ctx;(void)first;(void)n;(void)result;
# 224
::exit(___);}
#if 0
# 219
{ 
# 220
result = async_copy_n(ctx, first, n, result); 
# 221
(ctx.barrier()); 
# 223
return result; 
# 224
} 
#endif
# 227 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/block/copy.h"
template< unsigned work_per_thread, class Context, class RandomAccessIterator1, class Size, class RandomAccessIterator2> __attribute__((unused)) inline RandomAccessIterator2 
# 229
async_copy_n_global_to_shared(Context &ctx, RandomAccessIterator1 first, Size n, RandomAccessIterator2 result) 
# 230
{int volatile ___ = 1;(void)ctx;(void)first;(void)n;(void)result;
# 277
::exit(___);}
#if 0
# 230
{ 
# 231
typedef typename iterator_value< RandomAccessIterator1> ::type value_type; 
# 234
value_type reg[work_per_thread]; 
# 237
if (n >= ((ctx.block_dimension()) * work_per_thread)) 
# 238
{ 
# 239
for (unsigned i = (0); i < work_per_thread; ++i) 
# 240
{ 
# 241
unsigned idx = ((ctx.block_dimension()) * i) + (ctx.thread_index()); 
# 243
((reg)[i]) = thrust::raw_reference_cast(first[idx]); 
# 244
}  
# 245
} else 
# 247
{ 
# 248
for (unsigned i = (0); i < work_per_thread; ++i) 
# 249
{ 
# 250
unsigned idx = ((ctx.block_dimension()) * i) + (ctx.thread_index()); 
# 252
if (idx < n) { ((reg)[i]) = thrust::raw_reference_cast(first[idx]); }  
# 253
}  
# 254
}  
# 257
if (n >= ((ctx.block_dimension()) * work_per_thread)) 
# 258
{ 
# 259
for (unsigned i = (0); i < work_per_thread; ++i) 
# 260
{ 
# 261
unsigned idx = ((ctx.block_dimension()) * i) + (ctx.thread_index()); 
# 263
thrust::raw_reference_cast(result[idx]) = ((reg)[i]); 
# 264
}  
# 265
} else 
# 267
{ 
# 268
for (unsigned i = (0); i < work_per_thread; ++i) 
# 269
{ 
# 270
unsigned idx = ((ctx.block_dimension()) * i) + (ctx.thread_index()); 
# 272
if (idx < n) { thrust::raw_reference_cast(result[idx]) = ((reg)[i]); }  
# 273
}  
# 274
}  
# 276
return result + n; 
# 277
} 
#endif
# 280 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/block/copy.h"
template< unsigned work_per_thread, class Context, class RandomAccessIterator1, class Size, class RandomAccessIterator2> __attribute__((unused)) RandomAccessIterator2 
# 282
copy_n_global_to_shared(Context &ctx, RandomAccessIterator1 first, Size n, RandomAccessIterator2 result) 
# 283
{int volatile ___ = 1;(void)ctx;(void)first;(void)n;(void)result;
# 289
::exit(___);}
#if 0
# 283
{ 
# 284
result = async_copy_n_global_to_shared< work_per_thread> (ctx, first, n, result); 
# 286
(ctx.barrier()); 
# 288
return result + n; 
# 289
} 
#endif
# 292 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/block/copy.h"
} namespace __T0 = block;
# 293
}
# 294
}
# 295
}
# 296
}
# 22 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/detail/merge.h"
namespace thrust { 
# 24
namespace system { 
# 26
namespace cuda { 
# 28
namespace detail { 
# 30
namespace detail { 
# 35
template< unsigned result_size_bound, class Iterator1, class Iterator2, class Iterator3, class Compare> __attribute__((unused)) void 
# 37
sequential_bounded_merge(Iterator1 first1, Iterator1 last1, Iterator2 
# 38
first2, Iterator2 last2, Iterator3 
# 39
result, Compare 
# 40
comp) 
# 41
{int volatile ___ = 1;(void)first1;(void)last1;(void)first2;(void)last2;(void)result;(void)comp;
# 82
::exit(___);}
#if 0
# 41
{ 
# 45
for (unsigned i = (0); i < result_size_bound; (++i), (++result)) 
# 46
{ 
# 47
bool p = (first2 >= last2) || ((first1 < last1) && (!comp(*first2, *first1))); 
# 49
(*result) = (p ? *first1 : (*first2)); 
# 51
if (p) 
# 52
{ 
# 53
++first1; 
# 54
} else 
# 56
{ 
# 57
++first2; 
# 58
}  
# 59
}  
# 82
} 
#endif
# 85 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/detail/merge.h"
template< class Size, class Iterator1, class Iterator2, class Compare> __attribute__((unused)) Size 
# 87
merge_path(Size pos, Iterator1 first1, Size n1, Iterator2 first2, Size n2, Compare comp) 
# 88
{int volatile ___ = 1;(void)pos;(void)first1;(void)n1;(void)first2;(void)n2;(void)comp;
# 106
::exit(___);}
#if 0
# 88
{ 
# 89
Size begin = (pos >= n2) ? pos - n2 : ((Size)0); 
# 90
Size end = thrust::min< Size> (pos, n1); 
# 92
while (begin < end) 
# 93
{ 
# 94
Size mid = (begin + end) >> 1; 
# 96
if (comp(first2[(pos - 1) - mid], first1[mid])) 
# 97
{ 
# 98
end = mid; 
# 99
} else 
# 101
{ 
# 102
begin = (mid + 1); 
# 103
}  
# 104
}  
# 105
return begin; 
# 106
} 
#endif
# 109 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/detail/merge.h"
}
# 110
}
# 111
}
# 112
}
# 113
}
# 23 "/usr/local/cuda-8.0/include/thrust/detail/integer_math.h"
namespace thrust { 
# 25
namespace detail { 
# 29
template< class Integer> 
# 30
__attribute((always_inline)) inline Integer 
# 31
clz(Integer x) 
# 32
{ 
# 35
int num_bits = ((8) * sizeof(Integer)); 
# 36
int num_bits_minus_one = num_bits - 1; 
# 38
for (int i = num_bits_minus_one; i >= 0; --i) 
# 39
{ 
# 40
if ((((Integer)1) << i) & x) 
# 41
{ 
# 42
return num_bits_minus_one - i; 
# 43
}  
# 44
}  
# 46
return num_bits; 
# 47
} 
# 50
template< class Integer> 
# 51
__attribute((always_inline)) inline bool 
# 52
is_power_of_2(Integer x) 
# 53
{ 
# 54
return 0 == (x & (x - 1)); 
# 55
} 
# 58
template< class Integer> 
# 59
__attribute((always_inline)) inline Integer 
# 60
log2(Integer x) 
# 61
{ 
# 62
Integer num_bits = ((8) * sizeof(Integer)); 
# 63
Integer num_bits_minus_one = num_bits - 1; 
# 65
return num_bits_minus_one - clz(x); 
# 66
} 
# 69
template< class Integer> 
# 70
__attribute((always_inline)) inline Integer 
# 71
log2_ri(Integer x) 
# 72
{ 
# 73
Integer result = log2(x); 
# 76
if (!is_power_of_2(x)) 
# 77
{ 
# 78
++result; 
# 79
}  
# 81
return result; 
# 82
} 
# 85
template< class Integer> 
# 86
__attribute((always_inline)) inline bool 
# 87
is_odd(Integer x) 
# 88
{ 
# 89
return 1 & x; 
# 90
} 
# 93
}
# 94
}
# 20 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/detail/virtualized_smem_closure.h"
namespace thrust { 
# 22
namespace system { 
# 24
namespace cuda { 
# 26
namespace detail { 
# 28
namespace detail { 
# 32
template< class Closure, class RandomAccessIterator> 
# 33
struct virtualized_smem_closure : public Closure { 
# 36
typedef Closure super_t; 
# 38
::size_t num_elements_per_block; 
# 39
RandomAccessIterator virtual_smem; 
# 41
__attribute((always_inline)) 
# 42
virtualized_smem_closure(Closure closure, ::size_t num_elements_per_block, RandomAccessIterator virtual_smem) : super_t(closure), num_elements_per_block(num_elements_per_block), virtual_smem(virtual_smem) 
# 46
{ } 
# 48
__attribute((always_inline)) void 
# 49
operator()() 
# 50
{int volatile ___ = 1;
# 56
::exit(___);}
#if 0
# 50
{ 
# 51
typename Closure::context_type ctx; 
# 53
RandomAccessIterator smem = (virtual_smem) + ((num_elements_per_block) * (ctx.block_index())); 
# 55
Closure::operator()(smem); 
# 56
} 
#endif
# 57 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/detail/virtualized_smem_closure.h"
}; 
# 60
}
# 61
}
# 62
}
# 63
}
# 64
}
# 31 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/detail/stable_sort_each.inl"
namespace thrust { 
# 33
namespace system { 
# 35
namespace cuda { 
# 37
namespace detail { 
# 39
namespace detail { 
# 41
namespace stable_sort_each_detail { 
# 43
namespace static_stable_odd_even_transpose_sort_detail { 
# 47
template< int i, int n> 
# 48
struct impl { 
# 50
template< class Iterator, class Compare> static void 
# 52
do_it(Iterator keys, Compare comp) 
# 53
{int volatile ___ = 1;(void)keys;(void)comp;
# 65
::exit(___);}
#if 0
# 53
{ 
# 54
for (int j = (1 & i); j < (n - 1); j += 2) 
# 55
{ 
# 56
if (comp(keys[j + 1], keys[j])) 
# 57
{ 
# 58
using thrust::swap;
# 60
swap(keys[j], keys[j + 1]); 
# 61
}  
# 62
}  
# 64
impl< i + 1, n> ::do_it(keys, comp); 
# 65
} 
#endif
# 66 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/detail/stable_sort_each.inl"
}; 
# 69
template< int i> 
# 70
struct impl< i, i>  { 
# 72
template< class Iterator, class Compare> static void 
# 74
do_it(Iterator, Compare) {int volatile ___ = 1;::exit(___);}
#if 0
# 74
{ } 
#endif
# 75 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/detail/stable_sort_each.inl"
}; 
# 78
}
# 81
template< int n, class RandomAccessIterator, class Compare> __attribute__((unused)) void 
# 83
static_stable_sort(RandomAccessIterator keys, Compare comp) 
# 84
{int volatile ___ = 1;(void)keys;(void)comp;
# 86
::exit(___);}
#if 0
# 84
{ 
# 85
static_stable_odd_even_transpose_sort_detail::impl< 0, n> ::do_it(keys, comp); 
# 86
} 
#endif
# 90 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/detail/stable_sort_each.inl"
template< unsigned bound_n, class RandomAccessIterator1, class Size, class RandomAccessIterator2> __attribute__((unused)) void 
# 92
bounded_copy_n(RandomAccessIterator1 first, Size n, RandomAccessIterator2 result) 
# 93
{int volatile ___ = 1;(void)first;(void)n;(void)result;
# 101
::exit(___);}
#if 0
# 93
{ 
# 94
for (unsigned i = (0); i < bound_n; ++i) 
# 95
{ 
# 96
if (i < n) 
# 97
{ 
# 98
(result[i]) = (first[i]); 
# 99
}  
# 100
}  
# 101
} 
#endif
# 104 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/detail/stable_sort_each.inl"
namespace block { 
# 108
template< unsigned work_per_thread, class Context, class Iterator, class Size, class Compare> __attribute__((unused)) void 
# 110
bounded_inplace_merge_adjacent_partitions(Context &ctx, Iterator 
# 111
first, Size 
# 112
n, Compare 
# 113
comp) 
# 114
{int volatile ___ = 1;(void)ctx;(void)first;(void)n;(void)comp;
# 154
::exit(___);}
#if 0
# 114
{ 
# 115
typedef typename iterator_value< Iterator> ::type value_type; 
# 117
for (Size num_threads_per_merge = (2); num_threads_per_merge <= (ctx.block_dimension()); num_threads_per_merge *= 2) 
# 118
{ 
# 120
Size list = (~(num_threads_per_merge - 1)) & (ctx.thread_index()); 
# 121
Size diag = thrust::min< Size> (n, work_per_thread * ((num_threads_per_merge - 1) & (ctx.thread_index()))); 
# 122
Size input_start = work_per_thread * list; 
# 125
Size input_size = work_per_thread * (num_threads_per_merge / 2); 
# 128
Size partition_first1 = thrust::min< Size> (n, input_start); 
# 129
Size partition_first2 = thrust::min< Size> (n, partition_first1 + input_size); 
# 130
Size partition_last2 = thrust::min< Size> (n, partition_first2 + input_size); 
# 132
Size n1 = partition_first2 - partition_first1; 
# 133
Size n2 = partition_last2 - partition_first2; 
# 135
Size mp = merge_path(diag, first + partition_first1, n1, first + partition_first2, n2, comp); 
# 138
value_type local_result[work_per_thread]; 
# 139
sequential_bounded_merge< work_per_thread> ((first + partition_first1) + mp, first + partition_first2, ((first + partition_first2) + diag) - mp, first + partition_last2, local_result, comp); 
# 144
(ctx.barrier()); 
# 147
Size local_result_size = thrust::min< Size> (work_per_thread, n - ((ctx.thread_index()) * work_per_thread)); 
# 150
bounded_copy_n< work_per_thread> (local_result, local_result_size, first + ((ctx.thread_index()) * work_per_thread)); 
# 152
(ctx.barrier()); 
# 153
}  
# 154
} 
#endif
# 157 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/detail/stable_sort_each.inl"
template< unsigned work_per_thread, class Context, class RandomAccessIterator, class Size, class Compare> __attribute__((unused)) void 
# 159
bounded_stable_sort(Context &ctx, RandomAccessIterator 
# 160
first, Size 
# 161
n, Compare 
# 162
comp) 
# 163
{int volatile ___ = 1;(void)ctx;(void)first;(void)n;(void)comp;
# 211
::exit(___);}
#if 0
# 163
{ 
# 164
typedef typename iterator_value< RandomAccessIterator> ::type value_type; 
# 167
Size local_tile_size = (work_per_thread); 
# 168
if ((work_per_thread * ((ctx.thread_index()) + 1)) > n) 
# 169
{ 
# 170
local_tile_size = thrust::max< Size> (0, n - (work_per_thread * (ctx.thread_index()))); 
# 171
}  
# 174
value_type local_keys[work_per_thread]; 
# 175
bounded_copy_n< work_per_thread> (first + ((ctx.thread_index()) * work_per_thread), local_tile_size, local_keys); 
# 178
if (local_tile_size < work_per_thread) 
# 179
{ 
# 180
value_type max_key = (local_keys)[0]; 
# 182
for (unsigned i = (1); i < work_per_thread; ++i) 
# 183
{ 
# 184
if (i < local_tile_size) 
# 185
{ 
# 186
max_key = ((comp(max_key, (local_keys)[i])) ? (local_keys)[i] : max_key); 
# 187
}  
# 188
}  
# 191
for (unsigned i = (0); i < work_per_thread; ++i) 
# 192
{ 
# 193
if (i >= local_tile_size) 
# 194
{ 
# 195
((local_keys)[i]) = max_key; 
# 196
}  
# 197
}  
# 198
}  
# 201
if ((work_per_thread * (ctx.thread_index())) < n) 
# 202
{ 
# 203
static_stable_sort< work_per_thread> (local_keys, comp); 
# 204
}  
# 207
bounded_copy_n< work_per_thread> (local_keys, local_tile_size, first + ((ctx.thread_index()) * work_per_thread)); 
# 208
(ctx.barrier()); 
# 210
block::bounded_inplace_merge_adjacent_partitions< work_per_thread> (ctx, first, n, comp); 
# 211
} 
#endif
# 214 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/detail/stable_sort_each.inl"
}
# 217
template< unsigned work_per_thread, class 
# 218
Context, class 
# 219
RandomAccessIterator1, class 
# 220
Size, class 
# 221
RandomAccessIterator2, class 
# 222
Compare> 
# 223
struct stable_sort_each_copy_closure { 
# 225
typedef Context context_type; 
# 227
RandomAccessIterator1 first; 
# 228
Size n; 
# 229
RandomAccessIterator2 result; 
# 230
thrust::detail::wrapped_function< Compare, bool>  comp; 
# 233
stable_sort_each_copy_closure(RandomAccessIterator1 first, Size n, RandomAccessIterator2 result, Compare comp) : first(first), n(n), result(result), comp(comp) 
# 238
{ } 
# 241
template< class RandomAccessIterator> 
# 242
__attribute((always_inline)) void 
# 243
operator()(RandomAccessIterator staging_buffer) 
# 244
{int volatile ___ = 1;(void)staging_buffer;
# 259
::exit(___);}
#if 0
# 244
{ 
# 245
context_type ctx; 
# 247
unsigned work_per_block = (ctx.block_dimension()) * work_per_thread; 
# 248
unsigned offset = work_per_block * (ctx.block_index()); 
# 249
unsigned tile_size = thrust::min< unsigned> (work_per_block, (n) - offset); 
# 252
cuda::detail::__T0::copy_n_global_to_shared< work_per_thread> (ctx, (first) + offset, tile_size, staging_buffer); 
# 255
block::bounded_stable_sort< work_per_thread> (ctx, staging_buffer, tile_size, comp); 
# 258
cuda::detail::__T0::copy_n(ctx, staging_buffer, tile_size, (result) + offset); 
# 259
} 
#endif
# 262 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/detail/stable_sort_each.inl"
__attribute((always_inline)) void 
# 263
operator()() 
# 264
{int volatile ___ = 1;
# 272
::exit(___);}
#if 0
# 264
{ 
# 265
typedef typename iterator_value< RandomAccessIterator1> ::type value_type; 
# 269
value_type *s_keys = extern_shared_ptr< typename iterator_value< RandomAccessIterator1> ::type> (); 
# 271
(this->operator()(s_keys)); 
# 272
} 
#endif
# 273 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/detail/stable_sort_each.inl"
}; 
# 276
}
# 279
template< unsigned work_per_thread, class 
# 280
DerivedPolicy, class 
# 281
Context, class 
# 282
RandomAccessIterator1, class 
# 283
Pointer, class 
# 284
RandomAccessIterator2, class 
# 285
Compare> void 
# 287
stable_sort_each_copy(execution_policy< DerivedPolicy>  &exec, Context 
# 288
context, unsigned 
# 289
block_size, RandomAccessIterator1 
# 290
first, RandomAccessIterator1 last, Pointer 
# 291
virtual_smem, RandomAccessIterator2 
# 292
result, Compare 
# 293
comp) 
# 294
{ 
# 295
typedef typename iterator_difference< RandomAccessIterator1> ::type difference_type; 
# 297
difference_type n = last - first; 
# 299
int num_blocks = thrust::detail::util::divide_ri(n, block_size * work_per_thread); 
# 308
typedef stable_sort_each_detail::stable_sort_each_copy_closure< work_per_thread, Context, RandomAccessIterator1, typename iterator_difference< RandomAccessIterator1> ::type, RandomAccessIterator2, Compare>  closure_type; 
# 310
closure_type closure(first, n, result, comp); 
# 312
typedef typename iterator_value< RandomAccessIterator1> ::type value_type; 
# 314
const size_t num_smem_elements_per_block = block_size * (work_per_thread + (1)); 
# 317
if (virtual_smem) 
# 318
{ 
# 319
virtualized_smem_closure< stable_sort_each_detail::stable_sort_each_copy_closure< work_per_thread, Context, RandomAccessIterator1, typename iterator_difference< RandomAccessIterator1> ::type, RandomAccessIterator2, Compare> , Pointer>  virtualized_closure(closure, num_smem_elements_per_block, virtual_smem); 
# 321
detail::launch_closure(exec, virtualized_closure, num_blocks, block_size); 
# 322
} else 
# 324
{ 
# 325
const size_t num_smem_bytes = (num_smem_elements_per_block * sizeof(value_type)); 
# 327
detail::launch_closure(exec, closure, num_blocks, block_size, num_smem_bytes); 
# 328
}  
# 329
} 
# 332
}
# 333
}
# 334
}
# 335
}
# 336
}
# 27 "/usr/local/cuda-8.0/include/thrust/sequence.h"
namespace thrust { 
# 71
template< class DerivedPolicy, class ForwardIterator> void sequence(const detail::execution_policy_base< DerivedPolicy>  & exec, ForwardIterator first, ForwardIterator last); 
# 108
template< class ForwardIterator> void sequence(ForwardIterator first, ForwardIterator last); 
# 152
template< class DerivedPolicy, class ForwardIterator, class T> void sequence(const detail::execution_policy_base< DerivedPolicy>  & exec, ForwardIterator first, ForwardIterator last, T init); 
# 193
template< class ForwardIterator, class T> void sequence(ForwardIterator first, ForwardIterator last, T init); 
# 239
template< class DerivedPolicy, class ForwardIterator, class T> void sequence(const detail::execution_policy_base< DerivedPolicy>  & exec, ForwardIterator first, ForwardIterator last, T init, T step); 
# 282
template< class ForwardIterator, class T> void sequence(ForwardIterator first, ForwardIterator last, T init, T step); 
# 293
}
# 23 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/sequence.h"
namespace thrust { 
# 25
namespace system { 
# 27
namespace detail { 
# 29
namespace generic { 
# 33
template< class DerivedPolicy, class 
# 34
ForwardIterator> void 
# 33
sequence(execution_policy< DerivedPolicy>  & exec, ForwardIterator first, ForwardIterator last); 
# 41
template< class DerivedPolicy, class ForwardIterator, class T> void sequence(execution_policy< DerivedPolicy>  & exec, ForwardIterator first, ForwardIterator last, T init); 
# 49
template< class DerivedPolicy, class ForwardIterator, class T> void sequence(execution_policy< DerivedPolicy>  & exec, ForwardIterator first, ForwardIterator last, T init, T step); 
# 58
}
# 59
}
# 60
}
# 61
}
# 22 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/sequence.inl"
namespace thrust { 
# 24
namespace system { 
# 26
namespace detail { 
# 28
namespace generic { 
# 30
namespace sequence_detail { 
# 34
template< class T> 
# 35
struct sequence_functor { 
# 37
T init, step; 
# 40
sequence_functor(T init, T step) : init(init), step(step) 
# 42
{ } 
# 44
template< class Index> T 
# 46
operator()(Index i) const 
# 47
{ 
# 48
return (init) + ((step) * i); 
# 49
} 
# 50
}; 
# 53
}
# 56
template< class DerivedPolicy, class ForwardIterator> void 
# 58
sequence(execution_policy< DerivedPolicy>  &exec, ForwardIterator 
# 59
first, ForwardIterator 
# 60
last) 
# 61
{ 
# 62
typedef typename iterator_traits< ForwardIterator> ::value_type T; 
# 64
thrust::sequence(exec, first, last, (T)0); 
# 65
} 
# 68
template< class DerivedPolicy, class ForwardIterator, class T> void 
# 70
sequence(execution_policy< DerivedPolicy>  &exec, ForwardIterator 
# 71
first, ForwardIterator 
# 72
last, T 
# 73
init) 
# 74
{ 
# 75
thrust::sequence(exec, first, last, init, (T)1); 
# 76
} 
# 79
template< class DerivedPolicy, class ForwardIterator, class T> void 
# 81
sequence(execution_policy< DerivedPolicy>  &exec, ForwardIterator 
# 82
first, ForwardIterator 
# 83
last, T 
# 84
init, T 
# 85
step) 
# 86
{ 
# 88
thrust::tabulate(exec, first, last, sequence_detail::sequence_functor< T> (init, step)); 
# 89
} 
# 92
}
# 93
}
# 94
}
# 95
}
# 29 "/usr/local/cuda-8.0/include/thrust/detail/sequence.inl"
namespace thrust { 
# 34
template< class DerivedPolicy, class ForwardIterator> void 
# 36
sequence(const detail::execution_policy_base< DerivedPolicy>  &exec, ForwardIterator 
# 37
first, ForwardIterator 
# 38
last) 
# 39
{ 
# 40
using system::detail::generic::sequence;
# 41
return sequence(detail::derived_cast(detail::strip_const(exec)), first, last); 
# 42
} 
# 46
template< class DerivedPolicy, class ForwardIterator, class T> void 
# 48
sequence(const detail::execution_policy_base< DerivedPolicy>  &exec, ForwardIterator 
# 49
first, ForwardIterator 
# 50
last, T 
# 51
init) 
# 52
{ 
# 53
using system::detail::generic::sequence;
# 54
return sequence(detail::derived_cast(detail::strip_const(exec)), first, last, init); 
# 55
} 
# 59
template< class DerivedPolicy, class ForwardIterator, class T> void 
# 61
sequence(const detail::execution_policy_base< DerivedPolicy>  &exec, ForwardIterator 
# 62
first, ForwardIterator 
# 63
last, T 
# 64
init, T 
# 65
step) 
# 66
{ 
# 67
using system::detail::generic::sequence;
# 68
return sequence(detail::derived_cast(detail::strip_const(exec)), first, last, init, step); 
# 69
} 
# 72
template< class ForwardIterator> void 
# 73
sequence(ForwardIterator first, ForwardIterator 
# 74
last) 
# 75
{ 
# 76
using thrust::system::detail::generic::select_system;
# 78
typedef typename iterator_system< ForwardIterator> ::type System; 
# 80
System system; 
# 82
return thrust::sequence(select_system(system), first, last); 
# 83
} 
# 86
template< class ForwardIterator, class T> void 
# 87
sequence(ForwardIterator first, ForwardIterator 
# 88
last, T 
# 89
init) 
# 90
{ 
# 91
using thrust::system::detail::generic::select_system;
# 93
typedef typename iterator_system< ForwardIterator> ::type System; 
# 95
System system; 
# 97
return thrust::sequence(select_system(system), first, last, init); 
# 98
} 
# 101
template< class ForwardIterator, class T> void 
# 102
sequence(ForwardIterator first, ForwardIterator 
# 103
last, T 
# 104
init, T 
# 105
step) 
# 106
{ 
# 107
using thrust::system::detail::generic::select_system;
# 109
typedef typename iterator_system< ForwardIterator> ::type System; 
# 111
System system; 
# 113
return thrust::sequence(select_system(system), first, last, init, step); 
# 114
} 
# 117
}
# 27 "/usr/local/cuda-8.0/include/thrust/gather.h"
namespace thrust { 
# 84
template< class DerivedPolicy, class 
# 85
InputIterator, class 
# 86
RandomAccessIterator, class 
# 87
OutputIterator> OutputIterator 
# 84
gather(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator map_first, InputIterator map_last, RandomAccessIterator input_first, OutputIterator result); 
# 137
template< class InputIterator, class 
# 138
RandomAccessIterator, class 
# 139
OutputIterator> OutputIterator 
# 137
gather(InputIterator map_first, InputIterator map_last, RandomAccessIterator input_first, OutputIterator result); 
# 202
template< class DerivedPolicy, class 
# 203
InputIterator1, class 
# 204
InputIterator2, class 
# 205
RandomAccessIterator, class 
# 206
OutputIterator> OutputIterator 
# 202
gather_if(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator1 map_first, InputIterator1 map_last, InputIterator2 stencil, RandomAccessIterator input_first, OutputIterator result); 
# 266
template< class InputIterator1, class 
# 267
InputIterator2, class 
# 268
RandomAccessIterator, class 
# 269
OutputIterator> OutputIterator 
# 266
gather_if(InputIterator1 map_first, InputIterator1 map_last, InputIterator2 stencil, RandomAccessIterator input_first, OutputIterator result); 
# 345
template< class DerivedPolicy, class 
# 346
InputIterator1, class 
# 347
InputIterator2, class 
# 348
RandomAccessIterator, class 
# 349
OutputIterator, class 
# 350
Predicate> OutputIterator 
# 345
gather_if(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator1 map_first, InputIterator1 map_last, InputIterator2 stencil, RandomAccessIterator input_first, OutputIterator result, Predicate pred); 
# 423
template< class InputIterator1, class 
# 424
InputIterator2, class 
# 425
RandomAccessIterator, class 
# 426
OutputIterator, class 
# 427
Predicate> OutputIterator 
# 423
gather_if(InputIterator1 map_first, InputIterator1 map_last, InputIterator2 stencil, RandomAccessIterator input_first, OutputIterator result, Predicate pred); 
# 438
}
# 23 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/gather.h"
namespace thrust { 
# 25
namespace system { 
# 27
namespace detail { 
# 29
namespace generic { 
# 33
template< class DerivedPolicy, class 
# 34
InputIterator, class 
# 35
RandomAccessIterator, class 
# 36
OutputIterator> OutputIterator 
# 33
gather(execution_policy< DerivedPolicy>  & exec, InputIterator map_first, InputIterator map_last, RandomAccessIterator input_first, OutputIterator result); 
# 45
template< class DerivedPolicy, class 
# 46
InputIterator1, class 
# 47
InputIterator2, class 
# 48
RandomAccessIterator, class 
# 49
OutputIterator> OutputIterator 
# 45
gather_if(execution_policy< DerivedPolicy>  & exec, InputIterator1 map_first, InputIterator1 map_last, InputIterator2 stencil, RandomAccessIterator input_first, OutputIterator result); 
# 59
template< class DerivedPolicy, class 
# 60
InputIterator1, class 
# 61
InputIterator2, class 
# 62
RandomAccessIterator, class 
# 63
OutputIterator, class 
# 64
Predicate> OutputIterator 
# 59
gather_if(execution_policy< DerivedPolicy>  & exec, InputIterator1 map_first, InputIterator1 map_last, InputIterator2 stencil, RandomAccessIterator input_first, OutputIterator result, Predicate pred); 
# 75
}
# 76
}
# 77
}
# 78
}
# 24 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/gather.inl"
namespace thrust { 
# 26
namespace system { 
# 28
namespace detail { 
# 30
namespace generic { 
# 34
template< class DerivedPolicy, class 
# 35
InputIterator, class 
# 36
RandomAccessIterator, class 
# 37
OutputIterator> OutputIterator 
# 39
gather(execution_policy< DerivedPolicy>  &exec, InputIterator 
# 40
map_first, InputIterator 
# 41
map_last, RandomAccessIterator 
# 42
input_first, OutputIterator 
# 43
result) 
# 44
{ 
# 45
return thrust::transform(exec, thrust::make_permutation_iterator(input_first, map_first), thrust::make_permutation_iterator(input_first, map_last), result, identity< typename iterator_value< RandomAccessIterator> ::type> ()); 
# 50
} 
# 53
template< class DerivedPolicy, class 
# 54
InputIterator1, class 
# 55
InputIterator2, class 
# 56
RandomAccessIterator, class 
# 57
OutputIterator> OutputIterator 
# 59
gather_if(execution_policy< DerivedPolicy>  &exec, InputIterator1 
# 60
map_first, InputIterator1 
# 61
map_last, InputIterator2 
# 62
stencil, RandomAccessIterator 
# 63
input_first, OutputIterator 
# 64
result) 
# 65
{ 
# 66
typedef typename iterator_value< InputIterator2> ::type StencilType; 
# 67
return thrust::gather_if(exec, map_first, map_last, stencil, input_first, result, identity< typename iterator_value< InputIterator2> ::type> ()); 
# 74
} 
# 77
template< class DerivedPolicy, class 
# 78
InputIterator1, class 
# 79
InputIterator2, class 
# 80
RandomAccessIterator, class 
# 81
OutputIterator, class 
# 82
Predicate> OutputIterator 
# 84
gather_if(execution_policy< DerivedPolicy>  &exec, InputIterator1 
# 85
map_first, InputIterator1 
# 86
map_last, InputIterator2 
# 87
stencil, RandomAccessIterator 
# 88
input_first, OutputIterator 
# 89
result, Predicate 
# 90
pred) 
# 91
{ 
# 92
typedef typename iterator_value< RandomAccessIterator> ::type InputType; 
# 93
return thrust::transform_if(exec, thrust::make_permutation_iterator(input_first, map_first), thrust::make_permutation_iterator(input_first, map_last), stencil, result, identity< typename iterator_value< RandomAccessIterator> ::type> (), pred); 
# 100
} 
# 103
}
# 104
}
# 105
}
# 106
}
# 28 "/usr/local/cuda-8.0/include/thrust/detail/gather.inl"
namespace thrust { 
# 33
template< class DerivedPolicy, class 
# 34
InputIterator, class 
# 35
RandomAccessIterator, class 
# 36
OutputIterator> OutputIterator 
# 38
gather(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator 
# 39
map_first, InputIterator 
# 40
map_last, RandomAccessIterator 
# 41
input_first, OutputIterator 
# 42
result) 
# 43
{ 
# 44
using system::detail::generic::gather;
# 45
return gather(detail::derived_cast(detail::strip_const(exec)), map_first, map_last, input_first, result); 
# 46
} 
# 50
template< class DerivedPolicy, class 
# 51
InputIterator1, class 
# 52
InputIterator2, class 
# 53
RandomAccessIterator, class 
# 54
OutputIterator> OutputIterator 
# 56
gather_if(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator1 
# 57
map_first, InputIterator1 
# 58
map_last, InputIterator2 
# 59
stencil, RandomAccessIterator 
# 60
input_first, OutputIterator 
# 61
result) 
# 62
{ 
# 63
using system::detail::generic::gather_if;
# 64
return gather_if(detail::derived_cast(detail::strip_const(exec)), map_first, map_last, stencil, input_first, result); 
# 65
} 
# 69
template< class DerivedPolicy, class 
# 70
InputIterator1, class 
# 71
InputIterator2, class 
# 72
RandomAccessIterator, class 
# 73
OutputIterator, class 
# 74
Predicate> OutputIterator 
# 76
gather_if(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator1 
# 77
map_first, InputIterator1 
# 78
map_last, InputIterator2 
# 79
stencil, RandomAccessIterator 
# 80
input_first, OutputIterator 
# 81
result, Predicate 
# 82
pred) 
# 83
{ 
# 84
using system::detail::generic::gather_if;
# 85
return gather_if(detail::derived_cast(detail::strip_const(exec)), map_first, map_last, stencil, input_first, result, pred); 
# 86
} 
# 89
template< class InputIterator, class 
# 90
RandomAccessIterator, class 
# 91
OutputIterator> OutputIterator 
# 92
gather(InputIterator map_first, InputIterator 
# 93
map_last, RandomAccessIterator 
# 94
input_first, OutputIterator 
# 95
result) 
# 96
{ 
# 97
using system::detail::generic::select_system;
# 99
typedef typename iterator_system< InputIterator> ::type System1; 
# 100
typedef typename iterator_system< RandomAccessIterator> ::type System2; 
# 101
typedef typename iterator_system< OutputIterator> ::type System3; 
# 103
System1 system1; 
# 104
System2 system2; 
# 105
System3 system3; 
# 107
return thrust::gather(select_system(system1, system2, system3), map_first, map_last, input_first, result); 
# 108
} 
# 111
template< class InputIterator1, class 
# 112
InputIterator2, class 
# 113
RandomAccessIterator, class 
# 114
OutputIterator> OutputIterator 
# 115
gather_if(InputIterator1 map_first, InputIterator1 
# 116
map_last, InputIterator2 
# 117
stencil, RandomAccessIterator 
# 118
input_first, OutputIterator 
# 119
result) 
# 120
{ 
# 121
using system::detail::generic::select_system;
# 123
typedef typename iterator_system< InputIterator1> ::type System1; 
# 124
typedef typename iterator_system< InputIterator2> ::type System2; 
# 125
typedef typename iterator_system< RandomAccessIterator> ::type System3; 
# 126
typedef typename iterator_system< OutputIterator> ::type System4; 
# 128
System1 system1; 
# 129
System2 system2; 
# 130
System3 system3; 
# 131
System4 system4; 
# 133
return thrust::gather_if(select_system(system1, system2, system3, system4), map_first, map_last, stencil, input_first, result); 
# 134
} 
# 137
template< class InputIterator1, class 
# 138
InputIterator2, class 
# 139
RandomAccessIterator, class 
# 140
OutputIterator, class 
# 141
Predicate> OutputIterator 
# 142
gather_if(InputIterator1 map_first, InputIterator1 
# 143
map_last, InputIterator2 
# 144
stencil, RandomAccessIterator 
# 145
input_first, OutputIterator 
# 146
result, Predicate 
# 147
pred) 
# 148
{ 
# 149
using system::detail::generic::select_system;
# 151
typedef typename iterator_system< InputIterator1> ::type System1; 
# 152
typedef typename iterator_system< InputIterator2> ::type System2; 
# 153
typedef typename iterator_system< RandomAccessIterator> ::type System3; 
# 154
typedef typename iterator_system< OutputIterator> ::type System4; 
# 156
System1 system1; 
# 157
System2 system2; 
# 158
System3 system3; 
# 159
System4 system4; 
# 161
return thrust::gather_if(select_system(system1, system2, system3, system4), map_first, map_last, stencil, input_first, result, pred); 
# 162
} 
# 165
}
# 24 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/temporary_indirect_permutation.h"
namespace thrust { 
# 26
namespace system { 
# 28
namespace cuda { 
# 30
namespace detail { 
# 34
template< class DerivedPolicy, class RandomAccessIterator> 
# 35
struct temporary_indirect_permutation { 
# 38
private: typedef unsigned size_type; 
# 39
typedef thrust::detail::temporary_array< unsigned, DerivedPolicy>  array_type; 
# 43
public: temporary_indirect_permutation(thrust::execution_policy< DerivedPolicy>  &exec, RandomAccessIterator first, RandomAccessIterator last) : m_exec(derived_cast(exec)), m_src_first(first), m_src_last(last), m_permutation(0, m_exec, last - first) 
# 48
{ 
# 50
thrust::sequence(exec, ((m_permutation).begin()), ((m_permutation).end())); 
# 51
} 
# 54
~temporary_indirect_permutation() 
# 55
{ 
# 57
typedef typename iterator_value< RandomAccessIterator> ::type value_type; 
# 58
thrust::detail::temporary_array< typename iterator_value< RandomAccessIterator> ::type, DerivedPolicy>  temp(m_exec, m_src_first, m_src_last); 
# 59
thrust::gather(m_exec, ((m_permutation).begin()), ((m_permutation).end()), (temp.begin()), m_src_first); 
# 60
} 
# 62
typedef typename thrust::detail::temporary_array< unsigned, DerivedPolicy> ::iterator iterator; 
# 65
iterator begin() 
# 66
{ 
# 67
return ((m_permutation).begin()); 
# 68
} 
# 71
iterator end() 
# 72
{ 
# 73
return ((m_permutation).end()); 
# 74
} 
# 77
private: DerivedPolicy &m_exec; 
# 78
RandomAccessIterator m_src_first, m_src_last; 
# 79
thrust::detail::temporary_array< unsigned, DerivedPolicy>  m_permutation; 
# 80
}; 
# 83
template< class DerivedPolicy, class RandomAccessIterator> 
# 84
struct iterator_range_with_execution_policy { 
# 87
iterator_range_with_execution_policy(thrust::execution_policy< DerivedPolicy>  &exec, RandomAccessIterator first, RandomAccessIterator last) : m_exec(derived_cast(exec)), m_first(first), m_last(last) 
# 89
{ } 
# 91
typedef RandomAccessIterator iterator; 
# 94
iterator begin() 
# 95
{ 
# 96
return m_first; 
# 97
} 
# 100
iterator end() 
# 101
{ 
# 102
return m_last; 
# 103
} 
# 106
DerivedPolicy &exec() 
# 107
{ 
# 108
return m_exec; 
# 109
} 
# 111
DerivedPolicy &m_exec; 
# 112
RandomAccessIterator m_first, m_last; 
# 113
}; 
# 116
template< class Condition, class DerivedPolicy, class RandomAccessIterator> 
# 117
struct conditional_temporary_indirect_permutation : public thrust::detail::eval_if< Condition::value, thrust::detail::identity_< temporary_indirect_permutation< DerivedPolicy, RandomAccessIterator> > , thrust::detail::identity_< iterator_range_with_execution_policy< DerivedPolicy, RandomAccessIterator> > > ::type { 
# 128
typedef typename ::thrust::detail::eval_if< Condition::value, ::thrust::detail::identity_< temporary_indirect_permutation< DerivedPolicy, RandomAccessIterator> > , ::thrust::detail::identity_< iterator_range_with_execution_policy< DerivedPolicy, RandomAccessIterator> > > ::type super_t; 
# 131
conditional_temporary_indirect_permutation(::thrust::execution_policy< DerivedPolicy>  &exec, RandomAccessIterator first, RandomAccessIterator last) : super_t(exec, first, last) 
# 133
{ } 
# 134
}; 
# 137
template< class DerivedPolicy, class RandomAccessIterator, class Compare> 
# 138
struct temporary_indirect_ordering : public temporary_indirect_permutation< DerivedPolicy, RandomAccessIterator>  { 
# 142
private: typedef ::thrust::system::cuda::detail::temporary_indirect_permutation< DerivedPolicy, RandomAccessIterator>  super_t; 
# 146
public: temporary_indirect_ordering(::thrust::execution_policy< DerivedPolicy>  &exec, RandomAccessIterator first, RandomAccessIterator last, Compare comp) : super_t(exec, first, last), m_comp(first, comp) 
# 149
{ } 
# 151
struct compare { 
# 153
RandomAccessIterator first; 
# 158
::thrust::detail::wrapped_function< Compare, bool>  comp; 
# 161
compare(RandomAccessIterator first, Compare comp) : first(first), comp(comp) 
# 163
{ } 
# 165
template< class Integral> bool 
# 167
operator()(Integral a, Integral b) 
# 168
{ 
# 169
return (comp)((first)[a], (first)[b]); 
# 170
} 
# 171
}; 
# 174
compare comp() const 
# 175
{ 
# 176
return m_comp; 
# 177
} 
# 180
private: compare m_comp; 
# 181
}; 
# 184
template< class DerivedPolicy, class RandomAccessIterator, class Compare> 
# 185
struct iterator_range_with_execution_policy_and_compare : public iterator_range_with_execution_policy< DerivedPolicy, RandomAccessIterator>  { 
# 188
typedef ::thrust::system::cuda::detail::iterator_range_with_execution_policy< DerivedPolicy, RandomAccessIterator>  super_t; 
# 191
iterator_range_with_execution_policy_and_compare(::thrust::execution_policy< DerivedPolicy>  &exec, RandomAccessIterator first, RandomAccessIterator last, Compare comp) : super_t(exec, first, last), m_comp(comp) 
# 193
{ } 
# 195
typedef Compare compare; 
# 198
compare comp() 
# 199
{ 
# 200
return m_comp; 
# 201
} 
# 203
Compare m_comp; 
# 204
}; 
# 207
template< class Condition, class DerivedPolicy, class RandomAccessIterator, class Compare> 
# 208
struct conditional_temporary_indirect_ordering : public thrust::detail::eval_if< Condition::value, thrust::detail::identity_< temporary_indirect_ordering< DerivedPolicy, RandomAccessIterator, Compare> > , thrust::detail::identity_< iterator_range_with_execution_policy_and_compare< DerivedPolicy, RandomAccessIterator, Compare> > > ::type { 
# 219
typedef typename ::thrust::detail::eval_if< Condition::value, ::thrust::detail::identity_< temporary_indirect_ordering< DerivedPolicy, RandomAccessIterator, Compare> > , ::thrust::detail::identity_< iterator_range_with_execution_policy_and_compare< DerivedPolicy, RandomAccessIterator, Compare> > > ::type super_t; 
# 222
conditional_temporary_indirect_ordering(::thrust::execution_policy< DerivedPolicy>  &exec, RandomAccessIterator first, RandomAccessIterator last, Compare comp) : super_t(exec, first, last, comp) 
# 224
{ } 
# 225
}; 
# 228
}
# 229
}
# 230
}
# 231
}
# 42 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/detail/stable_merge_sort.inl"
namespace thrust { 
# 44
namespace system { 
# 46
namespace cuda { 
# 48
namespace detail { 
# 50
namespace detail { 
# 52
namespace stable_merge_sort_detail { 
# 54
namespace block { 
# 59
template< unsigned work_per_thread, class 
# 60
Context, class 
# 61
Iterator, class 
# 62
Size, class 
# 63
Compare> __attribute__((unused)) void 
# 65
bounded_inplace_merge(Context &ctx, Iterator first, Size n1, Size n2, Compare comp) 
# 66
{int volatile ___ = 1;(void)ctx;(void)first;(void)n1;(void)n2;(void)comp;
# 94
::exit(___);}
#if 0
# 66
{ 
# 67
Iterator first2 = first + n1; 
# 70
Size diag = thrust::min< Size> (n1 + n2, work_per_thread * (ctx.thread_index())); 
# 72
Size mp = merge_path(diag, first, n1, first2, n2, comp); 
# 75
Size start1 = mp; 
# 76
Size start2 = diag - mp; 
# 78
Size end1 = n1; 
# 79
Size end2 = n2; 
# 82
typedef typename iterator_value< Iterator> ::type value_type; 
# 83
value_type local_result[work_per_thread]; 
# 84
sequential_bounded_merge< work_per_thread> (first + start1, first + end1, first2 + start2, first2 + end2, local_result, comp); 
# 88
(ctx.barrier()); 
# 92
thrust::copy_n(thrust::seq, local_result, work_per_thread, first + (work_per_thread * (ctx.thread_index()))); 
# 93
(ctx.barrier()); 
# 94
} 
#endif
# 98 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/detail/stable_merge_sort.inl"
template< unsigned work_per_thread, class 
# 99
Context, class 
# 100
Iterator1, class Size1, class 
# 101
Iterator2, class Size2, class 
# 102
Iterator3, class 
# 103
Iterator4, class 
# 104
Compare> __attribute__((unused)) void 
# 106
staged_bounded_merge(Context &ctx, Iterator1 
# 107
first1, Size1 n1, Iterator2 
# 108
first2, Size2 n2, Iterator3 
# 109
staging_buffer, Iterator4 
# 110
result, Compare 
# 111
comp) 
# 112
{int volatile ___ = 1;(void)ctx;(void)first1;(void)n1;(void)first2;(void)n2;(void)staging_buffer;(void)result;(void)comp;
# 123
::exit(___);}
#if 0
# 112
{ 
# 114
cuda::detail::__T0::async_copy_n_global_to_shared< work_per_thread> (ctx, first1, n1, staging_buffer); 
# 115
cuda::detail::__T0::async_copy_n_global_to_shared< work_per_thread> (ctx, first2, n2, staging_buffer + n1); 
# 116
(ctx.barrier()); 
# 119
block::bounded_inplace_merge< work_per_thread> (ctx, staging_buffer, n1, n2, comp); 
# 122
cuda::detail::__T0::copy_n(ctx, staging_buffer, n1 + n2, result); 
# 123
} 
#endif
# 126 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/detail/stable_merge_sort.inl"
}
# 131
inline tuple< int, int, int, int, null_type, null_type, null_type, null_type, null_type, null_type>  find_mergesort_interval(int partition_first1, int partition_size, int num_blocks_per_merge, int block_idx, int num_elements_per_block, int n, int mp, int right_mp) 
# 132
{ 
# 133
int partition_first2 = partition_first1 + partition_size; 
# 136
int diag = (num_elements_per_block * block_idx) - partition_first1; 
# 137
int start1 = partition_first1 + mp; 
# 138
int end1 = thrust::min< int> (n, partition_first1 + right_mp); 
# 139
int start2 = thrust::min< int> (n, (partition_first2 + diag) - mp); 
# 140
int end2 = thrust::min< int> (n, ((partition_first2 + diag) + num_elements_per_block) - right_mp); 
# 147
if ((num_blocks_per_merge - 1) == ((num_blocks_per_merge - 1) & block_idx)) 
# 148
{ 
# 149
end1 = thrust::min< int> (n, partition_first1 + partition_size); 
# 150
end2 = thrust::min< int> (n, partition_first2 + partition_size); 
# 151
}  
# 153
return thrust::make_tuple(start1, end1, start2, end2); 
# 154
} 
# 158
inline tuple< int, int, int, int, null_type, null_type, null_type, null_type, null_type, null_type>  locate_merge_partitions(int n, int block_idx, int num_blocks_per_merge, int num_elements_per_block, int mp, int right_mp) 
# 159
{ 
# 160
int first_block_in_partition = (~(num_blocks_per_merge - 1)) & block_idx; 
# 161
int partition_size = num_elements_per_block * (num_blocks_per_merge >> 1); 
# 163
int partition_first1 = num_elements_per_block * first_block_in_partition; 
# 165
return find_mergesort_interval(partition_first1, partition_size, num_blocks_per_merge, block_idx, num_elements_per_block, n, mp, right_mp); 
# 166
} 
# 169
template< unsigned work_per_thread, class 
# 170
Context, class 
# 171
Size, class 
# 172
Iterator1, class 
# 173
Iterator2, class 
# 174
Iterator3, class 
# 175
Compare> 
# 176
struct merge_adjacent_partitions_closure { 
# 178
typedef Context context_type; 
# 180
Size num_blocks_per_merge; 
# 181
Iterator1 first; 
# 182
Size n; 
# 183
Iterator2 merge_paths; 
# 184
Iterator3 result; 
# 185
thrust::detail::wrapped_function< Compare, bool>  comp; 
# 189
merge_adjacent_partitions_closure(Size num_blocks_per_merge, Iterator1 first, Size n, Iterator2 merge_paths, Iterator3 result, Compare comp) : num_blocks_per_merge(num_blocks_per_merge), first(first), n(n), merge_paths(merge_paths), result(result), comp(comp) 
# 196
{ } 
# 199
template< class RandomAccessIterator> 
# 200
__attribute((always_inline)) void 
# 201
operator()(RandomAccessIterator staging_buffer) 
# 202
{int volatile ___ = 1;(void)staging_buffer;
# 218
::exit(___);}
#if 0
# 202
{ 
# 203
context_type ctx; 
# 205
Size work_per_block = (ctx.block_dimension()) * work_per_thread; 
# 207
Size start1 = (0), end1 = (0), start2 = (0), end2 = (0); 
# 209
thrust::tie(start1, end1, start2, end2) = locate_merge_partitions(n, (ctx.block_index()), num_blocks_per_merge, work_per_block, thrust::raw_reference_cast((merge_paths)[(ctx.block_index())]), thrust::raw_reference_cast((merge_paths)[(ctx.block_index()) + 1])); 
# 212
block::staged_bounded_merge< work_per_thread> (ctx, (first) + start1, end1 - start1, (first) + start2, end2 - start2, staging_buffer, (result) + ((ctx.block_index()) * work_per_block), comp); 
# 218
} 
#endif
# 221 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/detail/stable_merge_sort.inl"
__attribute((always_inline)) void 
# 222
operator()() 
# 223
{int volatile ___ = 1;
# 231
::exit(___);}
#if 0
# 223
{ 
# 224
typedef typename iterator_value< Iterator1> ::type value_type; 
# 228
value_type *s_keys = extern_shared_ptr< typename iterator_value< Iterator1> ::type> (); 
# 230
(this->operator()(s_keys)); 
# 231
} 
#endif
# 232 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/detail/stable_merge_sort.inl"
}; 
# 235
template< unsigned work_per_thread, class 
# 236
DerivedPolicy, class 
# 237
Context, class 
# 238
Size, class 
# 239
Iterator1, class 
# 240
Iterator2, class 
# 241
Pointer, class 
# 242
Iterator3, class 
# 243
Compare> void 
# 245
merge_adjacent_partitions(execution_policy< DerivedPolicy>  &exec, Context 
# 246
context, unsigned 
# 247
block_size, Size 
# 248
num_blocks_per_merge, Iterator1 
# 249
first, Size 
# 250
n, Iterator2 
# 251
merge_paths, Pointer 
# 252
virtual_smem, Iterator3 
# 253
result, Compare 
# 254
comp) 
# 255
{ 
# 264
typedef merge_adjacent_partitions_closure< work_per_thread, Context, Size, Iterator1, Iterator2, Iterator3, Compare>  closure_type; 
# 266
closure_type closure(num_blocks_per_merge, first, n, merge_paths, result, comp); 
# 268
Size num_blocks = thrust::detail::util::divide_ri(n, block_size * work_per_thread); 
# 270
typedef typename iterator_value< Iterator1> ::type value_type; 
# 272
const size_t num_smem_elements_per_block = block_size * (work_per_thread + (1)); 
# 275
if (virtual_smem) 
# 276
{ 
# 277
virtualized_smem_closure< merge_adjacent_partitions_closure< work_per_thread, Context, Size, Iterator1, Iterator2, Iterator3, Compare> , Pointer>  virtualized_closure(closure, num_smem_elements_per_block, virtual_smem); 
# 279
detail::launch_closure(exec, virtualized_closure, num_blocks, block_size); 
# 280
} else 
# 282
{ 
# 283
const size_t num_smem_bytes = (num_smem_elements_per_block * sizeof(value_type)); 
# 285
detail::launch_closure(exec, closure, num_blocks, block_size, num_smem_bytes); 
# 286
}  
# 287
} 
# 290
template< class Iterator, class Size, class Compare> 
# 291
struct locate_merge_path { 
# 293
Iterator haystack_first; 
# 294
Size haystack_size; 
# 295
Size num_elements_per_block; 
# 296
Size num_blocks_per_merge; 
# 297
thrust::detail::wrapped_function< Compare, bool>  comp; 
# 300
locate_merge_path(Iterator haystack_first, Size haystack_size, Size num_elements_per_block, Size num_blocks_per_merge, Compare comp) : haystack_first(haystack_first), haystack_size(haystack_size), num_elements_per_block(num_elements_per_block), num_blocks_per_merge(num_blocks_per_merge), comp(comp) 
# 306
{ } 
# 308
template< class Index> Index 
# 310
operator()(Index merge_path_idx) 
# 311
{ 
# 313
Size first_block_in_partition = (~((num_blocks_per_merge) - 1)) & merge_path_idx; 
# 316
Size size = (num_elements_per_block) * ((num_blocks_per_merge) / 2); 
# 319
Size start1 = (num_elements_per_block) * first_block_in_partition; 
# 320
Size start2 = thrust::min< Size> (haystack_size, start1 + size); 
# 324
Size n1 = thrust::min< Size> (size, (haystack_size) - start1); 
# 325
Size n2 = thrust::min< Size> (size, (haystack_size) - start2); 
# 328
Size diag = thrust::min< Size> (n1 + n2, ((num_elements_per_block) * merge_path_idx) - start1); 
# 330
return merge_path(diag, (haystack_first) + start1, n1, (haystack_first) + start2, n2, comp); 
# 331
} 
# 332
}; 
# 335
template< class DerivedPolicy, class Iterator1, class Size1, class Iterator2, class Size2, class Compare> void 
# 337
locate_merge_paths(execution_policy< DerivedPolicy>  &exec, Iterator1 
# 338
result, Size1 
# 339
n, Iterator2 
# 340
haystack_first, Size2 
# 341
haystack_size, Size2 
# 342
num_elements_per_block, Size2 
# 343
num_blocks_per_merge, Compare 
# 344
comp) 
# 345
{ 
# 346
locate_merge_path< Iterator2, Size2, Compare>  f(haystack_first, haystack_size, num_elements_per_block, num_blocks_per_merge, comp); 
# 348
thrust::tabulate(exec, result, result + n, f); 
# 349
} 
# 352
template< class T> bool 
# 354
virtualize_smem(size_t num_elements_per_block) 
# 355
{ 
# 357
size_t num_smem_bytes_required = num_elements_per_block * sizeof(T); 
# 359
device_properties_t props = thrust::system::cuda::detail::device_properties(); 
# 361
size_t num_smem_bytes_available = props.sharedMemPerBlock; 
# 362
if ((props.major) == 1) 
# 363
{ 
# 365
num_smem_bytes_available -= (256); 
# 366
}  
# 368
return num_smem_bytes_required > num_smem_bytes_available; 
# 374
} 
# 377
template< class DerivedPolicy, class RandomAccessIterator, class Size, class Compare> void 
# 379
stable_merge_sort_n(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator 
# 380
first, Size 
# 381
n, Compare 
# 382
comp) 
# 383
{ 
# 384
if (n <= 0) { return; }  
# 386
typedef typename iterator_value< RandomAccessIterator> ::type T; 
# 388
const Size block_size = (256); 
# 390
typedef statically_blocked_thread_array< block_size>  context_type; 
# 392
context_type context; 
# 394
const Size work_per_thread = ((sizeof(T) < (8)) ? 11 : 7); 
# 395
const Size work_per_block = block_size * work_per_thread; 
# 397
Size num_blocks = thrust::detail::util::divide_ri(n, work_per_block); 
# 399
const unsigned num_smem_elements_per_block = block_size * (work_per_thread + 1); 
# 401
thrust::detail::temporary_array< typename iterator_value< RandomAccessIterator> ::type, DerivedPolicy>  virtual_smem(exec, (virtualize_smem< typename iterator_value< RandomAccessIterator> ::type> (num_smem_elements_per_block)) ? num_blocks * num_smem_elements_per_block : 0); 
# 406
bool ping = false; 
# 407
thrust::detail::temporary_array< typename iterator_value< RandomAccessIterator> ::type, DerivedPolicy>  pong_buffer(exec, n); 
# 409
Size num_passes = thrust::detail::log2_ri(num_blocks); 
# 411
if (thrust::detail::is_odd(num_passes)) 
# 412
{ 
# 413
stable_sort_each_copy< work_per_thread> (exec, context, block_size, first, first + n, thrust::raw_pointer_cast(&(*(virtual_smem.begin()))), (pong_buffer.begin()), comp); 
# 414
} else 
# 416
{ 
# 417
stable_sort_each_copy< work_per_thread> (exec, context, block_size, first, first + n, thrust::raw_pointer_cast(&(*(virtual_smem.begin()))), first, comp); 
# 418
ping = true; 
# 419
}  
# 421
thrust::detail::temporary_array< Size, DerivedPolicy>  merge_paths(exec, num_blocks + 1); 
# 423
for (Size pass = (0); pass < num_passes; (++pass), (ping = (!ping))) 
# 424
{ 
# 425
Size num_blocks_per_merge = 2 << pass; 
# 427
if (ping) 
# 428
{ 
# 429
locate_merge_paths(exec, (merge_paths.begin()), (merge_paths.size()), first, n, work_per_block, num_blocks_per_merge, comp); 
# 431
merge_adjacent_partitions< work_per_thread> (exec, context, block_size, num_blocks_per_merge, first, n, (merge_paths.begin()), thrust::raw_pointer_cast(&(*(virtual_smem.begin()))), (pong_buffer.begin()), comp); 
# 432
} else 
# 434
{ 
# 435
locate_merge_paths(exec, (merge_paths.begin()), (merge_paths.size()), (pong_buffer.begin()), n, work_per_block, num_blocks_per_merge, comp); 
# 437
merge_adjacent_partitions< work_per_thread> (exec, context, block_size, num_blocks_per_merge, (pong_buffer.begin()), n, (merge_paths.begin()), thrust::raw_pointer_cast(&(*(virtual_smem.begin()))), first, comp); 
# 438
}  
# 439
}  
# 440
} 
# 443
template< class DerivedPolicy, class RandomAccessIterator, class Compare> void 
# 445
stable_merge_sort(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator 
# 446
first, RandomAccessIterator 
# 447
last, Compare 
# 448
comp) 
# 449
{ 
# 450
typedef typename iterator_difference< RandomAccessIterator> ::type difference_type; 
# 452
difference_type n = last - first; 
# 455
thrust::detail::uint32_t threshold = thrust::detail::integer_traits_base< unsigned, 0U, 4294967295U> ::const_max; 
# 456
if ((sizeof(difference_type) > sizeof(thrust::detail::uint32_t)) && (n <= ((difference_type)threshold))) 
# 457
{ 
# 458
stable_merge_sort_n(exec, first, static_cast< thrust::detail::uint32_t>(n), comp); 
# 459
} else 
# 461
{ 
# 462
stable_merge_sort_n(exec, first, n, comp); 
# 463
}  
# 464
} 
# 467
}
# 470
template< class DerivedPolicy, class RandomAccessIterator, class Compare> void 
# 472
stable_merge_sort(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator 
# 473
first, RandomAccessIterator 
# 474
last, Compare 
# 475
comp) 
# 476
{ 
# 478
typedef typename iterator_value< RandomAccessIterator> ::type value_type; 
# 480
typedef thrust::detail::integral_constant< bool, (sizeof(typename iterator_value< RandomAccessIterator> ::type) > (16))>  use_indirection; 
# 487
conditional_temporary_indirect_ordering< thrust::detail::integral_constant< bool, (sizeof(typename iterator_value< RandomAccessIterator> ::type) > (16))> , DerivedPolicy, RandomAccessIterator, Compare>  potentially_indirect_range(exec, first, last, comp); 
# 489
stable_merge_sort_detail::stable_merge_sort(exec, (potentially_indirect_range.begin()), (potentially_indirect_range.end()), (potentially_indirect_range.comp())); 
# 493
} 
# 496
template< class DerivedPolicy, class RandomAccessIterator1, class RandomAccessIterator2, class Compare> void 
# 498
stable_merge_sort_by_key(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator1 
# 499
keys_first, RandomAccessIterator1 
# 500
keys_last, RandomAccessIterator2 
# 501
values_first, Compare 
# 502
comp) 
# 503
{ 
# 504
typedef tuple< RandomAccessIterator1, RandomAccessIterator2, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type>  iterator_tuple; 
# 505
typedef thrust::zip_iterator< tuple< RandomAccessIterator1, RandomAccessIterator2, null_type, null_type, null_type, null_type, null_type, null_type, null_type, null_type> >  zip_iterator; 
# 507
zip_iterator zipped_first = thrust::make_zip_iterator(thrust::make_tuple(keys_first, values_first)); 
# 508
zip_iterator zipped_last = thrust::make_zip_iterator(thrust::make_tuple(keys_last, values_first)); 
# 510
thrust::detail::compare_first< Compare>  comp_first(comp); 
# 512
stable_merge_sort(exec, zipped_first, zipped_last, comp_first); 
# 513
} 
# 516
}
# 517
}
# 518
}
# 519
}
# 520
}
# 23 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/detail/stable_primitive_sort.h"
namespace thrust { 
# 25
namespace system { 
# 27
namespace cuda { 
# 29
namespace detail { 
# 31
namespace detail { 
# 35
template< class DerivedPolicy, class 
# 36
RandomAccessIterator> void 
# 35
stable_primitive_sort(execution_policy< DerivedPolicy>  & exec, RandomAccessIterator first, RandomAccessIterator last, less< typename iterator_value< RandomAccessIterator> ::type> ); 
# 44
template< class DerivedPolicy, class 
# 45
RandomAccessIterator> void 
# 44
stable_primitive_sort(execution_policy< DerivedPolicy>  & exec, RandomAccessIterator first, RandomAccessIterator last, greater< typename iterator_value< RandomAccessIterator> ::type> ); 
# 53
template< class DerivedPolicy, class 
# 54
RandomAccessIterator1, class 
# 55
RandomAccessIterator2> void 
# 53
stable_primitive_sort_by_key(execution_policy< DerivedPolicy>  & exec, RandomAccessIterator1 keys_first, RandomAccessIterator1 keys_last, RandomAccessIterator2 values_first, less< typename iterator_value< RandomAccessIterator1> ::type> ); 
# 64
template< class DerivedPolicy, class 
# 65
RandomAccessIterator1, class 
# 66
RandomAccessIterator2> void 
# 64
stable_primitive_sort_by_key(execution_policy< DerivedPolicy>  & exec, RandomAccessIterator1 keys_first, RandomAccessIterator1 keys_last, RandomAccessIterator2 values_first, greater< typename iterator_value< RandomAccessIterator1> ::type> ); 
# 75
}
# 76
}
# 77
}
# 78
}
# 79
}
# 28 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/detail/stable_radix_sort.h"
namespace thrust { 
# 30
namespace system { 
# 32
namespace cuda { 
# 34
namespace detail { 
# 36
namespace detail { 
# 40
template< class DerivedPolicy, class 
# 41
RandomAccessIterator> void 
# 40
stable_radix_sort(execution_policy< DerivedPolicy>  & exec, RandomAccessIterator first, RandomAccessIterator last, less< typename iterator_value< RandomAccessIterator> ::type> ); 
# 49
template< class DerivedPolicy, class 
# 50
RandomAccessIterator> void 
# 49
stable_radix_sort(execution_policy< DerivedPolicy>  & exec, RandomAccessIterator first, RandomAccessIterator last, greater< typename iterator_value< RandomAccessIterator> ::type> ); 
# 58
template< class DerivedPolicy, class 
# 59
RandomAccessIterator1, class 
# 60
RandomAccessIterator2> void 
# 58
stable_radix_sort_by_key(execution_policy< DerivedPolicy>  & exec, RandomAccessIterator1 keys_first, RandomAccessIterator1 keys_last, RandomAccessIterator2 values_first, less< typename iterator_value< RandomAccessIterator1> ::type> ); 
# 69
template< class DerivedPolicy, class 
# 70
RandomAccessIterator1, class 
# 71
RandomAccessIterator2> void 
# 69
stable_radix_sort_by_key(execution_policy< DerivedPolicy>  & exec, RandomAccessIterator1 keys_first, RandomAccessIterator1 keys_last, RandomAccessIterator2 values_first, greater< typename iterator_value< RandomAccessIterator1> ::type> ); 
# 80
}
# 81
}
# 82
}
# 83
}
# 84
}
# 38 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../util_macro.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 41
namespace cub_ { 
# 106
}
# 107
}}}}
# 39 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../util_arch.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 42
namespace cub_ { 
# 197
}
# 198
}}}}
# 44 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../util_type.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 47
namespace cub_ { 
# 64
template< bool IF, class ThenType, class ElseType> 
# 65
struct If { 
# 68
typedef ThenType Type; 
# 69
}; 
# 73
template< class ThenType, class ElseType> 
# 74
struct If< false, ThenType, ElseType>  { 
# 76
typedef ElseType Type; 
# 77
}; 
# 90
template< class A, class B> 
# 91
struct Equals { 
# 93
enum { 
# 94
VALUE, 
# 95
NEGATE = 1
# 96
}; 
# 97
}; 
# 101
template< class A> 
# 102
struct Equals< A, A>  { 
# 104
enum { 
# 105
VALUE = 1, 
# 106
NEGATE = 0
# 107
}; 
# 108
}; 
# 120
struct NullType { 
# 124
template< class T> 
# 125
__attribute((always_inline)) NullType &operator=(const T &b) { return *this; } 
# 127
__attribute((always_inline)) bool operator==(const NullType &b) { return true; } 
# 129
__attribute((always_inline)) bool operator!=(const NullType &b) { return false; } 
# 132
}; 
# 138
template< int A> 
# 139
struct Int2Type { 
# 141
enum { VALUE = A}; 
# 142
}; 
# 153
template< class T> 
# 154
struct AlignBytes { 
# 156
struct Pad { 
# 158
T val; 
# 159
char byte; 
# 160
}; 
# 163
enum { 
# 165
ALIGN_BYTES = sizeof(Pad) - sizeof(T)
# 166
}; 
# 167
}; 
# 171
template<> struct AlignBytes< short4>  { enum { ALIGN_BYTES = 8}; }; 
# 172
template<> struct AlignBytes< ushort4>  { enum { ALIGN_BYTES = 8}; }; 
# 173
template<> struct AlignBytes< int2>  { enum { ALIGN_BYTES = 8}; }; 
# 174
template<> struct AlignBytes< uint2>  { enum { ALIGN_BYTES = 8}; }; 
# 179
template<> struct AlignBytes< long long>  { enum { ALIGN_BYTES = 8}; }; 
# 180
template<> struct AlignBytes< unsigned long long>  { enum { ALIGN_BYTES = 8}; }; 
# 181
template<> struct AlignBytes< float2>  { enum { ALIGN_BYTES = 8}; }; 
# 182
template<> struct AlignBytes< double>  { enum { ALIGN_BYTES = 8}; }; 
# 184
template<> struct AlignBytes< int4>  { enum { ALIGN_BYTES = 16}; }; 
# 185
template<> struct AlignBytes< uint4>  { enum { ALIGN_BYTES = 16}; }; 
# 186
template<> struct AlignBytes< float4>  { enum { ALIGN_BYTES = 16}; }; 
# 188
template<> struct AlignBytes< long2>  { enum { ALIGN_BYTES = 16}; }; 
# 189
template<> struct AlignBytes< ulong2>  { enum { ALIGN_BYTES = 16}; }; 
# 191
template<> struct AlignBytes< long4>  { enum { ALIGN_BYTES = 16}; }; 
# 192
template<> struct AlignBytes< ulong4>  { enum { ALIGN_BYTES = 16}; }; 
# 193
template<> struct AlignBytes< longlong2>  { enum { ALIGN_BYTES = 16}; }; 
# 194
template<> struct AlignBytes< ulonglong2>  { enum { ALIGN_BYTES = 16}; }; 
# 195
template<> struct AlignBytes< double2>  { enum { ALIGN_BYTES = 16}; }; 
# 196
template<> struct AlignBytes< longlong4>  { enum { ALIGN_BYTES = 16}; }; 
# 197
template<> struct AlignBytes< ulonglong4>  { enum { ALIGN_BYTES = 16}; }; 
# 198
template<> struct AlignBytes< double4>  { enum { ALIGN_BYTES = 16}; }; 
# 202
template< class T> 
# 203
struct UnitWord { 
# 205
enum { 
# 206
ALIGN_BYTES = AlignBytes< T> ::ALIGN_BYTES
# 207
}; 
# 209
template< class Unit> 
# 210
struct IsMultiple { 
# 212
enum { 
# 213
UNIT_ALIGN_BYTES = AlignBytes< Unit> ::ALIGN_BYTES, 
# 214
IS_MULTIPLE = ((sizeof(T) % sizeof(Unit)) == (0)) && (((AlignBytes< T> ::ALIGN_BYTES) % (AlignBytes< Unit> ::ALIGN_BYTES)) == 0)
# 215
}; 
# 216
}; 
# 223
typedef typename If< IsMultiple< int> ::IS_MULTIPLE, unsigned, typename If< IsMultiple< short> ::IS_MULTIPLE, unsigned short, unsigned char> ::Type> ::Type ShuffleWord; 
# 228
typedef typename If< IsMultiple< long long> ::IS_MULTIPLE, unsigned long long, typename If< IsMultiple< int> ::IS_MULTIPLE, unsigned, typename If< IsMultiple< short> ::IS_MULTIPLE, unsigned short, unsigned char> ::Type> ::Type> ::Type VolatileWord; 
# 233
typedef typename If< IsMultiple< longlong2> ::IS_MULTIPLE, ulonglong2, typename If< IsMultiple< long long> ::IS_MULTIPLE, unsigned long long, typename If< IsMultiple< int> ::IS_MULTIPLE, unsigned, typename If< IsMultiple< short> ::IS_MULTIPLE, unsigned short, unsigned char> ::Type> ::Type> ::Type> ::Type DeviceWord; 
# 240
typedef typename If< IsMultiple< int4> ::IS_MULTIPLE, uint4, typename If< IsMultiple< int2> ::IS_MULTIPLE, uint2, typename If< IsMultiple< int> ::IS_MULTIPLE, unsigned, typename If< IsMultiple< short> ::IS_MULTIPLE, unsigned short, unsigned char> ::Type> ::Type> ::Type> ::Type TextureWord; 
# 241
}; 
# 246
template<> struct UnitWord< float2>  { 
# 248
typedef int ShuffleWord; 
# 253
typedef unsigned long long VolatileWord; 
# 254
typedef unsigned long long DeviceWord; 
# 256
typedef float2 TextureWord; 
# 257
}; 
# 261
template<> struct UnitWord< float4>  { 
# 263
typedef int ShuffleWord; 
# 268
typedef unsigned long long VolatileWord; 
# 269
typedef ulonglong2 DeviceWord; 
# 271
typedef float4 TextureWord; 
# 272
}; 
# 277
template<> struct UnitWord< char2>  { 
# 279
typedef unsigned short ShuffleWord; 
# 284
typedef unsigned short VolatileWord; 
# 285
typedef unsigned short DeviceWord; 
# 287
typedef unsigned short TextureWord; 
# 288
}; 
# 301
template< class T, int vec_elements> struct CubVector; 
# 306
enum { 
# 308
MAX_VEC_ELEMENTS = 4
# 309
}; 
# 315
template< class T> 
# 316
struct CubVector< T, 1>  { 
# 318
T x; 
# 320
typedef T BaseType; 
# 321
typedef cub_::CubVector< T, 1>  Type; 
# 322
}; 
# 327
template< class T> 
# 328
struct CubVector< T, 2>  { 
# 330
T x; 
# 331
T y; 
# 333
typedef T BaseType; 
# 334
typedef cub_::CubVector< T, 2>  Type; 
# 335
}; 
# 340
template< class T> 
# 341
struct CubVector< T, 3>  { 
# 343
T x; 
# 344
T y; 
# 345
T z; 
# 347
typedef T BaseType; 
# 348
typedef cub_::CubVector< T, 3>  Type; 
# 349
}; 
# 354
template< class T> 
# 355
struct CubVector< T, 4>  { 
# 357
T x; 
# 358
T y; 
# 359
T z; 
# 360
T w; 
# 362
typedef T BaseType; 
# 363
typedef cub_::CubVector< T, 4>  Type; 
# 364
}; 
# 451
template<> struct CubVector< char, 1>  : public char1 { typedef char BaseType; typedef char1 Type; __attribute((always_inline)) cub_::CubVector< char, 1>  operator+(const cub_::CubVector< char, 1>  &other) const { cub_::CubVector< char, 1>  retval; (retval.x) = ((x) + (other.x)); return retval; } __attribute((always_inline)) cub_::CubVector< char, 1>  operator-(const cub_::CubVector< char, 1>  &other) const { cub_::CubVector< char, 1>  retval; (retval.x) = ((x) - (other.x)); return retval; } }; template<> struct CubVector< char, 2>  : public char2 { typedef char BaseType; typedef char2 Type; __attribute((always_inline)) cub_::CubVector< char, 2>  operator+(const cub_::CubVector< char, 2>  &other) const { cub_::CubVector< char, 2>  retval; (retval.x) = ((x) + (other.x)); (retval.y) = ((y) + (other.y)); return retval; } __attribute((always_inline)) cub_::CubVector< char, 2>  operator-(const cub_::CubVector< char, 2>  &other) const { cub_::CubVector< char, 2>  retval; (retval.x) = ((x) - (other.x)); (retval.y) = ((y) - (other.y)); return retval; } }; template<> struct CubVector< char, 3>  : public char3 { typedef char BaseType; typedef char3 Type; __attribute((always_inline)) cub_::CubVector< char, 3>  operator+(const cub_::CubVector< char, 3>  &other) const { cub_::CubVector< char, 3>  retval; (retval.x) = ((x) + (other.x)); (retval.y) = ((y) + (other.y)); (retval.z) = ((z) + (other.z)); return retval; } __attribute((always_inline)) cub_::CubVector< char, 3>  operator-(const cub_::CubVector< char, 3>  &other) const { cub_::CubVector< char, 3>  retval; (retval.x) = ((x) - (other.x)); (retval.y) = ((y) - (other.y)); (retval.z) = ((z) - (other.z)); return retval; } }; template<> struct CubVector< char, 4>  : public char4 { typedef char BaseType; typedef char4 Type; __attribute((always_inline)) cub_::CubVector< char, 4>  operator+(const cub_::CubVector< char, 4>  &other) const { cub_::CubVector< char, 4>  retval; (retval.x) = ((x) + (other.x)); (retval.y) = ((y) + (other.y)); (retval.z) = ((z) + (other.z)); (retval.w) = ((w) + (other.w)); return retval; } __attribute((always_inline)) cub_::CubVector< char, 4>  operator-(const cub_::CubVector< char, 4>  &other) const { cub_::CubVector< char, 4>  retval; (retval.x) = ((x) - (other.x)); (retval.y) = ((y) - (other.y)); (retval.z) = ((z) - (other.z)); (retval.w) = ((w) - (other.w)); return retval; } }; 
# 452
template<> struct CubVector< signed char, 1>  : public char1 { typedef signed char BaseType; typedef char1 Type; __attribute((always_inline)) cub_::CubVector< signed char, 1>  operator+(const cub_::CubVector< signed char, 1>  &other) const { cub_::CubVector< signed char, 1>  retval; (retval.x) = ((x) + (other.x)); return retval; } __attribute((always_inline)) cub_::CubVector< signed char, 1>  operator-(const cub_::CubVector< signed char, 1>  &other) const { cub_::CubVector< signed char, 1>  retval; (retval.x) = ((x) - (other.x)); return retval; } }; template<> struct CubVector< signed char, 2>  : public char2 { typedef signed char BaseType; typedef char2 Type; __attribute((always_inline)) cub_::CubVector< signed char, 2>  operator+(const cub_::CubVector< signed char, 2>  &other) const { cub_::CubVector< signed char, 2>  retval; (retval.x) = ((x) + (other.x)); (retval.y) = ((y) + (other.y)); return retval; } __attribute((always_inline)) cub_::CubVector< signed char, 2>  operator-(const cub_::CubVector< signed char, 2>  &other) const { cub_::CubVector< signed char, 2>  retval; (retval.x) = ((x) - (other.x)); (retval.y) = ((y) - (other.y)); return retval; } }; template<> struct CubVector< signed char, 3>  : public char3 { typedef signed char BaseType; typedef char3 Type; __attribute((always_inline)) cub_::CubVector< signed char, 3>  operator+(const cub_::CubVector< signed char, 3>  &other) const { cub_::CubVector< signed char, 3>  retval; (retval.x) = ((x) + (other.x)); (retval.y) = ((y) + (other.y)); (retval.z) = ((z) + (other.z)); return retval; } __attribute((always_inline)) cub_::CubVector< signed char, 3>  operator-(const cub_::CubVector< signed char, 3>  &other) const { cub_::CubVector< signed char, 3>  retval; (retval.x) = ((x) - (other.x)); (retval.y) = ((y) - (other.y)); (retval.z) = ((z) - (other.z)); return retval; } }; template<> struct CubVector< signed char, 4>  : public char4 { typedef signed char BaseType; typedef char4 Type; __attribute((always_inline)) cub_::CubVector< signed char, 4>  operator+(const cub_::CubVector< signed char, 4>  &other) const { cub_::CubVector< signed char, 4>  retval; (retval.x) = ((x) + (other.x)); (retval.y) = ((y) + (other.y)); (retval.z) = ((z) + (other.z)); (retval.w) = ((w) + (other.w)); return retval; } __attribute((always_inline)) cub_::CubVector< signed char, 4>  operator-(const cub_::CubVector< signed char, 4>  &other) const { cub_::CubVector< signed char, 4>  retval; (retval.x) = ((x) - (other.x)); (retval.y) = ((y) - (other.y)); (retval.z) = ((z) - (other.z)); (retval.w) = ((w) - (other.w)); return retval; } }; 
# 453
template<> struct CubVector< short, 1>  : public short1 { typedef short BaseType; typedef short1 Type; __attribute((always_inline)) cub_::CubVector< short, 1>  operator+(const cub_::CubVector< short, 1>  &other) const { cub_::CubVector< short, 1>  retval; (retval.x) = ((x) + (other.x)); return retval; } __attribute((always_inline)) cub_::CubVector< short, 1>  operator-(const cub_::CubVector< short, 1>  &other) const { cub_::CubVector< short, 1>  retval; (retval.x) = ((x) - (other.x)); return retval; } }; template<> struct CubVector< short, 2>  : public short2 { typedef short BaseType; typedef short2 Type; __attribute((always_inline)) cub_::CubVector< short, 2>  operator+(const cub_::CubVector< short, 2>  &other) const { cub_::CubVector< short, 2>  retval; (retval.x) = ((x) + (other.x)); (retval.y) = ((y) + (other.y)); return retval; } __attribute((always_inline)) cub_::CubVector< short, 2>  operator-(const cub_::CubVector< short, 2>  &other) const { cub_::CubVector< short, 2>  retval; (retval.x) = ((x) - (other.x)); (retval.y) = ((y) - (other.y)); return retval; } }; template<> struct CubVector< short, 3>  : public short3 { typedef short BaseType; typedef short3 Type; __attribute((always_inline)) cub_::CubVector< short, 3>  operator+(const cub_::CubVector< short, 3>  &other) const { cub_::CubVector< short, 3>  retval; (retval.x) = ((x) + (other.x)); (retval.y) = ((y) + (other.y)); (retval.z) = ((z) + (other.z)); return retval; } __attribute((always_inline)) cub_::CubVector< short, 3>  operator-(const cub_::CubVector< short, 3>  &other) const { cub_::CubVector< short, 3>  retval; (retval.x) = ((x) - (other.x)); (retval.y) = ((y) - (other.y)); (retval.z) = ((z) - (other.z)); return retval; } }; template<> struct CubVector< short, 4>  : public short4 { typedef short BaseType; typedef short4 Type; __attribute((always_inline)) cub_::CubVector< short, 4>  operator+(const cub_::CubVector< short, 4>  &other) const { cub_::CubVector< short, 4>  retval; (retval.x) = ((x) + (other.x)); (retval.y) = ((y) + (other.y)); (retval.z) = ((z) + (other.z)); (retval.w) = ((w) + (other.w)); return retval; } __attribute((always_inline)) cub_::CubVector< short, 4>  operator-(const cub_::CubVector< short, 4>  &other) const { cub_::CubVector< short, 4>  retval; (retval.x) = ((x) - (other.x)); (retval.y) = ((y) - (other.y)); (retval.z) = ((z) - (other.z)); (retval.w) = ((w) - (other.w)); return retval; } }; 
# 454
template<> struct CubVector< int, 1>  : public int1 { typedef int BaseType; typedef int1 Type; __attribute((always_inline)) cub_::CubVector< int, 1>  operator+(const cub_::CubVector< int, 1>  &other) const { cub_::CubVector< int, 1>  retval; (retval.x) = ((x) + (other.x)); return retval; } __attribute((always_inline)) cub_::CubVector< int, 1>  operator-(const cub_::CubVector< int, 1>  &other) const { cub_::CubVector< int, 1>  retval; (retval.x) = ((x) - (other.x)); return retval; } }; template<> struct CubVector< int, 2>  : public int2 { typedef int BaseType; typedef int2 Type; __attribute((always_inline)) cub_::CubVector< int, 2>  operator+(const cub_::CubVector< int, 2>  &other) const { cub_::CubVector< int, 2>  retval; (retval.x) = ((x) + (other.x)); (retval.y) = ((y) + (other.y)); return retval; } __attribute((always_inline)) cub_::CubVector< int, 2>  operator-(const cub_::CubVector< int, 2>  &other) const { cub_::CubVector< int, 2>  retval; (retval.x) = ((x) - (other.x)); (retval.y) = ((y) - (other.y)); return retval; } }; template<> struct CubVector< int, 3>  : public int3 { typedef int BaseType; typedef int3 Type; __attribute((always_inline)) cub_::CubVector< int, 3>  operator+(const cub_::CubVector< int, 3>  &other) const { cub_::CubVector< int, 3>  retval; (retval.x) = ((x) + (other.x)); (retval.y) = ((y) + (other.y)); (retval.z) = ((z) + (other.z)); return retval; } __attribute((always_inline)) cub_::CubVector< int, 3>  operator-(const cub_::CubVector< int, 3>  &other) const { cub_::CubVector< int, 3>  retval; (retval.x) = ((x) - (other.x)); (retval.y) = ((y) - (other.y)); (retval.z) = ((z) - (other.z)); return retval; } }; template<> struct CubVector< int, 4>  : public int4 { typedef int BaseType; typedef int4 Type; __attribute((always_inline)) cub_::CubVector< int, 4>  operator+(const cub_::CubVector< int, 4>  &other) const { cub_::CubVector< int, 4>  retval; (retval.x) = ((x) + (other.x)); (retval.y) = ((y) + (other.y)); (retval.z) = ((z) + (other.z)); (retval.w) = ((w) + (other.w)); return retval; } __attribute((always_inline)) cub_::CubVector< int, 4>  operator-(const cub_::CubVector< int, 4>  &other) const { cub_::CubVector< int, 4>  retval; (retval.x) = ((x) - (other.x)); (retval.y) = ((y) - (other.y)); (retval.z) = ((z) - (other.z)); (retval.w) = ((w) - (other.w)); return retval; } }; 
# 455
template<> struct CubVector< long, 1>  : public long1 { typedef long BaseType; typedef long1 Type; __attribute((always_inline)) cub_::CubVector< long, 1>  operator+(const cub_::CubVector< long, 1>  &other) const { cub_::CubVector< long, 1>  retval; (retval.x) = ((x) + (other.x)); return retval; } __attribute((always_inline)) cub_::CubVector< long, 1>  operator-(const cub_::CubVector< long, 1>  &other) const { cub_::CubVector< long, 1>  retval; (retval.x) = ((x) - (other.x)); return retval; } }; template<> struct CubVector< long, 2>  : public long2 { typedef long BaseType; typedef long2 Type; __attribute((always_inline)) cub_::CubVector< long, 2>  operator+(const cub_::CubVector< long, 2>  &other) const { cub_::CubVector< long, 2>  retval; (retval.x) = ((x) + (other.x)); (retval.y) = ((y) + (other.y)); return retval; } __attribute((always_inline)) cub_::CubVector< long, 2>  operator-(const cub_::CubVector< long, 2>  &other) const { cub_::CubVector< long, 2>  retval; (retval.x) = ((x) - (other.x)); (retval.y) = ((y) - (other.y)); return retval; } }; template<> struct CubVector< long, 3>  : public long3 { typedef long BaseType; typedef long3 Type; __attribute((always_inline)) cub_::CubVector< long, 3>  operator+(const cub_::CubVector< long, 3>  &other) const { cub_::CubVector< long, 3>  retval; (retval.x) = ((x) + (other.x)); (retval.y) = ((y) + (other.y)); (retval.z) = ((z) + (other.z)); return retval; } __attribute((always_inline)) cub_::CubVector< long, 3>  operator-(const cub_::CubVector< long, 3>  &other) const { cub_::CubVector< long, 3>  retval; (retval.x) = ((x) - (other.x)); (retval.y) = ((y) - (other.y)); (retval.z) = ((z) - (other.z)); return retval; } }; template<> struct CubVector< long, 4>  : public long4 { typedef long BaseType; typedef long4 Type; __attribute((always_inline)) cub_::CubVector< long, 4>  operator+(const cub_::CubVector< long, 4>  &other) const { cub_::CubVector< long, 4>  retval; (retval.x) = ((x) + (other.x)); (retval.y) = ((y) + (other.y)); (retval.z) = ((z) + (other.z)); (retval.w) = ((w) + (other.w)); return retval; } __attribute((always_inline)) cub_::CubVector< long, 4>  operator-(const cub_::CubVector< long, 4>  &other) const { cub_::CubVector< long, 4>  retval; (retval.x) = ((x) - (other.x)); (retval.y) = ((y) - (other.y)); (retval.z) = ((z) - (other.z)); (retval.w) = ((w) - (other.w)); return retval; } }; 
# 456
template<> struct CubVector< long long, 1>  : public longlong1 { typedef long long BaseType; typedef longlong1 Type; __attribute((always_inline)) cub_::CubVector< long long, 1>  operator+(const cub_::CubVector< long long, 1>  &other) const { cub_::CubVector< long long, 1>  retval; (retval.x) = ((x) + (other.x)); return retval; } __attribute((always_inline)) cub_::CubVector< long long, 1>  operator-(const cub_::CubVector< long long, 1>  &other) const { cub_::CubVector< long long, 1>  retval; (retval.x) = ((x) - (other.x)); return retval; } }; template<> struct CubVector< long long, 2>  : public longlong2 { typedef long long BaseType; typedef longlong2 Type; __attribute((always_inline)) cub_::CubVector< long long, 2>  operator+(const cub_::CubVector< long long, 2>  &other) const { cub_::CubVector< long long, 2>  retval; (retval.x) = ((x) + (other.x)); (retval.y) = ((y) + (other.y)); return retval; } __attribute((always_inline)) cub_::CubVector< long long, 2>  operator-(const cub_::CubVector< long long, 2>  &other) const { cub_::CubVector< long long, 2>  retval; (retval.x) = ((x) - (other.x)); (retval.y) = ((y) - (other.y)); return retval; } }; template<> struct CubVector< long long, 3>  : public longlong3 { typedef long long BaseType; typedef longlong3 Type; __attribute((always_inline)) cub_::CubVector< long long, 3>  operator+(const cub_::CubVector< long long, 3>  &other) const { cub_::CubVector< long long, 3>  retval; (retval.x) = ((x) + (other.x)); (retval.y) = ((y) + (other.y)); (retval.z) = ((z) + (other.z)); return retval; } __attribute((always_inline)) cub_::CubVector< long long, 3>  operator-(const cub_::CubVector< long long, 3>  &other) const { cub_::CubVector< long long, 3>  retval; (retval.x) = ((x) - (other.x)); (retval.y) = ((y) - (other.y)); (retval.z) = ((z) - (other.z)); return retval; } }; template<> struct CubVector< long long, 4>  : public longlong4 { typedef long long BaseType; typedef longlong4 Type; __attribute((always_inline)) cub_::CubVector< long long, 4>  operator+(const cub_::CubVector< long long, 4>  &other) const { cub_::CubVector< long long, 4>  retval; (retval.x) = ((x) + (other.x)); (retval.y) = ((y) + (other.y)); (retval.z) = ((z) + (other.z)); (retval.w) = ((w) + (other.w)); return retval; } __attribute((always_inline)) cub_::CubVector< long long, 4>  operator-(const cub_::CubVector< long long, 4>  &other) const { cub_::CubVector< long long, 4>  retval; (retval.x) = ((x) - (other.x)); (retval.y) = ((y) - (other.y)); (retval.z) = ((z) - (other.z)); (retval.w) = ((w) - (other.w)); return retval; } }; 
# 457
template<> struct CubVector< unsigned char, 1>  : public uchar1 { typedef unsigned char BaseType; typedef uchar1 Type; __attribute((always_inline)) cub_::CubVector< unsigned char, 1>  operator+(const cub_::CubVector< unsigned char, 1>  &other) const { cub_::CubVector< unsigned char, 1>  retval; (retval.x) = ((x) + (other.x)); return retval; } __attribute((always_inline)) cub_::CubVector< unsigned char, 1>  operator-(const cub_::CubVector< unsigned char, 1>  &other) const { cub_::CubVector< unsigned char, 1>  retval; (retval.x) = ((x) - (other.x)); return retval; } }; template<> struct CubVector< unsigned char, 2>  : public uchar2 { typedef unsigned char BaseType; typedef uchar2 Type; __attribute((always_inline)) cub_::CubVector< unsigned char, 2>  operator+(const cub_::CubVector< unsigned char, 2>  &other) const { cub_::CubVector< unsigned char, 2>  retval; (retval.x) = ((x) + (other.x)); (retval.y) = ((y) + (other.y)); return retval; } __attribute((always_inline)) cub_::CubVector< unsigned char, 2>  operator-(const cub_::CubVector< unsigned char, 2>  &other) const { cub_::CubVector< unsigned char, 2>  retval; (retval.x) = ((x) - (other.x)); (retval.y) = ((y) - (other.y)); return retval; } }; template<> struct CubVector< unsigned char, 3>  : public uchar3 { typedef unsigned char BaseType; typedef uchar3 Type; __attribute((always_inline)) cub_::CubVector< unsigned char, 3>  operator+(const cub_::CubVector< unsigned char, 3>  &other) const { cub_::CubVector< unsigned char, 3>  retval; (retval.x) = ((x) + (other.x)); (retval.y) = ((y) + (other.y)); (retval.z) = ((z) + (other.z)); return retval; } __attribute((always_inline)) cub_::CubVector< unsigned char, 3>  operator-(const cub_::CubVector< unsigned char, 3>  &other) const { cub_::CubVector< unsigned char, 3>  retval; (retval.x) = ((x) - (other.x)); (retval.y) = ((y) - (other.y)); (retval.z) = ((z) - (other.z)); return retval; } }; template<> struct CubVector< unsigned char, 4>  : public uchar4 { typedef unsigned char BaseType; typedef uchar4 Type; __attribute((always_inline)) cub_::CubVector< unsigned char, 4>  operator+(const cub_::CubVector< unsigned char, 4>  &other) const { cub_::CubVector< unsigned char, 4>  retval; (retval.x) = ((x) + (other.x)); (retval.y) = ((y) + (other.y)); (retval.z) = ((z) + (other.z)); (retval.w) = ((w) + (other.w)); return retval; } __attribute((always_inline)) cub_::CubVector< unsigned char, 4>  operator-(const cub_::CubVector< unsigned char, 4>  &other) const { cub_::CubVector< unsigned char, 4>  retval; (retval.x) = ((x) - (other.x)); (retval.y) = ((y) - (other.y)); (retval.z) = ((z) - (other.z)); (retval.w) = ((w) - (other.w)); return retval; } }; 
# 458
template<> struct CubVector< unsigned short, 1>  : public ushort1 { typedef unsigned short BaseType; typedef ushort1 Type; __attribute((always_inline)) cub_::CubVector< unsigned short, 1>  operator+(const cub_::CubVector< unsigned short, 1>  &other) const { cub_::CubVector< unsigned short, 1>  retval; (retval.x) = ((x) + (other.x)); return retval; } __attribute((always_inline)) cub_::CubVector< unsigned short, 1>  operator-(const cub_::CubVector< unsigned short, 1>  &other) const { cub_::CubVector< unsigned short, 1>  retval; (retval.x) = ((x) - (other.x)); return retval; } }; template<> struct CubVector< unsigned short, 2>  : public ushort2 { typedef unsigned short BaseType; typedef ushort2 Type; __attribute((always_inline)) cub_::CubVector< unsigned short, 2>  operator+(const cub_::CubVector< unsigned short, 2>  &other) const { cub_::CubVector< unsigned short, 2>  retval; (retval.x) = ((x) + (other.x)); (retval.y) = ((y) + (other.y)); return retval; } __attribute((always_inline)) cub_::CubVector< unsigned short, 2>  operator-(const cub_::CubVector< unsigned short, 2>  &other) const { cub_::CubVector< unsigned short, 2>  retval; (retval.x) = ((x) - (other.x)); (retval.y) = ((y) - (other.y)); return retval; } }; template<> struct CubVector< unsigned short, 3>  : public ushort3 { typedef unsigned short BaseType; typedef ushort3 Type; __attribute((always_inline)) cub_::CubVector< unsigned short, 3>  operator+(const cub_::CubVector< unsigned short, 3>  &other) const { cub_::CubVector< unsigned short, 3>  retval; (retval.x) = ((x) + (other.x)); (retval.y) = ((y) + (other.y)); (retval.z) = ((z) + (other.z)); return retval; } __attribute((always_inline)) cub_::CubVector< unsigned short, 3>  operator-(const cub_::CubVector< unsigned short, 3>  &other) const { cub_::CubVector< unsigned short, 3>  retval; (retval.x) = ((x) - (other.x)); (retval.y) = ((y) - (other.y)); (retval.z) = ((z) - (other.z)); return retval; } }; template<> struct CubVector< unsigned short, 4>  : public ushort4 { typedef unsigned short BaseType; typedef ushort4 Type; __attribute((always_inline)) cub_::CubVector< unsigned short, 4>  operator+(const cub_::CubVector< unsigned short, 4>  &other) const { cub_::CubVector< unsigned short, 4>  retval; (retval.x) = ((x) + (other.x)); (retval.y) = ((y) + (other.y)); (retval.z) = ((z) + (other.z)); (retval.w) = ((w) + (other.w)); return retval; } __attribute((always_inline)) cub_::CubVector< unsigned short, 4>  operator-(const cub_::CubVector< unsigned short, 4>  &other) const { cub_::CubVector< unsigned short, 4>  retval; (retval.x) = ((x) - (other.x)); (retval.y) = ((y) - (other.y)); (retval.z) = ((z) - (other.z)); (retval.w) = ((w) - (other.w)); return retval; } }; 
# 459
template<> struct CubVector< unsigned, 1>  : public uint1 { typedef unsigned BaseType; typedef uint1 Type; __attribute((always_inline)) cub_::CubVector< unsigned, 1>  operator+(const cub_::CubVector< unsigned, 1>  &other) const { cub_::CubVector< unsigned, 1>  retval; (retval.x) = ((x) + (other.x)); return retval; } __attribute((always_inline)) cub_::CubVector< unsigned, 1>  operator-(const cub_::CubVector< unsigned, 1>  &other) const { cub_::CubVector< unsigned, 1>  retval; (retval.x) = ((x) - (other.x)); return retval; } }; template<> struct CubVector< unsigned, 2>  : public uint2 { typedef unsigned BaseType; typedef uint2 Type; __attribute((always_inline)) cub_::CubVector< unsigned, 2>  operator+(const cub_::CubVector< unsigned, 2>  &other) const { cub_::CubVector< unsigned, 2>  retval; (retval.x) = ((x) + (other.x)); (retval.y) = ((y) + (other.y)); return retval; } __attribute((always_inline)) cub_::CubVector< unsigned, 2>  operator-(const cub_::CubVector< unsigned, 2>  &other) const { cub_::CubVector< unsigned, 2>  retval; (retval.x) = ((x) - (other.x)); (retval.y) = ((y) - (other.y)); return retval; } }; template<> struct CubVector< unsigned, 3>  : public uint3 { typedef unsigned BaseType; typedef uint3 Type; __attribute((always_inline)) cub_::CubVector< unsigned, 3>  operator+(const cub_::CubVector< unsigned, 3>  &other) const { cub_::CubVector< unsigned, 3>  retval; (retval.x) = ((x) + (other.x)); (retval.y) = ((y) + (other.y)); (retval.z) = ((z) + (other.z)); return retval; } __attribute((always_inline)) cub_::CubVector< unsigned, 3>  operator-(const cub_::CubVector< unsigned, 3>  &other) const { cub_::CubVector< unsigned, 3>  retval; (retval.x) = ((x) - (other.x)); (retval.y) = ((y) - (other.y)); (retval.z) = ((z) - (other.z)); return retval; } }; template<> struct CubVector< unsigned, 4>  : public uint4 { typedef unsigned BaseType; typedef uint4 Type; __attribute((always_inline)) cub_::CubVector< unsigned, 4>  operator+(const cub_::CubVector< unsigned, 4>  &other) const { cub_::CubVector< unsigned, 4>  retval; (retval.x) = ((x) + (other.x)); (retval.y) = ((y) + (other.y)); (retval.z) = ((z) + (other.z)); (retval.w) = ((w) + (other.w)); return retval; } __attribute((always_inline)) cub_::CubVector< unsigned, 4>  operator-(const cub_::CubVector< unsigned, 4>  &other) const { cub_::CubVector< unsigned, 4>  retval; (retval.x) = ((x) - (other.x)); (retval.y) = ((y) - (other.y)); (retval.z) = ((z) - (other.z)); (retval.w) = ((w) - (other.w)); return retval; } }; 
# 460
template<> struct CubVector< unsigned long, 1>  : public ulong1 { typedef unsigned long BaseType; typedef ulong1 Type; __attribute((always_inline)) cub_::CubVector< unsigned long, 1>  operator+(const cub_::CubVector< unsigned long, 1>  &other) const { cub_::CubVector< unsigned long, 1>  retval; (retval.x) = ((x) + (other.x)); return retval; } __attribute((always_inline)) cub_::CubVector< unsigned long, 1>  operator-(const cub_::CubVector< unsigned long, 1>  &other) const { cub_::CubVector< unsigned long, 1>  retval; (retval.x) = ((x) - (other.x)); return retval; } }; template<> struct CubVector< unsigned long, 2>  : public ulong2 { typedef unsigned long BaseType; typedef ulong2 Type; __attribute((always_inline)) cub_::CubVector< unsigned long, 2>  operator+(const cub_::CubVector< unsigned long, 2>  &other) const { cub_::CubVector< unsigned long, 2>  retval; (retval.x) = ((x) + (other.x)); (retval.y) = ((y) + (other.y)); return retval; } __attribute((always_inline)) cub_::CubVector< unsigned long, 2>  operator-(const cub_::CubVector< unsigned long, 2>  &other) const { cub_::CubVector< unsigned long, 2>  retval; (retval.x) = ((x) - (other.x)); (retval.y) = ((y) - (other.y)); return retval; } }; template<> struct CubVector< unsigned long, 3>  : public ulong3 { typedef unsigned long BaseType; typedef ulong3 Type; __attribute((always_inline)) cub_::CubVector< unsigned long, 3>  operator+(const cub_::CubVector< unsigned long, 3>  &other) const { cub_::CubVector< unsigned long, 3>  retval; (retval.x) = ((x) + (other.x)); (retval.y) = ((y) + (other.y)); (retval.z) = ((z) + (other.z)); return retval; } __attribute((always_inline)) cub_::CubVector< unsigned long, 3>  operator-(const cub_::CubVector< unsigned long, 3>  &other) const { cub_::CubVector< unsigned long, 3>  retval; (retval.x) = ((x) - (other.x)); (retval.y) = ((y) - (other.y)); (retval.z) = ((z) - (other.z)); return retval; } }; template<> struct CubVector< unsigned long, 4>  : public ulong4 { typedef unsigned long BaseType; typedef ulong4 Type; __attribute((always_inline)) cub_::CubVector< unsigned long, 4>  operator+(const cub_::CubVector< unsigned long, 4>  &other) const { cub_::CubVector< unsigned long, 4>  retval; (retval.x) = ((x) + (other.x)); (retval.y) = ((y) + (other.y)); (retval.z) = ((z) + (other.z)); (retval.w) = ((w) + (other.w)); return retval; } __attribute((always_inline)) cub_::CubVector< unsigned long, 4>  operator-(const cub_::CubVector< unsigned long, 4>  &other) const { cub_::CubVector< unsigned long, 4>  retval; (retval.x) = ((x) - (other.x)); (retval.y) = ((y) - (other.y)); (retval.z) = ((z) - (other.z)); (retval.w) = ((w) - (other.w)); return retval; } }; 
# 461
template<> struct CubVector< unsigned long long, 1>  : public ulonglong1 { typedef unsigned long long BaseType; typedef ulonglong1 Type; __attribute((always_inline)) cub_::CubVector< unsigned long long, 1>  operator+(const cub_::CubVector< unsigned long long, 1>  &other) const { cub_::CubVector< unsigned long long, 1>  retval; (retval.x) = ((x) + (other.x)); return retval; } __attribute((always_inline)) cub_::CubVector< unsigned long long, 1>  operator-(const cub_::CubVector< unsigned long long, 1>  &other) const { cub_::CubVector< unsigned long long, 1>  retval; (retval.x) = ((x) - (other.x)); return retval; } }; template<> struct CubVector< unsigned long long, 2>  : public ulonglong2 { typedef unsigned long long BaseType; typedef ulonglong2 Type; __attribute((always_inline)) cub_::CubVector< unsigned long long, 2>  operator+(const cub_::CubVector< unsigned long long, 2>  &other) const { cub_::CubVector< unsigned long long, 2>  retval; (retval.x) = ((x) + (other.x)); (retval.y) = ((y) + (other.y)); return retval; } __attribute((always_inline)) cub_::CubVector< unsigned long long, 2>  operator-(const cub_::CubVector< unsigned long long, 2>  &other) const { cub_::CubVector< unsigned long long, 2>  retval; (retval.x) = ((x) - (other.x)); (retval.y) = ((y) - (other.y)); return retval; } }; template<> struct CubVector< unsigned long long, 3>  : public ulonglong3 { typedef unsigned long long BaseType; typedef ulonglong3 Type; __attribute((always_inline)) cub_::CubVector< unsigned long long, 3>  operator+(const cub_::CubVector< unsigned long long, 3>  &other) const { cub_::CubVector< unsigned long long, 3>  retval; (retval.x) = ((x) + (other.x)); (retval.y) = ((y) + (other.y)); (retval.z) = ((z) + (other.z)); return retval; } __attribute((always_inline)) cub_::CubVector< unsigned long long, 3>  operator-(const cub_::CubVector< unsigned long long, 3>  &other) const { cub_::CubVector< unsigned long long, 3>  retval; (retval.x) = ((x) - (other.x)); (retval.y) = ((y) - (other.y)); (retval.z) = ((z) - (other.z)); return retval; } }; template<> struct CubVector< unsigned long long, 4>  : public ulonglong4 { typedef unsigned long long BaseType; typedef ulonglong4 Type; __attribute((always_inline)) cub_::CubVector< unsigned long long, 4>  operator+(const cub_::CubVector< unsigned long long, 4>  &other) const { cub_::CubVector< unsigned long long, 4>  retval; (retval.x) = ((x) + (other.x)); (retval.y) = ((y) + (other.y)); (retval.z) = ((z) + (other.z)); (retval.w) = ((w) + (other.w)); return retval; } __attribute((always_inline)) cub_::CubVector< unsigned long long, 4>  operator-(const cub_::CubVector< unsigned long long, 4>  &other) const { cub_::CubVector< unsigned long long, 4>  retval; (retval.x) = ((x) - (other.x)); (retval.y) = ((y) - (other.y)); (retval.z) = ((z) - (other.z)); (retval.w) = ((w) - (other.w)); return retval; } }; 
# 462
template<> struct CubVector< float, 1>  : public float1 { typedef float BaseType; typedef float1 Type; __attribute((always_inline)) cub_::CubVector< float, 1>  operator+(const cub_::CubVector< float, 1>  &other) const { cub_::CubVector< float, 1>  retval; (retval.x) = ((x) + (other.x)); return retval; } __attribute((always_inline)) cub_::CubVector< float, 1>  operator-(const cub_::CubVector< float, 1>  &other) const { cub_::CubVector< float, 1>  retval; (retval.x) = ((x) - (other.x)); return retval; } }; template<> struct CubVector< float, 2>  : public float2 { typedef float BaseType; typedef float2 Type; __attribute((always_inline)) cub_::CubVector< float, 2>  operator+(const cub_::CubVector< float, 2>  &other) const { cub_::CubVector< float, 2>  retval; (retval.x) = ((x) + (other.x)); (retval.y) = ((y) + (other.y)); return retval; } __attribute((always_inline)) cub_::CubVector< float, 2>  operator-(const cub_::CubVector< float, 2>  &other) const { cub_::CubVector< float, 2>  retval; (retval.x) = ((x) - (other.x)); (retval.y) = ((y) - (other.y)); return retval; } }; template<> struct CubVector< float, 3>  : public float3 { typedef float BaseType; typedef float3 Type; __attribute((always_inline)) cub_::CubVector< float, 3>  operator+(const cub_::CubVector< float, 3>  &other) const { cub_::CubVector< float, 3>  retval; (retval.x) = ((x) + (other.x)); (retval.y) = ((y) + (other.y)); (retval.z) = ((z) + (other.z)); return retval; } __attribute((always_inline)) cub_::CubVector< float, 3>  operator-(const cub_::CubVector< float, 3>  &other) const { cub_::CubVector< float, 3>  retval; (retval.x) = ((x) - (other.x)); (retval.y) = ((y) - (other.y)); (retval.z) = ((z) - (other.z)); return retval; } }; template<> struct CubVector< float, 4>  : public float4 { typedef float BaseType; typedef float4 Type; __attribute((always_inline)) cub_::CubVector< float, 4>  operator+(const cub_::CubVector< float, 4>  &other) const { cub_::CubVector< float, 4>  retval; (retval.x) = ((x) + (other.x)); (retval.y) = ((y) + (other.y)); (retval.z) = ((z) + (other.z)); (retval.w) = ((w) + (other.w)); return retval; } __attribute((always_inline)) cub_::CubVector< float, 4>  operator-(const cub_::CubVector< float, 4>  &other) const { cub_::CubVector< float, 4>  retval; (retval.x) = ((x) - (other.x)); (retval.y) = ((y) - (other.y)); (retval.z) = ((z) - (other.z)); (retval.w) = ((w) - (other.w)); return retval; } }; 
# 463
template<> struct CubVector< double, 1>  : public double1 { typedef double BaseType; typedef double1 Type; __attribute((always_inline)) cub_::CubVector< double, 1>  operator+(const cub_::CubVector< double, 1>  &other) const { cub_::CubVector< double, 1>  retval; (retval.x) = ((x) + (other.x)); return retval; } __attribute((always_inline)) cub_::CubVector< double, 1>  operator-(const cub_::CubVector< double, 1>  &other) const { cub_::CubVector< double, 1>  retval; (retval.x) = ((x) - (other.x)); return retval; } }; template<> struct CubVector< double, 2>  : public double2 { typedef double BaseType; typedef double2 Type; __attribute((always_inline)) cub_::CubVector< double, 2>  operator+(const cub_::CubVector< double, 2>  &other) const { cub_::CubVector< double, 2>  retval; (retval.x) = ((x) + (other.x)); (retval.y) = ((y) + (other.y)); return retval; } __attribute((always_inline)) cub_::CubVector< double, 2>  operator-(const cub_::CubVector< double, 2>  &other) const { cub_::CubVector< double, 2>  retval; (retval.x) = ((x) - (other.x)); (retval.y) = ((y) - (other.y)); return retval; } }; template<> struct CubVector< double, 3>  : public double3 { typedef double BaseType; typedef double3 Type; __attribute((always_inline)) cub_::CubVector< double, 3>  operator+(const cub_::CubVector< double, 3>  &other) const { cub_::CubVector< double, 3>  retval; (retval.x) = ((x) + (other.x)); (retval.y) = ((y) + (other.y)); (retval.z) = ((z) + (other.z)); return retval; } __attribute((always_inline)) cub_::CubVector< double, 3>  operator-(const cub_::CubVector< double, 3>  &other) const { cub_::CubVector< double, 3>  retval; (retval.x) = ((x) - (other.x)); (retval.y) = ((y) - (other.y)); (retval.z) = ((z) - (other.z)); return retval; } }; template<> struct CubVector< double, 4>  : public double4 { typedef double BaseType; typedef double4 Type; __attribute((always_inline)) cub_::CubVector< double, 4>  operator+(const cub_::CubVector< double, 4>  &other) const { cub_::CubVector< double, 4>  retval; (retval.x) = ((x) + (other.x)); (retval.y) = ((y) + (other.y)); (retval.z) = ((z) + (other.z)); (retval.w) = ((w) + (other.w)); return retval; } __attribute((always_inline)) cub_::CubVector< double, 4>  operator-(const cub_::CubVector< double, 4>  &other) const { cub_::CubVector< double, 4>  retval; (retval.x) = ((x) - (other.x)); (retval.y) = ((y) - (other.y)); (retval.z) = ((z) - (other.z)); (retval.w) = ((w) - (other.w)); return retval; } }; 
# 464
template<> struct CubVector< bool, 1>  : public uchar1 { typedef bool BaseType; typedef uchar1 Type; __attribute((always_inline)) cub_::CubVector< bool, 1>  operator+(const cub_::CubVector< bool, 1>  &other) const { cub_::CubVector< bool, 1>  retval; (retval.x) = ((x) + (other.x)); return retval; } __attribute((always_inline)) cub_::CubVector< bool, 1>  operator-(const cub_::CubVector< bool, 1>  &other) const { cub_::CubVector< bool, 1>  retval; (retval.x) = ((x) - (other.x)); return retval; } }; template<> struct CubVector< bool, 2>  : public uchar2 { typedef bool BaseType; typedef uchar2 Type; __attribute((always_inline)) cub_::CubVector< bool, 2>  operator+(const cub_::CubVector< bool, 2>  &other) const { cub_::CubVector< bool, 2>  retval; (retval.x) = ((x) + (other.x)); (retval.y) = ((y) + (other.y)); return retval; } __attribute((always_inline)) cub_::CubVector< bool, 2>  operator-(const cub_::CubVector< bool, 2>  &other) const { cub_::CubVector< bool, 2>  retval; (retval.x) = ((x) - (other.x)); (retval.y) = ((y) - (other.y)); return retval; } }; template<> struct CubVector< bool, 3>  : public uchar3 { typedef bool BaseType; typedef uchar3 Type; __attribute((always_inline)) cub_::CubVector< bool, 3>  operator+(const cub_::CubVector< bool, 3>  &other) const { cub_::CubVector< bool, 3>  retval; (retval.x) = ((x) + (other.x)); (retval.y) = ((y) + (other.y)); (retval.z) = ((z) + (other.z)); return retval; } __attribute((always_inline)) cub_::CubVector< bool, 3>  operator-(const cub_::CubVector< bool, 3>  &other) const { cub_::CubVector< bool, 3>  retval; (retval.x) = ((x) - (other.x)); (retval.y) = ((y) - (other.y)); (retval.z) = ((z) - (other.z)); return retval; } }; template<> struct CubVector< bool, 4>  : public uchar4 { typedef bool BaseType; typedef uchar4 Type; __attribute((always_inline)) cub_::CubVector< bool, 4>  operator+(const cub_::CubVector< bool, 4>  &other) const { cub_::CubVector< bool, 4>  retval; (retval.x) = ((x) + (other.x)); (retval.y) = ((y) + (other.y)); (retval.z) = ((z) + (other.z)); (retval.w) = ((w) + (other.w)); return retval; } __attribute((always_inline)) cub_::CubVector< bool, 4>  operator-(const cub_::CubVector< bool, 4>  &other) const { cub_::CubVector< bool, 4>  retval; (retval.x) = ((x) - (other.x)); (retval.y) = ((y) - (other.y)); (retval.z) = ((z) - (other.z)); (retval.w) = ((w) - (other.w)); return retval; } }; 
# 480
template< class T> 
# 481
struct Uninitialized { 
# 484
typedef typename UnitWord< T> ::DeviceWord DeviceWord; 
# 487
enum { 
# 488
WORDS = sizeof(T) / sizeof(DeviceWord)
# 489
}; 
# 492
DeviceWord storage[WORDS]; 
# 495
__attribute((always_inline)) T &Alias() 
# 496
{ 
# 497
return reinterpret_cast< T &>(*this); 
# 498
} 
# 499
}; 
# 505
template< class _T, class _Offset> 
# 506
struct ItemOffsetPair { 
# 508
typedef _T T; 
# 509
typedef _Offset Offset; 
# 513
union { 
# 514
Offset offset; 
# 515
typename UnitWord< _T> ::DeviceWord align0; 
# 516
}; 
# 521
T value; 
# 524
__attribute((always_inline)) bool operator!=(const ItemOffsetPair &b) 
# 525
{ 
# 526
return ((value) != (b.value)) || ((cub_::ItemOffsetPair< _T, _Offset> ::offset) != (b.cub_::ItemOffsetPair< _T, _Offset> ::offset)); 
# 527
} 
# 528
}; 
# 534
template< class _Key, class _Value> 
# 535
struct KeyValuePair { 
# 537
typedef _Key Key; 
# 538
typedef _Value Value; 
# 540
Value value; 
# 541
Key key; 
# 544
__attribute((always_inline)) bool operator!=(const KeyValuePair &b) 
# 545
{ 
# 546
return ((value) != (b.value)) || ((key) != (b.key)); 
# 547
} 
# 549
}; 
# 557
template< class T> 
# 558
__attribute((always_inline)) inline T ZeroInitialize() 
# 559
{ 
# 572
return T(); 
# 575
} 
# 581
template< class T, int COUNT> 
# 582
struct ArrayWrapper { 
# 585
T array[COUNT]; 
# 586
}; 
# 598
template< class T> 
# 599
struct DoubleBuffer { 
# 602
T *d_buffers[2]; 
# 605
int selector; 
# 608
__attribute((always_inline)) DoubleBuffer() 
# 609
{ 
# 610
(selector) = 0; 
# 611
((d_buffers)[0]) = __null; 
# 612
((d_buffers)[1]) = __null; 
# 613
} 
# 616
__attribute((always_inline)) DoubleBuffer(T *
# 617
d_current, T *
# 618
d_alternate) 
# 619
{ 
# 620
(selector) = 0; 
# 621
((d_buffers)[0]) = d_current; 
# 622
((d_buffers)[1]) = d_alternate; 
# 623
} 
# 626
__attribute((always_inline)) T *Current() { return (d_buffers)[selector]; } 
# 627
}; 
# 642
template< int N, int CURRENT_VAL = N, int COUNT = 0> 
# 643
struct Log2 { 
# 646
enum { VALUE = cub_::Log2< N, (CURRENT_VAL >> 1), COUNT + 1> ::VALUE}; 
# 647
}; 
# 650
template< int N, int COUNT> 
# 651
struct Log2< N, 0, COUNT>  { 
# 653
enum { VALUE = ((1 << (COUNT - 1)) < N) ? COUNT : (COUNT - 1)
# 655
}; 
# 656
}; 
# 663
template< int N> 
# 664
struct PowerOfTwo { 
# 666
enum { VALUE = (N & (N - 1)) == 0}; 
# 667
}; 
# 680
template< class Tp> 
# 681
struct IsPointer { 
# 683
enum { VALUE}; 
# 684
}; 
# 688
template< class Tp> 
# 689
struct IsPointer< Tp *>  { 
# 691
enum { VALUE = 1}; 
# 692
}; 
# 705
template< class Tp> 
# 706
struct IsVolatile { 
# 708
enum { VALUE}; 
# 709
}; 
# 713
template< class Tp> 
# 714
struct IsVolatile< volatile Tp>  { 
# 716
enum { VALUE = 1}; 
# 717
}; 
# 732
template< class Tp, class Up = Tp> 
# 733
struct RemoveQualifiers { 
# 736
typedef Up Type; 
# 737
}; 
# 741
template< class Tp, class Up> 
# 742
struct RemoveQualifiers< Tp, volatile Up>  { 
# 744
typedef Up Type; 
# 745
}; 
# 747
template< class Tp, class Up> 
# 748
struct RemoveQualifiers< Tp, const Up>  { 
# 750
typedef Up Type; 
# 751
}; 
# 753
template< class Tp, class Up> 
# 754
struct RemoveQualifiers< Tp, const volatile Up>  { 
# 756
typedef Up Type; 
# 757
}; 
# 794
template< bool Condition, class T = void> 
# 795
struct EnableIf { 
# 798
typedef T Type; 
# 799
}; 
# 803
template< class T> 
# 804
struct EnableIf< false, T>  { }; 
# 816
template< class T, class BinaryOp> 
# 817
struct BinaryOpHasIdxParam { 
# 826
private: template< class BinaryOpT, bool (BinaryOpT::*)(const T & a, const T & b, int idx) const> struct SFINAE5 { }; 
# 827
template< class BinaryOpT, bool (BinaryOpT::*)(const T & a, const T & b, int idx)> struct SFINAE6 { }; 
# 828
template< class BinaryOpT, bool (BinaryOpT::*)(T a, T b, int idx) const> struct SFINAE7 { }; 
# 829
template< class BinaryOpT, bool (BinaryOpT::*)(T a, T b, int idx)> struct SFINAE8 { }; 
# 836
template< class BinaryOpT> static char Test(SFINAE5< BinaryOpT, &BinaryOpT::operator()>  *); 
# 837
template< class BinaryOpT> static char Test(SFINAE6< BinaryOpT, &BinaryOpT::operator()>  *); 
# 838
template< class BinaryOpT> static char Test(SFINAE7< BinaryOpT, &BinaryOpT::operator()>  *); 
# 839
template< class BinaryOpT> static char Test(SFINAE8< BinaryOpT, &BinaryOpT::operator()>  *); 
# 841
template< class BinaryOpT> static int Test(...); 
# 846
public: static const bool HAS_PARAM = (sizeof(Test< BinaryOp> (__null)) == sizeof(char)); 
# 847
}; 
# 865
enum Category { 
# 867
NOT_A_NUMBER, 
# 868
SIGNED_INTEGER, 
# 869
UNSIGNED_INTEGER, 
# 870
FLOATING_POINT
# 871
}; 
# 877
template< Category _CATEGORY, bool _PRIMITIVE, bool _NULL_TYPE, class _UnsignedBits> 
# 878
struct BaseTraits { 
# 881
static const Category CATEGORY = _CATEGORY; 
# 883
enum { 
# 884
PRIMITIVE = _PRIMITIVE, 
# 885
NULL_TYPE = _NULL_TYPE
# 886
}; 
# 887
}; 
# 894
template< class _UnsignedBits> 
# 895
struct BaseTraits< UNSIGNED_INTEGER, true, false, _UnsignedBits>  { 
# 897
typedef _UnsignedBits UnsignedBits; 
# 899
static const Category CATEGORY = UNSIGNED_INTEGER; 
# 900
static const UnsignedBits MIN_KEY = ((UnsignedBits)0); 
# 901
static const UnsignedBits MAX_KEY = ((UnsignedBits)(-1)); 
# 904
enum { 
# 905
PRIMITIVE = true, 
# 906
NULL_TYPE = false
# 907
}; 
# 910
__attribute((always_inline)) static UnsignedBits TwiddleIn(UnsignedBits key) 
# 911
{int volatile ___ = 1;(void)key;
# 913
::exit(___);}
#if 0
# 911
{ 
# 912
return key; 
# 913
} 
#endif
# 915 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../util_type.cuh"
__attribute((always_inline)) static UnsignedBits TwiddleOut(UnsignedBits key) 
# 916
{int volatile ___ = 1;(void)key;
# 918
::exit(___);}
#if 0
# 916
{ 
# 917
return key; 
# 918
} 
#endif
# 919 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../util_type.cuh"
}; 
# 925
template< class _UnsignedBits> 
# 926
struct BaseTraits< SIGNED_INTEGER, true, false, _UnsignedBits>  { 
# 928
typedef _UnsignedBits UnsignedBits; 
# 930
static const Category CATEGORY = SIGNED_INTEGER; 
# 931
static const UnsignedBits HIGH_BIT = (((UnsignedBits)1) << ((sizeof(UnsignedBits) * (8)) - (1))); 
# 932
static const UnsignedBits MIN_KEY = HIGH_BIT; 
# 933
static const UnsignedBits MAX_KEY = (((UnsignedBits)(-1)) ^ HIGH_BIT); 
# 936
enum { 
# 937
PRIMITIVE = true, 
# 938
NULL_TYPE = false
# 939
}; 
# 941
__attribute((always_inline)) static UnsignedBits TwiddleIn(UnsignedBits key) 
# 942
{int volatile ___ = 1;(void)key;
# 944
::exit(___);}
#if 0
# 942
{ 
# 943
return key ^ HIGH_BIT; 
# 944
} 
#endif
# 946 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../util_type.cuh"
__attribute((always_inline)) static UnsignedBits TwiddleOut(UnsignedBits key) 
# 947
{int volatile ___ = 1;(void)key;
# 949
::exit(___);}
#if 0
# 947
{ 
# 948
return key ^ HIGH_BIT; 
# 949
} 
#endif
# 951 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../util_type.cuh"
}; 
# 957
template< class _UnsignedBits> 
# 958
struct BaseTraits< FLOATING_POINT, true, false, _UnsignedBits>  { 
# 960
typedef _UnsignedBits UnsignedBits; 
# 962
static const Category CATEGORY = FLOATING_POINT; 
# 963
static const UnsignedBits HIGH_BIT = (((UnsignedBits)1) << ((sizeof(UnsignedBits) * (8)) - (1))); 
# 964
static const UnsignedBits MIN_KEY = ((UnsignedBits)(-1)); 
# 965
static const UnsignedBits MAX_KEY = (((UnsignedBits)(-1)) ^ HIGH_BIT); 
# 967
__attribute((always_inline)) static UnsignedBits TwiddleIn(UnsignedBits key) 
# 968
{int volatile ___ = 1;(void)key;
# 971
::exit(___);}
#if 0
# 968
{ 
# 969
UnsignedBits mask = (key & HIGH_BIT) ? (UnsignedBits)(-1) : HIGH_BIT; 
# 970
return key ^ mask; 
# 971
} 
#endif
# 973 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../util_type.cuh"
__attribute((always_inline)) static UnsignedBits TwiddleOut(UnsignedBits key) 
# 974
{int volatile ___ = 1;(void)key;
# 977
::exit(___);}
#if 0
# 974
{ 
# 975
UnsignedBits mask = (key & HIGH_BIT) ? HIGH_BIT : ((UnsignedBits)(-1)); 
# 976
return key ^ mask; 
# 977
} 
#endif
# 980 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../util_type.cuh"
enum { 
# 981
PRIMITIVE = true, 
# 982
NULL_TYPE = false
# 983
}; 
# 984
}; 
# 992
template< class T> struct NumericTraits : public BaseTraits< NOT_A_NUMBER, false, false, T>  { }; 
# 996
template<> struct NumericTraits< NullType>  : public BaseTraits< NOT_A_NUMBER, false, true, NullType>  { }; 
# 998
template<> struct NumericTraits< char>  : public BaseTraits< UNSIGNED_INTEGER, true, false, unsigned char>  { }; 
# 999
template<> struct NumericTraits< signed char>  : public BaseTraits< SIGNED_INTEGER, true, false, unsigned char>  { }; 
# 1000
template<> struct NumericTraits< short>  : public BaseTraits< SIGNED_INTEGER, true, false, unsigned short>  { }; 
# 1001
template<> struct NumericTraits< int>  : public BaseTraits< SIGNED_INTEGER, true, false, unsigned>  { }; 
# 1002
template<> struct NumericTraits< long>  : public BaseTraits< SIGNED_INTEGER, true, false, unsigned long>  { }; 
# 1003
template<> struct NumericTraits< long long>  : public BaseTraits< SIGNED_INTEGER, true, false, unsigned long long>  { }; 
# 1005
template<> struct NumericTraits< unsigned char>  : public BaseTraits< UNSIGNED_INTEGER, true, false, unsigned char>  { }; 
# 1006
template<> struct NumericTraits< unsigned short>  : public BaseTraits< UNSIGNED_INTEGER, true, false, unsigned short>  { }; 
# 1007
template<> struct NumericTraits< unsigned>  : public BaseTraits< UNSIGNED_INTEGER, true, false, unsigned>  { }; 
# 1008
template<> struct NumericTraits< unsigned long>  : public BaseTraits< UNSIGNED_INTEGER, true, false, unsigned long>  { }; 
# 1009
template<> struct NumericTraits< unsigned long long>  : public BaseTraits< UNSIGNED_INTEGER, true, false, unsigned long long>  { }; 
# 1011
template<> struct NumericTraits< float>  : public BaseTraits< FLOATING_POINT, true, false, unsigned>  { }; 
# 1012
template<> struct NumericTraits< double>  : public BaseTraits< FLOATING_POINT, true, false, unsigned long long>  { }; 
# 1020
template< class T> 
# 1021
struct Traits : public NumericTraits< typename RemoveQualifiers< T> ::Type>  { }; 
# 1027
}
# 1028
}}}}
# 42 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../util_ptx.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 45
namespace cub_ { 
# 85
__attribute((always_inline)) __attribute__((unused)) inline unsigned SHR_ADD(unsigned 
# 86
x, unsigned 
# 87
shift, unsigned 
# 88
addend) 
# 89
{int volatile ___ = 1;(void)x;(void)shift;(void)addend;
# 98
::exit(___);}
#if 0
# 89
{ 
# 90
unsigned ret; 
# 95
ret = ((x >> shift) + addend); 
# 97
return ret; 
# 98
} 
#endif
# 104 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../util_ptx.cuh"
__attribute((always_inline)) __attribute__((unused)) inline unsigned SHL_ADD(unsigned 
# 105
x, unsigned 
# 106
shift, unsigned 
# 107
addend) 
# 108
{int volatile ___ = 1;(void)x;(void)shift;(void)addend;
# 117
::exit(___);}
#if 0
# 108
{ 
# 109
unsigned ret; 
# 114
ret = ((x << shift) + addend); 
# 116
return ret; 
# 117
} 
#endif
# 124 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../util_ptx.cuh"
template< class UnsignedBits, int BYTE_LEN> 
# 125
__attribute((always_inline)) __attribute__((unused)) inline unsigned BFE(UnsignedBits 
# 126
source, unsigned 
# 127
bit_start, unsigned 
# 128
num_bits, Int2Type< BYTE_LEN>  
# 129
byte_len) 
# 130
{int volatile ___ = 1;(void)source;(void)bit_start;(void)num_bits;(void)byte_len;
# 139
::exit(___);}
#if 0
# 130
{ 
# 131
unsigned bits; 
# 135
const unsigned MASK = (1 << num_bits) - 1; 
# 136
bits = ((source >> bit_start) & MASK); 
# 138
return bits; 
# 139
} 
#endif
# 145 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../util_ptx.cuh"
template< class UnsignedBits> 
# 146
__attribute((always_inline)) __attribute__((unused)) inline unsigned BFE(UnsignedBits 
# 147
source, unsigned 
# 148
bit_start, unsigned 
# 149
num_bits, Int2Type< 8>  
# 150
byte_len) 
# 151
{int volatile ___ = 1;(void)source;(void)bit_start;(void)num_bits;(void)byte_len;
# 154
::exit(___);}
#if 0
# 151
{ 
# 152
const unsigned long long MASK = (1ULL << num_bits) - (1); 
# 153
return (source >> bit_start) & MASK; 
# 154
} 
#endif
# 161 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../util_ptx.cuh"
template< class UnsignedBits> 
# 162
__attribute((always_inline)) __attribute__((unused)) inline unsigned BFE(UnsignedBits 
# 163
source, unsigned 
# 164
bit_start, unsigned 
# 165
num_bits) 
# 166
{int volatile ___ = 1;(void)source;(void)bit_start;(void)num_bits;
# 168
::exit(___);}
#if 0
# 166
{ 
# 167
return BFE(source, bit_start, num_bits, Int2Type< sizeof(UnsignedBits)> ()); 
# 168
} 
#endif
# 174 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../util_ptx.cuh"
__attribute((always_inline)) __attribute__((unused)) inline void BFI(unsigned &
# 175
ret, unsigned 
# 176
x, unsigned 
# 177
y, unsigned 
# 178
bit_start, unsigned 
# 179
num_bits) 
# 180
{int volatile ___ = 1;(void)ret;(void)x;(void)y;(void)bit_start;(void)num_bits;
# 190
::exit(___);}
#if 0
# 180
{ 
# 185
x <<= bit_start; 
# 186
unsigned MASK_X = ((1 << num_bits) - 1) << bit_start; 
# 187
unsigned MASK_Y = ~MASK_X; 
# 188
ret = ((y & MASK_Y) | (x & MASK_X)); 
# 190
} 
#endif
# 196 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../util_ptx.cuh"
__attribute((always_inline)) __attribute__((unused)) inline unsigned IADD3(unsigned x, unsigned y, unsigned z) 
# 197
{int volatile ___ = 1;(void)x;(void)y;(void)z;
# 204
::exit(___);}
#if 0
# 197
{ 
# 201
x = ((x + y) + z); 
# 203
return x; 
# 204
} 
#endif
# 233 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../util_ptx.cuh"
__attribute((always_inline)) __attribute__((unused)) inline int PRMT(unsigned a, unsigned b, unsigned index) 
# 234
{int volatile ___ = 1;(void)a;(void)b;(void)index;
# 238
::exit(___);}
#if 0
# 234
{ 
# 235
int ret; 
# 236
__asm__("prmt.b32 %0, %1, %2, %3;" : "=r" (ret) : "r" (a), "r" (b), "r" (index)); 
# 237
return ret; 
# 238
} 
#endif
# 245 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../util_ptx.cuh"
__attribute((always_inline)) __attribute__((unused)) inline void BAR(int count) 
# 246
{int volatile ___ = 1;(void)count;
# 248
::exit(___);}
#if 0
# 246
{ 
# 247
__asm__ volatile("bar.sync 1, %0;" : : "r" (count)); 
# 248
} 
#endif
# 254 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../util_ptx.cuh"
__attribute((always_inline)) __attribute__((unused)) inline float FMUL_RZ(float a, float b) 
# 255
{int volatile ___ = 1;(void)a;(void)b;
# 259
::exit(___);}
#if 0
# 255
{ 
# 256
float d; 
# 257
__asm__("mul.rz.f32 %0, %1, %2;" : "=f" (d) : "f" (a), "f" (b)); 
# 258
return d; 
# 259
} 
#endif
# 265 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../util_ptx.cuh"
__attribute((always_inline)) __attribute__((unused)) inline float FFMA_RZ(float a, float b, float c) 
# 266
{int volatile ___ = 1;(void)a;(void)b;(void)c;
# 270
::exit(___);}
#if 0
# 266
{ 
# 267
float d; 
# 268
__asm__("fma.rz.f32 %0, %1, %2, %3;" : "=f" (d) : "f" (a), "f" (b), "f" (c)); 
# 269
return d; 
# 270
} 
#endif
# 277 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../util_ptx.cuh"
__attribute((always_inline)) __attribute__((unused)) inline void ThreadExit() {int volatile ___ = 1;
# 279
::exit(___);}
#if 0
# 277
{ 
# 278
__asm__("exit;"); 
# 279
} 
#endif
# 285 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../util_ptx.cuh"
__attribute((always_inline)) __attribute__((unused)) inline int RowMajorTid(int block_dim_x, int block_dim_y, int block_dim_z) 
# 286
{int volatile ___ = 1;(void)block_dim_x;(void)block_dim_y;(void)block_dim_z;
# 290
::exit(___);}
#if 0
# 286
{ 
# 287
return (((block_dim_z == 1) ? 0 : (((__device_builtin_variable_threadIdx.z) * block_dim_x) * block_dim_y)) + ((block_dim_y == 1) ? 0 : ((__device_builtin_variable_threadIdx.y) * block_dim_x))) + (__device_builtin_variable_threadIdx.x); 
# 290
} 
#endif
# 296 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../util_ptx.cuh"
__attribute((always_inline)) __attribute__((unused)) inline unsigned LaneId() 
# 297
{int volatile ___ = 1;
# 301
::exit(___);}
#if 0
# 297
{ 
# 298
unsigned ret; 
# 299
__asm__("mov.u32 %0, %laneid;" : "=r" (ret) :); 
# 300
return ret; 
# 301
} 
#endif
# 307 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../util_ptx.cuh"
__attribute((always_inline)) __attribute__((unused)) inline unsigned WarpId() 
# 308
{int volatile ___ = 1;
# 312
::exit(___);}
#if 0
# 308
{ 
# 309
unsigned ret; 
# 310
__asm__("mov.u32 %0, %warpid;" : "=r" (ret) :); 
# 311
return ret; 
# 312
} 
#endif
# 317 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../util_ptx.cuh"
__attribute((always_inline)) __attribute__((unused)) inline unsigned LaneMaskLt() 
# 318
{int volatile ___ = 1;
# 322
::exit(___);}
#if 0
# 318
{ 
# 319
unsigned ret; 
# 320
__asm__("mov.u32 %0, %lanemask_lt;" : "=r" (ret) :); 
# 321
return ret; 
# 322
} 
#endif
# 327 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../util_ptx.cuh"
__attribute((always_inline)) __attribute__((unused)) inline unsigned LaneMaskLe() 
# 328
{int volatile ___ = 1;
# 332
::exit(___);}
#if 0
# 328
{ 
# 329
unsigned ret; 
# 330
__asm__("mov.u32 %0, %lanemask_le;" : "=r" (ret) :); 
# 331
return ret; 
# 332
} 
#endif
# 337 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../util_ptx.cuh"
__attribute((always_inline)) __attribute__((unused)) inline unsigned LaneMaskGt() 
# 338
{int volatile ___ = 1;
# 342
::exit(___);}
#if 0
# 338
{ 
# 339
unsigned ret; 
# 340
__asm__("mov.u32 %0, %lanemask_gt;" : "=r" (ret) :); 
# 341
return ret; 
# 342
} 
#endif
# 347 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../util_ptx.cuh"
__attribute((always_inline)) __attribute__((unused)) inline unsigned LaneMaskGe() 
# 348
{int volatile ___ = 1;
# 352
::exit(___);}
#if 0
# 348
{ 
# 349
unsigned ret; 
# 350
__asm__("mov.u32 %0, %lanemask_ge;" : "=r" (ret) :); 
# 351
return ret; 
# 352
} 
#endif
# 387 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../util_ptx.cuh"
template< class T> 
# 388
__attribute((always_inline)) __attribute__((unused)) inline T ShuffleUp(T 
# 389
input, int 
# 390
src_offset) 
# 391
{int volatile ___ = 1;(void)input;(void)src_offset;
# 415
::exit(___);}
#if 0
# 391
{ 
# 393
enum { 
# 394
SHFL_C
# 395
}; 
# 397
typedef typename UnitWord< T> ::ShuffleWord ShuffleWord; 
# 399
const int WORDS = (((sizeof(T) + sizeof(ShuffleWord)) - (1)) / sizeof(ShuffleWord)); 
# 400
T output; 
# 401
ShuffleWord *output_alias = (reinterpret_cast< ShuffleWord *>(&output)); 
# 402
ShuffleWord *input_alias = (reinterpret_cast< ShuffleWord *>(&input)); 
# 405
#pragma unroll
for (
# 405
int WORD = 0; WORD < WORDS; ++WORD) 
# 406
{ 
# 407
unsigned shuffle_word = input_alias[WORD]; 
# 408
__asm__("  shfl.up.b32 %0, %1, %2, %3;" : "=r" (shuffle_word) : "r" (shuffle_word), "r" (src_offset), "r" (SHFL_C)); 
# 411
(output_alias[WORD]) = ((ShuffleWord)shuffle_word); 
# 412
}  
# 414
return output; 
# 415
} 
#endif
# 446 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../util_ptx.cuh"
template< class T> 
# 447
__attribute((always_inline)) __attribute__((unused)) inline T ShuffleDown(T 
# 448
input, int 
# 449
src_offset) 
# 450
{int volatile ___ = 1;(void)input;(void)src_offset;
# 474
::exit(___);}
#if 0
# 450
{ 
# 452
enum { 
# 453
SHFL_C = 31
# 454
}; 
# 456
typedef typename UnitWord< T> ::ShuffleWord ShuffleWord; 
# 458
const int WORDS = (((sizeof(T) + sizeof(ShuffleWord)) - (1)) / sizeof(ShuffleWord)); 
# 459
T output; 
# 460
ShuffleWord *output_alias = (reinterpret_cast< ShuffleWord *>(&output)); 
# 461
ShuffleWord *input_alias = (reinterpret_cast< ShuffleWord *>(&input)); 
# 464
#pragma unroll
for (
# 464
int WORD = 0; WORD < WORDS; ++WORD) 
# 465
{ 
# 466
unsigned shuffle_word = input_alias[WORD]; 
# 467
__asm__("  shfl.down.b32 %0, %1, %2, %3;" : "=r" (shuffle_word) : "r" (shuffle_word), "r" (src_offset), "r" (SHFL_C)); 
# 470
(output_alias[WORD]) = ((ShuffleWord)shuffle_word); 
# 471
}  
# 473
return output; 
# 474
} 
#endif
# 485 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../util_ptx.cuh"
template< class T> 
# 486
__attribute((always_inline)) __attribute__((unused)) inline T ShuffleBroadcast(T 
# 487
input, int 
# 488
src_lane, int 
# 489
logical_warp_threads) 
# 490
{int volatile ___ = 1;(void)input;(void)src_lane;(void)logical_warp_threads;
# 508
::exit(___);}
#if 0
# 490
{ 
# 491
typedef typename UnitWord< T> ::ShuffleWord ShuffleWord; 
# 493
const int WORDS = (((sizeof(T) + sizeof(ShuffleWord)) - (1)) / sizeof(ShuffleWord)); 
# 494
T output; 
# 495
ShuffleWord *output_alias = (reinterpret_cast< ShuffleWord *>(&output)); 
# 496
ShuffleWord *input_alias = (reinterpret_cast< ShuffleWord *>(&input)); 
# 499
#pragma unroll
for (
# 499
int WORD = 0; WORD < WORDS; ++WORD) 
# 500
{ 
# 501
unsigned shuffle_word = input_alias[WORD]; 
# 502
__asm__("shfl.idx.b32 %0, %1, %2, %3;" : "=r" (shuffle_word) : "r" (shuffle_word), "r" (src_lane), "r" (logical_warp_threads - 1)); 
# 504
(output_alias[WORD]) = ((ShuffleWord)shuffle_word); 
# 505
}  
# 507
return output; 
# 508
} 
#endif
# 541 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../util_ptx.cuh"
template< class T> 
# 542
__attribute((always_inline)) __attribute__((unused)) inline T ShuffleBroadcast(T 
# 543
input, int 
# 544
src_lane) 
# 545
{int volatile ___ = 1;(void)input;(void)src_lane;
# 547
::exit(___);}
#if 0
# 545
{ 
# 546
return ShuffleBroadcast(input, src_lane, 1 << 5); 
# 547
} 
#endif
# 557 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../util_ptx.cuh"
__attribute((always_inline)) __attribute__((unused)) inline int WarpAll(int cond) 
# 558
{int volatile ___ = 1;(void)cond;
# 576
::exit(___);}
#if 0
# 558
{ 
# 561
__attribute__((unused)) static volatile int warp_signals[768 / 32]; 
# 563
if (LaneId() == (0)) { 
# 564
((warp_signals)[WarpId()]) = 1; }  
# 566
if (cond == 0) { 
# 567
((warp_signals)[WarpId()]) = 0; }  
# 569
return (warp_signals)[WarpId()]; 
# 576
} 
#endif
# 583 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../util_ptx.cuh"
__attribute((always_inline)) __attribute__((unused)) inline int WarpAny(int cond) 
# 584
{int volatile ___ = 1;(void)cond;
# 602
::exit(___);}
#if 0
# 584
{ 
# 587
__attribute__((unused)) static volatile int warp_signals[768 / 32]; 
# 589
if (LaneId() == (0)) { 
# 590
((warp_signals)[WarpId()]) = 0; }  
# 592
if (cond) { 
# 593
((warp_signals)[WarpId()]) = 1; }  
# 595
return (warp_signals)[WarpId()]; 
# 602
} 
#endif
# 605 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../util_ptx.cuh"
}
# 606
}}}}
# 43 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_exchange.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 46
namespace cub_ { 
# 108
template< class 
# 109
T, int 
# 110
BLOCK_DIM_X, int 
# 111
ITEMS_PER_THREAD, bool 
# 112
WARP_TIME_SLICING = false, int 
# 113
BLOCK_DIM_Y = 1, int 
# 114
BLOCK_DIM_Z = 1, int 
# 115
PTX_ARCH = 0> 
# 116
class BlockExchange { 
# 126
enum { 
# 128
BLOCK_THREADS = (BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z, 
# 130
LOG_WARP_THREADS = 5, 
# 131
WARP_THREADS = 1 << (5), 
# 132
WARPS = ((((BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z) + (1 << (5))) - 1) / (1 << (5)), 
# 134
LOG_SMEM_BANKS = (PTX_ARCH >= 200) ? 5 : 4, 
# 135
SMEM_BANKS = 1 << ((PTX_ARCH >= 200) ? 5 : 4), 
# 137
TILE_ITEMS = ((BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z) * ITEMS_PER_THREAD, 
# 139
TIME_SLICES = WARP_TIME_SLICING ? ((((BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z) + (1 << (5))) - 1) / (1 << (5)) : 1, 
# 141
TIME_SLICED_THREADS = WARP_TIME_SLICING ? ((1 << (5)) < ((BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z)) ? 1 << (5) : ((BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z) : ((BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z), 
# 142
TIME_SLICED_ITEMS = (WARP_TIME_SLICING ? ((1 << (5)) < ((BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z)) ? 1 << (5) : ((BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z) : ((BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z)) * ITEMS_PER_THREAD, 
# 144
WARP_TIME_SLICED_THREADS = ((1 << (5)) < ((BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z)) ? 1 << (5) : ((BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z), 
# 145
WARP_TIME_SLICED_ITEMS = (((1 << (5)) < ((BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z)) ? 1 << (5) : ((BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z)) * ITEMS_PER_THREAD, 
# 148
INSERT_PADDING = 0, 
# 149
PADDING_ITEMS = (0) ? ((WARP_TIME_SLICING ? ((1 << (5)) < ((BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z)) ? 1 << (5) : ((BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z) : ((BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z)) * ITEMS_PER_THREAD) >> ((PTX_ARCH >= 200) ? 5 : 4) : 0
# 150
}; 
# 157
typedef T _TempStorage[(TIME_SLICED_ITEMS) + (PADDING_ITEMS)]; 
# 162
public: struct TempStorage : public Uninitialized< T [(TIME_SLICED_ITEMS) + (PADDING_ITEMS)]>  { }; 
# 172
private: _TempStorage &temp_storage; 
# 175
int linear_tid; 
# 176
int lane_id; 
# 177
int warp_id; 
# 178
int warp_offset; 
# 186
__attribute((always_inline)) _TempStorage &PrivateStorage() 
# 187
{int volatile ___ = 1;
# 190
::exit(___);}
#if 0
# 187
{ 
# 188
__attribute__((unused)) static _TempStorage private_storage; 
# 189
return private_storage; 
# 190
} 
#endif
# 196 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_exchange.cuh"
__attribute((always_inline)) void BlockedToStriped(T 
# 197
items[], Int2Type< 0>  
# 198
time_slicing) 
# 199
{int volatile ___ = 1;(void)items;(void)time_slicing;
# 217
::exit(___);}
#if 0
# 199
{ 
# 201
#pragma unroll
for (
# 201
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 202
{ 
# 203
int item_offset = ((linear_tid) * ITEMS_PER_THREAD) + ITEM; 
# 204
if (INSERT_PADDING) { item_offset += (item_offset >> (LOG_SMEM_BANKS)); }  
# 205
((temp_storage)[item_offset]) = (items[ITEM]); 
# 206
}  
# 208
__syncthreads(); 
# 211
#pragma unroll
for (
# 211
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 212
{ 
# 213
int item_offset = ((int)(ITEM * (BLOCK_THREADS))) + (linear_tid); 
# 214
if (INSERT_PADDING) { item_offset += (item_offset >> (LOG_SMEM_BANKS)); }  
# 215
(items[ITEM]) = ((temp_storage)[item_offset]); 
# 216
}  
# 217
} 
#endif
# 223 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_exchange.cuh"
__attribute((always_inline)) void BlockedToStriped(T 
# 224
items[], Int2Type< 1>  
# 225
time_slicing) 
# 226
{int volatile ___ = 1;(void)items;(void)time_slicing;
# 275
::exit(___);}
#if 0
# 226
{ 
# 227
T temp_items[ITEMS_PER_THREAD]; 
# 230
#pragma unroll
for (
# 230
int SLICE = 0; SLICE < (TIME_SLICES); SLICE++) 
# 231
{ 
# 232
const int SLICE_OFFSET = SLICE * (TIME_SLICED_ITEMS); 
# 233
const int SLICE_OOB = SLICE_OFFSET + (TIME_SLICED_ITEMS); 
# 235
__syncthreads(); 
# 237
if ((warp_id) == SLICE) 
# 238
{ 
# 240
#pragma unroll
for (
# 240
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 241
{ 
# 242
int item_offset = ((lane_id) * ITEMS_PER_THREAD) + ITEM; 
# 243
if (INSERT_PADDING) { item_offset += (item_offset >> (LOG_SMEM_BANKS)); }  
# 244
((temp_storage)[item_offset]) = (items[ITEM]); 
# 245
}  
# 246
}  
# 248
__syncthreads(); 
# 251
#pragma unroll
for (
# 251
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 252
{ 
# 254
const int STRIP_OFFSET = ITEM * (BLOCK_THREADS); 
# 255
const int STRIP_OOB = STRIP_OFFSET + (BLOCK_THREADS); 
# 257
if ((SLICE_OFFSET < STRIP_OOB) && (SLICE_OOB > STRIP_OFFSET)) 
# 258
{ 
# 259
int item_offset = (STRIP_OFFSET + (linear_tid)) - SLICE_OFFSET; 
# 260
if ((item_offset >= 0) && (item_offset < (TIME_SLICED_ITEMS))) 
# 261
{ 
# 262
if (INSERT_PADDING) { item_offset += (item_offset >> (LOG_SMEM_BANKS)); }  
# 263
((temp_items)[ITEM]) = ((temp_storage)[item_offset]); 
# 264
}  
# 265
}  
# 266
}  
# 267
}  
# 271
#pragma unroll
for (
# 271
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 272
{ 
# 273
(items[ITEM]) = ((temp_items)[ITEM]); 
# 274
}  
# 275
} 
#endif
# 281 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_exchange.cuh"
__attribute((always_inline)) void BlockedToWarpStriped(T 
# 282
items[], Int2Type< 0>  
# 283
time_slicing) 
# 284
{int volatile ___ = 1;(void)items;(void)time_slicing;
# 302
::exit(___);}
#if 0
# 284
{ 
# 286
#pragma unroll
for (
# 286
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 287
{ 
# 288
int item_offset = ((warp_offset) + ITEM) + ((lane_id) * ITEMS_PER_THREAD); 
# 289
if (INSERT_PADDING) { item_offset += (item_offset >> (LOG_SMEM_BANKS)); }  
# 290
((temp_storage)[item_offset]) = (items[ITEM]); 
# 291
}  
# 293
__threadfence_block(); 
# 296
#pragma unroll
for (
# 296
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 297
{ 
# 298
int item_offset = ((warp_offset) + (ITEM * (WARP_TIME_SLICED_THREADS))) + (lane_id); 
# 299
if (INSERT_PADDING) { item_offset += (item_offset >> (LOG_SMEM_BANKS)); }  
# 300
(items[ITEM]) = ((temp_storage)[item_offset]); 
# 301
}  
# 302
} 
#endif
# 307 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_exchange.cuh"
__attribute((always_inline)) void BlockedToWarpStriped(T 
# 308
items[], Int2Type< 1>  
# 309
time_slicing) 
# 310
{int volatile ___ = 1;(void)items;(void)time_slicing;
# 358
::exit(___);}
#if 0
# 310
{ 
# 311
if ((warp_id) == 0) 
# 312
{ 
# 314
#pragma unroll
for (
# 314
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 315
{ 
# 316
int item_offset = ITEM + ((lane_id) * ITEMS_PER_THREAD); 
# 317
if (INSERT_PADDING) { item_offset += (item_offset >> (LOG_SMEM_BANKS)); }  
# 318
((temp_storage)[item_offset]) = (items[ITEM]); 
# 319
}  
# 321
__threadfence_block(); 
# 324
#pragma unroll
for (
# 324
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 325
{ 
# 326
int item_offset = (ITEM * (WARP_TIME_SLICED_THREADS)) + (lane_id); 
# 327
if (INSERT_PADDING) { item_offset += (item_offset >> (LOG_SMEM_BANKS)); }  
# 328
(items[ITEM]) = ((temp_storage)[item_offset]); 
# 329
}  
# 330
}  
# 333
#pragma unroll
for (
# 333
int SLICE = 1; SLICE < (TIME_SLICES); ++SLICE) 
# 334
{ 
# 335
__syncthreads(); 
# 337
if ((warp_id) == SLICE) 
# 338
{ 
# 340
#pragma unroll
for (
# 340
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 341
{ 
# 342
int item_offset = ITEM + ((lane_id) * ITEMS_PER_THREAD); 
# 343
if (INSERT_PADDING) { item_offset += (item_offset >> (LOG_SMEM_BANKS)); }  
# 344
((temp_storage)[item_offset]) = (items[ITEM]); 
# 345
}  
# 347
__threadfence_block(); 
# 350
#pragma unroll
for (
# 350
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 351
{ 
# 352
int item_offset = (ITEM * (WARP_TIME_SLICED_THREADS)) + (lane_id); 
# 353
if (INSERT_PADDING) { item_offset += (item_offset >> (LOG_SMEM_BANKS)); }  
# 354
(items[ITEM]) = ((temp_storage)[item_offset]); 
# 355
}  
# 356
}  
# 357
}  
# 358
} 
#endif
# 364 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_exchange.cuh"
__attribute((always_inline)) void StripedToBlocked(T 
# 365
items[], Int2Type< 0>  
# 366
time_slicing) 
# 367
{int volatile ___ = 1;(void)items;(void)time_slicing;
# 386
::exit(___);}
#if 0
# 367
{ 
# 369
#pragma unroll
for (
# 369
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 370
{ 
# 371
int item_offset = ((int)(ITEM * (BLOCK_THREADS))) + (linear_tid); 
# 372
if (INSERT_PADDING) { item_offset += (item_offset >> (LOG_SMEM_BANKS)); }  
# 373
((temp_storage)[item_offset]) = (items[ITEM]); 
# 374
}  
# 376
__syncthreads(); 
# 380
#pragma unroll
for (
# 380
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 381
{ 
# 382
int item_offset = ((linear_tid) * ITEMS_PER_THREAD) + ITEM; 
# 383
if (INSERT_PADDING) { item_offset += (item_offset >> (LOG_SMEM_BANKS)); }  
# 384
(items[ITEM]) = ((temp_storage)[item_offset]); 
# 385
}  
# 386
} 
#endif
# 392 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_exchange.cuh"
__attribute((always_inline)) void StripedToBlocked(T 
# 393
items[], Int2Type< 1>  
# 394
time_slicing) 
# 395
{int volatile ___ = 1;(void)items;(void)time_slicing;
# 445
::exit(___);}
#if 0
# 395
{ 
# 397
T temp_items[ITEMS_PER_THREAD]; 
# 400
#pragma unroll
for (
# 400
int SLICE = 0; SLICE < (TIME_SLICES); SLICE++) 
# 401
{ 
# 402
const int SLICE_OFFSET = SLICE * (TIME_SLICED_ITEMS); 
# 403
const int SLICE_OOB = SLICE_OFFSET + (TIME_SLICED_ITEMS); 
# 405
__syncthreads(); 
# 408
#pragma unroll
for (
# 408
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 409
{ 
# 411
const int STRIP_OFFSET = ITEM * (BLOCK_THREADS); 
# 412
const int STRIP_OOB = STRIP_OFFSET + (BLOCK_THREADS); 
# 414
if ((SLICE_OFFSET < STRIP_OOB) && (SLICE_OOB > STRIP_OFFSET)) 
# 415
{ 
# 416
int item_offset = (STRIP_OFFSET + (linear_tid)) - SLICE_OFFSET; 
# 417
if ((item_offset >= 0) && (item_offset < (TIME_SLICED_ITEMS))) 
# 418
{ 
# 419
if (INSERT_PADDING) { item_offset += (item_offset >> (LOG_SMEM_BANKS)); }  
# 420
((temp_storage)[item_offset]) = (items[ITEM]); 
# 421
}  
# 422
}  
# 423
}  
# 425
__syncthreads(); 
# 427
if ((warp_id) == SLICE) 
# 428
{ 
# 430
#pragma unroll
for (
# 430
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 431
{ 
# 432
int item_offset = ((lane_id) * ITEMS_PER_THREAD) + ITEM; 
# 433
if (INSERT_PADDING) { item_offset += (item_offset >> (LOG_SMEM_BANKS)); }  
# 434
((temp_items)[ITEM]) = ((temp_storage)[item_offset]); 
# 435
}  
# 436
}  
# 437
}  
# 441
#pragma unroll
for (
# 441
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 442
{ 
# 443
(items[ITEM]) = ((temp_items)[ITEM]); 
# 444
}  
# 445
} 
#endif
# 451 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_exchange.cuh"
__attribute((always_inline)) void WarpStripedToBlocked(T 
# 452
items[], Int2Type< 0>  
# 453
time_slicing) 
# 454
{int volatile ___ = 1;(void)items;(void)time_slicing;
# 472
::exit(___);}
#if 0
# 454
{ 
# 456
#pragma unroll
for (
# 456
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 457
{ 
# 458
int item_offset = ((warp_offset) + (ITEM * (WARP_TIME_SLICED_THREADS))) + (lane_id); 
# 459
if (INSERT_PADDING) { item_offset += (item_offset >> (LOG_SMEM_BANKS)); }  
# 460
((temp_storage)[item_offset]) = (items[ITEM]); 
# 461
}  
# 463
__threadfence_block(); 
# 466
#pragma unroll
for (
# 466
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 467
{ 
# 468
int item_offset = ((warp_offset) + ITEM) + ((lane_id) * ITEMS_PER_THREAD); 
# 469
if (INSERT_PADDING) { item_offset += (item_offset >> (LOG_SMEM_BANKS)); }  
# 470
(items[ITEM]) = ((temp_storage)[item_offset]); 
# 471
}  
# 472
} 
#endif
# 478 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_exchange.cuh"
__attribute((always_inline)) void WarpStripedToBlocked(T 
# 479
items[], Int2Type< 1>  
# 480
time_slicing) 
# 481
{int volatile ___ = 1;(void)items;(void)time_slicing;
# 508
::exit(___);}
#if 0
# 481
{ 
# 483
#pragma unroll
for (
# 483
int SLICE = 0; SLICE < (TIME_SLICES); ++SLICE) 
# 484
{ 
# 485
__syncthreads(); 
# 487
if ((warp_id) == SLICE) 
# 488
{ 
# 490
#pragma unroll
for (
# 490
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 491
{ 
# 492
int item_offset = (ITEM * (WARP_TIME_SLICED_THREADS)) + (lane_id); 
# 493
if (INSERT_PADDING) { item_offset += (item_offset >> (LOG_SMEM_BANKS)); }  
# 494
((temp_storage)[item_offset]) = (items[ITEM]); 
# 495
}  
# 497
__threadfence_block(); 
# 500
#pragma unroll
for (
# 500
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 501
{ 
# 502
int item_offset = ITEM + ((lane_id) * ITEMS_PER_THREAD); 
# 503
if (INSERT_PADDING) { item_offset += (item_offset >> (LOG_SMEM_BANKS)); }  
# 504
(items[ITEM]) = ((temp_storage)[item_offset]); 
# 505
}  
# 506
}  
# 507
}  
# 508
} 
#endif
# 514 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_exchange.cuh"
template< class Offset> 
# 515
__attribute((always_inline)) void ScatterToBlocked(T 
# 516
items[], Offset 
# 517
ranks[], Int2Type< 0>  
# 518
time_slicing) 
# 519
{int volatile ___ = 1;(void)items;(void)ranks;(void)time_slicing;
# 537
::exit(___);}
#if 0
# 519
{ 
# 521
#pragma unroll
for (
# 521
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 522
{ 
# 523
int item_offset = ranks[ITEM]; 
# 524
if (INSERT_PADDING) { item_offset = SHR_ADD(item_offset, LOG_SMEM_BANKS, item_offset); }  
# 525
((temp_storage)[item_offset]) = (items[ITEM]); 
# 526
}  
# 528
__syncthreads(); 
# 531
#pragma unroll
for (
# 531
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 532
{ 
# 533
int item_offset = ((linear_tid) * ITEMS_PER_THREAD) + ITEM; 
# 534
if (INSERT_PADDING) { item_offset = SHR_ADD(item_offset, LOG_SMEM_BANKS, item_offset); }  
# 535
(items[ITEM]) = ((temp_storage)[item_offset]); 
# 536
}  
# 537
} 
#endif
# 542 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_exchange.cuh"
template< class Offset> 
# 543
__attribute((always_inline)) void ScatterToBlocked(T 
# 544
items[], Offset 
# 545
ranks[], Int2Type< 1>  
# 546
time_slicing) 
# 547
{int volatile ___ = 1;(void)items;(void)ranks;(void)time_slicing;
# 588
::exit(___);}
#if 0
# 547
{ 
# 548
T temp_items[ITEMS_PER_THREAD]; 
# 551
#pragma unroll
for (
# 551
int SLICE = 0; SLICE < (TIME_SLICES); SLICE++) 
# 552
{ 
# 553
__syncthreads(); 
# 555
const int SLICE_OFFSET = (TIME_SLICED_ITEMS) * SLICE; 
# 558
#pragma unroll
for (
# 558
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 559
{ 
# 560
int item_offset = (ranks[ITEM]) - SLICE_OFFSET; 
# 561
if ((item_offset >= 0) && (item_offset < (WARP_TIME_SLICED_ITEMS))) 
# 562
{ 
# 563
if (INSERT_PADDING) { item_offset = SHR_ADD(item_offset, LOG_SMEM_BANKS, item_offset); }  
# 564
((temp_storage)[item_offset]) = (items[ITEM]); 
# 565
}  
# 566
}  
# 568
__syncthreads(); 
# 570
if ((warp_id) == SLICE) 
# 571
{ 
# 573
#pragma unroll
for (
# 573
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 574
{ 
# 575
int item_offset = ((lane_id) * ITEMS_PER_THREAD) + ITEM; 
# 576
if (INSERT_PADDING) { item_offset = SHR_ADD(item_offset, LOG_SMEM_BANKS, item_offset); }  
# 577
((temp_items)[ITEM]) = ((temp_storage)[item_offset]); 
# 578
}  
# 579
}  
# 580
}  
# 584
#pragma unroll
for (
# 584
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 585
{ 
# 586
(items[ITEM]) = ((temp_items)[ITEM]); 
# 587
}  
# 588
} 
#endif
# 594 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_exchange.cuh"
template< class Offset> 
# 595
__attribute((always_inline)) void ScatterToStriped(T 
# 596
items[], Offset 
# 597
ranks[], Int2Type< 0>  
# 598
time_slicing) 
# 599
{int volatile ___ = 1;(void)items;(void)ranks;(void)time_slicing;
# 617
::exit(___);}
#if 0
# 599
{ 
# 601
#pragma unroll
for (
# 601
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 602
{ 
# 603
int item_offset = ranks[ITEM]; 
# 604
if (INSERT_PADDING) { item_offset = SHR_ADD(item_offset, LOG_SMEM_BANKS, item_offset); }  
# 605
((temp_storage)[item_offset]) = (items[ITEM]); 
# 606
}  
# 608
__syncthreads(); 
# 611
#pragma unroll
for (
# 611
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 612
{ 
# 613
int item_offset = ((int)(ITEM * (BLOCK_THREADS))) + (linear_tid); 
# 614
if (INSERT_PADDING) { item_offset = SHR_ADD(item_offset, LOG_SMEM_BANKS, item_offset); }  
# 615
(items[ITEM]) = ((temp_storage)[item_offset]); 
# 616
}  
# 617
} 
#endif
# 623 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_exchange.cuh"
template< class Offset> 
# 624
__attribute((always_inline)) void ScatterToStriped(T 
# 625
items[], Offset 
# 626
ranks[], Int2Type< 1>  
# 627
time_slicing) 
# 628
{int volatile ___ = 1;(void)items;(void)ranks;(void)time_slicing;
# 677
::exit(___);}
#if 0
# 628
{ 
# 629
T temp_items[ITEMS_PER_THREAD]; 
# 632
#pragma unroll
for (
# 632
int SLICE = 0; SLICE < (TIME_SLICES); SLICE++) 
# 633
{ 
# 634
const int SLICE_OFFSET = SLICE * (TIME_SLICED_ITEMS); 
# 635
const int SLICE_OOB = SLICE_OFFSET + (TIME_SLICED_ITEMS); 
# 637
__syncthreads(); 
# 640
#pragma unroll
for (
# 640
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 641
{ 
# 642
int item_offset = (ranks[ITEM]) - SLICE_OFFSET; 
# 643
if ((item_offset >= 0) && (item_offset < (WARP_TIME_SLICED_ITEMS))) 
# 644
{ 
# 645
if (INSERT_PADDING) { item_offset = SHR_ADD(item_offset, LOG_SMEM_BANKS, item_offset); }  
# 646
((temp_storage)[item_offset]) = (items[ITEM]); 
# 647
}  
# 648
}  
# 650
__syncthreads(); 
# 653
#pragma unroll
for (
# 653
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 654
{ 
# 656
const int STRIP_OFFSET = ITEM * (BLOCK_THREADS); 
# 657
const int STRIP_OOB = STRIP_OFFSET + (BLOCK_THREADS); 
# 659
if ((SLICE_OFFSET < STRIP_OOB) && (SLICE_OOB > STRIP_OFFSET)) 
# 660
{ 
# 661
int item_offset = (STRIP_OFFSET + (linear_tid)) - SLICE_OFFSET; 
# 662
if ((item_offset >= 0) && (item_offset < (TIME_SLICED_ITEMS))) 
# 663
{ 
# 664
if (INSERT_PADDING) { item_offset += (item_offset >> (LOG_SMEM_BANKS)); }  
# 665
((temp_items)[ITEM]) = ((temp_storage)[item_offset]); 
# 666
}  
# 667
}  
# 668
}  
# 669
}  
# 673
#pragma unroll
for (
# 673
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 674
{ 
# 675
(items[ITEM]) = ((temp_items)[ITEM]); 
# 676
}  
# 677
} 
#endif
# 690 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_exchange.cuh"
public: __attribute((always_inline)) BlockExchange() : temp_storage(PrivateStorage()), linear_tid(RowMajorTid(BLOCK_DIM_X, BLOCK_DIM_Y, BLOCK_DIM_Z)), lane_id(LaneId()), warp_id(((WARPS) == 1) ? 0 : ((linear_tid) / (WARP_THREADS))), warp_offset((warp_id) * (WARP_TIME_SLICED_ITEMS)) 
# 697
{int *volatile ___ = 0;::free(___);}
#if 0
# 697
{ } 
#endif
# 703 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_exchange.cuh"
__attribute((always_inline)) BlockExchange(TempStorage &
# 704
temp_storage) : temp_storage((temp_storage.Alias())), linear_tid(RowMajorTid(BLOCK_DIM_X, BLOCK_DIM_Y, BLOCK_DIM_Z)), lane_id(LaneId()), warp_id(((WARPS) == 1) ? 0 : ((linear_tid) / (WARP_THREADS))), warp_offset((warp_id) * (WARP_TIME_SLICED_ITEMS)) 
# 711
{int *volatile ___ = 0;(void)temp_storage;::free(___);}
#if 0
# 711
{ } 
#endif
# 756 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_exchange.cuh"
__attribute((always_inline)) void StripedToBlocked(T 
# 757
items[]) 
# 758
{int volatile ___ = 1;(void)items;
# 760
::exit(___);}
#if 0
# 758
{ 
# 759
StripedToBlocked(items, Int2Type< WARP_TIME_SLICING> ()); 
# 760
} 
#endif
# 802 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_exchange.cuh"
__attribute((always_inline)) void BlockedToStriped(T 
# 803
items[]) 
# 804
{int volatile ___ = 1;(void)items;
# 806
::exit(___);}
#if 0
# 804
{ 
# 805
BlockedToStriped(items, Int2Type< WARP_TIME_SLICING> ()); 
# 806
} 
#endif
# 847 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_exchange.cuh"
__attribute((always_inline)) void WarpStripedToBlocked(T 
# 848
items[]) 
# 849
{int volatile ___ = 1;(void)items;
# 851
::exit(___);}
#if 0
# 849
{ 
# 850
WarpStripedToBlocked(items, Int2Type< WARP_TIME_SLICING> ()); 
# 851
} 
#endif
# 894 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_exchange.cuh"
__attribute((always_inline)) void BlockedToWarpStriped(T 
# 895
items[]) 
# 896
{int volatile ___ = 1;(void)items;
# 898
::exit(___);}
#if 0
# 896
{ 
# 897
BlockedToWarpStriped(items, Int2Type< WARP_TIME_SLICING> ()); 
# 898
} 
#endif
# 916 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_exchange.cuh"
template< class Offset> 
# 917
__attribute((always_inline)) void ScatterToBlocked(T 
# 918
items[], Offset 
# 919
ranks[]) 
# 920
{int volatile ___ = 1;(void)items;(void)ranks;
# 922
::exit(___);}
#if 0
# 920
{ 
# 921
ScatterToBlocked(items, ranks, Int2Type< WARP_TIME_SLICING> ()); 
# 922
} 
#endif
# 933 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_exchange.cuh"
template< class Offset> 
# 934
__attribute((always_inline)) void ScatterToStriped(T 
# 935
items[], Offset 
# 936
ranks[]) 
# 937
{int volatile ___ = 1;(void)items;(void)ranks;
# 939
::exit(___);}
#if 0
# 937
{ 
# 938
ScatterToStriped(items, ranks, Int2Type< WARP_TIME_SLICING> ()); 
# 939
} 
#endif
# 950 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_exchange.cuh"
template< class Offset> 
# 951
__attribute((always_inline)) void ScatterToStripedGuarded(T 
# 952
items[], Offset 
# 953
ranks[]) 
# 954
{int volatile ___ = 1;(void)items;(void)ranks;
# 973
::exit(___);}
#if 0
# 954
{ 
# 956
#pragma unroll
for (
# 956
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 957
{ 
# 958
int item_offset = ranks[ITEM]; 
# 959
if (INSERT_PADDING) { item_offset = SHR_ADD(item_offset, LOG_SMEM_BANKS, item_offset); }  
# 960
if ((ranks[ITEM]) >= 0) { 
# 961
((temp_storage)[item_offset]) = (items[ITEM]); }  
# 962
}  
# 964
__syncthreads(); 
# 967
#pragma unroll
for (
# 967
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 968
{ 
# 969
int item_offset = ((int)(ITEM * (BLOCK_THREADS))) + (linear_tid); 
# 970
if (INSERT_PADDING) { item_offset = SHR_ADD(item_offset, LOG_SMEM_BANKS, item_offset); }  
# 971
(items[ITEM]) = ((temp_storage)[item_offset]); 
# 972
}  
# 973
} 
#endif
# 984 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_exchange.cuh"
template< class Offset, class ValidFlag> 
# 985
__attribute((always_inline)) void ScatterToStriped(T 
# 986
items[], Offset 
# 987
ranks[], ValidFlag 
# 988
is_valid[]) 
# 989
{int volatile ___ = 1;(void)items;(void)ranks;(void)is_valid;
# 1008
::exit(___);}
#if 0
# 989
{ 
# 991
#pragma unroll
for (
# 991
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 992
{ 
# 993
int item_offset = ranks[ITEM]; 
# 994
if (INSERT_PADDING) { item_offset = SHR_ADD(item_offset, LOG_SMEM_BANKS, item_offset); }  
# 995
if (is_valid[ITEM]) { 
# 996
((temp_storage)[item_offset]) = (items[ITEM]); }  
# 997
}  
# 999
__syncthreads(); 
# 1002
#pragma unroll
for (
# 1002
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 1003
{ 
# 1004
int item_offset = ((int)(ITEM * (BLOCK_THREADS))) + (linear_tid); 
# 1005
if (INSERT_PADDING) { item_offset = SHR_ADD(item_offset, LOG_SMEM_BANKS, item_offset); }  
# 1006
(items[ITEM]) = ((temp_storage)[item_offset]); 
# 1007
}  
# 1008
} 
#endif
# 1012 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_exchange.cuh"
}; 
# 1018
template< class 
# 1019
T, int 
# 1020
ITEMS_PER_THREAD, int 
# 1021
LOGICAL_WARP_THREADS = 32, int 
# 1022
PTX_ARCH = 0> 
# 1023
class WarpExchange { 
# 1031
enum { 
# 1033
IS_ARCH_WARP = LOGICAL_WARP_THREADS == (1 << 5), 
# 1035
WARP_ITEMS = (ITEMS_PER_THREAD * LOGICAL_WARP_THREADS) + 1, 
# 1037
LOG_SMEM_BANKS = (PTX_ARCH >= 200) ? 5 : 4, 
# 1038
SMEM_BANKS = 1 << ((PTX_ARCH >= 200) ? 5 : 4), 
# 1041
INSERT_PADDING = 0, 
# 1042
PADDING_ITEMS = (0) ? ((ITEMS_PER_THREAD * LOGICAL_WARP_THREADS) + 1) >> ((PTX_ARCH >= 200) ? 5 : 4) : 0
# 1043
}; 
# 1050
typedef T _TempStorage[(WARP_ITEMS) + (PADDING_ITEMS)]; 
# 1055
public: struct TempStorage : public Uninitialized< T [(WARP_ITEMS) + (PADDING_ITEMS)]>  { }; 
# 1064
private: _TempStorage &temp_storage; 
# 1065
int lane_id; 
# 1074
public: __attribute((always_inline)) WarpExchange(TempStorage &
# 1075
temp_storage) : temp_storage((temp_storage.Alias())), lane_id((IS_ARCH_WARP) ? LaneId() : (LaneId() % (LOGICAL_WARP_THREADS))) 
# 1081
{int *volatile ___ = 0;(void)temp_storage;::free(___);}
#if 0
# 1081
{ } 
#endif
# 1096 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_exchange.cuh"
template< class Offset> 
# 1097
__attribute((always_inline)) void ScatterToStriped(T 
# 1098
items[], Offset 
# 1099
ranks[]) 
# 1100
{int volatile ___ = 1;(void)items;(void)ranks;
# 1117
::exit(___);}
#if 0
# 1100
{ 
# 1102
#pragma unroll
for (
# 1102
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 1103
{ 
# 1104
if (INSERT_PADDING) { (ranks[ITEM]) = SHR_ADD(ranks[ITEM], LOG_SMEM_BANKS, ranks[ITEM]); }  
# 1105
((temp_storage)[ranks[ITEM]]) = (items[ITEM]); 
# 1106
}  
# 1108
__threadfence_block(); 
# 1111
#pragma unroll
for (
# 1111
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 1112
{ 
# 1113
int item_offset = (ITEM * LOGICAL_WARP_THREADS) + (lane_id); 
# 1114
if (INSERT_PADDING) { item_offset = SHR_ADD(item_offset, LOG_SMEM_BANKS, item_offset); }  
# 1115
(items[ITEM]) = ((temp_storage)[item_offset]); 
# 1116
}  
# 1117
} 
#endif
# 1119 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_exchange.cuh"
}; 
# 1130
}
# 1131
}}}}
# 45 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../thread/../thread/thread_operators.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 48
namespace cub_ { 
# 59
struct Equality { 
# 62
template< class T> 
# 63
__attribute((always_inline)) bool operator()(const T &a, const T &b) const 
# 64
{ 
# 65
return a == b; 
# 66
} 
# 67
}; 
# 73
struct Inequality { 
# 76
template< class T> 
# 77
__attribute((always_inline)) bool operator()(const T &a, const T &b) const 
# 78
{ 
# 79
return a != b; 
# 80
} 
# 81
}; 
# 87
template< class EqualityOp> 
# 88
struct InequalityWrapper { 
# 91
EqualityOp op; 
# 94
__attribute((always_inline)) 
# 95
InequalityWrapper(EqualityOp op) : op(op) { } 
# 98
template< class T> 
# 99
__attribute((always_inline)) bool operator()(const T &a, const T &b) const 
# 100
{ 
# 101
return !(op)(a, b); 
# 102
} 
# 103
}; 
# 109
struct Sum { 
# 112
template< class T> 
# 113
__attribute((always_inline)) T operator()(const T &a, const T &b) const 
# 114
{ 
# 115
return a + b; 
# 116
} 
# 117
}; 
# 123
struct Max { 
# 126
template< class T> 
# 127
__attribute((always_inline)) T operator()(const T &a, const T &b) const 
# 128
{ 
# 129
return (b > a) ? b : a; 
# 130
} 
# 131
}; 
# 137
struct ArgMax { 
# 140
template< class T, class Offset> 
# 141
__attribute((always_inline)) ItemOffsetPair< T, Offset>  operator()(const ItemOffsetPair< T, Offset>  &
# 142
a, const ItemOffsetPair< T, Offset>  &
# 143
b) const 
# 144
{ 
# 145
if ((a.value) == (b.value)) { 
# 146
return ((b.offset) < (a.offset)) ? b : a; }  
# 148
return ((b.value) > (a.value)) ? b : a; 
# 149
} 
# 150
}; 
# 156
struct Min { 
# 159
template< class T> 
# 160
__attribute((always_inline)) T operator()(const T &a, const T &b) const 
# 161
{ 
# 162
return (b < a) ? b : a; 
# 163
} 
# 164
}; 
# 170
struct ArgMin { 
# 173
template< class T, class Offset> 
# 174
__attribute((always_inline)) ItemOffsetPair< T, Offset>  operator()(const ItemOffsetPair< T, Offset>  &
# 175
a, const ItemOffsetPair< T, Offset>  &
# 176
b) const 
# 177
{ 
# 178
if ((a.value) == (b.value)) { 
# 179
return ((b.offset) < (a.offset)) ? b : a; }  
# 181
return ((b.value) < (a.value)) ? b : a; 
# 182
} 
# 183
}; 
# 189
template< class B> 
# 190
struct Cast { 
# 193
template< class A> 
# 194
__attribute((always_inline)) B operator()(const A &a) const 
# 195
{ 
# 196
return (B)a; 
# 197
} 
# 198
}; 
# 217
template< class 
# 218
ReductionOp, class 
# 219
ItemOffsetPair> 
# 220
class ReduceBySegmentOp { 
# 225
ReductionOp op; 
# 230
public: __attribute((always_inline)) ReduceBySegmentOp(ReductionOp op) : op(op) { } 
# 233
__attribute((always_inline)) ItemOffsetPair operator()(const ItemOffsetPair &
# 234
first, const ItemOffsetPair &
# 235
second) 
# 236
{ 
# 238
ItemOffsetPair retval; 
# 239
(retval.offset) = ((first.offset) + (second.offset)); 
# 240
(retval.value) = ((second.offset) ? second.value : (op)((first.value), (second.value))); 
# 243
return retval; 
# 244
} 
# 245
}; 
# 251
}
# 252
}}}}
# 40 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../thread/thread_reduce.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 43
namespace cub_ { 
# 56
template< int 
# 57
LENGTH, class 
# 58
T, class 
# 59
ReductionOp> 
# 60
__attribute((always_inline)) __attribute__((unused)) inline T ThreadReduce(T *
# 61
input, ReductionOp 
# 62
reduction_op, T 
# 63
prefix, Int2Type< LENGTH>  
# 64
length) 
# 65
{int volatile ___ = 1;(void)input;(void)reduction_op;(void)prefix;(void)length;
# 70
::exit(___);}
#if 0
# 65
{ 
# 66
T addend = *input; 
# 67
prefix = reduction_op(prefix, addend); 
# 69
return ThreadReduce(input + 1, reduction_op, prefix, Int2Type< LENGTH - 1> ()); 
# 70
} 
#endif
# 72 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../thread/thread_reduce.cuh"
template< class 
# 73
T, class 
# 74
ReductionOp> 
# 75
__attribute((always_inline)) __attribute__((unused)) inline T ThreadReduce(T *
# 76
input, ReductionOp 
# 77
reduction_op, T 
# 78
prefix, Int2Type< 0>  
# 79
length) 
# 80
{int volatile ___ = 1;(void)input;(void)reduction_op;(void)prefix;(void)length;
# 82
::exit(___);}
#if 0
# 80
{ 
# 81
return prefix; 
# 82
} 
#endif
# 92 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../thread/thread_reduce.cuh"
template< int 
# 93
LENGTH, class 
# 94
T, class 
# 95
ReductionOp> 
# 96
__attribute((always_inline)) __attribute__((unused)) inline T ThreadReduce(T *
# 97
input, ReductionOp 
# 98
reduction_op, T 
# 99
prefix) 
# 100
{int volatile ___ = 1;(void)input;(void)reduction_op;(void)prefix;
# 102
::exit(___);}
#if 0
# 100
{ 
# 101
return ThreadReduce(input, reduction_op, prefix, Int2Type< LENGTH> ()); 
# 102
} 
#endif
# 112 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../thread/thread_reduce.cuh"
template< int 
# 113
LENGTH, class 
# 114
T, class 
# 115
ReductionOp> 
# 116
__attribute((always_inline)) __attribute__((unused)) inline T ThreadReduce(T *
# 117
input, ReductionOp 
# 118
reduction_op) 
# 119
{int volatile ___ = 1;(void)input;(void)reduction_op;
# 122
::exit(___);}
#if 0
# 119
{ 
# 120
T prefix = input[0]; 
# 121
return ThreadReduce< LENGTH - 1> (input + 1, reduction_op, prefix); 
# 122
} 
#endif
# 132 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../thread/thread_reduce.cuh"
template< int 
# 133
LENGTH, class 
# 134
T, class 
# 135
ReductionOp> 
# 136
__attribute((always_inline)) __attribute__((unused)) inline T ThreadReduce(T (&
# 137
input)[LENGTH], ReductionOp 
# 138
reduction_op, T 
# 139
prefix) 
# 140
{int volatile ___ = 1;(void)input;(void)reduction_op;(void)prefix;
# 142
::exit(___);}
#if 0
# 140
{ 
# 141
return ThreadReduce< LENGTH> (input, reduction_op, prefix); 
# 142
} 
#endif
# 152 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../thread/thread_reduce.cuh"
template< int 
# 153
LENGTH, class 
# 154
T, class 
# 155
ReductionOp> 
# 156
__attribute((always_inline)) __attribute__((unused)) inline T ThreadReduce(T (&
# 157
input)[LENGTH], ReductionOp 
# 158
reduction_op) 
# 159
{int volatile ___ = 1;(void)input;(void)reduction_op;
# 161
::exit(___);}
#if 0
# 159
{ 
# 160
return ThreadReduce< LENGTH> ((T *)(input), reduction_op); 
# 161
} 
#endif
# 168 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../thread/thread_reduce.cuh"
}
# 169
}}}}
# 40 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../thread/thread_scan.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 43
namespace cub_ { 
# 55
template< int 
# 56
LENGTH, class 
# 57
T, class 
# 58
ScanOp> 
# 59
__attribute((always_inline)) __attribute__((unused)) inline T ThreadScanExclusive(T 
# 60
inclusive, T 
# 61
exclusive, T *
# 62
input, T *
# 63
output, ScanOp 
# 64
scan_op, Int2Type< LENGTH>  
# 65
length) 
# 66
{int volatile ___ = 1;(void)inclusive;(void)exclusive;(void)input;(void)output;(void)scan_op;(void)length;
# 73
::exit(___);}
#if 0
# 66
{ 
# 67
T addend = *input; 
# 68
inclusive = scan_op(exclusive, addend); 
# 69
(*output) = exclusive; 
# 70
exclusive = inclusive; 
# 72
return ThreadScanExclusive(inclusive, exclusive, input + 1, output + 1, scan_op, Int2Type< LENGTH - 1> ()); 
# 73
} 
#endif
# 75 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../thread/thread_scan.cuh"
template< class 
# 76
T, class 
# 77
ScanOp> 
# 78
__attribute((always_inline)) __attribute__((unused)) inline T ThreadScanExclusive(T 
# 79
inclusive, T 
# 80
exclusive, T *
# 81
input, T *
# 82
output, ScanOp 
# 83
scan_op, Int2Type< 0>  
# 84
length) 
# 85
{int volatile ___ = 1;(void)inclusive;(void)exclusive;(void)input;(void)output;(void)scan_op;(void)length;
# 87
::exit(___);}
#if 0
# 85
{ 
# 86
return inclusive; 
# 87
} 
#endif
# 97 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../thread/thread_scan.cuh"
template< int 
# 98
LENGTH, class 
# 99
T, class 
# 100
ScanOp> 
# 101
__attribute((always_inline)) __attribute__((unused)) inline T ThreadScanExclusive(T *
# 102
input, T *
# 103
output, ScanOp 
# 104
scan_op, T 
# 105
prefix, bool 
# 106
apply_prefix = true) 
# 107
{int volatile ___ = 1;(void)input;(void)output;(void)scan_op;(void)prefix;(void)apply_prefix;
# 117
::exit(___);}
#if 0
# 107
{ 
# 108
T inclusive = input[0]; 
# 109
if (apply_prefix) 
# 110
{ 
# 111
inclusive = scan_op(prefix, inclusive); 
# 112
}  
# 113
(output[0]) = prefix; 
# 114
T exclusive = inclusive; 
# 116
return ThreadScanExclusive(inclusive, exclusive, input + 1, output + 1, scan_op, Int2Type< LENGTH - 1> ()); 
# 117
} 
#endif
# 127 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../thread/thread_scan.cuh"
template< int 
# 128
LENGTH, class 
# 129
T, class 
# 130
ScanOp> 
# 131
__attribute((always_inline)) __attribute__((unused)) inline T ThreadScanExclusive(T (&
# 132
input)[LENGTH], T (&
# 133
output)[LENGTH], ScanOp 
# 134
scan_op, T 
# 135
prefix, bool 
# 136
apply_prefix = true) 
# 137
{int volatile ___ = 1;(void)input;(void)output;(void)scan_op;(void)prefix;(void)apply_prefix;
# 139
::exit(___);}
#if 0
# 137
{ 
# 138
return ThreadScanExclusive< LENGTH> ((T *)(input), (T *)(output), scan_op, prefix, apply_prefix); 
# 139
} 
#endif
# 149 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../thread/thread_scan.cuh"
template< int 
# 150
LENGTH, class 
# 151
T, class 
# 152
ScanOp> 
# 153
__attribute((always_inline)) __attribute__((unused)) inline T ThreadScanInclusive(T 
# 154
inclusive, T *
# 155
input, T *
# 156
output, ScanOp 
# 157
scan_op, Int2Type< LENGTH>  
# 158
length) 
# 159
{int volatile ___ = 1;(void)inclusive;(void)input;(void)output;(void)scan_op;(void)length;
# 165
::exit(___);}
#if 0
# 159
{ 
# 160
T addend = *input; 
# 161
inclusive = scan_op(inclusive, addend); 
# 162
(output[0]) = inclusive; 
# 164
return ThreadScanInclusive(inclusive, input + 1, output + 1, scan_op, Int2Type< LENGTH - 1> ()); 
# 165
} 
#endif
# 167 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../thread/thread_scan.cuh"
template< class 
# 168
T, class 
# 169
ScanOp> 
# 170
__attribute((always_inline)) __attribute__((unused)) inline T ThreadScanInclusive(T 
# 171
inclusive, T *
# 172
input, T *
# 173
output, ScanOp 
# 174
scan_op, Int2Type< 0>  
# 175
length) 
# 176
{int volatile ___ = 1;(void)inclusive;(void)input;(void)output;(void)scan_op;(void)length;
# 178
::exit(___);}
#if 0
# 176
{ 
# 177
return inclusive; 
# 178
} 
#endif
# 188 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../thread/thread_scan.cuh"
template< int 
# 189
LENGTH, class 
# 190
T, class 
# 191
ScanOp> 
# 192
__attribute((always_inline)) __attribute__((unused)) inline T ThreadScanInclusive(T *
# 193
input, T *
# 194
output, ScanOp 
# 195
scan_op) 
# 196
{int volatile ___ = 1;(void)input;(void)output;(void)scan_op;
# 202
::exit(___);}
#if 0
# 196
{ 
# 197
T inclusive = input[0]; 
# 198
(output[0]) = inclusive; 
# 201
return ThreadScanInclusive(inclusive, input + 1, output + 1, scan_op, Int2Type< LENGTH - 1> ()); 
# 202
} 
#endif
# 212 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../thread/thread_scan.cuh"
template< int 
# 213
LENGTH, class 
# 214
T, class 
# 215
ScanOp> 
# 216
__attribute((always_inline)) __attribute__((unused)) inline T ThreadScanInclusive(T (&
# 217
input)[LENGTH], T (&
# 218
output)[LENGTH], ScanOp 
# 219
scan_op) 
# 220
{int volatile ___ = 1;(void)input;(void)output;(void)scan_op;
# 222
::exit(___);}
#if 0
# 220
{ 
# 221
return ThreadScanInclusive< LENGTH> ((T *)(input), (T *)(output), scan_op); 
# 222
} 
#endif
# 232 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../thread/thread_scan.cuh"
template< int 
# 233
LENGTH, class 
# 234
T, class 
# 235
ScanOp> 
# 236
__attribute((always_inline)) __attribute__((unused)) inline T ThreadScanInclusive(T *
# 237
input, T *
# 238
output, ScanOp 
# 239
scan_op, T 
# 240
prefix, bool 
# 241
apply_prefix = true) 
# 242
{int volatile ___ = 1;(void)input;(void)output;(void)scan_op;(void)prefix;(void)apply_prefix;
# 252
::exit(___);}
#if 0
# 242
{ 
# 243
T inclusive = input[0]; 
# 244
if (apply_prefix) 
# 245
{ 
# 246
inclusive = scan_op(prefix, inclusive); 
# 247
}  
# 248
(output[0]) = inclusive; 
# 251
return ThreadScanInclusive(inclusive, input + 1, output + 1, scan_op, Int2Type< LENGTH - 1> ()); 
# 252
} 
#endif
# 262 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../thread/thread_scan.cuh"
template< int 
# 263
LENGTH, class 
# 264
T, class 
# 265
ScanOp> 
# 266
__attribute((always_inline)) __attribute__((unused)) inline T ThreadScanInclusive(T (&
# 267
input)[LENGTH], T (&
# 268
output)[LENGTH], ScanOp 
# 269
scan_op, T 
# 270
prefix, bool 
# 271
apply_prefix = true) 
# 272
{int volatile ___ = 1;(void)input;(void)output;(void)scan_op;(void)prefix;(void)apply_prefix;
# 274
::exit(___);}
#if 0
# 272
{ 
# 273
return ThreadScanInclusive< LENGTH> ((T *)(input), (T *)(output), scan_op, prefix, apply_prefix); 
# 274
} 
#endif
# 282 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../thread/thread_scan.cuh"
}
# 283
}}}}
# 42 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../block/block_raking_layout.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 45
namespace cub_ { 
# 62
template< class 
# 63
T, int 
# 64
BLOCK_THREADS, int 
# 65
PTX_ARCH = 0> 
# 66
struct BlockRakingLayout { 
# 73
enum { 
# 75
SHARED_ELEMENTS = BLOCK_THREADS, 
# 78
MAX_RAKING_THREADS = ((1 << 5) < BLOCK_THREADS) ? 1 << 5 : BLOCK_THREADS, 
# 81
SEGMENT_LENGTH = (((BLOCK_THREADS) + (((1 << 5) < BLOCK_THREADS) ? 1 << 5 : BLOCK_THREADS)) - 1) / (((1 << 5) < BLOCK_THREADS) ? 1 << 5 : BLOCK_THREADS), 
# 84
RAKING_THREADS = (((BLOCK_THREADS) + ((((BLOCK_THREADS) + (((1 << 5) < BLOCK_THREADS) ? 1 << 5 : BLOCK_THREADS)) - 1) / (((1 << 5) < BLOCK_THREADS) ? 1 << 5 : BLOCK_THREADS))) - 1) / ((((BLOCK_THREADS) + (((1 << 5) < BLOCK_THREADS) ? 1 << 5 : BLOCK_THREADS)) - 1) / (((1 << 5) < BLOCK_THREADS) ? 1 << 5 : BLOCK_THREADS)), 
# 87
HAS_CONFLICTS = ((1 << ((PTX_ARCH >= 200) ? 5 : 4)) % ((((BLOCK_THREADS) + (((1 << 5) < BLOCK_THREADS) ? 1 << 5 : BLOCK_THREADS)) - 1) / (((1 << 5) < BLOCK_THREADS) ? 1 << 5 : BLOCK_THREADS))) == 0, 
# 90
CONFLICT_DEGREE = (((1 << ((PTX_ARCH >= 200) ? 5 : 4)) % ((((BLOCK_THREADS) + (((1 << 5) < BLOCK_THREADS) ? 1 << 5 : BLOCK_THREADS)) - 1) / (((1 << 5) < BLOCK_THREADS) ? 1 << 5 : BLOCK_THREADS))) == 0) ? ((((1 << 5) < BLOCK_THREADS) ? 1 << 5 : BLOCK_THREADS) * ((((BLOCK_THREADS) + (((1 << 5) < BLOCK_THREADS) ? 1 << 5 : BLOCK_THREADS)) - 1) / (((1 << 5) < BLOCK_THREADS) ? 1 << 5 : BLOCK_THREADS))) / (1 << ((PTX_ARCH >= 200) ? 5 : 4)) : 1, 
# 95
SEGMENT_PADDING = (((((1 << ((PTX_ARCH >= 200) ? 5 : 4)) % ((((BLOCK_THREADS) + (((1 << 5) < BLOCK_THREADS) ? 1 << 5 : BLOCK_THREADS)) - 1) / (((1 << 5) < BLOCK_THREADS) ? 1 << 5 : BLOCK_THREADS))) == 0) ? ((((1 << 5) < BLOCK_THREADS) ? 1 << 5 : BLOCK_THREADS) * ((((BLOCK_THREADS) + (((1 << 5) < BLOCK_THREADS) ? 1 << 5 : BLOCK_THREADS)) - 1) / (((1 << 5) < BLOCK_THREADS) ? 1 << 5 : BLOCK_THREADS))) / (1 << ((PTX_ARCH >= 200) ? 5 : 4)) : 1) > ((PTX_ARCH >= 300) ? 1 : 4)) ? 1 : 0, 
# 99
GRID_ELEMENTS = ((((BLOCK_THREADS) + ((((BLOCK_THREADS) + (((1 << 5) < BLOCK_THREADS) ? 1 << 5 : BLOCK_THREADS)) - 1) / (((1 << 5) < BLOCK_THREADS) ? 1 << 5 : BLOCK_THREADS))) - 1) / ((((BLOCK_THREADS) + (((1 << 5) < BLOCK_THREADS) ? 1 << 5 : BLOCK_THREADS)) - 1) / (((1 << 5) < BLOCK_THREADS) ? 1 << 5 : BLOCK_THREADS))) * (((((BLOCK_THREADS) + (((1 << 5) < BLOCK_THREADS) ? 1 << 5 : BLOCK_THREADS)) - 1) / (((1 << 5) < BLOCK_THREADS) ? 1 << 5 : BLOCK_THREADS)) + ((((((1 << ((PTX_ARCH >= 200) ? 5 : 4)) % ((((BLOCK_THREADS) + (((1 << 5) < BLOCK_THREADS) ? 1 << 5 : BLOCK_THREADS)) - 1) / (((1 << 5) < BLOCK_THREADS) ? 1 << 5 : BLOCK_THREADS))) == 0) ? ((((1 << 5) < BLOCK_THREADS) ? 1 << 5 : BLOCK_THREADS) * ((((BLOCK_THREADS) + (((1 << 5) < BLOCK_THREADS) ? 1 << 5 : BLOCK_THREADS)) - 1) / (((1 << 5) < BLOCK_THREADS) ? 1 << 5 : BLOCK_THREADS))) / (1 << ((PTX_ARCH >= 200) ? 5 : 4)) : 1) > ((PTX_ARCH >= 300) ? 1 : 4)) ? 1 : 0)), 
# 102
UNGUARDED = ((BLOCK_THREADS) % ((((BLOCK_THREADS) + ((((BLOCK_THREADS) + (((1 << 5) < BLOCK_THREADS) ? 1 << 5 : BLOCK_THREADS)) - 1) / (((1 << 5) < BLOCK_THREADS) ? 1 << 5 : BLOCK_THREADS))) - 1) / ((((BLOCK_THREADS) + (((1 << 5) < BLOCK_THREADS) ? 1 << 5 : BLOCK_THREADS)) - 1) / (((1 << 5) < BLOCK_THREADS) ? 1 << 5 : BLOCK_THREADS)))) == 0
# 103
}; 
# 109
typedef T _TempStorage[GRID_ELEMENTS]; 
# 112
struct TempStorage : public Uninitialized< T [GRID_ELEMENTS]>  { }; 
# 118
__attribute((always_inline)) static T *PlacementPtr(TempStorage &
# 119
temp_storage, int 
# 120
linear_tid) 
# 121
{int volatile ___ = 1;(void)temp_storage;(void)linear_tid;
# 133
::exit(___);}
#if 0
# 121
{ 
# 123
unsigned offset = linear_tid; 
# 126
if ((SEGMENT_PADDING) > 0) 
# 127
{ 
# 128
offset += (offset / (SEGMENT_LENGTH)); 
# 129
}  
# 132
return (temp_storage.Alias()) + offset; 
# 133
} 
#endif
# 139 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../block/block_raking_layout.cuh"
__attribute((always_inline)) static T *RakingPtr(TempStorage &
# 140
temp_storage, int 
# 141
linear_tid) 
# 142
{int volatile ___ = 1;(void)temp_storage;(void)linear_tid;
# 144
::exit(___);}
#if 0
# 142
{ 
# 143
return (temp_storage.Alias()) + (linear_tid * ((SEGMENT_LENGTH) + (SEGMENT_PADDING))); 
# 144
} 
#endif
# 145 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../block/block_raking_layout.cuh"
}; 
# 147
}
# 148
}}}}
# 42 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/warp_scan_shfl.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 45
namespace cub_ { 
# 50
template< class 
# 51
T, int 
# 52
LOGICAL_WARP_THREADS, int 
# 53
PTX_ARCH> 
# 54
struct WarpScanShfl { 
# 62
enum { 
# 64
IS_ARCH_WARP = LOGICAL_WARP_THREADS == (1 << 5), 
# 67
STEPS = Log2< LOGICAL_WARP_THREADS> ::VALUE, 
# 70
SHFL_C = (((-1) << (Log2< LOGICAL_WARP_THREADS> ::VALUE)) & 31) << 8
# 71
}; 
# 73
template< class S> 
# 74
struct IsInteger { 
# 76
enum { 
# 78
IS_INTEGER = (Traits< S> ::CATEGORY == UNSIGNED_INTEGER) || (Traits< S> ::CATEGORY == SIGNED_INTEGER), 
# 81
IS_SMALL_INTEGER = ((Traits< S> ::CATEGORY == UNSIGNED_INTEGER) || (Traits< S> ::CATEGORY == SIGNED_INTEGER)) && (sizeof(S) <= sizeof(unsigned))
# 82
}; 
# 83
}; 
# 86
typedef NullType TempStorage; 
# 93
int lane_id; 
# 100
__attribute((always_inline)) WarpScanShfl(TempStorage &
# 101
temp_storage) : lane_id((IS_ARCH_WARP) ? LaneId() : (LaneId() % (LOGICAL_WARP_THREADS))) 
# 106
{int *volatile ___ = 0;(void)temp_storage;::free(___);}
#if 0
# 106
{ } 
#endif
# 114 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/warp_scan_shfl.cuh"
__attribute((always_inline)) unsigned InclusiveScanStep(unsigned 
# 115
input, Sum 
# 116
scan_op, int 
# 117
first_lane, int 
# 118
offset) 
# 119
{int volatile ___ = 1;(void)input;(void)scan_op;(void)first_lane;(void)offset;
# 134
::exit(___);}
#if 0
# 119
{ 
# 120
unsigned output; 
# 123
__asm__("{  .reg .u32 r0;  .reg .pred p;  shfl.up.b32 r0|p, %1, %2, %3;  @p add.u32 r0, r0, %4;  mov.u32 %0, r0;}" : "=r" (output) : "r" (input), "r" (offset), "r" (first_lane), "r" (input)); 
# 133
return output; 
# 134
} 
#endif
# 138 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/warp_scan_shfl.cuh"
__attribute((always_inline)) float InclusiveScanStep(float 
# 139
input, Sum 
# 140
scan_op, int 
# 141
first_lane, int 
# 142
offset) 
# 143
{int volatile ___ = 1;(void)input;(void)scan_op;(void)first_lane;(void)offset;
# 158
::exit(___);}
#if 0
# 143
{ 
# 144
float output; 
# 147
__asm__("{  .reg .f32 r0;  .reg .pred p;  shfl.up.b32 r0|p, %1, %2, %3;  @p add.f32 r0, r0, %4;  mov.f32 %0, r0;}" : "=f" (output) : "f" (input), "r" (offset), "r" (first_lane), "f" (input)); 
# 157
return output; 
# 158
} 
#endif
# 162 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/warp_scan_shfl.cuh"
__attribute((always_inline)) unsigned long long InclusiveScanStep(unsigned long long 
# 163
input, Sum 
# 164
scan_op, int 
# 165
first_lane, int 
# 166
offset) 
# 167
{int volatile ___ = 1;(void)input;(void)scan_op;(void)first_lane;(void)offset;
# 185
::exit(___);}
#if 0
# 167
{ 
# 168
unsigned long long output; 
# 171
__asm__("{  .reg .u32 lo;  .reg .u32 hi;  .reg .pred p;  mov.b64 {lo, hi}, %1;  shfl.up.b32 lo|p, lo, %2, %3;  shfl.up.b32 hi|p, hi, %2, " "%3;  mov.b64 %0, {lo, hi};  @p add.u64 %0, %0, %1;}" : "=l" (output) : "l" (input), "r" (offset), "r" (first_lane)); 
# 184
return output; 
# 185
} 
#endif
# 189 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/warp_scan_shfl.cuh"
__attribute((always_inline)) long long InclusiveScanStep(long long 
# 190
input, Sum 
# 191
scan_op, int 
# 192
first_lane, int 
# 193
offset) 
# 194
{int volatile ___ = 1;(void)input;(void)scan_op;(void)first_lane;(void)offset;
# 212
::exit(___);}
#if 0
# 194
{ 
# 195
long long output; 
# 198
__asm__("{  .reg .u32 lo;  .reg .u32 hi;  .reg .pred p;  mov.b64 {lo, hi}, %1;  shfl.up.b32 lo|p, lo, %2, %3;  shfl.up.b32 hi|p, hi, %2, " "%3;  mov.b64 %0, {lo, hi};  @p add.s64 %0, %0, %1;}" : "=l" (output) : "l" (input), "r" (offset), "r" (first_lane)); 
# 211
return output; 
# 212
} 
#endif
# 216 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/warp_scan_shfl.cuh"
__attribute((always_inline)) double InclusiveScanStep(double 
# 217
input, Sum 
# 218
scan_op, int 
# 219
first_lane, int 
# 220
offset) 
# 221
{int volatile ___ = 1;(void)input;(void)scan_op;(void)first_lane;(void)offset;
# 239
::exit(___);}
#if 0
# 221
{ 
# 222
double output; 
# 225
__asm__("{  .reg .u32 lo;  .reg .u32 hi;  .reg .pred p;  mov.b64 {lo, hi}, %1;  shfl.up.b32 lo|p, lo, %2, %3;  shfl.up.b32 hi|p, hi, %2, " "%3;  mov.b64 %0, {lo, hi};  @p add.f64 %0, %0, %1;}" : "=d" (output) : "d" (input), "r" (offset), "r" (first_lane)); 
# 238
return output; 
# 239
} 
#endif
# 243 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/warp_scan_shfl.cuh"
template< class Value, class Offset> 
# 244
__attribute((always_inline)) ItemOffsetPair< Value, Offset>  InclusiveScanStep(ItemOffsetPair< Value, Offset>  
# 245
input, ReduceBySegmentOp< Sum, ItemOffsetPair< Value, Offset> >  
# 246
scan_op, int 
# 247
first_lane, int 
# 248
offset) 
# 249
{int volatile ___ = 1;(void)input;(void)scan_op;(void)first_lane;(void)offset;
# 263
::exit(___);}
#if 0
# 249
{ 
# 250
ItemOffsetPair< Value, Offset>  output; 
# 252
(output.value) = InclusiveScanStep((input.value), Sum(), first_lane, offset, Int2Type< IsInteger< Value> ::IS_SMALL_INTEGER> ()); 
# 253
(output.offset) = InclusiveScanStep((input.offset), Sum(), first_lane, offset, Int2Type< IsInteger< Offset> ::IS_SMALL_INTEGER> ()); 
# 255
if ((input.offset) > 0) { 
# 256
(output.value) = (input.value); }  
# 262
return output; 
# 263
} 
#endif
# 267 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/warp_scan_shfl.cuh"
template< class _T, class ScanOp> 
# 268
__attribute((always_inline)) _T InclusiveScanStep(_T 
# 269
input, ScanOp 
# 270
scan_op, int 
# 271
first_lane, int 
# 272
offset) 
# 273
{int volatile ___ = 1;(void)input;(void)scan_op;(void)first_lane;(void)offset;
# 283
::exit(___);}
#if 0
# 273
{ 
# 274
T output = input; 
# 276
T temp = ShuffleUp(output, offset); 
# 279
if ((lane_id) >= offset) { 
# 280
output = scan_op(temp, output); }  
# 282
return output; 
# 283
} 
#endif
# 287 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/warp_scan_shfl.cuh"
template< class _T, class ScanOp> 
# 288
__attribute((always_inline)) _T InclusiveScanStep(_T 
# 289
input, ScanOp 
# 290
scan_op, int 
# 291
first_lane, int 
# 292
offset, Int2Type< 1>  
# 293
is_small_integer) 
# 294
{int volatile ___ = 1;(void)input;(void)scan_op;(void)first_lane;(void)offset;(void)is_small_integer;
# 300
::exit(___);}
#if 0
# 294
{ 
# 295
unsigned temp = reinterpret_cast< unsigned &>(input); 
# 297
temp = InclusiveScanStep(temp, scan_op, first_lane, offset); 
# 299
return reinterpret_cast< _T &>(temp); 
# 300
} 
#endif
# 304 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/warp_scan_shfl.cuh"
template< class _T, class ScanOp> 
# 305
__attribute((always_inline)) _T InclusiveScanStep(_T 
# 306
input, ScanOp 
# 307
scan_op, int 
# 308
first_lane, int 
# 309
offset, Int2Type< 0>  
# 310
is_small_integer) 
# 311
{int volatile ___ = 1;(void)input;(void)scan_op;(void)first_lane;(void)offset;(void)is_small_integer;
# 313
::exit(___);}
#if 0
# 311
{ 
# 312
return InclusiveScanStep(input, scan_op, first_lane, offset); 
# 313
} 
#endif
# 317 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/warp_scan_shfl.cuh"
__attribute((always_inline)) T GetExclusive(T 
# 318
input, T 
# 319
inclusive, Sum 
# 320
scan_op, Int2Type< 1>  
# 321
is_integer) 
# 322
{int volatile ___ = 1;(void)input;(void)inclusive;(void)scan_op;(void)is_integer;
# 324
::exit(___);}
#if 0
# 322
{ 
# 323
return inclusive - input; 
# 324
} 
#endif
# 328 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/warp_scan_shfl.cuh"
template< class ScanOp, int _IS_INTEGER> 
# 329
__attribute((always_inline)) T GetExclusive(T 
# 330
input, T 
# 331
inclusive, ScanOp 
# 332
scan_op, Int2Type< _IS_INTEGER>  
# 333
is_integer) 
# 334
{int volatile ___ = 1;(void)input;(void)inclusive;(void)scan_op;(void)is_integer;
# 336
::exit(___);}
#if 0
# 334
{ 
# 335
return ShuffleUp(inclusive, 1); 
# 336
} 
#endif
# 339 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/warp_scan_shfl.cuh"
__attribute((always_inline)) T GetExclusive(T 
# 340
input, T 
# 341
inclusive, T 
# 342
identity, Sum 
# 343
scan_op, Int2Type< 1>  
# 344
is_integer) 
# 345
{int volatile ___ = 1;(void)input;(void)inclusive;(void)identity;(void)scan_op;(void)is_integer;
# 347
::exit(___);}
#if 0
# 345
{ 
# 346
return inclusive - input; 
# 347
} 
#endif
# 351 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/warp_scan_shfl.cuh"
template< class ScanOp, int _IS_INTEGER> 
# 352
__attribute((always_inline)) T GetExclusive(T 
# 353
input, T 
# 354
inclusive, T 
# 355
identity, ScanOp 
# 356
scan_op, Int2Type< _IS_INTEGER>  
# 357
is_integer) 
# 358
{int volatile ___ = 1;(void)input;(void)inclusive;(void)identity;(void)scan_op;(void)is_integer;
# 361
::exit(___);}
#if 0
# 358
{ 
# 359
T exclusive = ShuffleUp(inclusive, 1); 
# 360
return ((lane_id) == 0) ? identity : exclusive; 
# 361
} 
#endif
# 370 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/warp_scan_shfl.cuh"
__attribute((always_inline)) T Broadcast(T 
# 371
input, int 
# 372
src_lane) 
# 373
{int volatile ___ = 1;(void)input;(void)src_lane;
# 375
::exit(___);}
#if 0
# 373
{ 
# 374
return ShuffleBroadcast(input, src_lane, LOGICAL_WARP_THREADS); 
# 375
} 
#endif
# 383 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/warp_scan_shfl.cuh"
template< class ScanOp> 
# 384
__attribute((always_inline)) void InclusiveScan(T 
# 385
input, T &
# 386
output, ScanOp 
# 387
scan_op) 
# 388
{int volatile ___ = 1;(void)input;(void)output;(void)scan_op;
# 397
::exit(___);}
#if 0
# 388
{ 
# 389
output = input; 
# 393
#pragma unroll
for (
# 393
int STEP = 0; STEP < (STEPS); STEP++) 
# 394
{ 
# 395
output = InclusiveScanStep(output, scan_op, SHFL_C, 1 << STEP, Int2Type< IsInteger< T> ::IS_SMALL_INTEGER> ()); 
# 396
}  
# 397
} 
#endif
# 401 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/warp_scan_shfl.cuh"
template< class ScanOp> 
# 402
__attribute((always_inline)) void InclusiveScan(T 
# 403
input, T &
# 404
output, ScanOp 
# 405
scan_op, T &
# 406
warp_aggregate) 
# 407
{int volatile ___ = 1;(void)input;(void)output;(void)scan_op;(void)warp_aggregate;
# 412
::exit(___);}
#if 0
# 407
{ 
# 408
InclusiveScan(input, output, scan_op); 
# 411
warp_aggregate = Broadcast(output, LOGICAL_WARP_THREADS - 1); 
# 412
} 
#endif
# 420 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/warp_scan_shfl.cuh"
template< class ScanOp> 
# 421
__attribute((always_inline)) void Scan(T 
# 422
input, T &
# 423
inclusive_output, T &
# 424
exclusive_output, ScanOp 
# 425
scan_op) 
# 426
{int volatile ___ = 1;(void)input;(void)inclusive_output;(void)exclusive_output;(void)scan_op;
# 432
::exit(___);}
#if 0
# 426
{ 
# 428
InclusiveScan(input, inclusive_output, scan_op); 
# 431
exclusive_output = GetExclusive(input, inclusive_output, scan_op, Int2Type< IsInteger< T> ::IS_INTEGER> ()); 
# 432
} 
#endif
# 435 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/warp_scan_shfl.cuh"
template< class ScanOp> 
# 436
__attribute((always_inline)) void Scan(T 
# 437
input, T &
# 438
inclusive_output, T &
# 439
exclusive_output, T 
# 440
identity, ScanOp 
# 441
scan_op) 
# 442
{int volatile ___ = 1;(void)input;(void)inclusive_output;(void)exclusive_output;(void)identity;(void)scan_op;
# 448
::exit(___);}
#if 0
# 442
{ 
# 444
InclusiveScan(input, inclusive_output, scan_op); 
# 447
exclusive_output = GetExclusive(input, inclusive_output, identity, scan_op, Int2Type< IsInteger< T> ::IS_INTEGER> ()); 
# 448
} 
#endif
# 456 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/warp_scan_shfl.cuh"
template< class ScanOp> 
# 457
__attribute((always_inline)) void ExclusiveScan(T 
# 458
input, T &
# 459
output, T 
# 460
identity, ScanOp 
# 461
scan_op) 
# 462
{int volatile ___ = 1;(void)input;(void)output;(void)identity;(void)scan_op;
# 465
::exit(___);}
#if 0
# 462
{ 
# 463
T inclusive_output; 
# 464
Scan(input, inclusive_output, output, identity, scan_op); 
# 465
} 
#endif
# 469 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/warp_scan_shfl.cuh"
template< class ScanOp> 
# 470
__attribute((always_inline)) void ExclusiveScan(T 
# 471
input, T &
# 472
output, ScanOp 
# 473
scan_op) 
# 474
{int volatile ___ = 1;(void)input;(void)output;(void)scan_op;
# 477
::exit(___);}
#if 0
# 474
{ 
# 475
T inclusive_output; 
# 476
Scan(input, inclusive_output, output, scan_op); 
# 477
} 
#endif
# 481 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/warp_scan_shfl.cuh"
template< class ScanOp> 
# 482
__attribute((always_inline)) void ExclusiveScan(T 
# 483
input, T &
# 484
output, T 
# 485
identity, ScanOp 
# 486
scan_op, T &
# 487
warp_aggregate) 
# 488
{int volatile ___ = 1;(void)input;(void)output;(void)identity;(void)scan_op;(void)warp_aggregate;
# 494
::exit(___);}
#if 0
# 488
{ 
# 489
T inclusive_output; 
# 490
Scan(input, inclusive_output, output, identity, scan_op); 
# 493
warp_aggregate = Broadcast(inclusive_output, LOGICAL_WARP_THREADS - 1); 
# 494
} 
#endif
# 498 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/warp_scan_shfl.cuh"
template< class ScanOp> 
# 499
__attribute((always_inline)) void ExclusiveScan(T 
# 500
input, T &
# 501
output, ScanOp 
# 502
scan_op, T &
# 503
warp_aggregate) 
# 504
{int volatile ___ = 1;(void)input;(void)output;(void)scan_op;(void)warp_aggregate;
# 510
::exit(___);}
#if 0
# 504
{ 
# 505
T inclusive_output; 
# 506
Scan(input, inclusive_output, output, scan_op); 
# 509
warp_aggregate = Broadcast(inclusive_output, LOGICAL_WARP_THREADS - 1); 
# 510
} 
#endif
# 512 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/warp_scan_shfl.cuh"
}; 
# 515
}
# 516
}}}}
# 45 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_load.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 48
namespace cub_ { 
# 62
enum CacheLoadModifier { 
# 64
LOAD_DEFAULT, 
# 65
LOAD_CA, 
# 66
LOAD_CG, 
# 67
LOAD_CS, 
# 68
LOAD_CV, 
# 69
LOAD_LDG, 
# 70
LOAD_VOLATILE
# 71
}; 
# 107
template< CacheLoadModifier 
# 108
MODIFIER, class 
# 109
InputIterator> 
# 110
__attribute((always_inline)) __attribute__((unused)) inline typename std::iterator_traits< InputIterator> ::value_type 
# 107
ThreadLoad(InputIterator itr); 
# 120
template< int COUNT, int MAX> 
# 121
struct IterateThreadLoad { 
# 123
template< CacheLoadModifier MODIFIER, class T> 
# 124
__attribute((always_inline)) static void Load(T *ptr, T *vals) 
# 125
{int volatile ___ = 1;(void)ptr;(void)vals;
# 128
::exit(___);}
#if 0
# 125
{ 
# 126
(vals[COUNT]) = ThreadLoad< MODIFIER> (ptr + COUNT); 
# 127
cub_::IterateThreadLoad< COUNT + 1, MAX> ::template Load< MODIFIER> (ptr, vals); 
# 128
} 
#endif
# 130 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_load.cuh"
template< class InputIterator, class T> 
# 131
__attribute((always_inline)) static void Dereference(InputIterator ptr, T *vals) 
# 132
{int volatile ___ = 1;(void)ptr;(void)vals;
# 135
::exit(___);}
#if 0
# 132
{ 
# 133
(vals[COUNT]) = (ptr[COUNT]); 
# 134
IterateThreadLoad< COUNT + 1, MAX> ::Dereference(ptr, vals); 
# 135
} 
#endif
# 136 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_load.cuh"
}; 
# 140
template< int MAX> 
# 141
struct IterateThreadLoad< MAX, MAX>  { 
# 143
template< CacheLoadModifier MODIFIER, class T> 
# 144
__attribute((always_inline)) static void Load(T *ptr, T *vals) {int volatile ___ = 1;(void)ptr;(void)vals;::exit(___);}
#if 0
# 144
{ } 
#endif
# 146 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_load.cuh"
template< class InputIterator, class T> 
# 147
__attribute((always_inline)) static void Dereference(InputIterator ptr, T *vals) {int volatile ___ = 1;(void)ptr;(void)vals;::exit(___);}
#if 0
# 147
{ } 
#endif
# 148 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_load.cuh"
}; 
# 284
template<> __attribute((always_inline)) __attribute__((unused)) inline uint4 ThreadLoad< LOAD_CA, uint4 *> (uint4 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 284
{ uint4 retval; __asm__ volatile("ld.global.v4.u32 {%0, %1, %2, %3}, [%4];" : "=r" (retval.x), "=r" (retval.y), "=r" (retval.z), "=r" (retval.w) : "l" (ptr)); return retval; } 
#endif
# 284 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_load.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline ulonglong2 ThreadLoad< LOAD_CA, ulonglong2 *> (ulonglong2 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 284
{ ulonglong2 retval; __asm__ volatile("ld.global.v2.u64 {%0, %1}, [%2];" : "=l" (retval.x), "=l" (retval.y) : "l" (ptr)); return retval; } 
#endif
# 284 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_load.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline ushort4 ThreadLoad< LOAD_CA, ushort4 *> (ushort4 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 284
{ ushort4 retval; __asm__ volatile("ld.global.v4.u16 {%0, %1, %2, %3}, [%4];" : "=h" (retval.x), "=h" (retval.y), "=h" (retval.z), "=h" (retval.w) : "l" (ptr)); return retval; } 
#endif
# 284 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_load.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline uint2 ThreadLoad< LOAD_CA, uint2 *> (uint2 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 284
{ uint2 retval; __asm__ volatile("ld.global.v2.u32 {%0, %1}, [%2];" : "=r" (retval.x), "=r" (retval.y) : "l" (ptr)); return retval; } 
#endif
# 284 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_load.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline unsigned long long ThreadLoad< LOAD_CA, unsigned long long *> (unsigned long long *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 284
{ unsigned long long retval; __asm__ volatile("ld.global.u64 %0, [%1];" : "=l" (retval) : "l" (ptr)); return retval; } 
#endif
# 284 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_load.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline unsigned ThreadLoad< LOAD_CA, unsigned *> (unsigned *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 284
{ unsigned retval; __asm__ volatile("ld.global.u32 %0, [%1];" : "=r" (retval) : "l" (ptr)); return retval; } 
#endif
# 284 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_load.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline unsigned short ThreadLoad< LOAD_CA, unsigned short *> (unsigned short *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 284
{ unsigned short retval; __asm__ volatile("ld.global.u16 %0, [%1];" : "=h" (retval) : "l" (ptr)); return retval; } 
#endif
# 284 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_load.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline unsigned char ThreadLoad< LOAD_CA, unsigned char *> (unsigned char *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 284
{ unsigned short retval; __asm__ volatile("{   .reg .u8 datum;    ld.global.u8 datum, [%1];    cvt.u16.u8 %0, datum;}" : "=h" (retval) : "l" (ptr)); return (unsigned char)retval; } 
#endif
# 286 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_load.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline uint4 ThreadLoad< LOAD_CG, uint4 *> (uint4 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 286
{ uint4 retval; __asm__ volatile("ld.volatile.global.v4.u32 {%0, %1, %2, %3}, [%4];" : "=r" (retval.x), "=r" (retval.y), "=r" (retval.z), "=r" (retval.w) : "l" (ptr)); return retval; } 
#endif
# 286 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_load.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline ulonglong2 ThreadLoad< LOAD_CG, ulonglong2 *> (ulonglong2 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 286
{ ulonglong2 retval; __asm__ volatile("ld.volatile.global.v2.u64 {%0, %1}, [%2];" : "=l" (retval.x), "=l" (retval.y) : "l" (ptr)); return retval; } 
#endif
# 286 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_load.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline ushort4 ThreadLoad< LOAD_CG, ushort4 *> (ushort4 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 286
{ ushort4 retval; __asm__ volatile("ld.volatile.global.v4.u16 {%0, %1, %2, %3}, [%4];" : "=h" (retval.x), "=h" (retval.y), "=h" (retval.z), "=h" (retval.w) : "l" (ptr)); return retval; } 
#endif
# 286 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_load.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline uint2 ThreadLoad< LOAD_CG, uint2 *> (uint2 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 286
{ uint2 retval; __asm__ volatile("ld.volatile.global.v2.u32 {%0, %1}, [%2];" : "=r" (retval.x), "=r" (retval.y) : "l" (ptr)); return retval; } 
#endif
# 286 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_load.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline unsigned long long ThreadLoad< LOAD_CG, unsigned long long *> (unsigned long long *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 286
{ unsigned long long retval; __asm__ volatile("ld.volatile.global.u64 %0, [%1];" : "=l" (retval) : "l" (ptr)); return retval; } 
#endif
# 286 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_load.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline unsigned ThreadLoad< LOAD_CG, unsigned *> (unsigned *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 286
{ unsigned retval; __asm__ volatile("ld.volatile.global.u32 %0, [%1];" : "=r" (retval) : "l" (ptr)); return retval; } 
#endif
# 286 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_load.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline unsigned short ThreadLoad< LOAD_CG, unsigned short *> (unsigned short *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 286
{ unsigned short retval; __asm__ volatile("ld.volatile.global.u16 %0, [%1];" : "=h" (retval) : "l" (ptr)); return retval; } 
#endif
# 286 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_load.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline unsigned char ThreadLoad< LOAD_CG, unsigned char *> (unsigned char *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 286
{ unsigned short retval; __asm__ volatile("{   .reg .u8 datum;    ld.volatile.global.u8 datum, [%1];    cvt.u16.u8 %0, datum;}" : "=h" (retval) : "l" (ptr)); return (unsigned char)retval; } 
#endif
# 287 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_load.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline uint4 ThreadLoad< LOAD_CS, uint4 *> (uint4 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 287
{ uint4 retval; __asm__ volatile("ld.global.v4.u32 {%0, %1, %2, %3}, [%4];" : "=r" (retval.x), "=r" (retval.y), "=r" (retval.z), "=r" (retval.w) : "l" (ptr)); return retval; } 
#endif
# 287 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_load.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline ulonglong2 ThreadLoad< LOAD_CS, ulonglong2 *> (ulonglong2 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 287
{ ulonglong2 retval; __asm__ volatile("ld.global.v2.u64 {%0, %1}, [%2];" : "=l" (retval.x), "=l" (retval.y) : "l" (ptr)); return retval; } 
#endif
# 287 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_load.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline ushort4 ThreadLoad< LOAD_CS, ushort4 *> (ushort4 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 287
{ ushort4 retval; __asm__ volatile("ld.global.v4.u16 {%0, %1, %2, %3}, [%4];" : "=h" (retval.x), "=h" (retval.y), "=h" (retval.z), "=h" (retval.w) : "l" (ptr)); return retval; } 
#endif
# 287 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_load.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline uint2 ThreadLoad< LOAD_CS, uint2 *> (uint2 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 287
{ uint2 retval; __asm__ volatile("ld.global.v2.u32 {%0, %1}, [%2];" : "=r" (retval.x), "=r" (retval.y) : "l" (ptr)); return retval; } 
#endif
# 287 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_load.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline unsigned long long ThreadLoad< LOAD_CS, unsigned long long *> (unsigned long long *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 287
{ unsigned long long retval; __asm__ volatile("ld.global.u64 %0, [%1];" : "=l" (retval) : "l" (ptr)); return retval; } 
#endif
# 287 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_load.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline unsigned ThreadLoad< LOAD_CS, unsigned *> (unsigned *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 287
{ unsigned retval; __asm__ volatile("ld.global.u32 %0, [%1];" : "=r" (retval) : "l" (ptr)); return retval; } 
#endif
# 287 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_load.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline unsigned short ThreadLoad< LOAD_CS, unsigned short *> (unsigned short *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 287
{ unsigned short retval; __asm__ volatile("ld.global.u16 %0, [%1];" : "=h" (retval) : "l" (ptr)); return retval; } 
#endif
# 287 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_load.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline unsigned char ThreadLoad< LOAD_CS, unsigned char *> (unsigned char *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 287
{ unsigned short retval; __asm__ volatile("{   .reg .u8 datum;    ld.global.u8 datum, [%1];    cvt.u16.u8 %0, datum;}" : "=h" (retval) : "l" (ptr)); return (unsigned char)retval; } 
#endif
# 288 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_load.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline uint4 ThreadLoad< LOAD_CV, uint4 *> (uint4 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 288
{ uint4 retval; __asm__ volatile("ld.volatile.global.v4.u32 {%0, %1, %2, %3}, [%4];" : "=r" (retval.x), "=r" (retval.y), "=r" (retval.z), "=r" (retval.w) : "l" (ptr)); return retval; } 
#endif
# 288 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_load.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline ulonglong2 ThreadLoad< LOAD_CV, ulonglong2 *> (ulonglong2 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 288
{ ulonglong2 retval; __asm__ volatile("ld.volatile.global.v2.u64 {%0, %1}, [%2];" : "=l" (retval.x), "=l" (retval.y) : "l" (ptr)); return retval; } 
#endif
# 288 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_load.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline ushort4 ThreadLoad< LOAD_CV, ushort4 *> (ushort4 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 288
{ ushort4 retval; __asm__ volatile("ld.volatile.global.v4.u16 {%0, %1, %2, %3}, [%4];" : "=h" (retval.x), "=h" (retval.y), "=h" (retval.z), "=h" (retval.w) : "l" (ptr)); return retval; } 
#endif
# 288 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_load.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline uint2 ThreadLoad< LOAD_CV, uint2 *> (uint2 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 288
{ uint2 retval; __asm__ volatile("ld.volatile.global.v2.u32 {%0, %1}, [%2];" : "=r" (retval.x), "=r" (retval.y) : "l" (ptr)); return retval; } 
#endif
# 288 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_load.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline unsigned long long ThreadLoad< LOAD_CV, unsigned long long *> (unsigned long long *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 288
{ unsigned long long retval; __asm__ volatile("ld.volatile.global.u64 %0, [%1];" : "=l" (retval) : "l" (ptr)); return retval; } 
#endif
# 288 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_load.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline unsigned ThreadLoad< LOAD_CV, unsigned *> (unsigned *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 288
{ unsigned retval; __asm__ volatile("ld.volatile.global.u32 %0, [%1];" : "=r" (retval) : "l" (ptr)); return retval; } 
#endif
# 288 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_load.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline unsigned short ThreadLoad< LOAD_CV, unsigned short *> (unsigned short *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 288
{ unsigned short retval; __asm__ volatile("ld.volatile.global.u16 %0, [%1];" : "=h" (retval) : "l" (ptr)); return retval; } 
#endif
# 288 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_load.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline unsigned char ThreadLoad< LOAD_CV, unsigned char *> (unsigned char *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 288
{ unsigned short retval; __asm__ volatile("{   .reg .u8 datum;    ld.volatile.global.u8 datum, [%1];    cvt.u16.u8 %0, datum;}" : "=h" (retval) : "l" (ptr)); return (unsigned char)retval; } 
#endif
# 294 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_load.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline uint4 ThreadLoad< LOAD_LDG, uint4 *> (uint4 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 294
{ uint4 retval; __asm__ volatile("ld.global.v4.u32 {%0, %1, %2, %3}, [%4];" : "=r" (retval.x), "=r" (retval.y), "=r" (retval.z), "=r" (retval.w) : "l" (ptr)); return retval; } 
#endif
# 294 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_load.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline ulonglong2 ThreadLoad< LOAD_LDG, ulonglong2 *> (ulonglong2 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 294
{ ulonglong2 retval; __asm__ volatile("ld.global.v2.u64 {%0, %1}, [%2];" : "=l" (retval.x), "=l" (retval.y) : "l" (ptr)); return retval; } 
#endif
# 294 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_load.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline ushort4 ThreadLoad< LOAD_LDG, ushort4 *> (ushort4 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 294
{ ushort4 retval; __asm__ volatile("ld.global.v4.u16 {%0, %1, %2, %3}, [%4];" : "=h" (retval.x), "=h" (retval.y), "=h" (retval.z), "=h" (retval.w) : "l" (ptr)); return retval; } 
#endif
# 294 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_load.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline uint2 ThreadLoad< LOAD_LDG, uint2 *> (uint2 *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 294
{ uint2 retval; __asm__ volatile("ld.global.v2.u32 {%0, %1}, [%2];" : "=r" (retval.x), "=r" (retval.y) : "l" (ptr)); return retval; } 
#endif
# 294 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_load.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline unsigned long long ThreadLoad< LOAD_LDG, unsigned long long *> (unsigned long long *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 294
{ unsigned long long retval; __asm__ volatile("ld.global.u64 %0, [%1];" : "=l" (retval) : "l" (ptr)); return retval; } 
#endif
# 294 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_load.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline unsigned ThreadLoad< LOAD_LDG, unsigned *> (unsigned *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 294
{ unsigned retval; __asm__ volatile("ld.global.u32 %0, [%1];" : "=r" (retval) : "l" (ptr)); return retval; } 
#endif
# 294 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_load.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline unsigned short ThreadLoad< LOAD_LDG, unsigned short *> (unsigned short *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 294
{ unsigned short retval; __asm__ volatile("ld.global.u16 %0, [%1];" : "=h" (retval) : "l" (ptr)); return retval; } 
#endif
# 294 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_load.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline unsigned char ThreadLoad< LOAD_LDG, unsigned char *> (unsigned char *ptr) {int volatile ___ = 1;(void)ptr;::exit(___);}
#if 0
# 294
{ unsigned short retval; __asm__ volatile("{   .reg .u8 datum;    ld.global.u8 datum, [%1];    cvt.u16.u8 %0, datum;}" : "=h" (retval) : "l" (ptr)); return (unsigned char)retval; } 
#endif
# 301 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_load.cuh"
template< class InputIterator> 
# 302
__attribute((always_inline)) __attribute__((unused)) inline typename std::iterator_traits< InputIterator> ::value_type ThreadLoad(InputIterator 
# 303
itr, Int2Type< 0>  
# 304
modifier, Int2Type< 0>  
# 305
is_pointer) 
# 306
{int volatile ___ = 1;(void)itr;(void)modifier;(void)is_pointer;
# 308
::exit(___);}
#if 0
# 306
{ 
# 307
return *itr; 
# 308
} 
#endif
# 314 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_load.cuh"
template< class T> 
# 315
__attribute((always_inline)) __attribute__((unused)) inline T ThreadLoad(T *
# 316
ptr, Int2Type< 0>  
# 317
modifier, Int2Type< 1>  
# 318
is_pointer) 
# 319
{int volatile ___ = 1;(void)ptr;(void)modifier;(void)is_pointer;
# 321
::exit(___);}
#if 0
# 319
{ 
# 320
return *ptr; 
# 321
} 
#endif
# 327 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_load.cuh"
template< class T> 
# 328
__attribute((always_inline)) __attribute__((unused)) inline T ThreadLoadVolatilePointer(T *
# 329
ptr, Int2Type< 1>  
# 330
is_primitive) 
# 331
{int volatile ___ = 1;(void)ptr;(void)is_primitive;
# 339
::exit(___);}
#if 0
# 331
{ 
# 332
T retval = *(reinterpret_cast< volatile T *>(ptr)); 
# 335
if (sizeof(T) == (1)) { __threadfence_block(); }  
# 338
return retval; 
# 339
} 
#endif
# 345 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_load.cuh"
template< class T> 
# 346
__attribute((always_inline)) __attribute__((unused)) inline T ThreadLoadVolatilePointer(T *
# 347
ptr, Int2Type< 0>  
# 348
is_primitive) 
# 349
{int volatile ___ = 1;(void)ptr;(void)is_primitive;
# 380
::exit(___);}
#if 0
# 349
{ 
# 353
T retval = *ptr; 
# 354
__threadfence_block(); 
# 355
return retval; 
# 380
} 
#endif
# 386 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_load.cuh"
template< class T> 
# 387
__attribute((always_inline)) __attribute__((unused)) inline T ThreadLoad(T *
# 388
ptr, Int2Type< LOAD_VOLATILE>  
# 389
modifier, Int2Type< 1>  
# 390
is_pointer) 
# 391
{int volatile ___ = 1;(void)ptr;(void)modifier;(void)is_pointer;
# 394
::exit(___);}
#if 0
# 391
{ 
# 393
return ThreadLoadVolatilePointer(ptr, Int2Type< Traits< T> ::PRIMITIVE> ()); 
# 394
} 
#endif
# 400 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_load.cuh"
template< class T, int MODIFIER> 
# 401
__attribute((always_inline)) __attribute__((unused)) inline T ThreadLoad(T *
# 402
ptr, Int2Type< MODIFIER>  
# 403
modifier, Int2Type< 1>  
# 404
is_pointer) 
# 405
{int volatile ___ = 1;(void)ptr;(void)modifier;(void)is_pointer;
# 417
::exit(___);}
#if 0
# 405
{ 
# 406
typedef typename UnitWord< T> ::DeviceWord DeviceWord; 
# 408
const int DEVICE_MULTIPLE = (sizeof(T) / sizeof(DeviceWord)); 
# 410
DeviceWord words[DEVICE_MULTIPLE]; 
# 412
IterateThreadLoad< 0, DEVICE_MULTIPLE> ::template Load< (CacheLoadModifier)MODIFIER> (reinterpret_cast< DeviceWord *>(ptr), words); 
# 416
return *(reinterpret_cast< T *>(words)); 
# 417
} 
#endif
# 423 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_load.cuh"
template< CacheLoadModifier 
# 424
MODIFIER, class 
# 425
InputIterator> 
# 426
__attribute((always_inline)) __attribute__((unused)) inline typename std::iterator_traits< InputIterator> ::value_type ThreadLoad(InputIterator itr) 
# 427
{int volatile ___ = 1;(void)itr;
# 433
::exit(___);}
#if 0
# 427
{ 
# 429
return ThreadLoad(itr, Int2Type< MODIFIER> (), Int2Type< IsPointer< InputIterator> ::VALUE> ()); 
# 433
} 
#endif
# 443 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_load.cuh"
}
# 444
}}}}
# 43 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_store.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 46
namespace cub_ { 
# 61
enum CacheStoreModifier { 
# 63
STORE_DEFAULT, 
# 64
STORE_WB, 
# 65
STORE_CG, 
# 66
STORE_CS, 
# 67
STORE_WT, 
# 68
STORE_VOLATILE
# 69
}; 
# 110
template< CacheStoreModifier 
# 111
MODIFIER, class 
# 112
OutputIterator, class 
# 113
T> 
# 114
__attribute((always_inline)) __attribute__((unused)) inline void 
# 110
ThreadStore(OutputIterator itr, T val); 
# 124
template< int COUNT, int MAX> 
# 125
struct IterateThreadStore { 
# 127
template< CacheStoreModifier MODIFIER, class T> 
# 128
__attribute((always_inline)) static void Store(T *ptr, T *vals) 
# 129
{int volatile ___ = 1;(void)ptr;(void)vals;
# 132
::exit(___);}
#if 0
# 129
{ 
# 130
ThreadStore< MODIFIER> (ptr + COUNT, vals[COUNT]); 
# 131
cub_::IterateThreadStore< COUNT + 1, MAX> ::template Store< MODIFIER> (ptr, vals); 
# 132
} 
#endif
# 134 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_store.cuh"
template< class OutputIterator, class T> 
# 135
__attribute((always_inline)) static void Dereference(OutputIterator ptr, T *vals) 
# 136
{int volatile ___ = 1;(void)ptr;(void)vals;
# 139
::exit(___);}
#if 0
# 136
{ 
# 137
(ptr[COUNT]) = (vals[COUNT]); 
# 138
IterateThreadStore< COUNT + 1, MAX> ::Dereference(ptr, vals); 
# 139
} 
#endif
# 141 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_store.cuh"
}; 
# 144
template< int MAX> 
# 145
struct IterateThreadStore< MAX, MAX>  { 
# 147
template< CacheStoreModifier MODIFIER, class T> 
# 148
__attribute((always_inline)) static void Store(T *ptr, T *vals) {int volatile ___ = 1;(void)ptr;(void)vals;::exit(___);}
#if 0
# 148
{ } 
#endif
# 150 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_store.cuh"
template< class OutputIterator, class T> 
# 151
__attribute((always_inline)) static void Dereference(OutputIterator ptr, T *vals) {int volatile ___ = 1;(void)ptr;(void)vals;::exit(___);}
#if 0
# 151
{ } 
#endif
# 152 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_store.cuh"
}; 
# 272
template<> __attribute((always_inline)) __attribute__((unused)) inline void ThreadStore< STORE_WB, uint4 *, uint4> (uint4 *ptr, uint4 val) {int volatile ___ = 1;(void)ptr;(void)val;::exit(___);}
#if 0
# 272
{ __asm__ volatile("st.global.v4.u32 [%0], {%1, %2, %3, %4};" : : "l" (ptr), "r" (val.x), "r" (val.y), "r" (val.z), "r" (val.w)); } 
#endif
# 272 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_store.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline void ThreadStore< STORE_WB, ulonglong2 *, ulonglong2> (ulonglong2 *ptr, ulonglong2 val) {int volatile ___ = 1;(void)ptr;(void)val;::exit(___);}
#if 0
# 272
{ __asm__ volatile("st.global.v2.u64 [%0], {%1, %2};" : : "l" (ptr), "l" (val.x), "l" (val.y)); } 
#endif
# 272 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_store.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline void ThreadStore< STORE_WB, ushort4 *, ushort4> (ushort4 *ptr, ushort4 val) {int volatile ___ = 1;(void)ptr;(void)val;::exit(___);}
#if 0
# 272
{ __asm__ volatile("st.global.v4.u16 [%0], {%1, %2, %3, %4};" : : "l" (ptr), "h" (val.x), "h" (val.y), "h" (val.z), "h" (val.w)); } 
#endif
# 272 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_store.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline void ThreadStore< STORE_WB, uint2 *, uint2> (uint2 *ptr, uint2 val) {int volatile ___ = 1;(void)ptr;(void)val;::exit(___);}
#if 0
# 272
{ __asm__ volatile("st.global.v2.u32 [%0], {%1, %2};" : : "l" (ptr), "r" (val.x), "r" (val.y)); } 
#endif
# 272 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_store.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline void ThreadStore< STORE_WB, unsigned long long *, unsigned long long> (unsigned long long *ptr, unsigned long long val) {int volatile ___ = 1;(void)ptr;(void)val;::exit(___);}
#if 0
# 272
{ __asm__ volatile("st.global.u64 [%0], %1;" : : "l" (ptr), "l" (val)); } 
#endif
# 272 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_store.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline void ThreadStore< STORE_WB, unsigned *, unsigned> (unsigned *ptr, unsigned val) {int volatile ___ = 1;(void)ptr;(void)val;::exit(___);}
#if 0
# 272
{ __asm__ volatile("st.global.u32 [%0], %1;" : : "l" (ptr), "r" (val)); } 
#endif
# 272 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_store.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline void ThreadStore< STORE_WB, unsigned short *, unsigned short> (unsigned short *ptr, unsigned short val) {int volatile ___ = 1;(void)ptr;(void)val;::exit(___);}
#if 0
# 272
{ __asm__ volatile("st.global.u16 [%0], %1;" : : "l" (ptr), "h" (val)); } 
#endif
# 272 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_store.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline void ThreadStore< STORE_WB, unsigned char *, unsigned char> (unsigned char *ptr, unsigned char val) {int volatile ___ = 1;(void)ptr;(void)val;::exit(___);}
#if 0
# 272
{ __asm__ volatile("{   .reg .u8 datum;   cvt.u8.u16 datum, %1;   st.global.u8 [%0], datum;}" : : "l" (ptr), "h" ((unsigned short)val)); } 
#endif
# 273 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_store.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline void ThreadStore< STORE_CG, uint4 *, uint4> (uint4 *ptr, uint4 val) {int volatile ___ = 1;(void)ptr;(void)val;::exit(___);}
#if 0
# 273
{ __asm__ volatile("st.global.v4.u32 [%0], {%1, %2, %3, %4};" : : "l" (ptr), "r" (val.x), "r" (val.y), "r" (val.z), "r" (val.w)); } 
#endif
# 273 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_store.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline void ThreadStore< STORE_CG, ulonglong2 *, ulonglong2> (ulonglong2 *ptr, ulonglong2 val) {int volatile ___ = 1;(void)ptr;(void)val;::exit(___);}
#if 0
# 273
{ __asm__ volatile("st.global.v2.u64 [%0], {%1, %2};" : : "l" (ptr), "l" (val.x), "l" (val.y)); } 
#endif
# 273 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_store.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline void ThreadStore< STORE_CG, ushort4 *, ushort4> (ushort4 *ptr, ushort4 val) {int volatile ___ = 1;(void)ptr;(void)val;::exit(___);}
#if 0
# 273
{ __asm__ volatile("st.global.v4.u16 [%0], {%1, %2, %3, %4};" : : "l" (ptr), "h" (val.x), "h" (val.y), "h" (val.z), "h" (val.w)); } 
#endif
# 273 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_store.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline void ThreadStore< STORE_CG, uint2 *, uint2> (uint2 *ptr, uint2 val) {int volatile ___ = 1;(void)ptr;(void)val;::exit(___);}
#if 0
# 273
{ __asm__ volatile("st.global.v2.u32 [%0], {%1, %2};" : : "l" (ptr), "r" (val.x), "r" (val.y)); } 
#endif
# 273 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_store.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline void ThreadStore< STORE_CG, unsigned long long *, unsigned long long> (unsigned long long *ptr, unsigned long long val) {int volatile ___ = 1;(void)ptr;(void)val;::exit(___);}
#if 0
# 273
{ __asm__ volatile("st.global.u64 [%0], %1;" : : "l" (ptr), "l" (val)); } 
#endif
# 273 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_store.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline void ThreadStore< STORE_CG, unsigned *, unsigned> (unsigned *ptr, unsigned val) {int volatile ___ = 1;(void)ptr;(void)val;::exit(___);}
#if 0
# 273
{ __asm__ volatile("st.global.u32 [%0], %1;" : : "l" (ptr), "r" (val)); } 
#endif
# 273 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_store.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline void ThreadStore< STORE_CG, unsigned short *, unsigned short> (unsigned short *ptr, unsigned short val) {int volatile ___ = 1;(void)ptr;(void)val;::exit(___);}
#if 0
# 273
{ __asm__ volatile("st.global.u16 [%0], %1;" : : "l" (ptr), "h" (val)); } 
#endif
# 273 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_store.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline void ThreadStore< STORE_CG, unsigned char *, unsigned char> (unsigned char *ptr, unsigned char val) {int volatile ___ = 1;(void)ptr;(void)val;::exit(___);}
#if 0
# 273
{ __asm__ volatile("{   .reg .u8 datum;   cvt.u8.u16 datum, %1;   st.global.u8 [%0], datum;}" : : "l" (ptr), "h" ((unsigned short)val)); } 
#endif
# 274 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_store.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline void ThreadStore< STORE_CS, uint4 *, uint4> (uint4 *ptr, uint4 val) {int volatile ___ = 1;(void)ptr;(void)val;::exit(___);}
#if 0
# 274
{ __asm__ volatile("st.global.v4.u32 [%0], {%1, %2, %3, %4};" : : "l" (ptr), "r" (val.x), "r" (val.y), "r" (val.z), "r" (val.w)); } 
#endif
# 274 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_store.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline void ThreadStore< STORE_CS, ulonglong2 *, ulonglong2> (ulonglong2 *ptr, ulonglong2 val) {int volatile ___ = 1;(void)ptr;(void)val;::exit(___);}
#if 0
# 274
{ __asm__ volatile("st.global.v2.u64 [%0], {%1, %2};" : : "l" (ptr), "l" (val.x), "l" (val.y)); } 
#endif
# 274 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_store.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline void ThreadStore< STORE_CS, ushort4 *, ushort4> (ushort4 *ptr, ushort4 val) {int volatile ___ = 1;(void)ptr;(void)val;::exit(___);}
#if 0
# 274
{ __asm__ volatile("st.global.v4.u16 [%0], {%1, %2, %3, %4};" : : "l" (ptr), "h" (val.x), "h" (val.y), "h" (val.z), "h" (val.w)); } 
#endif
# 274 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_store.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline void ThreadStore< STORE_CS, uint2 *, uint2> (uint2 *ptr, uint2 val) {int volatile ___ = 1;(void)ptr;(void)val;::exit(___);}
#if 0
# 274
{ __asm__ volatile("st.global.v2.u32 [%0], {%1, %2};" : : "l" (ptr), "r" (val.x), "r" (val.y)); } 
#endif
# 274 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_store.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline void ThreadStore< STORE_CS, unsigned long long *, unsigned long long> (unsigned long long *ptr, unsigned long long val) {int volatile ___ = 1;(void)ptr;(void)val;::exit(___);}
#if 0
# 274
{ __asm__ volatile("st.global.u64 [%0], %1;" : : "l" (ptr), "l" (val)); } 
#endif
# 274 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_store.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline void ThreadStore< STORE_CS, unsigned *, unsigned> (unsigned *ptr, unsigned val) {int volatile ___ = 1;(void)ptr;(void)val;::exit(___);}
#if 0
# 274
{ __asm__ volatile("st.global.u32 [%0], %1;" : : "l" (ptr), "r" (val)); } 
#endif
# 274 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_store.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline void ThreadStore< STORE_CS, unsigned short *, unsigned short> (unsigned short *ptr, unsigned short val) {int volatile ___ = 1;(void)ptr;(void)val;::exit(___);}
#if 0
# 274
{ __asm__ volatile("st.global.u16 [%0], %1;" : : "l" (ptr), "h" (val)); } 
#endif
# 274 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_store.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline void ThreadStore< STORE_CS, unsigned char *, unsigned char> (unsigned char *ptr, unsigned char val) {int volatile ___ = 1;(void)ptr;(void)val;::exit(___);}
#if 0
# 274
{ __asm__ volatile("{   .reg .u8 datum;   cvt.u8.u16 datum, %1;   st.global.u8 [%0], datum;}" : : "l" (ptr), "h" ((unsigned short)val)); } 
#endif
# 275 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_store.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline void ThreadStore< STORE_WT, uint4 *, uint4> (uint4 *ptr, uint4 val) {int volatile ___ = 1;(void)ptr;(void)val;::exit(___);}
#if 0
# 275
{ __asm__ volatile("st.volatile.global.v4.u32 [%0], {%1, %2, %3, %4};" : : "l" (ptr), "r" (val.x), "r" (val.y), "r" (val.z), "r" (val.w)); } 
#endif
# 275 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_store.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline void ThreadStore< STORE_WT, ulonglong2 *, ulonglong2> (ulonglong2 *ptr, ulonglong2 val) {int volatile ___ = 1;(void)ptr;(void)val;::exit(___);}
#if 0
# 275
{ __asm__ volatile("st.volatile.global.v2.u64 [%0], {%1, %2};" : : "l" (ptr), "l" (val.x), "l" (val.y)); } 
#endif
# 275 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_store.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline void ThreadStore< STORE_WT, ushort4 *, ushort4> (ushort4 *ptr, ushort4 val) {int volatile ___ = 1;(void)ptr;(void)val;::exit(___);}
#if 0
# 275
{ __asm__ volatile("st.volatile.global.v4.u16 [%0], {%1, %2, %3, %4};" : : "l" (ptr), "h" (val.x), "h" (val.y), "h" (val.z), "h" (val.w)); } 
#endif
# 275 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_store.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline void ThreadStore< STORE_WT, uint2 *, uint2> (uint2 *ptr, uint2 val) {int volatile ___ = 1;(void)ptr;(void)val;::exit(___);}
#if 0
# 275
{ __asm__ volatile("st.volatile.global.v2.u32 [%0], {%1, %2};" : : "l" (ptr), "r" (val.x), "r" (val.y)); } 
#endif
# 275 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_store.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline void ThreadStore< STORE_WT, unsigned long long *, unsigned long long> (unsigned long long *ptr, unsigned long long val) {int volatile ___ = 1;(void)ptr;(void)val;::exit(___);}
#if 0
# 275
{ __asm__ volatile("st.volatile.global.u64 [%0], %1;" : : "l" (ptr), "l" (val)); } 
#endif
# 275 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_store.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline void ThreadStore< STORE_WT, unsigned *, unsigned> (unsigned *ptr, unsigned val) {int volatile ___ = 1;(void)ptr;(void)val;::exit(___);}
#if 0
# 275
{ __asm__ volatile("st.volatile.global.u32 [%0], %1;" : : "l" (ptr), "r" (val)); } 
#endif
# 275 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_store.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline void ThreadStore< STORE_WT, unsigned short *, unsigned short> (unsigned short *ptr, unsigned short val) {int volatile ___ = 1;(void)ptr;(void)val;::exit(___);}
#if 0
# 275
{ __asm__ volatile("st.volatile.global.u16 [%0], %1;" : : "l" (ptr), "h" (val)); } 
#endif
# 275 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_store.cuh"
template<> __attribute((always_inline)) __attribute__((unused)) inline void ThreadStore< STORE_WT, unsigned char *, unsigned char> (unsigned char *ptr, unsigned char val) {int volatile ___ = 1;(void)ptr;(void)val;::exit(___);}
#if 0
# 275
{ __asm__ volatile("{   .reg .u8 datum;   cvt.u8.u16 datum, %1;   st.volatile.global.u8 [%0], datum;}" : : "l" (ptr), "h" ((unsigned short)val)); } 
#endif
# 282 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_store.cuh"
template< class OutputIterator, class T> 
# 283
__attribute((always_inline)) __attribute__((unused)) inline void ThreadStore(OutputIterator 
# 284
itr, T 
# 285
val, Int2Type< 0>  
# 286
modifier, Int2Type< 0>  
# 287
is_pointer) 
# 288
{int volatile ___ = 1;(void)itr;(void)val;(void)modifier;(void)is_pointer;
# 290
::exit(___);}
#if 0
# 288
{ 
# 289
(*itr) = val; 
# 290
} 
#endif
# 296 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_store.cuh"
template< class T> 
# 297
__attribute((always_inline)) __attribute__((unused)) inline void ThreadStore(T *
# 298
ptr, T 
# 299
val, Int2Type< 0>  
# 300
modifier, Int2Type< 1>  
# 301
is_pointer) 
# 302
{int volatile ___ = 1;(void)ptr;(void)val;(void)modifier;(void)is_pointer;
# 304
::exit(___);}
#if 0
# 302
{ 
# 303
(*ptr) = val; 
# 304
} 
#endif
# 310 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_store.cuh"
template< class T> 
# 311
__attribute((always_inline)) __attribute__((unused)) inline void ThreadStoreVolatilePtr(T *
# 312
ptr, T 
# 313
val, Int2Type< 1>  
# 314
is_primitive) 
# 315
{int volatile ___ = 1;(void)ptr;(void)val;(void)is_primitive;
# 317
::exit(___);}
#if 0
# 315
{ 
# 316
(*(reinterpret_cast< volatile T *>(ptr))) = val; 
# 317
} 
#endif
# 323 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_store.cuh"
template< class T> 
# 324
__attribute((always_inline)) __attribute__((unused)) inline void ThreadStoreVolatilePtr(T *
# 325
ptr, T 
# 326
val, Int2Type< 0>  
# 327
is_primitive) 
# 328
{int volatile ___ = 1;(void)ptr;(void)val;(void)is_primitive;
# 351
::exit(___);}
#if 0
# 328
{ 
# 331
(*ptr) = val; 
# 332
__threadfence_block(); 
# 351
} 
#endif
# 357 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_store.cuh"
template< class T> 
# 358
__attribute((always_inline)) __attribute__((unused)) inline void ThreadStore(T *
# 359
ptr, T 
# 360
val, Int2Type< STORE_VOLATILE>  
# 361
modifier, Int2Type< 1>  
# 362
is_pointer) 
# 363
{int volatile ___ = 1;(void)ptr;(void)val;(void)modifier;(void)is_pointer;
# 365
::exit(___);}
#if 0
# 363
{ 
# 364
ThreadStoreVolatilePtr(ptr, val, Int2Type< Traits< T> ::PRIMITIVE> ()); 
# 365
} 
#endif
# 371 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_store.cuh"
template< class T, int MODIFIER> 
# 372
__attribute((always_inline)) __attribute__((unused)) inline void ThreadStore(T *
# 373
ptr, T 
# 374
val, Int2Type< MODIFIER>  
# 375
modifier, Int2Type< 1>  
# 376
is_pointer) 
# 377
{int volatile ___ = 1;(void)ptr;(void)val;(void)modifier;(void)is_pointer;
# 389
::exit(___);}
#if 0
# 377
{ 
# 378
typedef typename UnitWord< T> ::DeviceWord DeviceWord; 
# 380
const int DEVICE_MULTIPLE = (sizeof(T) / sizeof(DeviceWord)); 
# 382
DeviceWord words[DEVICE_MULTIPLE]; 
# 384
(*(reinterpret_cast< T *>(words))) = val; 
# 386
IterateThreadStore< 0, DEVICE_MULTIPLE> ::template Store< (CacheStoreModifier)MODIFIER> (reinterpret_cast< DeviceWord *>(ptr), words); 
# 389
} 
#endif
# 395 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_store.cuh"
template< CacheStoreModifier MODIFIER, class OutputIterator, class T> 
# 396
__attribute((always_inline)) __attribute__((unused)) inline void ThreadStore(OutputIterator itr, T val) 
# 397
{int volatile ___ = 1;(void)itr;(void)val;
# 403
::exit(___);}
#if 0
# 397
{ 
# 398
ThreadStore(itr, val, Int2Type< MODIFIER> (), Int2Type< IsPointer< OutputIterator> ::VALUE> ()); 
# 403
} 
#endif
# 413 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/../../thread/thread_store.cuh"
}
# 414
}}}}
# 43 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/warp_scan_smem.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 46
namespace cub_ { 
# 51
template< class 
# 52
T, int 
# 53
LOGICAL_WARP_THREADS, int 
# 54
PTX_ARCH> 
# 55
struct WarpScanSmem { 
# 62
enum { 
# 64
IS_ARCH_WARP = LOGICAL_WARP_THREADS == (1 << 5), 
# 67
STEPS = Log2< LOGICAL_WARP_THREADS> ::VALUE, 
# 70
HALF_WARP_THREADS = 1 << ((Log2< LOGICAL_WARP_THREADS> ::VALUE) - 1), 
# 73
WARP_SMEM_ELEMENTS = LOGICAL_WARP_THREADS + (1 << ((Log2< LOGICAL_WARP_THREADS> ::VALUE) - 1)), 
# 76
IS_INTEGER = (Traits< T> ::CATEGORY == UNSIGNED_INTEGER) || (Traits< T> ::CATEGORY == SIGNED_INTEGER)
# 78
}; 
# 81
typedef typename If< (Equals< T, char> ::VALUE || Equals< T, signed char> ::VALUE) && (PTX_ARCH < 200), int, T> ::Type CellT; 
# 84
typedef CellT _TempStorage[WARP_SMEM_ELEMENTS]; 
# 87
struct TempStorage : public Uninitialized< typename If< (Equals< T, char> ::VALUE || Equals< T, signed char> ::VALUE) && (PTX_ARCH < 200), int, T> ::Type [WARP_SMEM_ELEMENTS]>  { }; 
# 94
_TempStorage &temp_storage; 
# 95
unsigned lane_id; 
# 103
__attribute((always_inline)) WarpScanSmem(TempStorage &
# 104
temp_storage) : temp_storage((temp_storage.Alias())), lane_id((IS_ARCH_WARP) ? LaneId() : (LaneId() % (LOGICAL_WARP_THREADS))) 
# 110
{int *volatile ___ = 0;(void)temp_storage;::free(___);}
#if 0
# 110
{ } 
#endif
# 118 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/warp_scan_smem.cuh"
template< bool 
# 119
HAS_IDENTITY, int 
# 120
STEP, class 
# 121
ScanOp> 
# 122
__attribute((always_inline)) void ScanStep(T &
# 123
partial, ScanOp 
# 124
scan_op, Int2Type< STEP>  
# 125
step) 
# 126
{int volatile ___ = 1;(void)partial;(void)scan_op;(void)step;
# 140
::exit(___);}
#if 0
# 126
{ 
# 127
const int OFFSET = (1 << STEP); 
# 130
ThreadStore< STORE_VOLATILE> (&((temp_storage)[(HALF_WARP_THREADS) + (lane_id)]), (CellT)partial); 
# 133
if (HAS_IDENTITY || ((lane_id) >= OFFSET)) 
# 134
{ 
# 135
T addend = (T)ThreadLoad< LOAD_VOLATILE> (&((temp_storage)[((HALF_WARP_THREADS) + (lane_id)) - OFFSET])); 
# 136
partial = scan_op(addend, partial); 
# 137
}  
# 139
ScanStep< HAS_IDENTITY> (partial, scan_op, Int2Type< STEP + 1> ()); 
# 140
} 
#endif
# 144 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/warp_scan_smem.cuh"
template< bool 
# 145
HAS_IDENTITY, class 
# 146
ScanOp> 
# 147
__attribute((always_inline)) void ScanStep(T &
# 148
partial, ScanOp 
# 149
scan_op, Int2Type< STEPS>  
# 150
step) 
# 151
{int volatile ___ = 1;(void)partial;(void)scan_op;(void)step;::exit(___);}
#if 0
# 151
{ } 
#endif
# 155 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/warp_scan_smem.cuh"
template< class ScanOp> 
# 156
__attribute((always_inline)) void InclusiveScan(T 
# 157
input, T &
# 158
output, T 
# 159
identity, ScanOp 
# 160
scan_op) 
# 161
{int volatile ___ = 1;(void)input;(void)output;(void)identity;(void)scan_op;
# 167
::exit(___);}
#if 0
# 161
{ 
# 162
ThreadStore< STORE_VOLATILE> (&((temp_storage)[lane_id]), (CellT)identity); 
# 165
output = input; 
# 166
ScanStep< true> (output, scan_op, Int2Type< 0> ()); 
# 167
} 
#endif
# 171 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/warp_scan_smem.cuh"
__attribute((always_inline)) void InclusiveScan(T 
# 172
input, T &
# 173
output, Sum 
# 174
scan_op, Int2Type< 1>  
# 175
is_primitive) 
# 176
{int volatile ___ = 1;(void)input;(void)output;(void)scan_op;(void)is_primitive;
# 179
::exit(___);}
#if 0
# 176
{ 
# 177
T identity = ZeroInitialize< T> (); 
# 178
InclusiveScan(input, output, identity, scan_op); 
# 179
} 
#endif
# 183 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/warp_scan_smem.cuh"
template< class ScanOp, int IS_PRIMITIVE> 
# 184
__attribute((always_inline)) void InclusiveScan(T 
# 185
input, T &
# 186
output, ScanOp 
# 187
scan_op, Int2Type< IS_PRIMITIVE>  
# 188
is_primitive) 
# 189
{int volatile ___ = 1;(void)input;(void)output;(void)scan_op;(void)is_primitive;
# 193
::exit(___);}
#if 0
# 189
{ 
# 191
output = input; 
# 192
ScanStep< false> (output, scan_op, Int2Type< 0> ()); 
# 193
} 
#endif
# 197 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/warp_scan_smem.cuh"
__attribute((always_inline)) T GetExclusive(T 
# 198
input, T 
# 199
inclusive, Sum 
# 200
scan_op, Int2Type< 1>  
# 201
is_integer) 
# 202
{int volatile ___ = 1;(void)input;(void)inclusive;(void)scan_op;(void)is_integer;
# 204
::exit(___);}
#if 0
# 202
{ 
# 203
return inclusive - input; 
# 204
} 
#endif
# 208 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/warp_scan_smem.cuh"
template< class ScanOp, int _IS_INTEGER> 
# 209
__attribute((always_inline)) T GetExclusive(T 
# 210
input, T 
# 211
inclusive, ScanOp 
# 212
scan_op, Int2Type< _IS_INTEGER>  
# 213
is_integer) 
# 214
{int volatile ___ = 1;(void)input;(void)inclusive;(void)scan_op;(void)is_integer;
# 217
::exit(___);}
#if 0
# 214
{ 
# 215
ThreadStore< STORE_VOLATILE> (&((temp_storage)[(HALF_WARP_THREADS) + (lane_id)]), (CellT)inclusive); 
# 216
return (T)ThreadLoad< LOAD_VOLATILE> (&((temp_storage)[((HALF_WARP_THREADS) + (lane_id)) - 1])); 
# 217
} 
#endif
# 221 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/warp_scan_smem.cuh"
__attribute((always_inline)) T GetExclusive(T 
# 222
input, T 
# 223
inclusive, Sum 
# 224
scan_op, T &
# 225
warp_aggregate, Int2Type< 1>  
# 226
is_integer) 
# 227
{int volatile ___ = 1;(void)input;(void)inclusive;(void)scan_op;(void)warp_aggregate;(void)is_integer;
# 232
::exit(___);}
#if 0
# 227
{ 
# 228
ThreadStore< STORE_VOLATILE> (&((temp_storage)[(HALF_WARP_THREADS) + (lane_id)]), (CellT)inclusive); 
# 229
warp_aggregate = ((T)ThreadLoad< LOAD_VOLATILE> (&((temp_storage)[(WARP_SMEM_ELEMENTS) - 1]))); 
# 231
return inclusive - input; 
# 232
} 
#endif
# 236 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/warp_scan_smem.cuh"
template< class ScanOp, int _IS_INTEGER> 
# 237
__attribute((always_inline)) T GetExclusive(T 
# 238
input, T 
# 239
inclusive, ScanOp 
# 240
scan_op, T &
# 241
warp_aggregate, Int2Type< _IS_INTEGER>  
# 242
is_integer) 
# 243
{int volatile ___ = 1;(void)input;(void)inclusive;(void)scan_op;(void)warp_aggregate;(void)is_integer;
# 248
::exit(___);}
#if 0
# 243
{ 
# 244
ThreadStore< STORE_VOLATILE> (&((temp_storage)[(HALF_WARP_THREADS) + (lane_id)]), (CellT)inclusive); 
# 245
warp_aggregate = ((T)ThreadLoad< LOAD_VOLATILE> (&((temp_storage)[(WARP_SMEM_ELEMENTS) - 1]))); 
# 247
return (T)ThreadLoad< LOAD_VOLATILE> (&((temp_storage)[((HALF_WARP_THREADS) + (lane_id)) - 1])); 
# 248
} 
#endif
# 256 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/warp_scan_smem.cuh"
__attribute((always_inline)) T Broadcast(T 
# 257
input, unsigned 
# 258
src_lane) 
# 259
{int volatile ___ = 1;(void)input;(void)src_lane;
# 266
::exit(___);}
#if 0
# 259
{ 
# 260
if ((lane_id) == src_lane) 
# 261
{ 
# 262
ThreadStore< STORE_VOLATILE> (temp_storage, (CellT)input); 
# 263
}  
# 265
return (T)ThreadLoad< LOAD_VOLATILE> (temp_storage); 
# 266
} 
#endif
# 274 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/warp_scan_smem.cuh"
template< class ScanOp> 
# 275
__attribute((always_inline)) void InclusiveScan(T 
# 276
input, T &
# 277
output, ScanOp 
# 278
scan_op) 
# 279
{int volatile ___ = 1;(void)input;(void)output;(void)scan_op;
# 280
::exit(___);}
#if 0
# 279
{ 
# 280
InclusiveScan(input, output, scan_op, Int2Type< Traits< T> ::PRIMITIVE> ()); } 
#endif
# 284 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/warp_scan_smem.cuh"
template< class ScanOp> 
# 285
__attribute((always_inline)) void InclusiveScan(T 
# 286
input, T &
# 287
output, ScanOp 
# 288
scan_op, T &
# 289
warp_aggregate) 
# 290
{int volatile ___ = 1;(void)input;(void)output;(void)scan_op;(void)warp_aggregate;
# 296
::exit(___);}
#if 0
# 290
{ 
# 291
InclusiveScan(input, output, scan_op); 
# 294
ThreadStore< STORE_VOLATILE> (&((temp_storage)[(HALF_WARP_THREADS) + (lane_id)]), (CellT)output); 
# 295
warp_aggregate = ((T)ThreadLoad< LOAD_VOLATILE> (&((temp_storage)[(WARP_SMEM_ELEMENTS) - 1]))); 
# 296
} 
#endif
# 304 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/warp_scan_smem.cuh"
template< class ScanOp> 
# 305
__attribute((always_inline)) void Scan(T 
# 306
input, T &
# 307
inclusive_output, T &
# 308
exclusive_output, ScanOp 
# 309
scan_op) 
# 310
{int volatile ___ = 1;(void)input;(void)inclusive_output;(void)exclusive_output;(void)scan_op;
# 316
::exit(___);}
#if 0
# 310
{ 
# 312
InclusiveScan(input, inclusive_output, scan_op); 
# 315
exclusive_output = GetExclusive(input, inclusive_output, scan_op, Int2Type< IS_INTEGER> ()); 
# 316
} 
#endif
# 319 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/warp_scan_smem.cuh"
template< class ScanOp> 
# 320
__attribute((always_inline)) void Scan(T 
# 321
input, T &
# 322
inclusive_output, T &
# 323
exclusive_output, T 
# 324
identity, ScanOp 
# 325
scan_op) 
# 326
{int volatile ___ = 1;(void)input;(void)inclusive_output;(void)exclusive_output;(void)identity;(void)scan_op;
# 332
::exit(___);}
#if 0
# 326
{ 
# 328
InclusiveScan(input, inclusive_output, identity, scan_op); 
# 331
exclusive_output = GetExclusive(input, inclusive_output, scan_op, Int2Type< IS_INTEGER> ()); 
# 332
} 
#endif
# 340 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/warp_scan_smem.cuh"
template< class ScanOp> 
# 341
__attribute((always_inline)) void ExclusiveScan(T 
# 342
input, T &
# 343
output, T 
# 344
identity, ScanOp 
# 345
scan_op) 
# 346
{int volatile ___ = 1;(void)input;(void)output;(void)identity;(void)scan_op;
# 349
::exit(___);}
#if 0
# 346
{ 
# 347
T inclusive_output; 
# 348
Scan(input, inclusive_output, output, identity, scan_op); 
# 349
} 
#endif
# 353 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/warp_scan_smem.cuh"
template< class ScanOp> 
# 354
__attribute((always_inline)) void ExclusiveScan(T 
# 355
input, T &
# 356
output, ScanOp 
# 357
scan_op) 
# 358
{int volatile ___ = 1;(void)input;(void)output;(void)scan_op;
# 361
::exit(___);}
#if 0
# 358
{ 
# 359
T inclusive_output; 
# 360
Scan(input, inclusive_output, output, scan_op); 
# 361
} 
#endif
# 364 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/warp_scan_smem.cuh"
template< class ScanOp> 
# 365
__attribute((always_inline)) void ExclusiveScan(T 
# 366
input, T &
# 367
output, T 
# 368
identity, ScanOp 
# 369
scan_op, T &
# 370
warp_aggregate) 
# 371
{int volatile ___ = 1;(void)input;(void)output;(void)identity;(void)scan_op;(void)warp_aggregate;
# 378
::exit(___);}
#if 0
# 371
{ 
# 373
T inclusive_output; 
# 374
InclusiveScan(input, inclusive_output, identity, scan_op); 
# 377
output = GetExclusive(input, inclusive_output, scan_op, warp_aggregate, Int2Type< IS_INTEGER> ()); 
# 378
} 
#endif
# 382 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/warp_scan_smem.cuh"
template< class ScanOp> 
# 383
__attribute((always_inline)) void ExclusiveScan(T 
# 384
input, T &
# 385
output, ScanOp 
# 386
scan_op, T &
# 387
warp_aggregate) 
# 388
{int volatile ___ = 1;(void)input;(void)output;(void)scan_op;(void)warp_aggregate;
# 395
::exit(___);}
#if 0
# 388
{ 
# 390
T inclusive_output; 
# 391
InclusiveScan(input, inclusive_output, scan_op); 
# 394
output = GetExclusive(input, inclusive_output, scan_op, warp_aggregate, Int2Type< IS_INTEGER> ()); 
# 395
} 
#endif
# 398 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/specializations/warp_scan_smem.cuh"
}; 
# 401
}
# 402
}}}}
# 44 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/warp_scan.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 47
namespace cub_ { 
# 142
template< class 
# 143
T, int 
# 144
LOGICAL_WARP_THREADS = 32, int 
# 145
PTX_ARCH = 0> 
# 146
class WarpScan { 
# 155
enum { 
# 157
IS_ARCH_WARP = LOGICAL_WARP_THREADS == (1 << 5), 
# 160
IS_POW_OF_TWO = (LOGICAL_WARP_THREADS & (LOGICAL_WARP_THREADS - 1)) == 0, 
# 163
IS_INTEGER = (Traits< T> ::CATEGORY == SIGNED_INTEGER) || (Traits< T> ::CATEGORY == UNSIGNED_INTEGER)
# 164
}; 
# 169
typedef typename If< (PTX_ARCH >= 300) && (IS_POW_OF_TWO), WarpScanShfl< T, LOGICAL_WARP_THREADS, PTX_ARCH> , WarpScanSmem< T, LOGICAL_WARP_THREADS, PTX_ARCH> > ::Type InternalWarpScan; 
# 172
typedef typename If< (PTX_ARCH >= 300) && (IS_POW_OF_TWO), WarpScanShfl< T, LOGICAL_WARP_THREADS, PTX_ARCH> , WarpScanSmem< T, LOGICAL_WARP_THREADS, PTX_ARCH> > ::Type::TempStorage _TempStorage; 
# 180
_TempStorage &temp_storage; 
# 181
int lane_id; 
# 192
public: struct TempStorage : public Uninitialized< typename If< (PTX_ARCH >= 300) && (IS_POW_OF_TWO), WarpScanShfl< T, LOGICAL_WARP_THREADS, PTX_ARCH> , WarpScanSmem< T, LOGICAL_WARP_THREADS, PTX_ARCH> > ::Type::TempStorage>  { }; 
# 203
__attribute((always_inline)) WarpScan(TempStorage &
# 204
temp_storage) : temp_storage((temp_storage.Alias())), lane_id((IS_ARCH_WARP) ? LaneId() : (LaneId() % (LOGICAL_WARP_THREADS))) 
# 210
{int *volatile ___ = 0;(void)temp_storage;::free(___);}
#if 0
# 210
{ } 
#endif
# 254 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/warp_scan.cuh"
__attribute((always_inline)) void InclusiveSum(T 
# 255
input, T &
# 256
output) 
# 257
{int volatile ___ = 1;(void)input;(void)output;
# 259
::exit(___);}
#if 0
# 257
{ 
# 258
(((InternalWarpScan)(temp_storage)).InclusiveScan(input, output, cub_::Sum())); 
# 259
} 
#endif
# 297 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/warp_scan.cuh"
__attribute((always_inline)) void InclusiveSum(T 
# 298
input, T &
# 299
output, T &
# 300
warp_aggregate) 
# 301
{int volatile ___ = 1;(void)input;(void)output;(void)warp_aggregate;
# 303
::exit(___);}
#if 0
# 301
{ 
# 302
(((InternalWarpScan)(temp_storage)).InclusiveScan(input, output, cub_::Sum(), warp_aggregate)); 
# 303
} 
#endif
# 349 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/warp_scan.cuh"
__attribute((always_inline)) void ExclusiveSum(T 
# 350
input, T &
# 351
output) 
# 352
{int volatile ___ = 1;(void)input;(void)output;
# 354
::exit(___);}
#if 0
# 352
{ 
# 353
(((InternalWarpScan)(temp_storage)).ExclusiveScan(input, output, ZeroInitialize< T> (), cub_::Sum())); 
# 354
} 
#endif
# 393 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/warp_scan.cuh"
__attribute((always_inline)) void ExclusiveSum(T 
# 394
input, T &
# 395
output, T &
# 396
warp_aggregate) 
# 397
{int volatile ___ = 1;(void)input;(void)output;(void)warp_aggregate;
# 399
::exit(___);}
#if 0
# 397
{ 
# 398
(((InternalWarpScan)(temp_storage)).ExclusiveScan(input, output, ZeroInitialize< T> (), cub_::Sum(), warp_aggregate)); 
# 399
} 
#endif
# 444 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/warp_scan.cuh"
template< class ScanOp> 
# 445
__attribute((always_inline)) void InclusiveScan(T 
# 446
input, T &
# 447
output, ScanOp 
# 448
scan_op) 
# 449
{int volatile ___ = 1;(void)input;(void)output;(void)scan_op;
# 451
::exit(___);}
#if 0
# 449
{ 
# 450
(((InternalWarpScan)(temp_storage)).InclusiveScan(input, output, scan_op)); 
# 451
} 
#endif
# 494 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/warp_scan.cuh"
template< class ScanOp> 
# 495
__attribute((always_inline)) void InclusiveScan(T 
# 496
input, T &
# 497
output, ScanOp 
# 498
scan_op, T &
# 499
warp_aggregate) 
# 500
{int volatile ___ = 1;(void)input;(void)output;(void)scan_op;(void)warp_aggregate;
# 502
::exit(___);}
#if 0
# 500
{ 
# 501
(((InternalWarpScan)(temp_storage)).InclusiveScan(input, output, scan_op, warp_aggregate)); 
# 502
} 
#endif
# 547 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/warp_scan.cuh"
template< class ScanOp> 
# 548
__attribute((always_inline)) void ExclusiveScan(T 
# 549
input, T &
# 550
output, T 
# 551
identity, ScanOp 
# 552
scan_op) 
# 553
{int volatile ___ = 1;(void)input;(void)output;(void)identity;(void)scan_op;
# 555
::exit(___);}
#if 0
# 553
{ 
# 554
(((InternalWarpScan)(temp_storage)).ExclusiveScan(input, output, identity, scan_op)); 
# 555
} 
#endif
# 597 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/warp_scan.cuh"
template< class ScanOp> 
# 598
__attribute((always_inline)) void ExclusiveScan(T 
# 599
input, T &
# 600
output, T 
# 601
identity, ScanOp 
# 602
scan_op, T &
# 603
warp_aggregate) 
# 604
{int volatile ___ = 1;(void)input;(void)output;(void)identity;(void)scan_op;(void)warp_aggregate;
# 606
::exit(___);}
#if 0
# 604
{ 
# 605
(((InternalWarpScan)(temp_storage)).ExclusiveScan(input, output, identity, scan_op, warp_aggregate)); 
# 606
} 
#endif
# 653 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/warp_scan.cuh"
template< class ScanOp> 
# 654
__attribute((always_inline)) void ExclusiveScan(T 
# 655
input, T &
# 656
output, ScanOp 
# 657
scan_op) 
# 658
{int volatile ___ = 1;(void)input;(void)output;(void)scan_op;
# 660
::exit(___);}
#if 0
# 658
{ 
# 659
(((InternalWarpScan)(temp_storage)).ExclusiveScan(input, output, scan_op)); 
# 660
} 
#endif
# 702 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/warp_scan.cuh"
template< class ScanOp> 
# 703
__attribute((always_inline)) void ExclusiveScan(T 
# 704
input, T &
# 705
output, ScanOp 
# 706
scan_op, T &
# 707
warp_aggregate) 
# 708
{int volatile ___ = 1;(void)input;(void)output;(void)scan_op;(void)warp_aggregate;
# 710
::exit(___);}
#if 0
# 708
{ 
# 709
(((InternalWarpScan)(temp_storage)).ExclusiveScan(input, output, scan_op, warp_aggregate)); 
# 710
} 
#endif
# 759 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/warp_scan.cuh"
__attribute((always_inline)) void Sum(T 
# 760
input, T &
# 761
inclusive_output, T &
# 762
exclusive_output) 
# 763
{int volatile ___ = 1;(void)input;(void)inclusive_output;(void)exclusive_output;
# 765
::exit(___);}
#if 0
# 763
{ 
# 764
(((InternalWarpScan)(temp_storage)).Scan(input, inclusive_output, exclusive_output, ZeroInitialize< T> (), cub_::Sum())); 
# 765
} 
#endif
# 807 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/warp_scan.cuh"
template< class ScanOp> 
# 808
__attribute((always_inline)) void Scan(T 
# 809
input, T &
# 810
inclusive_output, T &
# 811
exclusive_output, T 
# 812
identity, ScanOp 
# 813
scan_op) 
# 814
{int volatile ___ = 1;(void)input;(void)inclusive_output;(void)exclusive_output;(void)identity;(void)scan_op;
# 816
::exit(___);}
#if 0
# 814
{ 
# 815
(((InternalWarpScan)(temp_storage)).Scan(input, inclusive_output, exclusive_output, identity, scan_op)); 
# 816
} 
#endif
# 858 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/warp_scan.cuh"
template< class ScanOp> 
# 859
__attribute((always_inline)) void Scan(T 
# 860
input, T &
# 861
inclusive_output, T &
# 862
exclusive_output, ScanOp 
# 863
scan_op) 
# 864
{int volatile ___ = 1;(void)input;(void)inclusive_output;(void)exclusive_output;(void)scan_op;
# 866
::exit(___);}
#if 0
# 864
{ 
# 865
(((InternalWarpScan)(temp_storage)).Scan(input, inclusive_output, exclusive_output, scan_op)); 
# 866
} 
#endif
# 910 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/warp_scan.cuh"
__attribute((always_inline)) T Broadcast(T 
# 911
input, unsigned 
# 912
src_lane) 
# 913
{int volatile ___ = 1;(void)input;(void)src_lane;
# 915
::exit(___);}
#if 0
# 913
{ 
# 914
return (((InternalWarpScan)(temp_storage)).Broadcast(input, src_lane)); 
# 915
} 
#endif
# 919 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/../../warp/warp_scan.cuh"
}; 
# 923
}
# 924
}}}}
# 46 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/block_scan_raking.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 49
namespace cub_ { 
# 55
template< class 
# 56
T, int 
# 57
BLOCK_DIM_X, int 
# 58
BLOCK_DIM_Y, int 
# 59
BLOCK_DIM_Z, bool 
# 60
MEMOIZE, int 
# 61
PTX_ARCH> 
# 62
struct BlockScanRaking { 
# 70
enum { 
# 72
BLOCK_THREADS = (BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z
# 73
}; 
# 76
typedef cub_::BlockRakingLayout< T, BLOCK_THREADS, PTX_ARCH>  BlockRakingLayout; 
# 80
enum { 
# 82
RAKING_THREADS = cub_::BlockRakingLayout< T, (BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z, PTX_ARCH> ::RAKING_THREADS, 
# 85
SEGMENT_LENGTH = cub_::BlockRakingLayout< T, (BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z, PTX_ARCH> ::SEGMENT_LENGTH, 
# 88
WARP_SYNCHRONOUS = ((BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z) == (cub_::BlockRakingLayout< T, (BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z, PTX_ARCH> ::RAKING_THREADS)
# 89
}; 
# 92
typedef cub_::WarpScan< T, RAKING_THREADS, PTX_ARCH>  WarpScan; 
# 95
struct _TempStorage { 
# 97
typename cub_::WarpScan< T, RAKING_THREADS, PTX_ARCH> ::TempStorage warp_scan; 
# 98
typename cub_::BlockRakingLayout< T, BLOCK_THREADS, PTX_ARCH> ::TempStorage raking_grid; 
# 99
T block_aggregate; 
# 100
}; 
# 104
struct TempStorage : public Uninitialized< _TempStorage>  { }; 
# 112
_TempStorage &temp_storage; 
# 113
int linear_tid; 
# 114
T cached_segment[SEGMENT_LENGTH]; 
# 122
template< int ITERATION, class ScanOp> 
# 123
__attribute((always_inline)) T GuardedReduce(T *
# 124
raking_ptr, ScanOp 
# 125
scan_op, T 
# 126
raking_partial, Int2Type< ITERATION>  
# 127
iteration) 
# 128
{int volatile ___ = 1;(void)raking_ptr;(void)scan_op;(void)raking_partial;(void)iteration;
# 136
::exit(___);}
#if 0
# 128
{ 
# 129
if (BlockRakingLayout::UNGUARDED || ((((linear_tid) * (SEGMENT_LENGTH)) + ITERATION) < (BLOCK_THREADS))) 
# 130
{ 
# 131
T addend = raking_ptr[ITERATION]; 
# 132
raking_partial = scan_op(raking_partial, addend); 
# 133
}  
# 135
return GuardedReduce(raking_ptr, scan_op, raking_partial, Int2Type< ITERATION + 1> ()); 
# 136
} 
#endif
# 140 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/block_scan_raking.cuh"
template< class ScanOp> 
# 141
__attribute((always_inline)) T GuardedReduce(T *
# 142
raking_ptr, ScanOp 
# 143
scan_op, T 
# 144
raking_partial, Int2Type< SEGMENT_LENGTH>  
# 145
iteration) 
# 146
{int volatile ___ = 1;(void)raking_ptr;(void)scan_op;(void)raking_partial;(void)iteration;
# 148
::exit(___);}
#if 0
# 146
{ 
# 147
return raking_partial; 
# 148
} 
#endif
# 152 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/block_scan_raking.cuh"
template< int ITERATION> 
# 153
__attribute((always_inline)) void CopySegment(T *
# 154
out, T *
# 155
in, Int2Type< ITERATION>  
# 156
iteration) 
# 157
{int volatile ___ = 1;(void)out;(void)in;(void)iteration;
# 160
::exit(___);}
#if 0
# 157
{ 
# 158
(out[ITERATION]) = (in[ITERATION]); 
# 159
CopySegment(out, in, Int2Type< ITERATION + 1> ()); 
# 160
} 
#endif
# 164 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/block_scan_raking.cuh"
__attribute((always_inline)) void CopySegment(T *
# 165
out, T *
# 166
in, Int2Type< SEGMENT_LENGTH>  
# 167
iteration) 
# 168
{int volatile ___ = 1;(void)out;(void)in;(void)iteration;::exit(___);}
#if 0
# 168
{ } 
#endif
# 172 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/block_scan_raking.cuh"
template< class ScanOp> 
# 173
__attribute((always_inline)) T Upsweep(ScanOp 
# 174
scan_op) 
# 175
{int volatile ___ = 1;(void)scan_op;
# 184
::exit(___);}
#if 0
# 175
{ 
# 176
T *smem_raking_ptr = BlockRakingLayout::RakingPtr(((temp_storage).raking_grid), linear_tid); 
# 179
CopySegment(cached_segment, smem_raking_ptr, Int2Type< 0> ()); 
# 181
T raking_partial = (cached_segment)[0]; 
# 183
return GuardedReduce(cached_segment, scan_op, raking_partial, Int2Type< 1> ()); 
# 184
} 
#endif
# 188 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/block_scan_raking.cuh"
template< class ScanOp> 
# 189
__attribute((always_inline)) void ExclusiveDownsweep(ScanOp 
# 190
scan_op, T 
# 191
raking_partial, bool 
# 192
apply_prefix = true) 
# 193
{int volatile ___ = 1;(void)scan_op;(void)raking_partial;(void)apply_prefix;
# 206
::exit(___);}
#if 0
# 193
{ 
# 194
T *smem_raking_ptr = BlockRakingLayout::RakingPtr(((temp_storage).raking_grid), linear_tid); 
# 197
if (!MEMOIZE) 
# 198
{ 
# 199
CopySegment(cached_segment, smem_raking_ptr, Int2Type< 0> ()); 
# 200
}  
# 202
ThreadScanExclusive(cached_segment, cached_segment, scan_op, raking_partial, apply_prefix); 
# 205
CopySegment(smem_raking_ptr, cached_segment, Int2Type< 0> ()); 
# 206
} 
#endif
# 210 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/block_scan_raking.cuh"
template< class ScanOp> 
# 211
__attribute((always_inline)) void InclusiveDownsweep(ScanOp 
# 212
scan_op, T 
# 213
raking_partial, bool 
# 214
apply_prefix = true) 
# 215
{int volatile ___ = 1;(void)scan_op;(void)raking_partial;(void)apply_prefix;
# 228
::exit(___);}
#if 0
# 215
{ 
# 216
T *smem_raking_ptr = BlockRakingLayout::RakingPtr(((temp_storage).raking_grid), linear_tid); 
# 219
if (!MEMOIZE) 
# 220
{ 
# 221
CopySegment(cached_segment, smem_raking_ptr, Int2Type< 0> ()); 
# 222
}  
# 224
ThreadScanInclusive(cached_segment, cached_segment, scan_op, raking_partial, apply_prefix); 
# 227
CopySegment(smem_raking_ptr, cached_segment, Int2Type< 0> ()); 
# 228
} 
#endif
# 236 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/block_scan_raking.cuh"
__attribute((always_inline)) BlockScanRaking(TempStorage &
# 237
temp_storage) : temp_storage((temp_storage.Alias())), linear_tid(RowMajorTid(BLOCK_DIM_X, BLOCK_DIM_Y, BLOCK_DIM_Z)) 
# 241
{int *volatile ___ = 0;(void)temp_storage;::free(___);}
#if 0
# 241
{ } 
#endif
# 249 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/block_scan_raking.cuh"
template< class ScanOp> 
# 250
__attribute((always_inline)) void ExclusiveScan(T 
# 251
input, T &
# 252
output, const T &
# 253
identity, ScanOp 
# 254
scan_op) 
# 255
{int volatile ___ = 1;(void)input;(void)output;(void)identity;(void)scan_op;
# 288
::exit(___);}
#if 0
# 255
{ 
# 256
if (WARP_SYNCHRONOUS) 
# 257
{ 
# 259
(((WarpScan)(((temp_storage).warp_scan))).ExclusiveScan(input, output, identity, scan_op)); 
# 260
} else 
# 262
{ 
# 264
T *placement_ptr = BlockRakingLayout::PlacementPtr(((temp_storage).raking_grid), linear_tid); 
# 265
(*placement_ptr) = input; 
# 267
__syncthreads(); 
# 270
if ((linear_tid) < (RAKING_THREADS)) 
# 271
{ 
# 273
T upsweep_partial = Upsweep(scan_op); 
# 276
T exclusive_partial; 
# 277
(((WarpScan)(((temp_storage).warp_scan))).ExclusiveScan(upsweep_partial, exclusive_partial, identity, scan_op)); 
# 280
ExclusiveDownsweep(scan_op, exclusive_partial); 
# 281
}  
# 283
__syncthreads(); 
# 286
output = (*placement_ptr); 
# 287
}  
# 288
} 
#endif
# 292 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/block_scan_raking.cuh"
template< class ScanOp> 
# 293
__attribute((always_inline)) void ExclusiveScan(T 
# 294
input, T &
# 295
output, const T &
# 296
identity, ScanOp 
# 297
scan_op, T &
# 298
block_aggregate) 
# 299
{int volatile ___ = 1;(void)input;(void)output;(void)identity;(void)scan_op;(void)block_aggregate;
# 340
::exit(___);}
#if 0
# 299
{ 
# 300
if (WARP_SYNCHRONOUS) 
# 301
{ 
# 303
(((WarpScan)(((temp_storage).warp_scan))).ExclusiveScan(input, output, identity, scan_op, block_aggregate)); 
# 304
} else 
# 306
{ 
# 308
T *placement_ptr = BlockRakingLayout::PlacementPtr(((temp_storage).raking_grid), linear_tid); 
# 309
(*placement_ptr) = input; 
# 311
__syncthreads(); 
# 314
if ((linear_tid) < (RAKING_THREADS)) 
# 315
{ 
# 317
T upsweep_partial = Upsweep(scan_op); 
# 320
T inclusive_partial; 
# 321
T exclusive_partial; 
# 322
(((WarpScan)(((temp_storage).warp_scan))).Scan(upsweep_partial, inclusive_partial, exclusive_partial, identity, scan_op)); 
# 325
if ((__device_builtin_variable_threadIdx.x) == ((RAKING_THREADS) - 1)) { 
# 326
((temp_storage).block_aggregate) = inclusive_partial; }  
# 329
ExclusiveDownsweep(scan_op, exclusive_partial); 
# 330
}  
# 332
__syncthreads(); 
# 335
output = (*placement_ptr); 
# 338
block_aggregate = ((temp_storage).block_aggregate); 
# 339
}  
# 340
} 
#endif
# 344 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/block_scan_raking.cuh"
template< class 
# 345
ScanOp, class 
# 346
BlockPrefixCallbackOp> 
# 347
__attribute((always_inline)) void ExclusiveScan(T 
# 348
input, T &
# 349
output, T 
# 350
identity, ScanOp 
# 351
scan_op, T &
# 352
block_aggregate, BlockPrefixCallbackOp &
# 353
block_prefix_callback_op) 
# 354
{int volatile ___ = 1;(void)input;(void)output;(void)identity;(void)scan_op;(void)block_aggregate;(void)block_prefix_callback_op;
# 413
::exit(___);}
#if 0
# 354
{ 
# 355
if (WARP_SYNCHRONOUS) 
# 356
{ 
# 358
T exclusive_partial; 
# 359
(((WarpScan)(((temp_storage).warp_scan))).ExclusiveScan(input, exclusive_partial, identity, scan_op, block_aggregate)); 
# 362
output = block_prefix_callback_op(block_aggregate); 
# 363
output = (((WarpScan)(((temp_storage).warp_scan))).Broadcast(output, 0)); 
# 366
if ((linear_tid) > 0) { 
# 367
output = scan_op(output, exclusive_partial); }  
# 368
} else 
# 370
{ 
# 372
T *placement_ptr = BlockRakingLayout::PlacementPtr(((temp_storage).raking_grid), linear_tid); 
# 373
(*placement_ptr) = input; 
# 375
__syncthreads(); 
# 378
if ((linear_tid) < (RAKING_THREADS)) 
# 379
{ 
# 381
T upsweep_partial = Upsweep(scan_op); 
# 384
T inclusive_partial; 
# 385
T exclusive_partial; 
# 386
(((WarpScan)(((temp_storage).warp_scan))).Scan(upsweep_partial, inclusive_partial, exclusive_partial, identity, scan_op)); 
# 389
if ((__device_builtin_variable_threadIdx.x) == ((RAKING_THREADS) - 1)) { 
# 390
ThreadStore< STORE_VOLATILE> (&((temp_storage).block_aggregate), inclusive_partial); }  
# 391
block_aggregate = ThreadLoad< LOAD_VOLATILE> (&((temp_storage).block_aggregate)); 
# 394
T prefix = block_prefix_callback_op(block_aggregate); 
# 395
prefix = (((WarpScan)(((temp_storage).warp_scan))).Broadcast(prefix, 0)); 
# 398
if ((linear_tid) > 0) { 
# 399
prefix = scan_op(prefix, exclusive_partial); }  
# 402
ExclusiveDownsweep(scan_op, prefix); 
# 403
}  
# 405
__syncthreads(); 
# 408
output = (*placement_ptr); 
# 411
block_aggregate = ((temp_storage).block_aggregate); 
# 412
}  
# 413
} 
#endif
# 420 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/block_scan_raking.cuh"
template< class ScanOp> 
# 421
__attribute((always_inline)) void ExclusiveScan(T 
# 422
input, T &
# 423
output, ScanOp 
# 424
scan_op) 
# 425
{int volatile ___ = 1;(void)input;(void)output;(void)scan_op;
# 458
::exit(___);}
#if 0
# 425
{ 
# 426
if (WARP_SYNCHRONOUS) 
# 427
{ 
# 429
(((WarpScan)(((temp_storage).warp_scan))).ExclusiveScan(input, output, scan_op)); 
# 430
} else 
# 432
{ 
# 434
T *placement_ptr = BlockRakingLayout::PlacementPtr(((temp_storage).raking_grid), linear_tid); 
# 435
(*placement_ptr) = input; 
# 437
__syncthreads(); 
# 440
if ((linear_tid) < (RAKING_THREADS)) 
# 441
{ 
# 443
T upsweep_partial = Upsweep(scan_op); 
# 446
T exclusive_partial; 
# 447
(((WarpScan)(((temp_storage).warp_scan))).ExclusiveScan(upsweep_partial, exclusive_partial, scan_op)); 
# 450
ExclusiveDownsweep(scan_op, exclusive_partial, (linear_tid) != 0); 
# 451
}  
# 453
__syncthreads(); 
# 456
output = (*placement_ptr); 
# 457
}  
# 458
} 
#endif
# 462 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/block_scan_raking.cuh"
template< class ScanOp> 
# 463
__attribute((always_inline)) void ExclusiveScan(T 
# 464
input, T &
# 465
output, ScanOp 
# 466
scan_op, T &
# 467
block_aggregate) 
# 468
{int volatile ___ = 1;(void)input;(void)output;(void)scan_op;(void)block_aggregate;
# 509
::exit(___);}
#if 0
# 468
{ 
# 469
if (WARP_SYNCHRONOUS) 
# 470
{ 
# 472
(((WarpScan)(((temp_storage).warp_scan))).ExclusiveScan(input, output, scan_op, block_aggregate)); 
# 473
} else 
# 475
{ 
# 477
T *placement_ptr = BlockRakingLayout::PlacementPtr(((temp_storage).raking_grid), linear_tid); 
# 478
(*placement_ptr) = input; 
# 480
__syncthreads(); 
# 483
if ((linear_tid) < (RAKING_THREADS)) 
# 484
{ 
# 486
T upsweep_partial = Upsweep(scan_op); 
# 489
T inclusive_partial; 
# 490
T exclusive_partial; 
# 491
(((WarpScan)(((temp_storage).warp_scan))).Scan(upsweep_partial, inclusive_partial, exclusive_partial, scan_op)); 
# 494
if ((__device_builtin_variable_threadIdx.x) == ((RAKING_THREADS) - 1)) { 
# 495
((temp_storage).block_aggregate) = inclusive_partial; }  
# 498
ExclusiveDownsweep(scan_op, exclusive_partial, (linear_tid) != 0); 
# 499
}  
# 501
__syncthreads(); 
# 504
output = (*placement_ptr); 
# 507
block_aggregate = ((temp_storage).block_aggregate); 
# 508
}  
# 509
} 
#endif
# 513 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/block_scan_raking.cuh"
template< class 
# 514
ScanOp, class 
# 515
BlockPrefixCallbackOp> 
# 516
__attribute((always_inline)) void ExclusiveScan(T 
# 517
input, T &
# 518
output, ScanOp 
# 519
scan_op, T &
# 520
block_aggregate, BlockPrefixCallbackOp &
# 521
block_prefix_callback_op) 
# 522
{int volatile ___ = 1;(void)input;(void)output;(void)scan_op;(void)block_aggregate;(void)block_prefix_callback_op;
# 581
::exit(___);}
#if 0
# 522
{ 
# 523
if (WARP_SYNCHRONOUS) 
# 524
{ 
# 526
T exclusive_partial; 
# 527
(((WarpScan)(((temp_storage).warp_scan))).ExclusiveScan(input, exclusive_partial, scan_op, block_aggregate)); 
# 530
output = block_prefix_callback_op(block_aggregate); 
# 531
output = (((WarpScan)(((temp_storage).warp_scan))).Broadcast(output, 0)); 
# 534
if ((linear_tid) > 0) { 
# 535
output = scan_op(output, exclusive_partial); }  
# 536
} else 
# 538
{ 
# 540
T *placement_ptr = BlockRakingLayout::PlacementPtr(((temp_storage).raking_grid), linear_tid); 
# 541
(*placement_ptr) = input; 
# 543
__syncthreads(); 
# 546
if ((linear_tid) < (RAKING_THREADS)) 
# 547
{ 
# 549
T upsweep_partial = Upsweep(scan_op); 
# 552
T inclusive_partial; 
# 553
T exclusive_partial; 
# 554
(((WarpScan)(((temp_storage).warp_scan))).Scan(upsweep_partial, inclusive_partial, exclusive_partial, scan_op)); 
# 557
if ((__device_builtin_variable_threadIdx.x) == ((RAKING_THREADS) - 1)) { 
# 558
ThreadStore< STORE_VOLATILE> (&((temp_storage).block_aggregate), inclusive_partial); }  
# 559
block_aggregate = ThreadLoad< LOAD_VOLATILE> (&((temp_storage).block_aggregate)); 
# 562
T prefix = block_prefix_callback_op(block_aggregate); 
# 563
prefix = (((WarpScan)(((temp_storage).warp_scan))).Broadcast(prefix, 0)); 
# 566
if ((linear_tid) > 0) { 
# 567
prefix = scan_op(prefix, exclusive_partial); }  
# 570
ExclusiveDownsweep(scan_op, prefix); 
# 571
}  
# 573
__syncthreads(); 
# 576
output = (*placement_ptr); 
# 579
block_aggregate = ((temp_storage).block_aggregate); 
# 580
}  
# 581
} 
#endif
# 589 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/block_scan_raking.cuh"
template< class ScanOp> 
# 590
__attribute((always_inline)) void InclusiveScan(T 
# 591
input, T &
# 592
output, ScanOp 
# 593
scan_op) 
# 594
{int volatile ___ = 1;(void)input;(void)output;(void)scan_op;
# 627
::exit(___);}
#if 0
# 594
{ 
# 595
if (WARP_SYNCHRONOUS) 
# 596
{ 
# 598
(((WarpScan)(((temp_storage).warp_scan))).InclusiveScan(input, output, scan_op)); 
# 599
} else 
# 601
{ 
# 603
T *placement_ptr = BlockRakingLayout::PlacementPtr(((temp_storage).raking_grid), linear_tid); 
# 604
(*placement_ptr) = input; 
# 606
__syncthreads(); 
# 609
if ((linear_tid) < (RAKING_THREADS)) 
# 610
{ 
# 612
T upsweep_partial = Upsweep(scan_op); 
# 615
T exclusive_partial; 
# 616
(((WarpScan)(((temp_storage).warp_scan))).ExclusiveScan(upsweep_partial, exclusive_partial, scan_op)); 
# 619
InclusiveDownsweep(scan_op, exclusive_partial, (linear_tid) != 0); 
# 620
}  
# 622
__syncthreads(); 
# 625
output = (*placement_ptr); 
# 626
}  
# 627
} 
#endif
# 631 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/block_scan_raking.cuh"
template< class ScanOp> 
# 632
__attribute((always_inline)) void InclusiveScan(T 
# 633
input, T &
# 634
output, ScanOp 
# 635
scan_op, T &
# 636
block_aggregate) 
# 637
{int volatile ___ = 1;(void)input;(void)output;(void)scan_op;(void)block_aggregate;
# 678
::exit(___);}
#if 0
# 637
{ 
# 638
if (WARP_SYNCHRONOUS) 
# 639
{ 
# 641
(((WarpScan)(((temp_storage).warp_scan))).InclusiveScan(input, output, scan_op, block_aggregate)); 
# 642
} else 
# 644
{ 
# 646
T *placement_ptr = BlockRakingLayout::PlacementPtr(((temp_storage).raking_grid), linear_tid); 
# 647
(*placement_ptr) = input; 
# 649
__syncthreads(); 
# 652
if ((linear_tid) < (RAKING_THREADS)) 
# 653
{ 
# 655
T upsweep_partial = Upsweep(scan_op); 
# 658
T inclusive_partial; 
# 659
T exclusive_partial; 
# 660
(((WarpScan)(((temp_storage).warp_scan))).Scan(upsweep_partial, inclusive_partial, exclusive_partial, scan_op)); 
# 663
if ((__device_builtin_variable_threadIdx.x) == ((RAKING_THREADS) - 1)) { 
# 664
((temp_storage).block_aggregate) = inclusive_partial; }  
# 667
InclusiveDownsweep(scan_op, exclusive_partial, (linear_tid) != 0); 
# 668
}  
# 670
__syncthreads(); 
# 673
output = (*placement_ptr); 
# 676
block_aggregate = ((temp_storage).block_aggregate); 
# 677
}  
# 678
} 
#endif
# 682 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/block_scan_raking.cuh"
template< class 
# 683
ScanOp, class 
# 684
BlockPrefixCallbackOp> 
# 685
__attribute((always_inline)) void InclusiveScan(T 
# 686
input, T &
# 687
output, ScanOp 
# 688
scan_op, T &
# 689
block_aggregate, BlockPrefixCallbackOp &
# 690
block_prefix_callback_op) 
# 691
{int volatile ___ = 1;(void)input;(void)output;(void)scan_op;(void)block_aggregate;(void)block_prefix_callback_op;
# 749
::exit(___);}
#if 0
# 691
{ 
# 692
if (WARP_SYNCHRONOUS) 
# 693
{ 
# 695
T inclusive_partial; 
# 696
(((WarpScan)(((temp_storage).warp_scan))).InclusiveScan(input, inclusive_partial, scan_op, block_aggregate)); 
# 699
output = block_prefix_callback_op(block_aggregate); 
# 700
output = (((WarpScan)(((temp_storage).warp_scan))).Broadcast(output, 0)); 
# 703
output = scan_op(output, inclusive_partial); 
# 704
} else 
# 706
{ 
# 708
T *placement_ptr = BlockRakingLayout::PlacementPtr(((temp_storage).raking_grid), linear_tid); 
# 709
(*placement_ptr) = input; 
# 711
__syncthreads(); 
# 714
if ((linear_tid) < (RAKING_THREADS)) 
# 715
{ 
# 717
T upsweep_partial = Upsweep(scan_op); 
# 720
T inclusive_partial; 
# 721
T exclusive_partial; 
# 722
(((WarpScan)(((temp_storage).warp_scan))).Scan(upsweep_partial, inclusive_partial, exclusive_partial, scan_op)); 
# 725
if ((__device_builtin_variable_threadIdx.x) == ((RAKING_THREADS) - 1)) { 
# 726
ThreadStore< STORE_VOLATILE> (&((temp_storage).block_aggregate), inclusive_partial); }  
# 727
block_aggregate = ThreadLoad< LOAD_VOLATILE> (&((temp_storage).block_aggregate)); 
# 730
T prefix = block_prefix_callback_op(block_aggregate); 
# 731
prefix = (((WarpScan)(((temp_storage).warp_scan))).Broadcast(prefix, 0)); 
# 734
if ((linear_tid) > 0) { 
# 735
prefix = scan_op(prefix, exclusive_partial); }  
# 738
InclusiveDownsweep(scan_op, prefix); 
# 739
}  
# 741
__syncthreads(); 
# 744
output = (*placement_ptr); 
# 747
block_aggregate = ((temp_storage).block_aggregate); 
# 748
}  
# 749
} 
#endif
# 751 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/block_scan_raking.cuh"
}; 
# 754
}
# 755
}}}}
# 42 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/block_scan_warp_scans.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 45
namespace cub_ { 
# 50
template< class 
# 51
T, int 
# 52
BLOCK_DIM_X, int 
# 53
BLOCK_DIM_Y, int 
# 54
BLOCK_DIM_Z, int 
# 55
PTX_ARCH> 
# 56
struct BlockScanWarpScans { 
# 64
enum { 
# 66
WARP_THREADS = 1 << 5, 
# 69
BLOCK_THREADS = (BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z, 
# 72
WARPS = ((((BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z) + (1 << 5)) - 1) / (1 << 5)
# 73
}; 
# 76
typedef WarpScan< T, WARP_THREADS, PTX_ARCH>  WarpScanT; 
# 79
typedef WarpScan< T, WARPS, PTX_ARCH>  WarpAggregateScan; 
# 82
struct _TempStorage { 
# 84
typename WarpScan< T, WARP_THREADS, PTX_ARCH> ::TempStorage warp_scan[WARPS]; 
# 85
T warp_aggregates[WARPS]; 
# 86
T block_prefix; 
# 87
}; 
# 91
struct TempStorage : public Uninitialized< _TempStorage>  { }; 
# 99
_TempStorage &temp_storage; 
# 100
int linear_tid; 
# 101
int warp_id; 
# 102
int lane_id; 
# 110
__attribute((always_inline)) BlockScanWarpScans(TempStorage &
# 111
temp_storage) : temp_storage((temp_storage.Alias())), linear_tid(RowMajorTid(BLOCK_DIM_X, BLOCK_DIM_Y, BLOCK_DIM_Z)), warp_id(((WARPS) == 1) ? 0 : ((linear_tid) / (WARP_THREADS))), lane_id(LaneId()) 
# 117
{int *volatile ___ = 0;(void)temp_storage;::free(___);}
#if 0
# 117
{ } 
#endif
# 124 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/block_scan_warp_scans.cuh"
template< class ScanOp, int WARP> 
# 125
__attribute((always_inline)) void ApplyWarpAggregates(T &
# 126
partial, ScanOp 
# 127
scan_op, T &
# 128
block_aggregate, bool 
# 129
lane_valid, Int2Type< WARP>  
# 130
addend_warp) 
# 131
{int volatile ___ = 1;(void)partial;(void)scan_op;(void)block_aggregate;(void)lane_valid;(void)addend_warp;
# 144
::exit(___);}
#if 0
# 131
{ 
# 132
T inclusive = scan_op(block_aggregate, partial); 
# 133
if ((warp_id) == WARP) 
# 134
{ 
# 135
partial = (lane_valid ? inclusive : block_aggregate); 
# 138
}  
# 140
T addend = ((temp_storage).warp_aggregates)[WARP]; 
# 141
block_aggregate = scan_op(block_aggregate, addend); 
# 143
ApplyWarpAggregates(partial, scan_op, block_aggregate, lane_valid, Int2Type< WARP + 1> ()); 
# 144
} 
#endif
# 146 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/block_scan_warp_scans.cuh"
template< class ScanOp> 
# 147
__attribute((always_inline)) void ApplyWarpAggregates(T &
# 148
partial, ScanOp 
# 149
scan_op, T &
# 150
block_aggregate, bool 
# 151
lane_valid, Int2Type< WARPS>  
# 152
addend_warp) 
# 153
{int volatile ___ = 1;(void)partial;(void)scan_op;(void)block_aggregate;(void)lane_valid;(void)addend_warp;::exit(___);}
#if 0
# 153
{ } 
#endif
# 157 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/block_scan_warp_scans.cuh"
template< class ScanOp> 
# 158
__attribute((always_inline)) void ApplyWarpAggregates(T &
# 159
partial, ScanOp 
# 160
scan_op, T 
# 161
warp_aggregate, T &
# 162
block_aggregate, bool 
# 163
lane_valid = true) 
# 164
{int volatile ___ = 1;(void)partial;(void)scan_op;(void)warp_aggregate;(void)block_aggregate;(void)lane_valid;
# 175
::exit(___);}
#if 0
# 164
{ 
# 166
if ((lane_id) == ((WARP_THREADS) - 1)) { 
# 167
(((temp_storage).warp_aggregates)[warp_id]) = warp_aggregate; }  
# 169
__syncthreads(); 
# 171
block_aggregate = (((temp_storage).warp_aggregates)[0]); 
# 174
ApplyWarpAggregates(partial, scan_op, block_aggregate, lane_valid, Int2Type< 1> ()); 
# 175
} 
#endif
# 182 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/block_scan_warp_scans.cuh"
template< class ScanOp> 
# 183
__attribute((always_inline)) void ExclusiveScan(T 
# 184
input, T &
# 185
output, const T &
# 186
identity, ScanOp 
# 187
scan_op) 
# 188
{int volatile ___ = 1;(void)input;(void)output;(void)identity;(void)scan_op;
# 191
::exit(___);}
#if 0
# 188
{ 
# 189
T block_aggregate; 
# 190
ExclusiveScan(input, output, identity, scan_op, block_aggregate); 
# 191
} 
#endif
# 195 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/block_scan_warp_scans.cuh"
template< class ScanOp> 
# 196
__attribute((always_inline)) void ExclusiveScan(T 
# 197
input, T &
# 198
output, const T &
# 199
identity, ScanOp 
# 200
scan_op, T &
# 201
block_aggregate) 
# 202
{int volatile ___ = 1;(void)input;(void)output;(void)identity;(void)scan_op;(void)block_aggregate;
# 208
::exit(___);}
#if 0
# 202
{ 
# 203
T inclusive_output; 
# 204
(((WarpScanT)(((temp_storage).warp_scan)[warp_id])).Scan(input, inclusive_output, output, identity, scan_op)); 
# 207
ApplyWarpAggregates(output, scan_op, inclusive_output, block_aggregate); 
# 208
} 
#endif
# 212 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/block_scan_warp_scans.cuh"
template< class 
# 213
ScanOp, class 
# 214
BlockPrefixCallbackOp> 
# 215
__attribute((always_inline)) void ExclusiveScan(T 
# 216
input, T &
# 217
output, T 
# 218
identity, ScanOp 
# 219
scan_op, T &
# 220
block_aggregate, BlockPrefixCallbackOp &
# 221
block_prefix_callback_op) 
# 222
{int volatile ___ = 1;(void)input;(void)output;(void)identity;(void)scan_op;(void)block_aggregate;(void)block_prefix_callback_op;
# 241
::exit(___);}
#if 0
# 222
{ 
# 223
ExclusiveScan(input, output, identity, scan_op, block_aggregate); 
# 226
if ((warp_id) == 0) 
# 227
{ 
# 228
T block_prefix = block_prefix_callback_op(block_aggregate); 
# 229
if ((lane_id) == 0) 
# 230
{ 
# 232
((temp_storage).block_prefix) = block_prefix; 
# 233
}  
# 234
}  
# 236
__syncthreads(); 
# 239
T block_prefix = (((temp_storage).block_prefix)); 
# 240
output = scan_op(block_prefix, output); 
# 241
} 
#endif
# 249 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/block_scan_warp_scans.cuh"
template< class ScanOp> 
# 250
__attribute((always_inline)) void ExclusiveScan(T 
# 251
input, T &
# 252
output, ScanOp 
# 253
scan_op) 
# 254
{int volatile ___ = 1;(void)input;(void)output;(void)scan_op;
# 257
::exit(___);}
#if 0
# 254
{ 
# 255
T block_aggregate; 
# 256
ExclusiveScan(input, output, scan_op, block_aggregate); 
# 257
} 
#endif
# 261 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/block_scan_warp_scans.cuh"
template< class ScanOp> 
# 262
__attribute((always_inline)) void ExclusiveScan(T 
# 263
input, T &
# 264
output, ScanOp 
# 265
scan_op, T &
# 266
block_aggregate) 
# 267
{int volatile ___ = 1;(void)input;(void)output;(void)scan_op;(void)block_aggregate;
# 273
::exit(___);}
#if 0
# 267
{ 
# 268
T inclusive_output; 
# 269
(((WarpScanT)(((temp_storage).warp_scan)[warp_id])).Scan(input, inclusive_output, output, scan_op)); 
# 272
ApplyWarpAggregates(output, scan_op, inclusive_output, block_aggregate, (lane_id) > 0); 
# 273
} 
#endif
# 277 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/block_scan_warp_scans.cuh"
template< class 
# 278
ScanOp, class 
# 279
BlockPrefixCallbackOp> 
# 280
__attribute((always_inline)) void ExclusiveScan(T 
# 281
input, T &
# 282
output, ScanOp 
# 283
scan_op, T &
# 284
block_aggregate, BlockPrefixCallbackOp &
# 285
block_prefix_callback_op) 
# 286
{int volatile ___ = 1;(void)input;(void)output;(void)scan_op;(void)block_aggregate;(void)block_prefix_callback_op;
# 307
::exit(___);}
#if 0
# 286
{ 
# 287
ExclusiveScan(input, output, scan_op, block_aggregate); 
# 290
if ((warp_id) == 0) 
# 291
{ 
# 292
T block_prefix = block_prefix_callback_op(block_aggregate); 
# 293
if ((lane_id) == 0) 
# 294
{ 
# 296
((temp_storage).block_prefix) = block_prefix; 
# 297
}  
# 298
}  
# 300
__syncthreads(); 
# 303
T block_prefix = (((temp_storage).block_prefix)); 
# 304
output = (((linear_tid) == 0) ? block_prefix : scan_op(block_prefix, output)); 
# 307
} 
#endif
# 315 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/block_scan_warp_scans.cuh"
template< class ScanOp> 
# 316
__attribute((always_inline)) void InclusiveScan(T 
# 317
input, T &
# 318
output, ScanOp 
# 319
scan_op) 
# 320
{int volatile ___ = 1;(void)input;(void)output;(void)scan_op;
# 323
::exit(___);}
#if 0
# 320
{ 
# 321
T block_aggregate; 
# 322
InclusiveScan(input, output, scan_op, block_aggregate); 
# 323
} 
#endif
# 327 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/block_scan_warp_scans.cuh"
template< class ScanOp> 
# 328
__attribute((always_inline)) void InclusiveScan(T 
# 329
input, T &
# 330
output, ScanOp 
# 331
scan_op, T &
# 332
block_aggregate) 
# 333
{int volatile ___ = 1;(void)input;(void)output;(void)scan_op;(void)block_aggregate;
# 339
::exit(___);}
#if 0
# 333
{ 
# 334
(((WarpScanT)(((temp_storage).warp_scan)[warp_id])).InclusiveScan(input, output, scan_op)); 
# 337
ApplyWarpAggregates(output, scan_op, output, block_aggregate); 
# 339
} 
#endif
# 343 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/block_scan_warp_scans.cuh"
template< class 
# 344
ScanOp, class 
# 345
BlockPrefixCallbackOp> 
# 346
__attribute((always_inline)) void InclusiveScan(T 
# 347
input, T &
# 348
output, ScanOp 
# 349
scan_op, T &
# 350
block_aggregate, BlockPrefixCallbackOp &
# 351
block_prefix_callback_op) 
# 352
{int volatile ___ = 1;(void)input;(void)output;(void)scan_op;(void)block_aggregate;(void)block_prefix_callback_op;
# 371
::exit(___);}
#if 0
# 352
{ 
# 353
InclusiveScan(input, output, scan_op, block_aggregate); 
# 356
if ((warp_id) == 0) 
# 357
{ 
# 358
T block_prefix = block_prefix_callback_op(block_aggregate); 
# 359
if ((lane_id) == 0) 
# 360
{ 
# 362
((temp_storage).block_prefix) = block_prefix; 
# 363
}  
# 364
}  
# 366
__syncthreads(); 
# 369
T block_prefix = (((temp_storage).block_prefix)); 
# 370
output = scan_op(block_prefix, output); 
# 371
} 
#endif
# 374 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/specializations/block_scan_warp_scans.cuh"
}; 
# 377
}
# 378
}}}}
# 44 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/block_scan.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 47
namespace cub_ { 
# 60
template< class ReductionOp> 
# 61
struct ReduceByKeyOp { 
# 63
ReductionOp op; 
# 66
__attribute((always_inline)) ReduceByKeyOp(ReductionOp op) : op(op) {int *volatile ___ = 0;(void)op;::free(___);}
#if 0
# 66
{ } 
#endif
# 69 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/block_scan.cuh"
template< class KeyValuePair> 
# 70
__attribute((always_inline)) KeyValuePair operator()(const KeyValuePair &
# 71
first, const KeyValuePair &
# 72
second) 
# 73
{int volatile ___ = 1;(void)first;(void)second;
# 82
::exit(___);}
#if 0
# 73
{ 
# 74
KeyValuePair retval; 
# 76
(retval.value) = (((second.key) != (first.key)) ? second.value : (op)((first.value), (second.value))); 
# 80
(retval.key) = (second.key); 
# 81
return retval; 
# 82
} 
#endif
# 83 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/block_scan.cuh"
}; 
# 90
template< class ReductionOp> 
# 91
struct SegmentedOp { 
# 93
ReductionOp op; 
# 96
__attribute((always_inline)) SegmentedOp(ReductionOp op) : op(op) {int *volatile ___ = 0;(void)op;::free(___);}
#if 0
# 96
{ } 
#endif
# 99 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/block_scan.cuh"
template< class KeyValuePair> 
# 100
__attribute((always_inline)) KeyValuePair operator()(const KeyValuePair &
# 101
first, const KeyValuePair &
# 102
second) 
# 103
{int volatile ___ = 1;(void)first;(void)second;
# 115
::exit(___);}
#if 0
# 103
{ 
# 104
if (second.key) { 
# 105
KeyValuePair retval; 
# 106
(retval.value) = (second.value); 
# 107
(retval.key) = ((first.key) + (second.key)); 
# 108
return retval; 
# 109
} else { 
# 110
KeyValuePair retval; 
# 111
(retval.value) = (op)((first.value), (second.value)); 
# 112
(retval.key) = ((first.key) + (second.key)); 
# 113
return; 
# 114
}  
# 115
} 
#endif
# 116 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/block_scan.cuh"
}; 
# 129
enum BlockScanAlgorithm { 
# 150
BLOCK_SCAN_RAKING, 
# 160
BLOCK_SCAN_RAKING_MEMOIZE, 
# 180
BLOCK_SCAN_WARP_SCANS
# 181
}; 
# 258
template< class 
# 259
T, int 
# 260
BLOCK_DIM_X, BlockScanAlgorithm 
# 261
ALGORITHM = BLOCK_SCAN_RAKING, int 
# 262
BLOCK_DIM_Y = 1, int 
# 263
BLOCK_DIM_Z = 1, int 
# 264
PTX_ARCH = 0> 
# 265
class BlockScan { 
# 275
enum { 
# 277
BLOCK_THREADS = (BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z
# 278
}; 
# 286
static const BlockScanAlgorithm SAFE_ALGORITHM = ((((ALGORITHM) == (BLOCK_SCAN_WARP_SCANS)) && (((BLOCK_THREADS) % (1 << 5)) != 0)) ? BLOCK_SCAN_RAKING : ALGORITHM); 
# 291
typedef BlockScanWarpScans< T, BLOCK_DIM_X, BLOCK_DIM_Y, BLOCK_DIM_Z, PTX_ARCH>  WarpScans; 
# 292
typedef BlockScanRaking< T, BLOCK_DIM_X, BLOCK_DIM_Y, BLOCK_DIM_Z, SAFE_ALGORITHM == (BLOCK_SCAN_RAKING_MEMOIZE), PTX_ARCH>  Raking; 
# 297
typedef typename If< SAFE_ALGORITHM == (BLOCK_SCAN_WARP_SCANS), BlockScanWarpScans< T, BLOCK_DIM_X, BLOCK_DIM_Y, BLOCK_DIM_Z, PTX_ARCH> , BlockScanRaking< T, BLOCK_DIM_X, BLOCK_DIM_Y, BLOCK_DIM_Z, SAFE_ALGORITHM == (BLOCK_SCAN_RAKING_MEMOIZE), PTX_ARCH> > ::Type InternalBlockScan; 
# 300
typedef typename If< SAFE_ALGORITHM == (BLOCK_SCAN_WARP_SCANS), BlockScanWarpScans< T, BLOCK_DIM_X, BLOCK_DIM_Y, BLOCK_DIM_Z, PTX_ARCH> , BlockScanRaking< T, BLOCK_DIM_X, BLOCK_DIM_Y, BLOCK_DIM_Z, SAFE_ALGORITHM == (BLOCK_SCAN_RAKING_MEMOIZE), PTX_ARCH> > ::Type::TempStorage _TempStorage; 
# 308
_TempStorage &temp_storage; 
# 311
int linear_tid; 
# 319
__attribute((always_inline)) _TempStorage &PrivateStorage() 
# 320
{int volatile ___ = 1;
# 323
::exit(___);}
#if 0
# 320
{ 
# 321
__attribute__((unused)) static _TempStorage private_storage; 
# 322
return private_storage; 
# 323
} 
#endif
# 332 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/block_scan.cuh"
public: struct TempStorage : public Uninitialized< typename If< SAFE_ALGORITHM == (BLOCK_SCAN_WARP_SCANS), BlockScanWarpScans< T, BLOCK_DIM_X, BLOCK_DIM_Y, BLOCK_DIM_Z, PTX_ARCH> , BlockScanRaking< T, BLOCK_DIM_X, BLOCK_DIM_Y, BLOCK_DIM_Z, SAFE_ALGORITHM == (BLOCK_SCAN_RAKING_MEMOIZE), PTX_ARCH> > ::Type::TempStorage>  { }; 
# 343
__attribute((always_inline)) BlockScan() : temp_storage(PrivateStorage()), linear_tid(RowMajorTid(BLOCK_DIM_X, BLOCK_DIM_Y, BLOCK_DIM_Z)) 
# 347
{int *volatile ___ = 0;::free(___);}
#if 0
# 347
{ } 
#endif
# 353 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/block_scan.cuh"
__attribute((always_inline)) BlockScan(TempStorage &
# 354
temp_storage) : temp_storage((temp_storage.Alias())), linear_tid(RowMajorTid(BLOCK_DIM_X, BLOCK_DIM_Y, BLOCK_DIM_Z)) 
# 358
{int *volatile ___ = 0;(void)temp_storage;::free(___);}
#if 0
# 358
{ } 
#endif
# 408 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/block_scan.cuh"
__attribute((always_inline)) void ExclusiveSum(T 
# 409
input, T &
# 410
output) 
# 411
{int volatile ___ = 1;(void)input;(void)output;
# 413
::exit(___);}
#if 0
# 411
{ 
# 412
ExclusiveScan(input, output, ZeroInitialize< T> (), Sum()); 
# 413
} 
#endif
# 454 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/block_scan.cuh"
__attribute((always_inline)) void ExclusiveSum(T 
# 455
input, T &
# 456
output, T &
# 457
block_aggregate) 
# 458
{int volatile ___ = 1;(void)input;(void)output;(void)block_aggregate;
# 460
::exit(___);}
#if 0
# 458
{ 
# 459
ExclusiveScan(input, output, ZeroInitialize< T> (), Sum(), block_aggregate); 
# 460
} 
#endif
# 539 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/block_scan.cuh"
template< class BlockPrefixCallbackOp> 
# 540
__attribute((always_inline)) void ExclusiveSum(T 
# 541
input, T &
# 542
output, T &
# 543
block_aggregate, BlockPrefixCallbackOp &
# 544
block_prefix_callback_op) 
# 545
{int volatile ___ = 1;(void)input;(void)output;(void)block_aggregate;(void)block_prefix_callback_op;
# 547
::exit(___);}
#if 0
# 545
{ 
# 546
ExclusiveScan(input, output, ZeroInitialize< T> (), Sum(), block_aggregate, block_prefix_callback_op); 
# 547
} 
#endif
# 596 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/block_scan.cuh"
template< int ITEMS_PER_THREAD> 
# 597
__attribute((always_inline)) void ExclusiveSum(T (&
# 598
input)[ITEMS_PER_THREAD], T (&
# 599
output)[ITEMS_PER_THREAD]) 
# 600
{int volatile ___ = 1;(void)input;(void)output;
# 610
::exit(___);}
#if 0
# 600
{ 
# 602
Sum scan_op; 
# 603
T thread_partial = ThreadReduce(input, scan_op); 
# 606
ExclusiveSum(thread_partial, thread_partial); 
# 609
ThreadScanExclusive(input, output, scan_op, thread_partial); 
# 610
} 
#endif
# 654 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/block_scan.cuh"
template< int ITEMS_PER_THREAD> 
# 655
__attribute((always_inline)) void ExclusiveSum(T (&
# 656
input)[ITEMS_PER_THREAD], T (&
# 657
output)[ITEMS_PER_THREAD], T &
# 658
block_aggregate) 
# 659
{int volatile ___ = 1;(void)input;(void)output;(void)block_aggregate;
# 669
::exit(___);}
#if 0
# 659
{ 
# 661
Sum scan_op; 
# 662
T thread_partial = ThreadReduce(input, scan_op); 
# 665
ExclusiveSum(thread_partial, thread_partial, block_aggregate); 
# 668
ThreadScanExclusive(input, output, scan_op, thread_partial); 
# 669
} 
#endif
# 760 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/block_scan.cuh"
template< int 
# 761
ITEMS_PER_THREAD, class 
# 762
BlockPrefixCallbackOp> 
# 763
__attribute((always_inline)) void ExclusiveSum(T (&
# 764
input)[ITEMS_PER_THREAD], T (&
# 765
output)[ITEMS_PER_THREAD], T &
# 766
block_aggregate, BlockPrefixCallbackOp &
# 767
block_prefix_callback_op) 
# 768
{int volatile ___ = 1;(void)input;(void)output;(void)block_aggregate;(void)block_prefix_callback_op;
# 778
::exit(___);}
#if 0
# 768
{ 
# 770
Sum scan_op; 
# 771
T thread_partial = ThreadReduce(input, scan_op); 
# 774
ExclusiveSum(thread_partial, thread_partial, block_aggregate, block_prefix_callback_op); 
# 777
ThreadScanExclusive(input, output, scan_op, thread_partial); 
# 778
} 
#endif
# 826 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/block_scan.cuh"
template< class ScanOp> 
# 827
__attribute((always_inline)) void ExclusiveScan(T 
# 828
input, T &
# 829
output, T 
# 830
identity, ScanOp 
# 831
scan_op) 
# 832
{int volatile ___ = 1;(void)input;(void)output;(void)identity;(void)scan_op;
# 834
::exit(___);}
#if 0
# 832
{ 
# 833
(((InternalBlockScan)(temp_storage)).ExclusiveScan(input, output, identity, scan_op)); 
# 834
} 
#endif
# 876 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/block_scan.cuh"
template< class ScanOp> 
# 877
__attribute((always_inline)) void ExclusiveScan(T 
# 878
input, T &
# 879
output, T 
# 880
identity, ScanOp 
# 881
scan_op, T &
# 882
block_aggregate) 
# 883
{int volatile ___ = 1;(void)input;(void)output;(void)identity;(void)scan_op;(void)block_aggregate;
# 885
::exit(___);}
#if 0
# 883
{ 
# 884
(((InternalBlockScan)(temp_storage)).ExclusiveScan(input, output, identity, scan_op, block_aggregate)); 
# 885
} 
#endif
# 966 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/block_scan.cuh"
template< class 
# 967
ScanOp, class 
# 968
BlockPrefixCallbackOp> 
# 969
__attribute((always_inline)) void ExclusiveScan(T 
# 970
input, T &
# 971
output, T 
# 972
identity, ScanOp 
# 973
scan_op, T &
# 974
block_aggregate, BlockPrefixCallbackOp &
# 975
block_prefix_callback_op) 
# 976
{int volatile ___ = 1;(void)input;(void)output;(void)identity;(void)scan_op;(void)block_aggregate;(void)block_prefix_callback_op;
# 978
::exit(___);}
#if 0
# 976
{ 
# 977
(((InternalBlockScan)(temp_storage)).ExclusiveScan(input, output, identity, scan_op, block_aggregate, block_prefix_callback_op)); 
# 978
} 
#endif
# 1030 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/block_scan.cuh"
template< int 
# 1031
ITEMS_PER_THREAD, class 
# 1032
ScanOp> 
# 1033
__attribute((always_inline)) void ExclusiveScan(T (&
# 1034
input)[ITEMS_PER_THREAD], T (&
# 1035
output)[ITEMS_PER_THREAD], T 
# 1036
identity, ScanOp 
# 1037
scan_op) 
# 1038
{int volatile ___ = 1;(void)input;(void)output;(void)identity;(void)scan_op;
# 1047
::exit(___);}
#if 0
# 1038
{ 
# 1040
T thread_partial = ThreadReduce(input, scan_op); 
# 1043
ExclusiveScan(thread_partial, thread_partial, identity, scan_op); 
# 1046
ThreadScanExclusive(input, output, scan_op, thread_partial); 
# 1047
} 
#endif
# 1092 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/block_scan.cuh"
template< int 
# 1093
ITEMS_PER_THREAD, class 
# 1094
ScanOp> 
# 1095
__attribute((always_inline)) void ExclusiveScan(T (&
# 1096
input)[ITEMS_PER_THREAD], T (&
# 1097
output)[ITEMS_PER_THREAD], T 
# 1098
identity, ScanOp 
# 1099
scan_op, T &
# 1100
block_aggregate) 
# 1101
{int volatile ___ = 1;(void)input;(void)output;(void)identity;(void)scan_op;(void)block_aggregate;
# 1110
::exit(___);}
#if 0
# 1101
{ 
# 1103
T thread_partial = ThreadReduce(input, scan_op); 
# 1106
ExclusiveScan(thread_partial, thread_partial, identity, scan_op, block_aggregate); 
# 1109
ThreadScanExclusive(input, output, scan_op, thread_partial); 
# 1110
} 
#endif
# 1202 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/block_scan.cuh"
template< int 
# 1203
ITEMS_PER_THREAD, class 
# 1204
ScanOp, class 
# 1205
BlockPrefixCallbackOp> 
# 1206
__attribute((always_inline)) void ExclusiveScan(T (&
# 1207
input)[ITEMS_PER_THREAD], T (&
# 1208
output)[ITEMS_PER_THREAD], T 
# 1209
identity, ScanOp 
# 1210
scan_op, T &
# 1211
block_aggregate, BlockPrefixCallbackOp &
# 1212
block_prefix_callback_op) 
# 1213
{int volatile ___ = 1;(void)input;(void)output;(void)identity;(void)scan_op;(void)block_aggregate;(void)block_prefix_callback_op;
# 1222
::exit(___);}
#if 0
# 1213
{ 
# 1215
T thread_partial = ThreadReduce(input, scan_op); 
# 1218
ExclusiveScan(thread_partial, thread_partial, identity, scan_op, block_aggregate, block_prefix_callback_op); 
# 1221
ThreadScanExclusive(input, output, scan_op, thread_partial); 
# 1222
} 
#endif
# 1330 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/block_scan.cuh"
template< int 
# 1331
ITEMS_PER_THREAD, class 
# 1332
ScanOp> 
# 1333
__attribute((always_inline)) void ExclusiveScan(T (&
# 1334
input)[ITEMS_PER_THREAD], T (&
# 1335
output)[ITEMS_PER_THREAD], ScanOp 
# 1336
scan_op) 
# 1337
{int volatile ___ = 1;(void)input;(void)output;(void)scan_op;
# 1346
::exit(___);}
#if 0
# 1337
{ 
# 1339
T thread_partial = ThreadReduce(input, scan_op); 
# 1342
ExclusiveScan(thread_partial, thread_partial, scan_op); 
# 1345
ThreadScanExclusive(input, output, scan_op, thread_partial, (linear_tid) != 0); 
# 1346
} 
#endif
# 1361 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/block_scan.cuh"
template< int 
# 1362
ITEMS_PER_THREAD, class 
# 1363
ScanOp> 
# 1364
__attribute((always_inline)) void ExclusiveScan(T (&
# 1365
input)[ITEMS_PER_THREAD], T (&
# 1366
output)[ITEMS_PER_THREAD], ScanOp 
# 1367
scan_op, T &
# 1368
block_aggregate) 
# 1369
{int volatile ___ = 1;(void)input;(void)output;(void)scan_op;(void)block_aggregate;
# 1378
::exit(___);}
#if 0
# 1369
{ 
# 1371
T thread_partial = ThreadReduce(input, scan_op); 
# 1374
ExclusiveScan(thread_partial, thread_partial, scan_op, block_aggregate); 
# 1377
ThreadScanExclusive(input, output, scan_op, thread_partial, (linear_tid) != 0); 
# 1378
} 
#endif
# 1399 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/block_scan.cuh"
template< int 
# 1400
ITEMS_PER_THREAD, class 
# 1401
ScanOp, class 
# 1402
BlockPrefixCallbackOp> 
# 1403
__attribute((always_inline)) void ExclusiveScan(T (&
# 1404
input)[ITEMS_PER_THREAD], T (&
# 1405
output)[ITEMS_PER_THREAD], ScanOp 
# 1406
scan_op, T &
# 1407
block_aggregate, BlockPrefixCallbackOp &
# 1408
block_prefix_callback_op) 
# 1409
{int volatile ___ = 1;(void)input;(void)output;(void)scan_op;(void)block_aggregate;(void)block_prefix_callback_op;
# 1418
::exit(___);}
#if 0
# 1409
{ 
# 1411
T thread_partial = ThreadReduce(input, scan_op); 
# 1414
ExclusiveScan(thread_partial, thread_partial, scan_op, block_aggregate, block_prefix_callback_op); 
# 1417
ThreadScanExclusive(input, output, scan_op, thread_partial); 
# 1418
} 
#endif
# 1466 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/block_scan.cuh"
__attribute((always_inline)) void InclusiveSum(T 
# 1467
input, T &
# 1468
output) 
# 1469
{int volatile ___ = 1;(void)input;(void)output;
# 1471
::exit(___);}
#if 0
# 1469
{ 
# 1470
InclusiveScan(input, output, Sum()); 
# 1471
} 
#endif
# 1511 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/block_scan.cuh"
__attribute((always_inline)) void InclusiveSum(T 
# 1512
input, T &
# 1513
output, T &
# 1514
block_aggregate) 
# 1515
{int volatile ___ = 1;(void)input;(void)output;(void)block_aggregate;
# 1517
::exit(___);}
#if 0
# 1515
{ 
# 1516
InclusiveScan(input, output, Sum(), block_aggregate); 
# 1517
} 
#endif
# 1596 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/block_scan.cuh"
template< class BlockPrefixCallbackOp> 
# 1597
__attribute((always_inline)) void InclusiveSum(T 
# 1598
input, T &
# 1599
output, T &
# 1600
block_aggregate, BlockPrefixCallbackOp &
# 1601
block_prefix_callback_op) 
# 1602
{int volatile ___ = 1;(void)input;(void)output;(void)block_aggregate;(void)block_prefix_callback_op;
# 1604
::exit(___);}
#if 0
# 1602
{ 
# 1603
InclusiveScan(input, output, Sum(), block_aggregate, block_prefix_callback_op); 
# 1604
} 
#endif
# 1652 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/block_scan.cuh"
template< int ITEMS_PER_THREAD> 
# 1653
__attribute((always_inline)) void InclusiveSum(T (&
# 1654
input)[ITEMS_PER_THREAD], T (&
# 1655
output)[ITEMS_PER_THREAD]) 
# 1656
{int volatile ___ = 1;(void)input;(void)output;
# 1673
::exit(___);}
#if 0
# 1656
{ 
# 1657
if (ITEMS_PER_THREAD == 1) 
# 1658
{ 
# 1659
InclusiveSum((input)[0], (output)[0]); 
# 1660
} else 
# 1662
{ 
# 1664
Sum scan_op; 
# 1665
T thread_partial = ThreadReduce(input, scan_op); 
# 1668
ExclusiveSum(thread_partial, thread_partial); 
# 1671
ThreadScanInclusive(input, output, scan_op, thread_partial, (linear_tid) != 0); 
# 1672
}  
# 1673
} 
#endif
# 1719 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/block_scan.cuh"
template< int ITEMS_PER_THREAD> 
# 1720
__attribute((always_inline)) void InclusiveSum(T (&
# 1721
input)[ITEMS_PER_THREAD], T (&
# 1722
output)[ITEMS_PER_THREAD], T &
# 1723
block_aggregate) 
# 1724
{int volatile ___ = 1;(void)input;(void)output;(void)block_aggregate;
# 1741
::exit(___);}
#if 0
# 1724
{ 
# 1725
if (ITEMS_PER_THREAD == 1) 
# 1726
{ 
# 1727
InclusiveSum((input)[0], (output)[0], block_aggregate); 
# 1728
} else 
# 1730
{ 
# 1732
Sum scan_op; 
# 1733
T thread_partial = ThreadReduce(input, scan_op); 
# 1736
ExclusiveSum(thread_partial, thread_partial, block_aggregate); 
# 1739
ThreadScanInclusive(input, output, scan_op, thread_partial, (linear_tid) != 0); 
# 1740
}  
# 1741
} 
#endif
# 1831 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/block_scan.cuh"
template< int 
# 1832
ITEMS_PER_THREAD, class 
# 1833
BlockPrefixCallbackOp> 
# 1834
__attribute((always_inline)) void InclusiveSum(T (&
# 1835
input)[ITEMS_PER_THREAD], T (&
# 1836
output)[ITEMS_PER_THREAD], T &
# 1837
block_aggregate, BlockPrefixCallbackOp &
# 1838
block_prefix_callback_op) 
# 1839
{int volatile ___ = 1;(void)input;(void)output;(void)block_aggregate;(void)block_prefix_callback_op;
# 1856
::exit(___);}
#if 0
# 1839
{ 
# 1840
if (ITEMS_PER_THREAD == 1) 
# 1841
{ 
# 1842
InclusiveSum((input)[0], (output)[0], block_aggregate, block_prefix_callback_op); 
# 1843
} else 
# 1845
{ 
# 1847
Sum scan_op; 
# 1848
T thread_partial = ThreadReduce(input, scan_op); 
# 1851
ExclusiveSum(thread_partial, thread_partial, block_aggregate, block_prefix_callback_op); 
# 1854
ThreadScanInclusive(input, output, scan_op, thread_partial); 
# 1855
}  
# 1856
} 
#endif
# 1903 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/block_scan.cuh"
template< class ScanOp> 
# 1904
__attribute((always_inline)) void InclusiveScan(T 
# 1905
input, T &
# 1906
output, ScanOp 
# 1907
scan_op) 
# 1908
{int volatile ___ = 1;(void)input;(void)output;(void)scan_op;
# 1910
::exit(___);}
#if 0
# 1908
{ 
# 1909
(((InternalBlockScan)(temp_storage)).InclusiveScan(input, output, scan_op)); 
# 1910
} 
#endif
# 1952 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/block_scan.cuh"
template< class ScanOp> 
# 1953
__attribute((always_inline)) void InclusiveScan(T 
# 1954
input, T &
# 1955
output, ScanOp 
# 1956
scan_op, T &
# 1957
block_aggregate) 
# 1958
{int volatile ___ = 1;(void)input;(void)output;(void)scan_op;(void)block_aggregate;
# 1960
::exit(___);}
#if 0
# 1958
{ 
# 1959
(((InternalBlockScan)(temp_storage)).InclusiveScan(input, output, scan_op, block_aggregate)); 
# 1960
} 
#endif
# 2041 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/block_scan.cuh"
template< class 
# 2042
ScanOp, class 
# 2043
BlockPrefixCallbackOp> 
# 2044
__attribute((always_inline)) void InclusiveScan(T 
# 2045
input, T &
# 2046
output, ScanOp 
# 2047
scan_op, T &
# 2048
block_aggregate, BlockPrefixCallbackOp &
# 2049
block_prefix_callback_op) 
# 2050
{int volatile ___ = 1;(void)input;(void)output;(void)scan_op;(void)block_aggregate;(void)block_prefix_callback_op;
# 2052
::exit(___);}
#if 0
# 2050
{ 
# 2051
(((InternalBlockScan)(temp_storage)).InclusiveScan(input, output, scan_op, block_aggregate, block_prefix_callback_op)); 
# 2052
} 
#endif
# 2102 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/block_scan.cuh"
template< int 
# 2103
ITEMS_PER_THREAD, class 
# 2104
ScanOp> 
# 2105
__attribute((always_inline)) void InclusiveScan(T (&
# 2106
input)[ITEMS_PER_THREAD], T (&
# 2107
output)[ITEMS_PER_THREAD], ScanOp 
# 2108
scan_op) 
# 2109
{int volatile ___ = 1;(void)input;(void)output;(void)scan_op;
# 2125
::exit(___);}
#if 0
# 2109
{ 
# 2110
if (ITEMS_PER_THREAD == 1) 
# 2111
{ 
# 2112
InclusiveScan((input)[0], (output)[0], scan_op); 
# 2113
} else 
# 2115
{ 
# 2117
T thread_partial = ThreadReduce(input, scan_op); 
# 2120
ExclusiveScan(thread_partial, thread_partial, scan_op); 
# 2123
ThreadScanInclusive(input, output, scan_op, thread_partial, (linear_tid) != 0); 
# 2124
}  
# 2125
} 
#endif
# 2172 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/block_scan.cuh"
template< int 
# 2173
ITEMS_PER_THREAD, class 
# 2174
ScanOp> 
# 2175
__attribute((always_inline)) void InclusiveScan(T (&
# 2176
input)[ITEMS_PER_THREAD], T (&
# 2177
output)[ITEMS_PER_THREAD], ScanOp 
# 2178
scan_op, T &
# 2179
block_aggregate) 
# 2180
{int volatile ___ = 1;(void)input;(void)output;(void)scan_op;(void)block_aggregate;
# 2196
::exit(___);}
#if 0
# 2180
{ 
# 2181
if (ITEMS_PER_THREAD == 1) 
# 2182
{ 
# 2183
InclusiveScan((input)[0], (output)[0], scan_op, block_aggregate); 
# 2184
} else 
# 2186
{ 
# 2188
T thread_partial = ThreadReduce(input, scan_op); 
# 2191
ExclusiveScan(thread_partial, thread_partial, scan_op, block_aggregate); 
# 2194
ThreadScanInclusive(input, output, scan_op, thread_partial, (linear_tid) != 0); 
# 2195
}  
# 2196
} 
#endif
# 2288 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/block_scan.cuh"
template< int 
# 2289
ITEMS_PER_THREAD, class 
# 2290
ScanOp, class 
# 2291
BlockPrefixCallbackOp> 
# 2292
__attribute((always_inline)) void InclusiveScan(T (&
# 2293
input)[ITEMS_PER_THREAD], T (&
# 2294
output)[ITEMS_PER_THREAD], ScanOp 
# 2295
scan_op, T &
# 2296
block_aggregate, BlockPrefixCallbackOp &
# 2297
block_prefix_callback_op) 
# 2298
{int volatile ___ = 1;(void)input;(void)output;(void)scan_op;(void)block_aggregate;(void)block_prefix_callback_op;
# 2314
::exit(___);}
#if 0
# 2298
{ 
# 2299
if (ITEMS_PER_THREAD == 1) 
# 2300
{ 
# 2301
InclusiveScan((input)[0], (output)[0], scan_op, block_aggregate, block_prefix_callback_op); 
# 2302
} else 
# 2304
{ 
# 2306
T thread_partial = ThreadReduce(input, scan_op); 
# 2309
ExclusiveScan(thread_partial, thread_partial, scan_op, block_aggregate, block_prefix_callback_op); 
# 2312
ThreadScanInclusive(input, output, scan_op, thread_partial); 
# 2313
}  
# 2314
} 
#endif
# 2319 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/../block/block_scan.cuh"
}; 
# 2325
}
# 2326
}}}}
# 46 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_radix_rank.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 49
namespace cub_ { 
# 85
template< int 
# 86
BLOCK_DIM_X, int 
# 87
RADIX_BITS, bool 
# 88
DESCENDING, bool 
# 89
MEMOIZE_OUTER_SCAN = false, BlockScanAlgorithm 
# 90
INNER_SCAN_ALGORITHM = BLOCK_SCAN_WARP_SCANS, cudaSharedMemConfig 
# 91
SMEM_CONFIG = cudaSharedMemBankSizeFourByte, int 
# 92
BLOCK_DIM_Y = 1, int 
# 93
BLOCK_DIM_Z = 1, int 
# 94
PTX_ARCH = 0> 
# 95
class BlockRadixRank { 
# 104
typedef unsigned short DigitCounter; 
# 109
typedef typename If< (SMEM_CONFIG) == (cudaSharedMemBankSizeEightByte), unsigned long long, unsigned> ::Type PackedCounter; 
# 112
enum { 
# 114
BLOCK_THREADS = (BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z, 
# 116
RADIX_DIGITS = 1 << RADIX_BITS, 
# 118
LOG_WARP_THREADS = 5, 
# 119
WARP_THREADS = 1 << (5), 
# 120
WARPS = ((((BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z) + (1 << (5))) - 1) / (1 << (5)), 
# 122
BYTES_PER_COUNTER = sizeof(DigitCounter), 
# 123
LOG_BYTES_PER_COUNTER = Log2< sizeof(unsigned short)> ::VALUE, 
# 125
PACKING_RATIO = sizeof(PackedCounter) / sizeof(DigitCounter), 
# 126
LOG_PACKING_RATIO = Log2< sizeof(typename If< (SMEM_CONFIG) == (cudaSharedMemBankSizeEightByte), unsigned long long, unsigned> ::Type) / sizeof(unsigned short)> ::VALUE, 
# 128
LOG_COUNTER_LANES = (0 > (RADIX_BITS - (Log2< sizeof(typename If< (SMEM_CONFIG) == (cudaSharedMemBankSizeEightByte), unsigned long long, unsigned> ::Type) / sizeof(unsigned short)> ::VALUE))) ? 0 : (RADIX_BITS - (Log2< sizeof(typename If< (SMEM_CONFIG) == (cudaSharedMemBankSizeEightByte), unsigned long long, unsigned> ::Type) / sizeof(unsigned short)> ::VALUE)), 
# 129
COUNTER_LANES = 1 << ((0 > (RADIX_BITS - (Log2< sizeof(typename If< (SMEM_CONFIG) == (cudaSharedMemBankSizeEightByte), unsigned long long, unsigned> ::Type) / sizeof(unsigned short)> ::VALUE))) ? 0 : (RADIX_BITS - (Log2< sizeof(typename If< (SMEM_CONFIG) == (cudaSharedMemBankSizeEightByte), unsigned long long, unsigned> ::Type) / sizeof(unsigned short)> ::VALUE))), 
# 132
RAKING_SEGMENT = (1 << ((0 > (RADIX_BITS - (Log2< sizeof(typename If< (SMEM_CONFIG) == (cudaSharedMemBankSizeEightByte), unsigned long long, unsigned> ::Type) / sizeof(unsigned short)> ::VALUE))) ? 0 : (RADIX_BITS - (Log2< sizeof(typename If< (SMEM_CONFIG) == (cudaSharedMemBankSizeEightByte), unsigned long long, unsigned> ::Type) / sizeof(unsigned short)> ::VALUE)))) + 1, 
# 134
LOG_SMEM_BANKS = (PTX_ARCH >= 200) ? 5 : 4, 
# 135
SMEM_BANKS = 1 << ((PTX_ARCH >= 200) ? 5 : 4)
# 136
}; 
# 147
typedef cub_::BlockScan< typename If< (SMEM_CONFIG) == (cudaSharedMemBankSizeEightByte), unsigned long long, unsigned> ::Type, BLOCK_DIM_X, INNER_SCAN_ALGORITHM, BLOCK_DIM_Y, BLOCK_DIM_Z, PTX_ARCH>  BlockScan; 
# 151
struct _TempStorage { 
# 154
typename cub_::BlockScan< typename If< (SMEM_CONFIG) == (cudaSharedMemBankSizeEightByte), unsigned long long, unsigned> ::Type, BLOCK_DIM_X, INNER_SCAN_ALGORITHM, BLOCK_DIM_Y, BLOCK_DIM_Z, PTX_ARCH> ::TempStorage block_scan; 
# 157
union { 
# 158
DigitCounter digit_counters[(COUNTER_LANES) + 1][BLOCK_THREADS][PACKING_RATIO]; 
# 159
PackedCounter raking_grid[BLOCK_THREADS][RAKING_SEGMENT]; 
# 160
}; 
# 161
}; 
# 169
_TempStorage &temp_storage; 
# 172
int linear_tid; 
# 175
PackedCounter cached_segment[RAKING_SEGMENT]; 
# 183
template< int COUNT, int MAX> 
# 184
struct Iterate { 
# 195
template< class UnsignedBits, int KEYS_PER_THREAD> 
# 196
__attribute((always_inline)) static void DecodeKeys(BlockRadixRank &
# 197
cta, UnsignedBits (&
# 198
keys)[KEYS_PER_THREAD], DigitCounter (&
# 199
thread_prefixes)[KEYS_PER_THREAD], DigitCounter *(&
# 200
digit_counters)[KEYS_PER_THREAD], int 
# 201
current_bit, int 
# 202
num_bits) 
# 203
{int volatile ___ = 1;(void)cta;(void)keys;(void)thread_prefixes;(void)digit_counters;(void)current_bit;(void)num_bits;
# 230
::exit(___);}
#if 0
# 203
{ 
# 205
UnsignedBits digit = BFE((keys)[COUNT], current_bit, num_bits); 
# 208
UnsignedBits sub_counter = digit >> (LOG_COUNTER_LANES); 
# 211
UnsignedBits counter_lane = digit & ((COUNTER_LANES) - 1); 
# 213
if (DESCENDING) 
# 214
{ 
# 215
sub_counter = (((PACKING_RATIO) - 1) - sub_counter); 
# 216
counter_lane = (((COUNTER_LANES) - 1) - counter_lane); 
# 217
}  
# 220
((digit_counters)[COUNT]) = (&(((((cta.temp_storage).digit_counters)[counter_lane])[cta.linear_tid])[sub_counter])); 
# 223
((thread_prefixes)[COUNT]) = (*((digit_counters)[COUNT])); 
# 226
(*((digit_counters)[COUNT])) = (((thread_prefixes)[COUNT]) + 1); 
# 229
Iterate< COUNT + 1, MAX> ::DecodeKeys(cta, keys, thread_prefixes, digit_counters, current_bit, num_bits); 
# 230
} 
#endif
# 234 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_radix_rank.cuh"
template< int KEYS_PER_THREAD> 
# 235
__attribute((always_inline)) static void UpdateRanks(int (&
# 236
ranks)[KEYS_PER_THREAD], DigitCounter (&
# 237
thread_prefixes)[KEYS_PER_THREAD], DigitCounter *(&
# 238
digit_counters)[KEYS_PER_THREAD]) 
# 239
{int volatile ___ = 1;(void)ranks;(void)thread_prefixes;(void)digit_counters;
# 245
::exit(___);}
#if 0
# 239
{ 
# 241
((ranks)[COUNT]) = (((thread_prefixes)[COUNT]) + (*((digit_counters)[COUNT]))); 
# 244
Iterate< COUNT + 1, MAX> ::UpdateRanks(ranks, thread_prefixes, digit_counters); 
# 245
} 
#endif
# 246 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_radix_rank.cuh"
}; 
# 250
template< int MAX> 
# 251
struct Iterate< MAX, MAX>  { 
# 254
template< class UnsignedBits, int KEYS_PER_THREAD> 
# 255
__attribute((always_inline)) static void DecodeKeys(BlockRadixRank &
# 256
cta, UnsignedBits (&
# 257
keys)[KEYS_PER_THREAD], DigitCounter (&
# 258
thread_prefixes)[KEYS_PER_THREAD], DigitCounter *(&
# 259
digit_counters)[KEYS_PER_THREAD], int 
# 260
current_bit, int 
# 261
num_bits) 
# 262
{int volatile ___ = 1;(void)cta;(void)keys;(void)thread_prefixes;(void)digit_counters;(void)current_bit;(void)num_bits;::exit(___);}
#if 0
# 262
{ } 
#endif
# 266 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_radix_rank.cuh"
template< int KEYS_PER_THREAD> 
# 267
__attribute((always_inline)) static void UpdateRanks(int (&
# 268
ranks)[KEYS_PER_THREAD], DigitCounter (&
# 269
thread_prefixes)[KEYS_PER_THREAD], DigitCounter *(&
# 270
digit_counters)[KEYS_PER_THREAD]) 
# 271
{int volatile ___ = 1;(void)ranks;(void)thread_prefixes;(void)digit_counters;::exit(___);}
#if 0
# 271
{ } 
#endif
# 272 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_radix_rank.cuh"
}; 
# 282
__attribute((always_inline)) _TempStorage &PrivateStorage() 
# 283
{int volatile ___ = 1;
# 286
::exit(___);}
#if 0
# 283
{ 
# 284
__attribute__((unused)) static _TempStorage private_storage; 
# 285
return private_storage; 
# 286
} 
#endif
# 292 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_radix_rank.cuh"
__attribute((always_inline)) PackedCounter Upsweep() 
# 293
{int volatile ___ = 1;
# 313
::exit(___);}
#if 0
# 293
{ 
# 294
PackedCounter *smem_raking_ptr = ((temp_storage).raking_grid)[linear_tid]; 
# 295
PackedCounter *raking_ptr; 
# 297
if (MEMOIZE_OUTER_SCAN) 
# 298
{ 
# 301
#pragma unroll
for (
# 301
int i = 0; i < (RAKING_SEGMENT); i++) 
# 302
{ 
# 303
((cached_segment)[i]) = (smem_raking_ptr[i]); 
# 304
}  
# 305
raking_ptr = (cached_segment); 
# 306
} else 
# 308
{ 
# 309
raking_ptr = smem_raking_ptr; 
# 310
}  
# 312
return ThreadReduce< RAKING_SEGMENT> (raking_ptr, Sum()); 
# 313
} 
#endif
# 317 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_radix_rank.cuh"
__attribute((always_inline)) void ExclusiveDownsweep(PackedCounter 
# 318
raking_partial) 
# 319
{int volatile ___ = 1;(void)raking_partial;
# 338
::exit(___);}
#if 0
# 319
{ 
# 320
PackedCounter *smem_raking_ptr = ((temp_storage).raking_grid)[linear_tid]; 
# 322
PackedCounter *raking_ptr = MEMOIZE_OUTER_SCAN ? cached_segment : smem_raking_ptr; 
# 327
ThreadScanExclusive< RAKING_SEGMENT> (raking_ptr, raking_ptr, Sum(), raking_partial); 
# 329
if (MEMOIZE_OUTER_SCAN) 
# 330
{ 
# 333
#pragma unroll
for (
# 333
int i = 0; i < (RAKING_SEGMENT); i++) 
# 334
{ 
# 335
(smem_raking_ptr[i]) = ((cached_segment)[i]); 
# 336
}  
# 337
}  
# 338
} 
#endif
# 344 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_radix_rank.cuh"
__attribute((always_inline)) void ResetCounters() 
# 345
{int volatile ___ = 1;
# 352
::exit(___);}
#if 0
# 345
{ 
# 348
#pragma unroll
for (
# 348
int LANE = 0; LANE < ((COUNTER_LANES) + 1); LANE++) 
# 349
{ 
# 350
(*((PackedCounter *)((((temp_storage).digit_counters)[LANE])[linear_tid]))) = 0; 
# 351
}  
# 352
} 
#endif
# 358 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_radix_rank.cuh"
__attribute((always_inline)) void ScanCounters() 
# 359
{int volatile ___ = 1;
# 377
::exit(___);}
#if 0
# 359
{ 
# 361
PackedCounter raking_partial = Upsweep(); 
# 364
PackedCounter exclusive_partial; 
# 365
PackedCounter packed_aggregate; 
# 366
(((BlockScan)(((temp_storage).block_scan))).ExclusiveSum(raking_partial, exclusive_partial, packed_aggregate)); 
# 370
#pragma unroll
for (
# 370
int PACKED = 1; PACKED < (PACKING_RATIO); PACKED++) 
# 371
{ 
# 372
exclusive_partial += (packed_aggregate << ((sizeof(DigitCounter) * (8)) * PACKED)); 
# 373
}  
# 376
ExclusiveDownsweep(exclusive_partial); 
# 377
} 
#endif
# 382 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_radix_rank.cuh"
public: struct TempStorage : public Uninitialized< _TempStorage>  { }; 
# 393
__attribute((always_inline)) BlockRadixRank() : temp_storage(PrivateStorage()), linear_tid(RowMajorTid(BLOCK_DIM_X, BLOCK_DIM_Y, BLOCK_DIM_Z)) 
# 397
{int *volatile ___ = 0;::free(___);}
#if 0
# 397
{ } 
#endif
# 403 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_radix_rank.cuh"
__attribute((always_inline)) BlockRadixRank(TempStorage &
# 404
temp_storage) : temp_storage((temp_storage.Alias())), linear_tid(RowMajorTid(BLOCK_DIM_X, BLOCK_DIM_Y, BLOCK_DIM_Z)) 
# 408
{int *volatile ___ = 0;(void)temp_storage;::free(___);}
#if 0
# 408
{ } 
#endif
# 420 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_radix_rank.cuh"
template< class 
# 421
UnsignedBits, int 
# 422
KEYS_PER_THREAD> 
# 423
__attribute((always_inline)) void RankKeys(UnsignedBits (&
# 424
keys)[KEYS_PER_THREAD], int (&
# 425
ranks)[KEYS_PER_THREAD], int 
# 426
current_bit, int 
# 427
num_bits) 
# 428
{int volatile ___ = 1;(void)keys;(void)ranks;(void)current_bit;(void)num_bits;
# 447
::exit(___);}
#if 0
# 428
{ 
# 429
DigitCounter thread_prefixes[KEYS_PER_THREAD]; 
# 430
DigitCounter *digit_counters[KEYS_PER_THREAD]; 
# 433
ResetCounters(); 
# 436
Iterate< 0, KEYS_PER_THREAD> ::DecodeKeys(*this, keys, thread_prefixes, digit_counters, current_bit, num_bits); 
# 438
__syncthreads(); 
# 441
ScanCounters(); 
# 443
__syncthreads(); 
# 446
Iterate< 0, KEYS_PER_THREAD> ::UpdateRanks(ranks, thread_prefixes, digit_counters); 
# 447
} 
#endif
# 453 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_radix_rank.cuh"
template< class 
# 454
UnsignedBits, int 
# 455
KEYS_PER_THREAD> 
# 456
__attribute((always_inline)) void RankKeys(UnsignedBits (&
# 457
keys)[KEYS_PER_THREAD], int (&
# 458
ranks)[KEYS_PER_THREAD], int 
# 459
current_bit, int 
# 460
num_bits, int &
# 461
inclusive_digit_prefix) 
# 462
{int volatile ___ = 1;(void)keys;(void)ranks;(void)current_bit;(void)num_bits;(void)inclusive_digit_prefix;
# 479
::exit(___);}
#if 0
# 462
{ 
# 464
RankKeys(keys, ranks, current_bit, num_bits); 
# 467
if (((BLOCK_THREADS) == (RADIX_DIGITS)) || ((linear_tid) < (RADIX_DIGITS))) 
# 468
{ 
# 469
int bin_idx = DESCENDING ? ((RADIX_DIGITS) - (linear_tid)) - 1 : (linear_tid); 
# 475
int counter_lane = bin_idx & ((COUNTER_LANES) - 1); 
# 476
int sub_counter = bin_idx >> (LOG_COUNTER_LANES); 
# 477
inclusive_digit_prefix = (((((temp_storage).digit_counters)[counter_lane + 1])[0])[sub_counter]); 
# 478
}  
# 479
} 
#endif
# 480 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_radix_rank.cuh"
}; 
# 482
}
# 483
}}}}
# 45 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_radix_sort.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 48
namespace cub_ { 
# 119
template< class 
# 120
Key, int 
# 121
BLOCK_DIM_X, int 
# 122
ITEMS_PER_THREAD, class 
# 123
Value = NullType, int 
# 124
RADIX_BITS = 4, bool 
# 125
MEMOIZE_OUTER_SCAN = false, BlockScanAlgorithm 
# 126
INNER_SCAN_ALGORITHM = BLOCK_SCAN_WARP_SCANS, cudaSharedMemConfig 
# 127
SMEM_CONFIG = cudaSharedMemBankSizeFourByte, int 
# 128
BLOCK_DIM_Y = 1, int 
# 129
BLOCK_DIM_Z = 1, int 
# 130
PTX_ARCH = 0> 
# 131
class BlockRadixSort { 
# 140
enum { 
# 142
BLOCK_THREADS = (BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z, 
# 145
KEYS_ONLY = Equals< Value, NullType> ::VALUE
# 146
}; 
# 149
typedef NumericTraits< Key>  KeyTraits; 
# 150
typedef typename NumericTraits< Key> ::UnsignedBits UnsignedBits; 
# 163
typedef BlockRadixRank< BLOCK_DIM_X, RADIX_BITS, false, MEMOIZE_OUTER_SCAN, INNER_SCAN_ALGORITHM, SMEM_CONFIG, BLOCK_DIM_Y, BLOCK_DIM_Z, PTX_ARCH>  AscendingBlockRadixRank; 
# 176
typedef BlockRadixRank< BLOCK_DIM_X, RADIX_BITS, true, MEMOIZE_OUTER_SCAN, INNER_SCAN_ALGORITHM, SMEM_CONFIG, BLOCK_DIM_Y, BLOCK_DIM_Z, PTX_ARCH>  DescendingBlockRadixRank; 
# 179
typedef BlockExchange< Key, BLOCK_DIM_X, ITEMS_PER_THREAD, false, BLOCK_DIM_Y, BLOCK_DIM_Z, PTX_ARCH>  BlockExchangeKeys; 
# 182
typedef BlockExchange< Value, BLOCK_DIM_X, ITEMS_PER_THREAD, false, BLOCK_DIM_Y, BLOCK_DIM_Z, PTX_ARCH>  BlockExchangeValues; 
# 185
struct _TempStorage { 
# 188
union { 
# 189
typename BlockRadixRank< BLOCK_DIM_X, RADIX_BITS, false, MEMOIZE_OUTER_SCAN, INNER_SCAN_ALGORITHM, SMEM_CONFIG, BLOCK_DIM_Y, BLOCK_DIM_Z, PTX_ARCH> ::TempStorage asending_ranking_storage; 
# 190
typename BlockRadixRank< BLOCK_DIM_X, RADIX_BITS, true, MEMOIZE_OUTER_SCAN, INNER_SCAN_ALGORITHM, SMEM_CONFIG, BLOCK_DIM_Y, BLOCK_DIM_Z, PTX_ARCH> ::TempStorage descending_ranking_storage; 
# 191
typename BlockExchange< Key, BLOCK_DIM_X, ITEMS_PER_THREAD, false, BLOCK_DIM_Y, BLOCK_DIM_Z, PTX_ARCH> ::TempStorage exchange_keys; 
# 192
typename BlockExchange< Value, BLOCK_DIM_X, ITEMS_PER_THREAD, false, BLOCK_DIM_Y, BLOCK_DIM_Z, PTX_ARCH> ::TempStorage exchange_values; 
# 193
}; 
# 194
}; 
# 202
_TempStorage &temp_storage; 
# 205
int linear_tid; 
# 212
__attribute((always_inline)) _TempStorage &PrivateStorage() 
# 213
{int volatile ___ = 1;
# 216
::exit(___);}
#if 0
# 213
{ 
# 214
__attribute__((unused)) static _TempStorage private_storage; 
# 215
return private_storage; 
# 216
} 
#endif
# 219 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_radix_sort.cuh"
__attribute((always_inline)) void RankKeys(UnsignedBits (&
# 220
unsigned_keys)[ITEMS_PER_THREAD], int (&
# 221
ranks)[ITEMS_PER_THREAD], int 
# 222
begin_bit, int 
# 223
pass_bits, Int2Type< 0>  
# 224
is_descending) 
# 225
{int volatile ___ = 1;(void)unsigned_keys;(void)ranks;(void)begin_bit;(void)pass_bits;(void)is_descending;
# 231
::exit(___);}
#if 0
# 225
{ 
# 226
(((AscendingBlockRadixRank)(((temp_storage).asending_ranking_storage))).RankKeys(unsigned_keys, ranks, begin_bit, pass_bits)); 
# 231
} 
#endif
# 234 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_radix_sort.cuh"
__attribute((always_inline)) void RankKeys(UnsignedBits (&
# 235
unsigned_keys)[ITEMS_PER_THREAD], int (&
# 236
ranks)[ITEMS_PER_THREAD], int 
# 237
begin_bit, int 
# 238
pass_bits, Int2Type< 1>  
# 239
is_descending) 
# 240
{int volatile ___ = 1;(void)unsigned_keys;(void)ranks;(void)begin_bit;(void)pass_bits;(void)is_descending;
# 246
::exit(___);}
#if 0
# 240
{ 
# 241
(((DescendingBlockRadixRank)(((temp_storage).descending_ranking_storage))).RankKeys(unsigned_keys, ranks, begin_bit, pass_bits)); 
# 246
} 
#endif
# 249 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_radix_sort.cuh"
__attribute((always_inline)) void ExchangeValues(Value (&
# 250
values)[ITEMS_PER_THREAD], int (&
# 251
ranks)[ITEMS_PER_THREAD], Int2Type< 0>  
# 252
is_keys_only, Int2Type< 1>  
# 253
is_blocked) 
# 254
{int volatile ___ = 1;(void)values;(void)ranks;(void)is_keys_only;(void)is_blocked;
# 259
::exit(___);}
#if 0
# 254
{ 
# 255
__syncthreads(); 
# 258
(((BlockExchangeValues)(((temp_storage).exchange_values))).ScatterToBlocked(values, ranks)); 
# 259
} 
#endif
# 262 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_radix_sort.cuh"
__attribute((always_inline)) void ExchangeValues(Value (&
# 263
values)[ITEMS_PER_THREAD], int (&
# 264
ranks)[ITEMS_PER_THREAD], Int2Type< 0>  
# 265
is_keys_only, Int2Type< 0>  
# 266
is_blocked) 
# 267
{int volatile ___ = 1;(void)values;(void)ranks;(void)is_keys_only;(void)is_blocked;
# 272
::exit(___);}
#if 0
# 267
{ 
# 268
__syncthreads(); 
# 271
(((BlockExchangeValues)(((temp_storage).exchange_values))).ScatterToStriped(values, ranks)); 
# 272
} 
#endif
# 275 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_radix_sort.cuh"
template< int IS_BLOCKED> 
# 276
__attribute((always_inline)) void ExchangeValues(Value (&
# 277
values)[ITEMS_PER_THREAD], int (&
# 278
ranks)[ITEMS_PER_THREAD], Int2Type< 1>  
# 279
is_keys_only, Int2Type< IS_BLOCKED>  
# 280
is_blocked) 
# 281
{int volatile ___ = 1;(void)values;(void)ranks;(void)is_keys_only;(void)is_blocked;::exit(___);}
#if 0
# 281
{ } 
#endif
# 284 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_radix_sort.cuh"
template< int DESCENDING, int KEYS_ONLY> 
# 285
__attribute((always_inline)) void SortBlocked(Key (&
# 286
keys)[ITEMS_PER_THREAD], Value (&
# 287
values)[ITEMS_PER_THREAD], int 
# 288
begin_bit, int 
# 289
end_bit, Int2Type< DESCENDING>  
# 290
is_descending, Int2Type< KEYS_ONLY>  
# 291
is_keys_only) 
# 292
{int volatile ___ = 1;(void)keys;(void)values;(void)begin_bit;(void)end_bit;(void)is_descending;(void)is_keys_only;
# 333
::exit(___);}
#if 0
# 292
{ 
# 293
UnsignedBits (&unsigned_keys)[ITEMS_PER_THREAD] = reinterpret_cast< UnsignedBits (&)[ITEMS_PER_THREAD]>(keys); 
# 298
#pragma unroll
for (
# 298
int KEY = 0; KEY < ITEMS_PER_THREAD; KEY++) 
# 299
{ 
# 300
((unsigned_keys)[KEY]) = KeyTraits::TwiddleIn((unsigned_keys)[KEY]); 
# 301
}  
# 304
while (true) 
# 305
{ 
# 306
int pass_bits = ((end_bit - begin_bit) < RADIX_BITS) ? end_bit - begin_bit : RADIX_BITS; 
# 309
int ranks[ITEMS_PER_THREAD]; 
# 310
RankKeys(unsigned_keys, ranks, begin_bit, pass_bits, is_descending); 
# 311
begin_bit += RADIX_BITS; 
# 313
__syncthreads(); 
# 316
(((BlockExchangeKeys)(((temp_storage).exchange_keys))).ScatterToBlocked(keys, ranks)); 
# 319
ExchangeValues(values, ranks, is_keys_only, Int2Type< 1> ()); 
# 322
if (begin_bit >= end_bit) { break; }  
# 324
__syncthreads(); 
# 325
}  
# 329
#pragma unroll
for (
# 329
int KEY = 0; KEY < ITEMS_PER_THREAD; KEY++) 
# 330
{ 
# 331
((unsigned_keys)[KEY]) = KeyTraits::TwiddleOut((unsigned_keys)[KEY]); 
# 332
}  
# 333
} 
#endif
# 336 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_radix_sort.cuh"
template< int DESCENDING, int KEYS_ONLY> 
# 337
__attribute((always_inline)) void SortBlockedToStriped(Key (&
# 338
keys)[ITEMS_PER_THREAD], Value (&
# 339
values)[ITEMS_PER_THREAD], int 
# 340
begin_bit, int 
# 341
end_bit, Int2Type< DESCENDING>  
# 342
is_descending, Int2Type< KEYS_ONLY>  
# 343
is_keys_only) 
# 344
{int volatile ___ = 1;(void)keys;(void)values;(void)begin_bit;(void)end_bit;(void)is_descending;(void)is_keys_only;
# 395
::exit(___);}
#if 0
# 344
{ 
# 345
UnsignedBits (&unsigned_keys)[ITEMS_PER_THREAD] = reinterpret_cast< UnsignedBits (&)[ITEMS_PER_THREAD]>(keys); 
# 350
#pragma unroll
for (
# 350
int KEY = 0; KEY < ITEMS_PER_THREAD; KEY++) 
# 351
{ 
# 352
((unsigned_keys)[KEY]) = KeyTraits::TwiddleIn((unsigned_keys)[KEY]); 
# 353
}  
# 356
while (true) 
# 357
{ 
# 358
int pass_bits = ((end_bit - begin_bit) < RADIX_BITS) ? end_bit - begin_bit : RADIX_BITS; 
# 361
int ranks[ITEMS_PER_THREAD]; 
# 362
RankKeys(unsigned_keys, ranks, begin_bit, pass_bits, is_descending); 
# 363
begin_bit += RADIX_BITS; 
# 365
__syncthreads(); 
# 368
if (begin_bit >= end_bit) 
# 369
{ 
# 371
(((BlockExchangeKeys)(((temp_storage).exchange_keys))).ScatterToStriped(keys, ranks)); 
# 374
ExchangeValues(values, ranks, is_keys_only, Int2Type< 0> ()); 
# 377
break; 
# 378
}  
# 381
(((BlockExchangeKeys)(((temp_storage).exchange_keys))).ScatterToBlocked(keys, ranks)); 
# 384
ExchangeValues(values, ranks, is_keys_only, Int2Type< 1> ()); 
# 386
__syncthreads(); 
# 387
}  
# 391
#pragma unroll
for (
# 391
int KEY = 0; KEY < ITEMS_PER_THREAD; KEY++) 
# 392
{ 
# 393
((unsigned_keys)[KEY]) = KeyTraits::TwiddleOut((unsigned_keys)[KEY]); 
# 394
}  
# 395
} 
#endif
# 402 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_radix_sort.cuh"
public: struct TempStorage : public Uninitialized< _TempStorage>  { }; 
# 413
__attribute((always_inline)) BlockRadixSort() : temp_storage(PrivateStorage()), linear_tid(RowMajorTid(BLOCK_DIM_X, BLOCK_DIM_Y, BLOCK_DIM_Z)) 
# 417
{int *volatile ___ = 0;::free(___);}
#if 0
# 417
{ } 
#endif
# 423 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_radix_sort.cuh"
__attribute((always_inline)) BlockRadixSort(TempStorage &
# 424
temp_storage) : temp_storage((temp_storage.Alias())), linear_tid(RowMajorTid(BLOCK_DIM_X, BLOCK_DIM_Y, BLOCK_DIM_Z)) 
# 428
{int *volatile ___ = 0;(void)temp_storage;::free(___);}
#if 0
# 428
{ } 
#endif
# 474 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_radix_sort.cuh"
__attribute((always_inline)) void Sort(Key (&
# 475
keys)[ITEMS_PER_THREAD], int 
# 476
begin_bit = 0, int 
# 477
end_bit = sizeof(Key) * (8)) 
# 478
{int volatile ___ = 1;(void)keys;(void)begin_bit;(void)end_bit;
# 482
::exit(___);}
#if 0
# 478
{ 
# 479
NullType values[ITEMS_PER_THREAD]; 
# 481
SortBlocked(keys, values, begin_bit, end_bit, Int2Type< 0> (), Int2Type< KEYS_ONLY> ()); 
# 482
} 
#endif
# 529 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_radix_sort.cuh"
__attribute((always_inline)) void Sort(Key (&
# 530
keys)[ITEMS_PER_THREAD], Value (&
# 531
values)[ITEMS_PER_THREAD], int 
# 532
begin_bit = 0, int 
# 533
end_bit = sizeof(Key) * (8)) 
# 534
{int volatile ___ = 1;(void)keys;(void)values;(void)begin_bit;(void)end_bit;
# 536
::exit(___);}
#if 0
# 534
{ 
# 535
SortBlocked(keys, values, begin_bit, end_bit, Int2Type< 0> (), Int2Type< KEYS_ONLY> ()); 
# 536
} 
#endif
# 575 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_radix_sort.cuh"
__attribute((always_inline)) void SortDescending(Key (&
# 576
keys)[ITEMS_PER_THREAD], int 
# 577
begin_bit = 0, int 
# 578
end_bit = sizeof(Key) * (8)) 
# 579
{int volatile ___ = 1;(void)keys;(void)begin_bit;(void)end_bit;
# 583
::exit(___);}
#if 0
# 579
{ 
# 580
NullType values[ITEMS_PER_THREAD]; 
# 582
SortBlocked(keys, values, begin_bit, end_bit, Int2Type< 1> (), Int2Type< KEYS_ONLY> ()); 
# 583
} 
#endif
# 630 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_radix_sort.cuh"
__attribute((always_inline)) void SortDescending(Key (&
# 631
keys)[ITEMS_PER_THREAD], Value (&
# 632
values)[ITEMS_PER_THREAD], int 
# 633
begin_bit = 0, int 
# 634
end_bit = sizeof(Key) * (8)) 
# 635
{int volatile ___ = 1;(void)keys;(void)values;(void)begin_bit;(void)end_bit;
# 637
::exit(___);}
#if 0
# 635
{ 
# 636
SortBlocked(keys, values, begin_bit, end_bit, Int2Type< 1> (), Int2Type< KEYS_ONLY> ()); 
# 637
} 
#endif
# 685 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_radix_sort.cuh"
__attribute((always_inline)) void SortBlockedToStriped(Key (&
# 686
keys)[ITEMS_PER_THREAD], int 
# 687
begin_bit = 0, int 
# 688
end_bit = sizeof(Key) * (8)) 
# 689
{int volatile ___ = 1;(void)keys;(void)begin_bit;(void)end_bit;
# 693
::exit(___);}
#if 0
# 689
{ 
# 690
NullType values[ITEMS_PER_THREAD]; 
# 692
SortBlockedToStriped(keys, values, begin_bit, end_bit, Int2Type< 0> (), Int2Type< KEYS_ONLY> ()); 
# 693
} 
#endif
# 740 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_radix_sort.cuh"
__attribute((always_inline)) void SortBlockedToStriped(Key (&
# 741
keys)[ITEMS_PER_THREAD], Value (&
# 742
values)[ITEMS_PER_THREAD], int 
# 743
begin_bit = 0, int 
# 744
end_bit = sizeof(Key) * (8)) 
# 745
{int volatile ___ = 1;(void)keys;(void)values;(void)begin_bit;(void)end_bit;
# 747
::exit(___);}
#if 0
# 745
{ 
# 746
SortBlockedToStriped(keys, values, begin_bit, end_bit, Int2Type< 0> (), Int2Type< KEYS_ONLY> ()); 
# 747
} 
#endif
# 788 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_radix_sort.cuh"
__attribute((always_inline)) void SortDescendingBlockedToStriped(Key (&
# 789
keys)[ITEMS_PER_THREAD], int 
# 790
begin_bit = 0, int 
# 791
end_bit = sizeof(Key) * (8)) 
# 792
{int volatile ___ = 1;(void)keys;(void)begin_bit;(void)end_bit;
# 796
::exit(___);}
#if 0
# 792
{ 
# 793
NullType values[ITEMS_PER_THREAD]; 
# 795
SortBlockedToStriped(keys, values, begin_bit, end_bit, Int2Type< 1> (), Int2Type< KEYS_ONLY> ()); 
# 796
} 
#endif
# 843 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_radix_sort.cuh"
__attribute((always_inline)) void SortDescendingBlockedToStriped(Key (&
# 844
keys)[ITEMS_PER_THREAD], Value (&
# 845
values)[ITEMS_PER_THREAD], int 
# 846
begin_bit = 0, int 
# 847
end_bit = sizeof(Key) * (8)) 
# 848
{int volatile ___ = 1;(void)keys;(void)values;(void)begin_bit;(void)end_bit;
# 850
::exit(___);}
#if 0
# 848
{ 
# 849
SortBlockedToStriped(keys, values, begin_bit, end_bit, Int2Type< 1> (), Int2Type< KEYS_ONLY> ()); 
# 850
} 
#endif
# 855 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_radix_sort.cuh"
}; 
# 861
}
# 862
}}}}
# 41 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_discontinuity.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 44
namespace cub_ { 
# 102
template< class 
# 103
T, int 
# 104
BLOCK_DIM_X, int 
# 105
BLOCK_DIM_Y = 1, int 
# 106
BLOCK_DIM_Z = 1, int 
# 107
PTX_ARCH = 0> 
# 108
class BlockDiscontinuity { 
# 118
enum { 
# 120
BLOCK_THREADS = (BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z
# 121
}; 
# 125
struct _TempStorage { 
# 127
T first_items[BLOCK_THREADS]; 
# 128
T last_items[BLOCK_THREADS]; 
# 129
}; 
# 137
__attribute((always_inline)) _TempStorage &PrivateStorage() 
# 138
{int volatile ___ = 1;
# 141
::exit(___);}
#if 0
# 138
{ 
# 139
__attribute__((unused)) static _TempStorage private_storage; 
# 140
return private_storage; 
# 141
} 
#endif
# 145 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_discontinuity.cuh"
template< class FlagOp, bool HAS_PARAM = BinaryOpHasIdxParam< T, FlagOp> ::HAS_PARAM> 
# 146
struct ApplyOp { 
# 149
__attribute((always_inline)) static bool Flag(FlagOp flag_op, const T &a, const T &b, int idx) 
# 150
{int volatile ___ = 1;(void)flag_op;(void)a;(void)b;(void)idx;
# 152
::exit(___);}
#if 0
# 150
{ 
# 151
return flag_op(a, b, idx); 
# 152
} 
#endif
# 153 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_discontinuity.cuh"
}; 
# 156
template< class FlagOp> 
# 157
struct ApplyOp< FlagOp, false>  { 
# 160
__attribute((always_inline)) static bool Flag(FlagOp flag_op, const T &a, const T &b, int idx) 
# 161
{int volatile ___ = 1;(void)flag_op;(void)a;(void)b;(void)idx;
# 163
::exit(___);}
#if 0
# 161
{ 
# 162
return flag_op(a, b); 
# 163
} 
#endif
# 164 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_discontinuity.cuh"
}; 
# 167
template< int ITERATION, int MAX_ITERATIONS> 
# 168
struct Iterate { 
# 171
template< int 
# 172
ITEMS_PER_THREAD, class 
# 173
FlagT, class 
# 174
FlagOp> 
# 175
__attribute((always_inline)) static void FlagHeads(int 
# 176
linear_tid, FlagT (&
# 177
flags)[ITEMS_PER_THREAD], T (&
# 178
input)[ITEMS_PER_THREAD], FlagOp 
# 179
flag_op) 
# 180
{int volatile ___ = 1;(void)linear_tid;(void)flags;(void)input;(void)flag_op;
# 188
::exit(___);}
#if 0
# 180
{ 
# 181
((flags)[ITERATION]) = ApplyOp< FlagOp> ::Flag(flag_op, (input)[ITERATION - 1], (input)[ITERATION], (linear_tid * ITEMS_PER_THREAD) + ITERATION); 
# 187
Iterate< ITERATION + 1, MAX_ITERATIONS> ::FlagHeads(linear_tid, flags, input, flag_op); 
# 188
} 
#endif
# 191 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_discontinuity.cuh"
template< int 
# 192
ITEMS_PER_THREAD, class 
# 193
FlagT, class 
# 194
FlagOp> 
# 195
__attribute((always_inline)) static void FlagTails(int 
# 196
linear_tid, FlagT (&
# 197
flags)[ITEMS_PER_THREAD], T (&
# 198
input)[ITEMS_PER_THREAD], FlagOp 
# 199
flag_op) 
# 200
{int volatile ___ = 1;(void)linear_tid;(void)flags;(void)input;(void)flag_op;
# 208
::exit(___);}
#if 0
# 200
{ 
# 201
((flags)[ITERATION]) = ApplyOp< FlagOp> ::Flag(flag_op, (input)[ITERATION], (input)[ITERATION + 1], (linear_tid * ITEMS_PER_THREAD) + ITERATION); 
# 207
Iterate< ITERATION + 1, MAX_ITERATIONS> ::FlagTails(linear_tid, flags, input, flag_op); 
# 208
} 
#endif
# 210 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_discontinuity.cuh"
}; 
# 213
template< int MAX_ITERATIONS> 
# 214
struct Iterate< MAX_ITERATIONS, MAX_ITERATIONS>  { 
# 217
template< int 
# 218
ITEMS_PER_THREAD, class 
# 219
FlagT, class 
# 220
FlagOp> 
# 221
__attribute((always_inline)) static void FlagHeads(int 
# 222
linear_tid, FlagT (&
# 223
flags)[ITEMS_PER_THREAD], T (&
# 224
input)[ITEMS_PER_THREAD], FlagOp 
# 225
flag_op) 
# 226
{int volatile ___ = 1;(void)linear_tid;(void)flags;(void)input;(void)flag_op;::exit(___);}
#if 0
# 226
{ } 
#endif
# 229 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_discontinuity.cuh"
template< int 
# 230
ITEMS_PER_THREAD, class 
# 231
FlagT, class 
# 232
FlagOp> 
# 233
__attribute((always_inline)) static void FlagTails(int 
# 234
linear_tid, FlagT (&
# 235
flags)[ITEMS_PER_THREAD], T (&
# 236
input)[ITEMS_PER_THREAD], FlagOp 
# 237
flag_op) 
# 238
{int volatile ___ = 1;(void)linear_tid;(void)flags;(void)input;(void)flag_op;::exit(___);}
#if 0
# 238
{ } 
#endif
# 239 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_discontinuity.cuh"
}; 
# 247
_TempStorage &temp_storage; 
# 250
int linear_tid; 
# 256
public: struct TempStorage : public Uninitialized< _TempStorage>  { }; 
# 267
__attribute((always_inline)) BlockDiscontinuity() : temp_storage(PrivateStorage()), linear_tid(RowMajorTid(BLOCK_DIM_X, BLOCK_DIM_Y, BLOCK_DIM_Z)) 
# 271
{int *volatile ___ = 0;::free(___);}
#if 0
# 271
{ } 
#endif
# 277 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_discontinuity.cuh"
__attribute((always_inline)) BlockDiscontinuity(TempStorage &
# 278
temp_storage) : temp_storage((temp_storage.Alias())), linear_tid(RowMajorTid(BLOCK_DIM_X, BLOCK_DIM_Y, BLOCK_DIM_Z)) 
# 282
{int *volatile ___ = 0;(void)temp_storage;::free(___);}
#if 0
# 282
{ } 
#endif
# 341 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_discontinuity.cuh"
template< int 
# 342
ITEMS_PER_THREAD, class 
# 343
FlagT, class 
# 344
FlagOp> 
# 345
__attribute((always_inline)) void FlagHeads(FlagT (&
# 346
head_flags)[ITEMS_PER_THREAD], T (&
# 347
input)[ITEMS_PER_THREAD], FlagOp 
# 348
flag_op) 
# 349
{int volatile ___ = 1;(void)head_flags;(void)input;(void)flag_op;
# 366
::exit(___);}
#if 0
# 349
{ 
# 351
(((temp_storage).last_items)[linear_tid]) = ((input)[ITEMS_PER_THREAD - 1]); 
# 353
__syncthreads(); 
# 356
((head_flags)[0]) = (((linear_tid) == 0) ? 1 : ApplyOp< FlagOp> ::Flag(flag_op, ((temp_storage).last_items)[(linear_tid) - 1], (input)[0], (linear_tid) * ITEMS_PER_THREAD)); 
# 365
Iterate< 1, ITEMS_PER_THREAD> ::FlagHeads(linear_tid, head_flags, input, flag_op); 
# 366
} 
#endif
# 424 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_discontinuity.cuh"
template< int 
# 425
ITEMS_PER_THREAD, class 
# 426
FlagT, class 
# 427
FlagOp> 
# 428
__attribute((always_inline)) void FlagHeads(FlagT (&
# 429
head_flags)[ITEMS_PER_THREAD], T (&
# 430
input)[ITEMS_PER_THREAD], FlagOp 
# 431
flag_op, T 
# 432
tile_predecessor_item) 
# 433
{int volatile ___ = 1;(void)head_flags;(void)input;(void)flag_op;(void)tile_predecessor_item;
# 452
::exit(___);}
#if 0
# 433
{ 
# 435
(((temp_storage).last_items)[linear_tid]) = ((input)[ITEMS_PER_THREAD - 1]); 
# 437
__syncthreads(); 
# 440
T predecessor_item = ((linear_tid) == 0) ? tile_predecessor_item : (((temp_storage).last_items)[(linear_tid) - 1]); 
# 444
((head_flags)[0]) = ApplyOp< FlagOp> ::Flag(flag_op, predecessor_item, (input)[0], (linear_tid) * ITEMS_PER_THREAD); 
# 451
Iterate< 1, ITEMS_PER_THREAD> ::FlagHeads(linear_tid, head_flags, input, flag_op); 
# 452
} 
#endif
# 512 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_discontinuity.cuh"
template< int 
# 513
ITEMS_PER_THREAD, class 
# 514
FlagT, class 
# 515
FlagOp> 
# 516
__attribute((always_inline)) void FlagTails(FlagT (&
# 517
tail_flags)[ITEMS_PER_THREAD], T (&
# 518
input)[ITEMS_PER_THREAD], FlagOp 
# 519
flag_op) 
# 520
{int volatile ___ = 1;(void)tail_flags;(void)input;(void)flag_op;
# 537
::exit(___);}
#if 0
# 520
{ 
# 522
(((temp_storage).first_items)[linear_tid]) = ((input)[0]); 
# 524
__syncthreads(); 
# 527
((tail_flags)[ITEMS_PER_THREAD - 1]) = (((linear_tid) == ((BLOCK_THREADS) - 1)) ? 1 : ApplyOp< FlagOp> ::Flag(flag_op, (input)[ITEMS_PER_THREAD - 1], ((temp_storage).first_items)[(linear_tid) + 1], ((linear_tid) * ITEMS_PER_THREAD) + (ITEMS_PER_THREAD - 1))); 
# 536
Iterate< 0, ITEMS_PER_THREAD - 1> ::FlagTails(linear_tid, tail_flags, input, flag_op); 
# 537
} 
#endif
# 596 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_discontinuity.cuh"
template< int 
# 597
ITEMS_PER_THREAD, class 
# 598
FlagT, class 
# 599
FlagOp> 
# 600
__attribute((always_inline)) void FlagTails(FlagT (&
# 601
tail_flags)[ITEMS_PER_THREAD], T (&
# 602
input)[ITEMS_PER_THREAD], FlagOp 
# 603
flag_op, T 
# 604
tile_successor_item) 
# 605
{int volatile ___ = 1;(void)tail_flags;(void)input;(void)flag_op;(void)tile_successor_item;
# 624
::exit(___);}
#if 0
# 605
{ 
# 607
(((temp_storage).first_items)[linear_tid]) = ((input)[0]); 
# 609
__syncthreads(); 
# 612
T successor_item = ((linear_tid) == ((BLOCK_THREADS) - 1)) ? tile_successor_item : (((temp_storage).first_items)[(linear_tid) + 1]); 
# 616
((tail_flags)[ITEMS_PER_THREAD - 1]) = ApplyOp< FlagOp> ::Flag(flag_op, (input)[ITEMS_PER_THREAD - 1], successor_item, ((linear_tid) * ITEMS_PER_THREAD) + (ITEMS_PER_THREAD - 1)); 
# 623
Iterate< 0, ITEMS_PER_THREAD - 1> ::FlagTails(linear_tid, tail_flags, input, flag_op); 
# 624
} 
#endif
# 694 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_discontinuity.cuh"
template< int 
# 695
ITEMS_PER_THREAD, class 
# 696
FlagT, class 
# 697
FlagOp> 
# 698
__attribute((always_inline)) void FlagHeadsAndTails(FlagT (&
# 699
head_flags)[ITEMS_PER_THREAD], FlagT (&
# 700
tail_flags)[ITEMS_PER_THREAD], T (&
# 701
input)[ITEMS_PER_THREAD], FlagOp 
# 702
flag_op) 
# 703
{int volatile ___ = 1;(void)head_flags;(void)tail_flags;(void)input;(void)flag_op;
# 733
::exit(___);}
#if 0
# 703
{ 
# 705
(((temp_storage).first_items)[linear_tid]) = ((input)[0]); 
# 706
(((temp_storage).last_items)[linear_tid]) = ((input)[ITEMS_PER_THREAD - 1]); 
# 708
__syncthreads(); 
# 711
((head_flags)[0]) = (((linear_tid) == 0) ? 1 : ApplyOp< FlagOp> ::Flag(flag_op, ((temp_storage).last_items)[(linear_tid) - 1], (input)[0], (linear_tid) * ITEMS_PER_THREAD)); 
# 720
((tail_flags)[ITEMS_PER_THREAD - 1]) = (((linear_tid) == ((BLOCK_THREADS) - 1)) ? 1 : ApplyOp< FlagOp> ::Flag(flag_op, (input)[ITEMS_PER_THREAD - 1], ((temp_storage).first_items)[(linear_tid) + 1], ((linear_tid) * ITEMS_PER_THREAD) + (ITEMS_PER_THREAD - 1))); 
# 729
Iterate< 1, ITEMS_PER_THREAD> ::FlagHeads(linear_tid, head_flags, input, flag_op); 
# 732
Iterate< 0, ITEMS_PER_THREAD - 1> ::FlagTails(linear_tid, tail_flags, input, flag_op); 
# 733
} 
#endif
# 801 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_discontinuity.cuh"
template< int 
# 802
ITEMS_PER_THREAD, class 
# 803
FlagT, class 
# 804
FlagOp> 
# 805
__attribute((always_inline)) void FlagHeadsAndTails(FlagT (&
# 806
head_flags)[ITEMS_PER_THREAD], FlagT (&
# 807
tail_flags)[ITEMS_PER_THREAD], T 
# 808
tile_successor_item, T (&
# 809
input)[ITEMS_PER_THREAD], FlagOp 
# 810
flag_op) 
# 811
{int volatile ___ = 1;(void)head_flags;(void)tail_flags;(void)tile_successor_item;(void)input;(void)flag_op;
# 843
::exit(___);}
#if 0
# 811
{ 
# 813
(((temp_storage).first_items)[linear_tid]) = ((input)[0]); 
# 814
(((temp_storage).last_items)[linear_tid]) = ((input)[ITEMS_PER_THREAD - 1]); 
# 816
__syncthreads(); 
# 819
((head_flags)[0]) = (((linear_tid) == 0) ? 1 : ApplyOp< FlagOp> ::Flag(flag_op, ((temp_storage).last_items)[(linear_tid) - 1], (input)[0], (linear_tid) * ITEMS_PER_THREAD)); 
# 828
T successor_item = ((linear_tid) == ((BLOCK_THREADS) - 1)) ? tile_successor_item : (((temp_storage).first_items)[(linear_tid) + 1]); 
# 832
((tail_flags)[ITEMS_PER_THREAD - 1]) = ApplyOp< FlagOp> ::Flag(flag_op, (input)[ITEMS_PER_THREAD - 1], successor_item, ((linear_tid) * ITEMS_PER_THREAD) + (ITEMS_PER_THREAD - 1)); 
# 839
Iterate< 1, ITEMS_PER_THREAD> ::FlagHeads(linear_tid, head_flags, input, flag_op); 
# 842
Iterate< 0, ITEMS_PER_THREAD - 1> ::FlagTails(linear_tid, tail_flags, input, flag_op); 
# 843
} 
#endif
# 917 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_discontinuity.cuh"
template< int 
# 918
ITEMS_PER_THREAD, class 
# 919
FlagT, class 
# 920
FlagOp> 
# 921
__attribute((always_inline)) void FlagHeadsAndTails(FlagT (&
# 922
head_flags)[ITEMS_PER_THREAD], T 
# 923
tile_predecessor_item, FlagT (&
# 924
tail_flags)[ITEMS_PER_THREAD], T (&
# 925
input)[ITEMS_PER_THREAD], FlagOp 
# 926
flag_op) 
# 927
{int volatile ___ = 1;(void)head_flags;(void)tile_predecessor_item;(void)tail_flags;(void)input;(void)flag_op;
# 959
::exit(___);}
#if 0
# 927
{ 
# 929
(((temp_storage).first_items)[linear_tid]) = ((input)[0]); 
# 930
(((temp_storage).last_items)[linear_tid]) = ((input)[ITEMS_PER_THREAD - 1]); 
# 932
__syncthreads(); 
# 935
T predecessor_item = ((linear_tid) == 0) ? tile_predecessor_item : (((temp_storage).last_items)[(linear_tid) - 1]); 
# 939
((head_flags)[0]) = ApplyOp< FlagOp> ::Flag(flag_op, predecessor_item, (input)[0], (linear_tid) * ITEMS_PER_THREAD); 
# 946
((tail_flags)[ITEMS_PER_THREAD - 1]) = (((linear_tid) == ((BLOCK_THREADS) - 1)) ? 1 : ApplyOp< FlagOp> ::Flag(flag_op, (input)[ITEMS_PER_THREAD - 1], ((temp_storage).first_items)[(linear_tid) + 1], ((linear_tid) * ITEMS_PER_THREAD) + (ITEMS_PER_THREAD - 1))); 
# 955
Iterate< 1, ITEMS_PER_THREAD> ::FlagHeads(linear_tid, head_flags, input, flag_op); 
# 958
Iterate< 0, ITEMS_PER_THREAD - 1> ::FlagTails(linear_tid, tail_flags, input, flag_op); 
# 959
} 
#endif
# 1034 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_discontinuity.cuh"
template< int 
# 1035
ITEMS_PER_THREAD, class 
# 1036
FlagT, class 
# 1037
FlagOp> 
# 1038
__attribute((always_inline)) void FlagHeadsAndTails(FlagT (&
# 1039
head_flags)[ITEMS_PER_THREAD], T 
# 1040
tile_predecessor_item, FlagT (&
# 1041
tail_flags)[ITEMS_PER_THREAD], T 
# 1042
tile_successor_item, T (&
# 1043
input)[ITEMS_PER_THREAD], FlagOp 
# 1044
flag_op) 
# 1045
{int volatile ___ = 1;(void)head_flags;(void)tile_predecessor_item;(void)tail_flags;(void)tile_successor_item;(void)input;(void)flag_op;
# 1079
::exit(___);}
#if 0
# 1045
{ 
# 1047
(((temp_storage).first_items)[linear_tid]) = ((input)[0]); 
# 1048
(((temp_storage).last_items)[linear_tid]) = ((input)[ITEMS_PER_THREAD - 1]); 
# 1050
__syncthreads(); 
# 1053
T predecessor_item = ((linear_tid) == 0) ? tile_predecessor_item : (((temp_storage).last_items)[(linear_tid) - 1]); 
# 1057
((head_flags)[0]) = ApplyOp< FlagOp> ::Flag(flag_op, predecessor_item, (input)[0], (linear_tid) * ITEMS_PER_THREAD); 
# 1064
T successor_item = ((linear_tid) == ((BLOCK_THREADS) - 1)) ? tile_successor_item : (((temp_storage).first_items)[(linear_tid) + 1]); 
# 1068
((tail_flags)[ITEMS_PER_THREAD - 1]) = ApplyOp< FlagOp> ::Flag(flag_op, (input)[ITEMS_PER_THREAD - 1], successor_item, ((linear_tid) * ITEMS_PER_THREAD) + (ITEMS_PER_THREAD - 1)); 
# 1075
Iterate< 1, ITEMS_PER_THREAD> ::FlagHeads(linear_tid, head_flags, input, flag_op); 
# 1078
Iterate< 0, ITEMS_PER_THREAD - 1> ::FlagTails(linear_tid, tail_flags, input, flag_op); 
# 1079
} 
#endif
# 1086 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../block/block_discontinuity.cuh"
}; 
# 1089
}
# 1090
}}}}
# 42 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/block_histogram_sort.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 45
namespace cub_ { 
# 52
template< class 
# 53
T, int 
# 54
BLOCK_DIM_X, int 
# 55
ITEMS_PER_THREAD, int 
# 56
BINS, int 
# 57
BLOCK_DIM_Y, int 
# 58
BLOCK_DIM_Z, int 
# 59
PTX_ARCH> 
# 60
struct BlockHistogramSort { 
# 64
enum { 
# 66
BLOCK_THREADS = (BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z
# 67
}; 
# 82
typedef BlockRadixSort< T, BLOCK_DIM_X, ITEMS_PER_THREAD, NullType, 4, (PTX_ARCH >= 350) ? true : false, BLOCK_SCAN_WARP_SCANS, (PTX_ARCH >= 350) ? cudaSharedMemBankSizeEightByte : cudaSharedMemBankSizeFourByte, BLOCK_DIM_Y, BLOCK_DIM_Z, PTX_ARCH>  BlockRadixSortT; 
# 91
typedef BlockDiscontinuity< T, BLOCK_DIM_X, BLOCK_DIM_Y, BLOCK_DIM_Z, PTX_ARCH>  BlockDiscontinuityT; 
# 94
union _TempStorage { 
# 97
typename BlockRadixSort< T, BLOCK_DIM_X, ITEMS_PER_THREAD, NullType, 4, (PTX_ARCH >= 350) ? true : false, BLOCK_SCAN_WARP_SCANS, (PTX_ARCH >= 350) ? cudaSharedMemBankSizeEightByte : cudaSharedMemBankSizeFourByte, BLOCK_DIM_Y, BLOCK_DIM_Z, PTX_ARCH> ::TempStorage sort; 
# 100
struct { 
# 102
typename BlockDiscontinuity< T, BLOCK_DIM_X, BLOCK_DIM_Y, BLOCK_DIM_Z, PTX_ARCH> ::TempStorage flag; 
# 105
unsigned run_begin[BINS]; 
# 106
unsigned run_end[BINS]; 
# 107
}; 
# 108
}; 
# 112
struct TempStorage : public Uninitialized< _TempStorage>  { }; 
# 116
_TempStorage &temp_storage; 
# 117
int linear_tid; 
# 121
__attribute((always_inline)) BlockHistogramSort(TempStorage &
# 122
temp_storage) : temp_storage((temp_storage.Alias())), linear_tid(RowMajorTid(BLOCK_DIM_X, BLOCK_DIM_Y, BLOCK_DIM_Z)) 
# 126
{int *volatile ___ = 0;(void)temp_storage;::free(___);}
#if 0
# 126
{ } 
#endif
# 130 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/block_histogram_sort.cuh"
struct DiscontinuityOp { 
# 133
_TempStorage &temp_storage; 
# 136
__attribute((always_inline)) DiscontinuityOp(_TempStorage &temp_storage) : temp_storage(temp_storage) 
# 138
{int *volatile ___ = 0;(void)temp_storage;::free(___);}
#if 0
# 138
{ } 
#endif
# 141 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/block_histogram_sort.cuh"
__attribute((always_inline)) bool operator()(const T &a, const T &b, unsigned b_index) 
# 142
{int volatile ___ = 1;(void)a;(void)b;(void)b_index;
# 155
::exit(___);}
#if 0
# 142
{ 
# 143
if (a != b) 
# 144
{ 
# 146
(((temp_storage).run_begin)[b]) = b_index; 
# 147
(((temp_storage).run_end)[a]) = b_index; 
# 149
return true; 
# 150
} else 
# 152
{ 
# 153
return false; 
# 154
}  
# 155
} 
#endif
# 156 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/block_histogram_sort.cuh"
}; 
# 160
template< class 
# 161
HistoCounter> 
# 162
__attribute((always_inline)) void Composite(T (&
# 163
items)[ITEMS_PER_THREAD], HistoCounter 
# 164
histogram[]) 
# 165
{int volatile ___ = 1;(void)items;(void)histogram;
# 220
::exit(___);}
#if 0
# 165
{ 
# 166
enum { TILE_SIZE = ((BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z) * ITEMS_PER_THREAD}; 
# 169
(((BlockRadixSortT)(((temp_storage).sort))).Sort(items)); 
# 171
__syncthreads(); 
# 174
int histo_offset = 0; 
# 177
#pragma unroll
for (; (histo_offset + (BLOCK_THREADS)) <= BINS; histo_offset += (BLOCK_THREADS)) { 
# 179
(((temp_storage).run_begin)[histo_offset + (linear_tid)]) = (TILE_SIZE); 
# 180
(((temp_storage).run_end)[histo_offset + (linear_tid)]) = (TILE_SIZE); 
# 181
}  
# 183
if (((BINS % (BLOCK_THREADS)) != 0) && ((histo_offset + (linear_tid)) < BINS)) 
# 184
{ 
# 185
(((temp_storage).run_begin)[histo_offset + (linear_tid)]) = (TILE_SIZE); 
# 186
(((temp_storage).run_end)[histo_offset + (linear_tid)]) = (TILE_SIZE); 
# 187
}  
# 189
__syncthreads(); 
# 191
int flags[ITEMS_PER_THREAD]; 
# 194
DiscontinuityOp flag_op(temp_storage); 
# 195
(((BlockDiscontinuityT)(((temp_storage).flag))).FlagHeads(flags, items, flag_op)); 
# 198
if ((linear_tid) == 0) { (((temp_storage).run_begin)[(items)[0]]) = 0; }  
# 200
__syncthreads(); 
# 203
histo_offset = 0; 
# 206
#pragma unroll
for (; (histo_offset + (BLOCK_THREADS)) <= BINS; histo_offset += (BLOCK_THREADS)) { 
# 208
int thread_offset = histo_offset + (linear_tid); 
# 209
HistoCounter count = (((temp_storage).run_end)[thread_offset]) - (((temp_storage).run_begin)[thread_offset]); 
# 210
(histogram[thread_offset]) += count; 
# 211
}  
# 214
if (((BINS % (BLOCK_THREADS)) != 0) && ((histo_offset + (linear_tid)) < BINS)) 
# 215
{ 
# 216
int thread_offset = histo_offset + (linear_tid); 
# 217
HistoCounter count = (((temp_storage).run_end)[thread_offset]) - (((temp_storage).run_begin)[thread_offset]); 
# 218
(histogram[thread_offset]) += count; 
# 219
}  
# 220
} 
#endif
# 222 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/block_histogram_sort.cuh"
}; 
# 224
}
# 225
}}}}
# 39 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/block_histogram_atomic.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 42
namespace cub_ { 
# 48
template< int BINS> 
# 49
struct BlockHistogramAtomic { 
# 52
struct TempStorage { }; 
# 56
__attribute((always_inline)) BlockHistogramAtomic(TempStorage &
# 57
temp_storage) 
# 58
{int *volatile ___ = 0;(void)temp_storage;::free(___);}
#if 0
# 58
{ } 
#endif
# 62 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/block_histogram_atomic.cuh"
template< class 
# 63
T, class 
# 64
HistoCounter, int 
# 65
ITEMS_PER_THREAD> 
# 66
__attribute((always_inline)) void Composite(T (&
# 67
items)[ITEMS_PER_THREAD], HistoCounter 
# 68
histogram[]) 
# 69
{int volatile ___ = 1;(void)items;(void)histogram;
# 76
::exit(___);}
#if 0
# 69
{ 
# 72
#pragma unroll
for (
# 72
int i = 0; i < ITEMS_PER_THREAD; ++i) 
# 73
{ 
# 74
atomicAdd(histogram + ((items)[i]), 1); 
# 75
}  
# 76
} 
#endif
# 78 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/block_histogram_atomic.cuh"
}; 
# 80
}
# 81
}}}}
# 43 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_histogram.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 46
namespace cub_ { 
# 56
enum BlockHistogramAlgorithm { 
# 68
BLOCK_HISTO_SORT, 
# 81
BLOCK_HISTO_ATOMIC
# 82
}; 
# 148
template< class 
# 149
T, int 
# 150
BLOCK_DIM_X, int 
# 151
ITEMS_PER_THREAD, int 
# 152
BINS, BlockHistogramAlgorithm 
# 153
ALGORITHM = BLOCK_HISTO_SORT, int 
# 154
BLOCK_DIM_Y = 1, int 
# 155
BLOCK_DIM_Z = 1, int 
# 156
PTX_ARCH = 0> 
# 157
class BlockHistogram { 
# 167
enum { 
# 169
BLOCK_THREADS = (BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z
# 170
}; 
# 178
static const BlockHistogramAlgorithm SAFE_ALGORITHM = ((((ALGORITHM) == (BLOCK_HISTO_ATOMIC)) && (PTX_ARCH < 120)) ? BLOCK_HISTO_SORT : ALGORITHM); 
# 186
typedef typename If< SAFE_ALGORITHM == (BLOCK_HISTO_SORT), BlockHistogramSort< T, BLOCK_DIM_X, ITEMS_PER_THREAD, BINS, BLOCK_DIM_Y, BLOCK_DIM_Z, PTX_ARCH> , BlockHistogramAtomic< BINS> > ::Type InternalBlockHistogram; 
# 189
typedef typename If< SAFE_ALGORITHM == (BLOCK_HISTO_SORT), BlockHistogramSort< T, BLOCK_DIM_X, ITEMS_PER_THREAD, BINS, BLOCK_DIM_Y, BLOCK_DIM_Z, PTX_ARCH> , BlockHistogramAtomic< BINS> > ::Type::TempStorage _TempStorage; 
# 197
_TempStorage &temp_storage; 
# 200
int linear_tid; 
# 208
__attribute((always_inline)) _TempStorage &PrivateStorage() 
# 209
{int volatile ___ = 1;
# 212
::exit(___);}
#if 0
# 209
{ 
# 210
__attribute__((unused)) static _TempStorage private_storage; 
# 211
return private_storage; 
# 212
} 
#endif
# 218 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_histogram.cuh"
public: struct TempStorage : public Uninitialized< typename If< SAFE_ALGORITHM == (BLOCK_HISTO_SORT), BlockHistogramSort< T, BLOCK_DIM_X, ITEMS_PER_THREAD, BINS, BLOCK_DIM_Y, BLOCK_DIM_Z, PTX_ARCH> , BlockHistogramAtomic< BINS> > ::Type::TempStorage>  { }; 
# 229
__attribute((always_inline)) BlockHistogram() : temp_storage(PrivateStorage()), linear_tid(RowMajorTid(BLOCK_DIM_X, BLOCK_DIM_Y, BLOCK_DIM_Z)) 
# 233
{int *volatile ___ = 0;::free(___);}
#if 0
# 233
{ } 
#endif
# 239 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_histogram.cuh"
__attribute((always_inline)) BlockHistogram(TempStorage &
# 240
temp_storage) : temp_storage((temp_storage.Alias())), linear_tid(RowMajorTid(BLOCK_DIM_X, BLOCK_DIM_Y, BLOCK_DIM_Z)) 
# 244
{int *volatile ___ = 0;(void)temp_storage;::free(___);}
#if 0
# 244
{ } 
#endif
# 290 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_histogram.cuh"
template< class HistoCounter> 
# 291
__attribute((always_inline)) void InitHistogram(HistoCounter histogram[]) 
# 292
{int volatile ___ = 1;(void)histogram;
# 306
::exit(___);}
#if 0
# 292
{ 
# 294
int histo_offset = 0; 
# 297
#pragma unroll
for (; (histo_offset + (BLOCK_THREADS)) <= BINS; histo_offset += (BLOCK_THREADS)) { 
# 299
(histogram[histo_offset + (linear_tid)]) = 0; 
# 300
}  
# 302
if (((BINS % (BLOCK_THREADS)) != 0) && ((histo_offset + (linear_tid)) < BINS)) 
# 303
{ 
# 304
(histogram[histo_offset + (linear_tid)]) = 0; 
# 305
}  
# 306
} 
#endif
# 345 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_histogram.cuh"
template< class 
# 346
HistoCounter> 
# 347
__attribute((always_inline)) void Histogram(T (&
# 348
items)[ITEMS_PER_THREAD], HistoCounter 
# 349
histogram[]) 
# 350
{int volatile ___ = 1;(void)items;(void)histogram;
# 358
::exit(___);}
#if 0
# 350
{ 
# 352
InitHistogram(histogram); 
# 354
__syncthreads(); 
# 357
(((InternalBlockHistogram)(temp_storage)).Composite(items, histogram)); 
# 358
} 
#endif
# 402 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_histogram.cuh"
template< class 
# 403
HistoCounter> 
# 404
__attribute((always_inline)) void Composite(T (&
# 405
items)[ITEMS_PER_THREAD], HistoCounter 
# 406
histogram[]) 
# 407
{int volatile ___ = 1;(void)items;(void)histogram;
# 409
::exit(___);}
#if 0
# 407
{ 
# 408
(((InternalBlockHistogram)(temp_storage)).Composite(items, histogram)); 
# 409
} 
#endif
# 411 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_histogram.cuh"
}; 
# 413
}
# 414
}}}}
# 45 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_load.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 48
namespace cub_ { 
# 71
template< class 
# 72
T, int 
# 73
ITEMS_PER_THREAD, class 
# 74
InputIterator> 
# 75
__attribute((always_inline)) __attribute__((unused)) inline void LoadDirectBlocked(int 
# 76
linear_tid, InputIterator 
# 77
block_itr, T (&
# 78
items)[ITEMS_PER_THREAD]) 
# 79
{int volatile ___ = 1;(void)linear_tid;(void)block_itr;(void)items;
# 86
::exit(___);}
#if 0
# 79
{ 
# 82
#pragma unroll
for (
# 82
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 83
{ 
# 84
((items)[ITEM]) = (block_itr[(linear_tid * ITEMS_PER_THREAD) + ITEM]); 
# 85
}  
# 86
} 
#endif
# 98 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_load.cuh"
template< class 
# 99
T, int 
# 100
ITEMS_PER_THREAD, class 
# 101
InputIterator> 
# 102
__attribute((always_inline)) __attribute__((unused)) inline void LoadDirectBlocked(int 
# 103
linear_tid, InputIterator 
# 104
block_itr, T (&
# 105
items)[ITEMS_PER_THREAD], int 
# 106
valid_items) 
# 107
{int volatile ___ = 1;(void)linear_tid;(void)block_itr;(void)items;(void)valid_items;
# 118
::exit(___);}
#if 0
# 107
{ 
# 108
int bounds = valid_items - (linear_tid * ITEMS_PER_THREAD); 
# 111
#pragma unroll
for (
# 111
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 112
{ 
# 113
if (ITEM < bounds) 
# 114
{ 
# 115
((items)[ITEM]) = (block_itr[(linear_tid * ITEMS_PER_THREAD) + ITEM]); 
# 116
}  
# 117
}  
# 118
} 
#endif
# 130 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_load.cuh"
template< class 
# 131
T, int 
# 132
ITEMS_PER_THREAD, class 
# 133
InputIterator> 
# 134
__attribute((always_inline)) __attribute__((unused)) inline void LoadDirectBlocked(int 
# 135
linear_tid, InputIterator 
# 136
block_itr, T (&
# 137
items)[ITEMS_PER_THREAD], int 
# 138
valid_items, T 
# 139
oob_default) 
# 140
{int volatile ___ = 1;(void)linear_tid;(void)block_itr;(void)items;(void)valid_items;(void)oob_default;
# 148
::exit(___);}
#if 0
# 140
{ 
# 142
#pragma unroll
for (
# 142
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 143
{ 
# 144
((items)[ITEM]) = oob_default; 
# 145
}  
# 147
LoadDirectBlocked(linear_tid, block_itr, items, valid_items); 
# 148
} 
#endif
# 165 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_load.cuh"
template< class 
# 166
T, int 
# 167
ITEMS_PER_THREAD> 
# 168
__attribute((always_inline)) __attribute__((unused)) inline void LoadDirectBlockedVectorized(int 
# 169
linear_tid, T *
# 170
block_ptr, T (&
# 171
items)[ITEMS_PER_THREAD]) 
# 172
{int volatile ___ = 1;(void)linear_tid;(void)block_ptr;(void)items;
# 208
::exit(___);}
#if 0
# 172
{ 
# 174
enum { 
# 176
MAX_VEC_SIZE = (ITEMS_PER_THREAD < 4) ? ITEMS_PER_THREAD : 4, 
# 179
VEC_SIZE = ((((((ITEMS_PER_THREAD < 4) ? ITEMS_PER_THREAD : 4) - 1) & ((ITEMS_PER_THREAD < 4) ? ITEMS_PER_THREAD : 4)) == 0) && ((ITEMS_PER_THREAD % ((ITEMS_PER_THREAD < 4) ? ITEMS_PER_THREAD : 4)) == 0)) ? (ITEMS_PER_THREAD < 4) ? ITEMS_PER_THREAD : 4 : 1, 
# 183
VECTORS_PER_THREAD = ITEMS_PER_THREAD / (((((((ITEMS_PER_THREAD < 4) ? ITEMS_PER_THREAD : 4) - 1) & ((ITEMS_PER_THREAD < 4) ? ITEMS_PER_THREAD : 4)) == 0) && ((ITEMS_PER_THREAD % ((ITEMS_PER_THREAD < 4) ? ITEMS_PER_THREAD : 4)) == 0)) ? (ITEMS_PER_THREAD < 4) ? ITEMS_PER_THREAD : 4 : 1)
# 184
}; 
# 187
typedef typename CubVector< T, VEC_SIZE> ::Type Vector; 
# 190
Vector vec_items[VECTORS_PER_THREAD]; 
# 193
Vector *ptr = reinterpret_cast< Vector *>(block_ptr + ((linear_tid * (VEC_SIZE)) * (VECTORS_PER_THREAD))); 
# 197
#pragma unroll
for (
# 197
int ITEM = 0; ITEM < (VECTORS_PER_THREAD); ITEM++) 
# 198
{ 
# 199
((vec_items)[ITEM]) = (ptr[ITEM]); 
# 200
}  
# 204
#pragma unroll
for (
# 204
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 205
{ 
# 206
((items)[ITEM]) = ((reinterpret_cast< T *>(vec_items))[ITEM]); 
# 207
}  
# 208
} 
#endif
# 229 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_load.cuh"
template< int 
# 230
BLOCK_THREADS, class 
# 231
T, int 
# 232
ITEMS_PER_THREAD, class 
# 233
InputIterator> 
# 234
__attribute((always_inline)) __attribute__((unused)) inline void LoadDirectStriped(int 
# 235
linear_tid, InputIterator 
# 236
block_itr, T (&
# 237
items)[ITEMS_PER_THREAD]) 
# 238
{int volatile ___ = 1;(void)linear_tid;(void)block_itr;(void)items;
# 244
::exit(___);}
#if 0
# 238
{ 
# 240
#pragma unroll
for (
# 240
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 241
{ 
# 242
((items)[ITEM]) = (block_itr[(ITEM * BLOCK_THREADS) + linear_tid]); 
# 243
}  
# 244
} 
#endif
# 257 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_load.cuh"
template< int 
# 258
BLOCK_THREADS, class 
# 259
T, int 
# 260
ITEMS_PER_THREAD, class 
# 261
InputIterator> 
# 262
__attribute((always_inline)) __attribute__((unused)) inline void LoadDirectStriped(int 
# 263
linear_tid, InputIterator 
# 264
block_itr, T (&
# 265
items)[ITEMS_PER_THREAD], int 
# 266
valid_items) 
# 267
{int volatile ___ = 1;(void)linear_tid;(void)block_itr;(void)items;(void)valid_items;
# 278
::exit(___);}
#if 0
# 267
{ 
# 268
int bounds = valid_items - linear_tid; 
# 271
#pragma unroll
for (
# 271
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 272
{ 
# 273
if ((ITEM * BLOCK_THREADS) < bounds) 
# 274
{ 
# 275
((items)[ITEM]) = (block_itr[linear_tid + (ITEM * BLOCK_THREADS)]); 
# 276
}  
# 277
}  
# 278
} 
#endif
# 291 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_load.cuh"
template< int 
# 292
BLOCK_THREADS, class 
# 293
T, int 
# 294
ITEMS_PER_THREAD, class 
# 295
InputIterator> 
# 296
__attribute((always_inline)) __attribute__((unused)) inline void LoadDirectStriped(int 
# 297
linear_tid, InputIterator 
# 298
block_itr, T (&
# 299
items)[ITEMS_PER_THREAD], int 
# 300
valid_items, T 
# 301
oob_default) 
# 302
{int volatile ___ = 1;(void)linear_tid;(void)block_itr;(void)items;(void)valid_items;(void)oob_default;
# 310
::exit(___);}
#if 0
# 302
{ 
# 304
#pragma unroll
for (
# 304
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 305
{ 
# 306
((items)[ITEM]) = oob_default; 
# 307
}  
# 309
LoadDirectStriped< BLOCK_THREADS> (linear_tid, block_itr, items, valid_items); 
# 310
} 
#endif
# 333 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_load.cuh"
template< class 
# 334
T, int 
# 335
ITEMS_PER_THREAD, class 
# 336
InputIterator> 
# 337
__attribute((always_inline)) __attribute__((unused)) inline void LoadDirectWarpStriped(int 
# 338
linear_tid, InputIterator 
# 339
block_itr, T (&
# 340
items)[ITEMS_PER_THREAD]) 
# 341
{int volatile ___ = 1;(void)linear_tid;(void)block_itr;(void)items;
# 352
::exit(___);}
#if 0
# 341
{ 
# 342
int tid = linear_tid & ((1 << 5) - 1); 
# 343
int wid = linear_tid >> 5; 
# 344
int warp_offset = (wid * (1 << 5)) * ITEMS_PER_THREAD; 
# 348
#pragma unroll
for (
# 348
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 349
{ 
# 350
((items)[ITEM]) = (block_itr[(warp_offset + tid) + (ITEM * (1 << 5))]); 
# 351
}  
# 352
} 
#endif
# 367 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_load.cuh"
template< class 
# 368
T, int 
# 369
ITEMS_PER_THREAD, class 
# 370
InputIterator> 
# 371
__attribute((always_inline)) __attribute__((unused)) inline void LoadDirectWarpStriped(int 
# 372
linear_tid, InputIterator 
# 373
block_itr, T (&
# 374
items)[ITEMS_PER_THREAD], int 
# 375
valid_items) 
# 376
{int volatile ___ = 1;(void)linear_tid;(void)block_itr;(void)items;(void)valid_items;
# 391
::exit(___);}
#if 0
# 376
{ 
# 377
int tid = linear_tid & ((1 << 5) - 1); 
# 378
int wid = linear_tid >> 5; 
# 379
int warp_offset = (wid * (1 << 5)) * ITEMS_PER_THREAD; 
# 380
int bounds = (valid_items - warp_offset) - tid; 
# 384
#pragma unroll
for (
# 384
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 385
{ 
# 386
if ((ITEM * (1 << 5)) < bounds) 
# 387
{ 
# 388
((items)[ITEM]) = (block_itr[(warp_offset + tid) + (ITEM * (1 << 5))]); 
# 389
}  
# 390
}  
# 391
} 
#endif
# 406 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_load.cuh"
template< class 
# 407
T, int 
# 408
ITEMS_PER_THREAD, class 
# 409
InputIterator> 
# 410
__attribute((always_inline)) __attribute__((unused)) inline void LoadDirectWarpStriped(int 
# 411
linear_tid, InputIterator 
# 412
block_itr, T (&
# 413
items)[ITEMS_PER_THREAD], int 
# 414
valid_items, T 
# 415
oob_default) 
# 416
{int volatile ___ = 1;(void)linear_tid;(void)block_itr;(void)items;(void)valid_items;(void)oob_default;
# 424
::exit(___);}
#if 0
# 416
{ 
# 418
#pragma unroll
for (
# 418
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 419
{ 
# 420
((items)[ITEM]) = oob_default; 
# 421
}  
# 423
LoadDirectWarpStriped(linear_tid, block_itr, items, valid_items); 
# 424
} 
#endif
# 440 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_load.cuh"
enum BlockLoadAlgorithm { 
# 453
BLOCK_LOAD_DIRECT, 
# 475
BLOCK_LOAD_VECTORIZE, 
# 494
BLOCK_LOAD_TRANSPOSE, 
# 517
BLOCK_LOAD_WARP_TRANSPOSE
# 518
}; 
# 584
template< class 
# 585
InputIterator, int 
# 586
BLOCK_DIM_X, int 
# 587
ITEMS_PER_THREAD, BlockLoadAlgorithm 
# 588
ALGORITHM = BLOCK_LOAD_DIRECT, bool 
# 589
WARP_TIME_SLICING = false, int 
# 590
BLOCK_DIM_Y = 1, int 
# 591
BLOCK_DIM_Z = 1, int 
# 592
PTX_ARCH = 0> 
# 593
class BlockLoad { 
# 603
enum { 
# 605
BLOCK_THREADS = (BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z
# 606
}; 
# 609
typedef typename std::iterator_traits< InputIterator> ::value_type T; 
# 617
template< BlockLoadAlgorithm _POLICY, int DUMMY> struct LoadInternal; 
# 624
template< int DUMMY> 
# 625
struct LoadInternal< BLOCK_LOAD_DIRECT, DUMMY>  { 
# 628
typedef NullType TempStorage; 
# 631
int linear_tid; 
# 634
__attribute((always_inline)) LoadInternal(TempStorage &
# 635
temp_storage, int 
# 636
linear_tid) : linear_tid(linear_tid) 
# 639
{int *volatile ___ = 0;(void)temp_storage;(void)linear_tid;::free(___);}
#if 0
# 639
{ } 
#endif
# 642 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_load.cuh"
__attribute((always_inline)) void Load(InputIterator 
# 643
block_itr, T (&
# 644
items)[ITEMS_PER_THREAD]) 
# 645
{int volatile ___ = 1;(void)block_itr;(void)items;
# 647
::exit(___);}
#if 0
# 645
{ 
# 646
LoadDirectBlocked(linear_tid, block_itr, items); 
# 647
} 
#endif
# 650 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_load.cuh"
__attribute((always_inline)) void Load(InputIterator 
# 651
block_itr, T (&
# 652
items)[ITEMS_PER_THREAD], int 
# 653
valid_items) 
# 654
{int volatile ___ = 1;(void)block_itr;(void)items;(void)valid_items;
# 656
::exit(___);}
#if 0
# 654
{ 
# 655
LoadDirectBlocked(linear_tid, block_itr, items, valid_items); 
# 656
} 
#endif
# 659 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_load.cuh"
__attribute((always_inline)) void Load(InputIterator 
# 660
block_itr, T (&
# 661
items)[ITEMS_PER_THREAD], int 
# 662
valid_items, T 
# 663
oob_default) 
# 664
{int volatile ___ = 1;(void)block_itr;(void)items;(void)valid_items;(void)oob_default;
# 666
::exit(___);}
#if 0
# 664
{ 
# 665
LoadDirectBlocked(linear_tid, block_itr, items, valid_items, oob_default); 
# 666
} 
#endif
# 668 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_load.cuh"
}; 
# 674
template< int DUMMY> 
# 675
struct LoadInternal< BLOCK_LOAD_VECTORIZE, DUMMY>  { 
# 678
typedef NullType TempStorage; 
# 681
int linear_tid; 
# 684
__attribute((always_inline)) LoadInternal(TempStorage &
# 685
temp_storage, int 
# 686
linear_tid) : linear_tid(linear_tid) 
# 689
{int *volatile ___ = 0;(void)temp_storage;(void)linear_tid;::free(___);}
#if 0
# 689
{ } 
#endif
# 692 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_load.cuh"
__attribute((always_inline)) void Load(T *
# 693
block_ptr, T (&
# 694
items)[ITEMS_PER_THREAD]) 
# 695
{int volatile ___ = 1;(void)block_ptr;(void)items;
# 697
::exit(___);}
#if 0
# 695
{ 
# 696
LoadDirectBlockedVectorized(linear_tid, block_ptr, items); 
# 697
} 
#endif
# 700 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_load.cuh"
template< class 
# 701
T, class 
# 702
_InputIterator> 
# 703
__attribute((always_inline)) void Load(_InputIterator 
# 704
block_itr, T (&
# 705
items)[ITEMS_PER_THREAD]) 
# 706
{int volatile ___ = 1;(void)block_itr;(void)items;
# 708
::exit(___);}
#if 0
# 706
{ 
# 707
LoadDirectBlocked(linear_tid, block_itr, items); 
# 708
} 
#endif
# 711 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_load.cuh"
__attribute((always_inline)) void Load(InputIterator 
# 712
block_itr, T (&
# 713
items)[ITEMS_PER_THREAD], int 
# 714
valid_items) 
# 715
{int volatile ___ = 1;(void)block_itr;(void)items;(void)valid_items;
# 717
::exit(___);}
#if 0
# 715
{ 
# 716
LoadDirectBlocked(linear_tid, block_itr, items, valid_items); 
# 717
} 
#endif
# 720 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_load.cuh"
__attribute((always_inline)) void Load(InputIterator 
# 721
block_itr, T (&
# 722
items)[ITEMS_PER_THREAD], int 
# 723
valid_items, T 
# 724
oob_default) 
# 725
{int volatile ___ = 1;(void)block_itr;(void)items;(void)valid_items;(void)oob_default;
# 727
::exit(___);}
#if 0
# 725
{ 
# 726
LoadDirectBlocked(linear_tid, block_itr, items, valid_items, oob_default); 
# 727
} 
#endif
# 729 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_load.cuh"
}; 
# 735
template< int DUMMY> 
# 736
struct LoadInternal< BLOCK_LOAD_TRANSPOSE, DUMMY>  { 
# 739
typedef cub_::BlockExchange< typename std::iterator_traits< InputIterator> ::value_type, BLOCK_DIM_X, ITEMS_PER_THREAD, WARP_TIME_SLICING, BLOCK_DIM_Y, BLOCK_DIM_Z, PTX_ARCH>  BlockExchange; 
# 742
typedef typename cub_::BlockExchange< typename std::iterator_traits< InputIterator> ::value_type, BLOCK_DIM_X, ITEMS_PER_THREAD, WARP_TIME_SLICING, BLOCK_DIM_Y, BLOCK_DIM_Z, PTX_ARCH> ::TempStorage _TempStorage; 
# 745
struct TempStorage : public Uninitialized< typename cub_::BlockExchange< typename std::iterator_traits< InputIterator> ::value_type, BLOCK_DIM_X, ITEMS_PER_THREAD, WARP_TIME_SLICING, BLOCK_DIM_Y, BLOCK_DIM_Z, PTX_ARCH> ::TempStorage>  { }; 
# 748
_TempStorage &temp_storage; 
# 751
int linear_tid; 
# 754
__attribute((always_inline)) LoadInternal(TempStorage &
# 755
temp_storage, int 
# 756
linear_tid) : temp_storage((temp_storage.Alias())), linear_tid(linear_tid) 
# 760
{int *volatile ___ = 0;(void)temp_storage;(void)linear_tid;::free(___);}
#if 0
# 760
{ } 
#endif
# 763 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_load.cuh"
__attribute((always_inline)) void Load(InputIterator 
# 764
block_itr, T (&
# 765
items)[ITEMS_PER_THREAD]) 
# 766
{int volatile ___ = 1;(void)block_itr;(void)items;
# 769
::exit(___);}
#if 0
# 766
{ 
# 767
LoadDirectStriped< BLOCK_THREADS> (linear_tid, block_itr, items); 
# 768
(((BlockExchange)(temp_storage)).StripedToBlocked(items)); 
# 769
} 
#endif
# 772 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_load.cuh"
__attribute((always_inline)) void Load(InputIterator 
# 773
block_itr, T (&
# 774
items)[ITEMS_PER_THREAD], int 
# 775
valid_items) 
# 776
{int volatile ___ = 1;(void)block_itr;(void)items;(void)valid_items;
# 779
::exit(___);}
#if 0
# 776
{ 
# 777
LoadDirectStriped< BLOCK_THREADS> (linear_tid, block_itr, items, valid_items); 
# 778
(((BlockExchange)(temp_storage)).StripedToBlocked(items)); 
# 779
} 
#endif
# 782 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_load.cuh"
__attribute((always_inline)) void Load(InputIterator 
# 783
block_itr, T (&
# 784
items)[ITEMS_PER_THREAD], int 
# 785
valid_items, T 
# 786
oob_default) 
# 787
{int volatile ___ = 1;(void)block_itr;(void)items;(void)valid_items;(void)oob_default;
# 790
::exit(___);}
#if 0
# 787
{ 
# 788
LoadDirectStriped< BLOCK_THREADS> (linear_tid, block_itr, items, valid_items, oob_default); 
# 789
(((BlockExchange)(temp_storage)).StripedToBlocked(items)); 
# 790
} 
#endif
# 792 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_load.cuh"
}; 
# 798
template< int DUMMY> 
# 799
struct LoadInternal< BLOCK_LOAD_WARP_TRANSPOSE, DUMMY>  { 
# 802
enum { 
# 803
WARP_THREADS = 1 << 5
# 804
}; 
# 807
typedef int cub_static_assert807[(((BLOCK_THREADS) % (WARP_THREADS)) == 0) ? 1 : (-1)]; 
# 810
typedef cub_::BlockExchange< typename std::iterator_traits< InputIterator> ::value_type, BLOCK_DIM_X, ITEMS_PER_THREAD, WARP_TIME_SLICING, BLOCK_DIM_Y, BLOCK_DIM_Z, PTX_ARCH>  BlockExchange; 
# 813
typedef typename cub_::BlockExchange< typename std::iterator_traits< InputIterator> ::value_type, BLOCK_DIM_X, ITEMS_PER_THREAD, WARP_TIME_SLICING, BLOCK_DIM_Y, BLOCK_DIM_Z, PTX_ARCH> ::TempStorage _TempStorage; 
# 816
struct TempStorage : public Uninitialized< typename cub_::BlockExchange< typename std::iterator_traits< InputIterator> ::value_type, BLOCK_DIM_X, ITEMS_PER_THREAD, WARP_TIME_SLICING, BLOCK_DIM_Y, BLOCK_DIM_Z, PTX_ARCH> ::TempStorage>  { }; 
# 819
_TempStorage &temp_storage; 
# 822
int linear_tid; 
# 825
__attribute((always_inline)) LoadInternal(TempStorage &
# 826
temp_storage, int 
# 827
linear_tid) : temp_storage((temp_storage.Alias())), linear_tid(linear_tid) 
# 831
{int *volatile ___ = 0;(void)temp_storage;(void)linear_tid;::free(___);}
#if 0
# 831
{ } 
#endif
# 834 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_load.cuh"
__attribute((always_inline)) void Load(InputIterator 
# 835
block_itr, T (&
# 836
items)[ITEMS_PER_THREAD]) 
# 837
{int volatile ___ = 1;(void)block_itr;(void)items;
# 840
::exit(___);}
#if 0
# 837
{ 
# 838
LoadDirectWarpStriped(linear_tid, block_itr, items); 
# 839
(((BlockExchange)(temp_storage)).WarpStripedToBlocked(items)); 
# 840
} 
#endif
# 843 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_load.cuh"
__attribute((always_inline)) void Load(InputIterator 
# 844
block_itr, T (&
# 845
items)[ITEMS_PER_THREAD], int 
# 846
valid_items) 
# 847
{int volatile ___ = 1;(void)block_itr;(void)items;(void)valid_items;
# 850
::exit(___);}
#if 0
# 847
{ 
# 848
LoadDirectWarpStriped(linear_tid, block_itr, items, valid_items); 
# 849
(((BlockExchange)(temp_storage)).WarpStripedToBlocked(items)); 
# 850
} 
#endif
# 854 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_load.cuh"
__attribute((always_inline)) void Load(InputIterator 
# 855
block_itr, T (&
# 856
items)[ITEMS_PER_THREAD], int 
# 857
valid_items, T 
# 858
oob_default) 
# 859
{int volatile ___ = 1;(void)block_itr;(void)items;(void)valid_items;(void)oob_default;
# 862
::exit(___);}
#if 0
# 859
{ 
# 860
LoadDirectWarpStriped(linear_tid, block_itr, items, valid_items, oob_default); 
# 861
(((BlockExchange)(temp_storage)).WarpStripedToBlocked(items)); 
# 862
} 
#endif
# 863 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_load.cuh"
}; 
# 871
typedef LoadInternal< ALGORITHM, 0>  InternalLoad; 
# 875
typedef typename LoadInternal< ALGORITHM, 0> ::TempStorage _TempStorage; 
# 883
__attribute((always_inline)) _TempStorage &PrivateStorage() 
# 884
{int volatile ___ = 1;
# 887
::exit(___);}
#if 0
# 884
{ 
# 885
__attribute__((unused)) static _TempStorage private_storage; 
# 886
return private_storage; 
# 887
} 
#endif
# 895 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_load.cuh"
_TempStorage &temp_storage; 
# 898
int linear_tid; 
# 903
public: struct TempStorage : public Uninitialized< typename LoadInternal< ALGORITHM, 0> ::TempStorage>  { }; 
# 914
__attribute((always_inline)) BlockLoad() : temp_storage(PrivateStorage()), linear_tid(RowMajorTid(BLOCK_DIM_X, BLOCK_DIM_Y, BLOCK_DIM_Z)) 
# 918
{int *volatile ___ = 0;::free(___);}
#if 0
# 918
{ } 
#endif
# 924 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_load.cuh"
__attribute((always_inline)) BlockLoad(TempStorage &
# 925
temp_storage) : temp_storage((temp_storage.Alias())), linear_tid(RowMajorTid(BLOCK_DIM_X, BLOCK_DIM_Y, BLOCK_DIM_Z)) 
# 929
{int *volatile ___ = 0;(void)temp_storage;::free(___);}
#if 0
# 929
{ } 
#endif
# 977 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_load.cuh"
__attribute((always_inline)) void Load(InputIterator 
# 978
block_itr, T (&
# 979
items)[ITEMS_PER_THREAD]) 
# 980
{int volatile ___ = 1;(void)block_itr;(void)items;
# 982
::exit(___);}
#if 0
# 980
{ 
# 981
(InternalLoad(temp_storage, linear_tid).Load(block_itr, items)); 
# 982
} 
#endif
# 1022 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_load.cuh"
__attribute((always_inline)) void Load(InputIterator 
# 1023
block_itr, T (&
# 1024
items)[ITEMS_PER_THREAD], int 
# 1025
valid_items) 
# 1026
{int volatile ___ = 1;(void)block_itr;(void)items;(void)valid_items;
# 1028
::exit(___);}
#if 0
# 1026
{ 
# 1027
(InternalLoad(temp_storage, linear_tid).Load(block_itr, items, valid_items)); 
# 1028
} 
#endif
# 1069 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_load.cuh"
__attribute((always_inline)) void Load(InputIterator 
# 1070
block_itr, T (&
# 1071
items)[ITEMS_PER_THREAD], int 
# 1072
valid_items, T 
# 1073
oob_default) 
# 1074
{int volatile ___ = 1;(void)block_itr;(void)items;(void)valid_items;(void)oob_default;
# 1076
::exit(___);}
#if 0
# 1074
{ 
# 1075
(InternalLoad(temp_storage, linear_tid).Load(block_itr, items, valid_items, oob_default)); 
# 1076
} 
#endif
# 1081 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_load.cuh"
}; 
# 1084
}
# 1085
}}}}
# 44 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../warp/specializations/../../util_debug.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 47
namespace cub_ { 
# 68
__attribute((always_inline)) inline cudaError_t Debug(cudaError_t 
# 69
error, const char *
# 70
filename, int 
# 71
line) 
# 72
{ 
# 84
return error; 
# 85
} 
# 114
}
# 115
}}}}
# 44 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../warp/specializations/warp_reduce_shfl.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 47
namespace cub_ { 
# 53
template< class 
# 54
T, int 
# 55
LOGICAL_WARP_THREADS, int 
# 56
PTX_ARCH> 
# 57
struct WarpReduceShfl { 
# 64
enum { 
# 66
IS_ARCH_WARP = LOGICAL_WARP_THREADS == (1 << 5), 
# 69
STEPS = Log2< LOGICAL_WARP_THREADS> ::VALUE, 
# 72
LOGICAL_WARPS = (1 << 5) / LOGICAL_WARP_THREADS
# 73
}; 
# 75
template< class S> 
# 76
struct IsInteger { 
# 78
enum { 
# 80
IS_INTEGER = (Traits< S> ::CATEGORY == UNSIGNED_INTEGER) || (Traits< S> ::CATEGORY == SIGNED_INTEGER), 
# 83
IS_SMALL_INTEGER = ((Traits< S> ::CATEGORY == UNSIGNED_INTEGER) || (Traits< S> ::CATEGORY == SIGNED_INTEGER)) && (sizeof(S) <= sizeof(unsigned))
# 84
}; 
# 85
}; 
# 89
template< int WARP, int WARPS> 
# 90
struct LastLaneMask { 
# 92
enum { 
# 93
BASE_MASK = 1 << (LOGICAL_WARP_THREADS - 1), 
# 94
MASK = (LastLaneMask< WARP + 1, WARPS> ::MASK << LOGICAL_WARP_THREADS) | (1 << (LOGICAL_WARP_THREADS - 1))
# 95
}; 
# 96
}; 
# 99
template< int WARP> 
# 100
struct LastLaneMask< WARP, WARP>  { 
# 102
enum { 
# 103
MASK = 1 << (LOGICAL_WARP_THREADS - 1)
# 104
}; 
# 105
}; 
# 110
typedef NullType TempStorage; 
# 117
int lane_id; 
# 125
__attribute((always_inline)) WarpReduceShfl(TempStorage &
# 126
temp_storage) : lane_id(LaneId()) 
# 129
{int *volatile ___ = 0;(void)temp_storage;::free(___);}
#if 0
# 129
{ } 
#endif
# 137 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../warp/specializations/warp_reduce_shfl.cuh"
__attribute((always_inline)) unsigned ReduceStep(unsigned 
# 138
input, Sum 
# 139
reduction_op, int 
# 140
last_lane, int 
# 141
offset) 
# 142
{int volatile ___ = 1;(void)input;(void)reduction_op;(void)last_lane;(void)offset;
# 157
::exit(___);}
#if 0
# 142
{ 
# 143
unsigned output; 
# 146
__asm__("{  .reg .u32 r0;  .reg .pred p;  shfl.down.b32 r0|p, %1, %2, %3;  @p add.u32 r0, r0, %4;  mov.u32 %0, r0;}" : "=r" (output) : "r" (input), "r" (offset), "r" (last_lane), "r" (input)); 
# 156
return output; 
# 157
} 
#endif
# 161 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../warp/specializations/warp_reduce_shfl.cuh"
__attribute((always_inline)) float ReduceStep(float 
# 162
input, Sum 
# 163
reduction_op, int 
# 164
last_lane, int 
# 165
offset) 
# 166
{int volatile ___ = 1;(void)input;(void)reduction_op;(void)last_lane;(void)offset;
# 181
::exit(___);}
#if 0
# 166
{ 
# 167
float output; 
# 170
__asm__("{  .reg .f32 r0;  .reg .pred p;  shfl.down.b32 r0|p, %1, %2, %3;  @p add.f32 r0, r0, %4;  mov.f32 %0, r0;}" : "=f" (output) : "f" (input), "r" (offset), "r" (last_lane), "f" (input)); 
# 180
return output; 
# 181
} 
#endif
# 185 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../warp/specializations/warp_reduce_shfl.cuh"
__attribute((always_inline)) unsigned long long ReduceStep(unsigned long long 
# 186
input, Sum 
# 187
reduction_op, int 
# 188
last_lane, int 
# 189
offset) 
# 190
{int volatile ___ = 1;(void)input;(void)reduction_op;(void)last_lane;(void)offset;
# 207
::exit(___);}
#if 0
# 190
{ 
# 191
unsigned long long output; 
# 193
__asm__("{  .reg .u32 lo;  .reg .u32 hi;  .reg .pred p;  mov.b64 {lo, hi}, %1;  shfl.down.b32 lo|p, lo, %2, %3;  shfl.down.b32 hi|p, hi, " "%2, %3;  mov.b64 %0, {lo, hi};  @p add.u64 %0, %0, %1;}" : "=l" (output) : "l" (input), "r" (offset), "r" (last_lane)); 
# 206
return output; 
# 207
} 
#endif
# 211 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../warp/specializations/warp_reduce_shfl.cuh"
__attribute((always_inline)) long long ReduceStep(long long 
# 212
input, Sum 
# 213
reduction_op, int 
# 214
last_lane, int 
# 215
offset) 
# 216
{int volatile ___ = 1;(void)input;(void)reduction_op;(void)last_lane;(void)offset;
# 234
::exit(___);}
#if 0
# 216
{ 
# 217
long long output; 
# 220
__asm__("{  .reg .u32 lo;  .reg .u32 hi;  .reg .pred p;  mov.b64 {lo, hi}, %1;  shfl.down.b32 lo|p, lo, %2, %3;  shfl.down.b32 hi|p, hi, " "%2, %3;  mov.b64 %0, {lo, hi};  @p add.s64 %0, %0, %1;}" : "=l" (output) : "l" (input), "r" (offset), "r" (last_lane)); 
# 233
return output; 
# 234
} 
#endif
# 238 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../warp/specializations/warp_reduce_shfl.cuh"
__attribute((always_inline)) double ReduceStep(double 
# 239
input, Sum 
# 240
reduction_op, int 
# 241
last_lane, int 
# 242
offset) 
# 243
{int volatile ___ = 1;(void)input;(void)reduction_op;(void)last_lane;(void)offset;
# 261
::exit(___);}
#if 0
# 243
{ 
# 244
double output; 
# 247
__asm__("{  .reg .u32 lo;  .reg .u32 hi;  .reg .pred p;  mov.b64 {lo, hi}, %1;  shfl.down.b32 lo|p, lo, %2, %3;  shfl.down.b32 hi|p, hi, " "%2, %3;  mov.b64 %0, {lo, hi};  @p add.f64 %0, %0, %1;}" : "=d" (output) : "d" (input), "r" (offset), "r" (last_lane)); 
# 260
return output; 
# 261
} 
#endif
# 265 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../warp/specializations/warp_reduce_shfl.cuh"
template< class Value, class Offset> 
# 266
__attribute((always_inline)) ItemOffsetPair< Value, Offset>  ReduceStep(ItemOffsetPair< Value, Offset>  
# 267
input, ReduceBySegmentOp< Sum, ItemOffsetPair< Value, Offset> >  
# 268
reduction_op, int 
# 269
last_lane, int 
# 270
offset) 
# 271
{int volatile ___ = 1;(void)input;(void)reduction_op;(void)last_lane;(void)offset;
# 284
::exit(___);}
#if 0
# 271
{ 
# 272
ItemOffsetPair< Value, Offset>  output; 
# 274
(output.value) = ReduceStep((input.value), Sum(), last_lane, offset, Int2Type< IsInteger< Value> ::IS_SMALL_INTEGER> ()); 
# 275
(output.offset) = ReduceStep((input.offset), Sum(), last_lane, offset, Int2Type< IsInteger< Offset> ::IS_SMALL_INTEGER> ()); 
# 280
if ((input.offset) > 0) { 
# 281
(output.value) = (input.value); }  
# 283
return output; 
# 284
} 
#endif
# 288 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../warp/specializations/warp_reduce_shfl.cuh"
template< class _T, class ReductionOp> 
# 289
__attribute((always_inline)) _T ReduceStep(_T 
# 290
input, ReductionOp 
# 291
reduction_op, int 
# 292
last_lane, int 
# 293
offset) 
# 294
{int volatile ___ = 1;(void)input;(void)reduction_op;(void)last_lane;(void)offset;
# 304
::exit(___);}
#if 0
# 294
{ 
# 295
T output = input; 
# 297
T temp = ShuffleDown(output, offset); 
# 300
if (offset <= (last_lane - (lane_id))) { 
# 301
output = reduction_op(temp, output); }  
# 303
return output; 
# 304
} 
#endif
# 308 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../warp/specializations/warp_reduce_shfl.cuh"
template< class _T, class ReductionOp> 
# 309
__attribute((always_inline)) _T ReduceStep(_T 
# 310
input, ReductionOp 
# 311
reduction_op, int 
# 312
last_lane, int 
# 313
offset, Int2Type< 1>  
# 314
is_small_integer) 
# 315
{int volatile ___ = 1;(void)input;(void)reduction_op;(void)last_lane;(void)offset;(void)is_small_integer;
# 321
::exit(___);}
#if 0
# 315
{ 
# 316
unsigned temp = reinterpret_cast< unsigned &>(input); 
# 318
temp = ReduceStep(temp, reduction_op, last_lane, offset); 
# 320
return reinterpret_cast< _T &>(temp); 
# 321
} 
#endif
# 324 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../warp/specializations/warp_reduce_shfl.cuh"
template< class _T, class ReductionOp> 
# 325
__attribute((always_inline)) _T ReduceStep(_T 
# 326
input, ReductionOp 
# 327
reduction_op, int 
# 328
last_lane, int 
# 329
offset, Int2Type< 0>  
# 330
is_small_integer) 
# 331
{int volatile ___ = 1;(void)input;(void)reduction_op;(void)last_lane;(void)offset;(void)is_small_integer;
# 333
::exit(___);}
#if 0
# 331
{ 
# 332
return ReduceStep(input, reduction_op, last_lane, offset); 
# 333
} 
#endif
# 341 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../warp/specializations/warp_reduce_shfl.cuh"
template< bool 
# 342
ALL_LANES_VALID, int 
# 343
FOLDED_ITEMS_PER_LANE, class 
# 344
ReductionOp> 
# 345
__attribute((always_inline)) T Reduce(T 
# 346
input, int 
# 347
folded_items_per_warp, ReductionOp 
# 348
reduction_op) 
# 349
{int volatile ___ = 1;(void)input;(void)folded_items_per_warp;(void)reduction_op;
# 377
::exit(___);}
#if 0
# 349
{ 
# 351
int first_warp_thread = 0; 
# 352
int last_warp_thread = (LOGICAL_WARP_THREADS - 1); 
# 353
if (!(IS_ARCH_WARP)) 
# 354
{ 
# 355
first_warp_thread = ((lane_id) & (~(LOGICAL_WARP_THREADS - 1))); 
# 356
last_warp_thread |= (lane_id); 
# 357
}  
# 360
int lanes_with_valid_data = (folded_items_per_warp - 1) / FOLDED_ITEMS_PER_LANE; 
# 363
int last_lane = ALL_LANES_VALID ? last_warp_thread : (((first_warp_thread + lanes_with_valid_data) < last_warp_thread) ? first_warp_thread + lanes_with_valid_data : last_warp_thread); 
# 367
T output = input; 
# 371
#pragma unroll
for (
# 371
int STEP = 0; STEP < (STEPS); STEP++) 
# 372
{ 
# 373
output = ReduceStep(output, reduction_op, last_lane, 1 << STEP, Int2Type< IsInteger< T> ::IS_SMALL_INTEGER> ()); 
# 374
}  
# 376
return output; 
# 377
} 
#endif
# 381 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../warp/specializations/warp_reduce_shfl.cuh"
template< bool 
# 382
HEAD_SEGMENTED, class 
# 383
Flag, class 
# 384
ReductionOp> 
# 385
__attribute((always_inline)) T SegmentedReduce(T 
# 386
input, Flag 
# 387
flag, ReductionOp 
# 388
reduction_op) 
# 389
{int volatile ___ = 1;(void)input;(void)flag;(void)reduction_op;
# 415
::exit(___);}
#if 0
# 389
{ 
# 391
int warp_flags = __ballot(flag); 
# 393
if (HEAD_SEGMENTED) { 
# 394
warp_flags >>= 1; }  
# 397
warp_flags |= LastLaneMask< 1, LOGICAL_WARPS> ::MASK; 
# 400
warp_flags &= LaneMaskGe(); 
# 403
int last_lane = __clz(__brev(warp_flags)); 
# 405
T output = input; 
# 409
#pragma unroll
for (
# 409
int STEP = 0; STEP < (STEPS); STEP++) 
# 410
{ 
# 411
output = ReduceStep(output, reduction_op, last_lane, 1 << STEP, Int2Type< IsInteger< T> ::IS_SMALL_INTEGER> ()); 
# 412
}  
# 414
return output; 
# 415
} 
#endif
# 416 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../warp/specializations/warp_reduce_shfl.cuh"
}; 
# 419
}
# 420
}}}}
# 43 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../warp/specializations/warp_reduce_smem.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 46
namespace cub_ { 
# 51
template< class 
# 52
T, int 
# 53
LOGICAL_WARP_THREADS, int 
# 54
PTX_ARCH> 
# 55
struct WarpReduceSmem { 
# 62
enum { 
# 64
IS_ARCH_WARP = LOGICAL_WARP_THREADS == (1 << 5), 
# 67
IS_POW_OF_TWO = (LOGICAL_WARP_THREADS & (LOGICAL_WARP_THREADS - 1)) == 0, 
# 70
STEPS = Log2< LOGICAL_WARP_THREADS> ::VALUE, 
# 73
HALF_WARP_THREADS = 1 << ((Log2< LOGICAL_WARP_THREADS> ::VALUE) - 1), 
# 76
WARP_SMEM_ELEMENTS = LOGICAL_WARP_THREADS + (1 << ((Log2< LOGICAL_WARP_THREADS> ::VALUE) - 1)), 
# 79
UNSET = 0, 
# 80
SET = 1, 
# 81
SEEN = 2
# 82
}; 
# 85
typedef unsigned char SmemFlag; 
# 88
struct _TempStorage { 
# 90
T reduce[WARP_SMEM_ELEMENTS]; 
# 91
SmemFlag flags[WARP_SMEM_ELEMENTS]; 
# 92
}; 
# 95
struct TempStorage : public Uninitialized< _TempStorage>  { }; 
# 102
_TempStorage &temp_storage; 
# 103
int lane_id; 
# 111
__attribute((always_inline)) WarpReduceSmem(TempStorage &
# 112
temp_storage) : temp_storage((temp_storage.Alias())), lane_id((IS_ARCH_WARP) ? LaneId() : (LaneId() % (LOGICAL_WARP_THREADS))) 
# 118
{int *volatile ___ = 0;(void)temp_storage;::free(___);}
#if 0
# 118
{ } 
#endif
# 131 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../warp/specializations/warp_reduce_smem.cuh"
template< bool 
# 132
ALL_LANES_VALID, int 
# 133
FOLDED_ITEMS_PER_LANE, class 
# 134
ReductionOp, int 
# 135
STEP> 
# 136
__attribute((always_inline)) T ReduceStep(T 
# 137
input, int 
# 138
folded_items_per_warp, ReductionOp 
# 139
reduction_op, Int2Type< STEP>  
# 140
step) 
# 141
{int volatile ___ = 1;(void)input;(void)folded_items_per_warp;(void)reduction_op;(void)step;
# 155
::exit(___);}
#if 0
# 141
{ 
# 142
const int OFFSET = (1 << STEP); 
# 145
ThreadStore< STORE_VOLATILE> (&(((temp_storage).reduce)[lane_id]), input); 
# 148
if ((ALL_LANES_VALID && (IS_POW_OF_TWO)) || ((((lane_id) + OFFSET) * FOLDED_ITEMS_PER_LANE) < folded_items_per_warp)) 
# 149
{ 
# 150
T peer_addend = ThreadLoad< LOAD_VOLATILE> (&(((temp_storage).reduce)[(lane_id) + OFFSET])); 
# 151
input = reduction_op(input, peer_addend); 
# 152
}  
# 154
return ReduceStep< ALL_LANES_VALID, FOLDED_ITEMS_PER_LANE> (input, folded_items_per_warp, reduction_op, Int2Type< STEP + 1> ()); 
# 155
} 
#endif
# 161 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../warp/specializations/warp_reduce_smem.cuh"
template< bool 
# 162
ALL_LANES_VALID, int 
# 163
FOLDED_ITEMS_PER_LANE, class 
# 164
ReductionOp> 
# 165
__attribute((always_inline)) T ReduceStep(T 
# 166
input, int 
# 167
folded_items_per_warp, ReductionOp 
# 168
reduction_op, Int2Type< STEPS>  
# 169
step) 
# 170
{int volatile ___ = 1;(void)input;(void)folded_items_per_warp;(void)reduction_op;(void)step;
# 172
::exit(___);}
#if 0
# 170
{ 
# 171
return input; 
# 172
} 
#endif
# 183 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../warp/specializations/warp_reduce_smem.cuh"
template< bool 
# 184
HEAD_SEGMENTED, class 
# 185
Flag, class 
# 186
ReductionOp> 
# 187
__attribute((always_inline)) T SegmentedReduce(T 
# 188
input, Flag 
# 189
flag, ReductionOp 
# 190
reduction_op, Int2Type< 1>  
# 191
has_ballot) 
# 192
{int volatile ___ = 1;(void)input;(void)flag;(void)reduction_op;(void)has_ballot;
# 232
::exit(___);}
#if 0
# 192
{ 
# 194
int warp_flags = __ballot(flag); 
# 196
if (!HEAD_SEGMENTED) { 
# 197
warp_flags <<= 1; }  
# 200
warp_flags &= LaneMaskGt(); 
# 203
if (!(IS_ARCH_WARP)) 
# 204
{ 
# 205
warp_flags >>= ((LaneId() / (LOGICAL_WARP_THREADS)) * (LOGICAL_WARP_THREADS)); 
# 206
}  
# 209
int next_flag = __clz(__brev(warp_flags)); 
# 212
if (LOGICAL_WARP_THREADS != 32) { 
# 213
next_flag = ((LOGICAL_WARP_THREADS < next_flag) ? LOGICAL_WARP_THREADS : next_flag); }  
# 216
#pragma unroll
for (
# 216
int STEP = 0; STEP < (STEPS); STEP++) 
# 217
{ 
# 218
const int OFFSET = 1 << STEP; 
# 221
ThreadStore< STORE_VOLATILE> (&(((temp_storage).reduce)[lane_id]), input); 
# 224
if (OFFSET < (next_flag - (lane_id))) 
# 225
{ 
# 226
T peer_addend = ThreadLoad< LOAD_VOLATILE> (&(((temp_storage).reduce)[(lane_id) + OFFSET])); 
# 227
input = reduction_op(input, peer_addend); 
# 228
}  
# 229
}  
# 231
return input; 
# 232
} 
#endif
# 238 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../warp/specializations/warp_reduce_smem.cuh"
template< bool 
# 239
HEAD_SEGMENTED, class 
# 240
Flag, class 
# 241
ReductionOp> 
# 242
__attribute((always_inline)) T SegmentedReduce(T 
# 243
input, Flag 
# 244
flag, ReductionOp 
# 245
reduction_op, Int2Type< 0>  
# 246
has_ballot) 
# 247
{int volatile ___ = 1;(void)input;(void)flag;(void)reduction_op;(void)has_ballot;
# 314
::exit(___);}
#if 0
# 247
{ 
# 249
enum { 
# 250
UNSET, 
# 251
SET, 
# 252
SEEN
# 253
}; 
# 256
volatile SmemFlag *flag_storage = (((temp_storage).flags)); 
# 258
SmemFlag flag_status = (flag) ? SET : UNSET; 
# 260
for (int STEP = 0; STEP < (STEPS); STEP++) 
# 261
{ 
# 262
const int OFFSET = 1 << STEP; 
# 265
ThreadStore< STORE_VOLATILE> (&(((temp_storage).reduce)[lane_id]), input); 
# 268
T peer_addend = ThreadLoad< LOAD_VOLATILE> (&(((temp_storage).reduce)[(lane_id) + OFFSET])); 
# 271
(flag_storage[lane_id]) = flag_status; 
# 274
SmemFlag peer_flag_status = flag_storage[(lane_id) + OFFSET]; 
# 277
if ((lane_id) < (LOGICAL_WARP_THREADS - OFFSET)) 
# 278
{ 
# 279
if (HEAD_SEGMENTED) 
# 280
{ 
# 282
if ((flag_status & SEEN) == 0) 
# 283
{ 
# 285
if (peer_flag_status & SET) 
# 286
{ 
# 288
flag_status |= SEEN; 
# 289
} else 
# 291
{ 
# 293
input = reduction_op(input, peer_addend); 
# 294
}  
# 297
flag_status |= (peer_flag_status & SEEN); 
# 298
}  
# 299
} else 
# 301
{ 
# 303
if (!flag_status) 
# 304
{ 
# 305
input = reduction_op(input, peer_addend); 
# 306
flag_status |= peer_flag_status; 
# 307
}  
# 309
}  
# 310
}  
# 311
}  
# 313
return input; 
# 314
} 
#endif
# 324 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../warp/specializations/warp_reduce_smem.cuh"
template< bool 
# 325
ALL_LANES_VALID, int 
# 326
FOLDED_ITEMS_PER_LANE, class 
# 327
ReductionOp> 
# 328
__attribute((always_inline)) T Reduce(T 
# 329
input, int 
# 330
folded_items_per_warp, ReductionOp 
# 331
reduction_op) 
# 332
{int volatile ___ = 1;(void)input;(void)folded_items_per_warp;(void)reduction_op;
# 334
::exit(___);}
#if 0
# 332
{ 
# 333
return ReduceStep< ALL_LANES_VALID, FOLDED_ITEMS_PER_LANE> (input, folded_items_per_warp, reduction_op, Int2Type< 0> ()); 
# 334
} 
#endif
# 340 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../warp/specializations/warp_reduce_smem.cuh"
template< bool 
# 341
HEAD_SEGMENTED, class 
# 342
Flag, class 
# 343
ReductionOp> 
# 344
__attribute((always_inline)) T SegmentedReduce(T 
# 345
input, Flag 
# 346
flag, ReductionOp 
# 347
reduction_op) 
# 348
{int volatile ___ = 1;(void)input;(void)flag;(void)reduction_op;
# 350
::exit(___);}
#if 0
# 348
{ 
# 349
return SegmentedReduce< HEAD_SEGMENTED> (input, flag, reduction_op, Int2Type< PTX_ARCH >= 200> ()); 
# 350
} 
#endif
# 353 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../warp/specializations/warp_reduce_smem.cuh"
}; 
# 356
}
# 357
}}}}
# 44 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../warp/warp_reduce.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 47
namespace cub_ { 
# 137
template< class 
# 138
T, int 
# 139
LOGICAL_WARP_THREADS = 32, int 
# 140
PTX_ARCH = 0> 
# 141
class WarpReduce { 
# 150
enum { 
# 152
IS_ARCH_WARP = LOGICAL_WARP_THREADS == (1 << 5), 
# 155
IS_POW_OF_TWO = PowerOfTwo< LOGICAL_WARP_THREADS> ::VALUE
# 156
}; 
# 165
public: typedef typename If< (PTX_ARCH >= 300) && (IS_POW_OF_TWO), WarpReduceShfl< T, LOGICAL_WARP_THREADS, PTX_ARCH> , WarpReduceSmem< T, LOGICAL_WARP_THREADS, PTX_ARCH> > ::Type InternalWarpReduce; 
# 173
private: typedef typename If< (PTX_ARCH >= 300) && (IS_POW_OF_TWO), WarpReduceShfl< T, LOGICAL_WARP_THREADS, PTX_ARCH> , WarpReduceSmem< T, LOGICAL_WARP_THREADS, PTX_ARCH> > ::Type::TempStorage _TempStorage; 
# 181
_TempStorage &temp_storage; 
# 191
public: struct TempStorage : public Uninitialized< typename If< (PTX_ARCH >= 300) && (IS_POW_OF_TWO), WarpReduceShfl< T, LOGICAL_WARP_THREADS, PTX_ARCH> , WarpReduceSmem< T, LOGICAL_WARP_THREADS, PTX_ARCH> > ::Type::TempStorage>  { }; 
# 203
__attribute((always_inline)) WarpReduce(TempStorage &
# 204
temp_storage) : temp_storage((temp_storage.Alias())) 
# 207
{int *volatile ___ = 0;(void)temp_storage;::free(___);}
#if 0
# 207
{ } 
#endif
# 251 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../warp/warp_reduce.cuh"
__attribute((always_inline)) T Sum(T 
# 252
input) 
# 253
{int volatile ___ = 1;(void)input;
# 255
::exit(___);}
#if 0
# 253
{ 
# 254
return (((InternalWarpReduce)(temp_storage)).template Reduce< true, 1> (input, LOGICAL_WARP_THREADS, cub_::Sum())); 
# 255
} 
#endif
# 295 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../warp/warp_reduce.cuh"
__attribute((always_inline)) T Sum(T 
# 296
input, int 
# 297
valid_items) 
# 298
{int volatile ___ = 1;(void)input;(void)valid_items;
# 301
::exit(___);}
#if 0
# 298
{ 
# 300
return (((InternalWarpReduce)(temp_storage)).template Reduce< false, 1> (input, valid_items, cub_::Sum())); 
# 301
} 
#endif
# 342 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../warp/warp_reduce.cuh"
template< class 
# 343
Flag> 
# 344
__attribute((always_inline)) T HeadSegmentedSum(T 
# 345
input, Flag 
# 346
head_flag) 
# 347
{int volatile ___ = 1;(void)input;(void)head_flag;
# 349
::exit(___);}
#if 0
# 347
{ 
# 348
return HeadSegmentedReduce(input, head_flag, cub_::Sum()); 
# 349
} 
#endif
# 389 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../warp/warp_reduce.cuh"
template< class 
# 390
Flag> 
# 391
__attribute((always_inline)) T TailSegmentedSum(T 
# 392
input, Flag 
# 393
tail_flag) 
# 394
{int volatile ___ = 1;(void)input;(void)tail_flag;
# 396
::exit(___);}
#if 0
# 394
{ 
# 395
return TailSegmentedReduce(input, tail_flag, cub_::Sum()); 
# 396
} 
#endif
# 444 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../warp/warp_reduce.cuh"
template< class ReductionOp> 
# 445
__attribute((always_inline)) T Reduce(T 
# 446
input, ReductionOp 
# 447
reduction_op) 
# 448
{int volatile ___ = 1;(void)input;(void)reduction_op;
# 450
::exit(___);}
#if 0
# 448
{ 
# 449
return (((InternalWarpReduce)(temp_storage)).template Reduce< true, 1> (input, LOGICAL_WARP_THREADS, reduction_op)); 
# 450
} 
#endif
# 493 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../warp/warp_reduce.cuh"
template< class ReductionOp> 
# 494
__attribute((always_inline)) T Reduce(T 
# 495
input, ReductionOp 
# 496
reduction_op, int 
# 497
valid_items) 
# 498
{int volatile ___ = 1;(void)input;(void)reduction_op;(void)valid_items;
# 500
::exit(___);}
#if 0
# 498
{ 
# 499
return (((InternalWarpReduce)(temp_storage)).template Reduce< false, 1> (input, valid_items, reduction_op)); 
# 500
} 
#endif
# 542 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../warp/warp_reduce.cuh"
template< class 
# 543
ReductionOp, class 
# 544
Flag> 
# 545
__attribute((always_inline)) T HeadSegmentedReduce(T 
# 546
input, Flag 
# 547
head_flag, ReductionOp 
# 548
reduction_op) 
# 549
{int volatile ___ = 1;(void)input;(void)head_flag;(void)reduction_op;
# 551
::exit(___);}
#if 0
# 549
{ 
# 550
return (((InternalWarpReduce)(temp_storage)).template SegmentedReduce< true> (input, head_flag, reduction_op)); 
# 551
} 
#endif
# 593 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../warp/warp_reduce.cuh"
template< class 
# 594
ReductionOp, class 
# 595
Flag> 
# 596
__attribute((always_inline)) T TailSegmentedReduce(T 
# 597
input, Flag 
# 598
tail_flag, ReductionOp 
# 599
reduction_op) 
# 600
{int volatile ___ = 1;(void)input;(void)tail_flag;(void)reduction_op;
# 602
::exit(___);}
#if 0
# 600
{ 
# 601
return (((InternalWarpReduce)(temp_storage)).template SegmentedReduce< false> (input, tail_flag, reduction_op)); 
# 602
} 
#endif
# 607 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/../../warp/warp_reduce.cuh"
}; 
# 611
}
# 612
}}}}
# 43 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/block_reduce_raking.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 46
namespace cub_ { 
# 62
template< class 
# 63
T, int 
# 64
BLOCK_DIM_X, int 
# 65
BLOCK_DIM_Y, int 
# 66
BLOCK_DIM_Z, int 
# 67
PTX_ARCH> 
# 68
struct BlockReduceRaking { 
# 72
enum { 
# 74
BLOCK_THREADS = (BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z
# 75
}; 
# 78
typedef cub_::BlockRakingLayout< T, BLOCK_THREADS, PTX_ARCH>  BlockRakingLayout; 
# 81
typedef typename cub_::WarpReduce< T, cub_::BlockRakingLayout< T, BLOCK_THREADS, PTX_ARCH> ::RAKING_THREADS, PTX_ARCH> ::InternalWarpReduce WarpReduce; 
# 85
enum { 
# 87
RAKING_THREADS = cub_::BlockRakingLayout< T, (BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z, PTX_ARCH> ::RAKING_THREADS, 
# 90
SEGMENT_LENGTH = cub_::BlockRakingLayout< T, (BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z, PTX_ARCH> ::SEGMENT_LENGTH, 
# 93
WARP_SYNCHRONOUS = (cub_::BlockRakingLayout< T, (BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z, PTX_ARCH> ::RAKING_THREADS) == ((BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z), 
# 96
WARP_SYNCHRONOUS_UNGUARDED = PowerOfTwo< cub_::BlockRakingLayout< T, (BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z, PTX_ARCH> ::RAKING_THREADS> ::VALUE, 
# 99
RAKING_UNGUARDED = cub_::BlockRakingLayout< T, (BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z, PTX_ARCH> ::UNGUARDED
# 101
}; 
# 105
struct _TempStorage { 
# 107
typename cub_::WarpReduce< T, cub_::BlockRakingLayout< T, BLOCK_THREADS, PTX_ARCH> ::RAKING_THREADS, PTX_ARCH> ::InternalWarpReduce::TempStorage warp_storage; 
# 108
typename cub_::BlockRakingLayout< T, BLOCK_THREADS, PTX_ARCH> ::TempStorage raking_grid; 
# 109
}; 
# 113
struct TempStorage : public Uninitialized< _TempStorage>  { }; 
# 117
_TempStorage &temp_storage; 
# 118
int linear_tid; 
# 122
__attribute((always_inline)) BlockReduceRaking(TempStorage &
# 123
temp_storage) : temp_storage((temp_storage.Alias())), linear_tid(RowMajorTid(BLOCK_DIM_X, BLOCK_DIM_Y, BLOCK_DIM_Z)) 
# 127
{int *volatile ___ = 0;(void)temp_storage;::free(___);}
#if 0
# 127
{ } 
#endif
# 130 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/block_reduce_raking.cuh"
template< bool FULL_TILE, class ReductionOp, int ITERATION> 
# 131
__attribute((always_inline)) T RakingReduction(ReductionOp 
# 132
reduction_op, T *
# 133
raking_segment, T 
# 134
partial, int 
# 135
num_valid, Int2Type< ITERATION>  
# 136
iteration) 
# 137
{int volatile ___ = 1;(void)reduction_op;(void)raking_segment;(void)partial;(void)num_valid;(void)iteration;
# 145
::exit(___);}
#if 0
# 137
{ 
# 139
if ((FULL_TILE && (RAKING_UNGUARDED)) || ((((linear_tid) * (SEGMENT_LENGTH)) + ITERATION) < num_valid)) 
# 140
{ 
# 141
T addend = raking_segment[ITERATION]; 
# 142
partial = reduction_op(partial, addend); 
# 143
}  
# 144
return RakingReduction< FULL_TILE> (reduction_op, raking_segment, partial, num_valid, Int2Type< ITERATION + 1> ()); 
# 145
} 
#endif
# 147 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/block_reduce_raking.cuh"
template< bool FULL_TILE, class ReductionOp> 
# 148
__attribute((always_inline)) T RakingReduction(ReductionOp 
# 149
reduction_op, T *
# 150
raking_segment, T 
# 151
partial, int 
# 152
num_valid, Int2Type< SEGMENT_LENGTH>  
# 153
iteration) 
# 154
{int volatile ___ = 1;(void)reduction_op;(void)raking_segment;(void)partial;(void)num_valid;(void)iteration;
# 156
::exit(___);}
#if 0
# 154
{ 
# 155
return partial; 
# 156
} 
#endif
# 160 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/block_reduce_raking.cuh"
template< bool FULL_TILE> 
# 161
__attribute((always_inline)) T Sum(T 
# 162
partial, int 
# 163
num_valid) 
# 164
{int volatile ___ = 1;(void)partial;(void)num_valid;
# 197
::exit(___);}
#if 0
# 164
{ 
# 165
cub_::Sum reduction_op; 
# 167
if (WARP_SYNCHRONOUS) 
# 168
{ 
# 170
partial = (((WarpReduce)((temp_storage).warp_storage)).template Sum< FULL_TILE, SEGMENT_LENGTH> (partial, num_valid)); 
# 173
} else 
# 175
{ 
# 177
(*BlockRakingLayout::PlacementPtr(((temp_storage).raking_grid), linear_tid)) = partial; 
# 179
__syncthreads(); 
# 182
if ((linear_tid) < (RAKING_THREADS)) 
# 183
{ 
# 185
T *raking_segment = BlockRakingLayout::RakingPtr(((temp_storage).raking_grid), linear_tid); 
# 186
partial = (raking_segment[0]); 
# 188
partial = RakingReduction< FULL_TILE> (reduction_op, raking_segment, partial, num_valid, Int2Type< 1> ()); 
# 190
partial = (((WarpReduce)((temp_storage).warp_storage)).template Sum< FULL_TILE && (RAKING_UNGUARDED), SEGMENT_LENGTH> (partial, num_valid)); 
# 193
}  
# 194
}  
# 196
return partial; 
# 197
} 
#endif
# 201 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/block_reduce_raking.cuh"
template< bool 
# 202
FULL_TILE, class 
# 203
ReductionOp> 
# 204
__attribute((always_inline)) T Reduce(T 
# 205
partial, int 
# 206
num_valid, ReductionOp 
# 207
reduction_op) 
# 208
{int volatile ___ = 1;(void)partial;(void)num_valid;(void)reduction_op;
# 241
::exit(___);}
#if 0
# 208
{ 
# 209
if (WARP_SYNCHRONOUS) 
# 210
{ 
# 212
partial = (((WarpReduce)((temp_storage).warp_storage)).template Reduce< FULL_TILE, SEGMENT_LENGTH> (partial, num_valid, reduction_op)); 
# 216
} else 
# 218
{ 
# 220
(*BlockRakingLayout::PlacementPtr(((temp_storage).raking_grid), linear_tid)) = partial; 
# 222
__syncthreads(); 
# 225
if ((linear_tid) < (RAKING_THREADS)) 
# 226
{ 
# 228
T *raking_segment = BlockRakingLayout::RakingPtr(((temp_storage).raking_grid), linear_tid); 
# 229
partial = (raking_segment[0]); 
# 231
partial = RakingReduction< FULL_TILE> (reduction_op, raking_segment, partial, num_valid, Int2Type< 1> ()); 
# 233
partial = (((WarpReduce)((temp_storage).warp_storage)).template Reduce< FULL_TILE && (RAKING_UNGUARDED), SEGMENT_LENGTH> (partial, num_valid, reduction_op)); 
# 237
}  
# 238
}  
# 240
return partial; 
# 241
} 
#endif
# 243 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/block_reduce_raking.cuh"
}; 
# 245
}
# 246
}}}}
# 43 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/block_reduce_raking_commutative_only.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 46
namespace cub_ { 
# 52
template< class 
# 53
T, int 
# 54
BLOCK_DIM_X, int 
# 55
BLOCK_DIM_Y, int 
# 56
BLOCK_DIM_Z, int 
# 57
PTX_ARCH> 
# 58
struct BlockReduceRakingCommutativeOnly { 
# 62
enum { 
# 64
BLOCK_THREADS = (BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z
# 65
}; 
# 68
typedef BlockReduceRaking< T, BLOCK_DIM_X, BLOCK_DIM_Y, BLOCK_DIM_Z, PTX_ARCH>  FallBack; 
# 72
enum { 
# 74
WARP_THREADS = 1 << 5, 
# 77
USE_FALLBACK = ((((BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z) % (1 << 5)) != 0) || (((BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z) <= (1 << 5)), 
# 80
RAKING_THREADS = 1 << 5, 
# 83
SHARING_THREADS = ((((BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z) - (1 << 5)) > 1) ? ((BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z) - (1 << 5) : 1, 
# 86
SEGMENT_LENGTH = (((((BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z) - (1 << 5)) > 1) ? ((BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z) - (1 << 5) : 1) / (1 << 5)
# 87
}; 
# 90
typedef cub_::WarpReduce< T, RAKING_THREADS, PTX_ARCH>  WarpReduce; 
# 93
typedef cub_::BlockRakingLayout< T, (SHARING_THREADS), PTX_ARCH>  BlockRakingLayout; 
# 96
struct _TempStorage { 
# 99
union { 
# 101
struct { 
# 102
typename cub_::WarpReduce< T, RAKING_THREADS, PTX_ARCH> ::TempStorage warp_storage; 
# 103
typename cub_::BlockRakingLayout< T, (SHARING_THREADS), PTX_ARCH> ::TempStorage raking_grid; 
# 104
}; 
# 105
typename BlockReduceRaking< T, BLOCK_DIM_X, BLOCK_DIM_Y, BLOCK_DIM_Z, PTX_ARCH> ::TempStorage fallback_storage; 
# 106
}; 
# 107
}; 
# 111
struct TempStorage : public Uninitialized< _TempStorage>  { }; 
# 115
_TempStorage &temp_storage; 
# 116
int linear_tid; 
# 120
__attribute((always_inline)) BlockReduceRakingCommutativeOnly(TempStorage &
# 121
temp_storage) : temp_storage((temp_storage.Alias())), linear_tid(RowMajorTid(BLOCK_DIM_X, BLOCK_DIM_Y, BLOCK_DIM_Z)) 
# 125
{int *volatile ___ = 0;(void)temp_storage;::free(___);}
#if 0
# 125
{ } 
#endif
# 129 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/block_reduce_raking_commutative_only.cuh"
template< bool FULL_TILE> 
# 130
__attribute((always_inline)) T Sum(T 
# 131
partial, int 
# 132
num_valid) 
# 133
{int volatile ___ = 1;(void)partial;(void)num_valid;
# 159
::exit(___);}
#if 0
# 133
{ 
# 134
if ((USE_FALLBACK) || (!FULL_TILE)) 
# 135
{ 
# 136
return (((FallBack)(((temp_storage).fallback_storage))).template Sum< FULL_TILE> (partial, num_valid)); 
# 137
} else 
# 139
{ 
# 141
if ((linear_tid) >= (RAKING_THREADS)) { 
# 142
(*BlockRakingLayout::PlacementPtr(((temp_storage).raking_grid), (linear_tid) - (RAKING_THREADS))) = partial; }  
# 144
__syncthreads(); 
# 147
if ((linear_tid) < (RAKING_THREADS)) 
# 148
{ 
# 150
T *raking_segment = BlockRakingLayout::RakingPtr(((temp_storage).raking_grid), linear_tid); 
# 151
partial = ThreadReduce< SEGMENT_LENGTH> (raking_segment, cub_::Sum(), partial); 
# 154
partial = (((WarpReduce)(((temp_storage).warp_storage))).Sum(partial)); 
# 155
}  
# 156
}  
# 158
return partial; 
# 159
} 
#endif
# 163 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/block_reduce_raking_commutative_only.cuh"
template< bool 
# 164
FULL_TILE, class 
# 165
ReductionOp> 
# 166
__attribute((always_inline)) T Reduce(T 
# 167
partial, int 
# 168
num_valid, ReductionOp 
# 169
reduction_op) 
# 170
{int volatile ___ = 1;(void)partial;(void)num_valid;(void)reduction_op;
# 196
::exit(___);}
#if 0
# 170
{ 
# 171
if ((USE_FALLBACK) || (!FULL_TILE)) 
# 172
{ 
# 173
return (((FallBack)(((temp_storage).fallback_storage))).template Reduce< FULL_TILE> (partial, num_valid, reduction_op)); 
# 174
} else 
# 176
{ 
# 178
if ((linear_tid) >= (RAKING_THREADS)) { 
# 179
(*BlockRakingLayout::PlacementPtr(((temp_storage).raking_grid), (linear_tid) - (RAKING_THREADS))) = partial; }  
# 181
__syncthreads(); 
# 184
if ((linear_tid) < (RAKING_THREADS)) 
# 185
{ 
# 187
T *raking_segment = BlockRakingLayout::RakingPtr(((temp_storage).raking_grid), linear_tid); 
# 188
partial = ThreadReduce< SEGMENT_LENGTH> (raking_segment, reduction_op, partial); 
# 191
partial = (((WarpReduce)(((temp_storage).warp_storage))).Reduce(partial, reduction_op)); 
# 192
}  
# 193
}  
# 195
return partial; 
# 196
} 
#endif
# 198 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/block_reduce_raking_commutative_only.cuh"
}; 
# 200
}
# 201
}}}}
# 42 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/block_reduce_warp_reductions.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 45
namespace cub_ { 
# 51
template< class 
# 52
T, int 
# 53
BLOCK_DIM_X, int 
# 54
BLOCK_DIM_Y, int 
# 55
BLOCK_DIM_Z, int 
# 56
PTX_ARCH> 
# 57
struct BlockReduceWarpReductions { 
# 61
enum { 
# 63
BLOCK_THREADS = (BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z, 
# 66
WARP_THREADS = 1 << 5, 
# 69
WARPS = ((((BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z) + (1 << 5)) - 1) / (1 << 5), 
# 72
LOGICAL_WARP_SIZE = ((1 << 5) < ((BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z)) ? 1 << 5 : ((BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z), 
# 75
EVEN_WARP_MULTIPLE = (((BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z) % (((1 << 5) < ((BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z)) ? 1 << 5 : ((BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z))) == 0
# 76
}; 
# 80
typedef typename cub_::WarpReduce< T, LOGICAL_WARP_SIZE, PTX_ARCH> ::InternalWarpReduce WarpReduce; 
# 84
struct _TempStorage { 
# 86
typename cub_::WarpReduce< T, LOGICAL_WARP_SIZE, PTX_ARCH> ::InternalWarpReduce::TempStorage warp_reduce[WARPS]; 
# 87
T warp_aggregates[WARPS]; 
# 88
T block_prefix; 
# 89
}; 
# 92
struct TempStorage : public Uninitialized< _TempStorage>  { }; 
# 96
_TempStorage &temp_storage; 
# 97
int linear_tid; 
# 98
int warp_id; 
# 99
int lane_id; 
# 103
__attribute((always_inline)) BlockReduceWarpReductions(TempStorage &
# 104
temp_storage) : temp_storage((temp_storage.Alias())), linear_tid(RowMajorTid(BLOCK_DIM_X, BLOCK_DIM_Y, BLOCK_DIM_Z)), warp_id(((WARPS) == 1) ? 0 : ((linear_tid) / (WARP_THREADS))), lane_id(LaneId()) 
# 110
{int *volatile ___ = 0;(void)temp_storage;::free(___);}
#if 0
# 110
{ } 
#endif
# 113 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/block_reduce_warp_reductions.cuh"
template< bool FULL_TILE, class ReductionOp, int SUCCESSOR_WARP> 
# 114
__attribute((always_inline)) T ApplyWarpAggregates(ReductionOp 
# 115
reduction_op, T 
# 116
warp_aggregate, int 
# 117
num_valid, Int2Type< SUCCESSOR_WARP>  
# 118
successor_warp) 
# 119
{int volatile ___ = 1;(void)reduction_op;(void)warp_aggregate;(void)num_valid;(void)successor_warp;
# 126
::exit(___);}
#if 0
# 119
{ 
# 120
if (FULL_TILE || ((SUCCESSOR_WARP * (LOGICAL_WARP_SIZE)) < num_valid)) 
# 121
{ 
# 122
T addend = ((temp_storage).warp_aggregates)[SUCCESSOR_WARP]; 
# 123
warp_aggregate = reduction_op(warp_aggregate, addend); 
# 124
}  
# 125
return ApplyWarpAggregates< FULL_TILE> (reduction_op, warp_aggregate, num_valid, Int2Type< SUCCESSOR_WARP + 1> ()); 
# 126
} 
#endif
# 128 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/block_reduce_warp_reductions.cuh"
template< bool FULL_TILE, class ReductionOp> 
# 129
__attribute((always_inline)) T ApplyWarpAggregates(ReductionOp 
# 130
reduction_op, T 
# 131
warp_aggregate, int 
# 132
num_valid, Int2Type< WARPS>  
# 133
successor_warp) 
# 134
{int volatile ___ = 1;(void)reduction_op;(void)warp_aggregate;(void)num_valid;(void)successor_warp;
# 136
::exit(___);}
#if 0
# 134
{ 
# 135
return warp_aggregate; 
# 136
} 
#endif
# 140 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/block_reduce_warp_reductions.cuh"
template< bool 
# 141
FULL_TILE, class 
# 142
ReductionOp> 
# 143
__attribute((always_inline)) T ApplyWarpAggregates(ReductionOp 
# 144
reduction_op, T 
# 145
warp_aggregate, int 
# 146
num_valid) 
# 147
{int volatile ___ = 1;(void)reduction_op;(void)warp_aggregate;(void)num_valid;
# 163
::exit(___);}
#if 0
# 147
{ 
# 149
if ((lane_id) == 0) 
# 150
{ 
# 151
(((temp_storage).warp_aggregates)[warp_id]) = warp_aggregate; 
# 152
}  
# 154
__syncthreads(); 
# 157
if ((linear_tid) == 0) 
# 158
{ 
# 159
warp_aggregate = ApplyWarpAggregates< FULL_TILE> (reduction_op, warp_aggregate, num_valid, Int2Type< 1> ()); 
# 160
}  
# 162
return warp_aggregate; 
# 163
} 
#endif
# 167 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/block_reduce_warp_reductions.cuh"
template< bool FULL_TILE> 
# 168
__attribute((always_inline)) T Sum(T 
# 169
input, int 
# 170
num_valid) 
# 171
{int volatile ___ = 1;(void)input;(void)num_valid;
# 187
::exit(___);}
#if 0
# 171
{ 
# 172
cub_::Sum reduction_op; 
# 173
unsigned warp_offset = (warp_id) * (LOGICAL_WARP_SIZE); 
# 174
unsigned warp_num_valid = (FULL_TILE && (EVEN_WARP_MULTIPLE)) ? LOGICAL_WARP_SIZE : ((warp_offset < num_valid) ? num_valid - warp_offset : (0)); 
# 181
T warp_aggregate = (((WarpReduce)(((temp_storage).warp_reduce)[warp_id])).template Sum< FULL_TILE && (EVEN_WARP_MULTIPLE), 1> (input, warp_num_valid)); 
# 186
return ApplyWarpAggregates< FULL_TILE> (reduction_op, warp_aggregate, num_valid); 
# 187
} 
#endif
# 191 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/block_reduce_warp_reductions.cuh"
template< bool 
# 192
FULL_TILE, class 
# 193
ReductionOp> 
# 194
__attribute((always_inline)) T Reduce(T 
# 195
input, int 
# 196
num_valid, ReductionOp 
# 197
reduction_op) 
# 198
{int volatile ___ = 1;(void)input;(void)num_valid;(void)reduction_op;
# 214
::exit(___);}
#if 0
# 198
{ 
# 199
unsigned warp_offset = (warp_id) * (LOGICAL_WARP_SIZE); 
# 200
unsigned warp_num_valid = (FULL_TILE && (EVEN_WARP_MULTIPLE)) ? LOGICAL_WARP_SIZE : ((warp_offset < num_valid) ? num_valid - warp_offset : (0)); 
# 207
T warp_aggregate = (((WarpReduce)(((temp_storage).warp_reduce)[warp_id])).template Reduce< FULL_TILE && (EVEN_WARP_MULTIPLE), 1> (input, warp_num_valid, reduction_op)); 
# 213
return ApplyWarpAggregates< FULL_TILE> (reduction_op, warp_aggregate, num_valid); 
# 214
} 
#endif
# 216 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/specializations/block_reduce_warp_reductions.cuh"
}; 
# 219
}
# 220
}}}}
# 45 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_reduce.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 48
namespace cub_ { 
# 60
enum BlockReduceAlgorithm { 
# 89
BLOCK_REDUCE_RAKING_COMMUTATIVE_ONLY, 
# 119
BLOCK_REDUCE_RAKING, 
# 148
BLOCK_REDUCE_WARP_REDUCTIONS
# 149
}; 
# 214
template< class 
# 215
T, int 
# 216
BLOCK_DIM_X, BlockReduceAlgorithm 
# 217
ALGORITHM = BLOCK_REDUCE_WARP_REDUCTIONS, int 
# 218
BLOCK_DIM_Y = 1, int 
# 219
BLOCK_DIM_Z = 1, int 
# 220
PTX_ARCH = 0> 
# 221
class BlockReduce { 
# 231
enum { 
# 233
BLOCK_THREADS = (BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z
# 234
}; 
# 236
typedef BlockReduceWarpReductions< T, BLOCK_DIM_X, BLOCK_DIM_Y, BLOCK_DIM_Z, PTX_ARCH>  WarpReductions; 
# 237
typedef BlockReduceRakingCommutativeOnly< T, BLOCK_DIM_X, BLOCK_DIM_Y, BLOCK_DIM_Z, PTX_ARCH>  RakingCommutativeOnly; 
# 238
typedef BlockReduceRaking< T, BLOCK_DIM_X, BLOCK_DIM_Y, BLOCK_DIM_Z, PTX_ARCH>  Raking; 
# 245
typedef typename If< (ALGORITHM) == (BLOCK_REDUCE_WARP_REDUCTIONS), BlockReduceWarpReductions< T, BLOCK_DIM_X, BLOCK_DIM_Y, BLOCK_DIM_Z, PTX_ARCH> , typename If< (ALGORITHM) == (BLOCK_REDUCE_RAKING_COMMUTATIVE_ONLY), BlockReduceRakingCommutativeOnly< T, BLOCK_DIM_X, BLOCK_DIM_Y, BLOCK_DIM_Z, PTX_ARCH> , BlockReduceRaking< T, BLOCK_DIM_X, BLOCK_DIM_Y, BLOCK_DIM_Z, PTX_ARCH> > ::Type> ::Type InternalBlockReduce; 
# 248
typedef typename If< (ALGORITHM) == (BLOCK_REDUCE_WARP_REDUCTIONS), BlockReduceWarpReductions< T, BLOCK_DIM_X, BLOCK_DIM_Y, BLOCK_DIM_Z, PTX_ARCH> , typename If< (ALGORITHM) == (BLOCK_REDUCE_RAKING_COMMUTATIVE_ONLY), BlockReduceRakingCommutativeOnly< T, BLOCK_DIM_X, BLOCK_DIM_Y, BLOCK_DIM_Z, PTX_ARCH> , BlockReduceRaking< T, BLOCK_DIM_X, BLOCK_DIM_Y, BLOCK_DIM_Z, PTX_ARCH> > ::Type> ::Type::TempStorage _TempStorage; 
# 256
__attribute((always_inline)) _TempStorage &PrivateStorage() 
# 257
{int volatile ___ = 1;
# 260
::exit(___);}
#if 0
# 257
{ 
# 258
__attribute__((unused)) static _TempStorage private_storage; 
# 259
return private_storage; 
# 260
} 
#endif
# 268 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_reduce.cuh"
_TempStorage &temp_storage; 
# 271
int linear_tid; 
# 277
public: struct TempStorage : public Uninitialized< typename If< (ALGORITHM) == (BLOCK_REDUCE_WARP_REDUCTIONS), BlockReduceWarpReductions< T, BLOCK_DIM_X, BLOCK_DIM_Y, BLOCK_DIM_Z, PTX_ARCH> , typename If< (ALGORITHM) == (BLOCK_REDUCE_RAKING_COMMUTATIVE_ONLY), BlockReduceRakingCommutativeOnly< T, BLOCK_DIM_X, BLOCK_DIM_Y, BLOCK_DIM_Z, PTX_ARCH> , BlockReduceRaking< T, BLOCK_DIM_X, BLOCK_DIM_Y, BLOCK_DIM_Z, PTX_ARCH> > ::Type> ::Type::TempStorage>  { }; 
# 288
__attribute((always_inline)) BlockReduce() : temp_storage(PrivateStorage()), linear_tid(RowMajorTid(BLOCK_DIM_X, BLOCK_DIM_Y, BLOCK_DIM_Z)) 
# 292
{int *volatile ___ = 0;::free(___);}
#if 0
# 292
{ } 
#endif
# 298 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_reduce.cuh"
__attribute((always_inline)) BlockReduce(TempStorage &
# 299
temp_storage) : temp_storage((temp_storage.Alias())), linear_tid(RowMajorTid(BLOCK_DIM_X, BLOCK_DIM_Y, BLOCK_DIM_Z)) 
# 303
{int *volatile ___ = 0;(void)temp_storage;::free(___);}
#if 0
# 303
{ } 
#endif
# 347 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_reduce.cuh"
template< class ReductionOp> 
# 348
__attribute((always_inline)) T Reduce(T 
# 349
input, ReductionOp 
# 350
reduction_op) 
# 351
{int volatile ___ = 1;(void)input;(void)reduction_op;
# 353
::exit(___);}
#if 0
# 351
{ 
# 352
return (((InternalBlockReduce)(temp_storage)).template Reduce< true> (input, BLOCK_THREADS, reduction_op)); 
# 353
} 
#endif
# 392 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_reduce.cuh"
template< int 
# 393
ITEMS_PER_THREAD, class 
# 394
ReductionOp> 
# 395
__attribute((always_inline)) T Reduce(T (&
# 396
inputs)[ITEMS_PER_THREAD], ReductionOp 
# 397
reduction_op) 
# 398
{int volatile ___ = 1;(void)inputs;(void)reduction_op;
# 402
::exit(___);}
#if 0
# 398
{ 
# 400
T partial = ThreadReduce(inputs, reduction_op); 
# 401
return Reduce(partial, reduction_op); 
# 402
} 
#endif
# 439 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_reduce.cuh"
template< class ReductionOp> 
# 440
__attribute((always_inline)) T Reduce(T 
# 441
input, ReductionOp 
# 442
reduction_op, int 
# 443
num_valid) 
# 444
{int volatile ___ = 1;(void)input;(void)reduction_op;(void)num_valid;
# 454
::exit(___);}
#if 0
# 444
{ 
# 446
if (num_valid >= (BLOCK_THREADS)) 
# 447
{ 
# 448
return (((InternalBlockReduce)(temp_storage)).template Reduce< true> (input, num_valid, reduction_op)); 
# 449
} else 
# 451
{ 
# 452
return (((InternalBlockReduce)(temp_storage)).template Reduce< false> (input, num_valid, reduction_op)); 
# 453
}  
# 454
} 
#endif
# 497 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_reduce.cuh"
__attribute((always_inline)) T Sum(T 
# 498
input) 
# 499
{int volatile ___ = 1;(void)input;
# 501
::exit(___);}
#if 0
# 499
{ 
# 500
return (((InternalBlockReduce)(temp_storage)).template Sum< true> (input, BLOCK_THREADS)); 
# 501
} 
#endif
# 538 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_reduce.cuh"
template< int ITEMS_PER_THREAD> 
# 539
__attribute((always_inline)) T Sum(T (&
# 540
inputs)[ITEMS_PER_THREAD]) 
# 541
{int volatile ___ = 1;(void)inputs;
# 545
::exit(___);}
#if 0
# 541
{ 
# 543
T partial = ThreadReduce(inputs, cub_::Sum()); 
# 544
return Sum(partial); 
# 545
} 
#endif
# 582 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_reduce.cuh"
__attribute((always_inline)) T Sum(T 
# 583
input, int 
# 584
num_valid) 
# 585
{int volatile ___ = 1;(void)input;(void)num_valid;
# 595
::exit(___);}
#if 0
# 585
{ 
# 587
if (num_valid >= (BLOCK_THREADS)) 
# 588
{ 
# 589
return (((InternalBlockReduce)(temp_storage)).template Sum< true> (input, num_valid)); 
# 590
} else 
# 592
{ 
# 593
return (((InternalBlockReduce)(temp_storage)).template Sum< false> (input, num_valid)); 
# 594
}  
# 595
} 
#endif
# 599 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_reduce.cuh"
}; 
# 605
}
# 606
}}}}
# 45 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_store.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 48
namespace cub_ { 
# 70
template< class 
# 71
T, int 
# 72
ITEMS_PER_THREAD, class 
# 73
OutputIterator> 
# 74
__attribute((always_inline)) __attribute__((unused)) inline void StoreDirectBlocked(int 
# 75
linear_tid, OutputIterator 
# 76
block_itr, T (&
# 77
items)[ITEMS_PER_THREAD]) 
# 78
{int volatile ___ = 1;(void)linear_tid;(void)block_itr;(void)items;
# 85
::exit(___);}
#if 0
# 78
{ 
# 81
#pragma unroll
for (
# 81
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 82
{ 
# 83
(block_itr[(linear_tid * ITEMS_PER_THREAD) + ITEM]) = ((items)[ITEM]); 
# 84
}  
# 85
} 
#endif
# 97 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_store.cuh"
template< class 
# 98
T, int 
# 99
ITEMS_PER_THREAD, class 
# 100
OutputIterator> 
# 101
__attribute((always_inline)) __attribute__((unused)) inline void StoreDirectBlocked(int 
# 102
linear_tid, OutputIterator 
# 103
block_itr, T (&
# 104
items)[ITEMS_PER_THREAD], int 
# 105
valid_items) 
# 106
{int volatile ___ = 1;(void)linear_tid;(void)block_itr;(void)items;(void)valid_items;
# 116
::exit(___);}
#if 0
# 106
{ 
# 109
#pragma unroll
for (
# 109
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 110
{ 
# 111
if ((ITEM + (linear_tid * ITEMS_PER_THREAD)) < valid_items) 
# 112
{ 
# 113
(block_itr[(linear_tid * ITEMS_PER_THREAD) + ITEM]) = ((items)[ITEM]); 
# 114
}  
# 115
}  
# 116
} 
#endif
# 136 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_store.cuh"
template< class 
# 137
T, int 
# 138
ITEMS_PER_THREAD> 
# 139
__attribute((always_inline)) __attribute__((unused)) inline void StoreDirectBlockedVectorized(int 
# 140
linear_tid, T *
# 141
block_ptr, T (&
# 142
items)[ITEMS_PER_THREAD]) 
# 143
{int volatile ___ = 1;(void)linear_tid;(void)block_ptr;(void)items;
# 176
::exit(___);}
#if 0
# 143
{ 
# 145
enum { 
# 147
MAX_VEC_SIZE = (ITEMS_PER_THREAD < 4) ? ITEMS_PER_THREAD : 4, 
# 150
VEC_SIZE = ((((((ITEMS_PER_THREAD < 4) ? ITEMS_PER_THREAD : 4) - 1) & ((ITEMS_PER_THREAD < 4) ? ITEMS_PER_THREAD : 4)) == 0) && ((ITEMS_PER_THREAD % ((ITEMS_PER_THREAD < 4) ? ITEMS_PER_THREAD : 4)) == 0)) ? (ITEMS_PER_THREAD < 4) ? ITEMS_PER_THREAD : 4 : 1, 
# 154
VECTORS_PER_THREAD = ITEMS_PER_THREAD / (((((((ITEMS_PER_THREAD < 4) ? ITEMS_PER_THREAD : 4) - 1) & ((ITEMS_PER_THREAD < 4) ? ITEMS_PER_THREAD : 4)) == 0) && ((ITEMS_PER_THREAD % ((ITEMS_PER_THREAD < 4) ? ITEMS_PER_THREAD : 4)) == 0)) ? (ITEMS_PER_THREAD < 4) ? ITEMS_PER_THREAD : 4 : 1)
# 155
}; 
# 158
typedef typename CubVector< T, VEC_SIZE> ::Type Vector; 
# 161
Vector *block_ptr_vectors = reinterpret_cast< Vector *>(block_ptr); 
# 164
Vector raw_vector[VECTORS_PER_THREAD]; 
# 165
T *raw_items = reinterpret_cast< T *>(raw_vector); 
# 169
#pragma unroll
for (
# 169
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 170
{ 
# 171
(raw_items[ITEM]) = ((items)[ITEM]); 
# 172
}  
# 175
StoreDirectBlocked(linear_tid, block_ptr_vectors, raw_vector); 
# 176
} 
#endif
# 197 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_store.cuh"
template< int 
# 198
BLOCK_THREADS, class 
# 199
T, int 
# 200
ITEMS_PER_THREAD, class 
# 201
OutputIterator> 
# 202
__attribute((always_inline)) __attribute__((unused)) inline void StoreDirectStriped(int 
# 203
linear_tid, OutputIterator 
# 204
block_itr, T (&
# 205
items)[ITEMS_PER_THREAD]) 
# 206
{int volatile ___ = 1;(void)linear_tid;(void)block_itr;(void)items;
# 213
::exit(___);}
#if 0
# 206
{ 
# 209
#pragma unroll
for (
# 209
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 210
{ 
# 211
(block_itr[(ITEM * BLOCK_THREADS) + linear_tid]) = ((items)[ITEM]); 
# 212
}  
# 213
} 
#endif
# 226 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_store.cuh"
template< int 
# 227
BLOCK_THREADS, class 
# 228
T, int 
# 229
ITEMS_PER_THREAD, class 
# 230
OutputIterator> 
# 231
__attribute((always_inline)) __attribute__((unused)) inline void StoreDirectStriped(int 
# 232
linear_tid, OutputIterator 
# 233
block_itr, T (&
# 234
items)[ITEMS_PER_THREAD], int 
# 235
valid_items) 
# 236
{int volatile ___ = 1;(void)linear_tid;(void)block_itr;(void)items;(void)valid_items;
# 246
::exit(___);}
#if 0
# 236
{ 
# 239
#pragma unroll
for (
# 239
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 240
{ 
# 241
if (((ITEM * BLOCK_THREADS) + linear_tid) < valid_items) 
# 242
{ 
# 243
(block_itr[(ITEM * BLOCK_THREADS) + linear_tid]) = ((items)[ITEM]); 
# 244
}  
# 245
}  
# 246
} 
#endif
# 269 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_store.cuh"
template< class 
# 270
T, int 
# 271
ITEMS_PER_THREAD, class 
# 272
OutputIterator> 
# 273
__attribute((always_inline)) __attribute__((unused)) inline void StoreDirectWarpStriped(int 
# 274
linear_tid, OutputIterator 
# 275
block_itr, T (&
# 276
items)[ITEMS_PER_THREAD]) 
# 277
{int volatile ___ = 1;(void)linear_tid;(void)block_itr;(void)items;
# 288
::exit(___);}
#if 0
# 277
{ 
# 278
int tid = linear_tid & ((1 << 5) - 1); 
# 279
int wid = linear_tid >> 5; 
# 280
int warp_offset = (wid * (1 << 5)) * ITEMS_PER_THREAD; 
# 284
#pragma unroll
for (
# 284
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 285
{ 
# 286
(block_itr[(warp_offset + tid) + (ITEM * (1 << 5))]) = ((items)[ITEM]); 
# 287
}  
# 288
} 
#endif
# 303 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_store.cuh"
template< class 
# 304
T, int 
# 305
ITEMS_PER_THREAD, class 
# 306
OutputIterator> 
# 307
__attribute((always_inline)) __attribute__((unused)) inline void StoreDirectWarpStriped(int 
# 308
linear_tid, OutputIterator 
# 309
block_itr, T (&
# 310
items)[ITEMS_PER_THREAD], int 
# 311
valid_items) 
# 312
{int volatile ___ = 1;(void)linear_tid;(void)block_itr;(void)items;(void)valid_items;
# 326
::exit(___);}
#if 0
# 312
{ 
# 313
int tid = linear_tid & ((1 << 5) - 1); 
# 314
int wid = linear_tid >> 5; 
# 315
int warp_offset = (wid * (1 << 5)) * ITEMS_PER_THREAD; 
# 319
#pragma unroll
for (
# 319
int ITEM = 0; ITEM < ITEMS_PER_THREAD; ITEM++) 
# 320
{ 
# 321
if (((warp_offset + tid) + (ITEM * (1 << 5))) < valid_items) 
# 322
{ 
# 323
(block_itr[(warp_offset + tid) + (ITEM * (1 << 5))]) = ((items)[ITEM]); 
# 324
}  
# 325
}  
# 326
} 
#endif
# 342 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_store.cuh"
enum BlockStoreAlgorithm { 
# 355
BLOCK_STORE_DIRECT, 
# 377
BLOCK_STORE_VECTORIZE, 
# 396
BLOCK_STORE_TRANSPOSE, 
# 415
BLOCK_STORE_WARP_TRANSPOSE
# 416
}; 
# 486
template< class 
# 487
OutputIterator, int 
# 488
BLOCK_DIM_X, int 
# 489
ITEMS_PER_THREAD, BlockStoreAlgorithm 
# 490
ALGORITHM = BLOCK_STORE_DIRECT, bool 
# 491
WARP_TIME_SLICING = false, int 
# 492
BLOCK_DIM_Y = 1, int 
# 493
BLOCK_DIM_Z = 1, int 
# 494
PTX_ARCH = 0> 
# 495
class BlockStore { 
# 504
enum { 
# 506
BLOCK_THREADS = (BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z
# 507
}; 
# 510
typedef typename std::iterator_traits< OutputIterator> ::value_type T; 
# 518
template< BlockStoreAlgorithm _POLICY, int DUMMY> struct StoreInternal; 
# 525
template< int DUMMY> 
# 526
struct StoreInternal< BLOCK_STORE_DIRECT, DUMMY>  { 
# 529
typedef NullType TempStorage; 
# 532
int linear_tid; 
# 535
__attribute((always_inline)) StoreInternal(TempStorage &
# 536
temp_storage, int 
# 537
linear_tid) : linear_tid(linear_tid) 
# 540
{int *volatile ___ = 0;(void)temp_storage;(void)linear_tid;::free(___);}
#if 0
# 540
{ } 
#endif
# 543 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_store.cuh"
__attribute((always_inline)) void Store(OutputIterator 
# 544
block_itr, T (&
# 545
items)[ITEMS_PER_THREAD]) 
# 546
{int volatile ___ = 1;(void)block_itr;(void)items;
# 548
::exit(___);}
#if 0
# 546
{ 
# 547
StoreDirectBlocked(linear_tid, block_itr, items); 
# 548
} 
#endif
# 551 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_store.cuh"
__attribute((always_inline)) void Store(OutputIterator 
# 552
block_itr, T (&
# 553
items)[ITEMS_PER_THREAD], int 
# 554
valid_items) 
# 555
{int volatile ___ = 1;(void)block_itr;(void)items;(void)valid_items;
# 557
::exit(___);}
#if 0
# 555
{ 
# 556
StoreDirectBlocked(linear_tid, block_itr, items, valid_items); 
# 557
} 
#endif
# 558 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_store.cuh"
}; 
# 564
template< int DUMMY> 
# 565
struct StoreInternal< BLOCK_STORE_VECTORIZE, DUMMY>  { 
# 568
typedef NullType TempStorage; 
# 571
int linear_tid; 
# 574
__attribute((always_inline)) StoreInternal(TempStorage &
# 575
temp_storage, int 
# 576
linear_tid) : linear_tid(linear_tid) 
# 579
{int *volatile ___ = 0;(void)temp_storage;(void)linear_tid;::free(___);}
#if 0
# 579
{ } 
#endif
# 582 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_store.cuh"
__attribute((always_inline)) void Store(T *
# 583
block_ptr, T (&
# 584
items)[ITEMS_PER_THREAD]) 
# 585
{int volatile ___ = 1;(void)block_ptr;(void)items;
# 587
::exit(___);}
#if 0
# 585
{ 
# 586
StoreDirectBlockedVectorized(linear_tid, block_ptr, items); 
# 587
} 
#endif
# 590 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_store.cuh"
template< class _OutputIterator> 
# 591
__attribute((always_inline)) void Store(_OutputIterator 
# 592
block_itr, T (&
# 593
items)[ITEMS_PER_THREAD]) 
# 594
{int volatile ___ = 1;(void)block_itr;(void)items;
# 596
::exit(___);}
#if 0
# 594
{ 
# 595
StoreDirectBlocked(linear_tid, block_itr, items); 
# 596
} 
#endif
# 599 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_store.cuh"
__attribute((always_inline)) void Store(OutputIterator 
# 600
block_itr, T (&
# 601
items)[ITEMS_PER_THREAD], int 
# 602
valid_items) 
# 603
{int volatile ___ = 1;(void)block_itr;(void)items;(void)valid_items;
# 605
::exit(___);}
#if 0
# 603
{ 
# 604
StoreDirectBlocked(linear_tid, block_itr, items, valid_items); 
# 605
} 
#endif
# 606 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_store.cuh"
}; 
# 612
template< int DUMMY> 
# 613
struct StoreInternal< BLOCK_STORE_TRANSPOSE, DUMMY>  { 
# 616
typedef cub_::BlockExchange< typename std::iterator_traits< OutputIterator> ::value_type, BLOCK_DIM_X, ITEMS_PER_THREAD, WARP_TIME_SLICING, BLOCK_DIM_Y, BLOCK_DIM_Z, PTX_ARCH>  BlockExchange; 
# 619
typedef typename cub_::BlockExchange< typename std::iterator_traits< OutputIterator> ::value_type, BLOCK_DIM_X, ITEMS_PER_THREAD, WARP_TIME_SLICING, BLOCK_DIM_Y, BLOCK_DIM_Z, PTX_ARCH> ::TempStorage _TempStorage; 
# 622
struct TempStorage : public Uninitialized< typename cub_::BlockExchange< typename std::iterator_traits< OutputIterator> ::value_type, BLOCK_DIM_X, ITEMS_PER_THREAD, WARP_TIME_SLICING, BLOCK_DIM_Y, BLOCK_DIM_Z, PTX_ARCH> ::TempStorage>  { }; 
# 625
_TempStorage &temp_storage; 
# 628
int linear_tid; 
# 631
__attribute((always_inline)) StoreInternal(TempStorage &
# 632
temp_storage, int 
# 633
linear_tid) : temp_storage((temp_storage.Alias())), linear_tid(linear_tid) 
# 637
{int *volatile ___ = 0;(void)temp_storage;(void)linear_tid;::free(___);}
#if 0
# 637
{ } 
#endif
# 640 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_store.cuh"
__attribute((always_inline)) void Store(OutputIterator 
# 641
block_itr, T (&
# 642
items)[ITEMS_PER_THREAD]) 
# 643
{int volatile ___ = 1;(void)block_itr;(void)items;
# 646
::exit(___);}
#if 0
# 643
{ 
# 644
(((BlockExchange)(temp_storage)).BlockedToStriped(items)); 
# 645
StoreDirectStriped< BLOCK_THREADS> (linear_tid, block_itr, items); 
# 646
} 
#endif
# 649 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_store.cuh"
__attribute((always_inline)) void Store(OutputIterator 
# 650
block_itr, T (&
# 651
items)[ITEMS_PER_THREAD], int 
# 652
valid_items) 
# 653
{int volatile ___ = 1;(void)block_itr;(void)items;(void)valid_items;
# 656
::exit(___);}
#if 0
# 653
{ 
# 654
(((BlockExchange)(temp_storage)).BlockedToStriped(items)); 
# 655
StoreDirectStriped< BLOCK_THREADS> (linear_tid, block_itr, items, valid_items); 
# 656
} 
#endif
# 657 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_store.cuh"
}; 
# 663
template< int DUMMY> 
# 664
struct StoreInternal< BLOCK_STORE_WARP_TRANSPOSE, DUMMY>  { 
# 667
enum { 
# 668
WARP_THREADS = 1 << 5
# 669
}; 
# 672
typedef int cub_static_assert672[(((BLOCK_THREADS) % (WARP_THREADS)) == 0) ? 1 : (-1)]; 
# 675
typedef cub_::BlockExchange< typename std::iterator_traits< OutputIterator> ::value_type, BLOCK_DIM_X, ITEMS_PER_THREAD, WARP_TIME_SLICING, BLOCK_DIM_Y, BLOCK_DIM_Z, PTX_ARCH>  BlockExchange; 
# 678
typedef typename cub_::BlockExchange< typename std::iterator_traits< OutputIterator> ::value_type, BLOCK_DIM_X, ITEMS_PER_THREAD, WARP_TIME_SLICING, BLOCK_DIM_Y, BLOCK_DIM_Z, PTX_ARCH> ::TempStorage _TempStorage; 
# 681
struct TempStorage : public Uninitialized< typename cub_::BlockExchange< typename std::iterator_traits< OutputIterator> ::value_type, BLOCK_DIM_X, ITEMS_PER_THREAD, WARP_TIME_SLICING, BLOCK_DIM_Y, BLOCK_DIM_Z, PTX_ARCH> ::TempStorage>  { }; 
# 684
_TempStorage &temp_storage; 
# 687
int linear_tid; 
# 690
__attribute((always_inline)) StoreInternal(TempStorage &
# 691
temp_storage, int 
# 692
linear_tid) : temp_storage((temp_storage.Alias())), linear_tid(linear_tid) 
# 696
{int *volatile ___ = 0;(void)temp_storage;(void)linear_tid;::free(___);}
#if 0
# 696
{ } 
#endif
# 699 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_store.cuh"
__attribute((always_inline)) void Store(OutputIterator 
# 700
block_itr, T (&
# 701
items)[ITEMS_PER_THREAD]) 
# 702
{int volatile ___ = 1;(void)block_itr;(void)items;
# 705
::exit(___);}
#if 0
# 702
{ 
# 703
(((BlockExchange)(temp_storage)).BlockedToWarpStriped(items)); 
# 704
StoreDirectWarpStriped(linear_tid, block_itr, items); 
# 705
} 
#endif
# 708 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_store.cuh"
__attribute((always_inline)) void Store(OutputIterator 
# 709
block_itr, T (&
# 710
items)[ITEMS_PER_THREAD], int 
# 711
valid_items) 
# 712
{int volatile ___ = 1;(void)block_itr;(void)items;(void)valid_items;
# 715
::exit(___);}
#if 0
# 712
{ 
# 713
(((BlockExchange)(temp_storage)).BlockedToWarpStriped(items)); 
# 714
StoreDirectWarpStriped(linear_tid, block_itr, items, valid_items); 
# 715
} 
#endif
# 716 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_store.cuh"
}; 
# 723
typedef StoreInternal< ALGORITHM, 0>  InternalStore; 
# 727
typedef typename StoreInternal< ALGORITHM, 0> ::TempStorage _TempStorage; 
# 735
__attribute((always_inline)) _TempStorage &PrivateStorage() 
# 736
{int volatile ___ = 1;
# 739
::exit(___);}
#if 0
# 736
{ 
# 737
__attribute__((unused)) static _TempStorage private_storage; 
# 738
return private_storage; 
# 739
} 
#endif
# 747 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_store.cuh"
_TempStorage &temp_storage; 
# 750
int linear_tid; 
# 756
public: struct TempStorage : public Uninitialized< typename StoreInternal< ALGORITHM, 0> ::TempStorage>  { }; 
# 767
__attribute((always_inline)) BlockStore() : temp_storage(PrivateStorage()), linear_tid(RowMajorTid(BLOCK_DIM_X, BLOCK_DIM_Y, BLOCK_DIM_Z)) 
# 771
{int *volatile ___ = 0;::free(___);}
#if 0
# 771
{ } 
#endif
# 777 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_store.cuh"
__attribute((always_inline)) BlockStore(TempStorage &
# 778
temp_storage) : temp_storage((temp_storage.Alias())), linear_tid(RowMajorTid(BLOCK_DIM_X, BLOCK_DIM_Y, BLOCK_DIM_Z)) 
# 782
{int *volatile ___ = 0;(void)temp_storage;::free(___);}
#if 0
# 782
{ } 
#endif
# 832 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_store.cuh"
__attribute((always_inline)) void Store(OutputIterator 
# 833
block_itr, T (&
# 834
items)[ITEMS_PER_THREAD]) 
# 835
{int volatile ___ = 1;(void)block_itr;(void)items;
# 837
::exit(___);}
#if 0
# 835
{ 
# 836
(InternalStore(temp_storage, linear_tid).Store(block_itr, items)); 
# 837
} 
#endif
# 880 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_store.cuh"
__attribute((always_inline)) void Store(OutputIterator 
# 881
block_itr, T (&
# 882
items)[ITEMS_PER_THREAD], int 
# 883
valid_items) 
# 884
{int volatile ___ = 1;(void)block_itr;(void)items;(void)valid_items;
# 886
::exit(___);}
#if 0
# 884
{ 
# 885
(InternalStore(temp_storage, linear_tid).Store(block_itr, items, valid_items)); 
# 886
} 
#endif
# 887 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_store.cuh"
}; 
# 890
}
# 891
}}}}
# 43 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_shift.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 46
namespace cub_ { 
# 64
template< class 
# 65
T, int 
# 66
BLOCK_DIM_X, int 
# 67
BLOCK_DIM_Y = 1, int 
# 68
BLOCK_DIM_Z = 1, int 
# 69
PTX_ARCH = 0> 
# 70
class BlockShift { 
# 79
enum { 
# 80
BLOCK_THREADS = (BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z, 
# 82
LOG_WARP_THREADS = 5, 
# 83
WARP_THREADS = 1 << (5), 
# 84
WARPS = ((((BLOCK_DIM_X * BLOCK_DIM_Y) * BLOCK_DIM_Z) + (1 << (5))) - 1) / (1 << (5))
# 85
}; 
# 94
typedef typename If< PTX_ARCH >= 300, T [WARPS], T [BLOCK_THREADS]> ::Type _TempStorage; 
# 99
public: struct TempStorage : public Uninitialized< typename If< PTX_ARCH >= 300, T [WARPS], T [BLOCK_THREADS]> ::Type>  { }; 
# 109
private: _TempStorage &temp_storage; 
# 112
int linear_tid; 
# 113
int lane_id; 
# 114
int warp_id; 
# 122
__attribute((always_inline)) _TempStorage &PrivateStorage() 
# 123
{int volatile ___ = 1;
# 126
::exit(___);}
#if 0
# 123
{ 
# 124
__attribute__((unused)) static _TempStorage private_storage; 
# 125
return private_storage; 
# 126
} 
#endif
# 139 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_shift.cuh"
public: __attribute((always_inline)) BlockShift() : temp_storage(PrivateStorage()), linear_tid(RowMajorTid(BLOCK_DIM_X, BLOCK_DIM_Y, BLOCK_DIM_Z)), lane_id(LaneId()), warp_id(((WARPS) == 1) ? 0 : ((linear_tid) / (WARP_THREADS))) 
# 145
{int *volatile ___ = 0;::free(___);}
#if 0
# 145
{ } 
#endif
# 151 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_shift.cuh"
__attribute((always_inline)) BlockShift(TempStorage &
# 152
temp_storage) : temp_storage((temp_storage.Alias())), linear_tid(RowMajorTid(BLOCK_DIM_X, BLOCK_DIM_Y, BLOCK_DIM_Z)), lane_id(LaneId()), warp_id(((WARPS) == 1) ? 0 : ((linear_tid) / (WARP_THREADS))) 
# 158
{int *volatile ___ = 0;(void)temp_storage;::free(___);}
#if 0
# 158
{ } 
#endif
# 174 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_shift.cuh"
__attribute((always_inline)) void Up(T 
# 175
input, T &
# 176
output, T 
# 177
block_prefix) 
# 178
{int volatile ___ = 1;(void)input;(void)output;(void)block_prefix;
# 201
::exit(___);}
#if 0
# 178
{ 
# 193
((temp_storage)[linear_tid]) = input; 
# 195
__syncthreads(); 
# 197
output = (((linear_tid) == 0) ? block_prefix : ((temp_storage)[(linear_tid) - 1])); 
# 201
} 
#endif
# 210 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_shift.cuh"
__attribute((always_inline)) void Up(T 
# 211
input, T &
# 212
output, T 
# 213
block_prefix, T &
# 214
block_suffix) 
# 215
{int volatile ___ = 1;(void)input;(void)output;(void)block_prefix;(void)block_suffix;
# 241
::exit(___);}
#if 0
# 215
{ 
# 231
((temp_storage)[linear_tid]) = input; 
# 233
__syncthreads(); 
# 235
output = (((linear_tid) == 0) ? block_prefix : ((temp_storage)[(linear_tid) - 1])); 
# 239
block_suffix = ((temp_storage)[(BLOCK_THREADS) - 1]); 
# 241
} 
#endif
# 250 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_shift.cuh"
__attribute((always_inline)) void Down(T 
# 251
input, T &
# 252
output, T 
# 253
block_suffix) 
# 254
{int volatile ___ = 1;(void)input;(void)output;(void)block_suffix;
# 277
::exit(___);}
#if 0
# 254
{ 
# 269
((temp_storage)[linear_tid]) = input; 
# 271
__syncthreads(); 
# 273
output = (((linear_tid) == ((BLOCK_THREADS) - 1)) ? block_suffix : ((temp_storage)[(linear_tid) + 1])); 
# 277
} 
#endif
# 286 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_shift.cuh"
__attribute((always_inline)) void Down(T 
# 287
input, T &
# 288
output, T 
# 289
block_suffix, T &
# 290
block_prefix) 
# 291
{int volatile ___ = 1;(void)input;(void)output;(void)block_suffix;(void)block_prefix;
# 316
::exit(___);}
#if 0
# 291
{ 
# 306
((temp_storage)[linear_tid]) = input; 
# 308
__syncthreads(); 
# 310
output = (((linear_tid) == ((BLOCK_THREADS) - 1)) ? block_suffix : ((temp_storage)[(linear_tid) + 1])); 
# 315
block_prefix = ((temp_storage)[0]); 
# 316
} 
#endif
# 321 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/block/block_shift.cuh"
}; 
# 323
}
# 324
}}}}
# 42 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/specializations/block_histogram_gatomic_sweep.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 45
namespace cub_ { 
# 52
template< class 
# 53
BlockHistogramSweepPolicy, int 
# 54
BINS, int 
# 55
CHANNELS, int 
# 56
ACTIVE_CHANNELS, class 
# 57
InputIterator, class 
# 58
HistoCounter, class 
# 59
Offset> 
# 60
struct BlockHistogramSweepGlobalAtomic { 
# 67
typedef typename std::iterator_traits< InputIterator> ::value_type SampleT; 
# 71
enum { 
# 72
BLOCK_THREADS = BlockHistogramSweepPolicy::BLOCK_THREADS, 
# 73
ITEMS_PER_THREAD = BlockHistogramSweepPolicy::ITEMS_PER_THREAD, 
# 74
TILE_CHANNEL_ITEMS = (BlockHistogramSweepPolicy::BLOCK_THREADS) * (BlockHistogramSweepPolicy::ITEMS_PER_THREAD), 
# 75
TILE_ITEMS = ((BlockHistogramSweepPolicy::BLOCK_THREADS) * (BlockHistogramSweepPolicy::ITEMS_PER_THREAD)) * CHANNELS
# 76
}; 
# 79
typedef NullType TempStorage; 
# 87
HistoCounter *(&d_out_histograms)[ACTIVE_CHANNELS]; 
# 90
InputIterator d_in; 
# 100
__attribute((always_inline)) BlockHistogramSweepGlobalAtomic(TempStorage &
# 101
temp_storage, InputIterator 
# 102
d_in, HistoCounter *(&
# 103
d_out_histograms)[ACTIVE_CHANNELS]) : d_out_histograms(d_out_histograms), d_in(d_in) 
# 107
{int *volatile ___ = 0;(void)temp_storage;(void)d_in;(void)d_out_histograms;::free(___);}
#if 0
# 107
{ } 
#endif
# 113 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/specializations/block_histogram_gatomic_sweep.cuh"
template< bool FULL_TILE> 
# 114
__attribute((always_inline)) void ConsumeTile(Offset 
# 115
block_offset, int 
# 116
valid_items = TILE_ITEMS) 
# 117
{int volatile ___ = 1;(void)block_offset;(void)valid_items;
# 171
::exit(___);}
#if 0
# 117
{ 
# 118
if (FULL_TILE) 
# 119
{ 
# 121
SampleT items[ITEMS_PER_THREAD][CHANNELS]; 
# 124
#pragma unroll
for (
# 124
int ITEM = 0; ITEM < (ITEMS_PER_THREAD); ITEM++) 
# 125
{ 
# 127
#pragma unroll
for (
# 127
int CHANNEL = 0; CHANNEL < CHANNELS; ++CHANNEL) 
# 128
{ 
# 129
if (CHANNEL < ACTIVE_CHANNELS) 
# 130
{ 
# 131
(((items)[ITEM])[CHANNEL]) = ((d_in)[((block_offset + ((ITEM * (BLOCK_THREADS)) * CHANNELS)) + ((__device_builtin_variable_threadIdx.x) * (CHANNELS))) + CHANNEL]); 
# 132
}  
# 133
}  
# 134
}  
# 136
__threadfence_block(); 
# 139
#pragma unroll
for (
# 139
int ITEM = 0; ITEM < (ITEMS_PER_THREAD); ITEM++) 
# 140
{ 
# 142
#pragma unroll
for (
# 142
int CHANNEL = 0; CHANNEL < CHANNELS; ++CHANNEL) 
# 143
{ 
# 144
if (CHANNEL < ACTIVE_CHANNELS) 
# 145
{ 
# 146
atomicAdd(((d_out_histograms)[CHANNEL]) + (((items)[ITEM])[CHANNEL]), 1); 
# 147
}  
# 148
}  
# 149
}  
# 150
} else 
# 152
{ 
# 154
int bounds = valid_items - ((__device_builtin_variable_threadIdx.x) * (CHANNELS)); 
# 157
#pragma unroll
for (
# 157
int ITEM = 0; ITEM < (ITEMS_PER_THREAD); ++ITEM) 
# 158
{ 
# 160
#pragma unroll
for (
# 160
int CHANNEL = 0; CHANNEL < CHANNELS; ++CHANNEL) 
# 161
{ 
# 162
if (((ACTIVE_CHANNELS == CHANNELS) || (CHANNEL < ACTIVE_CHANNELS)) && ((((ITEM * (BLOCK_THREADS)) * CHANNELS) + CHANNEL) < bounds)) 
# 163
{ 
# 164
SampleT item = (d_in)[((block_offset + ((ITEM * (BLOCK_THREADS)) * CHANNELS)) + ((__device_builtin_variable_threadIdx.x) * (CHANNELS))) + CHANNEL]; 
# 165
atomicAdd(((d_out_histograms)[CHANNEL]) + item, 1); 
# 166
}  
# 167
}  
# 168
}  
# 170
}  
# 171
} 
#endif
# 177 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/specializations/block_histogram_gatomic_sweep.cuh"
__attribute((always_inline)) void AggregateOutput() 
# 178
{int volatile ___ = 1;::exit(___);}
#if 0
# 178
{ } 
#endif
# 179 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/specializations/block_histogram_gatomic_sweep.cuh"
}; 
# 182
}
# 183
}}}}
# 42 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/specializations/block_histogram_satomic_sweep.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 45
namespace cub_ { 
# 51
template< class 
# 52
BlockHistogramSweepPolicy, int 
# 53
BINS, int 
# 54
CHANNELS, int 
# 55
ACTIVE_CHANNELS, class 
# 56
InputIterator, class 
# 57
HistoCounter, class 
# 58
Offset> 
# 59
struct BlockHistogramSweepSharedAtomic { 
# 66
typedef typename std::iterator_traits< InputIterator> ::value_type SampleT; 
# 70
enum { 
# 71
BLOCK_THREADS = BlockHistogramSweepPolicy::BLOCK_THREADS, 
# 72
ITEMS_PER_THREAD = BlockHistogramSweepPolicy::ITEMS_PER_THREAD, 
# 73
TILE_CHANNEL_ITEMS = (BlockHistogramSweepPolicy::BLOCK_THREADS) * (BlockHistogramSweepPolicy::ITEMS_PER_THREAD), 
# 74
TILE_ITEMS = ((BlockHistogramSweepPolicy::BLOCK_THREADS) * (BlockHistogramSweepPolicy::ITEMS_PER_THREAD)) * CHANNELS
# 75
}; 
# 78
struct _TempStorage { 
# 80
HistoCounter histograms[ACTIVE_CHANNELS][BINS + 1]; 
# 81
}; 
# 85
struct TempStorage : public Uninitialized< _TempStorage>  { }; 
# 93
_TempStorage &temp_storage; 
# 96
HistoCounter *(&d_out_histograms)[ACTIVE_CHANNELS]; 
# 99
InputIterator d_in; 
# 109
__attribute((always_inline)) BlockHistogramSweepSharedAtomic(TempStorage &
# 110
temp_storage, InputIterator 
# 111
d_in, HistoCounter *(&
# 112
d_out_histograms)[ACTIVE_CHANNELS]) : temp_storage((temp_storage.Alias())), d_out_histograms(d_out_histograms), d_in(d_in) 
# 117
{int *volatile ___ = 0;(void)temp_storage;(void)d_in;(void)d_out_histograms;
# 137
::free(___);}
#if 0
# 117
{ 
# 120
#pragma unroll
for (
# 120
int CHANNEL = 0; CHANNEL < ACTIVE_CHANNELS; ++CHANNEL) 
# 121
{ 
# 122
int histo_offset = 0; 
# 125
#pragma unroll
for (; (histo_offset + (BLOCK_THREADS)) <= BINS; histo_offset += (BLOCK_THREADS)) { 
# 127
((((this->temp_storage).histograms)[CHANNEL])[histo_offset + (__device_builtin_variable_threadIdx.x)]) = 0; 
# 128
}  
# 130
if (((BINS % (BLOCK_THREADS)) != 0) && ((histo_offset + (__device_builtin_variable_threadIdx.x)) < (BINS))) 
# 131
{ 
# 132
((((this->temp_storage).histograms)[CHANNEL])[histo_offset + (__device_builtin_variable_threadIdx.x)]) = 0; 
# 133
}  
# 134
}  
# 136
__syncthreads(); 
# 137
} 
#endif
# 143 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/specializations/block_histogram_satomic_sweep.cuh"
template< bool FULL_TILE> 
# 144
__attribute((always_inline)) void ConsumeTile(Offset 
# 145
block_offset, int 
# 146
valid_items = TILE_ITEMS) 
# 147
{int volatile ___ = 1;(void)block_offset;(void)valid_items;
# 203
::exit(___);}
#if 0
# 147
{ 
# 148
if (FULL_TILE) 
# 149
{ 
# 151
SampleT items[ITEMS_PER_THREAD][CHANNELS]; 
# 154
#pragma unroll
for (
# 154
int ITEM = 0; ITEM < (ITEMS_PER_THREAD); ITEM++) 
# 155
{ 
# 157
#pragma unroll
for (
# 157
int CHANNEL = 0; CHANNEL < CHANNELS; ++CHANNEL) 
# 158
{ 
# 159
if (CHANNEL < ACTIVE_CHANNELS) 
# 160
{ 
# 161
(((items)[ITEM])[CHANNEL]) = ((d_in)[((block_offset + ((ITEM * (BLOCK_THREADS)) * CHANNELS)) + ((__device_builtin_variable_threadIdx.x) * (CHANNELS))) + CHANNEL]); 
# 162
}  
# 163
}  
# 164
}  
# 166
__threadfence_block(); 
# 169
#pragma unroll
for (
# 169
int ITEM = 0; ITEM < (ITEMS_PER_THREAD); ITEM++) 
# 170
{ 
# 172
#pragma unroll
for (
# 172
int CHANNEL = 0; CHANNEL < CHANNELS; ++CHANNEL) 
# 173
{ 
# 174
if (CHANNEL < ACTIVE_CHANNELS) 
# 175
{ 
# 176
atomicAdd((((temp_storage).histograms)[CHANNEL]) + (((items)[ITEM])[CHANNEL]), 1); 
# 177
}  
# 178
}  
# 179
}  
# 181
__threadfence_block(); 
# 182
} else 
# 184
{ 
# 186
int bounds = valid_items - ((__device_builtin_variable_threadIdx.x) * (CHANNELS)); 
# 189
#pragma unroll
for (
# 189
int ITEM = 0; ITEM < (ITEMS_PER_THREAD); ++ITEM) 
# 190
{ 
# 192
#pragma unroll
for (
# 192
int CHANNEL = 0; CHANNEL < CHANNELS; ++CHANNEL) 
# 193
{ 
# 194
if (((ACTIVE_CHANNELS == CHANNELS) || (CHANNEL < ACTIVE_CHANNELS)) && ((((ITEM * (BLOCK_THREADS)) * CHANNELS) + CHANNEL) < bounds)) 
# 195
{ 
# 196
SampleT item = (d_in)[((block_offset + ((ITEM * (BLOCK_THREADS)) * CHANNELS)) + ((__device_builtin_variable_threadIdx.x) * (CHANNELS))) + CHANNEL]; 
# 197
atomicAdd((((temp_storage).histograms)[CHANNEL]) + item, 1); 
# 198
}  
# 199
}  
# 200
}  
# 202
}  
# 203
} 
#endif
# 209 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/specializations/block_histogram_satomic_sweep.cuh"
__attribute((always_inline)) void AggregateOutput() 
# 210
{int volatile ___ = 1;
# 238
::exit(___);}
#if 0
# 210
{ 
# 212
__syncthreads(); 
# 215
int channel_offset = (__device_builtin_variable_blockIdx.x) * (BINS); 
# 218
#pragma unroll
for (
# 218
int CHANNEL = 0; CHANNEL < ACTIVE_CHANNELS; ++CHANNEL) 
# 219
{ 
# 220
int histo_offset = 0; 
# 223
#pragma unroll
for (; (histo_offset + (BLOCK_THREADS)) <= BINS; histo_offset += (BLOCK_THREADS)) { 
# 225
HistoCounter count = (((temp_storage).histograms)[CHANNEL])[histo_offset + (__device_builtin_variable_threadIdx.x)]; 
# 227
(((d_out_histograms)[CHANNEL])[(channel_offset + histo_offset) + (__device_builtin_variable_threadIdx.x)]) = count; 
# 228
}  
# 231
if (((BINS % (BLOCK_THREADS)) != 0) && ((histo_offset + (__device_builtin_variable_threadIdx.x)) < (BINS))) 
# 232
{ 
# 233
HistoCounter count = (((temp_storage).histograms)[CHANNEL])[histo_offset + (__device_builtin_variable_threadIdx.x)]; 
# 235
(((d_out_histograms)[CHANNEL])[(channel_offset + histo_offset) + (__device_builtin_variable_threadIdx.x)]) = count; 
# 236
}  
# 237
}  
# 238
} 
#endif
# 239 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/specializations/block_histogram_satomic_sweep.cuh"
}; 
# 243
}
# 244
}}}}
# 43 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/specializations/block_histogram_sort_sweep.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 46
namespace cub_ { 
# 52
template< class 
# 53
BlockHistogramSweepPolicy, int 
# 54
BINS, int 
# 55
CHANNELS, int 
# 56
ACTIVE_CHANNELS, class 
# 57
InputIterator, class 
# 58
HistoCounter, class 
# 59
Offset> 
# 60
struct BlockHistogramSweepSort { 
# 67
typedef typename std::iterator_traits< InputIterator> ::value_type SampleT; 
# 71
enum { 
# 72
BLOCK_THREADS = BlockHistogramSweepPolicy::BLOCK_THREADS, 
# 73
ITEMS_PER_THREAD = BlockHistogramSweepPolicy::ITEMS_PER_THREAD, 
# 74
TILE_CHANNEL_ITEMS = (BlockHistogramSweepPolicy::BLOCK_THREADS) * (BlockHistogramSweepPolicy::ITEMS_PER_THREAD), 
# 75
TILE_ITEMS = ((BlockHistogramSweepPolicy::BLOCK_THREADS) * (BlockHistogramSweepPolicy::ITEMS_PER_THREAD)) * CHANNELS, 
# 77
STRIPED_COUNTERS_PER_THREAD = ((BINS + (BlockHistogramSweepPolicy::BLOCK_THREADS)) - 1) / (BlockHistogramSweepPolicy::BLOCK_THREADS)
# 78
}; 
# 81
typedef BlockRadixSort< typename std::iterator_traits< InputIterator> ::value_type, BLOCK_THREADS, ITEMS_PER_THREAD>  BlockRadixSortT; 
# 84
typedef BlockDiscontinuity< typename std::iterator_traits< InputIterator> ::value_type, BLOCK_THREADS>  BlockDiscontinuityT; 
# 87
union _TempStorage { 
# 90
typename BlockRadixSort< typename std::iterator_traits< InputIterator> ::value_type, BLOCK_THREADS, ITEMS_PER_THREAD> ::TempStorage sort; 
# 93
struct { 
# 95
typename BlockDiscontinuity< typename std::iterator_traits< InputIterator> ::value_type, BLOCK_THREADS> ::TempStorage flag; 
# 98
int run_begin[(BLOCK_THREADS) * (STRIPED_COUNTERS_PER_THREAD)]; 
# 99
int run_end[(BLOCK_THREADS) * (STRIPED_COUNTERS_PER_THREAD)]; 
# 100
}; 
# 101
}; 
# 105
struct TempStorage : public Uninitialized< _TempStorage>  { }; 
# 109
struct DiscontinuityOp { 
# 112
_TempStorage &temp_storage; 
# 115
__attribute((always_inline)) DiscontinuityOp(_TempStorage &temp_storage) : temp_storage(temp_storage) 
# 117
{int *volatile ___ = 0;(void)temp_storage;::free(___);}
#if 0
# 117
{ } 
#endif
# 120 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/specializations/block_histogram_sort_sweep.cuh"
__attribute((always_inline)) bool operator()(const SampleT &a, const SampleT &b, int b_index) 
# 121
{int volatile ___ = 1;(void)a;(void)b;(void)b_index;
# 134
::exit(___);}
#if 0
# 121
{ 
# 122
if (a != b) 
# 123
{ 
# 125
(((temp_storage).run_begin)[b]) = b_index; 
# 126
(((temp_storage).run_end)[a]) = b_index; 
# 128
return true; 
# 129
} else 
# 131
{ 
# 132
return false; 
# 133
}  
# 134
} 
#endif
# 135 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/specializations/block_histogram_sort_sweep.cuh"
}; 
# 143
_TempStorage &temp_storage; 
# 146
HistoCounter thread_counters[ACTIVE_CHANNELS][STRIPED_COUNTERS_PER_THREAD]; 
# 149
HistoCounter *(&d_out_histograms)[ACTIVE_CHANNELS]; 
# 152
InputIterator d_in; 
# 162
__attribute((always_inline)) BlockHistogramSweepSort(TempStorage &
# 163
temp_storage, InputIterator 
# 164
d_in, HistoCounter *(&
# 165
d_out_histograms)[ACTIVE_CHANNELS]) : temp_storage((temp_storage.Alias())), d_out_histograms(d_out_histograms), d_in(d_in) 
# 170
{int *volatile ___ = 0;(void)temp_storage;(void)d_in;(void)d_out_histograms;
# 181
::free(___);}
#if 0
# 170
{ 
# 173
#pragma unroll
for (
# 173
int CHANNEL = 0; CHANNEL < ACTIVE_CHANNELS; ++CHANNEL) 
# 174
{ 
# 176
#pragma unroll
for (
# 176
int COUNTER = 0; COUNTER < (STRIPED_COUNTERS_PER_THREAD); ++COUNTER) 
# 177
{ 
# 178
(((thread_counters)[CHANNEL])[COUNTER]) = 0; 
# 179
}  
# 180
}  
# 181
} 
#endif
# 187 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/specializations/block_histogram_sort_sweep.cuh"
__attribute((always_inline)) void Composite(SampleT (&
# 188
items)[ITEMS_PER_THREAD], HistoCounter 
# 189
thread_counters[]) 
# 190
{int volatile ___ = 1;(void)items;(void)thread_counters;
# 226
::exit(___);}
#if 0
# 190
{ 
# 192
(((BlockRadixSortT)(((temp_storage).sort))).Sort(items)); 
# 194
__syncthreads(); 
# 198
#pragma unroll
for (
# 198
int COUNTER = 0; COUNTER < (STRIPED_COUNTERS_PER_THREAD); ++COUNTER) 
# 199
{ 
# 200
(((temp_storage).run_begin)[(COUNTER * (BLOCK_THREADS)) + (__device_builtin_variable_threadIdx.x)]) = (TILE_CHANNEL_ITEMS); 
# 201
(((temp_storage).run_end)[(COUNTER * (BLOCK_THREADS)) + (__device_builtin_variable_threadIdx.x)]) = (TILE_CHANNEL_ITEMS); 
# 202
}  
# 204
__syncthreads(); 
# 207
int flags[ITEMS_PER_THREAD]; 
# 208
DiscontinuityOp flag_op(temp_storage); 
# 209
(((BlockDiscontinuityT)(((temp_storage).flag))).FlagHeads(flags, items, flag_op)); 
# 212
if ((__device_builtin_variable_threadIdx.x) == (0)) { (((temp_storage).run_begin)[(items)[0]]) = 0; }  
# 214
__syncthreads(); 
# 219
#pragma unroll
for (
# 219
int COUNTER = 0; COUNTER < (STRIPED_COUNTERS_PER_THREAD); ++COUNTER) 
# 220
{ 
# 221
int bin = (COUNTER * (BLOCK_THREADS)) + (__device_builtin_variable_threadIdx.x); 
# 222
HistoCounter run_length = (((temp_storage).run_end)[bin]) - (((temp_storage).run_begin)[bin]); 
# 224
(thread_counters[COUNTER]) += run_length; 
# 225
}  
# 226
} 
#endif
# 232 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/specializations/block_histogram_sort_sweep.cuh"
template< bool FULL_TILE> 
# 233
__attribute((always_inline)) void ConsumeTileChannel(int 
# 234
channel, Offset 
# 235
block_offset, int 
# 236
valid_items) 
# 237
{int volatile ___ = 1;(void)channel;(void)block_offset;(void)valid_items;
# 282
::exit(___);}
#if 0
# 237
{ 
# 239
if (FULL_TILE) 
# 240
{ 
# 242
SampleT items[ITEMS_PER_THREAD]; 
# 246
#pragma unroll
for (
# 246
int ITEM = 0; ITEM < (ITEMS_PER_THREAD); ITEM++) 
# 247
{ 
# 248
((items)[ITEM]) = ((d_in)[((channel + block_offset) + ((ITEM * (BLOCK_THREADS)) * CHANNELS)) + ((__device_builtin_variable_threadIdx.x) * (CHANNELS))]); 
# 249
}  
# 252
Composite(items, (thread_counters)[channel]); 
# 253
} else 
# 255
{ 
# 257
SampleT items[ITEMS_PER_THREAD]; 
# 260
int bounds = valid_items - ((__device_builtin_variable_threadIdx.x) * (CHANNELS)); 
# 263
#pragma unroll
for (
# 263
int ITEM = 0; ITEM < (ITEMS_PER_THREAD); ITEM++) 
# 264
{ 
# 265
((items)[ITEM]) = ((((ITEM * (BLOCK_THREADS)) * CHANNELS) < bounds) ? (d_in)[((channel + block_offset) + ((ITEM * (BLOCK_THREADS)) * CHANNELS)) + ((__device_builtin_variable_threadIdx.x) * (CHANNELS))] : 0); 
# 268
}  
# 271
Composite(items, (thread_counters)[channel]); 
# 273
__syncthreads(); 
# 276
if ((__device_builtin_variable_threadIdx.x) == (0)) 
# 277
{ 
# 278
int extra = ((TILE_ITEMS) - valid_items) / CHANNELS; 
# 279
(((thread_counters)[channel])[0]) -= extra; 
# 280
}  
# 281
}  
# 282
} 
#endif
# 288 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/specializations/block_histogram_sort_sweep.cuh"
template< bool FULL_TILE, int CHANNEL, int END> 
# 289
struct IterateChannels { 
# 294
__attribute((always_inline)) static void ConsumeTileChannel(BlockHistogramSweepSort *
# 295
cta, Offset 
# 296
block_offset, int 
# 297
valid_items) 
# 298
{int volatile ___ = 1;(void)cta;(void)block_offset;(void)valid_items;
# 304
::exit(___);}
#if 0
# 298
{ 
# 299
__syncthreads(); 
# 301
(cta->template ConsumeTileChannel< FULL_TILE> (CHANNEL, block_offset, valid_items)); 
# 303
IterateChannels< FULL_TILE, CHANNEL + 1, END> ::ConsumeTileChannel(cta, block_offset, valid_items); 
# 304
} 
#endif
# 305 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/specializations/block_histogram_sort_sweep.cuh"
}; 
# 311
template< bool FULL_TILE, int END> 
# 312
struct IterateChannels< FULL_TILE, END, END>  { 
# 314
__attribute((always_inline)) static void ConsumeTileChannel(BlockHistogramSweepSort *cta, Offset block_offset, int valid_items) {int volatile ___ = 1;(void)cta;(void)block_offset;(void)valid_items;::exit(___);}
#if 0
# 314
{ } 
#endif
# 315 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/specializations/block_histogram_sort_sweep.cuh"
}; 
# 321
template< bool FULL_TILE> 
# 322
__attribute((always_inline)) void ConsumeTile(Offset 
# 323
block_offset, int 
# 324
valid_items = TILE_ITEMS) 
# 325
{int volatile ___ = 1;(void)block_offset;(void)valid_items;
# 331
::exit(___);}
#if 0
# 325
{ 
# 327
ConsumeTileChannel< FULL_TILE> (0, block_offset, valid_items); 
# 330
IterateChannels< FULL_TILE, 1, ACTIVE_CHANNELS> ::ConsumeTileChannel(this, block_offset, valid_items); 
# 331
} 
#endif
# 337 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/specializations/block_histogram_sort_sweep.cuh"
__attribute((always_inline)) void AggregateOutput() 
# 338
{int volatile ___ = 1;
# 356
::exit(___);}
#if 0
# 338
{ 
# 341
#pragma unroll
for (
# 341
int CHANNEL = 0; CHANNEL < ACTIVE_CHANNELS; ++CHANNEL) 
# 342
{ 
# 343
int channel_offset = (__device_builtin_variable_blockIdx.x) * (BINS); 
# 346
#pragma unroll
for (
# 346
int COUNTER = 0; COUNTER < (STRIPED_COUNTERS_PER_THREAD); ++COUNTER) 
# 347
{ 
# 348
int bin = (COUNTER * (BLOCK_THREADS)) + (__device_builtin_variable_threadIdx.x); 
# 350
if ((((STRIPED_COUNTERS_PER_THREAD) * (BLOCK_THREADS)) == BINS) || (bin < BINS)) 
# 351
{ 
# 352
(((d_out_histograms)[CHANNEL])[channel_offset + bin]) = (((thread_counters)[CHANNEL])[COUNTER]); 
# 353
}  
# 354
}  
# 355
}  
# 356
} 
#endif
# 357 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/specializations/block_histogram_sort_sweep.cuh"
}; 
# 362
}
# 363
}}}}
# 39 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/../grid/grid_mapping.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 42
namespace cub_ { 
# 59
enum GridMappingStrategy { 
# 74
GRID_MAPPING_EVEN_SHARE, 
# 87
GRID_MAPPING_DYNAMIC
# 88
}; 
# 93
}
# 94
}}}}
# 41 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/../grid/grid_even_share.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 44
namespace cub_ { 
# 70
template< class Offset> 
# 71
struct GridEvenShare { 
# 73
Offset total_grains; 
# 74
int big_blocks; 
# 75
Offset big_share; 
# 76
Offset normal_share; 
# 77
Offset normal_base_offset; 
# 80
Offset num_items; 
# 83
int grid_size; 
# 86
Offset block_offset; 
# 89
Offset block_end; 
# 94
__attribute((always_inline)) GridEvenShare() : num_items(0), grid_size(0), block_offset(0), block_end(0) 
# 98
{ } 
# 103
__attribute((always_inline)) GridEvenShare(Offset 
# 104
num_items, int 
# 105
max_grid_size, int 
# 106
schedule_granularity) 
# 107
{ 
# 108
(this->num_items) = num_items; 
# 109
(this->block_offset) = num_items; 
# 110
(this->block_end) = num_items; 
# 111
(this->total_grains) = (((num_items + schedule_granularity) - 1) / schedule_granularity); 
# 112
(this->grid_size) = ((max_grid_size < (total_grains)) ? max_grid_size : (total_grains)); 
# 113
Offset grains_per_block = (total_grains) / (grid_size); 
# 114
(this->big_blocks) = ((total_grains) - (grains_per_block * (grid_size))); 
# 115
(this->normal_share) = (grains_per_block * schedule_granularity); 
# 116
(this->normal_base_offset) = ((big_blocks) * schedule_granularity); 
# 117
(this->big_share) = ((normal_share) + schedule_granularity); 
# 118
} 
# 125
__attribute((always_inline)) void Init(int partition_id) 
# 126
{int volatile ___ = 1;(void)partition_id;
# 139
::exit(___);}
#if 0
# 126
{ 
# 127
if (partition_id < (big_blocks)) 
# 128
{ 
# 130
(block_offset) = (partition_id * (big_share)); 
# 131
(block_end) = ((block_offset) + (big_share)); 
# 132
} else { 
# 133
if (partition_id < (total_grains)) 
# 134
{ 
# 136
(block_offset) = ((normal_base_offset) + (partition_id * (normal_share))); 
# 137
(block_end) = ((((block_offset) + (normal_share)) < (num_items)) ? (block_offset) + (normal_share) : (num_items)); 
# 138
}  }  
# 139
} 
#endif
# 145 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/../grid/grid_even_share.cuh"
__attribute((always_inline)) void BlockInit() 
# 146
{int volatile ___ = 1;
# 148
::exit(___);}
#if 0
# 146
{ 
# 147
Init(__device_builtin_variable_blockIdx.x); 
# 148
} 
#endif
# 154 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/../grid/grid_even_share.cuh"
__attribute((always_inline)) void Print() 
# 155
{ 
# 156
printf("num_items(%lu)  total_grains(%lu)  big_blocks(%lu)  big_share(%lu)  normal_share(%lu)\n", (unsigned long)(num_items), (unsigned long)(total_grains), (unsigned long)(big_blocks), (unsigned long)(big_share), (unsigned long)(normal_share)); 
# 177
} 
# 178
}; 
# 184
}
# 185
}}}}
# 40 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/../grid/grid_queue.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 43
namespace cub_ { 
# 81
template< class Offset> 
# 82
class GridQueue { 
# 88
enum { 
# 89
FILL, 
# 90
DRAIN = 1
# 91
}; 
# 94
Offset *d_counters; 
# 100
public: 
# 99
__attribute((always_inline)) static size_t 
# 100
AllocationSize() 
# 101
{ 
# 102
return sizeof(Offset) * (2); 
# 103
} 
# 107
__attribute((always_inline)) GridQueue() : d_counters((__null)) 
# 110
{ } 
# 114
__attribute((always_inline)) GridQueue(void *
# 115
d_storage) : d_counters((Offset *)d_storage) 
# 118
{ } 
# 122
__attribute((always_inline)) cudaError_t FillAndResetDrain(Offset 
# 123
fill_size, cudaStream_t 
# 124
stream = 0) 
# 125
{ 
# 131
Offset counters[2]; 
# 132
(counters[FILL]) = fill_size; 
# 133
(counters[DRAIN]) = 0; 
# 134
return cub_::Debug(cudaMemcpyAsync(d_counters, counters, sizeof(Offset) * (2), cudaMemcpyHostToDevice, stream), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/../grid/grid_queue.cuh", 134); 
# 136
} 
# 140
__attribute((always_inline)) cudaError_t ResetDrain(cudaStream_t stream = 0) 
# 141
{ 
# 146
return FillAndResetDrain(0, stream); 
# 148
} 
# 152
__attribute((always_inline)) cudaError_t ResetFill() 
# 153
{ 
# 158
return cub_::Debug(cudaMemset((d_counters) + (FILL), 0, sizeof(Offset)), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/../grid/grid_queue.cuh", 158); 
# 160
} 
# 164
__attribute((always_inline)) cudaError_t FillSize(Offset &
# 165
fill_size, cudaStream_t 
# 166
stream = 0) 
# 167
{ 
# 172
return cub_::Debug(cudaMemcpyAsync(&fill_size, (d_counters) + (FILL), sizeof(Offset), cudaMemcpyDeviceToHost, stream), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/../grid/grid_queue.cuh", 172); 
# 174
} 
# 178
__attribute((always_inline)) Offset Drain(Offset num_items) 
# 179
{int volatile ___ = 1;(void)num_items;
# 181
::exit(___);}
#if 0
# 179
{ 
# 180
return atomicAdd((d_counters) + (DRAIN), num_items); 
# 181
} 
#endif
# 185 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/../grid/grid_queue.cuh"
__attribute((always_inline)) Offset Fill(Offset num_items) 
# 186
{int volatile ___ = 1;(void)num_items;
# 188
::exit(___);}
#if 0
# 186
{ 
# 187
return atomicAdd((d_counters) + (FILL), num_items); 
# 188
} 
#endif
# 189 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/../grid/grid_queue.cuh"
}; 
# 198
template< class Offset> static void 
# 199
__wrapper__device_stub_FillAndResetDrainKernel(GridQueue< Offset>  &
# 200
grid_queue, Offset &
# 201
num_items) {exit(1);}
#if 0
# 202
{ 
# 203
(grid_queue.FillAndResetDrain(num_items)); 
# 204
} 
#endif
# 198 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/../grid/grid_queue.cuh"
template< class Offset> void 
# 199
FillAndResetDrainKernel(GridQueue< Offset>  
# 200
grid_queue, Offset 
# 201
num_items) 
# 202
{__wrapper__device_stub_FillAndResetDrainKernel<Offset>(grid_queue,num_items);
# 204
return;}
#if 0
# 202
{ 
# 203
(grid_queue.FillAndResetDrain(num_items)); 
# 204
} 
#endif
# 213 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/../grid/grid_queue.cuh"
}
# 214
}}}}
# 48 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_histogram_sweep.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 51
namespace cub_ { 
# 62
enum DeviceHistogramAlgorithm { 
# 79
DEVICE_HISTO_SORT, 
# 100
DEVICE_HISTO_SHARED_ATOMIC, 
# 117
DEVICE_HISTO_GLOBAL_ATOMIC
# 119
}; 
# 129
template< int 
# 130
_BLOCK_THREADS, int 
# 131
_ITEMS_PER_THREAD, DeviceHistogramAlgorithm 
# 132
_HISTO_ALGORITHM, GridMappingStrategy 
# 133
_GRID_MAPPING> 
# 134
struct BlockHistogramSweepPolicy { 
# 137
enum { 
# 138
BLOCK_THREADS = _BLOCK_THREADS, 
# 139
ITEMS_PER_THREAD = _ITEMS_PER_THREAD
# 140
}; 
# 142
static const DeviceHistogramAlgorithm HISTO_ALGORITHM = _HISTO_ALGORITHM; 
# 143
static const GridMappingStrategy GRID_MAPPING = _GRID_MAPPING; 
# 144
}; 
# 155
template< class 
# 156
BlockHistogramSweepPolicy, int 
# 157
BINS, int 
# 158
CHANNELS, int 
# 159
ACTIVE_CHANNELS, class 
# 160
InputIterator, class 
# 161
HistoCounter, class 
# 162
Offset> 
# 163
struct BlockHistogramSweep { 
# 170
static const DeviceHistogramAlgorithm HISTO_ALGORITHM = (BlockHistogramSweepPolicy::HISTO_ALGORITHM); 
# 173
typedef BlockHistogramSweepSort< BlockHistogramSweepPolicy, BINS, CHANNELS, ACTIVE_CHANNELS, InputIterator, HistoCounter, Offset>  BlockHistogramSweepSortT; 
# 174
typedef BlockHistogramSweepSharedAtomic< BlockHistogramSweepPolicy, BINS, CHANNELS, ACTIVE_CHANNELS, InputIterator, HistoCounter, Offset>  BlockHistogramSweepSharedAtomicT; 
# 175
typedef BlockHistogramSweepGlobalAtomic< BlockHistogramSweepPolicy, BINS, CHANNELS, ACTIVE_CHANNELS, InputIterator, HistoCounter, Offset>  BlockHistogramSweepGlobalAtomicT; 
# 182
typedef typename If< HISTO_ALGORITHM == (DEVICE_HISTO_SORT), BlockHistogramSweepSort< BlockHistogramSweepPolicy, BINS, CHANNELS, ACTIVE_CHANNELS, InputIterator, HistoCounter, Offset> , typename If< HISTO_ALGORITHM == (DEVICE_HISTO_SHARED_ATOMIC), BlockHistogramSweepSharedAtomic< BlockHistogramSweepPolicy, BINS, CHANNELS, ACTIVE_CHANNELS, InputIterator, HistoCounter, Offset> , BlockHistogramSweepGlobalAtomic< BlockHistogramSweepPolicy, BINS, CHANNELS, ACTIVE_CHANNELS, InputIterator, HistoCounter, Offset> > ::Type> ::Type InternalBlockDelegate; 
# 185
enum { 
# 186
TILE_ITEMS = If< HISTO_ALGORITHM == (DEVICE_HISTO_SORT), BlockHistogramSweepSort< BlockHistogramSweepPolicy, BINS, CHANNELS, ACTIVE_CHANNELS, InputIterator, HistoCounter, Offset> , typename If< HISTO_ALGORITHM == (DEVICE_HISTO_SHARED_ATOMIC), BlockHistogramSweepSharedAtomic< BlockHistogramSweepPolicy, BINS, CHANNELS, ACTIVE_CHANNELS, InputIterator, HistoCounter, Offset> , BlockHistogramSweepGlobalAtomic< BlockHistogramSweepPolicy, BINS, CHANNELS, ACTIVE_CHANNELS, InputIterator, HistoCounter, Offset> > ::Type> ::Type::TILE_ITEMS
# 187
}; 
# 191
typedef typename If< HISTO_ALGORITHM == (DEVICE_HISTO_SORT), BlockHistogramSweepSort< BlockHistogramSweepPolicy, BINS, CHANNELS, ACTIVE_CHANNELS, InputIterator, HistoCounter, Offset> , typename If< HISTO_ALGORITHM == (DEVICE_HISTO_SHARED_ATOMIC), BlockHistogramSweepSharedAtomic< BlockHistogramSweepPolicy, BINS, CHANNELS, ACTIVE_CHANNELS, InputIterator, HistoCounter, Offset> , BlockHistogramSweepGlobalAtomic< BlockHistogramSweepPolicy, BINS, CHANNELS, ACTIVE_CHANNELS, InputIterator, HistoCounter, Offset> > ::Type> ::Type::TempStorage TempStorage; 
# 198
InternalBlockDelegate internal_delegate; 
# 208
__attribute((always_inline)) BlockHistogramSweep(TempStorage &
# 209
temp_storage, InputIterator 
# 210
d_in, HistoCounter *(&
# 211
d_out_histograms)[ACTIVE_CHANNELS]) : internal_delegate(temp_storage, d_in, d_out_histograms) 
# 214
{int *volatile ___ = 0;(void)temp_storage;(void)d_in;(void)d_out_histograms;::free(___);}
#if 0
# 214
{ } 
#endif
# 220 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_histogram_sweep.cuh"
__attribute((always_inline)) void ConsumeRange(Offset 
# 221
block_offset, Offset 
# 222
block_end) 
# 223
{int volatile ___ = 1;(void)block_offset;(void)block_end;
# 240
::exit(___);}
#if 0
# 223
{ 
# 225
while ((block_offset + (TILE_ITEMS)) <= block_end) 
# 226
{ 
# 227
(((internal_delegate).ConsumeTile) < true) > block_offset; 
# 228
block_offset += (TILE_ITEMS); 
# 229
}  
# 232
if (block_offset < block_end) 
# 233
{ 
# 234
int valid_items = block_end - block_offset; 
# 235
(((internal_delegate).ConsumeTile) < false) > (block_offset, valid_items); 
# 236
}  
# 239
((internal_delegate).AggregateOutput()); 
# 240
} 
#endif
# 246 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_histogram_sweep.cuh"
__attribute((always_inline)) void ConsumeRange(Offset 
# 247
num_items, GridEvenShare< Offset>  &
# 248
even_share, GridQueue< Offset>  &
# 249
queue, Int2Type< 0>  
# 250
is_even_share) 
# 251
{int volatile ___ = 1;(void)num_items;(void)even_share;(void)queue;(void)is_even_share;
# 254
::exit(___);}
#if 0
# 251
{ 
# 252
(even_share.BlockInit()); 
# 253
ConsumeRange((even_share.block_offset), (even_share.block_end)); 
# 254
} 
#endif
# 260 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_histogram_sweep.cuh"
__attribute((always_inline)) void ConsumeRange(int 
# 261
num_items, GridQueue< Offset>  
# 262
queue) 
# 263
{int volatile ___ = 1;(void)num_items;(void)queue;
# 296
::exit(___);}
#if 0
# 263
{ 
# 265
__attribute__((unused)) static Offset shared_block_offset; 
# 268
Offset block_offset = (__device_builtin_variable_blockIdx.x) * (TILE_ITEMS); 
# 269
Offset even_share_base = (__device_builtin_variable_gridDim.x) * (TILE_ITEMS); 
# 272
while ((block_offset + (TILE_ITEMS)) <= num_items) 
# 273
{ 
# 274
(((internal_delegate).ConsumeTile) < true) > block_offset; 
# 277
if ((__device_builtin_variable_threadIdx.x) == (0)) { 
# 278
shared_block_offset = ((queue.Drain(TILE_ITEMS)) + even_share_base); }  
# 280
__syncthreads(); 
# 282
block_offset = shared_block_offset; 
# 284
__syncthreads(); 
# 285
}  
# 288
if (block_offset < num_items) 
# 289
{ 
# 290
int valid_items = num_items - block_offset; 
# 291
(((internal_delegate).ConsumeTile) < false) > (block_offset, valid_items); 
# 292
}  
# 295
((internal_delegate).AggregateOutput()); 
# 296
} 
#endif
# 302 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_histogram_sweep.cuh"
__attribute((always_inline)) void ConsumeRange(Offset 
# 303
num_items, GridEvenShare< Offset>  &
# 304
even_share, GridQueue< Offset>  &
# 305
queue, Int2Type< 1>  
# 306
is_dynamic) 
# 307
{int volatile ___ = 1;(void)num_items;(void)even_share;(void)queue;(void)is_dynamic;
# 309
::exit(___);}
#if 0
# 307
{ 
# 308
ConsumeRange(num_items, queue); 
# 309
} 
#endif
# 312 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_histogram_sweep.cuh"
}; 
# 317
}
# 318
}}}}
# 42 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../util_device.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 45
namespace cub_ { 
# 59
template< class T> static void 
# 60
__wrapper__device_stub_EmptyKernel() {exit(1);}
#if 0
# 60
{ } 
#endif
# 59 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../util_device.cuh"
template< class T> void 
# 60
EmptyKernel() {__wrapper__device_stub_EmptyKernel<T>();return;}
#if 0
# 60
{ } 
#endif
# 66 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../util_device.cuh"
template< int ALLOCATIONS> 
# 67
__attribute((always_inline)) inline cudaError_t 
# 68
AliasTemporaries(void *
# 69
d_temp_storage, size_t &
# 70
temp_storage_bytes, void *(&
# 71
allocations)[ALLOCATIONS], size_t (&
# 72
allocation_sizes)[ALLOCATIONS]) 
# 73
{ 
# 74
const int ALIGN_BYTES = 256; 
# 75
const int ALIGN_MASK = (~(ALIGN_BYTES - 1)); 
# 78
size_t allocation_offsets[ALLOCATIONS]; 
# 79
size_t bytes_needed = (0); 
# 80
for (int i = 0; i < ALLOCATIONS; ++i) 
# 81
{ 
# 82
size_t allocation_bytes = ((((allocation_sizes)[i]) + ALIGN_BYTES) - 1) & ALIGN_MASK; 
# 83
((allocation_offsets)[i]) = bytes_needed; 
# 84
bytes_needed += allocation_bytes; 
# 85
}  
# 88
if (!d_temp_storage) 
# 89
{ 
# 90
temp_storage_bytes = bytes_needed; 
# 91
return cudaSuccess; 
# 92
}  
# 95
if (temp_storage_bytes < bytes_needed) 
# 96
{ 
# 97
return cub_::Debug(cudaErrorInvalidValue, "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../util_device.cuh", 97); 
# 98
}  
# 101
for (int i = 0; i < ALLOCATIONS; ++i) 
# 102
{ 
# 103
((allocations)[i]) = ((static_cast< char *>(d_temp_storage)) + ((allocation_offsets)[i])); 
# 104
}  
# 106
return cudaSuccess; 
# 107
} 
# 118
__attribute((always_inline)) inline cudaError_t PtxVersion(int &ptx_version) 
# 119
{ 
# 120
struct Dummy { 
# 123
typedef void (*EmptyKernelPtr)(void); 
# 126
__attribute((always_inline)) EmptyKernelPtr 
# 127
Empty() 
# 128
{ 
# 129
return EmptyKernel< void> ; 
# 130
} 
# 131
}; 
# 146
cudaError_t error = cudaSuccess; 
# 147
do 
# 148
{ 
# 149
cudaFuncAttributes empty_kernel_attrs; 
# 150
if (cub_::Debug(error = cudaFuncGetAttributes(&empty_kernel_attrs, EmptyKernel< void> ), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../util_device.cuh", 150)) { break; }  
# 151
ptx_version = ((empty_kernel_attrs.ptxVersion) * 10); 
# 152
} 
# 153
while (0); 
# 155
return error; 
# 158
} 
# 164
__attribute((always_inline)) inline cudaError_t SmVersion(int &sm_version, int device_ordinal) 
# 165
{ 
# 173
cudaError_t error = cudaSuccess; 
# 174
do 
# 175
{ 
# 177
int major, minor; 
# 178
if (cub_::Debug(error = cudaDeviceGetAttribute(&major, cudaDevAttrComputeCapabilityMajor, device_ordinal), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../util_device.cuh", 178)) { break; }  
# 179
if (cub_::Debug(error = cudaDeviceGetAttribute(&minor, cudaDevAttrComputeCapabilityMinor, device_ordinal), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../util_device.cuh", 179)) { break; }  
# 180
sm_version = ((major * 100) + (minor * 10)); 
# 181
} 
# 182
while (0); 
# 184
return error; 
# 187
} 
# 195
__attribute((always_inline)) static inline cudaError_t 
# 196
SyncStream(cudaStream_t stream) 
# 197
{ 
# 199
return cudaStreamSynchronize(stream); 
# 204
} 
# 210
template< class KernelPtr> 
# 211
__attribute((always_inline)) inline cudaError_t 
# 212
MaxSmOccupancy(int &
# 213
max_sm_occupancy, int 
# 214
sm_version, KernelPtr 
# 215
kernel_ptr, int 
# 216
block_threads) 
# 217
{ 
# 225
cudaError_t error = cudaSuccess; 
# 226
do 
# 227
{ 
# 228
int warp_threads = (1 << 5); 
# 229
int max_sm_blocks = (sm_version >= 300) ? 16 : 8; 
# 230
int max_sm_warps = ((sm_version >= 300) ? 2048 : ((sm_version >= 200) ? 1536 : ((sm_version >= 120) ? 1024 : 768))) / warp_threads; 
# 231
int regs_by_block = (sm_version >= 200) ? false : true; 
# 232
int max_sm_registers = (sm_version >= 300) ? 64 * 1024 : ((sm_version >= 200) ? 32 * 1024 : ((sm_version >= 120) ? 16 * 1024 : (8 * 1024))); 
# 233
int warp_alloc_unit = (sm_version >= 300) ? 4 : 2; 
# 234
int smem_alloc_unit = (sm_version >= 300) ? 256 : ((sm_version >= 200) ? 128 : 512); 
# 235
int reg_alloc_unit = (sm_version >= 300) ? 256 : ((sm_version >= 200) ? 64 : ((sm_version >= 120) ? 512 : 256)); 
# 236
int smem_bytes = (sm_version >= 200) ? 48 * 1024 : (16 * 1024); 
# 239
cudaFuncAttributes kernel_attrs; 
# 240
if (cub_::Debug(error = cudaFuncGetAttributes(&kernel_attrs, kernel_ptr), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../util_device.cuh", 240)) { break; }  
# 243
int block_warps = ((block_threads + warp_threads) - 1) / warp_threads; 
# 246
int max_warp_occupancy = (block_warps > 0) ? max_sm_warps / block_warps : max_sm_blocks; 
# 251
int max_reg_occupancy; 
# 252
if ((block_threads == 0) || ((kernel_attrs.numRegs) == 0)) 
# 253
{ 
# 255
max_reg_occupancy = max_sm_blocks; 
# 256
} else { 
# 257
if (regs_by_block) 
# 258
{ 
# 260
int block_regs = ((((((kernel_attrs.numRegs) * warp_threads) * block_warps) + reg_alloc_unit) - 1) / reg_alloc_unit) * reg_alloc_unit; 
# 261
max_reg_occupancy = (max_sm_registers / block_regs); 
# 262
} else 
# 264
{ 
# 266
int sm_sides = warp_alloc_unit; 
# 267
int sm_registers_per_side = max_sm_registers / sm_sides; 
# 268
int regs_per_warp = (((((kernel_attrs.numRegs) * warp_threads) + reg_alloc_unit) - 1) / reg_alloc_unit) * reg_alloc_unit; 
# 269
int warps_per_side = sm_registers_per_side / regs_per_warp; 
# 270
int warps = warps_per_side * sm_sides; 
# 271
max_reg_occupancy = (warps / block_warps); 
# 272
}  }  
# 275
int block_allocated_smem = (((((int)(kernel_attrs.sharedSizeBytes)) + smem_alloc_unit) - 1) / smem_alloc_unit) * smem_alloc_unit; 
# 280
int max_smem_occupancy = (block_allocated_smem > 0) ? smem_bytes / block_allocated_smem : max_sm_blocks; 
# 285
max_sm_occupancy = ((((max_reg_occupancy < max_smem_occupancy) ? max_reg_occupancy : max_smem_occupancy) < ((max_warp_occupancy < max_sm_blocks) ? max_warp_occupancy : max_sm_blocks)) ? (max_reg_occupancy < max_smem_occupancy) ? max_reg_occupancy : max_smem_occupancy : ((max_warp_occupancy < max_sm_blocks) ? max_warp_occupancy : max_sm_blocks)); 
# 291
} while (0); 
# 293
return error; 
# 296
} 
# 332
template< class KernelPtr> 
# 333
__attribute((always_inline)) inline cudaError_t 
# 334
MaxSmOccupancy(int &
# 335
max_sm_occupancy, KernelPtr 
# 336
kernel_ptr, int 
# 337
block_threads) 
# 338
{ 
# 346
cudaError_t error = cudaSuccess; 
# 347
do 
# 348
{ 
# 350
int device_ordinal; 
# 351
if (cub_::Debug(error = cudaGetDevice(&device_ordinal), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../util_device.cuh", 351)) { break; }  
# 354
int sm_version; 
# 355
if (cub_::Debug(error = SmVersion(sm_version, device_ordinal), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../util_device.cuh", 355)) { break; }  
# 358
if (cub_::Debug(error = MaxSmOccupancy(max_sm_occupancy, sm_version, kernel_ptr, block_threads), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../util_device.cuh", 358)) { break; }  
# 360
} while (0); 
# 362
return error; 
# 366
} 
# 371
}
# 372
}}}}
# 48 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_histogram_dispatch.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 51
namespace cub_ { 
# 60
template< int 
# 61
BINS, int 
# 62
ACTIVE_CHANNELS, class 
# 63
Offset, class 
# 64
HistoCounter> static void 
# 66
__wrapper__device_stub_DeviceHistogramInitKernel(GridQueue< Offset>  &
# 67
grid_queue, ArrayWrapper< HistoCounter *, ACTIVE_CHANNELS>  &
# 68
d_out_histograms, Offset &
# 69
num_samples) {exit(1);}
#if 0
# 70
{ 
# 71
(((d_out_histograms.array)[__device_builtin_variable_blockIdx.x])[__device_builtin_variable_threadIdx.x]) = 0; 
# 72
if ((__device_builtin_variable_threadIdx.x) == (0)) { (grid_queue.FillAndResetDrain(num_samples)); }  
# 73
} 
#endif
# 60 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_histogram_dispatch.cuh"
template< int 
# 61
BINS, int 
# 62
ACTIVE_CHANNELS, class 
# 63
Offset, class 
# 64
HistoCounter> void 
# 66
DeviceHistogramInitKernel(GridQueue< Offset>  
# 67
grid_queue, ArrayWrapper< HistoCounter *, ACTIVE_CHANNELS>  
# 68
d_out_histograms, Offset 
# 69
num_samples) 
# 70
{__wrapper__device_stub_DeviceHistogramInitKernel<BINS,ACTIVE_CHANNELS,Offset,HistoCounter>(grid_queue,d_out_histograms,num_samples);
# 73
return;}
#if 0
# 70
{ 
# 71
(((d_out_histograms.array)[__device_builtin_variable_blockIdx.x])[__device_builtin_variable_threadIdx.x]) = 0; 
# 72
if ((__device_builtin_variable_threadIdx.x) == (0)) { (grid_queue.FillAndResetDrain(num_samples)); }  
# 73
} 
#endif
# 79 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_histogram_dispatch.cuh"
template< class 
# 80
BlockHistogramSweepPolicy, int 
# 81
BINS, int 
# 82
CHANNELS, int 
# 83
ACTIVE_CHANNELS, class 
# 84
InputIterator, class 
# 85
HistoCounter, class 
# 86
Offset> static void 
# 88
__wrapper__device_stub_DeviceHistogramSweepKernel(InputIterator &
# 89
d_samples, ArrayWrapper< HistoCounter *, ACTIVE_CHANNELS>  &
# 90
d_out_histograms, Offset &
# 91
num_samples, GridEvenShare< Offset>  &
# 92
even_share, GridQueue< Offset>  &
# 93
queue) {exit(1);}
#if 0
# 94
{ 
# 97
enum { 
# 98
BLOCK_THREADS = BlockHistogramSweepPolicy::BLOCK_THREADS, 
# 99
ITEMS_PER_THREAD = BlockHistogramSweepPolicy::ITEMS_PER_THREAD, 
# 100
TILE_SIZE = (BlockHistogramSweepPolicy::BLOCK_THREADS) * (BlockHistogramSweepPolicy::ITEMS_PER_THREAD)
# 101
}; 
# 104
typedef BlockHistogramSweep< BlockHistogramSweepPolicy, BINS, CHANNELS, ACTIVE_CHANNELS, InputIterator, HistoCounter, Offset>  BlockHistogramSweepT; 
# 107
__attribute__((unused)) static typename BlockHistogramSweep< BlockHistogramSweepPolicy, BINS, CHANNELS, ACTIVE_CHANNELS, InputIterator, HistoCounter, Offset> ::TempStorage temp_storage; 
# 110
(BlockHistogramSweepT(temp_storage, d_samples, (d_out_histograms.array)).ConsumeRange(num_samples, even_share, queue, Int2Type< BlockHistogramSweepPolicy::GRID_MAPPING> ())); 
# 115
} 
#endif
# 79 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_histogram_dispatch.cuh"
template< class 
# 80
BlockHistogramSweepPolicy, int 
# 81
BINS, int 
# 82
CHANNELS, int 
# 83
ACTIVE_CHANNELS, class 
# 84
InputIterator, class 
# 85
HistoCounter, class 
# 86
Offset> void 
# 88
DeviceHistogramSweepKernel(InputIterator 
# 89
d_samples, ArrayWrapper< HistoCounter *, ACTIVE_CHANNELS>  
# 90
d_out_histograms, Offset 
# 91
num_samples, GridEvenShare< Offset>  
# 92
even_share, GridQueue< Offset>  
# 93
queue) 
# 94
{__wrapper__device_stub_DeviceHistogramSweepKernel<BlockHistogramSweepPolicy,BINS,CHANNELS,ACTIVE_CHANNELS,InputIterator,HistoCounter,Offset>(d_samples,d_out_histograms,num_samples,even_share,queue);
# 115
return;}
#if 0
# 94
{ 
# 97
enum { 
# 98
BLOCK_THREADS = BlockHistogramSweepPolicy::BLOCK_THREADS, 
# 99
ITEMS_PER_THREAD = BlockHistogramSweepPolicy::ITEMS_PER_THREAD, 
# 100
TILE_SIZE = (BlockHistogramSweepPolicy::BLOCK_THREADS) * (BlockHistogramSweepPolicy::ITEMS_PER_THREAD)
# 101
}; 
# 104
typedef BlockHistogramSweep< BlockHistogramSweepPolicy, BINS, CHANNELS, ACTIVE_CHANNELS, InputIterator, HistoCounter, Offset>  BlockHistogramSweepT; 
# 107
__attribute__((unused)) static typename BlockHistogramSweep< BlockHistogramSweepPolicy, BINS, CHANNELS, ACTIVE_CHANNELS, InputIterator, HistoCounter, Offset> ::TempStorage temp_storage; 
# 110
(BlockHistogramSweepT(temp_storage, d_samples, (d_out_histograms.array)).ConsumeRange(num_samples, even_share, queue, Int2Type< BlockHistogramSweepPolicy::GRID_MAPPING> ())); 
# 115
} 
#endif
# 121 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_histogram_dispatch.cuh"
template< int 
# 122
BINS, int 
# 123
ACTIVE_CHANNELS, class 
# 124
HistoCounter> static void 
# 126
__wrapper__device_stub_DeviceHistogramAggregateKernel(HistoCounter *&
# 127
d_block_histograms, ArrayWrapper< HistoCounter *, ACTIVE_CHANNELS>  &
# 128
d_out_histograms, int &
# 129
num_threadblocks) {exit(1);}
#if 0
# 130
{ 
# 132
HistoCounter bin_aggregate = (0); 
# 134
int block_offset = (__device_builtin_variable_blockIdx.x) * (num_threadblocks * BINS); 
# 135
int block_end = block_offset + (num_threadblocks * BINS); 
# 140
while (block_offset < block_end) 
# 141
{ 
# 142
HistoCounter block_bin_count = d_block_histograms[block_offset + (__device_builtin_variable_threadIdx.x)]; 
# 144
bin_aggregate += block_bin_count; 
# 145
block_offset += BINS; 
# 146
}  
# 149
(((d_out_histograms.array)[__device_builtin_variable_blockIdx.x])[__device_builtin_variable_threadIdx.x]) = bin_aggregate; 
# 150
} 
#endif
# 121 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_histogram_dispatch.cuh"
template< int 
# 122
BINS, int 
# 123
ACTIVE_CHANNELS, class 
# 124
HistoCounter> void 
# 126
DeviceHistogramAggregateKernel(HistoCounter *
# 127
d_block_histograms, ArrayWrapper< HistoCounter *, ACTIVE_CHANNELS>  
# 128
d_out_histograms, int 
# 129
num_threadblocks) 
# 130
{__wrapper__device_stub_DeviceHistogramAggregateKernel<BINS,ACTIVE_CHANNELS,HistoCounter>(d_block_histograms,d_out_histograms,num_threadblocks);
# 150
return;}
#if 0
# 130
{ 
# 132
HistoCounter bin_aggregate = (0); 
# 134
int block_offset = (__device_builtin_variable_blockIdx.x) * (num_threadblocks * BINS); 
# 135
int block_end = block_offset + (num_threadblocks * BINS); 
# 140
while (block_offset < block_end) 
# 141
{ 
# 142
HistoCounter block_bin_count = d_block_histograms[block_offset + (__device_builtin_variable_threadIdx.x)]; 
# 144
bin_aggregate += block_bin_count; 
# 145
block_offset += BINS; 
# 146
}  
# 149
(((d_out_histograms.array)[__device_builtin_variable_blockIdx.x])[__device_builtin_variable_threadIdx.x]) = bin_aggregate; 
# 150
} 
#endif
# 161 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_histogram_dispatch.cuh"
template< DeviceHistogramAlgorithm 
# 162
HISTO_ALGORITHM, int 
# 163
BINS, int 
# 164
CHANNELS, int 
# 165
ACTIVE_CHANNELS, class 
# 166
InputIterator, class 
# 167
HistoCounter, class 
# 168
Offset> 
# 169
struct DeviceHistogramDispatch { 
# 176
struct Policy350 { 
# 184
typedef BlockHistogramSweepPolicy< ((HISTO_ALGORITHM) == (DEVICE_HISTO_SORT)) ? 128 : 256, ((HISTO_ALGORITHM) == (DEVICE_HISTO_SORT)) ? 12 : (30 / ACTIVE_CHANNELS), HISTO_ALGORITHM, ((HISTO_ALGORITHM) == (DEVICE_HISTO_SORT)) ? GRID_MAPPING_DYNAMIC : GRID_MAPPING_EVEN_SHARE>  RangeHistoPolicy; 
# 185
}; 
# 188
struct Policy300 { 
# 196
typedef BlockHistogramSweepPolicy< 128, ((HISTO_ALGORITHM) == (DEVICE_HISTO_SORT)) ? 20 : (22 / ACTIVE_CHANNELS), HISTO_ALGORITHM, ((HISTO_ALGORITHM) == (DEVICE_HISTO_SORT)) ? GRID_MAPPING_DYNAMIC : GRID_MAPPING_EVEN_SHARE>  RangeHistoPolicy; 
# 197
}; 
# 200
struct Policy200 { 
# 208
typedef BlockHistogramSweepPolicy< 128, ((HISTO_ALGORITHM) == (DEVICE_HISTO_SORT)) ? 21 : (23 / ACTIVE_CHANNELS), HISTO_ALGORITHM, GRID_MAPPING_DYNAMIC>  RangeHistoPolicy; 
# 209
}; 
# 212
struct Policy100 { 
# 220
typedef BlockHistogramSweepPolicy< 128, 7, DEVICE_HISTO_SORT, GRID_MAPPING_EVEN_SHARE>  RangeHistoPolicy; 
# 221
}; 
# 238
typedef Policy100 PtxPolicy; 
# 243
struct PtxRangeHistoPolicy : public Policy100::RangeHistoPolicy { }; 
# 253
template< class KernelConfig> 
# 254
__attribute((always_inline)) static void 
# 255
InitConfigs(int 
# 256
ptx_version, KernelConfig &
# 257
device_histogram_sweep_config) 
# 258
{ 
# 267
if (ptx_version >= 350) 
# 268
{ 
# 269
(device_histogram_sweep_config.template Init< typename Policy350::RangeHistoPolicy> ()); 
# 270
} else { 
# 271
if (ptx_version >= 300) 
# 272
{ 
# 273
(device_histogram_sweep_config.template Init< typename Policy300::RangeHistoPolicy> ()); 
# 274
} else { 
# 275
if (ptx_version >= 200) 
# 276
{ 
# 277
(device_histogram_sweep_config.template Init< typename Policy200::RangeHistoPolicy> ()); 
# 278
} else 
# 280
{ 
# 281
(device_histogram_sweep_config.template Init< typename Policy100::RangeHistoPolicy> ()); 
# 282
}  }  }  
# 285
} 
# 291
struct KernelConfig { 
# 293
int block_threads; 
# 294
int items_per_thread; 
# 295
DeviceHistogramAlgorithm block_algorithm; 
# 296
GridMappingStrategy grid_mapping; 
# 298
template< class BlockPolicy> 
# 299
__attribute((always_inline)) void 
# 300
Init() 
# 301
{ 
# 302
(block_threads) = BlockPolicy::BLOCK_THREADS; 
# 303
(items_per_thread) = BlockPolicy::ITEMS_PER_THREAD; 
# 304
(block_algorithm) = BlockPolicy::HISTO_ALGORITHM; 
# 305
(grid_mapping) = BlockPolicy::GRID_MAPPING; 
# 306
} 
# 308
__attribute((always_inline)) void 
# 309
Print() 
# 310
{ 
# 311
printf("%d, %d, %d, %d", block_threads, items_per_thread, block_algorithm, grid_mapping); 
# 312
} 
# 314
}; 
# 325
template< class 
# 326
InitHistoKernelPtr, class 
# 327
DeviceHistogramSweepKernelPtr, class 
# 328
SingleHistogramPartialsKernelPtr> 
# 329
__attribute((always_inline)) static cudaError_t 
# 330
Dispatch(void *
# 331
d_temp_storage, size_t &
# 332
temp_storage_bytes, InputIterator 
# 333
d_samples, HistoCounter *
# 334
d_histograms[], Offset 
# 335
num_samples, cudaStream_t 
# 336
stream, bool 
# 337
debug_synchronous, InitHistoKernelPtr 
# 338
init_kernel, DeviceHistogramSweepKernelPtr 
# 339
device_histogram_sweep_kernel, SingleHistogramPartialsKernelPtr 
# 340
single_histogram_partials_kernel, KernelConfig 
# 341
device_histogram_sweep_config) 
# 342
{ 
# 350
cudaError error = cudaSuccess; 
# 351
do 
# 352
{ 
# 354
int device_ordinal; 
# 355
if (cub_::Debug(error = cudaGetDevice(&device_ordinal), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_histogram_dispatch.cuh", 355)) { break; }  
# 358
int sm_version; 
# 359
if (cub_::Debug(error = SmVersion(sm_version, device_ordinal), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_histogram_dispatch.cuh", 359)) { break; }  
# 362
int sm_count; 
# 363
if (cub_::Debug(error = cudaDeviceGetAttribute(&sm_count, cudaDevAttrMultiProcessorCount, device_ordinal), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_histogram_dispatch.cuh", 363)) { break; }  
# 366
int histo_range_sm_occupancy; 
# 367
if (cub_::Debug(error = MaxSmOccupancy(histo_range_sm_occupancy, sm_version, device_histogram_sweep_kernel, (device_histogram_sweep_config.block_threads)), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_histogram_dispatch.cuh", 371)) { 
# 371
break; }  
# 374
int histo_range_occupancy = histo_range_sm_occupancy * sm_count; 
# 377
int channel_tile_size = (device_histogram_sweep_config.block_threads) * (device_histogram_sweep_config.items_per_thread); 
# 378
int tile_size = channel_tile_size * CHANNELS; 
# 381
int subscription_factor = histo_range_sm_occupancy; 
# 382
GridEvenShare< Offset>  even_share(num_samples, histo_range_occupancy * subscription_factor, tile_size); 
# 388
int histo_range_grid_size; 
# 389
switch (device_histogram_sweep_config.grid_mapping) 
# 390
{ 
# 391
case GRID_MAPPING_EVEN_SHARE:  
# 394
histo_range_grid_size = (even_share.grid_size); 
# 395
break; 
# 397
case GRID_MAPPING_DYNAMIC:  
# 400
int num_tiles = ((num_samples + tile_size) - 1) / tile_size; 
# 401
histo_range_grid_size = ((num_tiles < histo_range_occupancy) ? num_tiles : histo_range_occupancy); 
# 404
break; 
# 405
}  ; 
# 408
void *allocations[2]; 
# 409
size_t allocation_sizes[2] = {((ACTIVE_CHANNELS * histo_range_grid_size) * sizeof(HistoCounter)) * (BINS), GridQueue< int> ::AllocationSize()}; 
# 416
if (cub_::Debug(error = AliasTemporaries(d_temp_storage, temp_storage_bytes, allocations, allocation_sizes), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_histogram_dispatch.cuh", 416)) { break; }  
# 417
if (d_temp_storage == (__null)) 
# 418
{ 
# 420
return cudaSuccess; 
# 421
}  
# 424
HistoCounter *d_block_histograms = (HistoCounter *)((allocations)[0]); 
# 427
GridQueue< Offset>  queue((allocations)[1]); 
# 430
ArrayWrapper< HistoCounter *, ACTIVE_CHANNELS>  d_histo_wrapper; 
# 431
for (int CHANNEL = 0; CHANNEL < ACTIVE_CHANNELS; ++CHANNEL) { 
# 432
((d_histo_wrapper.array)[CHANNEL]) = (d_histograms[CHANNEL]); }  
# 435
ArrayWrapper< HistoCounter *, ACTIVE_CHANNELS>  d_temp_histo_wrapper; 
# 436
for (int CHANNEL = 0; CHANNEL < ACTIVE_CHANNELS; ++CHANNEL) { 
# 437
((d_temp_histo_wrapper.array)[CHANNEL]) = (d_block_histograms + ((CHANNEL * histo_range_grid_size) * BINS)); }  
# 440
if (debug_synchronous) { printf("Invoking init_kernel<<<%d, %d, 0, %lld>>>()\n", ACTIVE_CHANNELS, BINS, (long long)stream); }  ; 
# 443
(cudaConfigureCall(ACTIVE_CHANNELS, BINS, 0, stream)) ? (void)0 : init_kernel(queue, d_histo_wrapper, num_samples); 
# 446
if (cub_::Debug(error = cudaPeekAtLastError(), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_histogram_dispatch.cuh", 446)) { break; }  
# 449
if (debug_synchronous && (cub_::Debug(error = SyncStream(stream), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_histogram_dispatch.cuh", 449))) { break; }  
# 452
bool privatized_temporaries = (histo_range_grid_size > 1) && ((device_histogram_sweep_config.block_algorithm) != DEVICE_HISTO_GLOBAL_ATOMIC); 
# 455
if (debug_synchronous) { printf("Invoking device_histogram_sweep_kernel<<<%d, %d, 0, %lld>>>(), %d items per thread, %d SM occupancy\n", histo_range_grid_size, (device_histogram_sweep_config.block_threads), (long long)stream, (device_histogram_sweep_config.items_per_thread), histo_range_sm_occupancy); }  
# 456
; 
# 459
(cudaConfigureCall(histo_range_grid_size, ((device_histogram_sweep_config.block_threads)), 0, stream)) ? (void)0 : device_histogram_sweep_kernel(d_samples, privatized_temporaries ? d_temp_histo_wrapper : d_histo_wrapper, num_samples, even_share, queue); 
# 469
if (cub_::Debug(error = cudaPeekAtLastError(), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_histogram_dispatch.cuh", 469)) { break; }  
# 472
if (debug_synchronous && (cub_::Debug(error = SyncStream(stream), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_histogram_dispatch.cuh", 472))) { break; }  
# 475
if (privatized_temporaries) 
# 476
{ 
# 478
if (debug_synchronous) { printf("Invoking single_histogram_partials_kernel<<<%d, %d, 0, %lld>>>()\n", ACTIVE_CHANNELS, BINS, (long long)stream); }  
# 479
; 
# 482
(cudaConfigureCall(ACTIVE_CHANNELS, BINS, 0, stream)) ? (void)0 : single_histogram_partials_kernel(d_block_histograms, d_histo_wrapper, histo_range_grid_size); 
# 488
if (cub_::Debug(error = cudaPeekAtLastError(), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_histogram_dispatch.cuh", 488)) { break; }  
# 491
if (debug_synchronous && (cub_::Debug(error = SyncStream(stream), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_histogram_dispatch.cuh", 491))) { break; }  
# 492
}  
# 493
} 
# 494
while (0); 
# 496
return error; 
# 499
} 
# 505
__attribute((always_inline)) static cudaError_t 
# 506
Dispatch(void *
# 507
d_temp_storage, size_t &
# 508
temp_storage_bytes, InputIterator 
# 509
d_samples, HistoCounter *
# 510
d_histograms[], int 
# 511
num_samples, cudaStream_t 
# 512
stream, bool 
# 513
debug_synchronous) 
# 514
{ 
# 515
cudaError error = cudaSuccess; 
# 516
do 
# 517
{ 
# 519
int ptx_version; 
# 521
if (cub_::Debug(error = PtxVersion(ptx_version), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_histogram_dispatch.cuh", 521)) { break; }  
# 527
KernelConfig device_histogram_sweep_config; 
# 528
InitConfigs(ptx_version, device_histogram_sweep_config); 
# 531
if (cub_::Debug(error = Dispatch(d_temp_storage, temp_storage_bytes, d_samples, d_histograms, num_samples, stream, debug_synchronous, DeviceHistogramInitKernel< BINS, ACTIVE_CHANNELS, Offset, HistoCounter> , DeviceHistogramSweepKernel< PtxRangeHistoPolicy, BINS, CHANNELS, ACTIVE_CHANNELS, InputIterator, HistoCounter, Offset> , DeviceHistogramAggregateKernel< BINS, ACTIVE_CHANNELS, HistoCounter> , device_histogram_sweep_config), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_histogram_dispatch.cuh", 542)) { 
# 542
break; }  
# 543
} 
# 544
while (0); 
# 546
return error; 
# 547
} 
# 548
}; 
# 551
}
# 552
}}}}
# 44 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/device_histogram.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 47
namespace cub_ { 
# 66
struct DeviceHistogram { 
# 124
template< int 
# 125
BINS, class 
# 126
InputIterator, class 
# 127
HistoCounter> static cudaError_t 
# 129
SingleChannelSorting(void *
# 130
d_temp_storage, size_t &
# 131
temp_storage_bytes, InputIterator 
# 132
d_samples, HistoCounter *
# 133
d_histogram, int 
# 134
num_samples, cudaStream_t 
# 135
stream = 0, bool 
# 136
debug_synchronous = false) 
# 137
{ 
# 139
typedef int Offset; 
# 150
typedef cub_::DeviceHistogramDispatch< DEVICE_HISTO_SORT, BINS, 1, 1, InputIterator, HistoCounter, int>  DeviceHistogramDispatch; 
# 152
return DeviceHistogramDispatch::Dispatch(d_temp_storage, temp_storage_bytes, d_samples, &d_histogram, num_samples, stream, debug_synchronous); 
# 160
} 
# 212
template< int 
# 213
BINS, class 
# 214
InputIterator, class 
# 215
HistoCounter> static cudaError_t 
# 217
SingleChannelSharedAtomic(void *
# 218
d_temp_storage, size_t &
# 219
temp_storage_bytes, InputIterator 
# 220
d_samples, HistoCounter *
# 221
d_histogram, int 
# 222
num_samples, cudaStream_t 
# 223
stream = 0, bool 
# 224
debug_synchronous = false) 
# 225
{ 
# 227
typedef int Offset; 
# 238
typedef cub_::DeviceHistogramDispatch< DEVICE_HISTO_SHARED_ATOMIC, BINS, 1, 1, InputIterator, HistoCounter, int>  DeviceHistogramDispatch; 
# 240
return DeviceHistogramDispatch::Dispatch(d_temp_storage, temp_storage_bytes, d_samples, &d_histogram, num_samples, stream, debug_synchronous); 
# 248
} 
# 300
template< int 
# 301
BINS, class 
# 302
InputIterator, class 
# 303
HistoCounter> static cudaError_t 
# 305
SingleChannelGlobalAtomic(void *
# 306
d_temp_storage, size_t &
# 307
temp_storage_bytes, InputIterator 
# 308
d_samples, HistoCounter *
# 309
d_histogram, int 
# 310
num_samples, cudaStream_t 
# 311
stream = 0, bool 
# 312
debug_synchronous = false) 
# 313
{ 
# 315
typedef int Offset; 
# 326
typedef cub_::DeviceHistogramDispatch< DEVICE_HISTO_GLOBAL_ATOMIC, BINS, 1, 1, InputIterator, HistoCounter, int>  DeviceHistogramDispatch; 
# 328
return DeviceHistogramDispatch::Dispatch(d_temp_storage, temp_storage_bytes, d_samples, &d_histogram, num_samples, stream, debug_synchronous); 
# 336
} 
# 405
template< int 
# 406
BINS, int 
# 407
CHANNELS, int 
# 408
ACTIVE_CHANNELS, class 
# 409
InputIterator, class 
# 410
HistoCounter> static cudaError_t 
# 412
MultiChannelSorting(void *
# 413
d_temp_storage, size_t &
# 414
temp_storage_bytes, InputIterator 
# 415
d_samples, HistoCounter *
# 416
d_histograms[], int 
# 417
num_samples, cudaStream_t 
# 418
stream = 0, bool 
# 419
debug_synchronous = false) 
# 420
{ 
# 422
typedef int Offset; 
# 432
typedef cub_::DeviceHistogramDispatch< DEVICE_HISTO_SORT, BINS, CHANNELS, ACTIVE_CHANNELS, InputIterator, HistoCounter, int>  DeviceHistogramDispatch; 
# 434
return DeviceHistogramDispatch::Dispatch(d_temp_storage, temp_storage_bytes, d_samples, d_histograms, num_samples, stream, debug_synchronous); 
# 442
} 
# 503
template< int 
# 504
BINS, int 
# 505
CHANNELS, int 
# 506
ACTIVE_CHANNELS, class 
# 507
InputIterator, class 
# 508
HistoCounter> static cudaError_t 
# 510
MultiChannelSharedAtomic(void *
# 511
d_temp_storage, size_t &
# 512
temp_storage_bytes, InputIterator 
# 513
d_samples, HistoCounter *
# 514
d_histograms[], int 
# 515
num_samples, cudaStream_t 
# 516
stream = 0, bool 
# 517
debug_synchronous = false) 
# 518
{ 
# 520
typedef int Offset; 
# 530
typedef cub_::DeviceHistogramDispatch< DEVICE_HISTO_SHARED_ATOMIC, BINS, CHANNELS, ACTIVE_CHANNELS, InputIterator, HistoCounter, int>  DeviceHistogramDispatch; 
# 532
return DeviceHistogramDispatch::Dispatch(d_temp_storage, temp_storage_bytes, d_samples, d_histograms, num_samples, stream, debug_synchronous); 
# 540
} 
# 602
template< int 
# 603
BINS, int 
# 604
CHANNELS, int 
# 605
ACTIVE_CHANNELS, class 
# 606
InputIterator, class 
# 607
HistoCounter> static cudaError_t 
# 609
MultiChannelGlobalAtomic(void *
# 610
d_temp_storage, size_t &
# 611
temp_storage_bytes, InputIterator 
# 612
d_samples, HistoCounter *
# 613
d_histograms[], int 
# 614
num_samples, cudaStream_t 
# 615
stream = 0, bool 
# 616
debug_synchronous = false) 
# 617
{ 
# 619
typedef int Offset; 
# 630
typedef cub_::DeviceHistogramDispatch< DEVICE_HISTO_GLOBAL_ATOMIC, BINS, CHANNELS, ACTIVE_CHANNELS, InputIterator, HistoCounter, int>  DeviceHistogramDispatch; 
# 632
return DeviceHistogramDispatch::Dispatch(d_temp_storage, temp_storage_bytes, d_samples, d_histograms, num_samples, stream, debug_synchronous); 
# 640
} 
# 644
}; 
# 650
}
# 651
}}}}
# 46 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_scan_prefix_operators.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 49
namespace cub_ { 
# 62
template< class 
# 63
T, class 
# 64
ScanOp> 
# 65
struct BlockScanRunningPrefixOp { 
# 67
ScanOp op; 
# 68
T running_total; 
# 71
__attribute((always_inline)) BlockScanRunningPrefixOp(ScanOp op) : op(op) 
# 74
{int *volatile ___ = 0;(void)op;::free(___);}
#if 0
# 74
{ } 
#endif
# 77 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_scan_prefix_operators.cuh"
__attribute((always_inline)) BlockScanRunningPrefixOp(T 
# 78
starting_prefix, ScanOp 
# 79
op) : op(op), running_total(starting_prefix) 
# 83
{int *volatile ___ = 0;(void)starting_prefix;(void)op;::free(___);}
#if 0
# 83
{ } 
#endif
# 88 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_scan_prefix_operators.cuh"
__attribute((always_inline)) T operator()(const T &
# 89
block_aggregate) 
# 90
{int volatile ___ = 1;(void)block_aggregate;
# 94
::exit(___);}
#if 0
# 90
{ 
# 91
T retval = running_total; 
# 92
(running_total) = (op)(running_total, block_aggregate); 
# 93
return retval; 
# 94
} 
#endif
# 95 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_scan_prefix_operators.cuh"
}; 
# 105
enum ScanTileStatus { 
# 107
SCAN_TILE_OOB, 
# 108
SCAN_TILE_INVALID, 
# 109
SCAN_TILE_PARTIAL, 
# 110
SCAN_TILE_INCLUSIVE
# 111
}; 
# 117
template< class 
# 118
T, bool 
# 119
SINGLE_WORD = Traits< T> ::PRIMITIVE> struct ScanTileState; 
# 128
template< class T> 
# 129
struct ScanTileState< T, true>  { 
# 138
typedef typename If< sizeof(T) == (8), long long, typename If< sizeof(T) == (4), int, typename If< sizeof(T) == (2), short, char> ::Type> ::Type> ::Type StatusWord; 
# 148
typedef typename If< sizeof(T) == (8), longlong2, typename If< sizeof(T) == (4), int2, typename If< sizeof(T) == (2), int, uchar2> ::Type> ::Type> ::Type TxnWord; 
# 152
struct TileDescriptor { 
# 154
StatusWord status; 
# 155
T value; 
# 156
}; 
# 161
enum { 
# 162
TILE_STATUS_PADDING = 1 << 5
# 163
}; 
# 167
TileDescriptor *d_tile_status; 
# 171
__attribute((always_inline)) 
# 172
ScanTileState() : d_tile_status((__null)) 
# 175
{ } 
# 179
__attribute((always_inline)) cudaError_t 
# 180
Init(int 
# 181
num_tiles, void *
# 182
d_temp_storage, size_t 
# 183
temp_storage_bytes) 
# 184
{ 
# 185
(d_tile_status) = (reinterpret_cast< TileDescriptor *>(d_temp_storage)); 
# 186
return cudaSuccess; 
# 187
} 
# 193
__attribute((always_inline)) static cudaError_t 
# 194
AllocationSize(int 
# 195
num_tiles, size_t &
# 196
temp_storage_bytes) 
# 197
{ 
# 198
temp_storage_bytes = ((num_tiles + (TILE_STATUS_PADDING)) * sizeof(TileDescriptor)); 
# 199
return cudaSuccess; 
# 200
} 
# 206
__attribute((always_inline)) void InitializeStatus(int num_tiles) 
# 207
{int volatile ___ = 1;(void)num_tiles;
# 220
::exit(___);}
#if 0
# 207
{ 
# 208
int tile_idx = ((__device_builtin_variable_blockIdx.x) * (__device_builtin_variable_blockDim.x)) + (__device_builtin_variable_threadIdx.x); 
# 209
if (tile_idx < num_tiles) 
# 210
{ 
# 212
(((d_tile_status)[(TILE_STATUS_PADDING) + tile_idx]).status) = ((StatusWord)SCAN_TILE_INVALID); 
# 213
}  
# 215
if (((__device_builtin_variable_blockIdx.x) == (0)) && ((__device_builtin_variable_threadIdx.x) < (TILE_STATUS_PADDING))) 
# 216
{ 
# 218
(((d_tile_status)[__device_builtin_variable_threadIdx.x]).status) = ((StatusWord)SCAN_TILE_OOB); 
# 219
}  
# 220
} 
#endif
# 226 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_scan_prefix_operators.cuh"
__attribute((always_inline)) void SetInclusive(int tile_idx, T tile_inclusive) 
# 227
{int volatile ___ = 1;(void)tile_idx;(void)tile_inclusive;
# 235
::exit(___);}
#if 0
# 227
{ 
# 228
TileDescriptor tile_descriptor; 
# 229
(tile_descriptor.status) = SCAN_TILE_INCLUSIVE; 
# 230
(tile_descriptor.value) = tile_inclusive; 
# 232
TxnWord alias; 
# 233
(*(reinterpret_cast< TileDescriptor *>(&alias))) = tile_descriptor; 
# 234
ThreadStore< STORE_CG> (reinterpret_cast< TxnWord *>(((d_tile_status) + (TILE_STATUS_PADDING)) + tile_idx), alias); 
# 235
} 
#endif
# 241 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_scan_prefix_operators.cuh"
__attribute((always_inline)) void SetPartial(int tile_idx, T tile_partial) 
# 242
{int volatile ___ = 1;(void)tile_idx;(void)tile_partial;
# 250
::exit(___);}
#if 0
# 242
{ 
# 243
TileDescriptor tile_descriptor; 
# 244
(tile_descriptor.status) = SCAN_TILE_PARTIAL; 
# 245
(tile_descriptor.value) = tile_partial; 
# 247
TxnWord alias; 
# 248
(*(reinterpret_cast< TileDescriptor *>(&alias))) = tile_descriptor; 
# 249
ThreadStore< STORE_CG> (reinterpret_cast< TxnWord *>(((d_tile_status) + (TILE_STATUS_PADDING)) + tile_idx), alias); 
# 250
} 
#endif
# 255 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_scan_prefix_operators.cuh"
__attribute((always_inline)) void WaitForValid(int 
# 256
tile_idx, StatusWord &
# 257
status, T &
# 258
value) 
# 259
{int volatile ___ = 1;(void)tile_idx;(void)status;(void)value;
# 272
::exit(___);}
#if 0
# 259
{ 
# 261
TxnWord alias = ThreadLoad< LOAD_CG> (reinterpret_cast< TxnWord *>(((d_tile_status) + (TILE_STATUS_PADDING)) + tile_idx)); 
# 262
TileDescriptor tile_descriptor = reinterpret_cast< TileDescriptor &>(alias); 
# 264
while ((tile_descriptor.status) == SCAN_TILE_INVALID) 
# 265
{ 
# 266
alias = ThreadLoad< LOAD_CG> (reinterpret_cast< TxnWord *>(((d_tile_status) + (TILE_STATUS_PADDING)) + tile_idx)); 
# 267
tile_descriptor = (reinterpret_cast< TileDescriptor &>(alias)); 
# 268
}  
# 270
status = (tile_descriptor.status); 
# 271
value = (tile_descriptor.value); 
# 272
} 
#endif
# 274 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_scan_prefix_operators.cuh"
}; 
# 282
template< class T> 
# 283
struct ScanTileState< T, false>  { 
# 286
typedef char StatusWord; 
# 290
enum { 
# 291
TILE_STATUS_PADDING = 1 << 5
# 292
}; 
# 295
StatusWord *d_tile_status; 
# 296
T *d_tile_partial; 
# 297
T *d_tile_inclusive; 
# 300
__attribute((always_inline)) 
# 301
ScanTileState() : d_tile_status((__null)), d_tile_partial((__null)), d_tile_inclusive((__null)) 
# 306
{ } 
# 310
__attribute((always_inline)) cudaError_t 
# 311
Init(int 
# 312
num_tiles, void *
# 313
d_temp_storage, size_t 
# 314
temp_storage_bytes) 
# 315
{ 
# 316
cudaError_t error = cudaSuccess; 
# 317
do 
# 318
{ 
# 319
void *allocations[3]; 
# 320
size_t allocation_sizes[3]; 
# 322
((allocation_sizes)[0]) = ((num_tiles + (TILE_STATUS_PADDING)) * sizeof(StatusWord)); 
# 323
((allocation_sizes)[1]) = ((num_tiles + (TILE_STATUS_PADDING)) * sizeof(Uninitialized< T> )); 
# 324
((allocation_sizes)[2]) = ((num_tiles + (TILE_STATUS_PADDING)) * sizeof(Uninitialized< T> )); 
# 327
if (cub_::Debug(error = AliasTemporaries(d_temp_storage, temp_storage_bytes, allocations, allocation_sizes), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_scan_prefix_operators.cuh", 327)) { break; }  
# 330
(d_tile_status) = (reinterpret_cast< StatusWord *>((allocations)[0])); 
# 331
(d_tile_partial) = (reinterpret_cast< T *>((allocations)[1])); 
# 332
(d_tile_inclusive) = (reinterpret_cast< T *>((allocations)[2])); 
# 333
} 
# 334
while (0); 
# 336
return error; 
# 337
} 
# 343
__attribute((always_inline)) static cudaError_t 
# 344
AllocationSize(int 
# 345
num_tiles, size_t &
# 346
temp_storage_bytes) 
# 347
{ 
# 349
size_t allocation_sizes[3]; 
# 350
((allocation_sizes)[0]) = ((num_tiles + (TILE_STATUS_PADDING)) * sizeof(StatusWord)); 
# 351
((allocation_sizes)[1]) = ((num_tiles + (TILE_STATUS_PADDING)) * sizeof(Uninitialized< T> )); 
# 352
((allocation_sizes)[2]) = ((num_tiles + (TILE_STATUS_PADDING)) * sizeof(Uninitialized< T> )); 
# 355
void *allocations[3]; 
# 356
return cub_::Debug(AliasTemporaries(__null, temp_storage_bytes, allocations, allocation_sizes), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_scan_prefix_operators.cuh", 356); 
# 357
} 
# 363
__attribute((always_inline)) void InitializeStatus(int num_tiles) 
# 364
{int volatile ___ = 1;(void)num_tiles;
# 377
::exit(___);}
#if 0
# 364
{ 
# 365
int tile_idx = ((__device_builtin_variable_blockIdx.x) * (__device_builtin_variable_blockDim.x)) + (__device_builtin_variable_threadIdx.x); 
# 366
if (tile_idx < num_tiles) 
# 367
{ 
# 369
((d_tile_status)[(TILE_STATUS_PADDING) + tile_idx]) = ((StatusWord)SCAN_TILE_INVALID); 
# 370
}  
# 372
if (((__device_builtin_variable_blockIdx.x) == (0)) && ((__device_builtin_variable_threadIdx.x) < (TILE_STATUS_PADDING))) 
# 373
{ 
# 375
((d_tile_status)[__device_builtin_variable_threadIdx.x]) = ((StatusWord)SCAN_TILE_OOB); 
# 376
}  
# 377
} 
#endif
# 383 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_scan_prefix_operators.cuh"
__attribute((always_inline)) void SetInclusive(int tile_idx, T tile_inclusive) 
# 384
{int volatile ___ = 1;(void)tile_idx;(void)tile_inclusive;
# 393
::exit(___);}
#if 0
# 384
{ 
# 386
ThreadStore< STORE_CG> (((d_tile_inclusive) + (TILE_STATUS_PADDING)) + tile_idx, tile_inclusive); 
# 389
__threadfence(); 
# 392
ThreadStore< STORE_CG> (((d_tile_status) + (TILE_STATUS_PADDING)) + tile_idx, (StatusWord)SCAN_TILE_INCLUSIVE); 
# 393
} 
#endif
# 399 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_scan_prefix_operators.cuh"
__attribute((always_inline)) void SetPartial(int tile_idx, T tile_partial) 
# 400
{int volatile ___ = 1;(void)tile_idx;(void)tile_partial;
# 409
::exit(___);}
#if 0
# 400
{ 
# 402
ThreadStore< STORE_CG> (((d_tile_partial) + (TILE_STATUS_PADDING)) + tile_idx, tile_partial); 
# 405
__threadfence(); 
# 408
ThreadStore< STORE_CG> (((d_tile_status) + (TILE_STATUS_PADDING)) + tile_idx, (StatusWord)SCAN_TILE_PARTIAL); 
# 409
} 
#endif
# 414 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_scan_prefix_operators.cuh"
__attribute((always_inline)) void WaitForValid(int 
# 415
tile_idx, StatusWord &
# 416
status, T &
# 417
value) 
# 418
{int volatile ___ = 1;(void)tile_idx;(void)status;(void)value;
# 432
::exit(___);}
#if 0
# 418
{ 
# 419
status = ThreadLoad< LOAD_CG> (((d_tile_status) + (TILE_STATUS_PADDING)) + tile_idx); 
# 420
while (status == (SCAN_TILE_INVALID)) 
# 421
{ 
# 422
status = ThreadLoad< LOAD_CG> (((d_tile_status) + (TILE_STATUS_PADDING)) + tile_idx); 
# 423
}  
# 425
T partial = ThreadLoad< LOAD_CG> (((d_tile_partial) + (TILE_STATUS_PADDING)) + tile_idx); 
# 426
T inclusive = ThreadLoad< LOAD_CG> (((d_tile_inclusive) + (TILE_STATUS_PADDING)) + tile_idx); 
# 428
value = ((status == ((StatusWord)SCAN_TILE_PARTIAL)) ? partial : inclusive); 
# 432
} 
#endif
# 433 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_scan_prefix_operators.cuh"
}; 
# 444
template< class 
# 445
Value, class 
# 446
Offset, bool 
# 447
SINGLE_WORD = Traits< Value> ::PRIMITIVE && ((sizeof(Value) + sizeof(Offset)) < (16))> struct ReduceByKeyScanTileState; 
# 455
template< class 
# 456
Value, class 
# 457
Offset> 
# 458
struct ReduceByKeyScanTileState< Value, Offset, false>  : public ScanTileState< ItemOffsetPair< Value, Offset> >  { 
# 461
typedef ScanTileState< ItemOffsetPair< Value, Offset> >  SuperClass; 
# 464
__attribute((always_inline)) 
# 465
ReduceByKeyScanTileState() : SuperClass() { } 
# 466
}; 
# 473
template< class 
# 474
Value, class 
# 475
Offset> 
# 476
struct ReduceByKeyScanTileState< Value, Offset, true>  { 
# 478
typedef ItemOffsetPair< Value, Offset>  ReductionOffsetPair; 
# 482
enum { 
# 483
PAIR_SIZE = sizeof(Value) + sizeof(Offset), 
# 484
TXN_WORD_SIZE = 1 << Log2< (sizeof(Value) + sizeof(Offset)) + (1)> ::VALUE, 
# 485
STATUS_WORD_SIZE = (1 << Log2< (sizeof(Value) + sizeof(Offset)) + (1)> ::VALUE) - (sizeof(Value) + sizeof(Offset)), 
# 487
TILE_STATUS_PADDING = 1 << 5
# 488
}; 
# 497
typedef typename If< (STATUS_WORD_SIZE) == 8, long long, typename If< (STATUS_WORD_SIZE) == 4, int, typename If< (STATUS_WORD_SIZE) == 2, short, char> ::Type> ::Type> ::Type StatusWord; 
# 504
typedef typename If< (TXN_WORD_SIZE) == 16, longlong2, typename If< (TXN_WORD_SIZE) == 8, long long, int> ::Type> ::Type TxnWord; 
# 507
struct TileDescriptorBigStatus { 
# 509
Offset offset; 
# 510
Value value; 
# 511
StatusWord status; 
# 512
}; 
# 515
struct TileDescriptorLittleStatus { 
# 517
Value value; 
# 518
StatusWord status; 
# 519
Offset offset; 
# 520
}; 
# 527
typedef typename If< sizeof(Value) == sizeof(Offset), TileDescriptorBigStatus, TileDescriptorLittleStatus> ::Type TileDescriptor; 
# 531
TileDescriptor *d_tile_status; 
# 535
__attribute((always_inline)) 
# 536
ReduceByKeyScanTileState() : d_tile_status((__null)) 
# 539
{ } 
# 543
__attribute((always_inline)) cudaError_t 
# 544
Init(int 
# 545
num_tiles, void *
# 546
d_temp_storage, size_t 
# 547
temp_storage_bytes) 
# 548
{ 
# 549
(d_tile_status) = (reinterpret_cast< TileDescriptor *>(d_temp_storage)); 
# 550
return cudaSuccess; 
# 551
} 
# 557
__attribute((always_inline)) static cudaError_t 
# 558
AllocationSize(int 
# 559
num_tiles, size_t &
# 560
temp_storage_bytes) 
# 561
{ 
# 562
temp_storage_bytes = ((num_tiles + (TILE_STATUS_PADDING)) * sizeof(TileDescriptor)); 
# 563
return cudaSuccess; 
# 564
} 
# 570
__attribute((always_inline)) void InitializeStatus(int num_tiles) 
# 571
{int volatile ___ = 1;(void)num_tiles;
# 584
::exit(___);}
#if 0
# 571
{ 
# 572
int tile_idx = ((__device_builtin_variable_blockIdx.x) * (__device_builtin_variable_blockDim.x)) + (__device_builtin_variable_threadIdx.x); 
# 573
if (tile_idx < num_tiles) 
# 574
{ 
# 576
(((d_tile_status)[(TILE_STATUS_PADDING) + tile_idx]).status) = ((StatusWord)SCAN_TILE_INVALID); 
# 577
}  
# 579
if (((__device_builtin_variable_blockIdx.x) == (0)) && ((__device_builtin_variable_threadIdx.x) < (TILE_STATUS_PADDING))) 
# 580
{ 
# 582
(((d_tile_status)[__device_builtin_variable_threadIdx.x]).status) = ((StatusWord)SCAN_TILE_OOB); 
# 583
}  
# 584
} 
#endif
# 590 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_scan_prefix_operators.cuh"
__attribute((always_inline)) void SetInclusive(int tile_idx, ReductionOffsetPair tile_inclusive) 
# 591
{int volatile ___ = 1;(void)tile_idx;(void)tile_inclusive;
# 600
::exit(___);}
#if 0
# 591
{ 
# 592
TileDescriptor tile_descriptor; 
# 593
(tile_descriptor.status) = SCAN_TILE_INCLUSIVE; 
# 594
(tile_descriptor.value) = (tile_inclusive.value); 
# 595
(tile_descriptor.offset) = (tile_inclusive.offset); 
# 597
TxnWord alias; 
# 598
(*(reinterpret_cast< TileDescriptor *>(&alias))) = tile_descriptor; 
# 599
ThreadStore< STORE_CG> (reinterpret_cast< TxnWord *>(((d_tile_status) + (TILE_STATUS_PADDING)) + tile_idx), alias); 
# 600
} 
#endif
# 606 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_scan_prefix_operators.cuh"
__attribute((always_inline)) void SetPartial(int tile_idx, ReductionOffsetPair tile_partial) 
# 607
{int volatile ___ = 1;(void)tile_idx;(void)tile_partial;
# 616
::exit(___);}
#if 0
# 607
{ 
# 608
TileDescriptor tile_descriptor; 
# 609
(tile_descriptor.status) = SCAN_TILE_PARTIAL; 
# 610
(tile_descriptor.value) = (tile_partial.value); 
# 611
(tile_descriptor.offset) = (tile_partial.offset); 
# 613
TxnWord alias; 
# 614
(*(reinterpret_cast< TileDescriptor *>(&alias))) = tile_descriptor; 
# 615
ThreadStore< STORE_CG> (reinterpret_cast< TxnWord *>(((d_tile_status) + (TILE_STATUS_PADDING)) + tile_idx), alias); 
# 616
} 
#endif
# 621 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_scan_prefix_operators.cuh"
__attribute((always_inline)) void WaitForValid(int 
# 622
tile_idx, StatusWord &
# 623
status, ReductionOffsetPair &
# 624
value) 
# 625
{int volatile ___ = 1;(void)tile_idx;(void)status;(void)value;
# 639
::exit(___);}
#if 0
# 625
{ 
# 627
TxnWord alias = ThreadLoad< LOAD_CG> (reinterpret_cast< TxnWord *>(((d_tile_status) + (TILE_STATUS_PADDING)) + tile_idx)); 
# 628
TileDescriptor tile_descriptor = reinterpret_cast< TileDescriptor &>(alias); 
# 630
while (WarpAny((tile_descriptor.status) == SCAN_TILE_INVALID)) 
# 631
{ 
# 632
alias = ThreadLoad< LOAD_CG> (reinterpret_cast< TxnWord *>(((d_tile_status) + (TILE_STATUS_PADDING)) + tile_idx)); 
# 633
tile_descriptor = (reinterpret_cast< TileDescriptor &>(alias)); 
# 634
}  
# 636
status = (tile_descriptor.status); 
# 637
(value.value) = (tile_descriptor.value); 
# 638
(value.offset) = (tile_descriptor.offset); 
# 639
} 
#endif
# 641 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_scan_prefix_operators.cuh"
}; 
# 654
template< class 
# 655
T, class 
# 656
ScanOp, class 
# 657
ScanTileState> 
# 658
struct BlockScanLookbackPrefixOp { 
# 661
typedef WarpReduce< T>  WarpReduceT; 
# 664
typedef typename WarpReduce< T> ::TempStorage _TempStorage; 
# 667
struct TempStorage : public Uninitialized< typename WarpReduce< T> ::TempStorage>  { }; 
# 670
typedef typename ScanTileState::StatusWord StatusWord; 
# 673
ScanTileState &tile_status; 
# 674
_TempStorage &temp_storage; 
# 675
ScanOp scan_op; 
# 676
int tile_idx; 
# 677
T exclusive_prefix; 
# 678
T inclusive_prefix; 
# 681
__attribute((always_inline)) 
# 682
BlockScanLookbackPrefixOp(ScanTileState &
# 683
tile_status, TempStorage &
# 684
temp_storage, ScanOp 
# 685
scan_op, int 
# 686
tile_idx) : tile_status(tile_status), temp_storage((temp_storage.Alias())), scan_op(scan_op), tile_idx(tile_idx) 
# 691
{int *volatile ___ = 0;(void)tile_status;(void)temp_storage;(void)scan_op;(void)tile_idx;::free(___);}
#if 0
# 691
{ } 
#endif
# 695 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_scan_prefix_operators.cuh"
__attribute((always_inline)) void 
# 696
ProcessWindow(int 
# 697
predecessor_idx, StatusWord &
# 698
predecessor_status, T &
# 699
window_aggregate) 
# 700
{int volatile ___ = 1;(void)predecessor_idx;(void)predecessor_status;(void)window_aggregate;
# 711
::exit(___);}
#if 0
# 700
{ 
# 701
T value; 
# 702
((tile_status).WaitForValid(predecessor_idx, predecessor_status, value)); 
# 705
int tail_flag = predecessor_status == ((StatusWord)SCAN_TILE_INCLUSIVE); 
# 707
window_aggregate = (((WarpReduceT)(temp_storage)).TailSegmentedReduce(value, tail_flag, scan_op)); 
# 711
} 
#endif
# 715 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_scan_prefix_operators.cuh"
__attribute((always_inline)) T 
# 716
operator()(T block_aggregate) 
# 717
{int volatile ___ = 1;(void)block_aggregate;
# 753
::exit(___);}
#if 0
# 717
{ 
# 719
if ((__device_builtin_variable_threadIdx.x) == (0)) 
# 720
{ 
# 721
((tile_status).SetPartial(tile_idx, block_aggregate)); 
# 722
}  
# 724
int predecessor_idx = ((tile_idx) - (__device_builtin_variable_threadIdx.x)) - (1); 
# 725
StatusWord predecessor_status; 
# 726
T window_aggregate; 
# 729
ProcessWindow(predecessor_idx, predecessor_status, window_aggregate); 
# 732
(exclusive_prefix) = window_aggregate; 
# 735
while (WarpAll(predecessor_status != ((StatusWord)SCAN_TILE_INCLUSIVE))) 
# 736
{ 
# 737
predecessor_idx -= (1 << 5); 
# 740
ProcessWindow(predecessor_idx, predecessor_status, window_aggregate); 
# 741
(exclusive_prefix) = (scan_op)(window_aggregate, exclusive_prefix); 
# 742
}  
# 745
if ((__device_builtin_variable_threadIdx.x) == (0)) 
# 746
{ 
# 747
(inclusive_prefix) = (scan_op)(exclusive_prefix, block_aggregate); 
# 748
((tile_status).SetInclusive(tile_idx, inclusive_prefix)); 
# 749
}  
# 752
return exclusive_prefix; 
# 753
} 
#endif
# 754 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_scan_prefix_operators.cuh"
}; 
# 757
}
# 758
}}}}
# 52 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/../iterator/cache_modified_input_iterator.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 55
namespace cub_ { 
# 103
template< CacheLoadModifier 
# 104
MODIFIER, class 
# 105
ValueType, class 
# 106
Offset = ptrdiff_t> 
# 107
class CacheModifiedInputIterator { 
# 112
public: typedef CacheModifiedInputIterator self_type; 
# 113
typedef Offset difference_type; 
# 114
typedef ValueType value_type; 
# 115
typedef ValueType *pointer; 
# 116
typedef ValueType reference; 
# 125
typedef typename thrust::detail::iterator_facade_category< tag, random_access_traversal_tag, ValueType, ValueType> ::type iterator_category; 
# 133
private: ValueType *ptr; 
# 138
public: __attribute((always_inline)) CacheModifiedInputIterator(ValueType *
# 139
ptr) : ptr(ptr) 
# 142
{ } 
# 145
__attribute((always_inline)) self_type operator++(int) 
# 146
{ 
# 147
self_type retval = *this; 
# 148
(ptr)++; 
# 149
return retval; 
# 150
} 
# 153
__attribute((always_inline)) self_type operator++() 
# 154
{ 
# 155
(ptr)++; 
# 156
return *this; 
# 157
} 
# 160
__attribute((always_inline)) reference operator*() const 
# 161
{ 
# 162
return ThreadLoad< MODIFIER> (ptr); 
# 163
} 
# 166
template< class Distance> 
# 167
__attribute((always_inline)) self_type operator+(Distance n) const 
# 168
{ 
# 169
self_type retval((ptr) + n); 
# 170
return retval; 
# 171
} 
# 174
template< class Distance> 
# 175
__attribute((always_inline)) self_type &operator+=(Distance n) 
# 176
{ 
# 177
(ptr) += n; 
# 178
return *this; 
# 179
} 
# 182
template< class Distance> 
# 183
__attribute((always_inline)) self_type operator-(Distance n) const 
# 184
{ 
# 185
self_type retval((ptr) - n); 
# 186
return retval; 
# 187
} 
# 190
template< class Distance> 
# 191
__attribute((always_inline)) self_type &operator-=(Distance n) 
# 192
{ 
# 193
(ptr) -= n; 
# 194
return *this; 
# 195
} 
# 198
__attribute((always_inline)) difference_type operator-(self_type other) const 
# 199
{ 
# 200
return (ptr) - (other.ptr); 
# 201
} 
# 204
template< class Distance> 
# 205
__attribute((always_inline)) reference operator[](Distance n) const 
# 206
{ 
# 207
return ThreadLoad< MODIFIER> ((ptr) + n); 
# 208
} 
# 211
__attribute((always_inline)) pointer operator->() 
# 212
{ 
# 213
return &ThreadLoad< MODIFIER> (ptr); 
# 214
} 
# 217
__attribute((always_inline)) bool operator==(const self_type &rhs) 
# 218
{ 
# 219
return (ptr) == (rhs.ptr); 
# 220
} 
# 223
__attribute((always_inline)) bool operator!=(const self_type &rhs) 
# 224
{ 
# 225
return (ptr) != (rhs.ptr); 
# 226
} 
# 229
friend inline std::ostream &operator<<(std::ostream &os, const self_type &itr) 
# 230
{ 
# 231
return os; 
# 232
} 
# 233
}; 
# 239
}
# 240
}}}}
# 47 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_scan_sweep.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 50
namespace cub_ { 
# 60
template< int 
# 61
_BLOCK_THREADS, int 
# 62
_ITEMS_PER_THREAD, BlockLoadAlgorithm 
# 63
_LOAD_ALGORITHM, bool 
# 64
_LOAD_WARP_TIME_SLICING, CacheLoadModifier 
# 65
_LOAD_MODIFIER, BlockStoreAlgorithm 
# 66
_STORE_ALGORITHM, bool 
# 67
_STORE_WARP_TIME_SLICING, BlockScanAlgorithm 
# 68
_SCAN_ALGORITHM> 
# 69
struct BlockScanSweepPolicy { 
# 72
enum { 
# 73
BLOCK_THREADS = _BLOCK_THREADS, 
# 74
ITEMS_PER_THREAD = _ITEMS_PER_THREAD, 
# 75
LOAD_WARP_TIME_SLICING = _LOAD_WARP_TIME_SLICING, 
# 76
STORE_WARP_TIME_SLICING = _STORE_WARP_TIME_SLICING
# 77
}; 
# 79
static const BlockLoadAlgorithm LOAD_ALGORITHM = _LOAD_ALGORITHM; 
# 80
static const CacheLoadModifier LOAD_MODIFIER = _LOAD_MODIFIER; 
# 81
static const BlockStoreAlgorithm STORE_ALGORITHM = _STORE_ALGORITHM; 
# 82
static const BlockScanAlgorithm SCAN_ALGORITHM = _SCAN_ALGORITHM; 
# 83
}; 
# 95
template< class 
# 96
BlockScanSweepPolicy, class 
# 97
InputIterator, class 
# 98
OutputIterator, class 
# 99
ScanOp, class 
# 100
Identity, class 
# 101
Offset> 
# 102
struct BlockScanSweep { 
# 109
typedef typename std::iterator_traits< InputIterator> ::value_type T; 
# 112
typedef cub_::ScanTileState< typename std::iterator_traits< InputIterator> ::value_type>  ScanTileState; 
# 118
typedef typename If< IsPointer< InputIterator> ::VALUE, CacheModifiedInputIterator< BlockScanSweepPolicy::LOAD_MODIFIER, typename std::iterator_traits< InputIterator> ::value_type, Offset> , InputIterator> ::Type WrappedInputIterator; 
# 122
enum { 
# 123
INCLUSIVE = Equals< Identity, NullType> ::VALUE, 
# 124
BLOCK_THREADS = BlockScanSweepPolicy::BLOCK_THREADS, 
# 125
ITEMS_PER_THREAD = BlockScanSweepPolicy::ITEMS_PER_THREAD, 
# 126
TILE_ITEMS = (BlockScanSweepPolicy::BLOCK_THREADS) * (BlockScanSweepPolicy::ITEMS_PER_THREAD), 
# 129
SYNC_AFTER_LOAD = BlockScanSweepPolicy::LOAD_ALGORITHM != BLOCK_LOAD_DIRECT
# 131
}; 
# 140
typedef BlockLoad< typename If< IsPointer< InputIterator> ::VALUE, CacheModifiedInputIterator< BlockScanSweepPolicy::LOAD_MODIFIER, typename std::iterator_traits< InputIterator> ::value_type, Offset> , InputIterator> ::Type, BlockScanSweepPolicy::BLOCK_THREADS, BlockScanSweepPolicy::ITEMS_PER_THREAD, BlockScanSweepPolicy::LOAD_ALGORITHM, BlockScanSweepPolicy::LOAD_WARP_TIME_SLICING>  BlockLoadT; 
# 149
typedef BlockStore< OutputIterator, BlockScanSweepPolicy::BLOCK_THREADS, BlockScanSweepPolicy::ITEMS_PER_THREAD, BlockScanSweepPolicy::STORE_ALGORITHM, BlockScanSweepPolicy::STORE_WARP_TIME_SLICING>  BlockStoreT; 
# 156
typedef BlockScan< typename std::iterator_traits< InputIterator> ::value_type, BlockScanSweepPolicy::BLOCK_THREADS, BlockScanSweepPolicy::SCAN_ALGORITHM>  BlockScanT; 
# 163
typedef BlockScanLookbackPrefixOp< typename std::iterator_traits< InputIterator> ::value_type, ScanOp, cub_::ScanTileState< typename std::iterator_traits< InputIterator> ::value_type> >  LookbackPrefixCallbackOp; 
# 169
typedef BlockScanRunningPrefixOp< typename std::iterator_traits< InputIterator> ::value_type, ScanOp>  RunningPrefixCallbackOp; 
# 172
struct _TempStorage { 
# 175
union { 
# 176
typename BlockLoad< typename If< IsPointer< InputIterator> ::VALUE, CacheModifiedInputIterator< BlockScanSweepPolicy::LOAD_MODIFIER, typename std::iterator_traits< InputIterator> ::value_type, Offset> , InputIterator> ::Type, BlockScanSweepPolicy::BLOCK_THREADS, BlockScanSweepPolicy::ITEMS_PER_THREAD, BlockScanSweepPolicy::LOAD_ALGORITHM, BlockScanSweepPolicy::LOAD_WARP_TIME_SLICING> ::TempStorage load; 
# 177
typename BlockStore< OutputIterator, BlockScanSweepPolicy::BLOCK_THREADS, BlockScanSweepPolicy::ITEMS_PER_THREAD, BlockScanSweepPolicy::STORE_ALGORITHM, BlockScanSweepPolicy::STORE_WARP_TIME_SLICING> ::TempStorage store; 
# 179
struct { 
# 180
typename BlockScanLookbackPrefixOp< typename std::iterator_traits< InputIterator> ::value_type, ScanOp, cub_::ScanTileState< typename std::iterator_traits< InputIterator> ::value_type> > ::TempStorage prefix; 
# 181
typename BlockScan< typename std::iterator_traits< InputIterator> ::value_type, BlockScanSweepPolicy::BLOCK_THREADS, BlockScanSweepPolicy::SCAN_ALGORITHM> ::TempStorage scan; 
# 182
}; 
# 183
}; 
# 185
Offset tile_idx; 
# 186
}; 
# 189
struct TempStorage : public Uninitialized< _TempStorage>  { }; 
# 196
_TempStorage &temp_storage; 
# 197
WrappedInputIterator d_in; 
# 198
OutputIterator d_out; 
# 199
ScanOp scan_op; 
# 200
Identity identity; 
# 211
template< class _ScanOp, class _Identity> 
# 212
__attribute((always_inline)) void 
# 213
ScanBlock(T (&items)[ITEMS_PER_THREAD], _ScanOp scan_op, _Identity identity, T &block_aggregate) 
# 214
{int volatile ___ = 1;(void)items;(void)scan_op;(void)identity;(void)block_aggregate;
# 216
::exit(___);}
#if 0
# 214
{ 
# 215
(((BlockScanT)(((temp_storage).scan))).ExclusiveScan(items, items, identity, scan_op, block_aggregate)); 
# 216
} 
#endif
# 221 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_scan_sweep.cuh"
template< class _Identity> 
# 222
__attribute((always_inline)) void 
# 223
ScanBlock(T (&items)[ITEMS_PER_THREAD], Sum scan_op, _Identity identity, T &block_aggregate) 
# 224
{int volatile ___ = 1;(void)items;(void)scan_op;(void)identity;(void)block_aggregate;
# 226
::exit(___);}
#if 0
# 224
{ 
# 225
(((BlockScanT)(((temp_storage).scan))).ExclusiveSum(items, items, block_aggregate)); 
# 226
} 
#endif
# 231 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_scan_sweep.cuh"
template< class _ScanOp> 
# 232
__attribute((always_inline)) void 
# 233
ScanBlock(T (&items)[ITEMS_PER_THREAD], _ScanOp scan_op, NullType identity, T &block_aggregate) 
# 234
{int volatile ___ = 1;(void)items;(void)scan_op;(void)identity;(void)block_aggregate;
# 236
::exit(___);}
#if 0
# 234
{ 
# 235
(((BlockScanT)(((temp_storage).scan))).InclusiveScan(items, items, scan_op, block_aggregate)); 
# 236
} 
#endif
# 241 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_scan_sweep.cuh"
__attribute((always_inline)) void 
# 242
ScanBlock(T (&items)[ITEMS_PER_THREAD], Sum scan_op, NullType identity, T &block_aggregate) 
# 243
{int volatile ___ = 1;(void)items;(void)scan_op;(void)identity;(void)block_aggregate;
# 245
::exit(___);}
#if 0
# 243
{ 
# 244
(((BlockScanT)(((temp_storage).scan))).InclusiveSum(items, items, block_aggregate)); 
# 245
} 
#endif
# 254 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_scan_sweep.cuh"
template< class _ScanOp, class _Identity, class PrefixCallback> 
# 255
__attribute((always_inline)) void 
# 256
ScanBlock(T (&items)[ITEMS_PER_THREAD], _ScanOp scan_op, _Identity identity, T &block_aggregate, PrefixCallback &prefix_op) 
# 257
{int volatile ___ = 1;(void)items;(void)scan_op;(void)identity;(void)block_aggregate;(void)prefix_op;
# 259
::exit(___);}
#if 0
# 257
{ 
# 258
(((BlockScanT)(((temp_storage).scan))).ExclusiveScan(items, items, identity, scan_op, block_aggregate, prefix_op)); 
# 259
} 
#endif
# 264 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_scan_sweep.cuh"
template< class _Identity, class PrefixCallback> 
# 265
__attribute((always_inline)) void 
# 266
ScanBlock(T (&items)[ITEMS_PER_THREAD], Sum scan_op, _Identity identity, T &block_aggregate, PrefixCallback &prefix_op) 
# 267
{int volatile ___ = 1;(void)items;(void)scan_op;(void)identity;(void)block_aggregate;(void)prefix_op;
# 269
::exit(___);}
#if 0
# 267
{ 
# 268
(((BlockScanT)(((temp_storage).scan))).ExclusiveSum(items, items, block_aggregate, prefix_op)); 
# 269
} 
#endif
# 274 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_scan_sweep.cuh"
template< class _ScanOp, class PrefixCallback> 
# 275
__attribute((always_inline)) void 
# 276
ScanBlock(T (&items)[ITEMS_PER_THREAD], _ScanOp scan_op, NullType identity, T &block_aggregate, PrefixCallback &prefix_op) 
# 277
{int volatile ___ = 1;(void)items;(void)scan_op;(void)identity;(void)block_aggregate;(void)prefix_op;
# 279
::exit(___);}
#if 0
# 277
{ 
# 278
(((BlockScanT)(((temp_storage).scan))).InclusiveScan(items, items, scan_op, block_aggregate, prefix_op)); 
# 279
} 
#endif
# 284 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_scan_sweep.cuh"
template< class PrefixCallback> 
# 285
__attribute((always_inline)) void 
# 286
ScanBlock(T (&items)[ITEMS_PER_THREAD], Sum scan_op, NullType identity, T &block_aggregate, PrefixCallback &prefix_op) 
# 287
{int volatile ___ = 1;(void)items;(void)scan_op;(void)identity;(void)block_aggregate;(void)prefix_op;
# 289
::exit(___);}
#if 0
# 287
{ 
# 288
(((BlockScanT)(((temp_storage).scan))).InclusiveSum(items, items, block_aggregate, prefix_op)); 
# 289
} 
#endif
# 297 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_scan_sweep.cuh"
__attribute((always_inline)) 
# 298
BlockScanSweep(TempStorage &
# 299
temp_storage, InputIterator 
# 300
d_in, OutputIterator 
# 301
d_out, ScanOp 
# 302
scan_op, Identity 
# 303
identity) : temp_storage((temp_storage.Alias())), d_in(d_in), d_out(d_out), scan_op(scan_op), identity(identity) 
# 310
{int *volatile ___ = 0;(void)temp_storage;(void)d_in;(void)d_out;(void)scan_op;(void)identity;::free(___);}
#if 0
# 310
{ } 
#endif
# 320 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_scan_sweep.cuh"
template< bool LAST_TILE> 
# 321
__attribute((always_inline)) void ConsumeTile(Offset 
# 322
num_items, Offset 
# 323
num_remaining, int 
# 324
tile_idx, Offset 
# 325
block_offset, ScanTileState &
# 326
tile_status) 
# 327
{int volatile ___ = 1;(void)num_items;(void)num_remaining;(void)tile_idx;(void)block_offset;(void)tile_status;
# 365
::exit(___);}
#if 0
# 327
{ 
# 329
T items[ITEMS_PER_THREAD]; 
# 331
if (LAST_TILE) { 
# 332
(((BlockLoadT)(((temp_storage).load))).Load((d_in) + block_offset, items, num_remaining)); } else { 
# 334
(((BlockLoadT)(((temp_storage).load))).Load((d_in) + block_offset, items)); }  
# 336
if (SYNC_AFTER_LOAD) { 
# 337
__syncthreads(); }  
# 340
if (tile_idx == 0) 
# 341
{ 
# 343
T block_aggregate; 
# 344
ScanBlock(items, scan_op, identity, block_aggregate); 
# 347
if ((!LAST_TILE) && ((__device_builtin_variable_threadIdx.x) == (0))) { 
# 348
(tile_status.SetInclusive(0, block_aggregate)); }  
# 349
} else 
# 351
{ 
# 353
T block_aggregate; 
# 354
LookbackPrefixCallbackOp prefix_op(tile_status, ((temp_storage).prefix), scan_op, tile_idx); 
# 355
ScanBlock(items, scan_op, identity, block_aggregate, prefix_op); 
# 356
}  
# 358
__syncthreads(); 
# 361
if (LAST_TILE) { 
# 362
(((BlockStoreT)(((temp_storage).store))).Store((d_out) + block_offset, items, num_remaining)); } else { 
# 364
(((BlockStoreT)(((temp_storage).store))).Store((d_out) + block_offset, items)); }  
# 365
} 
#endif
# 371 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_scan_sweep.cuh"
__attribute((always_inline)) void ConsumeRange(int 
# 372
num_items, GridQueue< int>  
# 373
queue, ScanTileState &
# 374
tile_status) 
# 375
{int volatile ___ = 1;(void)num_items;(void)queue;(void)tile_status;
# 425
::exit(___);}
#if 0
# 375
{ 
# 379
int tile_idx = ((__device_builtin_variable_blockIdx.y) * (__device_builtin_variable_gridDim.x)) + (__device_builtin_variable_blockIdx.x); 
# 380
Offset block_offset = ((Offset)(TILE_ITEMS)) * tile_idx; 
# 381
Offset num_remaining = num_items - block_offset; 
# 383
if (num_remaining > (TILE_ITEMS)) { 
# 384
ConsumeTile< false> (num_items, num_remaining, tile_idx, block_offset, tile_status); } else { 
# 385
if (num_remaining > 0) { 
# 386
ConsumeTile< true> (num_items, num_remaining, tile_idx, block_offset, tile_status); }  }  
# 425
} 
#endif
# 435 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_scan_sweep.cuh"
template< bool 
# 436
FULL_TILE, bool 
# 437
FIRST_TILE> 
# 438
__attribute((always_inline)) void ConsumeTile(Offset 
# 439
block_offset, RunningPrefixCallbackOp &
# 440
prefix_op, int 
# 441
valid_items = TILE_ITEMS) 
# 442
{int volatile ___ = 1;(void)block_offset;(void)prefix_op;(void)valid_items;
# 473
::exit(___);}
#if 0
# 442
{ 
# 444
T items[ITEMS_PER_THREAD]; 
# 446
if (FULL_TILE) { 
# 447
(((BlockLoadT)(((temp_storage).load))).Load((d_in) + block_offset, items)); } else { 
# 449
(((BlockLoadT)(((temp_storage).load))).Load((d_in) + block_offset, items, valid_items)); }  
# 451
__syncthreads(); 
# 454
if (FIRST_TILE) 
# 455
{ 
# 456
T block_aggregate; 
# 457
ScanBlock(items, scan_op, identity, block_aggregate); 
# 458
(prefix_op.running_total) = block_aggregate; 
# 459
} else 
# 461
{ 
# 462
T block_aggregate; 
# 463
ScanBlock(items, scan_op, identity, block_aggregate, prefix_op); 
# 464
}  
# 466
__syncthreads(); 
# 469
if (FULL_TILE) { 
# 470
(((BlockStoreT)(((temp_storage).store))).Store((d_out) + block_offset, items)); } else { 
# 472
(((BlockStoreT)(((temp_storage).store))).Store((d_out) + block_offset, items, valid_items)); }  
# 473
} 
#endif
# 479 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_scan_sweep.cuh"
__attribute((always_inline)) void ConsumeRange(Offset 
# 480
block_offset, Offset 
# 481
block_end) 
# 482
{int volatile ___ = 1;(void)block_offset;(void)block_end;
# 511
::exit(___);}
#if 0
# 482
{ 
# 483
BlockScanRunningPrefixOp< typename std::iterator_traits< InputIterator> ::value_type, ScanOp>  prefix_op(scan_op); 
# 485
if ((block_offset + (TILE_ITEMS)) <= block_end) 
# 486
{ 
# 488
ConsumeTile< true, true> (block_offset, prefix_op); 
# 489
block_offset += (TILE_ITEMS); 
# 492
while ((block_offset + (TILE_ITEMS)) <= block_end) 
# 493
{ 
# 494
ConsumeTile< true, false> (block_offset, prefix_op); 
# 495
block_offset += (TILE_ITEMS); 
# 496
}  
# 499
if (block_offset < block_end) 
# 500
{ 
# 501
int valid_items = block_end - block_offset; 
# 502
ConsumeTile< false, false> (block_offset, prefix_op, valid_items); 
# 503
}  
# 504
} else 
# 506
{ 
# 508
int valid_items = block_end - block_offset; 
# 509
ConsumeTile< false, true> (block_offset, prefix_op, valid_items); 
# 510
}  
# 511
} 
#endif
# 517 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_scan_sweep.cuh"
__attribute((always_inline)) void ConsumeRange(Offset 
# 518
block_offset, Offset 
# 519
block_end, T 
# 520
prefix) 
# 521
{int volatile ___ = 1;(void)block_offset;(void)block_end;(void)prefix;
# 537
::exit(___);}
#if 0
# 521
{ 
# 522
BlockScanRunningPrefixOp< typename std::iterator_traits< InputIterator> ::value_type, ScanOp>  prefix_op(prefix, scan_op); 
# 525
while ((block_offset + (TILE_ITEMS)) <= block_end) 
# 526
{ 
# 527
ConsumeTile< true, false> (block_offset, prefix_op); 
# 528
block_offset += (TILE_ITEMS); 
# 529
}  
# 532
if (block_offset < block_end) 
# 533
{ 
# 534
int valid_items = block_end - block_offset; 
# 535
ConsumeTile< false, false> (block_offset, prefix_op, valid_items); 
# 536
}  
# 537
} 
#endif
# 539 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_scan_sweep.cuh"
}; 
# 542
}
# 543
}}}}
# 48 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_scan_dispatch.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 51
namespace cub_ { 
# 61
template< class 
# 62
Offset, class 
# 63
ScanTileState> static void 
# 64
__wrapper__device_stub_DeviceScanInitKernel(GridQueue< Offset>  &
# 65
grid_queue, ScanTileState &
# 66
tile_status, int &
# 67
num_tiles) {exit(1);}
#if 0
# 68
{ 
# 70
if (((__device_builtin_variable_blockIdx.x) == (0)) && ((__device_builtin_variable_threadIdx.x) == (0))) { 
# 71
(grid_queue.FillAndResetDrain(num_tiles)); }  
# 74
(tile_status.InitializeStatus(num_tiles)); 
# 75
} 
#endif
# 61 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_scan_dispatch.cuh"
template< class 
# 62
Offset, class 
# 63
ScanTileState> void 
# 64
DeviceScanInitKernel(GridQueue< Offset>  
# 65
grid_queue, ScanTileState 
# 66
tile_status, int 
# 67
num_tiles) 
# 68
{__wrapper__device_stub_DeviceScanInitKernel<Offset,ScanTileState>(grid_queue,tile_status,num_tiles);
# 75
return;}
#if 0
# 68
{ 
# 70
if (((__device_builtin_variable_blockIdx.x) == (0)) && ((__device_builtin_variable_threadIdx.x) == (0))) { 
# 71
(grid_queue.FillAndResetDrain(num_tiles)); }  
# 74
(tile_status.InitializeStatus(num_tiles)); 
# 75
} 
#endif
# 81 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_scan_dispatch.cuh"
template< class 
# 82
BlockScanSweepPolicy, class 
# 83
InputIterator, class 
# 84
OutputIterator, class 
# 85
ScanTileState, class 
# 86
ScanOp, class 
# 87
Identity, class 
# 88
Offset> static void 
# 90
__wrapper__device_stub_DeviceScanSweepKernel(InputIterator &
# 91
d_in, OutputIterator &
# 92
d_out, ScanTileState &
# 93
tile_status, ScanOp &
# 94
scan_op, Identity &
# 95
identity, Offset &
# 96
num_items, GridQueue< int>  &
# 97
queue) {exit(1);}
#if 0
# 98
{ 
# 106
typedef BlockScanSweep< BlockScanSweepPolicy, InputIterator, OutputIterator, ScanOp, Identity, Offset>  BlockScanSweepT; 
# 109
__attribute__((unused)) static typename BlockScanSweep< BlockScanSweepPolicy, InputIterator, OutputIterator, ScanOp, Identity, Offset> ::TempStorage temp_storage; 
# 112
(BlockScanSweepT(temp_storage, d_in, d_out, scan_op, identity).ConsumeRange(num_items, queue, tile_status)); 
# 116
} 
#endif
# 81 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_scan_dispatch.cuh"
template< class 
# 82
BlockScanSweepPolicy, class 
# 83
InputIterator, class 
# 84
OutputIterator, class 
# 85
ScanTileState, class 
# 86
ScanOp, class 
# 87
Identity, class 
# 88
Offset> void 
# 90
DeviceScanSweepKernel(InputIterator 
# 91
d_in, OutputIterator 
# 92
d_out, ScanTileState 
# 93
tile_status, ScanOp 
# 94
scan_op, Identity 
# 95
identity, Offset 
# 96
num_items, GridQueue< int>  
# 97
queue) 
# 98
{__wrapper__device_stub_DeviceScanSweepKernel<BlockScanSweepPolicy,InputIterator,OutputIterator,ScanTileState,ScanOp,Identity,Offset>(d_in,d_out,tile_status,scan_op,identity,num_items,queue);
# 116
return;}
#if 0
# 98
{ 
# 106
typedef BlockScanSweep< BlockScanSweepPolicy, InputIterator, OutputIterator, ScanOp, Identity, Offset>  BlockScanSweepT; 
# 109
__attribute__((unused)) static typename BlockScanSweep< BlockScanSweepPolicy, InputIterator, OutputIterator, ScanOp, Identity, Offset> ::TempStorage temp_storage; 
# 112
(BlockScanSweepT(temp_storage, d_in, d_out, scan_op, identity).ConsumeRange(num_items, queue, tile_status)); 
# 116
} 
#endif
# 128 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_scan_dispatch.cuh"
template< class 
# 129
InputIterator, class 
# 130
OutputIterator, class 
# 131
ScanOp, class 
# 132
Identity, class 
# 133
Offset> 
# 134
struct DeviceScanDispatch { 
# 137
enum { 
# 138
INIT_KERNEL_THREADS = 128
# 139
}; 
# 142
typedef typename std::iterator_traits< InputIterator> ::value_type T; 
# 145
typedef cub_::ScanTileState< typename std::iterator_traits< InputIterator> ::value_type>  ScanTileState; 
# 153
struct Policy350 { 
# 155
enum { 
# 156
NOMINAL_4B_ITEMS_PER_THREAD = 12, 
# 157
ITEMS_PER_THREAD = ((((((12) * 4) / sizeof(T)) > (1)) ? ((12) * 4) / sizeof(T) : (1)) < (12)) ? ((((12) * 4) / sizeof(T)) > (1)) ? ((12) * 4) / sizeof(T) : (1) : (12)
# 158
}; 
# 170
typedef BlockScanSweepPolicy< 128, (ITEMS_PER_THREAD), BLOCK_LOAD_DIRECT, false, LOAD_LDG, BLOCK_STORE_WARP_TRANSPOSE, true, BLOCK_SCAN_RAKING_MEMOIZE>  RangeScanPolicy; 
# 171
}; 
# 174
struct Policy300 { 
# 176
enum { 
# 177
NOMINAL_4B_ITEMS_PER_THREAD = 9, 
# 178
ITEMS_PER_THREAD = ((((((9) * 4) / sizeof(T)) > (1)) ? ((9) * 4) / sizeof(T) : (1)) < (9)) ? ((((9) * 4) / sizeof(T)) > (1)) ? ((9) * 4) / sizeof(T) : (1) : (9)
# 179
}; 
# 190
typedef BlockScanSweepPolicy< 256, (ITEMS_PER_THREAD), BLOCK_LOAD_WARP_TRANSPOSE, false, LOAD_DEFAULT, BLOCK_STORE_WARP_TRANSPOSE, false, BLOCK_SCAN_RAKING_MEMOIZE>  RangeScanPolicy; 
# 191
}; 
# 194
struct Policy200 { 
# 196
enum { 
# 197
NOMINAL_4B_ITEMS_PER_THREAD = 15, 
# 198
ITEMS_PER_THREAD = ((((((15) * 4) / sizeof(T)) > (1)) ? ((15) * 4) / sizeof(T) : (1)) < (15)) ? ((((15) * 4) / sizeof(T)) > (1)) ? ((15) * 4) / sizeof(T) : (1) : (15)
# 199
}; 
# 211
typedef BlockScanSweepPolicy< 128, (ITEMS_PER_THREAD), BLOCK_LOAD_WARP_TRANSPOSE, false, LOAD_DEFAULT, BLOCK_STORE_WARP_TRANSPOSE, false, BLOCK_SCAN_RAKING_MEMOIZE>  RangeScanPolicy; 
# 212
}; 
# 215
struct Policy130 { 
# 217
enum { 
# 218
NOMINAL_4B_ITEMS_PER_THREAD = 21, 
# 219
ITEMS_PER_THREAD = ((((((21) * 4) / sizeof(T)) > (1)) ? ((21) * 4) / sizeof(T) : (1)) < (21)) ? ((((21) * 4) / sizeof(T)) > (1)) ? ((21) * 4) / sizeof(T) : (1) : (21)
# 220
}; 
# 231
typedef BlockScanSweepPolicy< 96, (ITEMS_PER_THREAD), BLOCK_LOAD_WARP_TRANSPOSE, false, LOAD_DEFAULT, BLOCK_STORE_WARP_TRANSPOSE, false, BLOCK_SCAN_RAKING_MEMOIZE>  RangeScanPolicy; 
# 232
}; 
# 235
struct Policy100 { 
# 237
enum { 
# 238
NOMINAL_4B_ITEMS_PER_THREAD = 9, 
# 239
ITEMS_PER_THREAD = ((((((9) * 4) / sizeof(T)) > (1)) ? ((9) * 4) / sizeof(T) : (1)) < (9)) ? ((((9) * 4) / sizeof(T)) > (1)) ? ((9) * 4) / sizeof(T) : (1) : (9)
# 240
}; 
# 251
typedef BlockScanSweepPolicy< 64, (ITEMS_PER_THREAD), BLOCK_LOAD_WARP_TRANSPOSE, true, LOAD_DEFAULT, BLOCK_STORE_WARP_TRANSPOSE, true, BLOCK_SCAN_WARP_SCANS>  RangeScanPolicy; 
# 252
}; 
# 272
typedef Policy100 PtxPolicy; 
# 277
struct PtxRangeScanPolicy : public Policy100::RangeScanPolicy { }; 
# 287
template< class KernelConfig> 
# 288
__attribute((always_inline)) static void 
# 289
InitConfigs(int 
# 290
ptx_version, KernelConfig &
# 291
device_scan_sweep_config) 
# 292
{ 
# 301
if (ptx_version >= 350) 
# 302
{ 
# 303
(device_scan_sweep_config.template Init< typename Policy350::RangeScanPolicy> ()); 
# 304
} else { 
# 305
if (ptx_version >= 300) 
# 306
{ 
# 307
(device_scan_sweep_config.template Init< typename Policy300::RangeScanPolicy> ()); 
# 308
} else { 
# 309
if (ptx_version >= 200) 
# 310
{ 
# 311
(device_scan_sweep_config.template Init< typename Policy200::RangeScanPolicy> ()); 
# 312
} else { 
# 313
if (ptx_version >= 130) 
# 314
{ 
# 315
(device_scan_sweep_config.template Init< typename Policy130::RangeScanPolicy> ()); 
# 316
} else 
# 318
{ 
# 319
(device_scan_sweep_config.template Init< typename Policy100::RangeScanPolicy> ()); 
# 320
}  }  }  }  
# 323
} 
# 329
struct KernelConfig { 
# 331
int block_threads; 
# 332
int items_per_thread; 
# 333
BlockLoadAlgorithm load_policy; 
# 334
BlockStoreAlgorithm store_policy; 
# 335
BlockScanAlgorithm scan_algorithm; 
# 337
template< class BlockScanSweepPolicy> 
# 338
__attribute((always_inline)) void 
# 339
Init() 
# 340
{ 
# 341
(block_threads) = BlockScanSweepPolicy::BLOCK_THREADS; 
# 342
(items_per_thread) = BlockScanSweepPolicy::ITEMS_PER_THREAD; 
# 343
(load_policy) = BlockScanSweepPolicy::LOAD_ALGORITHM; 
# 344
(store_policy) = BlockScanSweepPolicy::STORE_ALGORITHM; 
# 345
(scan_algorithm) = BlockScanSweepPolicy::SCAN_ALGORITHM; 
# 346
} 
# 348
__attribute((always_inline)) void 
# 349
Print() 
# 350
{ 
# 351
printf("%d, %d, %d, %d, %d", block_threads, items_per_thread, load_policy, store_policy, scan_algorithm); 
# 357
} 
# 358
}; 
# 369
template< class 
# 370
DeviceScanInitKernelPtr, class 
# 371
DeviceScanSweepKernelPtr> 
# 372
__attribute((always_inline)) static cudaError_t 
# 373
Dispatch(void *
# 374
d_temp_storage, size_t &
# 375
temp_storage_bytes, InputIterator 
# 376
d_in, OutputIterator 
# 377
d_out, ScanOp 
# 378
scan_op, Identity 
# 379
identity, Offset 
# 380
num_items, cudaStream_t 
# 381
stream, bool 
# 382
debug_synchronous, int 
# 383
ptx_version, DeviceScanInitKernelPtr 
# 384
device_scan_init_kernel, DeviceScanSweepKernelPtr 
# 385
device_scan_sweep_kernel, KernelConfig 
# 386
device_scan_sweep_config) 
# 387
{ 
# 395
cudaError error = cudaSuccess; 
# 396
do 
# 397
{ 
# 399
int device_ordinal; 
# 400
if (cub_::Debug(error = cudaGetDevice(&device_ordinal), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_scan_dispatch.cuh", 400)) { break; }  
# 403
int sm_version; 
# 404
if (cub_::Debug(error = SmVersion(sm_version, device_ordinal), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_scan_dispatch.cuh", 404)) { break; }  
# 407
int sm_count; 
# 408
if (cub_::Debug(error = cudaDeviceGetAttribute(&sm_count, cudaDevAttrMultiProcessorCount, device_ordinal), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_scan_dispatch.cuh", 408)) { break; }  
# 411
int tile_size = (device_scan_sweep_config.block_threads) * (device_scan_sweep_config.items_per_thread); 
# 412
int num_tiles = ((num_items + tile_size) - 1) / tile_size; 
# 415
size_t allocation_sizes[2]; 
# 416
if (cub_::Debug(error = ScanTileState::AllocationSize(num_tiles, (allocation_sizes)[0]), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_scan_dispatch.cuh", 416)) { break; }  
# 417
((allocation_sizes)[1]) = GridQueue< int> ::AllocationSize(); 
# 420
void *allocations[2]; 
# 421
if (cub_::Debug(error = AliasTemporaries(d_temp_storage, temp_storage_bytes, allocations, allocation_sizes), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_scan_dispatch.cuh", 421)) { break; }  
# 422
if (d_temp_storage == (__null)) 
# 423
{ 
# 425
return cudaSuccess; 
# 426
}  
# 429
ScanTileState tile_status; 
# 430
if (cub_::Debug(error = (tile_status.Init(num_tiles, (allocations)[0], (allocation_sizes)[0])), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_scan_dispatch.cuh", 430)) { break; }  
# 433
GridQueue< int>  queue((allocations)[1]); 
# 436
int init_grid_size = ((num_tiles + (INIT_KERNEL_THREADS)) - 1) / (INIT_KERNEL_THREADS); 
# 437
if (debug_synchronous) { printf("Invoking device_scan_init_kernel<<<%d, %d, 0, %lld>>>()\n", init_grid_size, INIT_KERNEL_THREADS, (long long)stream); }  ; 
# 440
(cudaConfigureCall(init_grid_size, INIT_KERNEL_THREADS, 0, stream)) ? (void)0 : device_scan_init_kernel(queue, tile_status, num_tiles); 
# 446
if (cub_::Debug(error = cudaPeekAtLastError(), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_scan_dispatch.cuh", 446)) { break; }  
# 449
if (debug_synchronous && (cub_::Debug(error = SyncStream(stream), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_scan_dispatch.cuh", 449))) { break; }  
# 452
int range_scan_sm_occupancy; 
# 453
if (cub_::Debug(error = MaxSmOccupancy(range_scan_sm_occupancy, sm_version, device_scan_sweep_kernel, (device_scan_sweep_config.block_threads)), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_scan_dispatch.cuh", 457)) { 
# 457
break; }  
# 460
dim3 scan_grid_size; 
# 461
if (ptx_version <= 130) 
# 462
{ 
# 464
int max_dim_x = (32 * 1024); 
# 465
(scan_grid_size.z) = (1); 
# 466
(scan_grid_size.y) = (((num_tiles + max_dim_x) - 1) / max_dim_x); 
# 467
(scan_grid_size.x) = ((max_dim_x < num_tiles) ? max_dim_x : num_tiles); 
# 468
} else 
# 470
{ 
# 472
int range_scan_occupancy = range_scan_sm_occupancy * sm_count; 
# 473
(scan_grid_size.z) = (1); 
# 474
(scan_grid_size.y) = (1); 
# 475
(scan_grid_size.x) = ((num_tiles < range_scan_occupancy) ? num_tiles : range_scan_occupancy); 
# 478
}  
# 481
if (debug_synchronous) { printf("Invoking device_scan_sweep_kernel<<<{%d,%d,%d}, %d, 0, %lld>>>(), %d items per thread, %d SM occupancy\n", scan_grid_size.x, scan_grid_size.y, scan_grid_size.z, (device_scan_sweep_config.block_threads), (long long)stream, (device_scan_sweep_config.items_per_thread), range_scan_sm_occupancy); }  
# 482
; 
# 485
(cudaConfigureCall(scan_grid_size, ((device_scan_sweep_config.block_threads)), 0, stream)) ? (void)0 : device_scan_sweep_kernel(d_in, d_out, tile_status, scan_op, identity, num_items, queue); 
# 495
if (cub_::Debug(error = cudaPeekAtLastError(), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_scan_dispatch.cuh", 495)) { break; }  
# 498
if (debug_synchronous && (cub_::Debug(error = SyncStream(stream), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_scan_dispatch.cuh", 498))) { break; }  
# 499
} 
# 500
while (0); 
# 502
return error; 
# 505
} 
# 511
__attribute((always_inline)) static cudaError_t 
# 512
Dispatch(void *
# 513
d_temp_storage, size_t &
# 514
temp_storage_bytes, InputIterator 
# 515
d_in, OutputIterator 
# 516
d_out, ScanOp 
# 517
scan_op, Identity 
# 518
identity, Offset 
# 519
num_items, cudaStream_t 
# 520
stream, bool 
# 521
debug_synchronous) 
# 522
{ 
# 523
cudaError error = cudaSuccess; 
# 524
do 
# 525
{ 
# 527
int ptx_version; 
# 529
if (cub_::Debug(error = PtxVersion(ptx_version), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_scan_dispatch.cuh", 529)) { break; }  
# 535
KernelConfig device_scan_sweep_config; 
# 536
InitConfigs(ptx_version, device_scan_sweep_config); 
# 539
if (cub_::Debug(error = Dispatch(d_temp_storage, temp_storage_bytes, d_in, d_out, scan_op, identity, num_items, stream, debug_synchronous, ptx_version, DeviceScanInitKernel< Offset, ScanTileState> , DeviceScanSweepKernel< PtxRangeScanPolicy, InputIterator, OutputIterator, ScanTileState, ScanOp, Identity, Offset> , device_scan_sweep_config), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_scan_dispatch.cuh", 552)) { 
# 552
break; }  
# 553
} 
# 554
while (0); 
# 556
return error; 
# 557
} 
# 558
}; 
# 562
}
# 563
}}}}
# 49 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_select_sweep.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 52
namespace cub_ { 
# 62
template< int 
# 63
_BLOCK_THREADS, int 
# 64
_ITEMS_PER_THREAD, BlockLoadAlgorithm 
# 65
_LOAD_ALGORITHM, CacheLoadModifier 
# 66
_LOAD_MODIFIER, bool 
# 67
_STORE_WARP_TIME_SLICING, BlockScanAlgorithm 
# 68
_SCAN_ALGORITHM> 
# 69
struct BlockSelectSweepPolicy { 
# 72
enum { 
# 73
BLOCK_THREADS = _BLOCK_THREADS, 
# 74
ITEMS_PER_THREAD = _ITEMS_PER_THREAD, 
# 75
STORE_WARP_TIME_SLICING = _STORE_WARP_TIME_SLICING
# 76
}; 
# 78
static const BlockLoadAlgorithm LOAD_ALGORITHM = _LOAD_ALGORITHM; 
# 79
static const CacheLoadModifier LOAD_MODIFIER = _LOAD_MODIFIER; 
# 80
static const BlockScanAlgorithm SCAN_ALGORITHM = _SCAN_ALGORITHM; 
# 81
}; 
# 97
template< class 
# 98
BlockSelectSweepPolicy, class 
# 99
InputIterator, class 
# 100
FlagsInputIterator, class 
# 101
SelectedOutputIterator, class 
# 102
SelectOp, class 
# 103
EqualityOp, class 
# 104
Offset, bool 
# 105
KEEP_REJECTS> 
# 106
struct BlockSelectSweep { 
# 113
typedef typename std::iterator_traits< InputIterator> ::value_type T; 
# 116
typedef typename std::iterator_traits< FlagsInputIterator> ::value_type Flag; 
# 119
typedef cub_::ScanTileState< Offset>  ScanTileState; 
# 123
enum { 
# 124
USE_SELECT_OP, 
# 125
USE_SELECT_FLAGS, 
# 126
USE_DISCONTINUITY, 
# 128
BLOCK_THREADS = BlockSelectSweepPolicy::BLOCK_THREADS, 
# 131
WARP_THREADS = 1 << 5, 
# 134
WARPS = (((BlockSelectSweepPolicy::BLOCK_THREADS) + (1 << 5)) - 1) / (1 << 5), 
# 136
ITEMS_PER_THREAD = BlockSelectSweepPolicy::ITEMS_PER_THREAD, 
# 137
TILE_ITEMS = (BlockSelectSweepPolicy::BLOCK_THREADS) * (BlockSelectSweepPolicy::ITEMS_PER_THREAD), 
# 140
SYNC_AFTER_LOAD = BlockSelectSweepPolicy::LOAD_ALGORITHM != BLOCK_LOAD_DIRECT, 
# 143
STORE_WARP_TIME_SLICING = BlockSelectSweepPolicy::STORE_WARP_TIME_SLICING, 
# 144
ACTIVE_EXCHANGE_WARPS = (BlockSelectSweepPolicy::STORE_WARP_TIME_SLICING) ? 1 : ((((BlockSelectSweepPolicy::BLOCK_THREADS) + (1 << 5)) - 1) / (1 << 5)), 
# 146
SELECT_METHOD = (!Equals< SelectOp, NullType> ::VALUE) ? 0 : ((!Equals< typename std::iterator_traits< FlagsInputIterator> ::value_type, NullType> ::VALUE) ? (0) + 1 : (((0) + 1) + 1))
# 151
}; 
# 157
typedef typename If< IsPointer< InputIterator> ::VALUE, CacheModifiedInputIterator< BlockSelectSweepPolicy::LOAD_MODIFIER, typename std::iterator_traits< InputIterator> ::value_type, Offset> , InputIterator> ::Type WrappedInputIterator; 
# 163
typedef typename If< IsPointer< FlagsInputIterator> ::VALUE, CacheModifiedInputIterator< BlockSelectSweepPolicy::LOAD_MODIFIER, typename std::iterator_traits< FlagsInputIterator> ::value_type, Offset> , FlagsInputIterator> ::Type WrappedFlagsInputIterator; 
# 171
typedef BlockLoad< typename If< IsPointer< InputIterator> ::VALUE, CacheModifiedInputIterator< BlockSelectSweepPolicy::LOAD_MODIFIER, typename std::iterator_traits< InputIterator> ::value_type, Offset> , InputIterator> ::Type, BlockSelectSweepPolicy::BLOCK_THREADS, BlockSelectSweepPolicy::ITEMS_PER_THREAD, BlockSelectSweepPolicy::LOAD_ALGORITHM>  BlockLoadT; 
# 179
typedef BlockLoad< typename If< IsPointer< FlagsInputIterator> ::VALUE, CacheModifiedInputIterator< BlockSelectSweepPolicy::LOAD_MODIFIER, typename std::iterator_traits< FlagsInputIterator> ::value_type, Offset> , FlagsInputIterator> ::Type, BlockSelectSweepPolicy::BLOCK_THREADS, BlockSelectSweepPolicy::ITEMS_PER_THREAD, BlockSelectSweepPolicy::LOAD_ALGORITHM>  BlockLoadFlags; 
# 182
typedef BlockDiscontinuity< typename std::iterator_traits< InputIterator> ::value_type, BLOCK_THREADS>  BlockDiscontinuityT; 
# 185
typedef WarpScan< Offset>  WarpScanAllocations; 
# 192
typedef BlockScanLookbackPrefixOp< Offset, Sum, cub_::ScanTileState< Offset> >  LookbackPrefixCallbackOp; 
# 195
typedef WarpExchange< typename std::iterator_traits< InputIterator> ::value_type, ITEMS_PER_THREAD>  WarpExchangeT; 
# 198
struct _TempStorage { 
# 201
union { 
# 203
struct { 
# 204
typename BlockDiscontinuity< typename std::iterator_traits< InputIterator> ::value_type, BLOCK_THREADS> ::TempStorage discontinuity; 
# 205
typename WarpScan< Offset> ::TempStorage warp_scan[WARPS]; 
# 206
Offset warp_aggregates[WARPS]; 
# 207
typename BlockScanLookbackPrefixOp< Offset, Sum, cub_::ScanTileState< Offset> > ::TempStorage prefix; 
# 208
}; 
# 211
typename BlockLoad< typename If< IsPointer< InputIterator> ::VALUE, CacheModifiedInputIterator< BlockSelectSweepPolicy::LOAD_MODIFIER, typename std::iterator_traits< InputIterator> ::value_type, Offset> , InputIterator> ::Type, BlockSelectSweepPolicy::BLOCK_THREADS, BlockSelectSweepPolicy::ITEMS_PER_THREAD, BlockSelectSweepPolicy::LOAD_ALGORITHM> ::TempStorage load_items; 
# 214
typename BlockLoad< typename If< IsPointer< FlagsInputIterator> ::VALUE, CacheModifiedInputIterator< BlockSelectSweepPolicy::LOAD_MODIFIER, typename std::iterator_traits< FlagsInputIterator> ::value_type, Offset> , FlagsInputIterator> ::Type, BlockSelectSweepPolicy::BLOCK_THREADS, BlockSelectSweepPolicy::ITEMS_PER_THREAD, BlockSelectSweepPolicy::LOAD_ALGORITHM> ::TempStorage load_flags; 
# 218
union { 
# 219
unsigned long long align; 
# 220
typename WarpExchange< typename std::iterator_traits< InputIterator> ::value_type, ITEMS_PER_THREAD> ::TempStorage exchange[ACTIVE_EXCHANGE_WARPS]; 
# 221
}; 
# 222
}; 
# 224
Offset tile_idx; 
# 225
Offset tile_inclusive; 
# 226
Offset tile_exclusive; 
# 227
}; 
# 230
struct TempStorage : public Uninitialized< _TempStorage>  { }; 
# 237
_TempStorage &temp_storage; 
# 238
WrappedInputIterator d_in; 
# 239
WrappedFlagsInputIterator d_flags; 
# 240
SelectedOutputIterator d_selected_out; 
# 241
SelectOp select_op; 
# 242
InequalityWrapper< EqualityOp>  inequality_op; 
# 243
Offset num_items; 
# 251
__attribute((always_inline)) 
# 252
BlockSelectSweep(TempStorage &
# 253
temp_storage, InputIterator 
# 254
d_in, FlagsInputIterator 
# 255
d_flags, SelectedOutputIterator 
# 256
d_selected_out, SelectOp 
# 257
select_op, EqualityOp 
# 258
equality_op, Offset 
# 259
num_items) : temp_storage((temp_storage.Alias())), d_in(d_in), d_flags(d_flags), d_selected_out(d_selected_out), select_op(select_op), inequality_op(equality_op), num_items(num_items) 
# 268
{int *volatile ___ = 0;(void)temp_storage;(void)d_in;(void)d_flags;(void)d_selected_out;(void)select_op;(void)equality_op;(void)num_items;::free(___);}
#if 0
# 268
{ } 
#endif
# 278 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_select_sweep.cuh"
template< bool FIRST_TILE, bool LAST_TILE, int ITERATION> 
# 279
__attribute((always_inline)) void ApplySelectionOp(Offset 
# 280
block_offset, Offset 
# 281
num_remaining, T (&
# 282
items)[ITEMS_PER_THREAD], Offset (&
# 283
selected)[ITEMS_PER_THREAD], Int2Type< ITERATION>  
# 284
iteration) 
# 285
{int volatile ___ = 1;(void)block_offset;(void)num_remaining;(void)items;(void)selected;(void)iteration;
# 291
::exit(___);}
#if 0
# 285
{ 
# 286
((selected)[ITERATION]) = 0; 
# 287
if ((!LAST_TILE) || ((((Offset)((__device_builtin_variable_threadIdx.x) * (ITEMS_PER_THREAD))) + ITERATION) < num_remaining)) { 
# 288
((selected)[ITERATION]) = (select_op)((items)[ITERATION]); }  
# 290
ApplySelectionOp< FIRST_TILE, LAST_TILE> (block_offset, num_remaining, items, selected, Int2Type< ITERATION + 1> ()); 
# 291
} 
#endif
# 296 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_select_sweep.cuh"
template< bool FIRST_TILE, bool LAST_TILE> 
# 297
__attribute((always_inline)) void ApplySelectionOp(Offset 
# 298
block_offset, Offset 
# 299
num_remaining, T (&
# 300
items)[ITEMS_PER_THREAD], Offset (&
# 301
selected)[ITEMS_PER_THREAD], Int2Type< ITEMS_PER_THREAD>  
# 302
iteration) 
# 303
{int volatile ___ = 1;(void)block_offset;(void)num_remaining;(void)items;(void)selected;(void)iteration;::exit(___);}
#if 0
# 303
{ } 
#endif
# 308 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_select_sweep.cuh"
template< bool FIRST_TILE, bool LAST_TILE> 
# 309
__attribute((always_inline)) void InitializeSelections(Offset 
# 310
block_offset, Offset 
# 311
num_remaining, T (&
# 312
items)[ITEMS_PER_THREAD], Offset (&
# 313
selected)[ITEMS_PER_THREAD], Int2Type< USE_SELECT_OP>  
# 314
select_method) 
# 315
{int volatile ___ = 1;(void)block_offset;(void)num_remaining;(void)items;(void)selected;(void)select_method;
# 319
::exit(___);}
#if 0
# 315
{ 
# 316
__syncthreads(); 
# 318
ApplySelectionOp< FIRST_TILE, LAST_TILE> (block_offset, num_remaining, items, selected, Int2Type< 0> ()); 
# 319
} 
#endif
# 325 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_select_sweep.cuh"
template< bool FIRST_TILE, bool LAST_TILE> 
# 326
__attribute((always_inline)) void InitializeSelections(Offset 
# 327
block_offset, Offset 
# 328
num_remaining, T (&
# 329
items)[ITEMS_PER_THREAD], Offset (&
# 330
selected)[ITEMS_PER_THREAD], Int2Type< USE_SELECT_FLAGS>  
# 331
select_method) 
# 332
{int volatile ___ = 1;(void)block_offset;(void)num_remaining;(void)items;(void)selected;(void)select_method;
# 348
::exit(___);}
#if 0
# 332
{ 
# 333
Flag flags[ITEMS_PER_THREAD]; 
# 335
if (LAST_TILE) { 
# 336
(((BlockLoadFlags)(((temp_storage).load_flags))).Load((d_flags) + block_offset, flags, num_remaining, 0)); } else { 
# 338
(((BlockLoadFlags)(((temp_storage).load_flags))).Load((d_flags) + block_offset, flags)); }  
# 341
#pragma unroll
for (
# 341
int ITEM = 0; ITEM < (ITEMS_PER_THREAD); ++ITEM) 
# 342
{ 
# 343
((selected)[ITEM]) = ((flags)[ITEM]); 
# 344
}  
# 346
if (SYNC_AFTER_LOAD) { 
# 347
__syncthreads(); }  
# 348
} 
#endif
# 354 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_select_sweep.cuh"
template< bool FIRST_TILE, bool LAST_TILE> 
# 355
__attribute((always_inline)) void InitializeSelections(Offset 
# 356
block_offset, Offset 
# 357
num_remaining, T (&
# 358
items)[ITEMS_PER_THREAD], Offset (&
# 359
selected)[ITEMS_PER_THREAD], Int2Type< USE_DISCONTINUITY>  
# 360
select_method) 
# 361
{int volatile ___ = 1;(void)block_offset;(void)num_remaining;(void)items;(void)selected;(void)select_method;
# 376
::exit(___);}
#if 0
# 361
{ 
# 362
if (FIRST_TILE) 
# 363
{ 
# 365
(((BlockDiscontinuityT)(((temp_storage).discontinuity))).FlagHeads(selected, items, inequality_op)); 
# 366
} else 
# 368
{ 
# 370
T tile_predecessor_item; 
# 371
if ((__device_builtin_variable_threadIdx.x) == (0)) { 
# 372
tile_predecessor_item = ((d_in)[block_offset - 1]); }  
# 374
(((BlockDiscontinuityT)(((temp_storage).discontinuity))).FlagHeads(selected, items, inequality_op, tile_predecessor_item)); 
# 375
}  
# 376
} 
#endif
# 386 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_select_sweep.cuh"
__attribute((always_inline)) void ScanAllocations(Offset &
# 387
tile_aggregate, int &
# 388
warp_aggregate, int &
# 389
warp_exclusive, int (&
# 390
selected)[ITEMS_PER_THREAD], int (&
# 391
thread_exclusives)[ITEMS_PER_THREAD]) 
# 392
{int volatile ___ = 1;(void)tile_aggregate;(void)warp_aggregate;(void)warp_exclusive;(void)selected;(void)thread_exclusives;
# 429
::exit(___);}
#if 0
# 392
{ 
# 394
int warp_id = ((WARPS) == 1) ? 0 : ((__device_builtin_variable_threadIdx.x) / (WARP_THREADS)); 
# 395
int lane_id = LaneId(); 
# 397
int thread_aggregate = ThreadReduce(selected, Sum()); 
# 398
int inclusive_partial, exclusive_partial; 
# 399
(((WarpScanAllocations)(((temp_storage).warp_scan)[warp_id])).Sum(thread_aggregate, inclusive_partial, exclusive_partial)); 
# 400
ThreadScanExclusive(selected, thread_exclusives, Sum(), exclusive_partial); 
# 403
if (lane_id == ((WARP_THREADS) - 1)) { 
# 404
(((temp_storage).warp_aggregates)[warp_id]) = inclusive_partial; }  
# 406
__syncthreads(); 
# 409
warp_exclusive = 0; 
# 410
warp_aggregate = (((temp_storage).warp_aggregates)[warp_id]); 
# 411
tile_aggregate = (((temp_storage).warp_aggregates)[0]); 
# 414
#pragma unroll
for (
# 414
int WARP = 1; WARP < (WARPS); ++WARP) 
# 415
{ 
# 416
if (warp_id == WARP) { 
# 417
warp_exclusive = tile_aggregate; }  
# 419
tile_aggregate += (((temp_storage).warp_aggregates)[WARP]); 
# 420
}  
# 424
#pragma unroll
for (
# 424
int ITEM = 0; ITEM < (ITEMS_PER_THREAD); ++ITEM) 
# 425
{ 
# 426
if (!((selected)[ITEM])) { 
# 427
((thread_exclusives)[ITEM]) = ((WARP_THREADS) * (ITEMS_PER_THREAD)); }  
# 428
}  
# 429
} 
#endif
# 438 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_select_sweep.cuh"
__attribute((always_inline)) void ScatterTwoPhase(Offset 
# 439
tile_exclusive, int 
# 440
warp_aggregate, int 
# 441
warp_exclusive, int (&
# 442
thread_exclusives)[ITEMS_PER_THREAD], T (&
# 443
items)[ITEMS_PER_THREAD], Int2Type< 1>  
# 444
is_warp_time_slice) 
# 445
{int volatile ___ = 1;(void)tile_exclusive;(void)warp_aggregate;(void)warp_exclusive;(void)thread_exclusives;(void)items;(void)is_warp_time_slice;
# 475
::exit(___);}
#if 0
# 445
{ 
# 446
int warp_id = ((WARPS) == 1) ? 0 : ((__device_builtin_variable_threadIdx.x) / (WARP_THREADS)); 
# 447
int lane_id = LaneId(); 
# 450
if (warp_id == 0) 
# 451
{ 
# 452
(((WarpExchangeT)(((temp_storage).exchange)[0])).ScatterToStriped(items, thread_exclusives)); 
# 453
}  
# 457
#pragma unroll
for (
# 457
int SLICE = 1; SLICE < (WARPS); ++SLICE) 
# 458
{ 
# 459
__syncthreads(); 
# 461
if (warp_id == SLICE) 
# 462
{ 
# 463
(((WarpExchangeT)(((temp_storage).exchange)[0])).ScatterToStriped(items, thread_exclusives)); 
# 464
}  
# 465
}  
# 468
#pragma unroll
for (
# 468
int ITEM = 0; ITEM < (ITEMS_PER_THREAD); ITEM++) 
# 469
{ 
# 470
if ((ITEM * (WARP_THREADS)) < (warp_aggregate - lane_id)) 
# 471
{ 
# 472
((d_selected_out)[((tile_exclusive + warp_exclusive) + (ITEM * (WARP_THREADS))) + lane_id]) = ((items)[ITEM]); 
# 473
}  
# 474
}  
# 475
} 
#endif
# 482 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_select_sweep.cuh"
__attribute((always_inline)) void ScatterTwoPhase(Offset 
# 483
tile_exclusive, int 
# 484
warp_aggregate, int 
# 485
warp_exclusive, int (&
# 486
thread_exclusives)[ITEMS_PER_THREAD], T (&
# 487
items)[ITEMS_PER_THREAD], Int2Type< 0>  
# 488
is_warp_time_slice) 
# 489
{int volatile ___ = 1;(void)tile_exclusive;(void)warp_aggregate;(void)warp_exclusive;(void)thread_exclusives;(void)items;(void)is_warp_time_slice;
# 503
::exit(___);}
#if 0
# 489
{ 
# 490
int warp_id = ((WARPS) == 1) ? 0 : ((__device_builtin_variable_threadIdx.x) / (WARP_THREADS)); 
# 491
int lane_id = LaneId(); 
# 493
(((WarpExchangeT)(((temp_storage).exchange)[warp_id])).ScatterToStriped(items, thread_exclusives)); 
# 496
#pragma unroll
for (
# 496
int ITEM = 0; ITEM < (ITEMS_PER_THREAD); ITEM++) 
# 497
{ 
# 498
if ((ITEM * (WARP_THREADS)) < (warp_aggregate - lane_id)) 
# 499
{ 
# 500
((d_selected_out)[((tile_exclusive + warp_exclusive) + (ITEM * (WARP_THREADS))) + lane_id]) = ((items)[ITEM]); 
# 501
}  
# 502
}  
# 503
} 
#endif
# 510 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_select_sweep.cuh"
__attribute((always_inline)) void Scatter(Offset 
# 511
tile_aggregate, Offset 
# 512
tile_exclusive, int 
# 513
warp_aggregate, int 
# 514
warp_exclusive, int (&
# 515
thread_exclusives)[ITEMS_PER_THREAD], T (&
# 516
items)[ITEMS_PER_THREAD]) 
# 517
{int volatile ___ = 1;(void)tile_aggregate;(void)tile_exclusive;(void)warp_aggregate;(void)warp_exclusive;(void)thread_exclusives;(void)items;
# 541
::exit(___);}
#if 0
# 517
{ 
# 518
if (((ITEMS_PER_THREAD) == 1) || (tile_aggregate < (BLOCK_THREADS))) 
# 519
{ 
# 521
if (warp_aggregate) 
# 522
{ 
# 524
#pragma unroll
for (
# 524
int ITEM = 0; ITEM < (ITEMS_PER_THREAD); ++ITEM) 
# 525
{ 
# 526
if (((thread_exclusives)[ITEM]) < warp_aggregate) { 
# 527
((d_selected_out)[(tile_exclusive + warp_exclusive) + ((thread_exclusives)[ITEM])]) = ((items)[ITEM]); }  
# 528
}  
# 529
}  
# 530
} else 
# 532
{ 
# 533
ScatterTwoPhase(tile_exclusive, warp_aggregate, warp_exclusive, thread_exclusives, items, Int2Type< STORE_WARP_TIME_SLICING> ()); 
# 540
}  
# 541
} 
#endif
# 554 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_select_sweep.cuh"
template< bool LAST_TILE> 
# 555
__attribute((always_inline)) Offset ConsumeTile(Offset 
# 556
num_items, Offset 
# 557
num_remaining, int 
# 558
tile_idx, Offset 
# 559
block_offset, ScanTileState &
# 560
tile_status) 
# 561
{int volatile ___ = 1;(void)num_items;(void)num_remaining;(void)tile_idx;(void)block_offset;(void)tile_status;
# 658
::exit(___);}
#if 0
# 561
{ 
# 562
if (tile_idx == 0) 
# 563
{ 
# 567
T items[ITEMS_PER_THREAD]; 
# 568
if (LAST_TILE) 
# 569
{ 
# 570
T oob_item = ((SELECT_METHOD) == (USE_DISCONTINUITY)) ? (d_in)[num_items - 1] : ZeroInitialize< T> (); 
# 574
(((BlockLoadT)(((temp_storage).load_items))).Load((d_in) + block_offset, items, num_remaining, oob_item)); 
# 575
} else 
# 577
{ 
# 578
(((BlockLoadT)(((temp_storage).load_items))).Load((d_in) + block_offset, items)); 
# 579
}  
# 581
if (SYNC_AFTER_LOAD) { 
# 582
__syncthreads(); }  
# 585
int selected[ITEMS_PER_THREAD]; 
# 586
InitializeSelections< true, LAST_TILE> (block_offset, num_remaining, items, selected, Int2Type< SELECT_METHOD> ()); 
# 589
Offset tile_aggregate; 
# 590
int warp_aggregate, warp_exclusive; 
# 591
int thread_exclusives[ITEMS_PER_THREAD]; 
# 592
ScanAllocations(tile_aggregate, warp_aggregate, warp_exclusive, selected, thread_exclusives); 
# 595
if ((!LAST_TILE) && ((__device_builtin_variable_threadIdx.x) == (0))) { 
# 596
(tile_status.SetInclusive(0, tile_aggregate)); }  
# 598
Offset tile_exclusive = (0); 
# 601
Scatter(tile_aggregate, tile_exclusive, warp_aggregate, warp_exclusive, thread_exclusives, items); 
# 604
return tile_aggregate; 
# 605
} else 
# 607
{ 
# 611
T items[ITEMS_PER_THREAD]; 
# 612
if (LAST_TILE) 
# 613
{ 
# 614
T oob_item = ((SELECT_METHOD) == (USE_DISCONTINUITY)) ? (d_in)[num_items - 1] : ZeroInitialize< T> (); 
# 618
(((BlockLoadT)(((temp_storage).load_items))).Load((d_in) + block_offset, items, num_remaining, oob_item)); 
# 619
} else 
# 621
{ 
# 622
(((BlockLoadT)(((temp_storage).load_items))).Load((d_in) + block_offset, items)); 
# 623
}  
# 625
if (SYNC_AFTER_LOAD) { 
# 626
__syncthreads(); }  
# 629
int selected[ITEMS_PER_THREAD]; 
# 630
InitializeSelections< false, LAST_TILE> (block_offset, num_remaining, items, selected, Int2Type< SELECT_METHOD> ()); 
# 633
Offset tile_aggregate; 
# 634
int warp_aggregate, warp_exclusive; 
# 635
int thread_exclusives[ITEMS_PER_THREAD]; 
# 636
ScanAllocations(tile_aggregate, warp_aggregate, warp_exclusive, selected, thread_exclusives); 
# 639
LookbackPrefixCallbackOp prefix_op(tile_status, ((temp_storage).prefix), Sum(), tile_idx); 
# 640
int warp_id = ((WARPS) == 1) ? 0 : ((__device_builtin_variable_threadIdx.x) / (WARP_THREADS)); 
# 641
if (warp_id == 0) 
# 642
{ 
# 643
prefix_op(tile_aggregate); 
# 644
if ((__device_builtin_variable_threadIdx.x) == (0)) { 
# 645
((temp_storage).tile_exclusive) = (prefix_op.exclusive_prefix); }  
# 646
}  
# 648
__syncthreads(); 
# 650
Offset tile_exclusive = (((temp_storage).tile_exclusive)); 
# 653
Scatter(tile_aggregate, tile_exclusive, warp_aggregate, warp_exclusive, thread_exclusives, items); 
# 656
return prefix_op.inclusive_prefix; 
# 657
}  
# 658
} 
#endif
# 664 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_select_sweep.cuh"
template< class NumSelectedIterator> 
# 665
__attribute((always_inline)) void ConsumeRange(int 
# 666
num_tiles, GridQueue< int>  
# 667
queue, ScanTileState &
# 668
tile_status, NumSelectedIterator 
# 669
d_num_selected_out) 
# 670
{int volatile ___ = 1;(void)num_tiles;(void)queue;(void)tile_status;(void)d_num_selected_out;
# 711
::exit(___);}
#if 0
# 670
{ 
# 685
int tile_idx = ((__device_builtin_variable_blockIdx.y) * (__device_builtin_variable_gridDim.x)) + (__device_builtin_variable_blockIdx.x); 
# 689
Offset block_offset = ((Offset)(TILE_ITEMS)) * tile_idx; 
# 690
Offset num_remaining = (num_items) - block_offset; 
# 692
if (num_remaining > 0) 
# 693
{ 
# 694
if (num_remaining > (TILE_ITEMS)) 
# 695
{ 
# 697
ConsumeTile< false> (num_items, num_remaining, tile_idx, block_offset, tile_status); 
# 698
} else 
# 700
{ 
# 702
Offset total_selected = ConsumeTile< true> (num_items, num_remaining, tile_idx, block_offset, tile_status); 
# 705
if ((__device_builtin_variable_threadIdx.x) == (0)) 
# 706
{ 
# 707
(*d_num_selected_out) = total_selected; 
# 708
}  
# 709
}  
# 710
}  
# 711
} 
#endif
# 713 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_select_sweep.cuh"
}; 
# 716
}
# 717
}}}}
# 48 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_select_dispatch.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 51
namespace cub_ { 
# 64
template< class 
# 65
BlockSelectSweepPolicy, class 
# 66
InputIterator, class 
# 67
FlagsInputIterator, class 
# 68
SelectedOutputIterator, class 
# 69
NumSelectedIterator, class 
# 70
ScanTileState, class 
# 71
SelectOp, class 
# 72
EqualityOp, class 
# 73
Offset, bool 
# 74
KEEP_REJECTS> static void 
# 76
__wrapper__device_stub_DeviceSelectSweepKernel(InputIterator &
# 77
d_in, FlagsInputIterator &
# 78
d_flags, SelectedOutputIterator &
# 79
d_selected_out, NumSelectedIterator &
# 80
d_num_selected_out, ScanTileState &
# 81
tile_status, SelectOp &
# 82
select_op, EqualityOp &
# 83
equality_op, Offset &
# 84
num_items, int &
# 85
num_tiles, GridQueue< int>  &
# 86
queue) {exit(1);}
#if 0
# 87
{ 
# 97
typedef BlockSelectSweep< BlockSelectSweepPolicy, InputIterator, FlagsInputIterator, SelectedOutputIterator, SelectOp, EqualityOp, Offset, KEEP_REJECTS>  BlockSelectSweepT; 
# 100
__attribute__((unused)) static typename BlockSelectSweep< BlockSelectSweepPolicy, InputIterator, FlagsInputIterator, SelectedOutputIterator, SelectOp, EqualityOp, Offset, KEEP_REJECTS> ::TempStorage temp_storage; 
# 103
(BlockSelectSweepT(temp_storage, d_in, d_flags, d_selected_out, select_op, equality_op, num_items).ConsumeRange(num_tiles, queue, tile_status, d_num_selected_out)); 
# 108
} 
#endif
# 64 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_select_dispatch.cuh"
template< class 
# 65
BlockSelectSweepPolicy, class 
# 66
InputIterator, class 
# 67
FlagsInputIterator, class 
# 68
SelectedOutputIterator, class 
# 69
NumSelectedIterator, class 
# 70
ScanTileState, class 
# 71
SelectOp, class 
# 72
EqualityOp, class 
# 73
Offset, bool 
# 74
KEEP_REJECTS> void 
# 76
DeviceSelectSweepKernel(InputIterator 
# 77
d_in, FlagsInputIterator 
# 78
d_flags, SelectedOutputIterator 
# 79
d_selected_out, NumSelectedIterator 
# 80
d_num_selected_out, ScanTileState 
# 81
tile_status, SelectOp 
# 82
select_op, EqualityOp 
# 83
equality_op, Offset 
# 84
num_items, int 
# 85
num_tiles, GridQueue< int>  
# 86
queue) 
# 87
{__wrapper__device_stub_DeviceSelectSweepKernel<BlockSelectSweepPolicy,InputIterator,FlagsInputIterator,SelectedOutputIterator,NumSelectedIterator,ScanTileState,SelectOp,EqualityOp,Offset,KEEP_REJECTS>(d_in,d_flags,d_selected_out,d_num_selected_out,tile_status,select_op,equality_op,num_items,num_tiles,queue);
# 108
return;}
#if 0
# 87
{ 
# 97
typedef BlockSelectSweep< BlockSelectSweepPolicy, InputIterator, FlagsInputIterator, SelectedOutputIterator, SelectOp, EqualityOp, Offset, KEEP_REJECTS>  BlockSelectSweepT; 
# 100
__attribute__((unused)) static typename BlockSelectSweep< BlockSelectSweepPolicy, InputIterator, FlagsInputIterator, SelectedOutputIterator, SelectOp, EqualityOp, Offset, KEEP_REJECTS> ::TempStorage temp_storage; 
# 103
(BlockSelectSweepT(temp_storage, d_in, d_flags, d_selected_out, select_op, equality_op, num_items).ConsumeRange(num_tiles, queue, tile_status, d_num_selected_out)); 
# 108
} 
#endif
# 120 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_select_dispatch.cuh"
template< class 
# 121
InputIterator, class 
# 122
FlagsInputIterator, class 
# 123
SelectedOutputIterator, class 
# 124
NumSelectedIterator, class 
# 125
SelectOp, class 
# 126
EqualityOp, class 
# 127
Offset, bool 
# 128
KEEP_REJECTS> 
# 129
struct DeviceSelectDispatch { 
# 136
typedef typename std::iterator_traits< InputIterator> ::value_type T; 
# 139
typedef typename std::iterator_traits< FlagsInputIterator> ::value_type Flag; 
# 142
enum { 
# 143
INIT_KERNEL_THREADS = 128
# 144
}; 
# 147
typedef cub_::ScanTileState< Offset>  ScanTileState; 
# 155
struct Policy350 { 
# 157
enum { 
# 158
NOMINAL_4B_ITEMS_PER_THREAD = 17, 
# 159
ITEMS_PER_THREAD = ((((((17) * 4) / sizeof(T)) > (1)) ? ((17) * 4) / sizeof(T) : (1)) < (17)) ? ((((17) * 4) / sizeof(T)) > (1)) ? ((17) * 4) / sizeof(T) : (1) : (17)
# 160
}; 
# 169
typedef BlockSelectSweepPolicy< 96, (ITEMS_PER_THREAD), BLOCK_LOAD_DIRECT, LOAD_LDG, true, BLOCK_SCAN_WARP_SCANS>  RangeSelectPolicy; 
# 170
}; 
# 173
struct Policy300 { 
# 175
enum { 
# 176
NOMINAL_4B_ITEMS_PER_THREAD = 5, 
# 177
ITEMS_PER_THREAD = ((((((5) * 4) / sizeof(T)) > (1)) ? ((5) * 4) / sizeof(T) : (1)) < (5)) ? ((((5) * 4) / sizeof(T)) > (1)) ? ((5) * 4) / sizeof(T) : (1) : (5)
# 178
}; 
# 187
typedef BlockSelectSweepPolicy< 256, (ITEMS_PER_THREAD), BLOCK_LOAD_WARP_TRANSPOSE, LOAD_DEFAULT, true, BLOCK_SCAN_RAKING_MEMOIZE>  RangeSelectPolicy; 
# 188
}; 
# 191
struct Policy200 { 
# 193
enum { 
# 194
NOMINAL_4B_ITEMS_PER_THREAD = KEEP_REJECTS ? 7 : 15, 
# 195
ITEMS_PER_THREAD = ((((((KEEP_REJECTS ? 7 : 15) * 4) / sizeof(T)) > (1)) ? ((KEEP_REJECTS ? 7 : 15) * 4) / sizeof(T) : (1)) < (KEEP_REJECTS ? 7 : 15)) ? ((((KEEP_REJECTS ? 7 : 15) * 4) / sizeof(T)) > (1)) ? ((KEEP_REJECTS ? 7 : 15) * 4) / sizeof(T) : (1) : (KEEP_REJECTS ? 7 : 15)
# 196
}; 
# 205
typedef BlockSelectSweepPolicy< 128, (ITEMS_PER_THREAD), BLOCK_LOAD_WARP_TRANSPOSE, LOAD_DEFAULT, false, BLOCK_SCAN_WARP_SCANS>  RangeSelectPolicy; 
# 206
}; 
# 209
struct Policy130 { 
# 211
enum { 
# 212
NOMINAL_4B_ITEMS_PER_THREAD = 9, 
# 213
ITEMS_PER_THREAD = ((((((9) * 4) / sizeof(T)) > (1)) ? ((9) * 4) / sizeof(T) : (1)) < (9)) ? ((((9) * 4) / sizeof(T)) > (1)) ? ((9) * 4) / sizeof(T) : (1) : (9)
# 214
}; 
# 223
typedef BlockSelectSweepPolicy< 64, (ITEMS_PER_THREAD), BLOCK_LOAD_WARP_TRANSPOSE, LOAD_DEFAULT, true, BLOCK_SCAN_RAKING_MEMOIZE>  RangeSelectPolicy; 
# 224
}; 
# 227
struct Policy100 { 
# 229
enum { 
# 230
NOMINAL_4B_ITEMS_PER_THREAD = 9, 
# 231
ITEMS_PER_THREAD = ((((((9) * 4) / sizeof(T)) > (1)) ? ((9) * 4) / sizeof(T) : (1)) < (9)) ? ((((9) * 4) / sizeof(T)) > (1)) ? ((9) * 4) / sizeof(T) : (1) : (9)
# 232
}; 
# 241
typedef BlockSelectSweepPolicy< 256, (ITEMS_PER_THREAD), BLOCK_LOAD_WARP_TRANSPOSE, LOAD_DEFAULT, true, BLOCK_SCAN_RAKING_MEMOIZE>  RangeSelectPolicy; 
# 242
}; 
# 262
typedef Policy100 PtxPolicy; 
# 267
struct PtxRangeSelectPolicy : public Policy100::RangeSelectPolicy { }; 
# 277
template< class KernelConfig> 
# 278
__attribute((always_inline)) static void 
# 279
InitConfigs(int 
# 280
ptx_version, KernelConfig &
# 281
device_select_sweep_config) 
# 282
{ 
# 291
if (ptx_version >= 350) 
# 292
{ 
# 293
(device_select_sweep_config.template Init< typename Policy350::RangeSelectPolicy> ()); 
# 294
} else { 
# 295
if (ptx_version >= 300) 
# 296
{ 
# 297
(device_select_sweep_config.template Init< typename Policy300::RangeSelectPolicy> ()); 
# 298
} else { 
# 299
if (ptx_version >= 200) 
# 300
{ 
# 301
(device_select_sweep_config.template Init< typename Policy200::RangeSelectPolicy> ()); 
# 302
} else { 
# 303
if (ptx_version >= 130) 
# 304
{ 
# 305
(device_select_sweep_config.template Init< typename Policy130::RangeSelectPolicy> ()); 
# 306
} else 
# 308
{ 
# 309
(device_select_sweep_config.template Init< typename Policy100::RangeSelectPolicy> ()); 
# 310
}  }  }  }  
# 313
} 
# 319
struct KernelConfig { 
# 321
int block_threads; 
# 322
int items_per_thread; 
# 323
BlockLoadAlgorithm load_policy; 
# 324
bool store_warp_time_slicing; 
# 325
BlockScanAlgorithm scan_algorithm; 
# 327
template< class BlockSelectSweepPolicy> 
# 328
__attribute((always_inline)) void 
# 329
Init() 
# 330
{ 
# 331
(block_threads) = BlockSelectSweepPolicy::BLOCK_THREADS; 
# 332
(items_per_thread) = BlockSelectSweepPolicy::ITEMS_PER_THREAD; 
# 333
(load_policy) = BlockSelectSweepPolicy::LOAD_ALGORITHM; 
# 334
(store_warp_time_slicing) = BlockSelectSweepPolicy::STORE_WARP_TIME_SLICING; 
# 335
(scan_algorithm) = BlockSelectSweepPolicy::SCAN_ALGORITHM; 
# 336
} 
# 338
__attribute((always_inline)) void 
# 339
Print() 
# 340
{ 
# 341
printf("%d, %d, %d, %d, %d", block_threads, items_per_thread, load_policy, store_warp_time_slicing, scan_algorithm); 
# 347
} 
# 348
}; 
# 359
template< class 
# 360
DeviceScanInitKernelPtr, class 
# 361
DeviceSelectSweepKernelPtr> 
# 362
__attribute((always_inline)) static cudaError_t 
# 363
Dispatch(void *
# 364
d_temp_storage, size_t &
# 365
temp_storage_bytes, InputIterator 
# 366
d_in, FlagsInputIterator 
# 367
d_flags, SelectedOutputIterator 
# 368
d_selected_out, NumSelectedIterator 
# 369
d_num_selected_out, SelectOp 
# 370
select_op, EqualityOp 
# 371
equality_op, Offset 
# 372
num_items, cudaStream_t 
# 373
stream, bool 
# 374
debug_synchronous, int 
# 375
ptx_version, DeviceScanInitKernelPtr 
# 376
device_scan_init_kernel, DeviceSelectSweepKernelPtr 
# 377
device_select_sweep_kernel, KernelConfig 
# 378
device_select_sweep_config) 
# 379
{ 
# 388
cudaError error = cudaSuccess; 
# 389
do 
# 390
{ 
# 392
int device_ordinal; 
# 393
if (cub_::Debug(error = cudaGetDevice(&device_ordinal), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_select_dispatch.cuh", 393)) { break; }  
# 396
int sm_version; 
# 397
if (cub_::Debug(error = SmVersion(sm_version, device_ordinal), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_select_dispatch.cuh", 397)) { break; }  
# 400
int sm_count; 
# 401
if (cub_::Debug(error = cudaDeviceGetAttribute(&sm_count, cudaDevAttrMultiProcessorCount, device_ordinal), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_select_dispatch.cuh", 401)) { break; }  
# 404
int tile_size = (device_select_sweep_config.block_threads) * (device_select_sweep_config.items_per_thread); 
# 405
int num_tiles = ((num_items + tile_size) - 1) / tile_size; 
# 408
size_t allocation_sizes[2]; 
# 409
if (cub_::Debug(error = ScanTileState::AllocationSize(num_tiles, (allocation_sizes)[0]), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_select_dispatch.cuh", 409)) { break; }  
# 410
((allocation_sizes)[1]) = GridQueue< int> ::AllocationSize(); 
# 413
void *allocations[2]; 
# 414
if (cub_::Debug(error = AliasTemporaries(d_temp_storage, temp_storage_bytes, allocations, allocation_sizes), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_select_dispatch.cuh", 414)) { break; }  
# 415
if (d_temp_storage == (__null)) 
# 416
{ 
# 418
return cudaSuccess; 
# 419
}  
# 422
ScanTileState tile_status; 
# 423
if (cub_::Debug(error = (tile_status.Init(num_tiles, (allocations)[0], (allocation_sizes)[0])), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_select_dispatch.cuh", 423)) { break; }  
# 426
GridQueue< int>  queue((allocations)[1]); 
# 429
int init_grid_size = ((num_tiles + (INIT_KERNEL_THREADS)) - 1) / (INIT_KERNEL_THREADS); 
# 430
if (debug_synchronous) { printf("Invoking device_scan_init_kernel<<<%d, %d, 0, %lld>>>()\n", init_grid_size, INIT_KERNEL_THREADS, (long long)stream); }  ; 
# 433
(cudaConfigureCall(init_grid_size, INIT_KERNEL_THREADS, 0, stream)) ? (void)0 : device_scan_init_kernel(queue, tile_status, num_tiles); 
# 439
if (cub_::Debug(error = cudaPeekAtLastError(), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_select_dispatch.cuh", 439)) { break; }  
# 442
if (debug_synchronous && (cub_::Debug(error = SyncStream(stream), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_select_dispatch.cuh", 442))) { break; }  
# 445
int range_select_sm_occupancy; 
# 446
if (cub_::Debug(error = MaxSmOccupancy(range_select_sm_occupancy, sm_version, device_select_sweep_kernel, (device_select_sweep_config.block_threads)), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_select_dispatch.cuh", 450)) { 
# 450
break; }  
# 453
dim3 select_grid_size; 
# 454
int max_dim_x = (32 * 1024); 
# 455
(select_grid_size.z) = (1); 
# 456
(select_grid_size.y) = (((num_tiles + max_dim_x) - 1) / max_dim_x); 
# 457
(select_grid_size.x) = ((max_dim_x < num_tiles) ? max_dim_x : num_tiles); 
# 460
if (debug_synchronous) { printf("Invoking device_select_sweep_kernel<<<{%d,%d,%d}, %d, 0, %lld>>>(), %d items per thread, %d SM occupancy\n", select_grid_size.x, select_grid_size.y, select_grid_size.z, (device_select_sweep_config.block_threads), (long long)stream, (device_select_sweep_config.items_per_thread), range_select_sm_occupancy); }  
# 461
; 
# 464
(cudaConfigureCall(select_grid_size, ((device_select_sweep_config.block_threads)), 0, stream)) ? (void)0 : device_select_sweep_kernel(d_in, d_flags, d_selected_out, d_num_selected_out, tile_status, select_op, equality_op, num_items, num_tiles, queue); 
# 477
if (cub_::Debug(error = cudaPeekAtLastError(), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_select_dispatch.cuh", 477)) { break; }  
# 480
if (debug_synchronous && (cub_::Debug(error = SyncStream(stream), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_select_dispatch.cuh", 480))) { break; }  
# 481
} 
# 482
while (0); 
# 484
return error; 
# 487
} 
# 493
__attribute((always_inline)) static cudaError_t 
# 494
Dispatch(void *
# 495
d_temp_storage, size_t &
# 496
temp_storage_bytes, InputIterator 
# 497
d_in, FlagsInputIterator 
# 498
d_flags, SelectedOutputIterator 
# 499
d_selected_out, NumSelectedIterator 
# 500
d_num_selected_out, SelectOp 
# 501
select_op, EqualityOp 
# 502
equality_op, Offset 
# 503
num_items, cudaStream_t 
# 504
stream, bool 
# 505
debug_synchronous) 
# 506
{ 
# 507
cudaError error = cudaSuccess; 
# 508
do 
# 509
{ 
# 511
int ptx_version; 
# 513
if (cub_::Debug(error = PtxVersion(ptx_version), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_select_dispatch.cuh", 513)) { break; }  
# 519
KernelConfig device_select_sweep_config; 
# 520
InitConfigs(ptx_version, device_select_sweep_config); 
# 523
if (cub_::Debug(error = Dispatch(d_temp_storage, temp_storage_bytes, d_in, d_flags, d_selected_out, d_num_selected_out, select_op, equality_op, num_items, stream, debug_synchronous, ptx_version, DeviceScanInitKernel< Offset, ScanTileState> , DeviceSelectSweepKernel< PtxRangeSelectPolicy, InputIterator, FlagsInputIterator, SelectedOutputIterator, NumSelectedIterator, ScanTileState, SelectOp, EqualityOp, Offset, KEEP_REJECTS> , device_select_sweep_config), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_select_dispatch.cuh", 538)) { 
# 538
break; }  
# 539
} 
# 540
while (0); 
# 542
return error; 
# 543
} 
# 544
}; 
# 547
}
# 548
}}}}
# 44 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/device_partition.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 47
namespace cub_ { 
# 73
struct DevicePartition { 
# 121
template< class 
# 122
InputIterator, class 
# 123
FlagIterator, class 
# 124
OutputIterator, class 
# 125
NumSelectedIterator> 
# 126
__attribute((always_inline)) static cudaError_t 
# 127
Flagged(void *
# 128
d_temp_storage, size_t &
# 129
temp_storage_bytes, InputIterator 
# 130
d_in, FlagIterator 
# 131
d_flags, OutputIterator 
# 132
d_out, NumSelectedIterator 
# 133
d_num_selected_out, int 
# 134
num_items, cudaStream_t 
# 135
stream = 0, bool 
# 136
debug_synchronous = false) 
# 137
{ 
# 138
typedef int Offset; 
# 139
typedef NullType SelectOp; 
# 140
typedef NullType EqualityOp; 
# 142
return DeviceSelectDispatch< InputIterator, FlagIterator, OutputIterator, NumSelectedIterator, NullType, NullType, int, true> ::Dispatch(d_temp_storage, temp_storage_bytes, d_in, d_flags, d_out, d_num_selected_out, SelectOp(), EqualityOp(), num_items, stream, debug_synchronous); 
# 154
} 
# 230
template< class 
# 231
InputIterator, class 
# 232
OutputIterator, class 
# 233
NumSelectedIterator, class 
# 234
SelectOp> 
# 235
__attribute((always_inline)) static cudaError_t 
# 236
If(void *
# 237
d_temp_storage, size_t &
# 238
temp_storage_bytes, InputIterator 
# 239
d_in, OutputIterator 
# 240
d_out, NumSelectedIterator 
# 241
d_num_selected_out, int 
# 242
num_items, SelectOp 
# 243
select_op, cudaStream_t 
# 244
stream = 0, bool 
# 245
debug_synchronous = false) 
# 246
{ 
# 247
typedef int Offset; 
# 248
typedef NullType *FlagIterator; 
# 249
typedef NullType EqualityOp; 
# 251
return DeviceSelectDispatch< InputIterator, NullType *, OutputIterator, NumSelectedIterator, SelectOp, NullType, int, true> ::Dispatch(d_temp_storage, temp_storage_bytes, d_in, __null, d_out, d_num_selected_out, select_op, EqualityOp(), num_items, stream, debug_synchronous); 
# 263
} 
# 265
}; 
# 272
}
# 273
}}}}
# 44 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_radix_sort_upsweep.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 47
namespace cub_ { 
# 56
template< int 
# 57
_BLOCK_THREADS, int 
# 58
_ITEMS_PER_THREAD, CacheLoadModifier 
# 59
_LOAD_MODIFIER, int 
# 60
_RADIX_BITS> 
# 61
struct BlockRadixSortUpsweepPolicy { 
# 64
enum { 
# 65
BLOCK_THREADS = _BLOCK_THREADS, 
# 66
ITEMS_PER_THREAD = _ITEMS_PER_THREAD, 
# 67
RADIX_BITS = _RADIX_BITS
# 68
}; 
# 70
static const CacheLoadModifier LOAD_MODIFIER = _LOAD_MODIFIER; 
# 71
}; 
# 81
template< class 
# 82
BlockRadixSortUpsweepPolicy, class 
# 83
Key, class 
# 84
Offset> 
# 85
struct BlockRadixSortUpsweep { 
# 92
typedef typename Traits< Key> ::UnsignedBits UnsignedBits; 
# 95
typedef unsigned char DigitCounter; 
# 98
typedef unsigned PackedCounter; 
# 100
static const CacheLoadModifier LOAD_MODIFIER = (BlockRadixSortUpsweepPolicy::LOAD_MODIFIER); 
# 103
enum { 
# 104
RADIX_BITS = BlockRadixSortUpsweepPolicy::RADIX_BITS, 
# 105
BLOCK_THREADS = BlockRadixSortUpsweepPolicy::BLOCK_THREADS, 
# 106
KEYS_PER_THREAD = BlockRadixSortUpsweepPolicy::ITEMS_PER_THREAD, 
# 108
RADIX_DIGITS = 1 << (BlockRadixSortUpsweepPolicy::RADIX_BITS), 
# 110
LOG_WARP_THREADS = 5, 
# 111
WARP_THREADS = 1 << (5), 
# 112
WARPS = (((BlockRadixSortUpsweepPolicy::BLOCK_THREADS) + (1 << (5))) - 1) / (1 << (5)), 
# 114
TILE_ITEMS = (BlockRadixSortUpsweepPolicy::BLOCK_THREADS) * (BlockRadixSortUpsweepPolicy::ITEMS_PER_THREAD), 
# 116
BYTES_PER_COUNTER = sizeof(DigitCounter), 
# 117
LOG_BYTES_PER_COUNTER = Log2< sizeof(unsigned char)> ::VALUE, 
# 119
PACKING_RATIO = sizeof(PackedCounter) / sizeof(DigitCounter), 
# 120
LOG_PACKING_RATIO = Log2< sizeof(unsigned) / sizeof(unsigned char)> ::VALUE, 
# 122
LOG_COUNTER_LANES = (((BlockRadixSortUpsweepPolicy::RADIX_BITS) - (Log2< sizeof(unsigned) / sizeof(unsigned char)> ::VALUE)) > 0) ? (BlockRadixSortUpsweepPolicy::RADIX_BITS) - (Log2< sizeof(unsigned) / sizeof(unsigned char)> ::VALUE) : 0, 
# 123
COUNTER_LANES = 1 << ((((BlockRadixSortUpsweepPolicy::RADIX_BITS) - (Log2< sizeof(unsigned) / sizeof(unsigned char)> ::VALUE)) > 0) ? (BlockRadixSortUpsweepPolicy::RADIX_BITS) - (Log2< sizeof(unsigned) / sizeof(unsigned char)> ::VALUE) : 0), 
# 129
LANES_PER_WARP = (((((1 << ((((BlockRadixSortUpsweepPolicy::RADIX_BITS) - (Log2< sizeof(unsigned) / sizeof(unsigned char)> ::VALUE)) > 0) ? (BlockRadixSortUpsweepPolicy::RADIX_BITS) - (Log2< sizeof(unsigned) / sizeof(unsigned char)> ::VALUE) : 0)) + ((((BlockRadixSortUpsweepPolicy::BLOCK_THREADS) + (1 << (5))) - 1) / (1 << (5)))) - 1) / ((((BlockRadixSortUpsweepPolicy::BLOCK_THREADS) + (1 << (5))) - 1) / (1 << (5)))) > 1) ? (((1 << ((((BlockRadixSortUpsweepPolicy::RADIX_BITS) - (Log2< sizeof(unsigned) / sizeof(unsigned char)> ::VALUE)) > 0) ? (BlockRadixSortUpsweepPolicy::RADIX_BITS) - (Log2< sizeof(unsigned) / sizeof(unsigned char)> ::VALUE) : 0)) + ((((BlockRadixSortUpsweepPolicy::BLOCK_THREADS) + (1 << (5))) - 1) / (1 << (5)))) - 1) / ((((BlockRadixSortUpsweepPolicy::BLOCK_THREADS) + (1 << (5))) - 1) / (1 << (5))) : 1, 
# 132
UNROLL_COUNT = ((255 / (BlockRadixSortUpsweepPolicy::ITEMS_PER_THREAD)) < 64) ? 255 / (BlockRadixSortUpsweepPolicy::ITEMS_PER_THREAD) : 64, 
# 133
UNROLLED_ELEMENTS = (((255 / (BlockRadixSortUpsweepPolicy::ITEMS_PER_THREAD)) < 64) ? 255 / (BlockRadixSortUpsweepPolicy::ITEMS_PER_THREAD) : 64) * ((BlockRadixSortUpsweepPolicy::BLOCK_THREADS) * (BlockRadixSortUpsweepPolicy::ITEMS_PER_THREAD))
# 134
}; 
# 138
typedef CacheModifiedInputIterator< LOAD_MODIFIER, typename Traits< Key> ::UnsignedBits, Offset>  KeysItr; 
# 143
struct _TempStorage { 
# 146
union { 
# 147
DigitCounter digit_counters[COUNTER_LANES][BLOCK_THREADS][PACKING_RATIO]; 
# 148
PackedCounter packed_counters[COUNTER_LANES][BLOCK_THREADS]; 
# 149
Offset digit_partials[RADIX_DIGITS][(WARP_THREADS) + 1]; 
# 150
}; 
# 151
}; 
# 155
struct TempStorage : public Uninitialized< _TempStorage>  { }; 
# 163
_TempStorage &temp_storage; 
# 166
Offset local_counts[LANES_PER_WARP][PACKING_RATIO]; 
# 169
KeysItr d_keys_in; 
# 172
int current_bit; 
# 175
int num_bits; 
# 184
template< int COUNT, int MAX> 
# 185
struct Iterate { 
# 188
__attribute((always_inline)) static void BucketKeys(BlockRadixSortUpsweep &
# 189
cta, UnsignedBits 
# 190
keys[]) 
# 191
{int volatile ___ = 1;(void)cta;(void)keys;
# 196
::exit(___);}
#if 0
# 191
{ 
# 192
cta.Bucket(keys[COUNT]); 
# 195
Iterate< COUNT + 1, MAX> ::BucketKeys(cta, keys); 
# 196
} 
#endif
# 197 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_radix_sort_upsweep.cuh"
}; 
# 200
template< int MAX> 
# 201
struct Iterate< MAX, MAX>  { 
# 204
__attribute((always_inline)) static void BucketKeys(BlockRadixSortUpsweep &cta, UnsignedBits keys[]) {int volatile ___ = 1;(void)cta;(void)keys;::exit(___);}
#if 0
# 204
{ } 
#endif
# 205 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_radix_sort_upsweep.cuh"
}; 
# 215
__attribute((always_inline)) void Bucket(UnsignedBits key) 
# 216
{int volatile ___ = 1;(void)key;
# 231
::exit(___);}
#if 0
# 216
{ 
# 218
UnsignedBits converted_key = Traits< Key> ::TwiddleIn(key); 
# 221
UnsignedBits digit = BFE(converted_key, current_bit, num_bits); 
# 224
UnsignedBits sub_counter = digit & ((PACKING_RATIO) - 1); 
# 227
UnsignedBits row_offset = digit >> (LOG_PACKING_RATIO); 
# 230
(((((temp_storage).digit_counters)[row_offset])[__device_builtin_variable_threadIdx.x])[sub_counter])++; 
# 231
} 
#endif
# 237 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_radix_sort_upsweep.cuh"
__attribute((always_inline)) void ResetDigitCounters() 
# 238
{int volatile ___ = 1;
# 244
::exit(___);}
#if 0
# 238
{ 
# 240
#pragma unroll
for (
# 240
int LANE = 0; LANE < (COUNTER_LANES); LANE++) 
# 241
{ 
# 242
((((temp_storage).packed_counters)[LANE])[__device_builtin_variable_threadIdx.x]) = 0; 
# 243
}  
# 244
} 
#endif
# 250 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_radix_sort_upsweep.cuh"
__attribute((always_inline)) void ResetUnpackedCounters() 
# 251
{int volatile ___ = 1;
# 261
::exit(___);}
#if 0
# 251
{ 
# 253
#pragma unroll
for (
# 253
int LANE = 0; LANE < (LANES_PER_WARP); LANE++) 
# 254
{ 
# 256
#pragma unroll
for (
# 256
int UNPACKED_COUNTER = 0; UNPACKED_COUNTER < (PACKING_RATIO); UNPACKED_COUNTER++) 
# 257
{ 
# 258
(((local_counts)[LANE])[UNPACKED_COUNTER]) = 0; 
# 259
}  
# 260
}  
# 261
} 
#endif
# 268 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_radix_sort_upsweep.cuh"
__attribute((always_inline)) void UnpackDigitCounts() 
# 269
{int volatile ___ = 1;
# 291
::exit(___);}
#if 0
# 269
{ 
# 270
unsigned warp_id = (__device_builtin_variable_threadIdx.x) >> (LOG_WARP_THREADS); 
# 271
unsigned warp_tid = (__device_builtin_variable_threadIdx.x) & ((WARP_THREADS) - 1); 
# 274
#pragma unroll
for (
# 274
int LANE = 0; LANE < (LANES_PER_WARP); LANE++) 
# 275
{ 
# 276
const int counter_lane = (LANE * (WARPS)) + warp_id; 
# 277
if (counter_lane < (COUNTER_LANES)) 
# 278
{ 
# 280
#pragma unroll
for (
# 280
int PACKED_COUNTER = 0; PACKED_COUNTER < (BLOCK_THREADS); PACKED_COUNTER += (WARP_THREADS)) 
# 281
{ 
# 283
#pragma unroll
for (
# 283
int UNPACKED_COUNTER = 0; UNPACKED_COUNTER < (PACKING_RATIO); UNPACKED_COUNTER++) 
# 284
{ 
# 285
Offset counter = ((((temp_storage).digit_counters)[counter_lane])[warp_tid + PACKED_COUNTER])[UNPACKED_COUNTER]; 
# 286
(((local_counts)[LANE])[UNPACKED_COUNTER]) += counter; 
# 287
}  
# 288
}  
# 289
}  
# 290
}  
# 291
} 
#endif
# 297 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_radix_sort_upsweep.cuh"
__attribute((always_inline)) void ReduceUnpackedCounts(Offset &bin_count) 
# 298
{int volatile ___ = 1;(void)bin_count;
# 329
::exit(___);}
#if 0
# 298
{ 
# 299
unsigned warp_id = (__device_builtin_variable_threadIdx.x) >> (LOG_WARP_THREADS); 
# 300
unsigned warp_tid = (__device_builtin_variable_threadIdx.x) & ((WARP_THREADS) - 1); 
# 304
#pragma unroll
for (
# 304
int LANE = 0; LANE < (LANES_PER_WARP); LANE++) 
# 305
{ 
# 306
int counter_lane = (LANE * (WARPS)) + warp_id; 
# 307
if (counter_lane < (COUNTER_LANES)) 
# 308
{ 
# 309
int digit_row = counter_lane << (LOG_PACKING_RATIO); 
# 312
#pragma unroll
for (
# 312
int UNPACKED_COUNTER = 0; UNPACKED_COUNTER < (PACKING_RATIO); UNPACKED_COUNTER++) 
# 313
{ 
# 314
((((temp_storage).digit_partials)[digit_row + UNPACKED_COUNTER])[warp_tid]) = (((local_counts)[LANE])[UNPACKED_COUNTER]); 
# 316
}  
# 317
}  
# 318
}  
# 320
__syncthreads(); 
# 323
if ((__device_builtin_variable_threadIdx.x) < (RADIX_DIGITS)) 
# 324
{ 
# 325
bin_count = ThreadReduce< WARP_THREADS> (((temp_storage).digit_partials)[__device_builtin_variable_threadIdx.x], Sum()); 
# 328
}  
# 329
} 
#endif
# 335 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_radix_sort_upsweep.cuh"
__attribute((always_inline)) void ProcessFullTile(Offset block_offset) 
# 336
{int volatile ___ = 1;(void)block_offset;
# 347
::exit(___);}
#if 0
# 336
{ 
# 338
UnsignedBits keys[KEYS_PER_THREAD]; 
# 340
LoadDirectStriped< BLOCK_THREADS> (__device_builtin_variable_threadIdx.x, (d_keys_in) + block_offset, keys); 
# 343
__syncthreads(); 
# 346
Iterate< 0, KEYS_PER_THREAD> ::BucketKeys(*this, keys); 
# 347
} 
#endif
# 353 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_radix_sort_upsweep.cuh"
__attribute((always_inline)) void ProcessPartialTile(Offset 
# 354
block_offset, const Offset &
# 355
block_end) 
# 356
{int volatile ___ = 1;(void)block_offset;(void)block_end;
# 366
::exit(___);}
#if 0
# 356
{ 
# 358
block_offset += (__device_builtin_variable_threadIdx.x); 
# 359
while (block_offset < block_end) 
# 360
{ 
# 362
UnsignedBits key = (d_keys_in)[block_offset]; 
# 363
Bucket(key); 
# 364
block_offset += (BLOCK_THREADS); 
# 365
}  
# 366
} 
#endif
# 376 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_radix_sort_upsweep.cuh"
__attribute((always_inline)) BlockRadixSortUpsweep(TempStorage &
# 377
temp_storage, Key *
# 378
d_keys_in, int 
# 379
current_bit, int 
# 380
num_bits) : temp_storage((temp_storage.Alias())), d_keys_in(reinterpret_cast< UnsignedBits *>(d_keys_in)), current_bit(current_bit), num_bits(num_bits) 
# 386
{int *volatile ___ = 0;(void)temp_storage;(void)d_keys_in;(void)current_bit;(void)num_bits;::free(___);}
#if 0
# 386
{ } 
#endif
# 392 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_radix_sort_upsweep.cuh"
__attribute((always_inline)) void ProcessRegion(Offset 
# 393
block_offset, const Offset &
# 394
block_end, Offset &
# 395
bin_count) 
# 396
{int volatile ___ = 1;(void)block_offset;(void)block_end;(void)bin_count;
# 442
::exit(___);}
#if 0
# 396
{ 
# 398
ResetDigitCounters(); 
# 399
ResetUnpackedCounters(); 
# 402
while ((block_offset + (UNROLLED_ELEMENTS)) <= block_end) 
# 403
{ 
# 404
for (int i = 0; i < (UNROLL_COUNT); ++i) 
# 405
{ 
# 406
ProcessFullTile(block_offset); 
# 407
block_offset += (TILE_ITEMS); 
# 408
}  
# 410
__syncthreads(); 
# 413
UnpackDigitCounts(); 
# 415
__syncthreads(); 
# 418
ResetDigitCounters(); 
# 419
}  
# 422
while ((block_offset + (TILE_ITEMS)) <= block_end) 
# 423
{ 
# 424
ProcessFullTile(block_offset); 
# 425
block_offset += (TILE_ITEMS); 
# 426
}  
# 429
ProcessPartialTile(block_offset, block_end); 
# 433
__syncthreads(); 
# 436
UnpackDigitCounts(); 
# 438
__syncthreads(); 
# 441
ReduceUnpackedCounts(bin_count); 
# 442
} 
#endif
# 444 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_radix_sort_upsweep.cuh"
}; 
# 447
}
# 448
}}}}
# 47 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_radix_sort_downsweep.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 50
namespace cub_ { 
# 60
enum RadixSortScatterAlgorithm { 
# 62
RADIX_SORT_SCATTER_DIRECT, 
# 63
RADIX_SORT_SCATTER_TWO_PHASE
# 64
}; 
# 70
template< int 
# 71
_BLOCK_THREADS, int 
# 72
_ITEMS_PER_THREAD, BlockLoadAlgorithm 
# 73
_LOAD_ALGORITHM, CacheLoadModifier 
# 74
_LOAD_MODIFIER, bool 
# 75
_EXCHANGE_TIME_SLICING, bool 
# 76
_MEMOIZE_OUTER_SCAN, BlockScanAlgorithm 
# 77
_INNER_SCAN_ALGORITHM, RadixSortScatterAlgorithm 
# 78
_SCATTER_ALGORITHM, cudaSharedMemConfig 
# 79
_SMEM_CONFIG, int 
# 80
_RADIX_BITS> 
# 81
struct BlockRadixSortDownsweepPolicy { 
# 84
enum { 
# 85
BLOCK_THREADS = _BLOCK_THREADS, 
# 86
ITEMS_PER_THREAD = _ITEMS_PER_THREAD, 
# 87
EXCHANGE_TIME_SLICING = _EXCHANGE_TIME_SLICING, 
# 88
RADIX_BITS = _RADIX_BITS, 
# 89
MEMOIZE_OUTER_SCAN = _MEMOIZE_OUTER_SCAN
# 90
}; 
# 92
static const BlockLoadAlgorithm LOAD_ALGORITHM = _LOAD_ALGORITHM; 
# 93
static const CacheLoadModifier LOAD_MODIFIER = _LOAD_MODIFIER; 
# 94
static const BlockScanAlgorithm INNER_SCAN_ALGORITHM = _INNER_SCAN_ALGORITHM; 
# 95
static const RadixSortScatterAlgorithm SCATTER_ALGORITHM = _SCATTER_ALGORITHM; 
# 96
static const cudaSharedMemConfig SMEM_CONFIG = _SMEM_CONFIG; 
# 97
}; 
# 107
template< class 
# 108
BlockRadixSortDownsweepPolicy, bool 
# 109
DESCENDING, class 
# 110
Key, class 
# 111
Value, class 
# 112
Offset> 
# 113
struct BlockRadixSortDownsweep { 
# 120
typedef typename Traits< Key> ::UnsignedBits UnsignedBits; 
# 122
static const UnsignedBits MIN_KEY = (Traits< Key> ::MIN_KEY); 
# 123
static const UnsignedBits MAX_KEY = (Traits< Key> ::MAX_KEY); 
# 125
static const BlockLoadAlgorithm LOAD_ALGORITHM = (BlockRadixSortDownsweepPolicy::LOAD_ALGORITHM); 
# 126
static const CacheLoadModifier LOAD_MODIFIER = (BlockRadixSortDownsweepPolicy::LOAD_MODIFIER); 
# 127
static const BlockScanAlgorithm INNER_SCAN_ALGORITHM = (BlockRadixSortDownsweepPolicy::INNER_SCAN_ALGORITHM); 
# 128
static const RadixSortScatterAlgorithm SCATTER_ALGORITHM = (BlockRadixSortDownsweepPolicy::SCATTER_ALGORITHM); 
# 129
static const cudaSharedMemConfig SMEM_CONFIG = (BlockRadixSortDownsweepPolicy::SMEM_CONFIG); 
# 132
enum { 
# 133
BLOCK_THREADS = BlockRadixSortDownsweepPolicy::BLOCK_THREADS, 
# 134
ITEMS_PER_THREAD = BlockRadixSortDownsweepPolicy::ITEMS_PER_THREAD, 
# 135
EXCHANGE_TIME_SLICING = BlockRadixSortDownsweepPolicy::EXCHANGE_TIME_SLICING, 
# 136
RADIX_BITS = BlockRadixSortDownsweepPolicy::RADIX_BITS, 
# 137
MEMOIZE_OUTER_SCAN = BlockRadixSortDownsweepPolicy::MEMOIZE_OUTER_SCAN, 
# 138
TILE_ITEMS = (BlockRadixSortDownsweepPolicy::BLOCK_THREADS) * (BlockRadixSortDownsweepPolicy::ITEMS_PER_THREAD), 
# 140
RADIX_DIGITS = 1 << (BlockRadixSortDownsweepPolicy::RADIX_BITS), 
# 141
KEYS_ONLY = Equals< Value, NullType> ::VALUE, 
# 143
WARP_THREADS = 5, 
# 144
WARPS = (((BlockRadixSortDownsweepPolicy::BLOCK_THREADS) + (5)) - 1) / (5), 
# 146
BYTES_PER_SIZET = sizeof(Offset), 
# 147
LOG_BYTES_PER_SIZET = Log2< sizeof(Offset)> ::VALUE, 
# 149
LOG_SMEM_BANKS = (0 >= 200) ? 5 : 4, 
# 150
SMEM_BANKS = 1 << ((0 >= 200) ? 5 : 4), 
# 152
DIGITS_PER_SCATTER_PASS = (BlockRadixSortDownsweepPolicy::BLOCK_THREADS) / (1 << ((0 >= 200) ? 5 : 4)), 
# 153
SCATTER_PASSES = (1 << (BlockRadixSortDownsweepPolicy::RADIX_BITS)) / ((BlockRadixSortDownsweepPolicy::BLOCK_THREADS) / (1 << ((0 >= 200) ? 5 : 4))), 
# 155
LOG_STORE_TXN_THREADS = (0 >= 200) ? 5 : 4, 
# 156
STORE_TXN_THREADS = 1 << ((0 >= 200) ? 5 : 4)
# 157
}; 
# 160
typedef CacheModifiedInputIterator< LOAD_MODIFIER, typename Traits< Key> ::UnsignedBits, Offset>  KeysItr; 
# 161
typedef CacheModifiedInputIterator< LOAD_MODIFIER, Value, Offset>  ValuesItr; 
# 170
typedef cub_::BlockRadixRank< BLOCK_THREADS, RADIX_BITS, DESCENDING, MEMOIZE_OUTER_SCAN, INNER_SCAN_ALGORITHM, SMEM_CONFIG>  BlockRadixRank; 
# 178
typedef BlockLoad< CacheModifiedInputIterator< LOAD_MODIFIER, typename Traits< Key> ::UnsignedBits, Offset> , BLOCK_THREADS, ITEMS_PER_THREAD, LOAD_ALGORITHM, EXCHANGE_TIME_SLICING>  BlockLoadKeys; 
# 186
typedef BlockLoad< CacheModifiedInputIterator< LOAD_MODIFIER, Value, Offset> , BLOCK_THREADS, ITEMS_PER_THREAD, LOAD_ALGORITHM, EXCHANGE_TIME_SLICING>  BlockLoadValues; 
# 193
typedef BlockExchange< typename Traits< Key> ::UnsignedBits, BLOCK_THREADS, ITEMS_PER_THREAD, EXCHANGE_TIME_SLICING>  BlockExchangeKeys; 
# 200
typedef BlockExchange< Value, BLOCK_THREADS, ITEMS_PER_THREAD, EXCHANGE_TIME_SLICING>  BlockExchangeValues; 
# 206
struct _TempStorage { 
# 208
Offset relative_bin_offsets[(RADIX_DIGITS) + 1]; 
# 209
bool short_circuit; 
# 212
union { 
# 213
typename cub_::BlockRadixRank< BLOCK_THREADS, RADIX_BITS, DESCENDING, MEMOIZE_OUTER_SCAN, INNER_SCAN_ALGORITHM, SMEM_CONFIG> ::TempStorage ranking; 
# 214
typename BlockLoad< CacheModifiedInputIterator< LOAD_MODIFIER, typename Traits< Key> ::UnsignedBits, Offset> , BLOCK_THREADS, ITEMS_PER_THREAD, LOAD_ALGORITHM, EXCHANGE_TIME_SLICING> ::TempStorage load_keys; 
# 215
typename BlockLoad< CacheModifiedInputIterator< LOAD_MODIFIER, Value, Offset> , BLOCK_THREADS, ITEMS_PER_THREAD, LOAD_ALGORITHM, EXCHANGE_TIME_SLICING> ::TempStorage load_values; 
# 216
typename BlockExchange< typename Traits< Key> ::UnsignedBits, BLOCK_THREADS, ITEMS_PER_THREAD, EXCHANGE_TIME_SLICING> ::TempStorage exchange_keys; 
# 217
typename BlockExchange< Value, BLOCK_THREADS, ITEMS_PER_THREAD, EXCHANGE_TIME_SLICING> ::TempStorage exchange_values; 
# 218
}; 
# 219
}; 
# 223
struct TempStorage : public Uninitialized< _TempStorage>  { }; 
# 231
_TempStorage &temp_storage; 
# 234
KeysItr d_keys_in; 
# 235
ValuesItr d_values_in; 
# 236
UnsignedBits *d_keys_out; 
# 237
Value *d_values_out; 
# 240
Offset bin_offset; 
# 243
int current_bit; 
# 246
int num_bits; 
# 249
bool short_circuit; 
# 260
__attribute((always_inline)) void DecodeRelativeBinOffsets(UnsignedBits (&
# 261
twiddled_keys)[ITEMS_PER_THREAD], Offset (&
# 262
relative_bin_offsets)[ITEMS_PER_THREAD]) 
# 263
{int volatile ___ = 1;(void)twiddled_keys;(void)relative_bin_offsets;
# 272
::exit(___);}
#if 0
# 263
{ 
# 265
#pragma unroll
for (
# 265
int KEY = 0; KEY < (ITEMS_PER_THREAD); KEY++) 
# 266
{ 
# 267
UnsignedBits digit = BFE((twiddled_keys)[KEY], current_bit, num_bits); 
# 270
((relative_bin_offsets)[KEY]) = (((temp_storage).relative_bin_offsets)[digit]); 
# 271
}  
# 272
} 
#endif
# 278 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_radix_sort_downsweep.cuh"
template< bool FULL_TILE, class T> 
# 279
__attribute((always_inline)) void ScatterItems(T (&
# 280
items)[ITEMS_PER_THREAD], int (&
# 281
local_ranks)[ITEMS_PER_THREAD], Offset (&
# 282
relative_bin_offsets)[ITEMS_PER_THREAD], T *
# 283
d_out, Offset 
# 284
valid_items) 
# 285
{int volatile ___ = 1;(void)items;(void)local_ranks;(void)relative_bin_offsets;(void)d_out;(void)valid_items;
# 295
::exit(___);}
#if 0
# 285
{ 
# 287
#pragma unroll
for (
# 287
int ITEM = 0; ITEM < (ITEMS_PER_THREAD); ++ITEM) 
# 288
{ 
# 290
if (FULL_TILE || (((local_ranks)[ITEM]) < valid_items)) 
# 291
{ 
# 292
(d_out[((relative_bin_offsets)[ITEM]) + ((local_ranks)[ITEM])]) = ((items)[ITEM]); 
# 293
}  
# 294
}  
# 295
} 
#endif
# 301 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_radix_sort_downsweep.cuh"
template< bool FULL_TILE> 
# 302
__attribute((always_inline)) void ScatterKeys(UnsignedBits (&
# 303
twiddled_keys)[ITEMS_PER_THREAD], Offset (&
# 304
relative_bin_offsets)[ITEMS_PER_THREAD], int (&
# 305
ranks)[ITEMS_PER_THREAD], Offset 
# 306
valid_items, Int2Type< 0>  
# 307
scatter_algorithm) 
# 308
{int volatile ___ = 1;(void)twiddled_keys;(void)relative_bin_offsets;(void)ranks;(void)valid_items;(void)scatter_algorithm;
# 323
::exit(___);}
#if 0
# 308
{ 
# 310
DecodeRelativeBinOffsets(twiddled_keys, relative_bin_offsets); 
# 313
UnsignedBits keys[ITEMS_PER_THREAD]; 
# 316
#pragma unroll
for (
# 316
int KEY = 0; KEY < (ITEMS_PER_THREAD); KEY++) 
# 317
{ 
# 318
((keys)[KEY]) = Traits< Key> ::TwiddleOut((twiddled_keys)[KEY]); 
# 319
}  
# 322
ScatterItems< FULL_TILE> (keys, ranks, relative_bin_offsets, d_keys_out, valid_items); 
# 323
} 
#endif
# 329 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_radix_sort_downsweep.cuh"
template< bool FULL_TILE> 
# 330
__attribute((always_inline)) void ScatterKeys(UnsignedBits (&
# 331
twiddled_keys)[ITEMS_PER_THREAD], Offset (&
# 332
relative_bin_offsets)[ITEMS_PER_THREAD], int (&
# 333
ranks)[ITEMS_PER_THREAD], Offset 
# 334
valid_items, Int2Type< 1>  
# 335
scatter_algorithm) 
# 336
{int volatile ___ = 1;(void)twiddled_keys;(void)relative_bin_offsets;(void)ranks;(void)valid_items;(void)scatter_algorithm;
# 356
::exit(___);}
#if 0
# 336
{ 
# 338
(((BlockExchangeKeys)(((temp_storage).exchange_keys))).ScatterToStriped(twiddled_keys, ranks)); 
# 341
int local_ranks[ITEMS_PER_THREAD]; 
# 344
#pragma unroll
for (
# 344
int ITEM = 0; ITEM < (ITEMS_PER_THREAD); ++ITEM) 
# 345
{ 
# 346
((local_ranks)[ITEM]) = ((__device_builtin_variable_threadIdx.x) + (ITEM * (BLOCK_THREADS))); 
# 347
}  
# 350
ScatterKeys< FULL_TILE> (twiddled_keys, relative_bin_offsets, local_ranks, valid_items, Int2Type< 0> ()); 
# 356
} 
#endif
# 362 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_radix_sort_downsweep.cuh"
template< bool FULL_TILE> 
# 363
__attribute((always_inline)) void ScatterValues(Value (&
# 364
values)[ITEMS_PER_THREAD], Offset (&
# 365
relative_bin_offsets)[ITEMS_PER_THREAD], int (&
# 366
ranks)[ITEMS_PER_THREAD], Offset 
# 367
valid_items, Int2Type< 0>  
# 368
scatter_algorithm) 
# 369
{int volatile ___ = 1;(void)values;(void)relative_bin_offsets;(void)ranks;(void)valid_items;(void)scatter_algorithm;
# 372
::exit(___);}
#if 0
# 369
{ 
# 371
ScatterItems< FULL_TILE> (values, ranks, relative_bin_offsets, d_values_out, valid_items); 
# 372
} 
#endif
# 378 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_radix_sort_downsweep.cuh"
template< bool FULL_TILE> 
# 379
__attribute((always_inline)) void ScatterValues(Value (&
# 380
values)[ITEMS_PER_THREAD], Offset (&
# 381
relative_bin_offsets)[ITEMS_PER_THREAD], int (&
# 382
ranks)[ITEMS_PER_THREAD], Offset 
# 383
valid_items, Int2Type< 1>  
# 384
scatter_algorithm) 
# 385
{int volatile ___ = 1;(void)values;(void)relative_bin_offsets;(void)ranks;(void)valid_items;(void)scatter_algorithm;
# 407
::exit(___);}
#if 0
# 385
{ 
# 386
__syncthreads(); 
# 389
(((BlockExchangeValues)(((temp_storage).exchange_values))).ScatterToStriped(values, ranks)); 
# 392
int local_ranks[ITEMS_PER_THREAD]; 
# 395
#pragma unroll
for (
# 395
int ITEM = 0; ITEM < (ITEMS_PER_THREAD); ++ITEM) 
# 396
{ 
# 397
((local_ranks)[ITEM]) = ((__device_builtin_variable_threadIdx.x) + (ITEM * (BLOCK_THREADS))); 
# 398
}  
# 401
ScatterValues< FULL_TILE> (values, relative_bin_offsets, local_ranks, valid_items, Int2Type< 0> ()); 
# 407
} 
#endif
# 413 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_radix_sort_downsweep.cuh"
template< class BlockLoadT, class T, class InputIterator> 
# 414
__attribute((always_inline)) void LoadItems(BlockLoadT &
# 415
block_loader, T (&
# 416
items)[ITEMS_PER_THREAD], InputIterator 
# 417
d_in, Offset 
# 418
valid_items, Int2Type< 1>  
# 419
is_full_tile) 
# 420
{int volatile ___ = 1;(void)block_loader;(void)items;(void)d_in;(void)valid_items;(void)is_full_tile;
# 422
::exit(___);}
#if 0
# 420
{ 
# 421
(block_loader.Load(d_in, items)); 
# 422
} 
#endif
# 428 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_radix_sort_downsweep.cuh"
template< class BlockLoadT, class T, class InputIterator> 
# 429
__attribute((always_inline)) void LoadItems(BlockLoadT &
# 430
block_loader, T (&
# 431
items)[ITEMS_PER_THREAD], InputIterator 
# 432
d_in, Offset 
# 433
valid_items, Int2Type< 0>  
# 434
is_full_tile) 
# 435
{int volatile ___ = 1;(void)block_loader;(void)items;(void)d_in;(void)valid_items;(void)is_full_tile;
# 437
::exit(___);}
#if 0
# 435
{ 
# 436
(block_loader.Load(d_in, items, valid_items)); 
# 437
} 
#endif
# 443 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_radix_sort_downsweep.cuh"
template< bool FULL_TILE, class _Value> 
# 444
__attribute((always_inline)) void GatherScatterValues(_Value (&
# 445
values)[ITEMS_PER_THREAD], Offset (&
# 446
relative_bin_offsets)[ITEMS_PER_THREAD], int (&
# 447
ranks)[ITEMS_PER_THREAD], Offset 
# 448
block_offset, Offset 
# 449
valid_items) 
# 450
{int volatile ___ = 1;(void)values;(void)relative_bin_offsets;(void)ranks;(void)block_offset;(void)valid_items;
# 467
::exit(___);}
#if 0
# 450
{ 
# 451
__syncthreads(); 
# 453
BlockLoadValues loader(((temp_storage).load_values)); 
# 454
LoadItems(loader, values, (d_values_in) + block_offset, valid_items, Int2Type< FULL_TILE> ()); 
# 461
ScatterValues< FULL_TILE> (values, relative_bin_offsets, ranks, valid_items, Int2Type< SCATTER_ALGORITHM> ()); 
# 467
} 
#endif
# 473 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_radix_sort_downsweep.cuh"
template< bool FULL_TILE> 
# 474
__attribute((always_inline)) void GatherScatterValues(NullType (&
# 475
values)[ITEMS_PER_THREAD], Offset (&
# 476
relative_bin_offsets)[ITEMS_PER_THREAD], int (&
# 477
ranks)[ITEMS_PER_THREAD], Offset 
# 478
block_offset, Offset 
# 479
valid_items) 
# 480
{int volatile ___ = 1;(void)values;(void)relative_bin_offsets;(void)ranks;(void)block_offset;(void)valid_items;::exit(___);}
#if 0
# 480
{ } 
#endif
# 486 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_radix_sort_downsweep.cuh"
template< bool FULL_TILE> 
# 487
__attribute((always_inline)) void ProcessTile(Offset 
# 488
block_offset, const Offset &
# 489
valid_items = TILE_ITEMS) 
# 490
{int volatile ___ = 1;(void)block_offset;(void)valid_items;
# 579
::exit(___);}
#if 0
# 490
{ 
# 492
UnsignedBits keys[ITEMS_PER_THREAD]; 
# 493
UnsignedBits twiddled_keys[ITEMS_PER_THREAD]; 
# 494
int ranks[ITEMS_PER_THREAD]; 
# 495
Offset relative_bin_offsets[ITEMS_PER_THREAD]; 
# 499
#pragma unroll
for (
# 499
int ITEM = 0; ITEM < (ITEMS_PER_THREAD); ++ITEM) 
# 500
{ 
# 501
((keys)[ITEM]) = (DESCENDING ? MIN_KEY : MAX_KEY); 
# 502
}  
# 505
BlockLoadKeys loader(((temp_storage).load_keys)); 
# 506
LoadItems(loader, keys, (d_keys_in) + block_offset, valid_items, Int2Type< FULL_TILE> ()); 
# 513
__syncthreads(); 
# 517
#pragma unroll
for (
# 517
int KEY = 0; KEY < (ITEMS_PER_THREAD); KEY++) 
# 518
{ 
# 519
((twiddled_keys)[KEY]) = Traits< Key> ::TwiddleIn((keys)[KEY]); 
# 520
}  
# 523
int inclusive_digit_prefix; 
# 524
(((BlockRadixRank)(((temp_storage).ranking))).RankKeys(twiddled_keys, ranks, current_bit, num_bits, inclusive_digit_prefix)); 
# 532
if (((BLOCK_THREADS) == (RADIX_DIGITS)) || ((__device_builtin_variable_threadIdx.x) < (RADIX_DIGITS))) 
# 533
{ 
# 534
int exclusive_digit_prefix; 
# 537
if (DESCENDING) 
# 538
{ 
# 545
volatile int *exchange = reinterpret_cast< int *>((temp_storage).relative_bin_offsets); 
# 546
(exchange[(__device_builtin_variable_threadIdx.x) + (1)]) = 0; 
# 547
(exchange[__device_builtin_variable_threadIdx.x]) = inclusive_digit_prefix; 
# 548
exclusive_digit_prefix = (exchange[(__device_builtin_variable_threadIdx.x) + (1)]); 
# 550
} else 
# 552
{ 
# 559
volatile int *exchange = reinterpret_cast< int *>((temp_storage).relative_bin_offsets); 
# 560
(exchange[__device_builtin_variable_threadIdx.x]) = 0; 
# 561
(exchange[(__device_builtin_variable_threadIdx.x) + (1)]) = inclusive_digit_prefix; 
# 562
exclusive_digit_prefix = (exchange[__device_builtin_variable_threadIdx.x]); 
# 564
}  
# 566
(bin_offset) -= exclusive_digit_prefix; 
# 567
(((temp_storage).relative_bin_offsets)[__device_builtin_variable_threadIdx.x]) = (bin_offset); 
# 568
(bin_offset) += inclusive_digit_prefix; 
# 569
}  
# 571
__syncthreads(); 
# 574
ScatterKeys< FULL_TILE> (twiddled_keys, relative_bin_offsets, ranks, valid_items, Int2Type< SCATTER_ALGORITHM> ()); 
# 577
Value values[ITEMS_PER_THREAD]; 
# 578
GatherScatterValues< FULL_TILE> (values, relative_bin_offsets, ranks, block_offset, valid_items); 
# 579
} 
#endif
# 585 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_radix_sort_downsweep.cuh"
template< class 
# 586
InputIterator, class 
# 587
T> 
# 588
__attribute((always_inline)) void Copy(InputIterator 
# 589
d_in, T *
# 590
d_out, Offset 
# 591
block_offset, Offset 
# 592
block_end) 
# 593
{int volatile ___ = 1;(void)d_in;(void)d_out;(void)block_offset;(void)block_end;
# 617
::exit(___);}
#if 0
# 593
{ 
# 595
while ((block_offset + (TILE_ITEMS)) <= block_end) 
# 596
{ 
# 597
T items[ITEMS_PER_THREAD]; 
# 599
LoadDirectStriped< BLOCK_THREADS> (__device_builtin_variable_threadIdx.x, d_in + block_offset, items); 
# 600
__syncthreads(); 
# 601
StoreDirectStriped< BLOCK_THREADS> (__device_builtin_variable_threadIdx.x, d_out + block_offset, items); 
# 603
block_offset += (TILE_ITEMS); 
# 604
}  
# 607
if (block_offset < block_end) 
# 608
{ 
# 609
Offset valid_items = block_end - block_offset; 
# 611
T items[ITEMS_PER_THREAD]; 
# 613
LoadDirectStriped< BLOCK_THREADS> (__device_builtin_variable_threadIdx.x, d_in + block_offset, items, valid_items); 
# 614
__syncthreads(); 
# 615
StoreDirectStriped< BLOCK_THREADS> (__device_builtin_variable_threadIdx.x, d_out + block_offset, items, valid_items); 
# 616
}  
# 617
} 
#endif
# 623 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_radix_sort_downsweep.cuh"
template< class InputIterator> 
# 624
__attribute((always_inline)) void Copy(InputIterator 
# 625
d_in, NullType *
# 626
d_out, Offset 
# 627
block_offset, Offset 
# 628
block_end) 
# 629
{int volatile ___ = 1;(void)d_in;(void)d_out;(void)block_offset;(void)block_end;::exit(___);}
#if 0
# 629
{ } 
#endif
# 639 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_radix_sort_downsweep.cuh"
__attribute((always_inline)) BlockRadixSortDownsweep(TempStorage &
# 640
temp_storage, Offset 
# 641
bin_offset, Key *
# 642
d_keys_in, Key *
# 643
d_keys_out, Value *
# 644
d_values_in, Value *
# 645
d_values_out, int 
# 646
current_bit, int 
# 647
num_bits) : temp_storage((temp_storage.Alias())), d_keys_in(reinterpret_cast< UnsignedBits *>(d_keys_in)), d_values_in(d_values_in), d_keys_out(reinterpret_cast< UnsignedBits *>(d_keys_out)), d_values_out(d_values_out), bin_offset(bin_offset), current_bit(current_bit), num_bits(num_bits), short_circuit(false) 
# 658
{int *volatile ___ = 0;(void)temp_storage;(void)bin_offset;(void)d_keys_in;(void)d_keys_out;(void)d_values_in;(void)d_values_out;(void)current_bit;(void)num_bits;::free(___);}
#if 0
# 658
{ } 
#endif
# 664 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_radix_sort_downsweep.cuh"
__attribute((always_inline)) BlockRadixSortDownsweep(TempStorage &
# 665
temp_storage, Offset 
# 666
num_items, Offset *
# 667
d_spine, Key *
# 668
d_keys_in, Key *
# 669
d_keys_out, Value *
# 670
d_values_in, Value *
# 671
d_values_out, int 
# 672
current_bit, int 
# 673
num_bits) : temp_storage((temp_storage.Alias())), d_keys_in(reinterpret_cast< UnsignedBits *>(d_keys_in)), d_values_in(d_values_in), d_keys_out(reinterpret_cast< UnsignedBits *>(d_keys_out)), d_values_out(d_values_out), current_bit(current_bit), num_bits(num_bits) 
# 682
{int *volatile ___ = 0;(void)temp_storage;(void)num_items;(void)d_spine;(void)d_keys_in;(void)d_keys_out;(void)d_values_in;(void)d_values_out;(void)current_bit;(void)num_bits;
# 702
::free(___);}
#if 0
# 682
{ 
# 684
if ((__device_builtin_variable_threadIdx.x) < (RADIX_DIGITS)) 
# 685
{ 
# 686
int bin_idx = DESCENDING ? ((RADIX_DIGITS) - (__device_builtin_variable_threadIdx.x)) - 1 : (__device_builtin_variable_threadIdx.x); 
# 691
Offset first_block_bin_offset = d_spine[(__device_builtin_variable_gridDim.x) * bin_idx]; 
# 692
int predicate = (first_block_bin_offset == 0) || (first_block_bin_offset == num_items); 
# 693
((this->temp_storage).short_circuit) = WarpAll(predicate); 
# 696
(bin_offset) = (d_spine[((__device_builtin_variable_gridDim.x) * bin_idx) + (__device_builtin_variable_blockIdx.x)]); 
# 697
}  
# 699
__syncthreads(); 
# 701
(short_circuit) = ((this->temp_storage).short_circuit); 
# 702
} 
#endif
# 708 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_radix_sort_downsweep.cuh"
__attribute((always_inline)) void ProcessRegion(Offset 
# 709
block_offset, const Offset &
# 710
block_end) 
# 711
{int volatile ___ = 1;(void)block_offset;(void)block_end;
# 737
::exit(___);}
#if 0
# 711
{ 
# 712
if (short_circuit) 
# 713
{ 
# 715
Copy(d_keys_in, d_keys_out, block_offset, block_end); 
# 718
Copy(d_values_in, d_values_out, block_offset, block_end); 
# 719
} else 
# 721
{ 
# 723
while ((block_offset + (TILE_ITEMS)) <= block_end) 
# 724
{ 
# 725
ProcessTile< true> (block_offset); 
# 726
block_offset += (TILE_ITEMS); 
# 728
__syncthreads(); 
# 729
}  
# 732
if (block_offset < block_end) 
# 733
{ 
# 734
ProcessTile< false> (block_offset, block_end - block_offset); 
# 735
}  
# 736
}  
# 737
} 
#endif
# 738 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_radix_sort_downsweep.cuh"
}; 
# 742
}
# 743
}}}}
# 49 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_radix_sort_dispatch.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 52
namespace cub_ { 
# 61
template< class 
# 62
BlockRadixSortUpsweepPolicy, bool 
# 63
DESCENDING, class 
# 64
Key, class 
# 65
Offset> static void 
# 67
__wrapper__device_stub_DeviceRadixSortUpsweepKernel(Key *&
# 68
d_keys, Offset *&
# 69
d_spine, Offset &
# 70
num_items, int &
# 71
current_bit, int &
# 72
num_bits, bool &
# 73
first_pass, GridEvenShare< Offset>  &
# 74
even_share) {exit(1);}
#if 0
# 75
{ 
# 77
typedef BlockRadixSortUpsweep< BlockRadixSortUpsweepPolicy, Key, Offset>  BlockRadixSortUpsweepT; 
# 80
__attribute__((unused)) static typename BlockRadixSortUpsweep< BlockRadixSortUpsweepPolicy, Key, Offset> ::TempStorage temp_storage; 
# 83
(even_share.BlockInit()); 
# 85
Offset bin_count; 
# 86
(BlockRadixSortUpsweepT(temp_storage, d_keys, current_bit, num_bits).ProcessRegion((even_share.block_offset), (even_share.block_end), bin_count)); 
# 92
if ((__device_builtin_variable_threadIdx.x) < BlockRadixSortUpsweepT::RADIX_DIGITS) 
# 93
{ 
# 94
int bin_idx = DESCENDING ? (BlockRadixSortUpsweepT::RADIX_DIGITS - (__device_builtin_variable_threadIdx.x)) - 1 : (__device_builtin_variable_threadIdx.x); 
# 98
(d_spine[((__device_builtin_variable_gridDim.x) * bin_idx) + (__device_builtin_variable_blockIdx.x)]) = bin_count; 
# 99
}  
# 100
} 
#endif
# 61 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_radix_sort_dispatch.cuh"
template< class 
# 62
BlockRadixSortUpsweepPolicy, bool 
# 63
DESCENDING, class 
# 64
Key, class 
# 65
Offset> void 
# 67
DeviceRadixSortUpsweepKernel(Key *
# 68
d_keys, Offset *
# 69
d_spine, Offset 
# 70
num_items, int 
# 71
current_bit, int 
# 72
num_bits, bool 
# 73
first_pass, GridEvenShare< Offset>  
# 74
even_share) 
# 75
{__wrapper__device_stub_DeviceRadixSortUpsweepKernel<BlockRadixSortUpsweepPolicy,DESCENDING,Key,Offset>(d_keys,d_spine,num_items,current_bit,num_bits,first_pass,even_share);
# 100
return;}
#if 0
# 75
{ 
# 77
typedef BlockRadixSortUpsweep< BlockRadixSortUpsweepPolicy, Key, Offset>  BlockRadixSortUpsweepT; 
# 80
__attribute__((unused)) static typename BlockRadixSortUpsweep< BlockRadixSortUpsweepPolicy, Key, Offset> ::TempStorage temp_storage; 
# 83
(even_share.BlockInit()); 
# 85
Offset bin_count; 
# 86
(BlockRadixSortUpsweepT(temp_storage, d_keys, current_bit, num_bits).ProcessRegion((even_share.block_offset), (even_share.block_end), bin_count)); 
# 92
if ((__device_builtin_variable_threadIdx.x) < BlockRadixSortUpsweepT::RADIX_DIGITS) 
# 93
{ 
# 94
int bin_idx = DESCENDING ? (BlockRadixSortUpsweepT::RADIX_DIGITS - (__device_builtin_variable_threadIdx.x)) - 1 : (__device_builtin_variable_threadIdx.x); 
# 98
(d_spine[((__device_builtin_variable_gridDim.x) * bin_idx) + (__device_builtin_variable_blockIdx.x)]) = bin_count; 
# 99
}  
# 100
} 
#endif
# 106 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_radix_sort_dispatch.cuh"
template< class 
# 107
BlockScanSweepPolicy, class 
# 108
Offset> static void 
# 110
__wrapper__device_stub_RadixSortScanBinsKernel(Offset *&
# 111
d_spine, int &
# 112
num_counts) {exit(1);}
#if 0
# 113
{ 
# 115
typedef BlockScanSweep< BlockScanSweepPolicy, Offset *, Offset *, Sum, Offset, Offset>  BlockScanSweepT; 
# 118
__attribute__((unused)) static typename BlockScanSweep< BlockScanSweepPolicy, Offset *, Offset *, Sum, Offset, Offset> ::TempStorage temp_storage; 
# 120
if ((__device_builtin_variable_blockIdx.x) > (0)) { return; }  
# 123
BlockScanSweepT block_scan(temp_storage, d_spine, d_spine, Sum(), (Offset)0); 
# 126
int block_offset = 0; 
# 127
BlockScanRunningPrefixOp< Offset, Sum>  prefix_op(0, Sum()); 
# 128
while ((block_offset + BlockScanSweepT::TILE_ITEMS) <= num_counts) 
# 129
{ 
# 130
((block_scan.ConsumeTile) < true), (false > (block_offset, prefix_op)); 
# 131
block_offset += BlockScanSweepT::TILE_ITEMS; 
# 132
}  
# 133
} 
#endif
# 106 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_radix_sort_dispatch.cuh"
template< class 
# 107
BlockScanSweepPolicy, class 
# 108
Offset> void 
# 110
RadixSortScanBinsKernel(Offset *
# 111
d_spine, int 
# 112
num_counts) 
# 113
{__wrapper__device_stub_RadixSortScanBinsKernel<BlockScanSweepPolicy,Offset>(d_spine,num_counts);
# 133
return;}
#if 0
# 113
{ 
# 115
typedef BlockScanSweep< BlockScanSweepPolicy, Offset *, Offset *, Sum, Offset, Offset>  BlockScanSweepT; 
# 118
__attribute__((unused)) static typename BlockScanSweep< BlockScanSweepPolicy, Offset *, Offset *, Sum, Offset, Offset> ::TempStorage temp_storage; 
# 120
if ((__device_builtin_variable_blockIdx.x) > (0)) { return; }  
# 123
BlockScanSweepT block_scan(temp_storage, d_spine, d_spine, Sum(), (Offset)0); 
# 126
int block_offset = 0; 
# 127
BlockScanRunningPrefixOp< Offset, Sum>  prefix_op(0, Sum()); 
# 128
while ((block_offset + BlockScanSweepT::TILE_ITEMS) <= num_counts) 
# 129
{ 
# 130
((block_scan.ConsumeTile) < true), (false > (block_offset, prefix_op)); 
# 131
block_offset += BlockScanSweepT::TILE_ITEMS; 
# 132
}  
# 133
} 
#endif
# 139 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_radix_sort_dispatch.cuh"
template< class 
# 140
BlockRadixSortDownsweepPolicy, bool 
# 141
DESCENDING, class 
# 142
Key, class 
# 143
Value, class 
# 144
Offset> static void 
# 146
__wrapper__device_stub_DeviceRadixSortDownsweepKernel(Key *&
# 147
d_keys_in, Key *&
# 148
d_keys_out, Value *&
# 149
d_values_in, Value *&
# 150
d_values_out, Offset *&
# 151
d_spine, Offset &
# 152
num_items, int &
# 153
current_bit, int &
# 154
num_bits, bool &
# 155
first_pass, bool &
# 156
last_pass, GridEvenShare< Offset>  &
# 157
even_share) {exit(1);}
#if 0
# 158
{ 
# 160
typedef BlockRadixSortDownsweep< BlockRadixSortDownsweepPolicy, DESCENDING, Key, Value, Offset>  BlockRadixSortDownsweepT; 
# 163
__attribute__((unused)) static typename BlockRadixSortDownsweep< BlockRadixSortDownsweepPolicy, DESCENDING, Key, Value, Offset> ::TempStorage temp_storage; 
# 166
(even_share.BlockInit()); 
# 169
(BlockRadixSortDownsweepT(temp_storage, num_items, d_spine, d_keys_in, d_keys_out, d_values_in, d_values_out, current_bit, num_bits).ProcessRegion((even_share.block_offset), (even_share.block_end))); 
# 172
} 
#endif
# 139 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_radix_sort_dispatch.cuh"
template< class 
# 140
BlockRadixSortDownsweepPolicy, bool 
# 141
DESCENDING, class 
# 142
Key, class 
# 143
Value, class 
# 144
Offset> void 
# 146
DeviceRadixSortDownsweepKernel(Key *
# 147
d_keys_in, Key *
# 148
d_keys_out, Value *
# 149
d_values_in, Value *
# 150
d_values_out, Offset *
# 151
d_spine, Offset 
# 152
num_items, int 
# 153
current_bit, int 
# 154
num_bits, bool 
# 155
first_pass, bool 
# 156
last_pass, GridEvenShare< Offset>  
# 157
even_share) 
# 158
{__wrapper__device_stub_DeviceRadixSortDownsweepKernel<BlockRadixSortDownsweepPolicy,DESCENDING,Key,Value,Offset>(d_keys_in,d_keys_out,d_values_in,d_values_out,d_spine,num_items,current_bit,num_bits,first_pass,last_pass,even_share);
# 172
return;}
#if 0
# 158
{ 
# 160
typedef BlockRadixSortDownsweep< BlockRadixSortDownsweepPolicy, DESCENDING, Key, Value, Offset>  BlockRadixSortDownsweepT; 
# 163
__attribute__((unused)) static typename BlockRadixSortDownsweep< BlockRadixSortDownsweepPolicy, DESCENDING, Key, Value, Offset> ::TempStorage temp_storage; 
# 166
(even_share.BlockInit()); 
# 169
(BlockRadixSortDownsweepT(temp_storage, num_items, d_spine, d_keys_in, d_keys_out, d_values_in, d_values_out, current_bit, num_bits).ProcessRegion((even_share.block_offset), (even_share.block_end))); 
# 172
} 
#endif
# 183 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_radix_sort_dispatch.cuh"
template< bool 
# 184
DESCENDING, class 
# 185
Key, class 
# 186
Value, class 
# 187
Offset> 
# 188
struct DeviceRadixSortDispatch { 
# 195
struct Policy350 { 
# 197
enum { 
# 198
KEYS_ONLY = Equals< Value, NullType> ::VALUE, 
# 199
SCALE_FACTOR = (((sizeof(Value) > sizeof(Key)) ? sizeof(Value) : sizeof(Key)) + (3)) / (4), 
# 200
RADIX_BITS = 5
# 201
}; 
# 204
typedef BlockRadixSortUpsweepPolicy< 64, (((18 / (SCALE_FACTOR)) > 1) ? 18 / (SCALE_FACTOR) : 1), LOAD_LDG, RADIX_BITS>  UpsweepPolicyKeys; 
# 205
typedef BlockRadixSortUpsweepPolicy< 128, (((15 / (SCALE_FACTOR)) > 1) ? 15 / (SCALE_FACTOR) : 1), LOAD_LDG, RADIX_BITS>  UpsweepPolicyPairs; 
# 206
typedef typename If< KEYS_ONLY, BlockRadixSortUpsweepPolicy< 64, (((18 / (SCALE_FACTOR)) > 1) ? 18 / (SCALE_FACTOR) : 1), LOAD_LDG, RADIX_BITS> , BlockRadixSortUpsweepPolicy< 128, (((15 / (SCALE_FACTOR)) > 1) ? 15 / (SCALE_FACTOR) : 1), LOAD_LDG, RADIX_BITS> > ::Type UpsweepPolicy; 
# 209
typedef BlockRadixSortUpsweepPolicy< 64, (((22 / (SCALE_FACTOR)) > 1) ? 22 / (SCALE_FACTOR) : 1), LOAD_LDG, (RADIX_BITS) - 1>  AltUpsweepPolicyKeys; 
# 210
typedef BlockRadixSortUpsweepPolicy< 128, (((15 / (SCALE_FACTOR)) > 1) ? 15 / (SCALE_FACTOR) : 1), LOAD_LDG, (RADIX_BITS) - 1>  AltUpsweepPolicyPairs; 
# 211
typedef typename If< KEYS_ONLY, BlockRadixSortUpsweepPolicy< 64, (((22 / (SCALE_FACTOR)) > 1) ? 22 / (SCALE_FACTOR) : 1), LOAD_LDG, (RADIX_BITS) - 1> , BlockRadixSortUpsweepPolicy< 128, (((15 / (SCALE_FACTOR)) > 1) ? 15 / (SCALE_FACTOR) : 1), LOAD_LDG, (RADIX_BITS) - 1> > ::Type AltUpsweepPolicy; 
# 214
typedef BlockScanSweepPolicy< 1024, 4, BLOCK_LOAD_VECTORIZE, false, LOAD_DEFAULT, BLOCK_STORE_VECTORIZE, false, BLOCK_SCAN_WARP_SCANS>  ScanPolicy; 
# 217
typedef BlockRadixSortDownsweepPolicy< 64, (((18 / (SCALE_FACTOR)) > 1) ? 18 / (SCALE_FACTOR) : 1), BLOCK_LOAD_DIRECT, LOAD_LDG, false, true, BLOCK_SCAN_WARP_SCANS, RADIX_SORT_SCATTER_TWO_PHASE, cudaSharedMemBankSizeEightByte, RADIX_BITS>  DownsweepPolicyKeys; 
# 218
typedef BlockRadixSortDownsweepPolicy< 128, (((15 / (SCALE_FACTOR)) > 1) ? 15 / (SCALE_FACTOR) : 1), BLOCK_LOAD_DIRECT, LOAD_LDG, false, true, BLOCK_SCAN_WARP_SCANS, RADIX_SORT_SCATTER_TWO_PHASE, cudaSharedMemBankSizeEightByte, RADIX_BITS>  DownsweepPolicyPairs; 
# 219
typedef typename If< KEYS_ONLY, BlockRadixSortDownsweepPolicy< 64, (((18 / (SCALE_FACTOR)) > 1) ? 18 / (SCALE_FACTOR) : 1), BLOCK_LOAD_DIRECT, LOAD_LDG, false, true, BLOCK_SCAN_WARP_SCANS, RADIX_SORT_SCATTER_TWO_PHASE, cudaSharedMemBankSizeEightByte, RADIX_BITS> , BlockRadixSortDownsweepPolicy< 128, (((15 / (SCALE_FACTOR)) > 1) ? 15 / (SCALE_FACTOR) : 1), BLOCK_LOAD_DIRECT, LOAD_LDG, false, true, BLOCK_SCAN_WARP_SCANS, RADIX_SORT_SCATTER_TWO_PHASE, cudaSharedMemBankSizeEightByte, RADIX_BITS> > ::Type DownsweepPolicy; 
# 222
typedef BlockRadixSortDownsweepPolicy< 128, (((11 / (SCALE_FACTOR)) > 1) ? 11 / (SCALE_FACTOR) : 1), BLOCK_LOAD_DIRECT, LOAD_LDG, false, true, BLOCK_SCAN_WARP_SCANS, RADIX_SORT_SCATTER_TWO_PHASE, cudaSharedMemBankSizeEightByte, (RADIX_BITS) - 1>  AltDownsweepPolicyKeys; 
# 223
typedef BlockRadixSortDownsweepPolicy< 128, (((15 / (SCALE_FACTOR)) > 1) ? 15 / (SCALE_FACTOR) : 1), BLOCK_LOAD_DIRECT, LOAD_LDG, false, true, BLOCK_SCAN_WARP_SCANS, RADIX_SORT_SCATTER_TWO_PHASE, cudaSharedMemBankSizeEightByte, (RADIX_BITS) - 1>  AltDownsweepPolicyPairs; 
# 224
typedef typename If< KEYS_ONLY, BlockRadixSortDownsweepPolicy< 128, (((11 / (SCALE_FACTOR)) > 1) ? 11 / (SCALE_FACTOR) : 1), BLOCK_LOAD_DIRECT, LOAD_LDG, false, true, BLOCK_SCAN_WARP_SCANS, RADIX_SORT_SCATTER_TWO_PHASE, cudaSharedMemBankSizeEightByte, (RADIX_BITS) - 1> , BlockRadixSortDownsweepPolicy< 128, (((15 / (SCALE_FACTOR)) > 1) ? 15 / (SCALE_FACTOR) : 1), BLOCK_LOAD_DIRECT, LOAD_LDG, false, true, BLOCK_SCAN_WARP_SCANS, RADIX_SORT_SCATTER_TWO_PHASE, cudaSharedMemBankSizeEightByte, (RADIX_BITS) - 1> > ::Type AltDownsweepPolicy; 
# 225
}; 
# 229
struct Policy300 { 
# 231
enum { 
# 232
KEYS_ONLY = Equals< Value, NullType> ::VALUE, 
# 233
SCALE_FACTOR = (((sizeof(Value) > sizeof(Key)) ? sizeof(Value) : sizeof(Key)) + (3)) / (4), 
# 234
RADIX_BITS = 5
# 235
}; 
# 238
typedef BlockRadixSortUpsweepPolicy< 256, (((7 / (SCALE_FACTOR)) > 1) ? 7 / (SCALE_FACTOR) : 1), LOAD_DEFAULT, RADIX_BITS>  UpsweepPolicyKeys; 
# 239
typedef BlockRadixSortUpsweepPolicy< 256, (((5 / (SCALE_FACTOR)) > 1) ? 5 / (SCALE_FACTOR) : 1), LOAD_DEFAULT, RADIX_BITS>  UpsweepPolicyPairs; 
# 240
typedef typename If< KEYS_ONLY, BlockRadixSortUpsweepPolicy< 256, (((7 / (SCALE_FACTOR)) > 1) ? 7 / (SCALE_FACTOR) : 1), LOAD_DEFAULT, RADIX_BITS> , BlockRadixSortUpsweepPolicy< 256, (((5 / (SCALE_FACTOR)) > 1) ? 5 / (SCALE_FACTOR) : 1), LOAD_DEFAULT, RADIX_BITS> > ::Type UpsweepPolicy; 
# 243
typedef BlockRadixSortUpsweepPolicy< 256, (((7 / (SCALE_FACTOR)) > 1) ? 7 / (SCALE_FACTOR) : 1), LOAD_DEFAULT, (RADIX_BITS) - 1>  AltUpsweepPolicyKeys; 
# 244
typedef BlockRadixSortUpsweepPolicy< 256, (((5 / (SCALE_FACTOR)) > 1) ? 5 / (SCALE_FACTOR) : 1), LOAD_DEFAULT, (RADIX_BITS) - 1>  AltUpsweepPolicyPairs; 
# 245
typedef typename If< KEYS_ONLY, BlockRadixSortUpsweepPolicy< 256, (((7 / (SCALE_FACTOR)) > 1) ? 7 / (SCALE_FACTOR) : 1), LOAD_DEFAULT, (RADIX_BITS) - 1> , BlockRadixSortUpsweepPolicy< 256, (((5 / (SCALE_FACTOR)) > 1) ? 5 / (SCALE_FACTOR) : 1), LOAD_DEFAULT, (RADIX_BITS) - 1> > ::Type AltUpsweepPolicy; 
# 248
typedef BlockScanSweepPolicy< 1024, 4, BLOCK_LOAD_VECTORIZE, false, LOAD_DEFAULT, BLOCK_STORE_VECTORIZE, false, BLOCK_SCAN_RAKING_MEMOIZE>  ScanPolicy; 
# 251
typedef BlockRadixSortDownsweepPolicy< 128, (((14 / (SCALE_FACTOR)) > 1) ? 14 / (SCALE_FACTOR) : 1), BLOCK_LOAD_WARP_TRANSPOSE, LOAD_DEFAULT, false, false, BLOCK_SCAN_WARP_SCANS, RADIX_SORT_SCATTER_TWO_PHASE, cudaSharedMemBankSizeEightByte, RADIX_BITS>  DownsweepPolicyKeys; 
# 252
typedef BlockRadixSortDownsweepPolicy< 128, (((10 / (SCALE_FACTOR)) > 1) ? 10 / (SCALE_FACTOR) : 1), BLOCK_LOAD_TRANSPOSE, LOAD_DEFAULT, false, false, BLOCK_SCAN_WARP_SCANS, RADIX_SORT_SCATTER_TWO_PHASE, cudaSharedMemBankSizeEightByte, RADIX_BITS>  DownsweepPolicyPairs; 
# 253
typedef typename If< KEYS_ONLY, BlockRadixSortDownsweepPolicy< 128, (((14 / (SCALE_FACTOR)) > 1) ? 14 / (SCALE_FACTOR) : 1), BLOCK_LOAD_WARP_TRANSPOSE, LOAD_DEFAULT, false, false, BLOCK_SCAN_WARP_SCANS, RADIX_SORT_SCATTER_TWO_PHASE, cudaSharedMemBankSizeEightByte, RADIX_BITS> , BlockRadixSortDownsweepPolicy< 128, (((10 / (SCALE_FACTOR)) > 1) ? 10 / (SCALE_FACTOR) : 1), BLOCK_LOAD_TRANSPOSE, LOAD_DEFAULT, false, false, BLOCK_SCAN_WARP_SCANS, RADIX_SORT_SCATTER_TWO_PHASE, cudaSharedMemBankSizeEightByte, RADIX_BITS> > ::Type DownsweepPolicy; 
# 256
typedef BlockRadixSortDownsweepPolicy< 128, (((14 / (SCALE_FACTOR)) > 1) ? 14 / (SCALE_FACTOR) : 1), BLOCK_LOAD_WARP_TRANSPOSE, LOAD_DEFAULT, false, false, BLOCK_SCAN_WARP_SCANS, RADIX_SORT_SCATTER_TWO_PHASE, cudaSharedMemBankSizeEightByte, (RADIX_BITS) - 1>  AltDownsweepPolicyKeys; 
# 257
typedef BlockRadixSortDownsweepPolicy< 128, (((10 / (SCALE_FACTOR)) > 1) ? 10 / (SCALE_FACTOR) : 1), BLOCK_LOAD_TRANSPOSE, LOAD_DEFAULT, false, false, BLOCK_SCAN_WARP_SCANS, RADIX_SORT_SCATTER_TWO_PHASE, cudaSharedMemBankSizeEightByte, (RADIX_BITS) - 1>  AltDownsweepPolicyPairs; 
# 258
typedef typename If< KEYS_ONLY, BlockRadixSortDownsweepPolicy< 128, (((14 / (SCALE_FACTOR)) > 1) ? 14 / (SCALE_FACTOR) : 1), BLOCK_LOAD_WARP_TRANSPOSE, LOAD_DEFAULT, false, false, BLOCK_SCAN_WARP_SCANS, RADIX_SORT_SCATTER_TWO_PHASE, cudaSharedMemBankSizeEightByte, (RADIX_BITS) - 1> , BlockRadixSortDownsweepPolicy< 128, (((10 / (SCALE_FACTOR)) > 1) ? 10 / (SCALE_FACTOR) : 1), BLOCK_LOAD_TRANSPOSE, LOAD_DEFAULT, false, false, BLOCK_SCAN_WARP_SCANS, RADIX_SORT_SCATTER_TWO_PHASE, cudaSharedMemBankSizeEightByte, (RADIX_BITS) - 1> > ::Type AltDownsweepPolicy; 
# 259
}; 
# 263
struct Policy200 { 
# 265
enum { 
# 266
KEYS_ONLY = Equals< Value, NullType> ::VALUE, 
# 267
SCALE_FACTOR = (((sizeof(Value) > sizeof(Key)) ? sizeof(Value) : sizeof(Key)) + (3)) / (4), 
# 268
RADIX_BITS = 5
# 269
}; 
# 272
typedef BlockRadixSortUpsweepPolicy< 64, (((18 / (SCALE_FACTOR)) > 1) ? 18 / (SCALE_FACTOR) : 1), LOAD_DEFAULT, RADIX_BITS>  UpsweepPolicyKeys; 
# 273
typedef BlockRadixSortUpsweepPolicy< 128, (((13 / (SCALE_FACTOR)) > 1) ? 13 / (SCALE_FACTOR) : 1), LOAD_DEFAULT, RADIX_BITS>  UpsweepPolicyPairs; 
# 274
typedef typename If< KEYS_ONLY, BlockRadixSortUpsweepPolicy< 64, (((18 / (SCALE_FACTOR)) > 1) ? 18 / (SCALE_FACTOR) : 1), LOAD_DEFAULT, RADIX_BITS> , BlockRadixSortUpsweepPolicy< 128, (((13 / (SCALE_FACTOR)) > 1) ? 13 / (SCALE_FACTOR) : 1), LOAD_DEFAULT, RADIX_BITS> > ::Type UpsweepPolicy; 
# 277
typedef BlockRadixSortUpsweepPolicy< 64, (((18 / (SCALE_FACTOR)) > 1) ? 18 / (SCALE_FACTOR) : 1), LOAD_DEFAULT, (RADIX_BITS) - 1>  AltUpsweepPolicyKeys; 
# 278
typedef BlockRadixSortUpsweepPolicy< 128, (((13 / (SCALE_FACTOR)) > 1) ? 13 / (SCALE_FACTOR) : 1), LOAD_DEFAULT, (RADIX_BITS) - 1>  AltUpsweepPolicyPairs; 
# 279
typedef typename If< KEYS_ONLY, BlockRadixSortUpsweepPolicy< 64, (((18 / (SCALE_FACTOR)) > 1) ? 18 / (SCALE_FACTOR) : 1), LOAD_DEFAULT, (RADIX_BITS) - 1> , BlockRadixSortUpsweepPolicy< 128, (((13 / (SCALE_FACTOR)) > 1) ? 13 / (SCALE_FACTOR) : 1), LOAD_DEFAULT, (RADIX_BITS) - 1> > ::Type AltUpsweepPolicy; 
# 282
typedef BlockScanSweepPolicy< 512, 4, BLOCK_LOAD_VECTORIZE, false, LOAD_DEFAULT, BLOCK_STORE_VECTORIZE, false, BLOCK_SCAN_RAKING_MEMOIZE>  ScanPolicy; 
# 285
typedef BlockRadixSortDownsweepPolicy< 64, (((18 / (SCALE_FACTOR)) > 1) ? 18 / (SCALE_FACTOR) : 1), BLOCK_LOAD_WARP_TRANSPOSE, LOAD_DEFAULT, false, false, BLOCK_SCAN_WARP_SCANS, RADIX_SORT_SCATTER_TWO_PHASE, cudaSharedMemBankSizeFourByte, RADIX_BITS>  DownsweepPolicyKeys; 
# 286
typedef BlockRadixSortDownsweepPolicy< 128, (((13 / (SCALE_FACTOR)) > 1) ? 13 / (SCALE_FACTOR) : 1), BLOCK_LOAD_WARP_TRANSPOSE, LOAD_DEFAULT, false, false, BLOCK_SCAN_WARP_SCANS, RADIX_SORT_SCATTER_TWO_PHASE, cudaSharedMemBankSizeFourByte, RADIX_BITS>  DownsweepPolicyPairs; 
# 287
typedef typename If< KEYS_ONLY, BlockRadixSortDownsweepPolicy< 64, (((18 / (SCALE_FACTOR)) > 1) ? 18 / (SCALE_FACTOR) : 1), BLOCK_LOAD_WARP_TRANSPOSE, LOAD_DEFAULT, false, false, BLOCK_SCAN_WARP_SCANS, RADIX_SORT_SCATTER_TWO_PHASE, cudaSharedMemBankSizeFourByte, RADIX_BITS> , BlockRadixSortDownsweepPolicy< 128, (((13 / (SCALE_FACTOR)) > 1) ? 13 / (SCALE_FACTOR) : 1), BLOCK_LOAD_WARP_TRANSPOSE, LOAD_DEFAULT, false, false, BLOCK_SCAN_WARP_SCANS, RADIX_SORT_SCATTER_TWO_PHASE, cudaSharedMemBankSizeFourByte, RADIX_BITS> > ::Type DownsweepPolicy; 
# 290
typedef BlockRadixSortDownsweepPolicy< 64, (((18 / (SCALE_FACTOR)) > 1) ? 18 / (SCALE_FACTOR) : 1), BLOCK_LOAD_WARP_TRANSPOSE, LOAD_DEFAULT, false, false, BLOCK_SCAN_WARP_SCANS, RADIX_SORT_SCATTER_TWO_PHASE, cudaSharedMemBankSizeFourByte, (RADIX_BITS) - 1>  AltDownsweepPolicyKeys; 
# 291
typedef BlockRadixSortDownsweepPolicy< 128, (((13 / (SCALE_FACTOR)) > 1) ? 13 / (SCALE_FACTOR) : 1), BLOCK_LOAD_WARP_TRANSPOSE, LOAD_DEFAULT, false, false, BLOCK_SCAN_WARP_SCANS, RADIX_SORT_SCATTER_TWO_PHASE, cudaSharedMemBankSizeFourByte, (RADIX_BITS) - 1>  AltDownsweepPolicyPairs; 
# 292
typedef typename If< KEYS_ONLY, BlockRadixSortDownsweepPolicy< 64, (((18 / (SCALE_FACTOR)) > 1) ? 18 / (SCALE_FACTOR) : 1), BLOCK_LOAD_WARP_TRANSPOSE, LOAD_DEFAULT, false, false, BLOCK_SCAN_WARP_SCANS, RADIX_SORT_SCATTER_TWO_PHASE, cudaSharedMemBankSizeFourByte, (RADIX_BITS) - 1> , BlockRadixSortDownsweepPolicy< 128, (((13 / (SCALE_FACTOR)) > 1) ? 13 / (SCALE_FACTOR) : 1), BLOCK_LOAD_WARP_TRANSPOSE, LOAD_DEFAULT, false, false, BLOCK_SCAN_WARP_SCANS, RADIX_SORT_SCATTER_TWO_PHASE, cudaSharedMemBankSizeFourByte, (RADIX_BITS) - 1> > ::Type AltDownsweepPolicy; 
# 293
}; 
# 297
struct Policy130 { 
# 299
enum { 
# 300
KEYS_ONLY = Equals< Value, NullType> ::VALUE, 
# 301
SCALE_FACTOR = (((sizeof(Value) > sizeof(Key)) ? sizeof(Value) : sizeof(Key)) + (3)) / (4), 
# 302
RADIX_BITS = 5
# 303
}; 
# 306
typedef BlockRadixSortUpsweepPolicy< 128, (((19 / (SCALE_FACTOR)) > 1) ? 19 / (SCALE_FACTOR) : 1), LOAD_DEFAULT, RADIX_BITS>  UpsweepPolicyKeys; 
# 307
typedef BlockRadixSortUpsweepPolicy< 128, (((19 / (SCALE_FACTOR)) > 1) ? 19 / (SCALE_FACTOR) : 1), LOAD_DEFAULT, RADIX_BITS>  UpsweepPolicyPairs; 
# 308
typedef typename If< KEYS_ONLY, BlockRadixSortUpsweepPolicy< 128, (((19 / (SCALE_FACTOR)) > 1) ? 19 / (SCALE_FACTOR) : 1), LOAD_DEFAULT, RADIX_BITS> , BlockRadixSortUpsweepPolicy< 128, (((19 / (SCALE_FACTOR)) > 1) ? 19 / (SCALE_FACTOR) : 1), LOAD_DEFAULT, RADIX_BITS> > ::Type UpsweepPolicy; 
# 311
typedef BlockRadixSortUpsweepPolicy< 128, (((15 / (SCALE_FACTOR)) > 1) ? 15 / (SCALE_FACTOR) : 1), LOAD_DEFAULT, (RADIX_BITS) - 1>  AltUpsweepPolicyKeys; 
# 312
typedef BlockRadixSortUpsweepPolicy< 128, (((15 / (SCALE_FACTOR)) > 1) ? 15 / (SCALE_FACTOR) : 1), LOAD_DEFAULT, (RADIX_BITS) - 1>  AltUpsweepPolicyPairs; 
# 313
typedef typename If< KEYS_ONLY, BlockRadixSortUpsweepPolicy< 128, (((15 / (SCALE_FACTOR)) > 1) ? 15 / (SCALE_FACTOR) : 1), LOAD_DEFAULT, (RADIX_BITS) - 1> , BlockRadixSortUpsweepPolicy< 128, (((15 / (SCALE_FACTOR)) > 1) ? 15 / (SCALE_FACTOR) : 1), LOAD_DEFAULT, (RADIX_BITS) - 1> > ::Type AltUpsweepPolicy; 
# 316
typedef BlockScanSweepPolicy< 256, 4, BLOCK_LOAD_VECTORIZE, false, LOAD_DEFAULT, BLOCK_STORE_VECTORIZE, false, BLOCK_SCAN_WARP_SCANS>  ScanPolicy; 
# 319
typedef BlockRadixSortDownsweepPolicy< 64, (((19 / (SCALE_FACTOR)) > 1) ? 19 / (SCALE_FACTOR) : 1), BLOCK_LOAD_WARP_TRANSPOSE, LOAD_DEFAULT, false, false, BLOCK_SCAN_WARP_SCANS, RADIX_SORT_SCATTER_TWO_PHASE, cudaSharedMemBankSizeFourByte, RADIX_BITS>  DownsweepPolicyKeys; 
# 320
typedef BlockRadixSortDownsweepPolicy< 64, (((19 / (SCALE_FACTOR)) > 1) ? 19 / (SCALE_FACTOR) : 1), BLOCK_LOAD_WARP_TRANSPOSE, LOAD_DEFAULT, false, false, BLOCK_SCAN_WARP_SCANS, RADIX_SORT_SCATTER_TWO_PHASE, cudaSharedMemBankSizeFourByte, RADIX_BITS>  DownsweepPolicyPairs; 
# 321
typedef typename If< KEYS_ONLY, BlockRadixSortDownsweepPolicy< 64, (((19 / (SCALE_FACTOR)) > 1) ? 19 / (SCALE_FACTOR) : 1), BLOCK_LOAD_WARP_TRANSPOSE, LOAD_DEFAULT, false, false, BLOCK_SCAN_WARP_SCANS, RADIX_SORT_SCATTER_TWO_PHASE, cudaSharedMemBankSizeFourByte, RADIX_BITS> , BlockRadixSortDownsweepPolicy< 64, (((19 / (SCALE_FACTOR)) > 1) ? 19 / (SCALE_FACTOR) : 1), BLOCK_LOAD_WARP_TRANSPOSE, LOAD_DEFAULT, false, false, BLOCK_SCAN_WARP_SCANS, RADIX_SORT_SCATTER_TWO_PHASE, cudaSharedMemBankSizeFourByte, RADIX_BITS> > ::Type DownsweepPolicy; 
# 324
typedef BlockRadixSortDownsweepPolicy< 128, (((15 / (SCALE_FACTOR)) > 1) ? 15 / (SCALE_FACTOR) : 1), BLOCK_LOAD_WARP_TRANSPOSE, LOAD_DEFAULT, false, false, BLOCK_SCAN_WARP_SCANS, RADIX_SORT_SCATTER_TWO_PHASE, cudaSharedMemBankSizeFourByte, (RADIX_BITS) - 1>  AltDownsweepPolicyKeys; 
# 325
typedef BlockRadixSortDownsweepPolicy< 128, (((15 / (SCALE_FACTOR)) > 1) ? 15 / (SCALE_FACTOR) : 1), BLOCK_LOAD_WARP_TRANSPOSE, LOAD_DEFAULT, false, false, BLOCK_SCAN_WARP_SCANS, RADIX_SORT_SCATTER_TWO_PHASE, cudaSharedMemBankSizeFourByte, (RADIX_BITS) - 1>  AltDownsweepPolicyPairs; 
# 326
typedef typename If< KEYS_ONLY, BlockRadixSortDownsweepPolicy< 128, (((15 / (SCALE_FACTOR)) > 1) ? 15 / (SCALE_FACTOR) : 1), BLOCK_LOAD_WARP_TRANSPOSE, LOAD_DEFAULT, false, false, BLOCK_SCAN_WARP_SCANS, RADIX_SORT_SCATTER_TWO_PHASE, cudaSharedMemBankSizeFourByte, (RADIX_BITS) - 1> , BlockRadixSortDownsweepPolicy< 128, (((15 / (SCALE_FACTOR)) > 1) ? 15 / (SCALE_FACTOR) : 1), BLOCK_LOAD_WARP_TRANSPOSE, LOAD_DEFAULT, false, false, BLOCK_SCAN_WARP_SCANS, RADIX_SORT_SCATTER_TWO_PHASE, cudaSharedMemBankSizeFourByte, (RADIX_BITS) - 1> > ::Type AltDownsweepPolicy; 
# 327
}; 
# 331
struct Policy100 { 
# 333
enum { 
# 334
RADIX_BITS = 4
# 335
}; 
# 338
typedef BlockRadixSortUpsweepPolicy< 64, 9, LOAD_DEFAULT, RADIX_BITS>  UpsweepPolicy; 
# 341
typedef BlockRadixSortUpsweepPolicy< 64, 9, LOAD_DEFAULT, (RADIX_BITS) - 1>  AltUpsweepPolicy; 
# 344
typedef BlockScanSweepPolicy< 256, 4, BLOCK_LOAD_VECTORIZE, false, LOAD_DEFAULT, BLOCK_STORE_VECTORIZE, false, BLOCK_SCAN_RAKING_MEMOIZE>  ScanPolicy; 
# 347
typedef BlockRadixSortDownsweepPolicy< 64, 9, BLOCK_LOAD_WARP_TRANSPOSE, LOAD_DEFAULT, false, false, BLOCK_SCAN_WARP_SCANS, RADIX_SORT_SCATTER_TWO_PHASE, cudaSharedMemBankSizeFourByte, RADIX_BITS>  DownsweepPolicy; 
# 350
typedef BlockRadixSortDownsweepPolicy< 64, 9, BLOCK_LOAD_WARP_TRANSPOSE, LOAD_DEFAULT, false, false, BLOCK_SCAN_WARP_SCANS, RADIX_SORT_SCATTER_TWO_PHASE, cudaSharedMemBankSizeFourByte, (RADIX_BITS) - 1>  AltDownsweepPolicy; 
# 351
}; 
# 371
typedef Policy100 PtxPolicy; 
# 376
struct PtxUpsweepPolicy : public Policy100::UpsweepPolicy { }; 
# 377
struct PtxAltUpsweepPolicy : public Policy100::AltUpsweepPolicy { }; 
# 378
struct PtxScanPolicy : public Policy100::ScanPolicy { }; 
# 379
struct PtxDownsweepPolicy : public Policy100::DownsweepPolicy { }; 
# 380
struct PtxAltDownsweepPolicy : public Policy100::AltDownsweepPolicy { }; 
# 390
template< class 
# 391
Policy, class 
# 392
KernelConfig, class 
# 393
UpsweepKernelPtr, class 
# 394
ScanKernelPtr, class 
# 395
DownsweepKernelPtr> 
# 396
__attribute((always_inline)) static cudaError_t 
# 397
InitConfigs(int 
# 398
sm_version, int 
# 399
sm_count, KernelConfig &
# 400
upsweep_config, KernelConfig &
# 401
alt_upsweep_config, KernelConfig &
# 402
scan_config, KernelConfig &
# 403
downsweep_config, KernelConfig &
# 404
alt_downsweep_config, UpsweepKernelPtr 
# 405
upsweep_kernel, UpsweepKernelPtr 
# 406
alt_upsweep_kernel, ScanKernelPtr 
# 407
scan_kernel, DownsweepKernelPtr 
# 408
downsweep_kernel, DownsweepKernelPtr 
# 409
alt_downsweep_kernel) 
# 410
{ 
# 411
cudaError_t error; 
# 412
do { 
# 413
if (cub_::Debug(error = (upsweep_config.template InitUpsweepPolicy< typename Policy::UpsweepPolicy> (sm_version, sm_count, upsweep_kernel)), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_radix_sort_dispatch.cuh", 413)) { break; }  
# 414
if (cub_::Debug(error = (alt_upsweep_config.template InitUpsweepPolicy< typename Policy::AltUpsweepPolicy> (sm_version, sm_count, alt_upsweep_kernel)), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_radix_sort_dispatch.cuh", 414)) { break; }  
# 415
if (cub_::Debug(error = (scan_config.template InitScanPolicy< typename Policy::ScanPolicy> (sm_version, sm_count, scan_kernel)), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_radix_sort_dispatch.cuh", 415)) { break; }  
# 416
if (cub_::Debug(error = (downsweep_config.template InitDownsweepPolicy< typename Policy::DownsweepPolicy> (sm_version, sm_count, downsweep_kernel)), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_radix_sort_dispatch.cuh", 416)) { break; }  
# 417
if (cub_::Debug(error = (alt_downsweep_config.template InitDownsweepPolicy< typename Policy::AltDownsweepPolicy> (sm_version, sm_count, alt_downsweep_kernel)), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_radix_sort_dispatch.cuh", 417)) { break; }  
# 419
} while (0); 
# 421
return error; 
# 422
} 
# 428
template< class 
# 429
KernelConfig, class 
# 430
UpsweepKernelPtr, class 
# 431
ScanKernelPtr, class 
# 432
DownsweepKernelPtr> 
# 433
__attribute((always_inline)) static cudaError_t 
# 434
InitConfigs(int 
# 435
ptx_version, int 
# 436
sm_version, int 
# 437
sm_count, KernelConfig &
# 438
upsweep_config, KernelConfig &
# 439
alt_upsweep_config, KernelConfig &
# 440
scan_config, KernelConfig &
# 441
downsweep_config, KernelConfig &
# 442
alt_downsweep_config, UpsweepKernelPtr 
# 443
upsweep_kernel, UpsweepKernelPtr 
# 444
alt_upsweep_kernel, ScanKernelPtr 
# 445
scan_kernel, DownsweepKernelPtr 
# 446
downsweep_kernel, DownsweepKernelPtr 
# 447
alt_downsweep_kernel) 
# 448
{ 
# 468
cudaError_t error; 
# 469
if (ptx_version >= 350) 
# 470
{ 
# 471
error = InitConfigs< Policy350> (sm_version, sm_count, upsweep_config, alt_upsweep_config, scan_config, downsweep_config, alt_downsweep_config, upsweep_kernel, alt_upsweep_kernel, scan_kernel, downsweep_kernel, alt_downsweep_kernel); 
# 472
} else { 
# 473
if (ptx_version >= 300) 
# 474
{ 
# 475
error = InitConfigs< Policy300> (sm_version, sm_count, upsweep_config, alt_upsweep_config, scan_config, downsweep_config, alt_downsweep_config, upsweep_kernel, alt_upsweep_kernel, scan_kernel, downsweep_kernel, alt_downsweep_kernel); 
# 476
} else { 
# 477
if (ptx_version >= 200) 
# 478
{ 
# 479
error = InitConfigs< Policy200> (sm_version, sm_count, upsweep_config, alt_upsweep_config, scan_config, downsweep_config, alt_downsweep_config, upsweep_kernel, alt_upsweep_kernel, scan_kernel, downsweep_kernel, alt_downsweep_kernel); 
# 480
} else { 
# 481
if (ptx_version >= 130) 
# 482
{ 
# 483
error = InitConfigs< Policy130> (sm_version, sm_count, upsweep_config, alt_upsweep_config, scan_config, downsweep_config, alt_downsweep_config, upsweep_kernel, alt_upsweep_kernel, scan_kernel, downsweep_kernel, alt_downsweep_kernel); 
# 484
} else 
# 486
{ 
# 487
error = InitConfigs< Policy100> (sm_version, sm_count, upsweep_config, alt_upsweep_config, scan_config, downsweep_config, alt_downsweep_config, upsweep_kernel, alt_upsweep_kernel, scan_kernel, downsweep_kernel, alt_downsweep_kernel); 
# 488
}  }  }  }  
# 490
return error; 
# 493
} 
# 500
struct KernelConfig { 
# 502
int block_threads; 
# 503
int items_per_thread; 
# 504
int tile_size; 
# 505
cudaSharedMemConfig smem_config; 
# 506
int radix_bits; 
# 507
int sm_occupancy; 
# 508
int max_grid_size; 
# 509
int subscription_factor; 
# 511
__attribute((always_inline)) KernelConfig() : block_threads(0), items_per_thread(0), tile_size(0), smem_config(cudaSharedMemBankSizeDefault), radix_bits(0), sm_occupancy(0), max_grid_size(0), subscription_factor(0) 
# 513
{ 
# 514
} 
# 516
template< class UpsweepPolicy, class UpsweepKernelPtr> 
# 517
__attribute((always_inline)) cudaError_t InitUpsweepPolicy(int 
# 518
sm_version, int sm_count, UpsweepKernelPtr upsweep_kernel) 
# 519
{ 
# 520
(block_threads) = UpsweepPolicy::BLOCK_THREADS; 
# 521
(items_per_thread) = UpsweepPolicy::ITEMS_PER_THREAD; 
# 522
(radix_bits) = UpsweepPolicy::RADIX_BITS; 
# 523
(smem_config) = cudaSharedMemBankSizeFourByte; 
# 524
(tile_size) = ((block_threads) * (items_per_thread)); 
# 525
cudaError_t retval = MaxSmOccupancy(sm_occupancy, sm_version, upsweep_kernel, block_threads); 
# 526
(subscription_factor) = ((sm_version >= 300) ? 5 : ((sm_version >= 200) ? 3 : 10)); 
# 527
(max_grid_size) = (((sm_occupancy) * sm_count) * (subscription_factor)); 
# 529
return retval; 
# 530
} 
# 532
template< class ScanPolicy, class ScanKernelPtr> 
# 533
__attribute((always_inline)) cudaError_t InitScanPolicy(int 
# 534
sm_version, int sm_count, ScanKernelPtr scan_kernel) 
# 535
{ 
# 536
(block_threads) = ScanPolicy::BLOCK_THREADS; 
# 537
(items_per_thread) = ScanPolicy::ITEMS_PER_THREAD; 
# 538
(radix_bits) = 0; 
# 539
(smem_config) = cudaSharedMemBankSizeFourByte; 
# 540
(tile_size) = ((block_threads) * (items_per_thread)); 
# 541
(sm_occupancy) = 1; 
# 542
(subscription_factor) = 1; 
# 543
(max_grid_size) = 1; 
# 545
return cudaSuccess; 
# 546
} 
# 548
template< class DownsweepPolicy, class DownsweepKernelPtr> 
# 549
__attribute((always_inline)) cudaError_t InitDownsweepPolicy(int 
# 550
sm_version, int sm_count, DownsweepKernelPtr downsweep_kernel) 
# 551
{ 
# 552
(block_threads) = DownsweepPolicy::BLOCK_THREADS; 
# 553
(items_per_thread) = DownsweepPolicy::ITEMS_PER_THREAD; 
# 554
(radix_bits) = DownsweepPolicy::RADIX_BITS; 
# 555
(smem_config) = DownsweepPolicy::SMEM_CONFIG; 
# 556
(tile_size) = ((block_threads) * (items_per_thread)); 
# 557
cudaError_t retval = MaxSmOccupancy(sm_occupancy, sm_version, downsweep_kernel, block_threads); 
# 558
(subscription_factor) = ((sm_version >= 300) ? 5 : ((sm_version >= 200) ? 3 : 10)); 
# 559
(max_grid_size) = (((sm_occupancy) * sm_count) * (subscription_factor)); 
# 561
return retval; 
# 562
} 
# 563
}; 
# 570
__attribute((always_inline)) static cudaError_t 
# 571
AllocateTemporaries(void *
# 572
d_temp_storage, size_t &
# 573
temp_storage_bytes, Offset *&
# 574
d_spine, KernelConfig &
# 575
scan_config, KernelConfig &
# 576
downsweep_config) 
# 577
{ 
# 578
cudaError error = cudaSuccess; 
# 579
do 
# 580
{ 
# 582
int spine_size = ((downsweep_config.max_grid_size) * (1 << (downsweep_config.radix_bits))) + (scan_config.tile_size); 
# 585
void *allocations[1]; 
# 586
size_t allocation_sizes[1] = {spine_size * sizeof(Offset)}; 
# 592
if (cub_::Debug(error = AliasTemporaries(d_temp_storage, temp_storage_bytes, allocations, allocation_sizes), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_radix_sort_dispatch.cuh", 592)) { break; }  
# 595
if (d_temp_storage == (__null)) { 
# 596
return cudaSuccess; }  
# 599
d_spine = ((Offset *)((allocations)[0])); 
# 601
} while (0); 
# 603
return error; 
# 604
} 
# 615
template< class 
# 616
UpsweepKernelPtr, class 
# 617
ScanKernelPtr, class 
# 618
DownsweepKernelPtr> 
# 619
__attribute((always_inline)) static cudaError_t 
# 620
Dispatch(DoubleBuffer< Key>  &
# 621
d_keys, DoubleBuffer< Value>  &
# 622
d_values, Offset *
# 623
d_spine, int 
# 624
spine_size, Offset 
# 625
num_items, int 
# 626
begin_bit, int 
# 627
end_bit, cudaStream_t 
# 628
stream, bool 
# 629
debug_synchronous, KernelConfig &
# 630
upsweep_config, KernelConfig &
# 631
scan_config, KernelConfig &
# 632
downsweep_config, UpsweepKernelPtr 
# 633
upsweep_kernel, ScanKernelPtr 
# 634
scan_kernel, DownsweepKernelPtr 
# 635
downsweep_kernel) 
# 636
{ 
# 644
cudaError error = cudaSuccess; 
# 645
do 
# 646
{ 
# 648
GridEvenShare< Offset>  even_share(num_items, (downsweep_config.max_grid_size), ((upsweep_config.tile_size) > (downsweep_config.tile_size)) ? upsweep_config.tile_size : (downsweep_config.tile_size)); 
# 652
cudaSharedMemConfig original_smem_config; 
# 653
if (cub_::Debug(error = cudaDeviceGetSharedMemConfig(&original_smem_config), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_radix_sort_dispatch.cuh", 653)) { break; }  
# 654
cudaSharedMemConfig current_smem_config = original_smem_config; 
# 657
int current_bit = begin_bit; 
# 658
while (current_bit < end_bit) 
# 659
{ 
# 660
int num_bits = ((downsweep_config.radix_bits) < (end_bit - current_bit)) ? downsweep_config.radix_bits : (end_bit - current_bit); 
# 664
if (current_smem_config != (upsweep_config.smem_config)) 
# 665
{ 
# 666
if (cub_::Debug(error = cudaDeviceSetSharedMemConfig((upsweep_config.smem_config)), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_radix_sort_dispatch.cuh", 666)) { break; }  
# 667
current_smem_config = (upsweep_config.smem_config); 
# 668
}  
# 672
if (debug_synchronous) { 
# 673
printf("Invoking upsweep_kernel<<<%d, %d, 0, %lld>>>(), %d smem config, %d items per thread, %d SM occupancy, selector %d, current bit %" "d, bit_grain %d\n", (even_share.grid_size), (upsweep_config.block_threads), (long long)stream, (upsweep_config.smem_config), (upsweep_config.items_per_thread), (upsweep_config.sm_occupancy), (d_keys.selector), current_bit, (downsweep_config.radix_bits)); }  
# 674
; 
# 677
(cudaConfigureCall(((even_share.grid_size)), ((upsweep_config.block_threads)), 0, stream)) ? (void)0 : upsweep_kernel((d_keys.d_buffers)[d_keys.selector], d_spine, num_items, current_bit, num_bits, current_bit == begin_bit, even_share); 
# 687
if (cub_::Debug(error = cudaPeekAtLastError(), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_radix_sort_dispatch.cuh", 687)) { break; }  
# 690
if (debug_synchronous && (cub_::Debug(error = SyncStream(stream), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_radix_sort_dispatch.cuh", 690))) { break; }  
# 693
if (debug_synchronous) { printf("Invoking scan_kernel<<<%d, %d, 0, %lld>>>(), %d items per thread\n", 1, (scan_config.block_threads), (long long)stream, (scan_config.items_per_thread)); }  
# 694
; 
# 697
(cudaConfigureCall(1, ((scan_config.block_threads)), 0, stream)) ? (void)0 : scan_kernel(d_spine, spine_size); 
# 702
if (cub_::Debug(error = cudaPeekAtLastError(), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_radix_sort_dispatch.cuh", 702)) { break; }  
# 705
if (debug_synchronous && (cub_::Debug(error = SyncStream(stream), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_radix_sort_dispatch.cuh", 705))) { break; }  
# 710
if (current_smem_config != (downsweep_config.smem_config)) 
# 711
{ 
# 712
if (cub_::Debug(error = cudaDeviceSetSharedMemConfig((downsweep_config.smem_config)), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_radix_sort_dispatch.cuh", 712)) { break; }  
# 713
current_smem_config = (downsweep_config.smem_config); 
# 714
}  
# 717
if (debug_synchronous) { printf("Invoking downsweep_kernel<<<%d, %d, 0, %lld>>>(), %d smem config, %d items per thread, %d SM occupancy\n", (even_share.grid_size), (downsweep_config.block_threads), (long long)stream, (downsweep_config.smem_config), (downsweep_config.items_per_thread), (downsweep_config.sm_occupancy)); }  
# 718
; 
# 721
(cudaConfigureCall(((even_share.grid_size)), ((downsweep_config.block_threads)), 0, stream)) ? (void)0 : downsweep_kernel((d_keys.d_buffers)[d_keys.selector], (d_keys.d_buffers)[(d_keys.selector) ^ 1], (d_values.d_buffers)[d_values.selector], (d_values.d_buffers)[(d_values.selector) ^ 1], d_spine, num_items, current_bit, num_bits, current_bit == begin_bit, (current_bit + (downsweep_config.radix_bits)) >= end_bit, even_share); 
# 735
if (cub_::Debug(error = cudaPeekAtLastError(), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_radix_sort_dispatch.cuh", 735)) { break; }  
# 738
if (debug_synchronous && (cub_::Debug(error = SyncStream(stream), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_radix_sort_dispatch.cuh", 738))) { break; }  
# 741
(d_keys.selector) ^= 1; 
# 742
(d_values.selector) ^= 1; 
# 745
current_bit += (downsweep_config.radix_bits); 
# 746
}  
# 750
if (current_smem_config != original_smem_config) 
# 751
{ 
# 752
if (cub_::Debug(error = cudaDeviceSetSharedMemConfig(original_smem_config), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_radix_sort_dispatch.cuh", 752)) { break; }  
# 753
}  
# 756
} 
# 757
while (0); 
# 759
return error; 
# 762
} 
# 768
template< class 
# 769
UpsweepKernelPtr, class 
# 770
ScanKernelPtr, class 
# 771
DownsweepKernelPtr> 
# 772
__attribute((always_inline)) static cudaError_t 
# 773
Dispatch(void *
# 774
d_temp_storage, size_t &
# 775
temp_storage_bytes, DoubleBuffer< Key>  &
# 776
d_keys, DoubleBuffer< Value>  &
# 777
d_values, Offset 
# 778
num_items, int 
# 779
begin_bit, int 
# 780
end_bit, cudaStream_t 
# 781
stream, bool 
# 782
debug_synchronous, UpsweepKernelPtr 
# 783
upsweep_kernel, UpsweepKernelPtr 
# 784
alt_upsweep_kernel, ScanKernelPtr 
# 785
scan_kernel, DownsweepKernelPtr 
# 786
downsweep_kernel, DownsweepKernelPtr 
# 787
alt_downsweep_kernel) 
# 788
{ 
# 796
cudaError error = cudaSuccess; 
# 798
do 
# 799
{ 
# 801
int ptx_version; 
# 803
if (cub_::Debug(error = PtxVersion(ptx_version), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_radix_sort_dispatch.cuh", 803)) { break; }  
# 809
int device_ordinal; 
# 810
if (cub_::Debug(error = cudaGetDevice(&device_ordinal), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_radix_sort_dispatch.cuh", 810)) { break; }  
# 813
int sm_version; 
# 814
if (cub_::Debug(error = SmVersion(sm_version, device_ordinal), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_radix_sort_dispatch.cuh", 814)) { break; }  
# 817
int sm_count; 
# 818
if (cub_::Debug(error = cudaDeviceGetAttribute(&sm_count, cudaDevAttrMultiProcessorCount, device_ordinal), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_radix_sort_dispatch.cuh", 818)) { break; }  
# 821
KernelConfig upsweep_config; 
# 822
KernelConfig alt_upsweep_config; 
# 823
KernelConfig scan_config; 
# 824
KernelConfig downsweep_config; 
# 825
KernelConfig alt_downsweep_config; 
# 827
if (cub_::Debug(error = InitConfigs(ptx_version, sm_version, sm_count, upsweep_config, alt_upsweep_config, scan_config, downsweep_config, alt_downsweep_config, upsweep_kernel, alt_upsweep_kernel, scan_kernel, downsweep_kernel, alt_downsweep_kernel), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_radix_sort_dispatch.cuh", 829)) { 
# 829
break; }  
# 832
int spine_size = ((downsweep_config.max_grid_size) * (1 << (downsweep_config.radix_bits))) + (scan_config.tile_size); 
# 833
int alt_spine_size = ((alt_downsweep_config.max_grid_size) * (1 << (alt_downsweep_config.radix_bits))) + (scan_config.tile_size); 
# 836
Offset *d_spine = (0); 
# 837
if (spine_size > alt_spine_size) 
# 838
{ 
# 839
if (cub_::Debug(error = (AllocateTemporaries)(d_temp_storage, temp_storage_bytes, d_spine, scan_config, downsweep_config), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_radix_sort_dispatch.cuh", 839)) { break; }  
# 840
} else 
# 842
{ 
# 843
if (cub_::Debug(error = (AllocateTemporaries)(d_temp_storage, temp_storage_bytes, d_spine, scan_config, alt_downsweep_config), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_radix_sort_dispatch.cuh", 843)) { break; }  
# 844
}  
# 847
if (d_temp_storage == (__null)) { 
# 848
return cudaSuccess; }  
# 851
int num_bits = end_bit - begin_bit; 
# 852
int remaining_bits = num_bits % (downsweep_config.radix_bits); 
# 854
if (remaining_bits != 0) 
# 855
{ 
# 857
int max_alt_passes = (downsweep_config.radix_bits) - remaining_bits; 
# 858
int alt_end_bit = ((begin_bit + (max_alt_passes * (alt_downsweep_config.radix_bits))) < end_bit) ? begin_bit + (max_alt_passes * (alt_downsweep_config.radix_bits)) : end_bit; 
# 860
if (cub_::Debug(error = Dispatch(d_keys, d_values, d_spine, alt_spine_size, num_items, begin_bit, alt_end_bit, stream, debug_synchronous, alt_upsweep_config, scan_config, alt_downsweep_config, alt_upsweep_kernel, scan_kernel, alt_downsweep_kernel), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_radix_sort_dispatch.cuh", 875)) { 
# 875
break; }  
# 877
begin_bit = alt_end_bit; 
# 878
}  
# 881
if (cub_::Debug(error = Dispatch(d_keys, d_values, d_spine, spine_size, num_items, begin_bit, end_bit, stream, debug_synchronous, upsweep_config, scan_config, downsweep_config, upsweep_kernel, scan_kernel, downsweep_kernel), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_radix_sort_dispatch.cuh", 896)) { 
# 896
break; }  
# 897
} 
# 898
while (0); 
# 900
return error; 
# 903
} 
# 910
__attribute((always_inline)) static cudaError_t 
# 911
Dispatch(void *
# 912
d_temp_storage, size_t &
# 913
temp_storage_bytes, DoubleBuffer< Key>  &
# 914
d_keys, DoubleBuffer< Value>  &
# 915
d_values, Offset 
# 916
num_items, int 
# 917
begin_bit, int 
# 918
end_bit, cudaStream_t 
# 919
stream, bool 
# 920
debug_synchronous) 
# 921
{ 
# 922
return Dispatch(d_temp_storage, temp_storage_bytes, d_keys, d_values, num_items, begin_bit, end_bit, stream, debug_synchronous, DeviceRadixSortUpsweepKernel< PtxUpsweepPolicy, DESCENDING, Key, Offset> , DeviceRadixSortUpsweepKernel< PtxAltUpsweepPolicy, DESCENDING, Key, Offset> , RadixSortScanBinsKernel< PtxScanPolicy, Offset> , DeviceRadixSortDownsweepKernel< PtxDownsweepPolicy, DESCENDING, Key, Value, Offset> , DeviceRadixSortDownsweepKernel< PtxAltDownsweepPolicy, DESCENDING, Key, Value, Offset> ); 
# 937
} 
# 939
}; 
# 941
}
# 942
}}}}
# 44 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/device_radix_sort.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 47
namespace cub_ { 
# 81
struct DeviceRadixSort { 
# 140
template< class 
# 141
Key, class 
# 142
Value> static cudaError_t 
# 144
SortPairs(void *
# 145
d_temp_storage, size_t &
# 146
temp_storage_bytes, DoubleBuffer< Key>  &
# 147
d_keys, DoubleBuffer< Value>  &
# 148
d_values, int 
# 149
num_items, int 
# 150
begin_bit = 0, int 
# 151
end_bit = sizeof(Key) * (8), cudaStream_t 
# 152
stream = 0, bool 
# 153
debug_synchronous = false) 
# 154
{ 
# 156
typedef int Offset; 
# 158
return DeviceRadixSortDispatch< false, Key, Value, int> ::Dispatch(d_temp_storage, temp_storage_bytes, d_keys, d_values, num_items, begin_bit, end_bit, stream, debug_synchronous); 
# 168
} 
# 223
template< class 
# 224
Key, class 
# 225
Value> static cudaError_t 
# 227
SortPairsDescending(void *
# 228
d_temp_storage, size_t &
# 229
temp_storage_bytes, DoubleBuffer< Key>  &
# 230
d_keys, DoubleBuffer< Value>  &
# 231
d_values, int 
# 232
num_items, int 
# 233
begin_bit = 0, int 
# 234
end_bit = sizeof(Key) * (8), cudaStream_t 
# 235
stream = 0, bool 
# 236
debug_synchronous = false) 
# 237
{ 
# 239
typedef int Offset; 
# 241
return DeviceRadixSortDispatch< true, Key, Value, int> ::Dispatch(d_temp_storage, temp_storage_bytes, d_keys, d_values, num_items, begin_bit, end_bit, stream, debug_synchronous); 
# 251
} 
# 304
template< class Key> static cudaError_t 
# 306
SortKeys(void *
# 307
d_temp_storage, size_t &
# 308
temp_storage_bytes, DoubleBuffer< Key>  &
# 309
d_keys, int 
# 310
num_items, int 
# 311
begin_bit = 0, int 
# 312
end_bit = sizeof(Key) * (8), cudaStream_t 
# 313
stream = 0, bool 
# 314
debug_synchronous = false) 
# 315
{ 
# 317
typedef int Offset; 
# 320
DoubleBuffer< NullType>  d_values; 
# 322
return DeviceRadixSortDispatch< false, Key, NullType, int> ::Dispatch(d_temp_storage, temp_storage_bytes, d_keys, d_values, num_items, begin_bit, end_bit, stream, debug_synchronous); 
# 332
} 
# 381
template< class Key> static cudaError_t 
# 383
SortKeysDescending(void *
# 384
d_temp_storage, size_t &
# 385
temp_storage_bytes, DoubleBuffer< Key>  &
# 386
d_keys, int 
# 387
num_items, int 
# 388
begin_bit = 0, int 
# 389
end_bit = sizeof(Key) * (8), cudaStream_t 
# 390
stream = 0, bool 
# 391
debug_synchronous = false) 
# 392
{ 
# 394
typedef int Offset; 
# 397
DoubleBuffer< NullType>  d_values; 
# 399
return DeviceRadixSortDispatch< true, Key, NullType, int> ::Dispatch(d_temp_storage, temp_storage_bytes, d_keys, d_values, num_items, begin_bit, end_bit, stream, debug_synchronous); 
# 409
} 
# 411
}; 
# 417
}
# 418
}}}}
# 49 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_reduce_sweep.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 52
namespace cub_ { 
# 62
template< int 
# 63
_BLOCK_THREADS, int 
# 64
_ITEMS_PER_THREAD, int 
# 65
_VECTOR_LOAD_LENGTH, BlockReduceAlgorithm 
# 66
_BLOCK_ALGORITHM, CacheLoadModifier 
# 67
_LOAD_MODIFIER, GridMappingStrategy 
# 68
_GRID_MAPPING> 
# 69
struct BlockReduceSweepPolicy { 
# 72
enum { 
# 73
BLOCK_THREADS = _BLOCK_THREADS, 
# 74
ITEMS_PER_THREAD = _ITEMS_PER_THREAD, 
# 75
VECTOR_LOAD_LENGTH = _VECTOR_LOAD_LENGTH
# 76
}; 
# 78
static const BlockReduceAlgorithm BLOCK_ALGORITHM = _BLOCK_ALGORITHM; 
# 79
static const CacheLoadModifier LOAD_MODIFIER = _LOAD_MODIFIER; 
# 80
static const GridMappingStrategy GRID_MAPPING = _GRID_MAPPING; 
# 81
}; 
# 96
template< class 
# 97
BlockReduceSweepPolicy, class 
# 98
InputIterator, class 
# 99
Offset, class 
# 100
ReductionOp> 
# 101
struct BlockReduceSweep { 
# 109
typedef typename std::iterator_traits< InputIterator> ::value_type T; 
# 112
typedef typename CubVector< typename std::iterator_traits< InputIterator> ::value_type, BlockReduceSweepPolicy::VECTOR_LOAD_LENGTH> ::Type VectorT; 
# 118
typedef typename If< IsPointer< InputIterator> ::VALUE, CacheModifiedInputIterator< BlockReduceSweepPolicy::LOAD_MODIFIER, typename std::iterator_traits< InputIterator> ::value_type, Offset> , InputIterator> ::Type WrappedInputIterator; 
# 122
enum { 
# 123
BLOCK_THREADS = BlockReduceSweepPolicy::BLOCK_THREADS, 
# 124
ITEMS_PER_THREAD = BlockReduceSweepPolicy::ITEMS_PER_THREAD, 
# 125
VECTOR_LOAD_LENGTH = (BlockReduceSweepPolicy::VECTOR_LOAD_LENGTH < (BlockReduceSweepPolicy::ITEMS_PER_THREAD)) ? BlockReduceSweepPolicy::VECTOR_LOAD_LENGTH : (BlockReduceSweepPolicy::ITEMS_PER_THREAD), 
# 126
TILE_ITEMS = (BlockReduceSweepPolicy::BLOCK_THREADS) * (BlockReduceSweepPolicy::ITEMS_PER_THREAD), 
# 129
CAN_VECTORIZE = (((BlockReduceSweepPolicy::VECTOR_LOAD_LENGTH < (BlockReduceSweepPolicy::ITEMS_PER_THREAD)) ? BlockReduceSweepPolicy::VECTOR_LOAD_LENGTH : (BlockReduceSweepPolicy::ITEMS_PER_THREAD)) > 1) && IsPointer< InputIterator> ::VALUE && Traits< typename std::iterator_traits< InputIterator> ::value_type> ::PRIMITIVE
# 133
}; 
# 135
static const CacheLoadModifier LOAD_MODIFIER = (BlockReduceSweepPolicy::LOAD_MODIFIER); 
# 136
static const BlockReduceAlgorithm BLOCK_ALGORITHM = (BlockReduceSweepPolicy::BLOCK_ALGORITHM); 
# 139
typedef BlockReduce< typename std::iterator_traits< InputIterator> ::value_type, BLOCK_THREADS, BlockReduceSweepPolicy::BLOCK_ALGORITHM>  BlockReduceT; 
# 142
typedef typename BlockReduce< typename std::iterator_traits< InputIterator> ::value_type, BLOCK_THREADS, BlockReduceSweepPolicy::BLOCK_ALGORITHM> ::TempStorage _TempStorage; 
# 145
struct TempStorage : public Uninitialized< typename BlockReduce< typename std::iterator_traits< InputIterator> ::value_type, BLOCK_THREADS, BlockReduceSweepPolicy::BLOCK_ALGORITHM> ::TempStorage>  { }; 
# 152
T thread_aggregate; 
# 153
_TempStorage &temp_storage; 
# 154
InputIterator d_in; 
# 155
WrappedInputIterator d_wrapped_in; 
# 156
ReductionOp reduction_op; 
# 157
int first_tile_size; 
# 158
bool is_aligned; 
# 167
template< class Iterator> 
# 168
__attribute((always_inline)) static bool IsAligned(Iterator 
# 169
d_in, Int2Type< 1>  
# 170
can_vectorize) 
# 171
{int volatile ___ = 1;(void)d_in;(void)can_vectorize;
# 173
::exit(___);}
#if 0
# 171
{ 
# 172
return (((size_t)d_in) & (sizeof(VectorT) - (1))) == (0); 
# 173
} 
#endif
# 176 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_reduce_sweep.cuh"
template< class Iterator> 
# 177
__attribute((always_inline)) static bool IsAligned(Iterator 
# 178
d_in, Int2Type< 0>  
# 179
can_vectorize) 
# 180
{int volatile ___ = 1;(void)d_in;(void)can_vectorize;
# 182
::exit(___);}
#if 0
# 180
{ 
# 181
return false; 
# 182
} 
#endif
# 188 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_reduce_sweep.cuh"
__attribute((always_inline)) BlockReduceSweep(TempStorage &
# 189
temp_storage, InputIterator 
# 190
d_in, ReductionOp 
# 191
reduction_op) : temp_storage((temp_storage.Alias())), d_in(d_in), d_wrapped_in(d_in), reduction_op(reduction_op), first_tile_size(0), is_aligned(IsAligned(d_in, Int2Type< (CAN_VECTORIZE)> ())) 
# 199
{int *volatile ___ = 0;(void)temp_storage;(void)d_in;(void)reduction_op;::free(___);}
#if 0
# 199
{ } 
#endif
# 205 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_reduce_sweep.cuh"
template< class _Offset> 
# 206
__attribute((always_inline)) T ConsumeFullTile(_Offset 
# 207
block_offset, Int2Type< 0>  
# 208
can_vectorize) 
# 209
{int volatile ___ = 1;(void)block_offset;(void)can_vectorize;
# 217
::exit(___);}
#if 0
# 209
{ 
# 210
T items[ITEMS_PER_THREAD]; 
# 213
LoadDirectStriped< BLOCK_THREADS> (__device_builtin_variable_threadIdx.x, (d_wrapped_in) + block_offset, items); 
# 216
return ThreadReduce(items, reduction_op); 
# 217
} 
#endif
# 223 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_reduce_sweep.cuh"
template< class _Offset> 
# 224
__attribute((always_inline)) T ConsumeFullTile(_Offset 
# 225
block_offset, Int2Type< 1>  
# 226
can_vectorize) 
# 227
{int volatile ___ = 1;(void)block_offset;(void)can_vectorize;
# 253
::exit(___);}
#if 0
# 227
{ 
# 228
if (!(is_aligned)) 
# 229
{ 
# 231
return ConsumeFullTile(block_offset, Int2Type< 0> ()); 
# 232
} else 
# 234
{ 
# 236
enum { WORDS = (BlockReduceSweepPolicy::ITEMS_PER_THREAD) / ((BlockReduceSweepPolicy::VECTOR_LOAD_LENGTH < (BlockReduceSweepPolicy::ITEMS_PER_THREAD)) ? BlockReduceSweepPolicy::VECTOR_LOAD_LENGTH : (BlockReduceSweepPolicy::ITEMS_PER_THREAD))}; 
# 238
T items[ITEMS_PER_THREAD]; 
# 240
VectorT *vec_items = reinterpret_cast< VectorT *>(items); 
# 243
CacheModifiedInputIterator< BlockReduceSweepPolicy::LOAD_MODIFIER, typename CubVector< typename std::iterator_traits< InputIterator> ::value_type, BlockReduceSweepPolicy::VECTOR_LOAD_LENGTH> ::Type, Offset>  d_vec_in(reinterpret_cast< VectorT *>(((d_in) + block_offset) + ((__device_builtin_variable_threadIdx.x) * (VECTOR_LOAD_LENGTH)))); 
# 247
#pragma unroll
for (
# 247
int i = 0; i < (WORDS); ++i) { 
# 248
(vec_items[i]) = (d_vec_in[(BLOCK_THREADS) * i]); }  
# 251
return ThreadReduce(items, reduction_op); 
# 252
}  
# 253
} 
#endif
# 260 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_reduce_sweep.cuh"
template< bool FULL_TILE> 
# 261
__attribute((always_inline)) void ConsumeTile(Offset 
# 262
block_offset, int 
# 263
valid_items = TILE_ITEMS) 
# 264
{int volatile ___ = 1;(void)block_offset;(void)valid_items;
# 299
::exit(___);}
#if 0
# 264
{ 
# 265
if (FULL_TILE) 
# 266
{ 
# 268
T partial = ConsumeFullTile(block_offset, Int2Type< (CAN_VECTORIZE)> ()); 
# 271
(thread_aggregate) = ((first_tile_size) ? (reduction_op)(thread_aggregate, partial) : partial); 
# 274
} else 
# 276
{ 
# 278
int thread_offset = __device_builtin_variable_threadIdx.x; 
# 280
if ((!(first_tile_size)) && (thread_offset < valid_items)) 
# 281
{ 
# 283
(thread_aggregate) = ((d_wrapped_in)[block_offset + thread_offset]); 
# 284
thread_offset += (BLOCK_THREADS); 
# 285
}  
# 287
while (thread_offset < valid_items) 
# 288
{ 
# 290
T item = (d_wrapped_in)[block_offset + thread_offset]; 
# 291
(thread_aggregate) = (reduction_op)(thread_aggregate, item); 
# 292
thread_offset += (BLOCK_THREADS); 
# 293
}  
# 294
}  
# 297
if (!(first_tile_size)) { 
# 298
(first_tile_size) = valid_items; }  
# 299
} 
#endif
# 309 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_reduce_sweep.cuh"
__attribute((always_inline)) void ConsumeRange(Offset 
# 310
block_offset, Offset 
# 311
block_end, T &
# 312
block_aggregate) 
# 313
{int volatile ___ = 1;(void)block_offset;(void)block_end;(void)block_aggregate;
# 332
::exit(___);}
#if 0
# 313
{ 
# 315
while ((block_offset + (TILE_ITEMS)) <= block_end) 
# 316
{ 
# 317
ConsumeTile< true> (block_offset); 
# 318
block_offset += (TILE_ITEMS); 
# 319
}  
# 322
if (block_offset < block_end) 
# 323
{ 
# 324
int valid_items = block_end - block_offset; 
# 325
ConsumeTile< false> (block_offset, valid_items); 
# 326
}  
# 329
block_aggregate = (((first_tile_size) < (TILE_ITEMS)) ? (((BlockReduceT)(temp_storage)).Reduce(thread_aggregate, reduction_op, first_tile_size)) : (((BlockReduceT)(temp_storage)).Reduce(thread_aggregate, reduction_op))); 
# 332
} 
#endif
# 338 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_reduce_sweep.cuh"
__attribute((always_inline)) void ConsumeRange(Offset 
# 339
num_items, GridEvenShare< Offset>  &
# 340
even_share, GridQueue< Offset>  &
# 341
queue, T &
# 342
block_aggregate, Int2Type< 0>  
# 343
is_even_share) 
# 344
{int volatile ___ = 1;(void)num_items;(void)even_share;(void)queue;(void)block_aggregate;(void)is_even_share;
# 350
::exit(___);}
#if 0
# 344
{ 
# 346
(even_share.BlockInit()); 
# 349
ConsumeRange((even_share.block_offset), (even_share.block_end), block_aggregate); 
# 350
} 
#endif
# 360 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_reduce_sweep.cuh"
__attribute((always_inline)) void ConsumeRange(int 
# 361
num_items, GridQueue< Offset>  
# 362
queue, T &
# 363
block_aggregate) 
# 364
{int volatile ___ = 1;(void)num_items;(void)queue;(void)block_aggregate;
# 409
::exit(___);}
#if 0
# 364
{ 
# 366
__attribute__((unused)) static Offset dequeue_offset; 
# 369
Offset block_offset = (__device_builtin_variable_blockIdx.x) * (TILE_ITEMS); 
# 370
Offset even_share_base = (__device_builtin_variable_gridDim.x) * (TILE_ITEMS); 
# 372
if ((block_offset + (TILE_ITEMS)) <= num_items) 
# 373
{ 
# 375
ConsumeTile< true> (block_offset); 
# 378
while (true) 
# 379
{ 
# 381
if ((__device_builtin_variable_threadIdx.x) == (0)) { 
# 382
dequeue_offset = ((queue.Drain(TILE_ITEMS)) + even_share_base); }  
# 384
__syncthreads(); 
# 387
block_offset = dequeue_offset; 
# 389
__syncthreads(); 
# 391
if ((block_offset + (TILE_ITEMS)) > num_items) { 
# 392
break; }  
# 395
ConsumeTile< true> (block_offset); 
# 396
}  
# 397
}  
# 399
if (block_offset < num_items) 
# 400
{ 
# 401
int valid_items = num_items - block_offset; 
# 402
ConsumeTile< false> (block_offset, valid_items); 
# 403
}  
# 406
block_aggregate = (((first_tile_size) < (TILE_ITEMS)) ? (((BlockReduceT)(temp_storage)).Reduce(thread_aggregate, reduction_op, first_tile_size)) : (((BlockReduceT)(temp_storage)).Reduce(thread_aggregate, reduction_op))); 
# 409
} 
#endif
# 415 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_reduce_sweep.cuh"
__attribute((always_inline)) void ConsumeRange(Offset 
# 416
num_items, GridEvenShare< Offset>  &
# 417
even_share, GridQueue< Offset>  &
# 418
queue, T &
# 419
block_aggregate, Int2Type< 1>  
# 420
is_dynamic) 
# 421
{int volatile ___ = 1;(void)num_items;(void)even_share;(void)queue;(void)block_aggregate;(void)is_dynamic;
# 423
::exit(___);}
#if 0
# 421
{ 
# 422
ConsumeRange(num_items, queue, block_aggregate); 
# 423
} 
#endif
# 425 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_reduce_sweep.cuh"
}; 
# 428
}
# 429
}}}}
# 51 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../iterator/constant_input_iterator.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 54
namespace cub_ { 
# 93
template< class 
# 94
ValueType, class 
# 95
Offset = ptrdiff_t> 
# 96
class ConstantInputIterator { 
# 101
public: typedef ConstantInputIterator self_type; 
# 102
typedef Offset difference_type; 
# 103
typedef ValueType value_type; 
# 104
typedef ValueType *pointer; 
# 105
typedef ValueType reference; 
# 114
typedef typename thrust::detail::iterator_facade_category< any_system_tag, random_access_traversal_tag, ValueType, ValueType> ::type iterator_category; 
# 121
private: ValueType val; 
# 122
Offset offset; 
# 130
public: __attribute((always_inline)) ConstantInputIterator(ValueType 
# 131
val, Offset 
# 132
offset = 0) : val(val), offset(offset) 
# 136
{ } 
# 139
__attribute((always_inline)) self_type operator++(int) 
# 140
{ 
# 141
self_type retval = *this; 
# 142
(offset)++; 
# 143
return retval; 
# 144
} 
# 147
__attribute((always_inline)) self_type operator++() 
# 148
{ 
# 149
(offset)++; 
# 150
return *this; 
# 151
} 
# 154
__attribute((always_inline)) reference operator*() const 
# 155
{ 
# 156
return val; 
# 157
} 
# 160
template< class Distance> 
# 161
__attribute((always_inline)) self_type operator+(Distance n) const 
# 162
{ 
# 163
self_type retval(val, (offset) + n); 
# 164
return retval; 
# 165
} 
# 168
template< class Distance> 
# 169
__attribute((always_inline)) self_type &operator+=(Distance n) 
# 170
{ 
# 171
(offset) += n; 
# 172
return *this; 
# 173
} 
# 176
template< class Distance> 
# 177
__attribute((always_inline)) self_type operator-(Distance n) const 
# 178
{ 
# 179
self_type retval(val, (offset) - n); 
# 180
return retval; 
# 181
} 
# 184
template< class Distance> 
# 185
__attribute((always_inline)) self_type &operator-=(Distance n) 
# 186
{ 
# 187
(offset) -= n; 
# 188
return *this; 
# 189
} 
# 192
__attribute((always_inline)) difference_type operator-(self_type other) const 
# 193
{ 
# 194
return (offset) - (other.offset); 
# 195
} 
# 198
template< class Distance> 
# 199
__attribute((always_inline)) reference operator[](Distance n) const 
# 200
{ 
# 201
return val; 
# 202
} 
# 205
__attribute((always_inline)) pointer operator->() 
# 206
{ 
# 207
return &(val); 
# 208
} 
# 211
__attribute((always_inline)) bool operator==(const self_type &rhs) 
# 212
{ 
# 213
return ((offset) == (rhs.offset)) && ((val) == (rhs.val)); 
# 214
} 
# 217
__attribute((always_inline)) bool operator!=(const self_type &rhs) 
# 218
{ 
# 219
return ((offset) != (rhs.offset)) || ((val) != (rhs.val)); 
# 220
} 
# 223
friend inline std::ostream &operator<<(std::ostream &os, const self_type &itr) 
# 224
{ 
# 225
(((((os << ("["))) << (itr.val)) << ",") << (itr.offset)) << "]"; 
# 226
return os; 
# 227
} 
# 229
}; 
# 234
}
# 235
}}}}
# 53 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../iterator/arg_index_input_iterator.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 56
namespace cub_ { 
# 108
template< class 
# 109
InputIterator, class 
# 110
Offset = ptrdiff_t> 
# 111
class ArgIndexInputIterator { 
# 116
typedef typename std::iterator_traits< InputIterator> ::value_type T; 
# 122
public: typedef ArgIndexInputIterator self_type; 
# 123
typedef Offset difference_type; 
# 124
typedef ItemOffsetPair< typename std::iterator_traits< InputIterator> ::value_type, Offset>  value_type; 
# 125
typedef value_type *pointer; 
# 126
typedef value_type reference; 
# 135
typedef typename thrust::detail::iterator_facade_category< any_system_tag, random_access_traversal_tag, ItemOffsetPair< typename std::iterator_traits< InputIterator> ::value_type, Offset> , ItemOffsetPair< typename std::iterator_traits< InputIterator> ::value_type, Offset> > ::type iterator_category; 
# 142
private: InputIterator itr; 
# 143
difference_type offset; 
# 148
public: __attribute((always_inline)) ArgIndexInputIterator(InputIterator 
# 149
itr, difference_type 
# 150
offset = 0) : itr(itr), offset(offset) 
# 154
{ } 
# 157
__attribute((always_inline)) self_type operator++(int) 
# 158
{ 
# 159
self_type retval = *this; 
# 160
(offset)++; 
# 161
return retval; 
# 162
} 
# 165
__attribute((always_inline)) self_type operator++() 
# 166
{ 
# 167
(offset)++; 
# 168
return *this; 
# 169
} 
# 172
__attribute((always_inline)) reference operator*() const 
# 173
{ 
# 174
value_type retval; 
# 175
(retval.value) = ((itr)[offset]); 
# 176
(retval.offset) = (offset); 
# 177
return retval; 
# 178
} 
# 181
template< class Distance> 
# 182
__attribute((always_inline)) self_type operator+(Distance n) const 
# 183
{ 
# 184
self_type retval(itr, (offset) + n); 
# 185
return retval; 
# 186
} 
# 189
template< class Distance> 
# 190
__attribute((always_inline)) self_type &operator+=(Distance n) 
# 191
{ 
# 192
(offset) += n; 
# 193
return *this; 
# 194
} 
# 197
template< class Distance> 
# 198
__attribute((always_inline)) self_type operator-(Distance n) const 
# 199
{ 
# 200
self_type retval(itr, (offset) - n); 
# 201
return retval; 
# 202
} 
# 205
template< class Distance> 
# 206
__attribute((always_inline)) self_type &operator-=(Distance n) 
# 207
{ 
# 208
(offset) -= n; 
# 209
return *this; 
# 210
} 
# 213
__attribute((always_inline)) difference_type operator-(self_type other) const 
# 214
{ 
# 215
return (offset) - (other.offset); 
# 216
} 
# 219
template< class Distance> 
# 220
__attribute((always_inline)) reference operator[](Distance n) const 
# 221
{ 
# 222
return *((*this) + n); 
# 223
} 
# 226
__attribute((always_inline)) pointer operator->() 
# 227
{ 
# 228
return &(*(*this)); 
# 229
} 
# 232
__attribute((always_inline)) bool operator==(const self_type &rhs) 
# 233
{ 
# 234
return ((itr) == (rhs.itr)) && ((offset) == (rhs.offset)); 
# 235
} 
# 238
__attribute((always_inline)) bool operator!=(const self_type &rhs) 
# 239
{ 
# 240
return ((itr) != (rhs.itr)) || ((offset) != (rhs.offset)); 
# 241
} 
# 244
friend inline std::ostream &operator<<(std::ostream &os, const self_type &itr) 
# 245
{ 
# 246
return os; 
# 247
} 
# 248
}; 
# 254
}
# 255
}}}}
# 51 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_reduce_dispatch.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 54
namespace cub_ { 
# 63
template< class 
# 64
BlockReduceSweepPolicy, class 
# 65
InputIterator, class 
# 66
OutputIterator, class 
# 67
Offset, class 
# 68
ReductionOp> static void 
# 70
__wrapper__device_stub_DeviceReduceSweepKernel(InputIterator &
# 71
d_in, OutputIterator &
# 72
d_out, Offset &
# 73
num_items, GridEvenShare< Offset>  &
# 74
even_share, GridQueue< Offset>  &
# 75
queue, ReductionOp &
# 76
reduction_op) {exit(1);}
#if 0
# 77
{ 
# 79
typedef typename std::iterator_traits< InputIterator> ::value_type T; 
# 82
typedef BlockReduceSweep< BlockReduceSweepPolicy, InputIterator, Offset, ReductionOp>  BlockReduceSweepT; 
# 85
T block_aggregate; 
# 88
__attribute__((unused)) static typename BlockReduceSweep< BlockReduceSweepPolicy, InputIterator, Offset, ReductionOp> ::TempStorage temp_storage; 
# 91
(BlockReduceSweepT(temp_storage, d_in, reduction_op).ConsumeRange(num_items, even_share, queue, block_aggregate, Int2Type< BlockReduceSweepPolicy::GRID_MAPPING> ())); 
# 99
if ((__device_builtin_variable_threadIdx.x) == (0)) 
# 100
{ 
# 101
(d_out[__device_builtin_variable_blockIdx.x]) = block_aggregate; 
# 102
}  
# 103
} 
#endif
# 63 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_reduce_dispatch.cuh"
template< class 
# 64
BlockReduceSweepPolicy, class 
# 65
InputIterator, class 
# 66
OutputIterator, class 
# 67
Offset, class 
# 68
ReductionOp> void 
# 70
DeviceReduceSweepKernel(InputIterator 
# 71
d_in, OutputIterator 
# 72
d_out, Offset 
# 73
num_items, GridEvenShare< Offset>  
# 74
even_share, GridQueue< Offset>  
# 75
queue, ReductionOp 
# 76
reduction_op) 
# 77
{__wrapper__device_stub_DeviceReduceSweepKernel<BlockReduceSweepPolicy,InputIterator,OutputIterator,Offset,ReductionOp>(d_in,d_out,num_items,even_share,queue,reduction_op);
# 103
return;}
#if 0
# 77
{ 
# 79
typedef typename std::iterator_traits< InputIterator> ::value_type T; 
# 82
typedef BlockReduceSweep< BlockReduceSweepPolicy, InputIterator, Offset, ReductionOp>  BlockReduceSweepT; 
# 85
T block_aggregate; 
# 88
__attribute__((unused)) static typename BlockReduceSweep< BlockReduceSweepPolicy, InputIterator, Offset, ReductionOp> ::TempStorage temp_storage; 
# 91
(BlockReduceSweepT(temp_storage, d_in, reduction_op).ConsumeRange(num_items, even_share, queue, block_aggregate, Int2Type< BlockReduceSweepPolicy::GRID_MAPPING> ())); 
# 99
if ((__device_builtin_variable_threadIdx.x) == (0)) 
# 100
{ 
# 101
(d_out[__device_builtin_variable_blockIdx.x]) = block_aggregate; 
# 102
}  
# 103
} 
#endif
# 109 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_reduce_dispatch.cuh"
template< class 
# 110
BlockReduceSweepPolicy, class 
# 111
InputIterator, class 
# 112
OutputIterator, class 
# 113
Offset, class 
# 114
ReductionOp> static void 
# 116
__wrapper__device_stub_SingleReduceSweepKernel(InputIterator &
# 117
d_in, OutputIterator &
# 118
d_out, Offset &
# 119
num_items, ReductionOp &
# 120
reduction_op) {exit(1);}
#if 0
# 121
{ 
# 123
typedef typename std::iterator_traits< InputIterator> ::value_type T; 
# 126
typedef BlockReduceSweep< BlockReduceSweepPolicy, InputIterator, Offset, ReductionOp>  BlockReduceSweepT; 
# 129
T block_aggregate; 
# 132
__attribute__((unused)) static typename BlockReduceSweep< BlockReduceSweepPolicy, InputIterator, Offset, ReductionOp> ::TempStorage temp_storage; 
# 135
(BlockReduceSweepT(temp_storage, d_in, reduction_op).ConsumeRange((Offset)0, (Offset)num_items, block_aggregate)); 
# 141
if ((__device_builtin_variable_threadIdx.x) == (0)) 
# 142
{ 
# 143
(d_out[__device_builtin_variable_blockIdx.x]) = block_aggregate; 
# 144
}  
# 145
} 
#endif
# 109 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_reduce_dispatch.cuh"
template< class 
# 110
BlockReduceSweepPolicy, class 
# 111
InputIterator, class 
# 112
OutputIterator, class 
# 113
Offset, class 
# 114
ReductionOp> void 
# 116
SingleReduceSweepKernel(InputIterator 
# 117
d_in, OutputIterator 
# 118
d_out, Offset 
# 119
num_items, ReductionOp 
# 120
reduction_op) 
# 121
{__wrapper__device_stub_SingleReduceSweepKernel<BlockReduceSweepPolicy,InputIterator,OutputIterator,Offset,ReductionOp>(d_in,d_out,num_items,reduction_op);
# 145
return;}
#if 0
# 121
{ 
# 123
typedef typename std::iterator_traits< InputIterator> ::value_type T; 
# 126
typedef BlockReduceSweep< BlockReduceSweepPolicy, InputIterator, Offset, ReductionOp>  BlockReduceSweepT; 
# 129
T block_aggregate; 
# 132
__attribute__((unused)) static typename BlockReduceSweep< BlockReduceSweepPolicy, InputIterator, Offset, ReductionOp> ::TempStorage temp_storage; 
# 135
(BlockReduceSweepT(temp_storage, d_in, reduction_op).ConsumeRange((Offset)0, (Offset)num_items, block_aggregate)); 
# 141
if ((__device_builtin_variable_threadIdx.x) == (0)) 
# 142
{ 
# 143
(d_out[__device_builtin_variable_blockIdx.x]) = block_aggregate; 
# 144
}  
# 145
} 
#endif
# 157 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_reduce_dispatch.cuh"
template< class 
# 158
InputIterator, class 
# 159
OutputIterator, class 
# 160
Offset, class 
# 161
ReductionOp> 
# 162
struct DeviceReduceDispatch { 
# 165
typedef typename std::iterator_traits< InputIterator> ::value_type T; 
# 173
struct Policy350 { 
# 183
typedef BlockReduceSweepPolicy< 128, 24, 4, BLOCK_REDUCE_RAKING, LOAD_LDG, GRID_MAPPING_DYNAMIC>  RangeReducePolicy1B; 
# 185
enum { 
# 186
NOMINAL_4B_ITEMS_PER_THREAD = 20, 
# 187
ITEMS_PER_THREAD = ((((((20) * 4) / sizeof(T)) > (1)) ? ((20) * 4) / sizeof(T) : (1)) < (20)) ? ((((20) * 4) / sizeof(T)) > (1)) ? ((20) * 4) / sizeof(T) : (1) : (20)
# 188
}; 
# 198
typedef BlockReduceSweepPolicy< 256, (ITEMS_PER_THREAD), 2, BLOCK_REDUCE_RAKING, LOAD_LDG, GRID_MAPPING_DYNAMIC>  RangeReducePolicy4B; 
# 203
typedef typename If< sizeof(typename std::iterator_traits< InputIterator> ::value_type) >= (4), BlockReduceSweepPolicy< 256, (ITEMS_PER_THREAD), 2, BLOCK_REDUCE_RAKING, LOAD_LDG, GRID_MAPPING_DYNAMIC> , BlockReduceSweepPolicy< 128, 24, 4, BLOCK_REDUCE_RAKING, LOAD_LDG, GRID_MAPPING_DYNAMIC> > ::Type RangeReducePolicy; 
# 213
typedef BlockReduceSweepPolicy< 256, 8, 1, BLOCK_REDUCE_WARP_REDUCTIONS, LOAD_DEFAULT, GRID_MAPPING_EVEN_SHARE>  SingleTilePolicy; 
# 214
}; 
# 217
struct Policy300 { 
# 219
enum { 
# 220
NOMINAL_4B_ITEMS_PER_THREAD = 2, 
# 221
ITEMS_PER_THREAD = ((((((2) * 4) / sizeof(T)) > (1)) ? ((2) * 4) / sizeof(T) : (1)) < (2)) ? ((((2) * 4) / sizeof(T)) > (1)) ? ((2) * 4) / sizeof(T) : (1) : (2)
# 222
}; 
# 232
typedef BlockReduceSweepPolicy< 256, (ITEMS_PER_THREAD), 1, BLOCK_REDUCE_WARP_REDUCTIONS, LOAD_DEFAULT, GRID_MAPPING_EVEN_SHARE>  RangeReducePolicy; 
# 242
typedef BlockReduceSweepPolicy< 256, 24, 4, BLOCK_REDUCE_WARP_REDUCTIONS, LOAD_DEFAULT, GRID_MAPPING_EVEN_SHARE>  SingleTilePolicy; 
# 243
}; 
# 246
struct Policy200 { 
# 258
typedef BlockReduceSweepPolicy< 192, 24, 4, BLOCK_REDUCE_RAKING, LOAD_DEFAULT, (sizeof(typename std::iterator_traits< InputIterator> ::value_type) == (1)) ? GRID_MAPPING_EVEN_SHARE : GRID_MAPPING_DYNAMIC>  RangeReducePolicy1B; 
# 260
enum { 
# 261
NOMINAL_4B_ITEMS_PER_THREAD = 8, 
# 262
NOMINAL_4B_VEC_ITEMS = 4, 
# 263
ITEMS_PER_THREAD = ((((((8) * 4) / sizeof(T)) > (1)) ? ((8) * 4) / sizeof(T) : (1)) < (8)) ? ((((8) * 4) / sizeof(T)) > (1)) ? ((8) * 4) / sizeof(T) : (1) : (8), 
# 264
VEC_ITEMS = ((((((4) * 4) / sizeof(T)) > (1)) ? ((4) * 4) / sizeof(T) : (1)) < (4)) ? ((((4) * 4) / sizeof(T)) > (1)) ? ((4) * 4) / sizeof(T) : (1) : (4)
# 265
}; 
# 275
typedef BlockReduceSweepPolicy< 128, (ITEMS_PER_THREAD), (VEC_ITEMS), BLOCK_REDUCE_RAKING, LOAD_DEFAULT, GRID_MAPPING_DYNAMIC>  RangeReducePolicy4B; 
# 280
typedef typename If< sizeof(typename std::iterator_traits< InputIterator> ::value_type) < (4), BlockReduceSweepPolicy< 192, 24, 4, BLOCK_REDUCE_RAKING, LOAD_DEFAULT, (sizeof(typename std::iterator_traits< InputIterator> ::value_type) == (1)) ? GRID_MAPPING_EVEN_SHARE : GRID_MAPPING_DYNAMIC> , BlockReduceSweepPolicy< 128, (ITEMS_PER_THREAD), (VEC_ITEMS), BLOCK_REDUCE_RAKING, LOAD_DEFAULT, GRID_MAPPING_DYNAMIC> > ::Type RangeReducePolicy; 
# 290
typedef BlockReduceSweepPolicy< 192, 7, 1, BLOCK_REDUCE_RAKING, LOAD_DEFAULT, GRID_MAPPING_EVEN_SHARE>  SingleTilePolicy; 
# 291
}; 
# 294
struct Policy130 { 
# 296
enum { 
# 297
NOMINAL_4B_ITEMS_PER_THREAD = 8, 
# 298
NOMINAL_4B_VEC_ITEMS = 2, 
# 299
ITEMS_PER_THREAD = ((((((8) * 4) / sizeof(T)) > (1)) ? ((8) * 4) / sizeof(T) : (1)) < (8)) ? ((((8) * 4) / sizeof(T)) > (1)) ? ((8) * 4) / sizeof(T) : (1) : (8), 
# 300
VEC_ITEMS = ((((((2) * 4) / sizeof(T)) > (1)) ? ((2) * 4) / sizeof(T) : (1)) < (2)) ? ((((2) * 4) / sizeof(T)) > (1)) ? ((2) * 4) / sizeof(T) : (1) : (2)
# 301
}; 
# 311
typedef BlockReduceSweepPolicy< 128, (ITEMS_PER_THREAD), (VEC_ITEMS), BLOCK_REDUCE_RAKING, LOAD_DEFAULT, GRID_MAPPING_EVEN_SHARE>  RangeReducePolicy; 
# 321
typedef BlockReduceSweepPolicy< 32, 4, (VEC_ITEMS), BLOCK_REDUCE_RAKING, LOAD_DEFAULT, GRID_MAPPING_EVEN_SHARE>  SingleTilePolicy; 
# 322
}; 
# 325
struct Policy100 { 
# 327
enum { 
# 328
NOMINAL_4B_ITEMS_PER_THREAD = 8, 
# 329
NOMINAL_4B_VEC_ITEMS = 2, 
# 330
ITEMS_PER_THREAD = ((((((8) * 4) / sizeof(T)) > (1)) ? ((8) * 4) / sizeof(T) : (1)) < (8)) ? ((((8) * 4) / sizeof(T)) > (1)) ? ((8) * 4) / sizeof(T) : (1) : (8), 
# 331
VEC_ITEMS = ((((((2) * 4) / sizeof(T)) > (1)) ? ((2) * 4) / sizeof(T) : (1)) < (2)) ? ((((2) * 4) / sizeof(T)) > (1)) ? ((2) * 4) / sizeof(T) : (1) : (2)
# 332
}; 
# 342
typedef BlockReduceSweepPolicy< 128, (ITEMS_PER_THREAD), (VEC_ITEMS), BLOCK_REDUCE_RAKING, LOAD_DEFAULT, GRID_MAPPING_EVEN_SHARE>  RangeReducePolicy; 
# 352
typedef BlockReduceSweepPolicy< 32, 4, 4, BLOCK_REDUCE_RAKING, LOAD_DEFAULT, GRID_MAPPING_EVEN_SHARE>  SingleTilePolicy; 
# 353
}; 
# 373
typedef Policy100 PtxPolicy; 
# 378
struct PtxRangeReducePolicy : public Policy100::RangeReducePolicy { }; 
# 379
struct PtxSingleTilePolicy : public Policy100::SingleTilePolicy { }; 
# 389
template< class KernelConfig> 
# 390
__attribute((always_inline)) static void 
# 391
InitConfigs(int 
# 392
ptx_version, KernelConfig &
# 393
device_reduce_sweep_config, KernelConfig &
# 394
single_reduce_sweep_config) 
# 395
{ 
# 405
if (ptx_version >= 350) 
# 406
{ 
# 407
(device_reduce_sweep_config.template Init< typename Policy350::RangeReducePolicy> ()); 
# 408
(single_reduce_sweep_config.template Init< typename Policy350::SingleTilePolicy> ()); 
# 409
} else { 
# 410
if (ptx_version >= 300) 
# 411
{ 
# 412
(device_reduce_sweep_config.template Init< typename Policy300::RangeReducePolicy> ()); 
# 413
(single_reduce_sweep_config.template Init< typename Policy300::SingleTilePolicy> ()); 
# 414
} else { 
# 415
if (ptx_version >= 200) 
# 416
{ 
# 417
(device_reduce_sweep_config.template Init< typename Policy200::RangeReducePolicy> ()); 
# 418
(single_reduce_sweep_config.template Init< typename Policy200::SingleTilePolicy> ()); 
# 419
} else { 
# 420
if (ptx_version >= 130) 
# 421
{ 
# 422
(device_reduce_sweep_config.template Init< typename Policy130::RangeReducePolicy> ()); 
# 423
(single_reduce_sweep_config.template Init< typename Policy130::SingleTilePolicy> ()); 
# 424
} else 
# 426
{ 
# 427
(device_reduce_sweep_config.template Init< typename Policy100::RangeReducePolicy> ()); 
# 428
(single_reduce_sweep_config.template Init< typename Policy100::SingleTilePolicy> ()); 
# 429
}  }  }  }  
# 432
} 
# 438
struct KernelConfig { 
# 440
int block_threads; 
# 441
int items_per_thread; 
# 442
int vector_load_length; 
# 443
BlockReduceAlgorithm block_algorithm; 
# 444
CacheLoadModifier load_modifier; 
# 445
GridMappingStrategy grid_mapping; 
# 447
template< class BlockPolicy> 
# 448
__attribute((always_inline)) void 
# 449
Init() 
# 450
{ 
# 451
(block_threads) = BlockPolicy::BLOCK_THREADS; 
# 452
(items_per_thread) = BlockPolicy::ITEMS_PER_THREAD; 
# 453
(vector_load_length) = BlockPolicy::VECTOR_LOAD_LENGTH; 
# 454
(block_algorithm) = BlockPolicy::BLOCK_ALGORITHM; 
# 455
(load_modifier) = BlockPolicy::LOAD_MODIFIER; 
# 456
(grid_mapping) = BlockPolicy::GRID_MAPPING; 
# 457
} 
# 459
__attribute((always_inline)) void 
# 460
Print() 
# 461
{ 
# 462
printf("%d threads, %d per thread, %d veclen, %d algo, %d loadmod, %d mapping", block_threads, items_per_thread, vector_load_length, block_algorithm, load_modifier, grid_mapping); 
# 469
} 
# 470
}; 
# 483
template< class 
# 484
DeviceReduceSweepKernelPtr, class 
# 485
SingleReducePartialsKernelPtr, class 
# 486
SingleReduceSweepKernelPtr, class 
# 487
FillAndResetDrainKernelPtr> 
# 488
__attribute((always_inline)) static cudaError_t 
# 489
Dispatch(void *
# 490
d_temp_storage, size_t &
# 491
temp_storage_bytes, InputIterator 
# 492
d_in, OutputIterator 
# 493
d_out, Offset 
# 494
num_items, ReductionOp 
# 495
reduction_op, cudaStream_t 
# 496
stream, bool 
# 497
debug_synchronous, FillAndResetDrainKernelPtr 
# 498
prepare_drain_kernel, DeviceReduceSweepKernelPtr 
# 499
device_reduce_sweep_kernel, SingleReducePartialsKernelPtr 
# 500
single_reduce_partials_kernel, SingleReduceSweepKernelPtr 
# 501
single_reduce_sweep_kernel, KernelConfig 
# 502
device_reduce_sweep_config, KernelConfig 
# 503
single_reduce_sweep_config) 
# 504
{ 
# 511
cudaError error = cudaSuccess; 
# 512
do 
# 513
{ 
# 515
int device_ordinal; 
# 516
if (cub_::Debug(error = cudaGetDevice(&device_ordinal), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_reduce_dispatch.cuh", 516)) { break; }  
# 519
int sm_version; 
# 520
if (cub_::Debug(error = SmVersion(sm_version, device_ordinal), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_reduce_dispatch.cuh", 520)) { break; }  
# 523
int sm_count; 
# 524
if (cub_::Debug(error = cudaDeviceGetAttribute(&sm_count, cudaDevAttrMultiProcessorCount, device_ordinal), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_reduce_dispatch.cuh", 524)) { break; }  
# 527
int tile_size = (device_reduce_sweep_config.block_threads) * (device_reduce_sweep_config.items_per_thread); 
# 529
if ((device_reduce_sweep_kernel == __null) || (num_items <= tile_size)) 
# 530
{ 
# 534
if (d_temp_storage == (__null)) 
# 535
{ 
# 536
temp_storage_bytes = (1); 
# 537
return cudaSuccess; 
# 538
}  
# 541
if (debug_synchronous) { printf("Invoking ReduceSingle<<<1, %d, 0, %lld>>>(), %d items per thread\n", (single_reduce_sweep_config.block_threads), (long long)stream, (single_reduce_sweep_config.items_per_thread)); }  
# 542
; 
# 545
(cudaConfigureCall(1, ((single_reduce_sweep_config.block_threads)))) ? (void)0 : single_reduce_sweep_kernel(d_in, d_out, num_items, reduction_op); 
# 552
if (cub_::Debug(error = cudaPeekAtLastError(), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_reduce_dispatch.cuh", 552)) { break; }  
# 555
if (debug_synchronous && (cub_::Debug(error = SyncStream(stream), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_reduce_dispatch.cuh", 555))) { break; }  
# 557
} else 
# 559
{ 
# 565
int range_reduce_sm_occupancy; 
# 566
if (cub_::Debug(error = MaxSmOccupancy(range_reduce_sm_occupancy, sm_version, device_reduce_sweep_kernel, (device_reduce_sweep_config.block_threads)), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_reduce_dispatch.cuh", 570)) { 
# 570
break; }  
# 573
int range_reduce_occupancy = range_reduce_sm_occupancy * sm_count; 
# 576
int subscription_factor = range_reduce_sm_occupancy; 
# 577
GridEvenShare< Offset>  even_share(num_items, range_reduce_occupancy * subscription_factor, tile_size); 
# 583
int range_reduce_grid_size; 
# 584
switch (device_reduce_sweep_config.grid_mapping) 
# 585
{ 
# 586
case GRID_MAPPING_EVEN_SHARE:  
# 589
range_reduce_grid_size = (even_share.grid_size); 
# 590
break; 
# 592
case GRID_MAPPING_DYNAMIC:  
# 595
int num_tiles = ((num_items + tile_size) - 1) / tile_size; 
# 596
range_reduce_grid_size = ((num_tiles < range_reduce_occupancy) ? num_tiles : range_reduce_occupancy); 
# 599
break; 
# 600
}  ; 
# 603
void *allocations[2]; 
# 604
size_t allocation_sizes[2] = {range_reduce_grid_size * sizeof(T), GridQueue< int> ::AllocationSize()}; 
# 611
if (cub_::Debug(error = AliasTemporaries(d_temp_storage, temp_storage_bytes, allocations, allocation_sizes), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_reduce_dispatch.cuh", 611)) { break; }  
# 612
if (d_temp_storage == (__null)) 
# 613
{ 
# 615
return cudaSuccess; 
# 616
}  
# 619
T *d_block_reductions = (T *)((allocations)[0]); 
# 622
GridQueue< Offset>  queue((allocations)[1]); 
# 625
if ((device_reduce_sweep_config.grid_mapping) == GRID_MAPPING_DYNAMIC) 
# 626
{ 
# 628
if (debug_synchronous) { printf("Invoking prepare_drain_kernel<<<1, 1, 0, %lld>>>()\n", (long long)stream); }  ; 
# 631
(cudaConfigureCall(1, 1, 0, stream)) ? (void)0 : prepare_drain_kernel(queue, num_items); 
# 634
if (cub_::Debug(error = cudaPeekAtLastError(), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_reduce_dispatch.cuh", 634)) { break; }  
# 637
if (debug_synchronous && (cub_::Debug(error = SyncStream(stream), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_reduce_dispatch.cuh", 637))) { break; }  
# 638
}  
# 641
if (debug_synchronous) { printf("Invoking device_reduce_sweep_kernel<<<%d, %d, 0, %lld>>>(), %d items per thread, %d SM occupancy\n", range_reduce_grid_size, (device_reduce_sweep_config.block_threads), (long long)stream, (device_reduce_sweep_config.items_per_thread), range_reduce_sm_occupancy); }  
# 642
; 
# 645
(cudaConfigureCall(range_reduce_grid_size, ((device_reduce_sweep_config.block_threads)), 0, stream)) ? (void)0 : device_reduce_sweep_kernel(d_in, d_block_reductions, num_items, even_share, queue, reduction_op); 
# 654
if (cub_::Debug(error = cudaPeekAtLastError(), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_reduce_dispatch.cuh", 654)) { break; }  
# 657
if (debug_synchronous && (cub_::Debug(error = SyncStream(stream), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_reduce_dispatch.cuh", 657))) { break; }  
# 660
if (debug_synchronous) { printf("Invoking single_reduce_sweep_kernel<<<%d, %d, 0, %lld>>>(), %d items per thread\n", 1, (single_reduce_sweep_config.block_threads), (long long)stream, (single_reduce_sweep_config.items_per_thread)); }  
# 661
; 
# 664
(cudaConfigureCall(1, ((single_reduce_sweep_config.block_threads)), 0, stream)) ? (void)0 : single_reduce_partials_kernel(d_block_reductions, d_out, range_reduce_grid_size, reduction_op); 
# 671
if (cub_::Debug(error = cudaPeekAtLastError(), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_reduce_dispatch.cuh", 671)) { break; }  
# 674
if (debug_synchronous && (cub_::Debug(error = SyncStream(stream), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_reduce_dispatch.cuh", 674))) { break; }  
# 675
}  
# 676
} 
# 677
while (0); 
# 679
return error; 
# 682
} 
# 688
__attribute((always_inline)) static cudaError_t 
# 689
Dispatch(void *
# 690
d_temp_storage, size_t &
# 691
temp_storage_bytes, InputIterator 
# 692
d_in, OutputIterator 
# 693
d_out, Offset 
# 694
num_items, ReductionOp 
# 695
reduction_op, cudaStream_t 
# 696
stream, bool 
# 697
debug_synchronous) 
# 698
{ 
# 699
cudaError error = cudaSuccess; 
# 700
do 
# 701
{ 
# 703
int ptx_version; 
# 705
if (cub_::Debug(error = PtxVersion(ptx_version), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_reduce_dispatch.cuh", 705)) { break; }  
# 711
KernelConfig device_reduce_sweep_config; 
# 712
KernelConfig single_reduce_sweep_config; 
# 713
InitConfigs(ptx_version, device_reduce_sweep_config, single_reduce_sweep_config); 
# 716
if (cub_::Debug(error = Dispatch(d_temp_storage, temp_storage_bytes, d_in, d_out, num_items, reduction_op, stream, debug_synchronous, FillAndResetDrainKernel< Offset> , DeviceReduceSweepKernel< PtxRangeReducePolicy, InputIterator, T *, Offset, ReductionOp> , SingleReduceSweepKernel< PtxSingleTilePolicy, T *, OutputIterator, Offset, ReductionOp> , SingleReduceSweepKernel< PtxSingleTilePolicy, InputIterator, OutputIterator, Offset, ReductionOp> , device_reduce_sweep_config, single_reduce_sweep_config), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_reduce_dispatch.cuh", 730)) { 
# 730
break; }  
# 731
} 
# 732
while (0); 
# 734
return error; 
# 735
} 
# 736
}; 
# 739
}
# 740
}}}}
# 50 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_reduce_by_key_sweep.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 53
namespace cub_ { 
# 63
template< int 
# 64
_BLOCK_THREADS, int 
# 65
_ITEMS_PER_THREAD, BlockLoadAlgorithm 
# 66
_LOAD_ALGORITHM, CacheLoadModifier 
# 67
_LOAD_MODIFIER, bool 
# 68
_TWO_PHASE_SCATTER, BlockScanAlgorithm 
# 69
_SCAN_ALGORITHM> 
# 70
struct BlockReduceSweepByKeyPolicy { 
# 73
enum { 
# 74
BLOCK_THREADS = _BLOCK_THREADS, 
# 75
ITEMS_PER_THREAD = _ITEMS_PER_THREAD, 
# 76
TWO_PHASE_SCATTER = _TWO_PHASE_SCATTER
# 77
}; 
# 79
static const BlockLoadAlgorithm LOAD_ALGORITHM = _LOAD_ALGORITHM; 
# 80
static const CacheLoadModifier LOAD_MODIFIER = _LOAD_MODIFIER; 
# 81
static const BlockScanAlgorithm SCAN_ALGORITHM = _SCAN_ALGORITHM; 
# 82
}; 
# 92
template< class 
# 93
BlockReduceSweepByKeyPolicy, class 
# 94
KeysInputIterator, class 
# 95
UniqueOutputIterator, class 
# 96
ValuesInputIterator, class 
# 97
AggregatesOutputIterator, class 
# 98
EqualityOp, class 
# 99
ReductionOp, class 
# 100
Offset> 
# 101
struct BlockReduceSweepByKey { 
# 108
typedef typename std::iterator_traits< KeysInputIterator> ::value_type Key; 
# 111
typedef typename std::iterator_traits< ValuesInputIterator> ::value_type Value; 
# 114
typedef ItemOffsetPair< typename std::iterator_traits< ValuesInputIterator> ::value_type, Offset>  ReductionOffsetPair; 
# 117
typedef ReduceByKeyScanTileState< typename std::iterator_traits< ValuesInputIterator> ::value_type, Offset>  ScanTileState; 
# 121
enum { 
# 122
BLOCK_THREADS = BlockReduceSweepByKeyPolicy::BLOCK_THREADS, 
# 123
WARPS = (BlockReduceSweepByKeyPolicy::BLOCK_THREADS) / (1 << 5), 
# 124
ITEMS_PER_THREAD = BlockReduceSweepByKeyPolicy::ITEMS_PER_THREAD, 
# 125
TWO_PHASE_SCATTER = BlockReduceSweepByKeyPolicy::TWO_PHASE_SCATTER && ((BlockReduceSweepByKeyPolicy::ITEMS_PER_THREAD) > 1), 
# 126
TILE_ITEMS = (BlockReduceSweepByKeyPolicy::BLOCK_THREADS) * (BlockReduceSweepByKeyPolicy::ITEMS_PER_THREAD), 
# 129
HAS_IDENTITY_ZERO = Equals< ReductionOp, Sum> ::VALUE && Traits< typename std::iterator_traits< ValuesInputIterator> ::value_type> ::PRIMITIVE, 
# 132
SYNC_AFTER_LOAD = BlockReduceSweepByKeyPolicy::LOAD_ALGORITHM != BLOCK_LOAD_DIRECT, 
# 135
IS_RUN_LENGTH_ENCODE = (Equals< ValuesInputIterator, ConstantInputIterator< typename std::iterator_traits< ValuesInputIterator> ::value_type, unsigned long> > ::VALUE || Equals< ValuesInputIterator, ConstantInputIterator< typename std::iterator_traits< ValuesInputIterator> ::value_type, int> > ::VALUE) || Equals< ValuesInputIterator, ConstantInputIterator< typename std::iterator_traits< ValuesInputIterator> ::value_type, unsigned> > ::VALUE
# 137
}; 
# 143
typedef typename If< IsPointer< KeysInputIterator> ::VALUE, CacheModifiedInputIterator< BlockReduceSweepByKeyPolicy::LOAD_MODIFIER, typename std::iterator_traits< KeysInputIterator> ::value_type, Offset> , KeysInputIterator> ::Type WrappedKeysInputIterator; 
# 149
typedef typename If< IsPointer< ValuesInputIterator> ::VALUE, CacheModifiedInputIterator< BlockReduceSweepByKeyPolicy::LOAD_MODIFIER, typename std::iterator_traits< ValuesInputIterator> ::value_type, Offset> , ValuesInputIterator> ::Type WrappedValuesInputIterator; 
# 152
typedef cub_::ReduceBySegmentOp< ReductionOp, ItemOffsetPair< typename std::iterator_traits< ValuesInputIterator> ::value_type, Offset> >  ReduceBySegmentOp; 
# 160
typedef BlockLoad< typename If< IsPointer< KeysInputIterator> ::VALUE, CacheModifiedInputIterator< BlockReduceSweepByKeyPolicy::LOAD_MODIFIER, typename std::iterator_traits< KeysInputIterator> ::value_type, Offset> , KeysInputIterator> ::Type, BlockReduceSweepByKeyPolicy::BLOCK_THREADS, BlockReduceSweepByKeyPolicy::ITEMS_PER_THREAD, BlockReduceSweepByKeyPolicy::LOAD_ALGORITHM>  BlockLoadKeys; 
# 170
typedef BlockLoad< typename If< IsPointer< ValuesInputIterator> ::VALUE, CacheModifiedInputIterator< BlockReduceSweepByKeyPolicy::LOAD_MODIFIER, typename std::iterator_traits< ValuesInputIterator> ::value_type, Offset> , ValuesInputIterator> ::Type, BlockReduceSweepByKeyPolicy::BLOCK_THREADS, BlockReduceSweepByKeyPolicy::ITEMS_PER_THREAD, (IS_RUN_LENGTH_ENCODE) ? BLOCK_LOAD_DIRECT : ((BlockLoadAlgorithm)BlockReduceSweepByKeyPolicy::LOAD_ALGORITHM)>  BlockLoadValues; 
# 177
typedef BlockExchange< typename std::iterator_traits< KeysInputIterator> ::value_type, BLOCK_THREADS, ITEMS_PER_THREAD>  BlockExchangeKeys; 
# 184
typedef BlockExchange< typename std::iterator_traits< ValuesInputIterator> ::value_type, BLOCK_THREADS, ITEMS_PER_THREAD>  BlockExchangeValues; 
# 187
typedef BlockDiscontinuity< typename std::iterator_traits< KeysInputIterator> ::value_type, BLOCK_THREADS>  BlockDiscontinuityKeys; 
# 194
typedef BlockScan< ItemOffsetPair< typename std::iterator_traits< ValuesInputIterator> ::value_type, Offset> , BlockReduceSweepByKeyPolicy::BLOCK_THREADS, BlockReduceSweepByKeyPolicy::SCAN_ALGORITHM>  BlockScanAllocations; 
# 201
typedef BlockScanLookbackPrefixOp< ItemOffsetPair< typename std::iterator_traits< ValuesInputIterator> ::value_type, Offset> , cub_::ReduceBySegmentOp< ReductionOp, ItemOffsetPair< typename std::iterator_traits< ValuesInputIterator> ::value_type, Offset> > , ReduceByKeyScanTileState< typename std::iterator_traits< ValuesInputIterator> ::value_type, Offset> >  LookbackPrefixCallbackOp; 
# 204
struct _TempStorage { 
# 208
union { 
# 210
struct { 
# 211
typename BlockScan< ItemOffsetPair< typename std::iterator_traits< ValuesInputIterator> ::value_type, Offset> , BlockReduceSweepByKeyPolicy::BLOCK_THREADS, BlockReduceSweepByKeyPolicy::SCAN_ALGORITHM> ::TempStorage scan; 
# 212
typename BlockScanLookbackPrefixOp< ItemOffsetPair< typename std::iterator_traits< ValuesInputIterator> ::value_type, Offset> , cub_::ReduceBySegmentOp< ReductionOp, ItemOffsetPair< typename std::iterator_traits< ValuesInputIterator> ::value_type, Offset> > , ReduceByKeyScanTileState< typename std::iterator_traits< ValuesInputIterator> ::value_type, Offset> > ::TempStorage prefix; 
# 213
typename BlockDiscontinuity< typename std::iterator_traits< KeysInputIterator> ::value_type, BLOCK_THREADS> ::TempStorage discontinuity; 
# 214
typename BlockLoad< typename If< IsPointer< KeysInputIterator> ::VALUE, CacheModifiedInputIterator< BlockReduceSweepByKeyPolicy::LOAD_MODIFIER, typename std::iterator_traits< KeysInputIterator> ::value_type, Offset> , KeysInputIterator> ::Type, BlockReduceSweepByKeyPolicy::BLOCK_THREADS, BlockReduceSweepByKeyPolicy::ITEMS_PER_THREAD, BlockReduceSweepByKeyPolicy::LOAD_ALGORITHM> ::TempStorage load_keys; 
# 216
Offset tile_idx; 
# 217
Offset tile_num_flags_prefix; 
# 218
}; 
# 221
typename BlockLoad< typename If< IsPointer< ValuesInputIterator> ::VALUE, CacheModifiedInputIterator< BlockReduceSweepByKeyPolicy::LOAD_MODIFIER, typename std::iterator_traits< ValuesInputIterator> ::value_type, Offset> , ValuesInputIterator> ::Type, BlockReduceSweepByKeyPolicy::BLOCK_THREADS, BlockReduceSweepByKeyPolicy::ITEMS_PER_THREAD, (IS_RUN_LENGTH_ENCODE) ? BLOCK_LOAD_DIRECT : ((BlockLoadAlgorithm)BlockReduceSweepByKeyPolicy::LOAD_ALGORITHM)> ::TempStorage load_values; 
# 224
typename BlockExchange< typename std::iterator_traits< ValuesInputIterator> ::value_type, BLOCK_THREADS, ITEMS_PER_THREAD> ::TempStorage exchange_values; 
# 227
typename BlockExchange< typename std::iterator_traits< KeysInputIterator> ::value_type, BLOCK_THREADS, ITEMS_PER_THREAD> ::TempStorage exchange_keys; 
# 228
}; 
# 230
}; 
# 233
struct TempStorage : public Uninitialized< _TempStorage>  { }; 
# 240
_TempStorage &temp_storage; 
# 242
WrappedKeysInputIterator d_keys_in; 
# 243
UniqueOutputIterator d_unique_out; 
# 245
WrappedValuesInputIterator d_values_in; 
# 246
AggregatesOutputIterator d_aggregates_out; 
# 248
InequalityWrapper< EqualityOp>  inequality_op; 
# 249
ReduceBySegmentOp scan_op; 
# 250
Offset num_items; 
# 258
__attribute((always_inline)) 
# 259
BlockReduceSweepByKey(TempStorage &
# 260
temp_storage, KeysInputIterator 
# 261
d_keys_in, UniqueOutputIterator 
# 262
d_unique_out, ValuesInputIterator 
# 263
d_values_in, AggregatesOutputIterator 
# 264
d_aggregates_out, EqualityOp 
# 265
equality_op, ReductionOp 
# 266
reduction_op, Offset 
# 267
num_items) : temp_storage((temp_storage.Alias())), d_keys_in(d_keys_in), d_unique_out(d_unique_out), d_values_in(d_values_in), d_aggregates_out(d_aggregates_out), inequality_op(equality_op), scan_op(reduction_op), num_items(num_items) 
# 277
{int *volatile ___ = 0;(void)temp_storage;(void)d_keys_in;(void)d_unique_out;(void)d_values_in;(void)d_aggregates_out;(void)equality_op;(void)reduction_op;(void)num_items;::free(___);}
#if 0
# 277
{ } 
#endif
# 287 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_reduce_by_key_sweep.cuh"
__attribute((always_inline)) void 
# 288
ScanBlock(ReductionOffsetPair (&
# 289
values_and_segments)[ITEMS_PER_THREAD], ReductionOffsetPair &
# 290
block_aggregate, Int2Type< 1>  
# 291
has_identity) 
# 292
{int volatile ___ = 1;(void)values_and_segments;(void)block_aggregate;(void)has_identity;
# 297
::exit(___);}
#if 0
# 292
{ 
# 293
ReductionOffsetPair identity; 
# 294
(identity.value) = 0; 
# 295
(identity.offset) = 0; 
# 296
(((BlockScanAllocations)(((temp_storage).scan))).ExclusiveScan(values_and_segments, values_and_segments, identity, scan_op, block_aggregate)); 
# 297
} 
#endif
# 303 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_reduce_by_key_sweep.cuh"
__attribute((always_inline)) void 
# 304
ScanBlock(ReductionOffsetPair (&
# 305
values_and_segments)[ITEMS_PER_THREAD], ReductionOffsetPair &
# 306
block_aggregate, Int2Type< 0>  
# 307
has_identity) 
# 308
{int volatile ___ = 1;(void)values_and_segments;(void)block_aggregate;(void)has_identity;
# 310
::exit(___);}
#if 0
# 308
{ 
# 309
(((BlockScanAllocations)(((temp_storage).scan))).ExclusiveScan(values_and_segments, values_and_segments, scan_op, block_aggregate)); 
# 310
} 
#endif
# 315 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_reduce_by_key_sweep.cuh"
__attribute((always_inline)) void 
# 316
ScanBlock(ReductionOffsetPair (&
# 317
values_and_segments)[ITEMS_PER_THREAD], ReductionOffsetPair &
# 318
block_aggregate, LookbackPrefixCallbackOp &
# 319
prefix_op, Int2Type< 1>  
# 320
has_identity) 
# 321
{int volatile ___ = 1;(void)values_and_segments;(void)block_aggregate;(void)prefix_op;(void)has_identity;
# 326
::exit(___);}
#if 0
# 321
{ 
# 322
ReductionOffsetPair identity; 
# 323
(identity.value) = 0; 
# 324
(identity.offset) = 0; 
# 325
(((BlockScanAllocations)(((temp_storage).scan))).ExclusiveScan(values_and_segments, values_and_segments, identity, scan_op, block_aggregate, prefix_op)); 
# 326
} 
#endif
# 331 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_reduce_by_key_sweep.cuh"
__attribute((always_inline)) void 
# 332
ScanBlock(ReductionOffsetPair (&
# 333
values_and_segments)[ITEMS_PER_THREAD], ReductionOffsetPair &
# 334
block_aggregate, LookbackPrefixCallbackOp &
# 335
prefix_op, Int2Type< 0>  
# 336
has_identity) 
# 337
{int volatile ___ = 1;(void)values_and_segments;(void)block_aggregate;(void)prefix_op;(void)has_identity;
# 339
::exit(___);}
#if 0
# 337
{ 
# 338
(((BlockScanAllocations)(((temp_storage).scan))).ExclusiveScan(values_and_segments, values_and_segments, scan_op, block_aggregate, prefix_op)); 
# 339
} 
#endif
# 346 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_reduce_by_key_sweep.cuh"
template< bool LAST_TILE> 
# 347
__attribute((always_inline)) void ZipValuesAndFlags(Offset 
# 348
num_remaining, Value (&
# 349
values)[ITEMS_PER_THREAD], Offset (&
# 350
flags)[ITEMS_PER_THREAD], ReductionOffsetPair (&
# 351
values_and_segments)[ITEMS_PER_THREAD]) 
# 352
{int volatile ___ = 1;(void)num_remaining;(void)values;(void)flags;(void)values_and_segments;
# 364
::exit(___);}
#if 0
# 352
{ 
# 355
#pragma unroll
for (
# 355
int ITEM = 0; ITEM < (ITEMS_PER_THREAD); ++ITEM) 
# 356
{ 
# 358
if (LAST_TILE && ((((Offset)((__device_builtin_variable_threadIdx.x) * (ITEMS_PER_THREAD))) + ITEM) >= num_remaining)) { 
# 359
((flags)[ITEM]) = 0; }  
# 361
(((values_and_segments)[ITEM]).value) = ((values)[ITEM]); 
# 362
(((values_and_segments)[ITEM]).offset) = ((flags)[ITEM]); 
# 363
}  
# 364
} 
#endif
# 382 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_reduce_by_key_sweep.cuh"
template< bool LAST_TILE, bool FIRST_TILE, int ITEM> 
# 383
__attribute((always_inline)) void ScatterDirect(Offset 
# 384
num_remaining, Key (&
# 385
keys)[ITEMS_PER_THREAD], ReductionOffsetPair (&
# 386
values_and_segments)[ITEMS_PER_THREAD], Offset (&
# 387
flags)[ITEMS_PER_THREAD], Offset 
# 388
tile_num_flags, Int2Type< ITEM>  
# 389
iteration) 
# 390
{int volatile ___ = 1;(void)num_remaining;(void)keys;(void)values_and_segments;(void)flags;(void)tile_num_flags;(void)iteration;
# 407
::exit(___);}
#if 0
# 390
{ 
# 392
if ((flags)[ITEM]) 
# 393
{ 
# 394
((d_unique_out)[((values_and_segments)[ITEM]).offset]) = ((keys)[ITEM]); 
# 395
}  
# 397
bool is_first_flag = FIRST_TILE && (ITEM == 0) && ((__device_builtin_variable_threadIdx.x) == (0)); 
# 398
bool is_oob_value = LAST_TILE && ((((Offset)((__device_builtin_variable_threadIdx.x) * (ITEMS_PER_THREAD))) + ITEM) == num_remaining); 
# 401
if ((((flags)[ITEM]) || is_oob_value) && (!is_first_flag)) 
# 402
{ 
# 403
((d_aggregates_out)[(((values_and_segments)[ITEM]).offset) - 1]) = (((values_and_segments)[ITEM]).value); 
# 404
}  
# 406
ScatterDirect< LAST_TILE, FIRST_TILE> (num_remaining, keys, values_and_segments, flags, tile_num_flags, Int2Type< ITEM + 1> ()); 
# 407
} 
#endif
# 409 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_reduce_by_key_sweep.cuh"
template< bool LAST_TILE, bool FIRST_TILE> 
# 410
__attribute((always_inline)) void ScatterDirect(Offset 
# 411
num_remaining, Key (&
# 412
keys)[ITEMS_PER_THREAD], ReductionOffsetPair (&
# 413
values_and_segments)[ITEMS_PER_THREAD], Offset (&
# 414
flags)[ITEMS_PER_THREAD], Offset 
# 415
tile_num_flags, Int2Type< ITEMS_PER_THREAD>  
# 416
iteration) 
# 417
{int volatile ___ = 1;(void)num_remaining;(void)keys;(void)values_and_segments;(void)flags;(void)tile_num_flags;(void)iteration;::exit(___);}
#if 0
# 417
{ } 
#endif
# 429 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_reduce_by_key_sweep.cuh"
template< bool LAST_TILE, bool FIRST_TILE> 
# 430
__attribute((always_inline)) void ScatterTwoPhase(Offset 
# 431
num_remaining, Key (&
# 432
keys)[ITEMS_PER_THREAD], ReductionOffsetPair (&
# 433
values_and_segments)[ITEMS_PER_THREAD], Offset (&
# 434
flags)[ITEMS_PER_THREAD], Offset 
# 435
tile_num_flags, Offset 
# 436
tile_num_flags_prefix) 
# 437
{int volatile ___ = 1;(void)num_remaining;(void)keys;(void)values_and_segments;(void)flags;(void)tile_num_flags;(void)tile_num_flags_prefix;
# 508
::exit(___);}
#if 0
# 437
{ 
# 438
int local_ranks[ITEMS_PER_THREAD]; 
# 439
Value values[ITEMS_PER_THREAD]; 
# 442
if ((__device_builtin_variable_threadIdx.x) == (0)) 
# 443
{ 
# 444
((temp_storage).tile_num_flags_prefix) = tile_num_flags_prefix; 
# 445
}  
# 447
__syncthreads(); 
# 450
tile_num_flags_prefix = ((temp_storage).tile_num_flags_prefix); 
# 452
__syncthreads(); 
# 456
#pragma unroll
for (
# 456
int ITEM = 0; ITEM < (ITEMS_PER_THREAD); ++ITEM) 
# 457
{ 
# 458
((local_ranks)[ITEM]) = ((((values_and_segments)[ITEM]).offset) - tile_num_flags_prefix); 
# 459
}  
# 462
(((BlockExchangeKeys)(((temp_storage).exchange_keys))).ScatterToStriped(keys, local_ranks, flags)); 
# 465
StoreDirectStriped< BLOCK_THREADS> (__device_builtin_variable_threadIdx.x, (d_unique_out) + tile_num_flags_prefix, keys, tile_num_flags); 
# 469
#pragma unroll
for (
# 469
int ITEM = 0; ITEM < (ITEMS_PER_THREAD); ++ITEM) 
# 470
{ 
# 471
((values)[ITEM]) = (((values_and_segments)[ITEM]).value); 
# 473
if (FIRST_TILE) { 
# 474
((local_ranks)[ITEM])--; }  
# 476
if (LAST_TILE && ((((Offset)((__device_builtin_variable_threadIdx.x) * (ITEMS_PER_THREAD))) + ITEM) == num_remaining)) { 
# 477
((flags)[ITEM]) = 1; }  
# 478
}  
# 481
if (FIRST_TILE && ((__device_builtin_variable_threadIdx.x) == (0))) { 
# 482
((flags)[0]) = 0; }  
# 484
__syncthreads(); 
# 487
(((BlockExchangeValues)(((temp_storage).exchange_values))).ScatterToStriped(values, local_ranks, flags)); 
# 490
Offset exchange_count = tile_num_flags; 
# 492
if (LAST_TILE && (num_remaining < (TILE_ITEMS))) { 
# 493
exchange_count++; }  
# 495
if (FIRST_TILE) 
# 496
{ 
# 497
exchange_count--; 
# 498
} else 
# 500
{ 
# 501
tile_num_flags_prefix--; 
# 502
}  
# 505
StoreDirectStriped< BLOCK_THREADS> (__device_builtin_variable_threadIdx.x, (d_aggregates_out) + tile_num_flags_prefix, values, exchange_count); 
# 507
__syncthreads(); 
# 508
} 
#endif
# 514 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_reduce_by_key_sweep.cuh"
template< bool LAST_TILE, bool FIRST_TILE> 
# 515
__attribute((always_inline)) void Scatter(Offset 
# 516
num_remaining, Key (&
# 517
keys)[ITEMS_PER_THREAD], ReductionOffsetPair (&
# 518
values_and_segments)[ITEMS_PER_THREAD], Offset (&
# 519
flags)[ITEMS_PER_THREAD], Offset 
# 520
tile_num_flags, Offset 
# 521
tile_num_flags_prefix) 
# 522
{int volatile ___ = 1;(void)num_remaining;(void)keys;(void)values_and_segments;(void)flags;(void)tile_num_flags;(void)tile_num_flags_prefix;
# 544
::exit(___);}
#if 0
# 522
{ 
# 524
if ((TWO_PHASE_SCATTER) && (tile_num_flags > (BLOCK_THREADS))) 
# 525
{ 
# 526
ScatterTwoPhase< LAST_TILE, FIRST_TILE> (num_remaining, keys, values_and_segments, flags, tile_num_flags, tile_num_flags_prefix); 
# 533
} else 
# 535
{ 
# 536
ScatterDirect< LAST_TILE, FIRST_TILE> (num_remaining, keys, values_and_segments, flags, tile_num_flags, Int2Type< 0> ()); 
# 543
}  
# 544
} 
#endif
# 554 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_reduce_by_key_sweep.cuh"
template< bool 
# 555
LAST_TILE> 
# 556
__attribute((always_inline)) ReductionOffsetPair ConsumeTile(Offset 
# 557
num_items, Offset 
# 558
num_remaining, int 
# 559
tile_idx, Offset 
# 560
block_offset, ScanTileState &
# 561
tile_status) 
# 562
{int volatile ___ = 1;(void)num_items;(void)num_remaining;(void)tile_idx;(void)block_offset;(void)tile_status;
# 647
::exit(___);}
#if 0
# 562
{ 
# 563
Key keys[ITEMS_PER_THREAD]; 
# 564
Value values[ITEMS_PER_THREAD]; 
# 565
Offset flags[ITEMS_PER_THREAD]; 
# 566
ReductionOffsetPair values_and_segments[ITEMS_PER_THREAD]; 
# 567
ReductionOffsetPair running_total; 
# 570
if (LAST_TILE) { 
# 571
(((BlockLoadKeys)(((temp_storage).load_keys))).Load((d_keys_in) + block_offset, keys, num_remaining)); } else { 
# 573
(((BlockLoadKeys)(((temp_storage).load_keys))).Load((d_keys_in) + block_offset, keys)); }  
# 575
if (tile_idx == 0) 
# 576
{ 
# 578
__syncthreads(); 
# 581
if (LAST_TILE) { 
# 582
(((BlockLoadValues)(((temp_storage).load_values))).Load((d_values_in) + block_offset, values, num_remaining)); } else { 
# 584
(((BlockLoadValues)(((temp_storage).load_values))).Load((d_values_in) + block_offset, values)); }  
# 586
__syncthreads(); 
# 589
(((BlockDiscontinuityKeys)(((temp_storage).discontinuity))).FlagHeads(flags, keys, inequality_op)); 
# 592
ZipValuesAndFlags< LAST_TILE> (num_remaining, values, flags, values_and_segments); 
# 595
ReductionOffsetPair block_aggregate; 
# 596
ScanBlock(values_and_segments, block_aggregate, Int2Type< HAS_IDENTITY_ZERO> ()); 
# 599
if ((!LAST_TILE) && ((__device_builtin_variable_threadIdx.x) == (0))) { 
# 600
(tile_status.SetInclusive(0, block_aggregate)); }  
# 603
if ((!(HAS_IDENTITY_ZERO)) && ((__device_builtin_variable_threadIdx.x) == (0))) { 
# 604
(((values_and_segments)[0]).offset) = 0; }  
# 606
running_total = block_aggregate; 
# 609
Scatter< LAST_TILE, true> (num_remaining, keys, values_and_segments, flags, (block_aggregate.offset), 0); 
# 610
} else 
# 612
{ 
# 615
Key tile_predecessor_key = ((__device_builtin_variable_threadIdx.x) == (0)) ? (d_keys_in)[block_offset - 1] : ZeroInitialize< Key> (); 
# 619
__syncthreads(); 
# 622
if (LAST_TILE) { 
# 623
(((BlockLoadValues)(((temp_storage).load_values))).Load((d_values_in) + block_offset, values, num_remaining)); } else { 
# 625
(((BlockLoadValues)(((temp_storage).load_values))).Load((d_values_in) + block_offset, values)); }  
# 627
__syncthreads(); 
# 630
(((BlockDiscontinuityKeys)(((temp_storage).discontinuity))).FlagHeads(flags, keys, inequality_op, tile_predecessor_key)); 
# 633
ZipValuesAndFlags< LAST_TILE> (num_remaining, values, flags, values_and_segments); 
# 636
ReductionOffsetPair block_aggregate; 
# 637
LookbackPrefixCallbackOp prefix_op(tile_status, ((temp_storage).prefix), scan_op, tile_idx); 
# 639
ScanBlock(values_and_segments, block_aggregate, prefix_op, Int2Type< HAS_IDENTITY_ZERO> ()); 
# 640
running_total = (prefix_op.inclusive_prefix); 
# 643
Scatter< LAST_TILE, false> (num_remaining, keys, values_and_segments, flags, (block_aggregate.offset), ((prefix_op.exclusive_prefix).offset)); 
# 644
}  
# 646
return running_total; 
# 647
} 
#endif
# 653 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_reduce_by_key_sweep.cuh"
template< class NumRunsIterator> 
# 654
__attribute((always_inline)) void ConsumeRange(int 
# 655
num_tiles, GridQueue< int>  
# 656
queue, ScanTileState &
# 657
tile_status, NumRunsIterator 
# 658
d_num_runs_out) 
# 659
{int volatile ___ = 1;(void)num_tiles;(void)queue;(void)tile_status;(void)d_num_runs_out;
# 736
::exit(___);}
#if 0
# 659
{ 
# 663
int tile_idx = (((__device_builtin_variable_blockIdx.y) * (32)) * (1024)) + (__device_builtin_variable_blockIdx.x); 
# 664
Offset block_offset = ((Offset)(TILE_ITEMS)) * tile_idx; 
# 665
Offset num_remaining = (num_items) - block_offset; 
# 667
if (num_remaining > (TILE_ITEMS)) 
# 668
{ 
# 670
ConsumeTile< false> (num_items, num_remaining, tile_idx, block_offset, tile_status); 
# 671
} else { 
# 672
if (num_remaining > 0) 
# 673
{ 
# 675
ReductionOffsetPair running_total = ConsumeTile< true> (num_items, num_remaining, tile_idx, block_offset, tile_status); 
# 678
if ((__device_builtin_variable_threadIdx.x) == (0)) 
# 679
{ 
# 680
(*d_num_runs_out) = (running_total.offset); 
# 683
if (num_remaining == (TILE_ITEMS)) 
# 684
{ 
# 685
((d_aggregates_out)[(running_total.offset) - 1]) = (running_total.value); 
# 686
}  
# 687
}  
# 688
}  }  
# 736
} 
#endif
# 738 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/../../block_sweep/block_reduce_by_key_sweep.cuh"
}; 
# 741
}
# 742
}}}}
# 48 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_reduce_by_key_dispatch.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 51
namespace cub_ { 
# 60
template< class 
# 61
BlockReduceSweepByKeyPolicy, class 
# 62
KeysInputIterator, class 
# 63
UniqueOutputIterator, class 
# 64
ValuesInputIterator, class 
# 65
AggregatesOutputIterator, class 
# 66
NumRunsOutputIterator, class 
# 67
ScanTileState, class 
# 68
EqualityOp, class 
# 69
ReductionOp, class 
# 70
Offset> static void 
# 72
__wrapper__device_stub_DeviceReduceByKeySweepKernel(KeysInputIterator &
# 73
d_keys_in, UniqueOutputIterator &
# 74
d_unique_out, ValuesInputIterator &
# 75
d_values_in, AggregatesOutputIterator &
# 76
d_aggregates_out, NumRunsOutputIterator &
# 77
d_num_runs_out, ScanTileState &
# 78
tile_status, EqualityOp &
# 79
equality_op, ReductionOp &
# 80
reduction_op, Offset &
# 81
num_items, int &
# 82
num_tiles, GridQueue< int>  &
# 83
queue) {exit(1);}
#if 0
# 84
{ 
# 94
typedef BlockReduceSweepByKey< BlockReduceSweepByKeyPolicy, KeysInputIterator, UniqueOutputIterator, ValuesInputIterator, AggregatesOutputIterator, EqualityOp, ReductionOp, Offset>  BlockReduceSweepByKeyT; 
# 97
__attribute__((unused)) static typename BlockReduceSweepByKey< BlockReduceSweepByKeyPolicy, KeysInputIterator, UniqueOutputIterator, ValuesInputIterator, AggregatesOutputIterator, EqualityOp, ReductionOp, Offset> ::TempStorage temp_storage; 
# 100
(BlockReduceSweepByKeyT(temp_storage, d_keys_in, d_unique_out, d_values_in, d_aggregates_out, equality_op, reduction_op, num_items).ConsumeRange(num_tiles, queue, tile_status, d_num_runs_out)); 
# 105
} 
#endif
# 60 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_reduce_by_key_dispatch.cuh"
template< class 
# 61
BlockReduceSweepByKeyPolicy, class 
# 62
KeysInputIterator, class 
# 63
UniqueOutputIterator, class 
# 64
ValuesInputIterator, class 
# 65
AggregatesOutputIterator, class 
# 66
NumRunsOutputIterator, class 
# 67
ScanTileState, class 
# 68
EqualityOp, class 
# 69
ReductionOp, class 
# 70
Offset> void 
# 72
DeviceReduceByKeySweepKernel(KeysInputIterator 
# 73
d_keys_in, UniqueOutputIterator 
# 74
d_unique_out, ValuesInputIterator 
# 75
d_values_in, AggregatesOutputIterator 
# 76
d_aggregates_out, NumRunsOutputIterator 
# 77
d_num_runs_out, ScanTileState 
# 78
tile_status, EqualityOp 
# 79
equality_op, ReductionOp 
# 80
reduction_op, Offset 
# 81
num_items, int 
# 82
num_tiles, GridQueue< int>  
# 83
queue) 
# 84
{__wrapper__device_stub_DeviceReduceByKeySweepKernel<BlockReduceSweepByKeyPolicy,KeysInputIterator,UniqueOutputIterator,ValuesInputIterator,AggregatesOutputIterator,NumRunsOutputIterator,ScanTileState,EqualityOp,ReductionOp,Offset>(d_keys_in,d_unique_out,d_values_in,d_aggregates_out,d_num_runs_out,tile_status,equality_op,reduction_op,num_items,num_tiles,queue);
# 105
return;}
#if 0
# 84
{ 
# 94
typedef BlockReduceSweepByKey< BlockReduceSweepByKeyPolicy, KeysInputIterator, UniqueOutputIterator, ValuesInputIterator, AggregatesOutputIterator, EqualityOp, ReductionOp, Offset>  BlockReduceSweepByKeyT; 
# 97
__attribute__((unused)) static typename BlockReduceSweepByKey< BlockReduceSweepByKeyPolicy, KeysInputIterator, UniqueOutputIterator, ValuesInputIterator, AggregatesOutputIterator, EqualityOp, ReductionOp, Offset> ::TempStorage temp_storage; 
# 100
(BlockReduceSweepByKeyT(temp_storage, d_keys_in, d_unique_out, d_values_in, d_aggregates_out, equality_op, reduction_op, num_items).ConsumeRange(num_tiles, queue, tile_status, d_num_runs_out)); 
# 105
} 
#endif
# 117 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_reduce_by_key_dispatch.cuh"
template< class 
# 118
KeysInputIterator, class 
# 119
UniqueOutputIterator, class 
# 120
ValuesInputIterator, class 
# 121
AggregatesOutputIterator, class 
# 122
NumRunsOutputIterator, class 
# 123
EqualityOp, class 
# 124
ReductionOp, class 
# 125
Offset> 
# 126
struct DeviceReduceByKeyDispatch { 
# 133
typedef typename std::iterator_traits< KeysInputIterator> ::value_type Key; 
# 136
typedef typename std::iterator_traits< ValuesInputIterator> ::value_type Value; 
# 139
enum { 
# 140
INIT_KERNEL_THREADS = 128, 
# 141
MAX_INPUT_BYTES = (sizeof(Value) > sizeof(Key)) ? sizeof(Value) : sizeof(Key), 
# 142
COMBINED_INPUT_BYTES = sizeof(Key) + sizeof(Value)
# 143
}; 
# 146
typedef ReduceByKeyScanTileState< typename std::iterator_traits< ValuesInputIterator> ::value_type, Offset>  ScanTileState; 
# 154
struct Policy350 { 
# 156
enum { 
# 157
NOMINAL_4B_ITEMS_PER_THREAD = 8, 
# 158
ITEMS_PER_THREAD = (((sizeof(Value) > sizeof(Key)) ? sizeof(Value) : sizeof(Key)) <= 8) ? 8 : (((((((((8) * 8) + (sizeof(Key) + sizeof(Value))) - 1) / (sizeof(Key) + sizeof(Value))) > 1) ? ((((8) * 8) + (sizeof(Key) + sizeof(Value))) - 1) / (sizeof(Key) + sizeof(Value)) : 1) < (8)) ? ((((((8) * 8) + (sizeof(Key) + sizeof(Value))) - 1) / (sizeof(Key) + sizeof(Value))) > 1) ? ((((8) * 8) + (sizeof(Key) + sizeof(Value))) - 1) / (sizeof(Key) + sizeof(Value)) : 1 : (8))
# 159
}; 
# 168
typedef BlockReduceSweepByKeyPolicy< 128, (ITEMS_PER_THREAD), BLOCK_LOAD_DIRECT, LOAD_LDG, true, BLOCK_SCAN_WARP_SCANS>  ReduceByKeyPolicy; 
# 169
}; 
# 172
struct Policy300 { 
# 174
enum { 
# 175
NOMINAL_4B_ITEMS_PER_THREAD = 6, 
# 176
ITEMS_PER_THREAD = ((((((((6) * 8) + (sizeof(Key) + sizeof(Value))) - 1) / (sizeof(Key) + sizeof(Value))) > 1) ? ((((6) * 8) + (sizeof(Key) + sizeof(Value))) - 1) / (sizeof(Key) + sizeof(Value)) : 1) < (6)) ? ((((((6) * 8) + (sizeof(Key) + sizeof(Value))) - 1) / (sizeof(Key) + sizeof(Value))) > 1) ? ((((6) * 8) + (sizeof(Key) + sizeof(Value))) - 1) / (sizeof(Key) + sizeof(Value)) : 1 : (6)
# 177
}; 
# 186
typedef BlockReduceSweepByKeyPolicy< 128, (ITEMS_PER_THREAD), BLOCK_LOAD_WARP_TRANSPOSE, LOAD_DEFAULT, true, BLOCK_SCAN_WARP_SCANS>  ReduceByKeyPolicy; 
# 187
}; 
# 190
struct Policy200 { 
# 192
enum { 
# 193
NOMINAL_4B_ITEMS_PER_THREAD = 13, 
# 194
ITEMS_PER_THREAD = ((((((((13) * 8) + (sizeof(Key) + sizeof(Value))) - 1) / (sizeof(Key) + sizeof(Value))) > 1) ? ((((13) * 8) + (sizeof(Key) + sizeof(Value))) - 1) / (sizeof(Key) + sizeof(Value)) : 1) < (13)) ? ((((((13) * 8) + (sizeof(Key) + sizeof(Value))) - 1) / (sizeof(Key) + sizeof(Value))) > 1) ? ((((13) * 8) + (sizeof(Key) + sizeof(Value))) - 1) / (sizeof(Key) + sizeof(Value)) : 1 : (13)
# 195
}; 
# 204
typedef BlockReduceSweepByKeyPolicy< 128, (ITEMS_PER_THREAD), BLOCK_LOAD_WARP_TRANSPOSE, LOAD_DEFAULT, true, BLOCK_SCAN_WARP_SCANS>  ReduceByKeyPolicy; 
# 205
}; 
# 208
struct Policy130 { 
# 210
enum { 
# 211
NOMINAL_4B_ITEMS_PER_THREAD = 7, 
# 212
ITEMS_PER_THREAD = ((((((((7) * 8) + (sizeof(Key) + sizeof(Value))) - 1) / (sizeof(Key) + sizeof(Value))) > 1) ? ((((7) * 8) + (sizeof(Key) + sizeof(Value))) - 1) / (sizeof(Key) + sizeof(Value)) : 1) < (7)) ? ((((((7) * 8) + (sizeof(Key) + sizeof(Value))) - 1) / (sizeof(Key) + sizeof(Value))) > 1) ? ((((7) * 8) + (sizeof(Key) + sizeof(Value))) - 1) / (sizeof(Key) + sizeof(Value)) : 1 : (7)
# 213
}; 
# 222
typedef BlockReduceSweepByKeyPolicy< 128, (ITEMS_PER_THREAD), BLOCK_LOAD_WARP_TRANSPOSE, LOAD_DEFAULT, true, BLOCK_SCAN_WARP_SCANS>  ReduceByKeyPolicy; 
# 223
}; 
# 226
struct Policy100 { 
# 228
enum { 
# 229
NOMINAL_4B_ITEMS_PER_THREAD = 5, 
# 230
ITEMS_PER_THREAD = ((((((5) * 8) / (sizeof(Key) + sizeof(Value))) > 1) ? ((5) * 8) / (sizeof(Key) + sizeof(Value)) : 1) < (5)) ? ((((5) * 8) / (sizeof(Key) + sizeof(Value))) > 1) ? ((5) * 8) / (sizeof(Key) + sizeof(Value)) : 1 : (5)
# 231
}; 
# 240
typedef BlockReduceSweepByKeyPolicy< 64, (ITEMS_PER_THREAD), BLOCK_LOAD_WARP_TRANSPOSE, LOAD_DEFAULT, true, BLOCK_SCAN_RAKING>  ReduceByKeyPolicy; 
# 241
}; 
# 261
typedef Policy100 PtxPolicy; 
# 266
struct PtxReduceByKeyPolicy : public Policy100::ReduceByKeyPolicy { }; 
# 276
template< class KernelConfig> 
# 277
__attribute((always_inline)) static void 
# 278
InitConfigs(int 
# 279
ptx_version, KernelConfig &
# 280
device_reduce_by_key_sweep_config) 
# 281
{ 
# 290
if (ptx_version >= 350) 
# 291
{ 
# 292
(device_reduce_by_key_sweep_config.template Init< typename Policy350::ReduceByKeyPolicy> ()); 
# 293
} else { 
# 294
if (ptx_version >= 300) 
# 295
{ 
# 296
(device_reduce_by_key_sweep_config.template Init< typename Policy300::ReduceByKeyPolicy> ()); 
# 297
} else { 
# 298
if (ptx_version >= 200) 
# 299
{ 
# 300
(device_reduce_by_key_sweep_config.template Init< typename Policy200::ReduceByKeyPolicy> ()); 
# 301
} else { 
# 302
if (ptx_version >= 130) 
# 303
{ 
# 304
(device_reduce_by_key_sweep_config.template Init< typename Policy130::ReduceByKeyPolicy> ()); 
# 305
} else 
# 307
{ 
# 308
(device_reduce_by_key_sweep_config.template Init< typename Policy100::ReduceByKeyPolicy> ()); 
# 309
}  }  }  }  
# 312
} 
# 318
struct KernelConfig { 
# 320
int block_threads; 
# 321
int items_per_thread; 
# 322
BlockLoadAlgorithm load_policy; 
# 323
bool two_phase_scatter; 
# 324
BlockScanAlgorithm scan_algorithm; 
# 325
cudaSharedMemConfig smem_config; 
# 327
template< class BlockReduceSweepByKeyPolicy> 
# 328
__attribute((always_inline)) void 
# 329
Init() 
# 330
{ 
# 331
(block_threads) = BlockReduceSweepByKeyPolicy::BLOCK_THREADS; 
# 332
(items_per_thread) = BlockReduceSweepByKeyPolicy::ITEMS_PER_THREAD; 
# 333
(load_policy) = BlockReduceSweepByKeyPolicy::LOAD_ALGORITHM; 
# 334
(two_phase_scatter) = BlockReduceSweepByKeyPolicy::TWO_PHASE_SCATTER; 
# 335
(scan_algorithm) = BlockReduceSweepByKeyPolicy::SCAN_ALGORITHM; 
# 336
(smem_config) = cudaSharedMemBankSizeEightByte; 
# 337
} 
# 339
__attribute((always_inline)) void 
# 340
Print() 
# 341
{ 
# 342
printf("%d, %d, %d, %d, %d, %d", block_threads, items_per_thread, load_policy, two_phase_scatter, scan_algorithm, smem_config); 
# 349
} 
# 350
}; 
# 361
template< class 
# 362
DeviceScanInitKernelPtr, class 
# 363
DeviceReduceByKeySweepKernelPtr> 
# 364
__attribute((always_inline)) static cudaError_t 
# 365
Dispatch(void *
# 366
d_temp_storage, size_t &
# 367
temp_storage_bytes, KeysInputIterator 
# 368
d_keys_in, UniqueOutputIterator 
# 369
d_unique_out, ValuesInputIterator 
# 370
d_values_in, AggregatesOutputIterator 
# 371
d_aggregates_out, NumRunsOutputIterator 
# 372
d_num_runs_out, EqualityOp 
# 373
equality_op, ReductionOp 
# 374
reduction_op, Offset 
# 375
num_items, cudaStream_t 
# 376
stream, bool 
# 377
debug_synchronous, int 
# 378
ptx_version, DeviceScanInitKernelPtr 
# 379
device_scan_init_kernel, DeviceReduceByKeySweepKernelPtr 
# 380
range_reduce_by_key_kernel, KernelConfig 
# 381
device_reduce_by_key_sweep_config) 
# 382
{ 
# 391
cudaError error = cudaSuccess; 
# 392
do 
# 393
{ 
# 395
int device_ordinal; 
# 396
if (cub_::Debug(error = cudaGetDevice(&device_ordinal), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_reduce_by_key_dispatch.cuh", 396)) { break; }  
# 399
int sm_version; 
# 400
if (cub_::Debug(error = SmVersion(sm_version, device_ordinal), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_reduce_by_key_dispatch.cuh", 400)) { break; }  
# 403
int sm_count; 
# 404
if (cub_::Debug(error = cudaDeviceGetAttribute(&sm_count, cudaDevAttrMultiProcessorCount, device_ordinal), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_reduce_by_key_dispatch.cuh", 404)) { break; }  
# 407
int tile_size = (device_reduce_by_key_sweep_config.block_threads) * (device_reduce_by_key_sweep_config.items_per_thread); 
# 408
int num_tiles = ((num_items + tile_size) - 1) / tile_size; 
# 411
size_t allocation_sizes[2]; 
# 412
if (cub_::Debug(error = ScanTileState::AllocationSize(num_tiles, (allocation_sizes)[0]), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_reduce_by_key_dispatch.cuh", 412)) { break; }  
# 413
((allocation_sizes)[1]) = GridQueue< int> ::AllocationSize(); 
# 416
void *allocations[2]; 
# 417
if (cub_::Debug(error = AliasTemporaries(d_temp_storage, temp_storage_bytes, allocations, allocation_sizes), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_reduce_by_key_dispatch.cuh", 417)) { break; }  
# 418
if (d_temp_storage == (__null)) 
# 419
{ 
# 421
return cudaSuccess; 
# 422
}  
# 425
ScanTileState tile_status; 
# 426
if (cub_::Debug(error = (tile_status.Init(num_tiles, (allocations)[0], (allocation_sizes)[0])), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_reduce_by_key_dispatch.cuh", 426)) { break; }  
# 429
GridQueue< int>  queue((allocations)[1]); 
# 432
int init_grid_size = ((num_tiles + (INIT_KERNEL_THREADS)) - 1) / (INIT_KERNEL_THREADS); 
# 433
if (debug_synchronous) { printf("Invoking device_scan_init_kernel<<<%d, %d, 0, %lld>>>()\n", init_grid_size, INIT_KERNEL_THREADS, (long long)stream); }  ; 
# 436
(cudaConfigureCall(init_grid_size, INIT_KERNEL_THREADS, 0, stream)) ? (void)0 : device_scan_init_kernel(queue, tile_status, num_tiles); 
# 442
if (cub_::Debug(error = cudaPeekAtLastError(), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_reduce_by_key_dispatch.cuh", 442)) { break; }  
# 445
if (debug_synchronous && (cub_::Debug(error = SyncStream(stream), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_reduce_by_key_dispatch.cuh", 445))) { break; }  
# 448
int range_reduce_by_key_sm_occupancy; 
# 449
if (cub_::Debug(error = MaxSmOccupancy(range_reduce_by_key_sm_occupancy, sm_version, range_reduce_by_key_kernel, (device_reduce_by_key_sweep_config.block_threads)), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_reduce_by_key_dispatch.cuh", 453)) { 
# 453
break; }  
# 456
dim3 reduce_by_key_grid_size; 
# 457
if (ptx_version <= 130) 
# 458
{ 
# 460
int max_dim_x = (32 * 1024); 
# 461
(reduce_by_key_grid_size.z) = (1); 
# 462
(reduce_by_key_grid_size.y) = (((num_tiles + max_dim_x) - 1) / max_dim_x); 
# 463
(reduce_by_key_grid_size.x) = ((max_dim_x < num_tiles) ? max_dim_x : num_tiles); 
# 464
} else 
# 466
{ 
# 468
int range_reduce_by_key_occupancy = range_reduce_by_key_sm_occupancy * sm_count; 
# 469
(reduce_by_key_grid_size.z) = (1); 
# 470
(reduce_by_key_grid_size.y) = (1); 
# 471
(reduce_by_key_grid_size.x) = ((num_tiles < range_reduce_by_key_occupancy) ? num_tiles : range_reduce_by_key_occupancy); 
# 474
}  
# 478
cudaSharedMemConfig original_smem_config; 
# 479
if (cub_::Debug(error = cudaDeviceGetSharedMemConfig(&original_smem_config), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_reduce_by_key_dispatch.cuh", 479)) { break; }  
# 480
cudaSharedMemConfig current_smem_config = original_smem_config; 
# 483
if (current_smem_config != (device_reduce_by_key_sweep_config.smem_config)) 
# 484
{ 
# 485
if (cub_::Debug(error = cudaDeviceSetSharedMemConfig((device_reduce_by_key_sweep_config.smem_config)), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_reduce_by_key_dispatch.cuh", 485)) { break; }  
# 486
current_smem_config = (device_reduce_by_key_sweep_config.smem_config); 
# 487
}  
# 491
if (debug_synchronous) { printf("Invoking range_reduce_by_key_kernel<<<{%d,%d,%d}, %d, 0, %lld>>>(), %d items per thread, %d SM occupancy\n", reduce_by_key_grid_size.x, reduce_by_key_grid_size.y, reduce_by_key_grid_size.z, (device_reduce_by_key_sweep_config.block_threads), (long long)stream, (device_reduce_by_key_sweep_config.items_per_thread), range_reduce_by_key_sm_occupancy); }  
# 492
; 
# 495
(cudaConfigureCall(reduce_by_key_grid_size, ((device_reduce_by_key_sweep_config.block_threads)), 0, stream)) ? (void)0 : range_reduce_by_key_kernel(d_keys_in, d_unique_out, d_values_in, d_aggregates_out, d_num_runs_out, tile_status, equality_op, reduction_op, num_items, num_tiles, queue); 
# 509
if (cub_::Debug(error = cudaPeekAtLastError(), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_reduce_by_key_dispatch.cuh", 509)) { break; }  
# 512
if (debug_synchronous && (cub_::Debug(error = SyncStream(stream), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_reduce_by_key_dispatch.cuh", 512))) { break; }  
# 516
if (current_smem_config != original_smem_config) 
# 517
{ 
# 518
if (cub_::Debug(error = cudaDeviceSetSharedMemConfig(original_smem_config), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_reduce_by_key_dispatch.cuh", 518)) { break; }  
# 519
}  
# 522
} 
# 523
while (0); 
# 525
return error; 
# 528
} 
# 534
__attribute((always_inline)) static cudaError_t 
# 535
Dispatch(void *
# 536
d_temp_storage, size_t &
# 537
temp_storage_bytes, KeysInputIterator 
# 538
d_keys_in, UniqueOutputIterator 
# 539
d_unique_out, ValuesInputIterator 
# 540
d_values_in, AggregatesOutputIterator 
# 541
d_aggregates_out, NumRunsOutputIterator 
# 542
d_num_runs_out, EqualityOp 
# 543
equality_op, ReductionOp 
# 544
reduction_op, Offset 
# 545
num_items, cudaStream_t 
# 546
stream, bool 
# 547
debug_synchronous) 
# 548
{ 
# 549
cudaError error = cudaSuccess; 
# 550
do 
# 551
{ 
# 553
int ptx_version; 
# 555
if (cub_::Debug(error = PtxVersion(ptx_version), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_reduce_by_key_dispatch.cuh", 555)) { break; }  
# 561
KernelConfig device_reduce_by_key_sweep_config; 
# 562
InitConfigs(ptx_version, device_reduce_by_key_sweep_config); 
# 565
if (cub_::Debug(error = Dispatch(d_temp_storage, temp_storage_bytes, d_keys_in, d_unique_out, d_values_in, d_aggregates_out, d_num_runs_out, equality_op, reduction_op, num_items, stream, debug_synchronous, ptx_version, DeviceScanInitKernel< Offset, ScanTileState> , DeviceReduceByKeySweepKernel< PtxReduceByKeyPolicy, KeysInputIterator, UniqueOutputIterator, ValuesInputIterator, AggregatesOutputIterator, NumRunsOutputIterator, ScanTileState, EqualityOp, ReductionOp, Offset> , device_reduce_by_key_sweep_config), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/dispatch/device_reduce_by_key_dispatch.cuh", 581)) { 
# 581
break; }  
# 582
} 
# 583
while (0); 
# 585
return error; 
# 586
} 
# 587
}; 
# 589
}
# 590
}}}}
# 45 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/device_reduce.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 48
namespace cub_ { 
# 82
struct DeviceReduce { 
# 137
template< class 
# 138
InputIterator, class 
# 139
OutputIterator, class 
# 140
ReductionOp> static cudaError_t 
# 142
Reduce(void *
# 143
d_temp_storage, size_t &
# 144
temp_storage_bytes, InputIterator 
# 145
d_in, OutputIterator 
# 146
d_out, int 
# 147
num_items, ReductionOp 
# 148
reduction_op, cudaStream_t 
# 149
stream = 0, bool 
# 150
debug_synchronous = false) 
# 151
{ 
# 153
typedef int Offset; 
# 156
typedef cub_::DeviceReduceDispatch< InputIterator, OutputIterator, int, ReductionOp>  DeviceReduceDispatch; 
# 158
return DeviceReduceDispatch::Dispatch(d_temp_storage, temp_storage_bytes, d_in, d_out, num_items, reduction_op, stream, debug_synchronous); 
# 167
} 
# 215
template< class 
# 216
InputIterator, class 
# 217
OutputIterator> static cudaError_t 
# 219
Sum(void *
# 220
d_temp_storage, size_t &
# 221
temp_storage_bytes, InputIterator 
# 222
d_in, OutputIterator 
# 223
d_out, int 
# 224
num_items, cudaStream_t 
# 225
stream = 0, bool 
# 226
debug_synchronous = false) 
# 227
{ 
# 229
typedef int Offset; 
# 232
typedef cub_::DeviceReduceDispatch< InputIterator, OutputIterator, int, cub_::Sum>  DeviceReduceDispatch; 
# 234
return DeviceReduceDispatch::Dispatch(d_temp_storage, temp_storage_bytes, d_in, d_out, num_items, cub_::Sum(), stream, debug_synchronous); 
# 243
} 
# 287
template< class 
# 288
InputIterator, class 
# 289
OutputIterator> static cudaError_t 
# 291
Min(void *
# 292
d_temp_storage, size_t &
# 293
temp_storage_bytes, InputIterator 
# 294
d_in, OutputIterator 
# 295
d_out, int 
# 296
num_items, cudaStream_t 
# 297
stream = 0, bool 
# 298
debug_synchronous = false) 
# 299
{ 
# 301
typedef int Offset; 
# 304
typedef cub_::DeviceReduceDispatch< InputIterator, OutputIterator, int, cub_::Min>  DeviceReduceDispatch; 
# 306
return DeviceReduceDispatch::Dispatch(d_temp_storage, temp_storage_bytes, d_in, d_out, num_items, cub_::Min(), stream, debug_synchronous); 
# 315
} 
# 364
template< class 
# 365
InputIterator, class 
# 366
OutputIterator> static cudaError_t 
# 368
ArgMin(void *
# 369
d_temp_storage, size_t &
# 370
temp_storage_bytes, InputIterator 
# 371
d_in, OutputIterator 
# 372
d_out, int 
# 373
num_items, cudaStream_t 
# 374
stream = 0, bool 
# 375
debug_synchronous = false) 
# 376
{ 
# 378
typedef int Offset; 
# 381
typedef cub_::ArgIndexInputIterator< InputIterator, int>  ArgIndexInputIterator; 
# 382
ArgIndexInputIterator d_argmin_in(d_in, 0); 
# 385
typedef cub_::DeviceReduceDispatch< cub_::ArgIndexInputIterator< InputIterator, int> , OutputIterator, int, cub_::ArgMin>  DeviceReduceDispatch; 
# 387
return DeviceReduceDispatch::Dispatch(d_temp_storage, temp_storage_bytes, d_argmin_in, d_out, num_items, cub_::ArgMin(), stream, debug_synchronous); 
# 396
} 
# 440
template< class 
# 441
InputIterator, class 
# 442
OutputIterator> static cudaError_t 
# 444
Max(void *
# 445
d_temp_storage, size_t &
# 446
temp_storage_bytes, InputIterator 
# 447
d_in, OutputIterator 
# 448
d_out, int 
# 449
num_items, cudaStream_t 
# 450
stream = 0, bool 
# 451
debug_synchronous = false) 
# 452
{ 
# 454
typedef int Offset; 
# 457
typedef cub_::DeviceReduceDispatch< InputIterator, OutputIterator, int, cub_::Max>  DeviceReduceDispatch; 
# 459
return DeviceReduceDispatch::Dispatch(d_temp_storage, temp_storage_bytes, d_in, d_out, num_items, cub_::Max(), stream, debug_synchronous); 
# 468
} 
# 517
template< class 
# 518
InputIterator, class 
# 519
OutputIterator> static cudaError_t 
# 521
ArgMax(void *
# 522
d_temp_storage, size_t &
# 523
temp_storage_bytes, InputIterator 
# 524
d_in, OutputIterator 
# 525
d_out, int 
# 526
num_items, cudaStream_t 
# 527
stream = 0, bool 
# 528
debug_synchronous = false) 
# 529
{ 
# 531
typedef int Offset; 
# 534
typedef cub_::ArgIndexInputIterator< InputIterator, int>  ArgIndexInputIterator; 
# 535
ArgIndexInputIterator d_argmax_in(d_in, 0); 
# 538
typedef cub_::DeviceReduceDispatch< cub_::ArgIndexInputIterator< InputIterator, int> , OutputIterator, int, cub_::ArgMax>  DeviceReduceDispatch; 
# 540
return DeviceReduceDispatch::Dispatch(d_temp_storage, temp_storage_bytes, d_argmax_in, d_out, num_items, cub_::ArgMax(), stream, debug_synchronous); 
# 549
} 
# 634
template< class 
# 635
KeysInputIterator, class 
# 636
UniqueOutputIterator, class 
# 637
ValuesInputIterator, class 
# 638
AggregatesOutputIterator, class 
# 639
NumRunsOutputIterator, class 
# 640
ReductionOp> 
# 641
__attribute((always_inline)) static cudaError_t 
# 642
ReduceByKey(void *
# 643
d_temp_storage, size_t &
# 644
temp_storage_bytes, KeysInputIterator 
# 645
d_keys_in, UniqueOutputIterator 
# 646
d_unique_out, ValuesInputIterator 
# 647
d_values_in, AggregatesOutputIterator 
# 648
d_aggregates_out, NumRunsOutputIterator 
# 649
d_num_runs_out, ReductionOp 
# 650
reduction_op, int 
# 651
num_items, cudaStream_t 
# 652
stream = 0, bool 
# 653
debug_synchronous = false) 
# 654
{ 
# 655
typedef int Offset; 
# 656
typedef NullType *FlagIterator; 
# 657
typedef NullType SelectOp; 
# 658
typedef Equality EqualityOp; 
# 660
return DeviceReduceByKeyDispatch< KeysInputIterator, UniqueOutputIterator, ValuesInputIterator, AggregatesOutputIterator, NumRunsOutputIterator, Equality, ReductionOp, int> ::Dispatch(d_temp_storage, temp_storage_bytes, d_keys_in, d_unique_out, d_values_in, d_aggregates_out, d_num_runs_out, EqualityOp(), reduction_op, num_items, stream, debug_synchronous); 
# 673
} 
# 675
}; 
# 681
}
# 682
}}}}
# 44 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/device_scan.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 47
namespace cub_ { 
# 77
struct DeviceScan { 
# 129
template< class 
# 130
InputIterator, class 
# 131
OutputIterator> static cudaError_t 
# 133
ExclusiveSum(void *
# 134
d_temp_storage, size_t &
# 135
temp_storage_bytes, InputIterator 
# 136
d_in, OutputIterator 
# 137
d_out, int 
# 138
num_items, cudaStream_t 
# 139
stream = 0, bool 
# 140
debug_synchronous = false) 
# 141
{ 
# 143
typedef int Offset; 
# 146
typedef typename std::iterator_traits< InputIterator> ::value_type T; 
# 148
return DeviceScanDispatch< InputIterator, OutputIterator, Sum, typename std::iterator_traits< InputIterator> ::value_type, int> ::Dispatch(d_temp_storage, temp_storage_bytes, d_in, d_out, Sum(), T(), num_items, stream, debug_synchronous); 
# 158
} 
# 215
template< class 
# 216
InputIterator, class 
# 217
OutputIterator, class 
# 218
ScanOp, class 
# 219
Identity> static cudaError_t 
# 221
ExclusiveScan(void *
# 222
d_temp_storage, size_t &
# 223
temp_storage_bytes, InputIterator 
# 224
d_in, OutputIterator 
# 225
d_out, ScanOp 
# 226
scan_op, Identity 
# 227
identity, int 
# 228
num_items, cudaStream_t 
# 229
stream = 0, bool 
# 230
debug_synchronous = false) 
# 231
{ 
# 233
typedef int Offset; 
# 235
return DeviceScanDispatch< InputIterator, OutputIterator, ScanOp, Identity, int> ::Dispatch(d_temp_storage, temp_storage_bytes, d_in, d_out, scan_op, identity, num_items, stream, debug_synchronous); 
# 245
} 
# 296
template< class 
# 297
InputIterator, class 
# 298
OutputIterator> static cudaError_t 
# 300
InclusiveSum(void *
# 301
d_temp_storage, size_t &
# 302
temp_storage_bytes, InputIterator 
# 303
d_in, OutputIterator 
# 304
d_out, int 
# 305
num_items, cudaStream_t 
# 306
stream = 0, bool 
# 307
debug_synchronous = false) 
# 308
{ 
# 310
typedef int Offset; 
# 312
return DeviceScanDispatch< InputIterator, OutputIterator, Sum, NullType, int> ::Dispatch(d_temp_storage, temp_storage_bytes, d_in, d_out, Sum(), NullType(), num_items, stream, debug_synchronous); 
# 322
} 
# 378
template< class 
# 379
InputIterator, class 
# 380
OutputIterator, class 
# 381
ScanOp> static cudaError_t 
# 383
InclusiveScan(void *
# 384
d_temp_storage, size_t &
# 385
temp_storage_bytes, InputIterator 
# 386
d_in, OutputIterator 
# 387
d_out, ScanOp 
# 388
scan_op, int 
# 389
num_items, cudaStream_t 
# 390
stream = 0, bool 
# 391
debug_synchronous = false) 
# 392
{ 
# 394
typedef int Offset; 
# 396
return DeviceScanDispatch< InputIterator, OutputIterator, ScanOp, NullType, int> ::Dispatch(d_temp_storage, temp_storage_bytes, d_in, d_out, scan_op, NullType(), num_items, stream, debug_synchronous); 
# 406
} 
# 410
}; 
# 416
}
# 417
}}}}
# 44 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/device/device_select.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 47
namespace cub_ { 
# 82
struct DeviceSelect { 
# 128
template< class 
# 129
InputIterator, class 
# 130
FlagIterator, class 
# 131
OutputIterator, class 
# 132
NumSelectedIterator> 
# 133
__attribute((always_inline)) static cudaError_t 
# 134
Flagged(void *
# 135
d_temp_storage, size_t &
# 136
temp_storage_bytes, InputIterator 
# 137
d_in, FlagIterator 
# 138
d_flags, OutputIterator 
# 139
d_out, NumSelectedIterator 
# 140
d_num_selected_out, int 
# 141
num_items, cudaStream_t 
# 142
stream = 0, bool 
# 143
debug_synchronous = false) 
# 144
{ 
# 145
typedef int Offset; 
# 146
typedef NullType SelectOp; 
# 147
typedef NullType EqualityOp; 
# 149
return DeviceSelectDispatch< InputIterator, FlagIterator, OutputIterator, NumSelectedIterator, NullType, NullType, int, false> ::Dispatch(d_temp_storage, temp_storage_bytes, d_in, d_flags, d_out, d_num_selected_out, SelectOp(), EqualityOp(), num_items, stream, debug_synchronous); 
# 161
} 
# 235
template< class 
# 236
InputIterator, class 
# 237
OutputIterator, class 
# 238
NumSelectedIterator, class 
# 239
SelectOp> 
# 240
__attribute((always_inline)) static cudaError_t 
# 241
If(void *
# 242
d_temp_storage, size_t &
# 243
temp_storage_bytes, InputIterator 
# 244
d_in, OutputIterator 
# 245
d_out, NumSelectedIterator 
# 246
d_num_selected_out, int 
# 247
num_items, SelectOp 
# 248
select_op, cudaStream_t 
# 249
stream = 0, bool 
# 250
debug_synchronous = false) 
# 251
{ 
# 252
typedef int Offset; 
# 253
typedef NullType *FlagIterator; 
# 254
typedef NullType EqualityOp; 
# 256
return DeviceSelectDispatch< InputIterator, NullType *, OutputIterator, NumSelectedIterator, SelectOp, NullType, int, false> ::Dispatch(d_temp_storage, temp_storage_bytes, d_in, __null, d_out, d_num_selected_out, select_op, EqualityOp(), num_items, stream, debug_synchronous); 
# 268
} 
# 327
template< class 
# 328
InputIterator, class 
# 329
OutputIterator, class 
# 330
NumSelectedIterator> 
# 331
__attribute((always_inline)) static cudaError_t 
# 332
Unique(void *
# 333
d_temp_storage, size_t &
# 334
temp_storage_bytes, InputIterator 
# 335
d_in, OutputIterator 
# 336
d_out, NumSelectedIterator 
# 337
d_num_selected_out, int 
# 338
num_items, cudaStream_t 
# 339
stream = 0, bool 
# 340
debug_synchronous = false) 
# 341
{ 
# 342
typedef int Offset; 
# 343
typedef NullType *FlagIterator; 
# 344
typedef NullType SelectOp; 
# 345
typedef Equality EqualityOp; 
# 347
return DeviceSelectDispatch< InputIterator, NullType *, OutputIterator, NumSelectedIterator, NullType, Equality, int, false> ::Dispatch(d_temp_storage, temp_storage_bytes, d_in, __null, d_out, d_num_selected_out, SelectOp(), EqualityOp(), num_items, stream, debug_synchronous); 
# 359
} 
# 361
}; 
# 369
}
# 370
}}}}
# 52 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/host/spinlock.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 55
namespace cub_ { 
# 66
typedef int Spinlock; 
# 71
__attribute((always_inline)) inline void _ReadWriteBarrier() 
# 72
{ 
# 73
__sync_synchronize(); 
# 74
} 
# 79
__attribute((always_inline)) inline long _InterlockedExchange(volatile int *const Target, const int Value) 
# 80
{ 
# 82
_ReadWriteBarrier(); 
# 83
return __sync_lock_test_and_set(Target, Value); 
# 84
} 
# 89
__attribute((always_inline)) inline void YieldProcessor() 
# 90
{ 
# 92
__asm__ volatile("pause\n" : : : "memory"); 
# 94
} 
# 101
__attribute((always_inline)) inline void Lock(volatile Spinlock *lock) 
# 102
{ 
# 103
while (1) 
# 104
{ 
# 105
if (!(_InterlockedExchange(lock, 1))) { return; }  
# 106
while (*lock) { YieldProcessor(); }  
# 107
}  
# 108
} 
# 114
__attribute((always_inline)) inline void Unlock(volatile Spinlock *lock) 
# 115
{ 
# 116
_ReadWriteBarrier(); 
# 117
(*lock) = 0; 
# 118
} 
# 121
}
# 122
}}}}
# 52 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/iterator/cache_modified_output_iterator.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 55
namespace cub_ { 
# 105
template< CacheStoreModifier 
# 106
MODIFIER, class 
# 107
ValueType, class 
# 108
Offset = ptrdiff_t> 
# 109
class CacheModifiedOutputIterator { 
# 114
struct Reference { 
# 116
ValueType *ptr; 
# 119
__attribute((always_inline)) Reference(ValueType *ptr) : ptr(ptr) { } 
# 122
__attribute((always_inline)) ValueType operator=(ValueType val) 
# 123
{ 
# 124
ThreadStore< MODIFIER> (ptr, val); 
# 125
return val; 
# 126
} 
# 127
}; 
# 132
public: typedef CacheModifiedOutputIterator self_type; 
# 133
typedef Offset difference_type; 
# 134
typedef ValueType value_type; 
# 135
typedef ValueType *pointer; 
# 136
typedef Reference reference; 
# 145
typedef typename thrust::detail::iterator_facade_category< tag, random_access_traversal_tag, ValueType, Reference> ::type iterator_category; 
# 152
private: ValueType *ptr; 
# 157
public: __attribute((always_inline)) CacheModifiedOutputIterator(ValueType *
# 158
ptr) : ptr(ptr) 
# 161
{ } 
# 164
__attribute((always_inline)) self_type operator++(int) 
# 165
{ 
# 166
self_type retval = *this; 
# 167
(ptr)++; 
# 168
return retval; 
# 169
} 
# 173
__attribute((always_inline)) self_type operator++() 
# 174
{ 
# 175
(ptr)++; 
# 176
return *this; 
# 177
} 
# 180
__attribute((always_inline)) reference operator*() const 
# 181
{ 
# 182
return (Reference)(ptr); 
# 183
} 
# 186
template< class Distance> 
# 187
__attribute((always_inline)) self_type operator+(Distance n) const 
# 188
{ 
# 189
self_type retval((ptr) + n); 
# 190
return retval; 
# 191
} 
# 194
template< class Distance> 
# 195
__attribute((always_inline)) self_type &operator+=(Distance n) 
# 196
{ 
# 197
(ptr) += n; 
# 198
return *this; 
# 199
} 
# 202
template< class Distance> 
# 203
__attribute((always_inline)) self_type operator-(Distance n) const 
# 204
{ 
# 205
self_type retval((ptr) - n); 
# 206
return retval; 
# 207
} 
# 210
template< class Distance> 
# 211
__attribute((always_inline)) self_type &operator-=(Distance n) 
# 212
{ 
# 213
(ptr) -= n; 
# 214
return *this; 
# 215
} 
# 218
__attribute((always_inline)) difference_type operator-(self_type other) const 
# 219
{ 
# 220
return (ptr) - (other.ptr); 
# 221
} 
# 224
template< class Distance> 
# 225
__attribute((always_inline)) reference operator[](Distance n) const 
# 226
{ 
# 227
return (Reference)((ptr) + n); 
# 228
} 
# 231
__attribute((always_inline)) bool operator==(const self_type &rhs) 
# 232
{ 
# 233
return (ptr) == (rhs.ptr); 
# 234
} 
# 237
__attribute((always_inline)) bool operator!=(const self_type &rhs) 
# 238
{ 
# 239
return (ptr) != (rhs.ptr); 
# 240
} 
# 243
friend inline std::ostream &operator<<(std::ostream &os, const self_type &itr) 
# 244
{ 
# 245
return os; 
# 246
} 
# 247
}; 
# 252
}
# 253
}}}}
# 52 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/iterator/counting_input_iterator.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 55
namespace cub_ { 
# 91
template< class 
# 92
ValueType, class 
# 93
Offset = ptrdiff_t> 
# 94
class CountingInputIterator { 
# 99
public: typedef CountingInputIterator self_type; 
# 100
typedef Offset difference_type; 
# 101
typedef ValueType value_type; 
# 102
typedef ValueType *pointer; 
# 103
typedef ValueType reference; 
# 112
typedef typename thrust::detail::iterator_facade_category< any_system_tag, random_access_traversal_tag, ValueType, ValueType> ::type iterator_category; 
# 119
private: ValueType val; 
# 124
public: __attribute((always_inline)) CountingInputIterator(const ValueType &
# 125
val) : val(val) 
# 128
{ } 
# 131
__attribute((always_inline)) self_type operator++(int) 
# 132
{ 
# 133
self_type retval = *this; 
# 134
(val)++; 
# 135
return retval; 
# 136
} 
# 139
__attribute((always_inline)) self_type operator++() 
# 140
{ 
# 141
(val)++; 
# 142
return *this; 
# 143
} 
# 146
__attribute((always_inline)) reference operator*() const 
# 147
{ 
# 148
return val; 
# 149
} 
# 152
template< class Distance> 
# 153
__attribute((always_inline)) self_type operator+(Distance n) const 
# 154
{ 
# 155
self_type retval((val) + n); 
# 156
return retval; 
# 157
} 
# 160
template< class Distance> 
# 161
__attribute((always_inline)) self_type &operator+=(Distance n) 
# 162
{ 
# 163
(val) += n; 
# 164
return *this; 
# 165
} 
# 168
template< class Distance> 
# 169
__attribute((always_inline)) self_type operator-(Distance n) const 
# 170
{ 
# 171
self_type retval((val) - n); 
# 172
return retval; 
# 173
} 
# 176
template< class Distance> 
# 177
__attribute((always_inline)) self_type &operator-=(Distance n) 
# 178
{ 
# 179
(val) -= n; 
# 180
return *this; 
# 181
} 
# 184
__attribute((always_inline)) difference_type operator-(self_type other) const 
# 185
{ 
# 186
return (val) - (other.val); 
# 187
} 
# 190
template< class Distance> 
# 191
__attribute((always_inline)) reference operator[](Distance n) const 
# 192
{ 
# 193
return (val) + n; 
# 194
} 
# 197
__attribute((always_inline)) pointer operator->() 
# 198
{ 
# 199
return &(val); 
# 200
} 
# 203
__attribute((always_inline)) bool operator==(const self_type &rhs) 
# 204
{ 
# 205
return (val) == (rhs.val); 
# 206
} 
# 209
__attribute((always_inline)) bool operator!=(const self_type &rhs) 
# 210
{ 
# 211
return (val) != (rhs.val); 
# 212
} 
# 215
friend inline std::ostream &operator<<(std::ostream &os, const self_type &itr) 
# 216
{ 
# 217
(((os << ("["))) << (itr.val)) << "]"; 
# 218
return os; 
# 219
} 
# 221
}; 
# 227
}
# 228
}}}}
# 53 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/iterator/tex_obj_input_iterator.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 56
namespace cub_ { 
# 108
template< class 
# 109
T, class 
# 110
Offset = ptrdiff_t> 
# 111
class TexObjInputIterator { 
# 116
public: typedef TexObjInputIterator self_type; 
# 117
typedef Offset difference_type; 
# 118
typedef T value_type; 
# 119
typedef T *pointer; 
# 120
typedef T reference; 
# 129
typedef typename thrust::detail::iterator_facade_category< tag, random_access_traversal_tag, T, T> ::type iterator_category; 
# 137
private: typedef typename UnitWord< T> ::TextureWord TextureWord; 
# 140
enum { 
# 141
TEXTURE_MULTIPLE = sizeof(T) / sizeof(TextureWord)
# 142
}; 
# 146
T *ptr; 
# 147
difference_type tex_offset; 
# 148
cudaTextureObject_t tex_obj; 
# 153
public: __attribute((always_inline)) TexObjInputIterator() : ptr((__null)), tex_offset(0), tex_obj((0)) 
# 158
{ } 
# 161
cudaError_t BindTexture(T *
# 162
ptr, size_t 
# 163
bytes, size_t 
# 164
tex_offset = 0) 
# 165
{ 
# 166
(this->ptr) = ptr; 
# 167
(this->tex_offset) = tex_offset; 
# 169
cudaChannelFormatDesc channel_desc = cudaCreateChannelDesc< TextureWord> (); 
# 170
cudaResourceDesc res_desc; 
# 171
cudaTextureDesc tex_desc; 
# 172
memset(&res_desc, 0, sizeof(cudaResourceDesc)); 
# 173
memset(&tex_desc, 0, sizeof(cudaTextureDesc)); 
# 174
(res_desc.resType) = cudaResourceTypeLinear; 
# 175
(((res_desc.res).linear).devPtr) = ptr; 
# 176
(((res_desc.res).linear).desc) = channel_desc; 
# 177
(((res_desc.res).linear).sizeInBytes) = bytes; 
# 178
(tex_desc.readMode) = cudaReadModeElementType; 
# 179
return cudaCreateTextureObject(&(tex_obj), &res_desc, &tex_desc, __null); 
# 180
} 
# 183
cudaError_t UnbindTexture() 
# 184
{ 
# 185
return cudaDestroyTextureObject(tex_obj); 
# 186
} 
# 189
__attribute((always_inline)) self_type operator++(int) 
# 190
{ 
# 191
self_type retval = *this; 
# 192
(tex_offset)++; 
# 193
return retval; 
# 194
} 
# 197
__attribute((always_inline)) self_type operator++() 
# 198
{ 
# 199
(tex_offset)++; 
# 200
return *this; 
# 201
} 
# 204
__attribute((always_inline)) reference operator*() const 
# 205
{ 
# 208
return (ptr)[tex_offset]; 
# 224
} 
# 227
template< class Distance> 
# 228
__attribute((always_inline)) self_type operator+(Distance n) const 
# 229
{ 
# 230
self_type retval; 
# 231
(retval.ptr) = (ptr); 
# 232
(retval.tex_obj) = (tex_obj); 
# 233
(retval.tex_offset) = ((tex_offset) + n); 
# 234
return retval; 
# 235
} 
# 238
template< class Distance> 
# 239
__attribute((always_inline)) self_type &operator+=(Distance n) 
# 240
{ 
# 241
(tex_offset) += n; 
# 242
return *this; 
# 243
} 
# 246
template< class Distance> 
# 247
__attribute((always_inline)) self_type operator-(Distance n) const 
# 248
{ 
# 249
self_type retval; 
# 250
(retval.ptr) = (ptr); 
# 251
(retval.tex_obj) = (tex_obj); 
# 252
(retval.tex_offset) = ((tex_offset) - n); 
# 253
return retval; 
# 254
} 
# 257
template< class Distance> 
# 258
__attribute((always_inline)) self_type &operator-=(Distance n) 
# 259
{ 
# 260
(tex_offset) -= n; 
# 261
return *this; 
# 262
} 
# 265
__attribute((always_inline)) difference_type operator-(self_type other) const 
# 266
{ 
# 267
return (tex_offset) - (other.tex_offset); 
# 268
} 
# 271
template< class Distance> 
# 272
__attribute((always_inline)) reference operator[](Distance n) const 
# 273
{ 
# 274
return *((*this) + n); 
# 275
} 
# 278
__attribute((always_inline)) pointer operator->() 
# 279
{ 
# 280
return &(*(*this)); 
# 281
} 
# 284
__attribute((always_inline)) bool operator==(const self_type &rhs) 
# 285
{ 
# 286
return ((ptr) == (rhs.ptr)) && ((tex_offset) == (rhs.tex_offset)) && ((tex_obj) == (rhs.tex_obj)); 
# 287
} 
# 290
__attribute((always_inline)) bool operator!=(const self_type &rhs) 
# 291
{ 
# 292
return (((ptr) != (rhs.ptr)) || ((tex_offset) != (rhs.tex_offset))) || ((tex_obj) != (rhs.tex_obj)); 
# 293
} 
# 296
friend inline std::ostream &operator<<(std::ostream &os, const self_type &itr) 
# 297
{ 
# 298
return os; 
# 299
} 
# 301
}; 
# 307
}
# 308
}}}}
# 54 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/iterator/tex_ref_input_iterator.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 57
namespace cub_ { 
# 67
namespace _GLOBAL__N__17_gpu_setup_cpp1_ii_524b47c1 { }; using namespace ::thrust::system::cuda::detail::cub_::_GLOBAL__N__17_gpu_setup_cpp1_ii_524b47c1; namespace _GLOBAL__N__17_gpu_setup_cpp1_ii_524b47c1 { 
# 70
template< class T> 
# 71
struct IteratorTexRef { 
# 74
template< int UNIQUE_ID> 
# 75
struct TexId { 
# 78
typedef typename UnitWord< T> ::DeviceWord DeviceWord; 
# 79
typedef typename UnitWord< T> ::TextureWord TextureWord; 
# 82
enum { 
# 83
DEVICE_MULTIPLE = sizeof(T) / sizeof(DeviceWord), 
# 84
TEXTURE_MULTIPLE = sizeof(T) / sizeof(TextureWord)
# 85
}; 
# 88
typedef texture< typename UnitWord< T> ::TextureWord>  TexRef; 
# 91
static TexRef ref; 
# 94
static cudaError_t BindTexture(void *d_in) 
# 95
{ 
# 96
if (d_in) 
# 97
{ 
# 98
cudaChannelFormatDesc tex_desc = cudaCreateChannelDesc< TextureWord> (); 
# 99
(ref.channelDesc) = tex_desc; 
# 100
return cub_::Debug(cudaBindTexture(__null, ref, d_in), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/iterator/tex_ref_input_iterator.cuh", 100); 
# 101
}  
# 103
return cudaSuccess; 
# 104
} 
# 107
static cudaError_t UnbindTexture() 
# 108
{ 
# 109
return cub_::Debug(cudaUnbindTexture(ref), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/iterator/tex_ref_input_iterator.cuh", 109); 
# 110
} 
# 113
template< class Distance> 
# 114
__attribute((always_inline)) static T Fetch(Distance tex_offset) 
# 115
{int volatile ___ = 1;(void)tex_offset;
# 126
::exit(___);}
#if 0
# 115
{ 
# 116
DeviceWord temp[DEVICE_MULTIPLE]; 
# 117
TextureWord *words = reinterpret_cast< TextureWord *>(temp); 
# 120
#pragma unroll
for (
# 120
int i = 0; i < (TEXTURE_MULTIPLE); ++i) 
# 121
{ 
# 122
(words[i]) = tex1Dfetch(ref, (tex_offset * (TEXTURE_MULTIPLE)) + i); 
# 123
}  
# 125
return reinterpret_cast< T &>(temp); 
# 126
} 
#endif
# 127 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/iterator/tex_ref_input_iterator.cuh"
}; 
# 128
}; 
# 131
template< class T> 
# 132
template< int UNIQUE_ID> typename IteratorTexRef< T> ::template TexId< UNIQUE_ID> ::TexRef 
# 133
IteratorTexRef< T> ::TexId< UNIQUE_ID> ::ref = 0; 
# 136
}
# 200
template< class 
# 201
T, int 
# 202
UNIQUE_ID, class 
# 203
Offset = ptrdiff_t> 
# 204
class TexRefInputIterator { 
# 209
public: typedef TexRefInputIterator self_type; 
# 210
typedef Offset difference_type; 
# 211
typedef T value_type; 
# 212
typedef T *pointer; 
# 213
typedef T reference; 
# 222
typedef typename thrust::detail::iterator_facade_category< tag, random_access_traversal_tag, T, T> ::type iterator_category; 
# 229
private: T *ptr; 
# 230
difference_type tex_offset; 
# 233
typedef typename cub_::IteratorTexRef< T> ::template TexId< UNIQUE_ID>  TexId; 
# 238
public: __attribute((always_inline)) TexRefInputIterator() : ptr((__null)), tex_offset(0) 
# 242
{ } 
# 245
cudaError_t BindTexture(T *
# 246
ptr, size_t 
# 247
bytes, size_t 
# 248
tex_offset = 0) 
# 249
{ 
# 250
(this->ptr) = ptr; 
# 251
(this->tex_offset) = ((difference_type)tex_offset); 
# 252
return TexId::BindTexture(ptr); 
# 253
} 
# 256
cudaError_t UnbindTexture() 
# 257
{ 
# 258
return TexId::UnbindTexture(); 
# 259
} 
# 262
__attribute((always_inline)) self_type operator++(int) 
# 263
{ 
# 264
self_type retval = *this; 
# 265
(tex_offset)++; 
# 266
return retval; 
# 267
} 
# 270
__attribute((always_inline)) self_type operator++() 
# 271
{ 
# 272
(tex_offset)++; 
# 273
return *this; 
# 274
} 
# 277
__attribute((always_inline)) reference operator*() const 
# 278
{ 
# 281
return (ptr)[tex_offset]; 
# 286
} 
# 289
template< class Distance> 
# 290
__attribute((always_inline)) self_type operator+(Distance n) const 
# 291
{ 
# 292
self_type retval; 
# 293
(retval.ptr) = (ptr); 
# 294
(retval.tex_offset) = ((tex_offset) + n); 
# 295
return retval; 
# 296
} 
# 299
template< class Distance> 
# 300
__attribute((always_inline)) self_type &operator+=(Distance n) 
# 301
{ 
# 302
(tex_offset) += n; 
# 303
return *this; 
# 304
} 
# 307
template< class Distance> 
# 308
__attribute((always_inline)) self_type operator-(Distance n) const 
# 309
{ 
# 310
self_type retval; 
# 311
(retval.ptr) = (ptr); 
# 312
(retval.tex_offset) = ((tex_offset) - n); 
# 313
return retval; 
# 314
} 
# 317
template< class Distance> 
# 318
__attribute((always_inline)) self_type &operator-=(Distance n) 
# 319
{ 
# 320
(tex_offset) -= n; 
# 321
return *this; 
# 322
} 
# 325
__attribute((always_inline)) difference_type operator-(self_type other) const 
# 326
{ 
# 327
return (tex_offset) - (other.tex_offset); 
# 328
} 
# 331
template< class Distance> 
# 332
__attribute((always_inline)) reference operator[](Distance n) const 
# 333
{ 
# 334
return *((*this) + n); 
# 335
} 
# 338
__attribute((always_inline)) pointer operator->() 
# 339
{ 
# 340
return &(*(*this)); 
# 341
} 
# 344
__attribute((always_inline)) bool operator==(const self_type &rhs) 
# 345
{ 
# 346
return ((ptr) == (rhs.ptr)) && ((tex_offset) == (rhs.tex_offset)); 
# 347
} 
# 350
__attribute((always_inline)) bool operator!=(const self_type &rhs) 
# 351
{ 
# 352
return ((ptr) != (rhs.ptr)) || ((tex_offset) != (rhs.tex_offset)); 
# 353
} 
# 356
friend inline std::ostream &operator<<(std::ostream &os, const self_type &itr) 
# 357
{ 
# 358
return os; 
# 359
} 
# 361
}; 
# 367
}
# 368
}}}}
# 52 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/iterator/transform_input_iterator.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 55
namespace cub_ { 
# 112
template< class 
# 113
ValueType, class 
# 114
ConversionOp, class 
# 115
InputIterator, class 
# 116
Offset = ptrdiff_t> 
# 117
class TransformInputIterator { 
# 122
public: typedef TransformInputIterator self_type; 
# 123
typedef Offset difference_type; 
# 124
typedef ValueType value_type; 
# 125
typedef ValueType *pointer; 
# 126
typedef ValueType reference; 
# 135
typedef typename thrust::detail::iterator_facade_category< any_system_tag, random_access_traversal_tag, ValueType, ValueType> ::type iterator_category; 
# 142
private: ConversionOp conversion_op; 
# 143
InputIterator input_itr; 
# 148
public: __attribute((always_inline)) TransformInputIterator(InputIterator 
# 149
input_itr, ConversionOp 
# 150
conversion_op) : conversion_op(conversion_op), input_itr(input_itr) 
# 154
{ } 
# 157
__attribute((always_inline)) self_type operator++(int) 
# 158
{ 
# 159
self_type retval = *this; 
# 160
(input_itr)++; 
# 161
return retval; 
# 162
} 
# 165
__attribute((always_inline)) self_type operator++() 
# 166
{ 
# 167
(input_itr)++; 
# 168
return *this; 
# 169
} 
# 172
__attribute((always_inline)) reference operator*() const 
# 173
{ 
# 174
return (conversion_op)(*(input_itr)); 
# 175
} 
# 178
template< class Distance> 
# 179
__attribute((always_inline)) self_type operator+(Distance n) const 
# 180
{ 
# 181
self_type retval((input_itr) + n, conversion_op); 
# 182
return retval; 
# 183
} 
# 186
template< class Distance> 
# 187
__attribute((always_inline)) self_type &operator+=(Distance n) 
# 188
{ 
# 189
(input_itr) += n; 
# 190
return *this; 
# 191
} 
# 194
template< class Distance> 
# 195
__attribute((always_inline)) self_type operator-(Distance n) const 
# 196
{ 
# 197
self_type retval((input_itr) - n, conversion_op); 
# 198
return retval; 
# 199
} 
# 202
template< class Distance> 
# 203
__attribute((always_inline)) self_type &operator-=(Distance n) 
# 204
{ 
# 205
(input_itr) -= n; 
# 206
return *this; 
# 207
} 
# 210
__attribute((always_inline)) difference_type operator-(self_type other) const 
# 211
{ 
# 212
return (input_itr) - (other.input_itr); 
# 213
} 
# 216
template< class Distance> 
# 217
__attribute((always_inline)) reference operator[](Distance n) const 
# 218
{ 
# 219
return (conversion_op)((input_itr)[n]); 
# 220
} 
# 223
__attribute((always_inline)) pointer operator->() 
# 224
{ 
# 225
return &(conversion_op)(*(input_itr)); 
# 226
} 
# 229
__attribute((always_inline)) bool operator==(const self_type &rhs) 
# 230
{ 
# 231
return (input_itr) == (rhs.input_itr); 
# 232
} 
# 235
__attribute((always_inline)) bool operator!=(const self_type &rhs) 
# 236
{ 
# 237
return (input_itr) != (rhs.input_itr); 
# 238
} 
# 241
friend inline std::ostream &operator<<(std::ostream &os, const self_type &itr) 
# 242
{ 
# 243
return os; 
# 244
} 
# 245
}; 
# 251
}
# 252
}}}}
# 69 "/usr/include/c++/4.8.2/bits/stl_tree.h" 3
namespace std __attribute((__visibility__("default"))) { 
# 89
enum _Rb_tree_color { _S_red, _S_black}; 
# 91
struct _Rb_tree_node_base { 
# 93
typedef _Rb_tree_node_base *_Base_ptr; 
# 94
typedef const _Rb_tree_node_base *_Const_Base_ptr; 
# 96
_Rb_tree_color _M_color; 
# 97
_Base_ptr _M_parent; 
# 98
_Base_ptr _M_left; 
# 99
_Base_ptr _M_right; 
# 102
static _Base_ptr _S_minimum(_Base_ptr __x) 
# 103
{ 
# 104
while ((__x->_M_left) != (0)) { __x = (__x->_M_left); }  
# 105
return __x; 
# 106
} 
# 109
static _Const_Base_ptr _S_minimum(_Const_Base_ptr __x) 
# 110
{ 
# 111
while ((__x->_M_left) != (0)) { __x = (__x->_M_left); }  
# 112
return __x; 
# 113
} 
# 116
static _Base_ptr _S_maximum(_Base_ptr __x) 
# 117
{ 
# 118
while ((__x->_M_right) != (0)) { __x = (__x->_M_right); }  
# 119
return __x; 
# 120
} 
# 123
static _Const_Base_ptr _S_maximum(_Const_Base_ptr __x) 
# 124
{ 
# 125
while ((__x->_M_right) != (0)) { __x = (__x->_M_right); }  
# 126
return __x; 
# 127
} 
# 128
}; 
# 130
template< class _Val> 
# 131
struct _Rb_tree_node : public _Rb_tree_node_base { 
# 133
typedef _Rb_tree_node *_Link_type; 
# 134
_Val _M_value_field; 
# 142
}; 
# 144
__attribute((__pure__)) _Rb_tree_node_base *
# 145
_Rb_tree_increment(_Rb_tree_node_base * __x) throw(); 
# 147
__attribute((__pure__)) const _Rb_tree_node_base *
# 148
_Rb_tree_increment(const _Rb_tree_node_base * __x) throw(); 
# 150
__attribute((__pure__)) _Rb_tree_node_base *
# 151
_Rb_tree_decrement(_Rb_tree_node_base * __x) throw(); 
# 153
__attribute((__pure__)) const _Rb_tree_node_base *
# 154
_Rb_tree_decrement(const _Rb_tree_node_base * __x) throw(); 
# 156
template< class _Tp> 
# 157
struct _Rb_tree_iterator { 
# 159
typedef _Tp value_type; 
# 160
typedef _Tp &reference; 
# 161
typedef _Tp *pointer; 
# 163
typedef bidirectional_iterator_tag iterator_category; 
# 164
typedef ptrdiff_t difference_type; 
# 166
typedef _Rb_tree_iterator _Self; 
# 167
typedef _Rb_tree_node_base::_Base_ptr _Base_ptr; 
# 168
typedef _Rb_tree_node< _Tp>  *_Link_type; 
# 170
_Rb_tree_iterator() : _M_node() 
# 171
{ } 
# 174
explicit _Rb_tree_iterator(_Link_type __x) : _M_node(__x) 
# 175
{ } 
# 178
reference operator*() const 
# 179
{ return (static_cast< _Link_type>(_M_node))->_M_value_field; } 
# 182
pointer operator->() const 
# 183
{ return std::__addressof(((static_cast< _Link_type>(_M_node))->_M_value_field)); 
# 184
} 
# 187
_Self &operator++() 
# 188
{ 
# 189
(_M_node) = _Rb_tree_increment(_M_node); 
# 190
return *this; 
# 191
} 
# 194
_Self operator++(int) 
# 195
{ 
# 196
_Self __tmp = *this; 
# 197
(_M_node) = _Rb_tree_increment(_M_node); 
# 198
return __tmp; 
# 199
} 
# 202
_Self &operator--() 
# 203
{ 
# 204
(_M_node) = _Rb_tree_decrement(_M_node); 
# 205
return *this; 
# 206
} 
# 209
_Self operator--(int) 
# 210
{ 
# 211
_Self __tmp = *this; 
# 212
(_M_node) = _Rb_tree_decrement(_M_node); 
# 213
return __tmp; 
# 214
} 
# 217
bool operator==(const _Self &__x) const 
# 218
{ return (_M_node) == (__x._M_node); } 
# 221
bool operator!=(const _Self &__x) const 
# 222
{ return (_M_node) != (__x._M_node); } 
# 224
_Base_ptr _M_node; 
# 225
}; 
# 227
template< class _Tp> 
# 228
struct _Rb_tree_const_iterator { 
# 230
typedef _Tp value_type; 
# 231
typedef const _Tp &reference; 
# 232
typedef const _Tp *pointer; 
# 234
typedef _Rb_tree_iterator< _Tp>  iterator; 
# 236
typedef bidirectional_iterator_tag iterator_category; 
# 237
typedef ptrdiff_t difference_type; 
# 239
typedef _Rb_tree_const_iterator _Self; 
# 240
typedef _Rb_tree_node_base::_Const_Base_ptr _Base_ptr; 
# 241
typedef const _Rb_tree_node< _Tp>  *_Link_type; 
# 243
_Rb_tree_const_iterator() : _M_node() 
# 244
{ } 
# 247
explicit _Rb_tree_const_iterator(_Link_type __x) : _M_node(__x) 
# 248
{ } 
# 250
_Rb_tree_const_iterator(const iterator &__it) : _M_node(((__it._M_node))) 
# 251
{ } 
# 254
iterator _M_const_cast() const 
# 255
{ return ((iterator)(static_cast< typename _Rb_tree_iterator< _Tp> ::_Link_type>(const_cast< typename _Rb_tree_iterator< _Tp> ::_Base_ptr>(_M_node)))); 
# 256
} 
# 259
reference operator*() const 
# 260
{ return (static_cast< _Link_type>(_M_node))->_M_value_field; } 
# 263
pointer operator->() const 
# 264
{ return std::__addressof(((static_cast< _Link_type>(_M_node))->_M_value_field)); 
# 265
} 
# 268
_Self &operator++() 
# 269
{ 
# 270
(_M_node) = _Rb_tree_increment(_M_node); 
# 271
return *this; 
# 272
} 
# 275
_Self operator++(int) 
# 276
{ 
# 277
_Self __tmp = *this; 
# 278
(_M_node) = _Rb_tree_increment(_M_node); 
# 279
return __tmp; 
# 280
} 
# 283
_Self &operator--() 
# 284
{ 
# 285
(_M_node) = _Rb_tree_decrement(_M_node); 
# 286
return *this; 
# 287
} 
# 290
_Self operator--(int) 
# 291
{ 
# 292
_Self __tmp = *this; 
# 293
(_M_node) = _Rb_tree_decrement(_M_node); 
# 294
return __tmp; 
# 295
} 
# 298
bool operator==(const _Self &__x) const 
# 299
{ return (_M_node) == (__x._M_node); } 
# 302
bool operator!=(const _Self &__x) const 
# 303
{ return (_M_node) != (__x._M_node); } 
# 305
_Base_ptr _M_node; 
# 306
}; 
# 308
template< class _Val> inline bool 
# 310
operator==(const _Rb_tree_iterator< _Val>  &__x, const _Rb_tree_const_iterator< _Val>  &
# 311
__y) 
# 312
{ return (__x._M_node) == (__y._M_node); } 
# 314
template< class _Val> inline bool 
# 316
operator!=(const _Rb_tree_iterator< _Val>  &__x, const _Rb_tree_const_iterator< _Val>  &
# 317
__y) 
# 318
{ return (__x._M_node) != (__y._M_node); } 
# 321
void _Rb_tree_insert_and_rebalance(const bool __insert_left, _Rb_tree_node_base * __x, _Rb_tree_node_base * __p, _Rb_tree_node_base & __header) throw(); 
# 327
_Rb_tree_node_base *_Rb_tree_rebalance_for_erase(_Rb_tree_node_base *const __z, _Rb_tree_node_base & __header) throw(); 
# 331
template< class _Key, class _Val, class _KeyOfValue, class 
# 332
_Compare, class _Alloc = allocator< _Val> > 
# 333
class _Rb_tree { 
# 336
typedef typename _Alloc::template rebind< _Rb_tree_node< _Val> > ::other _Node_allocator; 
# 339
protected: typedef _Rb_tree_node_base *_Base_ptr; 
# 340
typedef const _Rb_tree_node_base *_Const_Base_ptr; 
# 343
public: typedef _Key key_type; 
# 344
typedef _Val value_type; 
# 345
typedef value_type *pointer; 
# 346
typedef const value_type *const_pointer; 
# 347
typedef value_type &reference; 
# 348
typedef const value_type &const_reference; 
# 349
typedef _Rb_tree_node< _Val>  *_Link_type; 
# 350
typedef const _Rb_tree_node< _Val>  *_Const_Link_type; 
# 351
typedef size_t size_type; 
# 352
typedef ptrdiff_t difference_type; 
# 353
typedef _Alloc allocator_type; 
# 356
_Node_allocator &_M_get_Node_allocator() 
# 357
{ return *(static_cast< _Node_allocator *>(&(this->_M_impl))); } 
# 360
const _Node_allocator &_M_get_Node_allocator() const 
# 361
{ return *(static_cast< const _Node_allocator *>(&(this->_M_impl))); } 
# 364
allocator_type get_allocator() const 
# 365
{ return (allocator_type)this->_M_get_Node_allocator(); } 
# 369
protected: _Link_type _M_get_node() 
# 370
{ return ((_M_impl)._Node_allocator::allocate(1)); } 
# 373
void _M_put_node(_Link_type __p) 
# 374
{ ((_M_impl)._Node_allocator::deallocate(__p, 1)); } 
# 378
_Link_type _M_create_node(const value_type &__x) 
# 379
{ 
# 380
_Link_type __tmp = _M_get_node(); 
# 381
try 
# 382
{ (get_allocator().construct(std::__addressof((__tmp->_M_value_field)), __x)); 
# 383
} 
# 384
catch (...) 
# 385
{ 
# 386
_M_put_node(__tmp); 
# 387
throw; 
# 388
}  
# 389
return __tmp; 
# 390
} 
# 393
void _M_destroy_node(_Link_type __p) 
# 394
{ 
# 395
(get_allocator().destroy(std::__addressof((__p->_M_value_field)))); 
# 396
_M_put_node(__p); 
# 397
} 
# 427
_Link_type _M_clone_node(_Const_Link_type __x) 
# 428
{ 
# 429
_Link_type __tmp = _M_create_node((__x->_M_value_field)); 
# 430
(__tmp->_M_color) = (__x->_M_color); 
# 431
(__tmp->_M_left) = 0; 
# 432
(__tmp->_M_right) = 0; 
# 433
return __tmp; 
# 434
} 
# 437
template< class _Key_compare, bool 
# 438
_Is_pod_comparator = __is_pod(_Key_compare)> 
# 439
struct _Rb_tree_impl : public _Node_allocator { 
# 441
_Key_compare _M_key_compare; 
# 442
::std::_Rb_tree_node_base _M_header; 
# 443
typename ::std::_Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc> ::size_type _M_node_count; 
# 445
_Rb_tree_impl() : ::std::_Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc> ::_Node_allocator(), _M_key_compare(), _M_header(), _M_node_count((0)) 
# 448
{ _M_initialize(); } 
# 450
_Rb_tree_impl(const _Key_compare &__comp, const typename ::std::_Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc> ::_Node_allocator &__a) : ::std::_Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc> ::_Node_allocator(__a), _M_key_compare(__comp), _M_header(), _M_node_count((0)) 
# 453
{ _M_initialize(); } 
# 464
private: void _M_initialize() 
# 465
{ 
# 466
((this->_M_header)._M_color) = _S_red; 
# 467
((this->_M_header)._M_parent) = (0); 
# 468
((this->_M_header)._M_left) = (&(this->_M_header)); 
# 469
((this->_M_header)._M_right) = (&(this->_M_header)); 
# 470
} 
# 471
}; 
# 473
_Rb_tree_impl< _Compare>  _M_impl; 
# 477
_Base_ptr &_M_root() 
# 478
{ return ((this->_M_impl)._M_header)._M_parent; } 
# 481
_Const_Base_ptr _M_root() const 
# 482
{ return ((this->_M_impl)._M_header)._M_parent; } 
# 485
_Base_ptr &_M_leftmost() 
# 486
{ return ((this->_M_impl)._M_header)._M_left; } 
# 489
_Const_Base_ptr _M_leftmost() const 
# 490
{ return ((this->_M_impl)._M_header)._M_left; } 
# 493
_Base_ptr &_M_rightmost() 
# 494
{ return ((this->_M_impl)._M_header)._M_right; } 
# 497
_Const_Base_ptr _M_rightmost() const 
# 498
{ return ((this->_M_impl)._M_header)._M_right; } 
# 501
_Link_type _M_begin() 
# 502
{ return static_cast< _Link_type>(((this->_M_impl)._M_header)._M_parent); } 
# 505
_Const_Link_type _M_begin() const 
# 506
{ 
# 507
return static_cast< _Const_Link_type>(((this->_M_impl)._M_header)._M_parent); 
# 509
} 
# 512
_Link_type _M_end() 
# 513
{ return reinterpret_cast< _Link_type>(&((this->_M_impl)._M_header)); } 
# 516
_Const_Link_type _M_end() const 
# 517
{ return reinterpret_cast< _Const_Link_type>(&((this->_M_impl)._M_header)); } 
# 520
static const_reference _S_value(_Const_Link_type __x) 
# 521
{ return __x->_M_value_field; } 
# 524
static const _Key &_S_key(_Const_Link_type __x) 
# 525
{ return _KeyOfValue()(_S_value(__x)); } 
# 528
static _Link_type _S_left(_Base_ptr __x) 
# 529
{ return static_cast< _Link_type>(__x->_M_left); } 
# 532
static _Const_Link_type _S_left(_Const_Base_ptr __x) 
# 533
{ return static_cast< _Const_Link_type>(__x->_M_left); } 
# 536
static _Link_type _S_right(_Base_ptr __x) 
# 537
{ return static_cast< _Link_type>(__x->_M_right); } 
# 540
static _Const_Link_type _S_right(_Const_Base_ptr __x) 
# 541
{ return static_cast< _Const_Link_type>(__x->_M_right); } 
# 544
static const_reference _S_value(_Const_Base_ptr __x) 
# 545
{ return (static_cast< _Const_Link_type>(__x))->_M_value_field; } 
# 548
static const _Key &_S_key(_Const_Base_ptr __x) 
# 549
{ return _KeyOfValue()(_S_value(__x)); } 
# 552
static _Base_ptr _S_minimum(_Base_ptr __x) 
# 553
{ return _Rb_tree_node_base::_S_minimum(__x); } 
# 556
static _Const_Base_ptr _S_minimum(_Const_Base_ptr __x) 
# 557
{ return _Rb_tree_node_base::_S_minimum(__x); } 
# 560
static _Base_ptr _S_maximum(_Base_ptr __x) 
# 561
{ return _Rb_tree_node_base::_S_maximum(__x); } 
# 564
static _Const_Base_ptr _S_maximum(_Const_Base_ptr __x) 
# 565
{ return _Rb_tree_node_base::_S_maximum(__x); } 
# 568
public: typedef _Rb_tree_iterator< _Val>  iterator; 
# 569
typedef _Rb_tree_const_iterator< _Val>  const_iterator; 
# 571
typedef std::reverse_iterator< _Rb_tree_iterator< _Val> >  reverse_iterator; 
# 572
typedef std::reverse_iterator< _Rb_tree_const_iterator< _Val> >  const_reverse_iterator; 
# 576
private: pair< _Rb_tree_node_base *, _Rb_tree_node_base *>  _M_get_insert_unique_pos(const key_type & __k); 
# 579
pair< _Rb_tree_node_base *, _Rb_tree_node_base *>  _M_get_insert_equal_pos(const key_type & __k); 
# 582
pair< _Rb_tree_node_base *, _Rb_tree_node_base *>  _M_get_insert_hint_unique_pos(const_iterator __pos, const key_type & __k); 
# 586
pair< _Rb_tree_node_base *, _Rb_tree_node_base *>  _M_get_insert_hint_equal_pos(const_iterator __pos, const key_type & __k); 
# 612
iterator _M_insert_(_Base_ptr __x, _Base_ptr __y, const value_type & __v); 
# 618
iterator _M_insert_lower(_Base_ptr __y, const value_type & __v); 
# 621
iterator _M_insert_equal_lower(const value_type & __x); 
# 625
_Link_type _M_copy(_Const_Link_type __x, _Link_type __p); 
# 628
void _M_erase(_Link_type __x); 
# 631
iterator _M_lower_bound(_Link_type __x, _Link_type __y, const _Key & __k); 
# 635
const_iterator _M_lower_bound(_Const_Link_type __x, _Const_Link_type __y, const _Key & __k) const; 
# 639
iterator _M_upper_bound(_Link_type __x, _Link_type __y, const _Key & __k); 
# 643
const_iterator _M_upper_bound(_Const_Link_type __x, _Const_Link_type __y, const _Key & __k) const; 
# 648
public: _Rb_tree() { } 
# 650
_Rb_tree(const _Compare &__comp, const allocator_type &
# 651
__a = allocator_type()) : _M_impl(__comp, (_Node_allocator)__a) 
# 652
{ } 
# 654
_Rb_tree(const _Rb_tree &__x) : _M_impl(((__x._M_impl)._M_key_compare), __x._M_get_Node_allocator()) 
# 656
{ 
# 657
if (__x._M_root() != (0)) 
# 658
{ 
# 659
this->_M_root() = _M_copy(__x._M_begin(), this->_M_end()); 
# 660
this->_M_leftmost() = _S_minimum(this->_M_root()); 
# 661
this->_M_rightmost() = _S_maximum(this->_M_root()); 
# 662
((_M_impl)._M_node_count) = ((__x._M_impl)._M_node_count); 
# 663
}  
# 664
} 
# 670
~_Rb_tree() 
# 671
{ _M_erase(this->_M_begin()); } 
# 674
_Rb_tree &operator=(const _Rb_tree & __x); 
# 678
_Compare key_comp() const 
# 679
{ return (_M_impl)._M_key_compare; } 
# 682
iterator begin() 
# 683
{ 
# 684
return ((iterator)(static_cast< _Link_type>(((this->_M_impl)._M_header)._M_left))); 
# 686
} 
# 689
const_iterator begin() const 
# 690
{ 
# 691
return ((const_iterator)(static_cast< _Const_Link_type>(((this->_M_impl)._M_header)._M_left))); 
# 693
} 
# 696
iterator end() 
# 697
{ return ((iterator)(static_cast< _Link_type>(&((this->_M_impl)._M_header)))); } 
# 700
const_iterator end() const 
# 701
{ 
# 702
return ((const_iterator)(static_cast< _Const_Link_type>(&((this->_M_impl)._M_header)))); 
# 704
} 
# 707
reverse_iterator rbegin() 
# 708
{ return ((reverse_iterator)(this->end())); } 
# 711
const_reverse_iterator rbegin() const 
# 712
{ return ((const_reverse_iterator)(this->end())); } 
# 715
reverse_iterator rend() 
# 716
{ return ((reverse_iterator)(this->begin())); } 
# 719
const_reverse_iterator rend() const 
# 720
{ return ((const_reverse_iterator)(this->begin())); } 
# 723
bool empty() const 
# 724
{ return ((_M_impl)._M_node_count) == 0; } 
# 727
size_type size() const 
# 728
{ return (_M_impl)._M_node_count; } 
# 731
size_type max_size() const 
# 732
{ return (this->_M_get_Node_allocator().max_size()); } 
# 735
void swap(_Rb_tree & __t); 
# 772
pair< _Rb_tree_iterator< _Val> , bool>  _M_insert_unique(const value_type & __x); 
# 775
iterator _M_insert_equal(const value_type & __x); 
# 778
iterator _M_insert_unique_(const_iterator __position, const value_type & __x); 
# 781
iterator _M_insert_equal_(const_iterator __position, const value_type & __x); 
# 784
template< class _InputIterator> void _M_insert_unique(_InputIterator __first, _InputIterator __last); 
# 788
template< class _InputIterator> void _M_insert_equal(_InputIterator __first, _InputIterator __last); 
# 794
private: void _M_erase_aux(const_iterator __position); 
# 797
void _M_erase_aux(const_iterator __first, const_iterator __last); 
# 825
public: void erase(iterator __position) 
# 826
{ _M_erase_aux(__position); } 
# 829
void erase(const_iterator __position) 
# 830
{ _M_erase_aux(__position); } 
# 833
size_type erase(const key_type & __x); 
# 847
void erase(iterator __first, iterator __last) 
# 848
{ _M_erase_aux(__first, __last); } 
# 851
void erase(const_iterator __first, const_iterator __last) 
# 852
{ _M_erase_aux(__first, __last); } 
# 855
void erase(const key_type * __first, const key_type * __last); 
# 858
void clear() 
# 859
{ 
# 860
_M_erase(this->_M_begin()); 
# 861
this->_M_leftmost() = this->_M_end(); 
# 862
this->_M_root() = (0); 
# 863
this->_M_rightmost() = this->_M_end(); 
# 864
((_M_impl)._M_node_count) = 0; 
# 865
} 
# 869
iterator find(const key_type & __k); 
# 872
const_iterator find(const key_type & __k) const; 
# 875
size_type count(const key_type & __k) const; 
# 878
iterator lower_bound(const key_type &__k) 
# 879
{ return _M_lower_bound(this->_M_begin(), this->_M_end(), __k); } 
# 882
const_iterator lower_bound(const key_type &__k) const 
# 883
{ return _M_lower_bound(this->_M_begin(), this->_M_end(), __k); } 
# 886
iterator upper_bound(const key_type &__k) 
# 887
{ return _M_upper_bound(this->_M_begin(), this->_M_end(), __k); } 
# 890
const_iterator upper_bound(const key_type &__k) const 
# 891
{ return _M_upper_bound(this->_M_begin(), this->_M_end(), __k); } 
# 894
pair< _Rb_tree_iterator< _Val> , _Rb_tree_iterator< _Val> >  equal_range(const key_type & __k); 
# 897
pair< _Rb_tree_const_iterator< _Val> , _Rb_tree_const_iterator< _Val> >  equal_range(const key_type & __k) const; 
# 901
bool __rb_verify() const; 
# 902
}; 
# 904
template< class _Key, class _Val, class _KeyOfValue, class 
# 905
_Compare, class _Alloc> inline bool 
# 907
operator==(const _Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc>  &__x, const _Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc>  &
# 908
__y) 
# 909
{ 
# 910
return ((__x.size()) == (__y.size())) && std::equal((__x.begin()), (__x.end()), (__y.begin())); 
# 912
} 
# 914
template< class _Key, class _Val, class _KeyOfValue, class 
# 915
_Compare, class _Alloc> inline bool 
# 917
operator<(const _Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc>  &__x, const _Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc>  &
# 918
__y) 
# 919
{ 
# 920
return std::lexicographical_compare((__x.begin()), (__x.end()), (__y.begin()), (__y.end())); 
# 922
} 
# 924
template< class _Key, class _Val, class _KeyOfValue, class 
# 925
_Compare, class _Alloc> inline bool 
# 927
operator!=(const _Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc>  &__x, const _Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc>  &
# 928
__y) 
# 929
{ return !(__x == __y); } 
# 931
template< class _Key, class _Val, class _KeyOfValue, class 
# 932
_Compare, class _Alloc> inline bool 
# 934
operator>(const _Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc>  &__x, const _Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc>  &
# 935
__y) 
# 936
{ return __y < __x; } 
# 938
template< class _Key, class _Val, class _KeyOfValue, class 
# 939
_Compare, class _Alloc> inline bool 
# 941
operator<=(const _Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc>  &__x, const _Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc>  &
# 942
__y) 
# 943
{ return !(__y < __x); } 
# 945
template< class _Key, class _Val, class _KeyOfValue, class 
# 946
_Compare, class _Alloc> inline bool 
# 948
operator>=(const _Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc>  &__x, const _Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc>  &
# 949
__y) 
# 950
{ return !(__x < __y); } 
# 952
template< class _Key, class _Val, class _KeyOfValue, class 
# 953
_Compare, class _Alloc> inline void 
# 955
swap(_Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc>  &__x, _Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc>  &
# 956
__y) 
# 957
{ (__x.swap(__y)); } 
# 984
template< class _Key, class _Val, class _KeyOfValue, class 
# 985
_Compare, class _Alloc> _Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc>  &
# 988
_Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc> ::operator=(const _Rb_tree &__x) 
# 989
{ 
# 990
if (this != (&__x)) 
# 991
{ 
# 993
clear(); 
# 994
((_M_impl)._M_key_compare) = ((__x._M_impl)._M_key_compare); 
# 995
if (__x._M_root() != (0)) 
# 996
{ 
# 997
this->_M_root() = _M_copy(__x._M_begin(), this->_M_end()); 
# 998
this->_M_leftmost() = _S_minimum(this->_M_root()); 
# 999
this->_M_rightmost() = _S_maximum(this->_M_root()); 
# 1000
((_M_impl)._M_node_count) = ((__x._M_impl)._M_node_count); 
# 1001
}  
# 1002
}  
# 1003
return *this; 
# 1004
} 
# 1006
template< class _Key, class _Val, class _KeyOfValue, class 
# 1007
_Compare, class _Alloc> typename _Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc> ::iterator 
# 1016
_Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc> ::_M_insert_(_Base_ptr __x, _Base_ptr __p, const _Val &__v) 
# 1018
{ 
# 1019
bool __insert_left = ((__x != (0)) || (__p == this->_M_end())) || ((_M_impl)._M_key_compare(_KeyOfValue()(__v), _S_key(__p))); 
# 1023
_Link_type __z = _M_create_node(__v); 
# 1025
_Rb_tree_insert_and_rebalance(__insert_left, __z, __p, ((this->_M_impl)._M_header)); 
# 1027
++((_M_impl)._M_node_count); 
# 1028
return ((iterator)(__z)); 
# 1029
} 
# 1031
template< class _Key, class _Val, class _KeyOfValue, class 
# 1032
_Compare, class _Alloc> typename _Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc> ::iterator 
# 1041
_Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc> ::_M_insert_lower(_Base_ptr __p, const _Val &__v) 
# 1043
{ 
# 1044
bool __insert_left = (__p == this->_M_end()) || (!((_M_impl)._M_key_compare(_S_key(__p), _KeyOfValue()(__v)))); 
# 1048
_Link_type __z = _M_create_node(__v); 
# 1050
_Rb_tree_insert_and_rebalance(__insert_left, __z, __p, ((this->_M_impl)._M_header)); 
# 1052
++((_M_impl)._M_node_count); 
# 1053
return ((iterator)(__z)); 
# 1054
} 
# 1056
template< class _Key, class _Val, class _KeyOfValue, class 
# 1057
_Compare, class _Alloc> typename _Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc> ::iterator 
# 1066
_Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc> ::_M_insert_equal_lower(const _Val &__v) 
# 1068
{ 
# 1069
_Link_type __x = this->_M_begin(); 
# 1070
_Link_type __y = this->_M_end(); 
# 1071
while (__x != 0) 
# 1072
{ 
# 1073
__y = __x; 
# 1074
__x = ((!((_M_impl)._M_key_compare(_S_key(__x), _KeyOfValue()(__v)))) ? _S_left(__x) : _S_right(__x)); 
# 1076
}  
# 1077
return _M_insert_lower(__y, __v); 
# 1078
} 
# 1080
template< class _Key, class _Val, class _KoV, class 
# 1081
_Compare, class _Alloc> typename _Rb_tree< _Key, _Val, _KoV, _Compare, _Alloc> ::_Link_type 
# 1084
_Rb_tree< _Key, _Val, _KoV, _Compare, _Alloc> ::_M_copy(_Const_Link_type __x, _Link_type __p) 
# 1085
{ 
# 1087
_Link_type __top = _M_clone_node(__x); 
# 1088
(__top->_M_parent) = __p; 
# 1090
try 
# 1091
{ 
# 1092
if (__x->_M_right) { 
# 1093
(__top->_M_right) = _M_copy(_S_right(__x), __top); }  
# 1094
__p = __top; 
# 1095
__x = _S_left(__x); 
# 1097
while (__x != 0) 
# 1098
{ 
# 1099
_Link_type __y = _M_clone_node(__x); 
# 1100
(__p->_M_left) = __y; 
# 1101
(__y->_M_parent) = __p; 
# 1102
if (__x->_M_right) { 
# 1103
(__y->_M_right) = _M_copy(_S_right(__x), __y); }  
# 1104
__p = __y; 
# 1105
__x = _S_left(__x); 
# 1106
}  
# 1107
} 
# 1108
catch (...) 
# 1109
{ 
# 1110
_M_erase(__top); 
# 1111
throw; 
# 1112
}  
# 1113
return __top; 
# 1114
} 
# 1116
template< class _Key, class _Val, class _KeyOfValue, class 
# 1117
_Compare, class _Alloc> void 
# 1120
_Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc> ::_M_erase(_Link_type __x) 
# 1121
{ 
# 1123
while (__x != 0) 
# 1124
{ 
# 1125
_M_erase(_S_right(__x)); 
# 1126
_Link_type __y = _S_left(__x); 
# 1127
_M_destroy_node(__x); 
# 1128
__x = __y; 
# 1129
}  
# 1130
} 
# 1132
template< class _Key, class _Val, class _KeyOfValue, class 
# 1133
_Compare, class _Alloc> typename _Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc> ::iterator 
# 1137
_Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc> ::_M_lower_bound(_Link_type __x, _Link_type __y, const _Key &
# 1138
__k) 
# 1139
{ 
# 1140
while (__x != 0) { 
# 1141
if (!((_M_impl)._M_key_compare(_S_key(__x), __k))) { 
# 1142
(__y = __x), (__x = _S_left(__x)); } else { 
# 1144
__x = _S_right(__x); }  }  
# 1145
return ((iterator)(__y)); 
# 1146
} 
# 1148
template< class _Key, class _Val, class _KeyOfValue, class 
# 1149
_Compare, class _Alloc> typename _Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc> ::const_iterator 
# 1153
_Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc> ::_M_lower_bound(_Const_Link_type __x, _Const_Link_type __y, const _Key &
# 1154
__k) const 
# 1155
{ 
# 1156
while (__x != 0) { 
# 1157
if (!((_M_impl)._M_key_compare(_S_key(__x), __k))) { 
# 1158
(__y = __x), (__x = _S_left(__x)); } else { 
# 1160
__x = _S_right(__x); }  }  
# 1161
return ((const_iterator)(__y)); 
# 1162
} 
# 1164
template< class _Key, class _Val, class _KeyOfValue, class 
# 1165
_Compare, class _Alloc> typename _Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc> ::iterator 
# 1169
_Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc> ::_M_upper_bound(_Link_type __x, _Link_type __y, const _Key &
# 1170
__k) 
# 1171
{ 
# 1172
while (__x != 0) { 
# 1173
if (((_M_impl)._M_key_compare(__k, _S_key(__x)))) { 
# 1174
(__y = __x), (__x = _S_left(__x)); } else { 
# 1176
__x = _S_right(__x); }  }  
# 1177
return ((iterator)(__y)); 
# 1178
} 
# 1180
template< class _Key, class _Val, class _KeyOfValue, class 
# 1181
_Compare, class _Alloc> typename _Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc> ::const_iterator 
# 1185
_Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc> ::_M_upper_bound(_Const_Link_type __x, _Const_Link_type __y, const _Key &
# 1186
__k) const 
# 1187
{ 
# 1188
while (__x != 0) { 
# 1189
if (((_M_impl)._M_key_compare(__k, _S_key(__x)))) { 
# 1190
(__y = __x), (__x = _S_left(__x)); } else { 
# 1192
__x = _S_right(__x); }  }  
# 1193
return ((const_iterator)(__y)); 
# 1194
} 
# 1196
template< class _Key, class _Val, class _KeyOfValue, class 
# 1197
_Compare, class _Alloc> pair< _Rb_tree_iterator< _Val> , _Rb_tree_iterator< _Val> >  
# 1203
_Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc> ::equal_range(const _Key &__k) 
# 1204
{ 
# 1205
_Link_type __x = this->_M_begin(); 
# 1206
_Link_type __y = this->_M_end(); 
# 1207
while (__x != 0) 
# 1208
{ 
# 1209
if (((_M_impl)._M_key_compare(_S_key(__x), __k))) { 
# 1210
__x = _S_right(__x); } else { 
# 1211
if (((_M_impl)._M_key_compare(__k, _S_key(__x)))) { 
# 1212
(__y = __x), (__x = _S_left(__x)); } else 
# 1214
{ 
# 1215
_Link_type __xu(__x), __yu(__y); 
# 1216
(__y = __x), (__x = _S_left(__x)); 
# 1217
__xu = _S_right(__xu); 
# 1218
return pair< _Rb_tree_iterator< _Val> , _Rb_tree_iterator< _Val> > (_M_lower_bound(__x, __y, __k), _M_upper_bound(__xu, __yu, __k)); 
# 1221
}  }  
# 1222
}  
# 1223
return pair< _Rb_tree_iterator< _Val> , _Rb_tree_iterator< _Val> > (((iterator)(__y)), ((iterator)(__y))); 
# 1225
} 
# 1227
template< class _Key, class _Val, class _KeyOfValue, class 
# 1228
_Compare, class _Alloc> pair< _Rb_tree_const_iterator< _Val> , _Rb_tree_const_iterator< _Val> >  
# 1234
_Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc> ::equal_range(const _Key &__k) const 
# 1235
{ 
# 1236
_Const_Link_type __x = this->_M_begin(); 
# 1237
_Const_Link_type __y = this->_M_end(); 
# 1238
while (__x != 0) 
# 1239
{ 
# 1240
if (((_M_impl)._M_key_compare(_S_key(__x), __k))) { 
# 1241
__x = _S_right(__x); } else { 
# 1242
if (((_M_impl)._M_key_compare(__k, _S_key(__x)))) { 
# 1243
(__y = __x), (__x = _S_left(__x)); } else 
# 1245
{ 
# 1246
_Const_Link_type __xu(__x), __yu(__y); 
# 1247
(__y = __x), (__x = _S_left(__x)); 
# 1248
__xu = _S_right(__xu); 
# 1249
return pair< _Rb_tree_const_iterator< _Val> , _Rb_tree_const_iterator< _Val> > (_M_lower_bound(__x, __y, __k), _M_upper_bound(__xu, __yu, __k)); 
# 1252
}  }  
# 1253
}  
# 1254
return pair< _Rb_tree_const_iterator< _Val> , _Rb_tree_const_iterator< _Val> > (((const_iterator)(__y)), ((const_iterator)(__y))); 
# 1256
} 
# 1258
template< class _Key, class _Val, class _KeyOfValue, class 
# 1259
_Compare, class _Alloc> void 
# 1262
_Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc> ::swap(_Rb_tree &__t) 
# 1263
{ 
# 1264
if (this->_M_root() == (0)) 
# 1265
{ 
# 1266
if (__t._M_root() != (0)) 
# 1267
{ 
# 1268
this->_M_root() = __t._M_root(); 
# 1269
this->_M_leftmost() = __t._M_leftmost(); 
# 1270
this->_M_rightmost() = __t._M_rightmost(); 
# 1271
(this->_M_root()->_M_parent) = this->_M_end(); 
# 1273
__t._M_root() = (0); 
# 1274
__t._M_leftmost() = __t._M_end(); 
# 1275
__t._M_rightmost() = __t._M_end(); 
# 1276
}  
# 1277
} else { 
# 1278
if (__t._M_root() == (0)) 
# 1279
{ 
# 1280
__t._M_root() = this->_M_root(); 
# 1281
__t._M_leftmost() = this->_M_leftmost(); 
# 1282
__t._M_rightmost() = this->_M_rightmost(); 
# 1283
(__t._M_root()->_M_parent) = __t._M_end(); 
# 1285
this->_M_root() = (0); 
# 1286
this->_M_leftmost() = this->_M_end(); 
# 1287
this->_M_rightmost() = this->_M_end(); 
# 1288
} else 
# 1290
{ 
# 1291
std::swap(this->_M_root(), __t._M_root()); 
# 1292
std::swap(this->_M_leftmost(), __t._M_leftmost()); 
# 1293
std::swap(this->_M_rightmost(), __t._M_rightmost()); 
# 1295
(this->_M_root()->_M_parent) = this->_M_end(); 
# 1296
(__t._M_root()->_M_parent) = __t._M_end(); 
# 1297
}  }  
# 1299
std::swap(((this->_M_impl)._M_node_count), ((__t._M_impl)._M_node_count)); 
# 1300
std::swap(((this->_M_impl)._M_key_compare), ((__t._M_impl)._M_key_compare)); 
# 1304
std::__alloc_swap< typename _Alloc::template rebind< _Rb_tree_node< _Val> > ::other> ::_S_do_it(this->_M_get_Node_allocator(), __t._M_get_Node_allocator()); 
# 1306
} 
# 1308
template< class _Key, class _Val, class _KeyOfValue, class 
# 1309
_Compare, class _Alloc> pair< _Rb_tree_node_base *, _Rb_tree_node_base *>  
# 1315
_Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc> ::_M_get_insert_unique_pos(const key_type &__k) 
# 1316
{ 
# 1317
typedef pair< _Rb_tree_node_base *, _Rb_tree_node_base *>  _Res; 
# 1318
_Link_type __x = this->_M_begin(); 
# 1319
_Link_type __y = this->_M_end(); 
# 1320
bool __comp = true; 
# 1321
while (__x != 0) 
# 1322
{ 
# 1323
__y = __x; 
# 1324
__comp = ((_M_impl)._M_key_compare(__k, _S_key(__x))); 
# 1325
__x = (__comp ? _S_left(__x) : _S_right(__x)); 
# 1326
}  
# 1327
iterator __j = ((iterator)(__y)); 
# 1328
if (__comp) 
# 1329
{ 
# 1330
if (__j == this->begin()) { 
# 1331
return _Res(__x, __y); } else { 
# 1333
--__j; }  
# 1334
}  
# 1335
if (((_M_impl)._M_key_compare(_S_key((__j._M_node)), __k))) { 
# 1336
return _Res(__x, __y); }  
# 1337
return _Res((__j._M_node), 0); 
# 1338
} 
# 1340
template< class _Key, class _Val, class _KeyOfValue, class 
# 1341
_Compare, class _Alloc> pair< _Rb_tree_node_base *, _Rb_tree_node_base *>  
# 1347
_Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc> ::_M_get_insert_equal_pos(const key_type &__k) 
# 1348
{ 
# 1349
typedef pair< _Rb_tree_node_base *, _Rb_tree_node_base *>  _Res; 
# 1350
_Link_type __x = this->_M_begin(); 
# 1351
_Link_type __y = this->_M_end(); 
# 1352
while (__x != 0) 
# 1353
{ 
# 1354
__y = __x; 
# 1355
__x = ((((_M_impl)._M_key_compare(__k, _S_key(__x)))) ? _S_left(__x) : _S_right(__x)); 
# 1357
}  
# 1358
return _Res(__x, __y); 
# 1359
} 
# 1361
template< class _Key, class _Val, class _KeyOfValue, class 
# 1362
_Compare, class _Alloc> pair< _Rb_tree_iterator< _Val> , bool>  
# 1372
_Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc> ::_M_insert_unique(const _Val &__v) 
# 1374
{ 
# 1375
typedef pair< _Rb_tree_iterator< _Val> , bool>  _Res; 
# 1376
pair< _Rb_tree_node_base *, _Rb_tree_node_base *>  __res = _M_get_insert_unique_pos(_KeyOfValue()(__v)); 
# 1379
if (__res.second) { 
# 1380
return _Res(_M_insert_(__res.first, __res.second, __v), true); }  
# 1384
return _Res(((iterator)(static_cast< _Link_type>(__res.first))), false); 
# 1385
} 
# 1387
template< class _Key, class _Val, class _KeyOfValue, class 
# 1388
_Compare, class _Alloc> typename _Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc> ::iterator 
# 1397
_Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc> ::_M_insert_equal(const _Val &__v) 
# 1399
{ 
# 1400
pair< _Rb_tree_node_base *, _Rb_tree_node_base *>  __res = _M_get_insert_equal_pos(_KeyOfValue()(__v)); 
# 1402
return _M_insert_(__res.first, __res.second, __v); 
# 1403
} 
# 1405
template< class _Key, class _Val, class _KeyOfValue, class 
# 1406
_Compare, class _Alloc> pair< _Rb_tree_node_base *, _Rb_tree_node_base *>  
# 1412
_Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc> ::_M_get_insert_hint_unique_pos(const_iterator __position, const key_type &
# 1413
__k) 
# 1414
{ 
# 1415
iterator __pos = (__position._M_const_cast()); 
# 1416
typedef pair< _Rb_tree_node_base *, _Rb_tree_node_base *>  _Res; 
# 1419
if ((__pos._M_node) == this->_M_end()) 
# 1420
{ 
# 1421
if ((size() > 0) && ((_M_impl)._M_key_compare(_S_key(this->_M_rightmost()), __k))) { 
# 1423
return _Res(0, this->_M_rightmost()); } else { 
# 1425
return _M_get_insert_unique_pos(__k); }  
# 1426
} else { 
# 1427
if (((_M_impl)._M_key_compare(__k, _S_key((__pos._M_node))))) 
# 1428
{ 
# 1430
iterator __before = __pos; 
# 1431
if ((__pos._M_node) == this->_M_leftmost()) { 
# 1432
return _Res(this->_M_leftmost(), this->_M_leftmost()); } else { 
# 1433
if (((_M_impl)._M_key_compare(_S_key(((--__before)._M_node)), __k))) 
# 1434
{ 
# 1435
if (_S_right((__before._M_node)) == 0) { 
# 1436
return _Res(0, (__before._M_node)); } else { 
# 1438
return _Res((__pos._M_node), (__pos._M_node)); }  
# 1439
} else { 
# 1441
return _M_get_insert_unique_pos(__k); }  }  
# 1442
} else { 
# 1443
if (((_M_impl)._M_key_compare(_S_key((__pos._M_node)), __k))) 
# 1444
{ 
# 1446
iterator __after = __pos; 
# 1447
if ((__pos._M_node) == this->_M_rightmost()) { 
# 1448
return _Res(0, this->_M_rightmost()); } else { 
# 1449
if (((_M_impl)._M_key_compare(__k, _S_key(((++__after)._M_node))))) 
# 1450
{ 
# 1451
if (_S_right((__pos._M_node)) == 0) { 
# 1452
return _Res(0, (__pos._M_node)); } else { 
# 1454
return _Res((__after._M_node), (__after._M_node)); }  
# 1455
} else { 
# 1457
return _M_get_insert_unique_pos(__k); }  }  
# 1458
} else { 
# 1461
return _Res((__pos._M_node), 0); }  }  }  
# 1462
} 
# 1464
template< class _Key, class _Val, class _KeyOfValue, class 
# 1465
_Compare, class _Alloc> typename _Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc> ::iterator 
# 1474
_Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc> ::_M_insert_unique_(const_iterator __position, const _Val &__v) 
# 1476
{ 
# 1477
pair< _Rb_tree_node_base *, _Rb_tree_node_base *>  __res = _M_get_insert_hint_unique_pos(__position, _KeyOfValue()(__v)); 
# 1480
if (__res.second) { 
# 1481
return _M_insert_(__res.first, __res.second, __v); }  
# 1483
return ((iterator)(static_cast< _Link_type>(__res.first))); 
# 1484
} 
# 1486
template< class _Key, class _Val, class _KeyOfValue, class 
# 1487
_Compare, class _Alloc> pair< _Rb_tree_node_base *, _Rb_tree_node_base *>  
# 1493
_Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc> ::_M_get_insert_hint_equal_pos(const_iterator __position, const key_type &__k) 
# 1494
{ 
# 1495
iterator __pos = (__position._M_const_cast()); 
# 1496
typedef pair< _Rb_tree_node_base *, _Rb_tree_node_base *>  _Res; 
# 1499
if ((__pos._M_node) == this->_M_end()) 
# 1500
{ 
# 1501
if ((size() > 0) && (!((_M_impl)._M_key_compare(__k, _S_key(this->_M_rightmost()))))) { 
# 1503
return _Res(0, this->_M_rightmost()); } else { 
# 1505
return _M_get_insert_equal_pos(__k); }  
# 1506
} else { 
# 1507
if (!((_M_impl)._M_key_compare(_S_key((__pos._M_node)), __k))) 
# 1508
{ 
# 1510
iterator __before = __pos; 
# 1511
if ((__pos._M_node) == this->_M_leftmost()) { 
# 1512
return _Res(this->_M_leftmost(), this->_M_leftmost()); } else { 
# 1513
if (!((_M_impl)._M_key_compare(__k, _S_key(((--__before)._M_node))))) 
# 1514
{ 
# 1515
if (_S_right((__before._M_node)) == 0) { 
# 1516
return _Res(0, (__before._M_node)); } else { 
# 1518
return _Res((__pos._M_node), (__pos._M_node)); }  
# 1519
} else { 
# 1521
return _M_get_insert_equal_pos(__k); }  }  
# 1522
} else 
# 1524
{ 
# 1526
iterator __after = __pos; 
# 1527
if ((__pos._M_node) == this->_M_rightmost()) { 
# 1528
return _Res(0, this->_M_rightmost()); } else { 
# 1529
if (!((_M_impl)._M_key_compare(_S_key(((++__after)._M_node)), __k))) 
# 1530
{ 
# 1531
if (_S_right((__pos._M_node)) == 0) { 
# 1532
return _Res(0, (__pos._M_node)); } else { 
# 1534
return _Res((__after._M_node), (__after._M_node)); }  
# 1535
} else { 
# 1537
return _Res(0, 0); }  }  
# 1538
}  }  
# 1539
} 
# 1541
template< class _Key, class _Val, class _KeyOfValue, class 
# 1542
_Compare, class _Alloc> typename _Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc> ::iterator 
# 1551
_Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc> ::_M_insert_equal_(const_iterator __position, const _Val &__v) 
# 1553
{ 
# 1554
pair< _Rb_tree_node_base *, _Rb_tree_node_base *>  __res = _M_get_insert_hint_equal_pos(__position, _KeyOfValue()(__v)); 
# 1557
if (__res.second) { 
# 1558
return _M_insert_(__res.first, __res.second, __v); }  
# 1561
return _M_insert_equal_lower(__v); 
# 1562
} 
# 1714
template< class _Key, class _Val, class _KoV, class 
# 1715
_Cmp, class _Alloc> 
# 1716
template< class _II> void 
# 1719
_Rb_tree< _Key, _Val, _KoV, _Cmp, _Alloc> ::_M_insert_unique(_II __first, _II __last) 
# 1720
{ 
# 1721
for (; __first != __last; ++__first) { 
# 1722
_M_insert_unique_(this->end(), *__first); }  
# 1723
} 
# 1725
template< class _Key, class _Val, class _KoV, class 
# 1726
_Cmp, class _Alloc> 
# 1727
template< class _II> void 
# 1730
_Rb_tree< _Key, _Val, _KoV, _Cmp, _Alloc> ::_M_insert_equal(_II __first, _II __last) 
# 1731
{ 
# 1732
for (; __first != __last; ++__first) { 
# 1733
_M_insert_equal_(this->end(), *__first); }  
# 1734
} 
# 1736
template< class _Key, class _Val, class _KeyOfValue, class 
# 1737
_Compare, class _Alloc> void 
# 1740
_Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc> ::_M_erase_aux(const_iterator __position) 
# 1741
{ 
# 1742
_Link_type __y = static_cast< _Link_type>(_Rb_tree_rebalance_for_erase(const_cast< _Base_ptr>(__position._M_node), ((this->_M_impl)._M_header))); 
# 1746
_M_destroy_node(__y); 
# 1747
--((_M_impl)._M_node_count); 
# 1748
} 
# 1750
template< class _Key, class _Val, class _KeyOfValue, class 
# 1751
_Compare, class _Alloc> void 
# 1754
_Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc> ::_M_erase_aux(const_iterator __first, const_iterator __last) 
# 1755
{ 
# 1756
if ((__first == this->begin()) && (__last == this->end())) { 
# 1757
clear(); } else { 
# 1759
while (__first != __last) { 
# 1760
erase(__first++); }  }  
# 1761
} 
# 1763
template< class _Key, class _Val, class _KeyOfValue, class 
# 1764
_Compare, class _Alloc> typename _Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc> ::size_type 
# 1767
_Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc> ::erase(const _Key &__x) 
# 1768
{ 
# 1769
pair< _Rb_tree_iterator< _Val> , _Rb_tree_iterator< _Val> >  __p = equal_range(__x); 
# 1770
const size_type __old_size = size(); 
# 1771
erase((__p.first), (__p.second)); 
# 1772
return __old_size - size(); 
# 1773
} 
# 1775
template< class _Key, class _Val, class _KeyOfValue, class 
# 1776
_Compare, class _Alloc> void 
# 1779
_Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc> ::erase(const _Key *__first, const _Key *__last) 
# 1780
{ 
# 1781
while (__first != __last) { 
# 1782
erase(*(__first++)); }  
# 1783
} 
# 1785
template< class _Key, class _Val, class _KeyOfValue, class 
# 1786
_Compare, class _Alloc> typename _Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc> ::iterator 
# 1790
_Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc> ::find(const _Key &__k) 
# 1791
{ 
# 1792
iterator __j = _M_lower_bound(this->_M_begin(), this->_M_end(), __k); 
# 1793
return ((__j == this->end()) || ((_M_impl)._M_key_compare(__k, _S_key((__j._M_node))))) ? this->end() : __j; 
# 1796
} 
# 1798
template< class _Key, class _Val, class _KeyOfValue, class 
# 1799
_Compare, class _Alloc> typename _Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc> ::const_iterator 
# 1803
_Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc> ::find(const _Key &__k) const 
# 1804
{ 
# 1805
const_iterator __j = _M_lower_bound(this->_M_begin(), this->_M_end(), __k); 
# 1806
return ((__j == this->end()) || ((_M_impl)._M_key_compare(__k, _S_key((__j._M_node))))) ? this->end() : __j; 
# 1809
} 
# 1811
template< class _Key, class _Val, class _KeyOfValue, class 
# 1812
_Compare, class _Alloc> typename _Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc> ::size_type 
# 1815
_Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc> ::count(const _Key &__k) const 
# 1816
{ 
# 1817
pair< _Rb_tree_const_iterator< _Val> , _Rb_tree_const_iterator< _Val> >  __p = equal_range(__k); 
# 1818
const size_type __n = std::distance((__p.first), (__p.second)); 
# 1819
return __n; 
# 1820
} 
# 1822
__attribute((__pure__)) unsigned 
# 1823
_Rb_tree_black_count(const _Rb_tree_node_base * __node, const _Rb_tree_node_base * __root) throw(); 
# 1826
template< class _Key, class _Val, class _KeyOfValue, class 
# 1827
_Compare, class _Alloc> bool 
# 1829
_Rb_tree< _Key, _Val, _KeyOfValue, _Compare, _Alloc> ::__rb_verify() const 
# 1830
{ 
# 1831
if ((((_M_impl)._M_node_count) == 0) || (this->begin() == this->end())) { 
# 1832
return (((_M_impl)._M_node_count) == 0) && (this->begin() == this->end()) && ((((this->_M_impl)._M_header)._M_left) == this->_M_end()) && ((((this->_M_impl)._M_header)._M_right) == this->_M_end()); }  
# 1836
unsigned __len = _Rb_tree_black_count(this->_M_leftmost(), this->_M_root()); 
# 1837
for (const_iterator __it = this->begin(); __it != this->end(); ++__it) 
# 1838
{ 
# 1839
_Const_Link_type __x = static_cast< _Const_Link_type>(__it._M_node); 
# 1840
_Const_Link_type __L = _S_left(__x); 
# 1841
_Const_Link_type __R = _S_right(__x); 
# 1843
if ((__x->_M_color) == _S_red) { 
# 1844
if ((__L && ((__L->_M_color) == _S_red)) || (__R && ((__R->_M_color) == _S_red))) { 
# 1846
return false; }  }  
# 1848
if (__L && ((_M_impl)._M_key_compare(_S_key(__x), _S_key(__L)))) { 
# 1849
return false; }  
# 1850
if (__R && ((_M_impl)._M_key_compare(_S_key(__R), _S_key(__x)))) { 
# 1851
return false; }  
# 1853
if ((!__L) && (!__R) && (_Rb_tree_black_count(__x, this->_M_root()) != __len)) { 
# 1854
return false; }  
# 1855
}  
# 1857
if (this->_M_leftmost() != _Rb_tree_node_base::_S_minimum(this->_M_root())) { 
# 1858
return false; }  
# 1859
if (this->_M_rightmost() != _Rb_tree_node_base::_S_maximum(this->_M_root())) { 
# 1860
return false; }  
# 1861
return true; 
# 1862
} 
# 1865
}
# 64 "/usr/include/c++/4.8.2/bits/stl_set.h" 3
namespace std __attribute((__visibility__("default"))) { 
# 88
template< class _Key, class _Compare = less< _Key> , class 
# 89
_Alloc = allocator< _Key> > 
# 90
class set { 
# 93
typedef typename _Alloc::value_type _Alloc_value_type; 
# 103
public: typedef _Key key_type; 
# 104
typedef _Key value_type; 
# 105
typedef _Compare key_compare; 
# 106
typedef _Compare value_compare; 
# 107
typedef _Alloc allocator_type; 
# 111
private: typedef typename _Alloc::template rebind< _Key> ::other _Key_alloc_type; 
# 114
typedef _Rb_tree< _Key, _Key, _Identity< _Key> , _Compare, typename _Alloc::template rebind< _Key> ::other>  _Rep_type; 
# 115
_Rep_type _M_t; 
# 120
public: typedef typename _Alloc::template rebind< _Key> ::other::pointer pointer; 
# 121
typedef typename _Alloc::template rebind< _Key> ::other::const_pointer const_pointer; 
# 122
typedef typename _Alloc::template rebind< _Key> ::other::reference reference; 
# 123
typedef typename _Alloc::template rebind< _Key> ::other::const_reference const_reference; 
# 127
typedef typename _Rb_tree< _Key, _Key, _Identity< _Key> , _Compare, typename _Alloc::template rebind< _Key> ::other> ::const_iterator iterator; 
# 128
typedef typename _Rb_tree< _Key, _Key, _Identity< _Key> , _Compare, typename _Alloc::template rebind< _Key> ::other> ::const_iterator const_iterator; 
# 129
typedef typename _Rb_tree< _Key, _Key, _Identity< _Key> , _Compare, typename _Alloc::template rebind< _Key> ::other> ::const_reverse_iterator reverse_iterator; 
# 130
typedef typename _Rb_tree< _Key, _Key, _Identity< _Key> , _Compare, typename _Alloc::template rebind< _Key> ::other> ::const_reverse_iterator const_reverse_iterator; 
# 131
typedef typename _Rb_tree< _Key, _Key, _Identity< _Key> , _Compare, typename _Alloc::template rebind< _Key> ::other> ::size_type size_type; 
# 132
typedef typename _Rb_tree< _Key, _Key, _Identity< _Key> , _Compare, typename _Alloc::template rebind< _Key> ::other> ::difference_type difference_type; 
# 139
set() : _M_t() 
# 140
{ } 
# 148
explicit set(const _Compare &__comp, const allocator_type &
# 149
__a = allocator_type()) : _M_t(__comp, (_Key_alloc_type)__a) 
# 150
{ } 
# 162
template< class _InputIterator> 
# 163
set(_InputIterator __first, _InputIterator __last) : _M_t() 
# 165
{ ((_M_t)._M_insert_unique(__first, __last)); } 
# 179
template< class _InputIterator> 
# 180
set(_InputIterator __first, _InputIterator __last, const _Compare &
# 181
__comp, const allocator_type &
# 182
__a = allocator_type()) : _M_t(__comp, (_Key_alloc_type)__a) 
# 184
{ ((_M_t)._M_insert_unique(__first, __last)); } 
# 193
set(const set &__x) : _M_t(__x._M_t) 
# 194
{ } 
# 233
set &operator=(const set &__x) 
# 234
{ 
# 235
(_M_t) = (__x._M_t); 
# 236
return *this; 
# 237
} 
# 281
key_compare key_comp() const 
# 282
{ return ((_M_t).key_comp()); } 
# 285
value_compare value_comp() const 
# 286
{ return ((_M_t).key_comp()); } 
# 289
allocator_type get_allocator() const 
# 290
{ return (allocator_type)((_M_t).get_allocator()); } 
# 298
iterator begin() const 
# 299
{ return ((_M_t).begin()); } 
# 307
iterator end() const 
# 308
{ return ((_M_t).end()); } 
# 316
reverse_iterator rbegin() const 
# 317
{ return ((_M_t).rbegin()); } 
# 325
reverse_iterator rend() const 
# 326
{ return ((_M_t).rend()); } 
# 368
bool empty() const 
# 369
{ return ((_M_t).empty()); } 
# 373
size_type size() const 
# 374
{ return ((_M_t).size()); } 
# 378
size_type max_size() const 
# 379
{ return ((_M_t).max_size()); } 
# 393
void swap(set &__x) 
# 394
{ ((_M_t).swap(__x._M_t)); } 
# 460
pair< typename _Rb_tree< _Key, _Key, _Identity< _Key> , _Compare, typename _Alloc::template rebind< _Key> ::other> ::const_iterator, bool>  insert(const value_type &__x) 
# 461
{ 
# 462
pair< typename _Rb_tree< _Key, _Key, _Identity< _Key> , _Compare, typename _Alloc::template rebind< _Key> ::other> ::iterator, bool>  __p = ((_M_t)._M_insert_unique(__x)); 
# 464
return pair< typename _Rb_tree< _Key, _Key, _Identity< _Key> , _Compare, typename _Alloc::template rebind< _Key> ::other> ::const_iterator, bool> ((__p.first), (__p.second)); 
# 465
} 
# 497
iterator insert(const_iterator __position, const value_type &__x) 
# 498
{ return ((_M_t)._M_insert_unique_(__position, __x)); } 
# 515
template< class _InputIterator> void 
# 517
insert(_InputIterator __first, _InputIterator __last) 
# 518
{ ((_M_t)._M_insert_unique(__first, __last)); } 
# 565
void erase(iterator __position) 
# 566
{ ((_M_t).erase(__position)); } 
# 581
size_type erase(const key_type &__x) 
# 582
{ return ((_M_t).erase(__x)); } 
# 619
void erase(iterator __first, iterator __last) 
# 620
{ ((_M_t).erase(__first, __last)); } 
# 630
void clear() 
# 631
{ ((_M_t).clear()); } 
# 644
size_type count(const key_type &__x) const 
# 645
{ return (((_M_t).find(__x)) == ((_M_t).end())) ? 0 : 1; } 
# 662
iterator find(const key_type &__x) 
# 663
{ return ((_M_t).find(__x)); } 
# 666
const_iterator find(const key_type &__x) const 
# 667
{ return ((_M_t).find(__x)); } 
# 683
iterator lower_bound(const key_type &__x) 
# 684
{ return ((_M_t).lower_bound(__x)); } 
# 687
const_iterator lower_bound(const key_type &__x) const 
# 688
{ return ((_M_t).lower_bound(__x)); } 
# 699
iterator upper_bound(const key_type &__x) 
# 700
{ return ((_M_t).upper_bound(__x)); } 
# 703
const_iterator upper_bound(const key_type &__x) const 
# 704
{ return ((_M_t).upper_bound(__x)); } 
# 724
pair< typename _Rb_tree< _Key, _Key, _Identity< _Key> , _Compare, typename _Alloc::template rebind< _Key> ::other> ::const_iterator, typename _Rb_tree< _Key, _Key, _Identity< _Key> , _Compare, typename _Alloc::template rebind< _Key> ::other> ::const_iterator>  equal_range(const key_type &__x) 
# 725
{ return ((_M_t).equal_range(__x)); } 
# 728
pair< typename _Rb_tree< _Key, _Key, _Identity< _Key> , _Compare, typename _Alloc::template rebind< _Key> ::other> ::const_iterator, typename _Rb_tree< _Key, _Key, _Identity< _Key> , _Compare, typename _Alloc::template rebind< _Key> ::other> ::const_iterator>  equal_range(const key_type &__x) const 
# 729
{ return ((_M_t).equal_range(__x)); } 
# 732
template< class _K1, class _C1, class _A1> friend bool operator==(const std::set< _K1, _C1, _A1>  &, const std::set< _K1, _C1, _A1>  &); 
# 736
template< class _K1, class _C1, class _A1> friend bool operator<(const std::set< _K1, _C1, _A1>  &, const std::set< _K1, _C1, _A1>  &); 
# 739
}; 
# 752
template< class _Key, class _Compare, class _Alloc> inline bool 
# 754
operator==(const set< _Key, _Compare, _Alloc>  &__x, const set< _Key, _Compare, _Alloc>  &
# 755
__y) 
# 756
{ return (__x._M_t) == (__y._M_t); } 
# 769
template< class _Key, class _Compare, class _Alloc> inline bool 
# 771
operator<(const set< _Key, _Compare, _Alloc>  &__x, const set< _Key, _Compare, _Alloc>  &
# 772
__y) 
# 773
{ return (__x._M_t) < (__y._M_t); } 
# 776
template< class _Key, class _Compare, class _Alloc> inline bool 
# 778
operator!=(const set< _Key, _Compare, _Alloc>  &__x, const set< _Key, _Compare, _Alloc>  &
# 779
__y) 
# 780
{ return !(__x == __y); } 
# 783
template< class _Key, class _Compare, class _Alloc> inline bool 
# 785
operator>(const set< _Key, _Compare, _Alloc>  &__x, const set< _Key, _Compare, _Alloc>  &
# 786
__y) 
# 787
{ return __y < __x; } 
# 790
template< class _Key, class _Compare, class _Alloc> inline bool 
# 792
operator<=(const set< _Key, _Compare, _Alloc>  &__x, const set< _Key, _Compare, _Alloc>  &
# 793
__y) 
# 794
{ return !(__y < __x); } 
# 797
template< class _Key, class _Compare, class _Alloc> inline bool 
# 799
operator>=(const set< _Key, _Compare, _Alloc>  &__x, const set< _Key, _Compare, _Alloc>  &
# 800
__y) 
# 801
{ return !(__x < __y); } 
# 804
template< class _Key, class _Compare, class _Alloc> inline void 
# 806
swap(set< _Key, _Compare, _Alloc>  &__x, set< _Key, _Compare, _Alloc>  &__y) 
# 807
{ (__x.swap(__y)); } 
# 810
}
# 64 "/usr/include/c++/4.8.2/bits/stl_multiset.h" 3
namespace std __attribute((__visibility__("default"))) { 
# 90
template< class _Key, class _Compare = less< _Key> , class 
# 91
_Alloc = allocator< _Key> > 
# 92
class multiset { 
# 95
typedef typename _Alloc::value_type _Alloc_value_type; 
# 103
public: typedef _Key key_type; 
# 104
typedef _Key value_type; 
# 105
typedef _Compare key_compare; 
# 106
typedef _Compare value_compare; 
# 107
typedef _Alloc allocator_type; 
# 111
private: typedef typename _Alloc::template rebind< _Key> ::other _Key_alloc_type; 
# 114
typedef _Rb_tree< _Key, _Key, _Identity< _Key> , _Compare, typename _Alloc::template rebind< _Key> ::other>  _Rep_type; 
# 116
_Rep_type _M_t; 
# 119
public: typedef typename _Alloc::template rebind< _Key> ::other::pointer pointer; 
# 120
typedef typename _Alloc::template rebind< _Key> ::other::const_pointer const_pointer; 
# 121
typedef typename _Alloc::template rebind< _Key> ::other::reference reference; 
# 122
typedef typename _Alloc::template rebind< _Key> ::other::const_reference const_reference; 
# 126
typedef typename _Rb_tree< _Key, _Key, _Identity< _Key> , _Compare, typename _Alloc::template rebind< _Key> ::other> ::const_iterator iterator; 
# 127
typedef typename _Rb_tree< _Key, _Key, _Identity< _Key> , _Compare, typename _Alloc::template rebind< _Key> ::other> ::const_iterator const_iterator; 
# 128
typedef typename _Rb_tree< _Key, _Key, _Identity< _Key> , _Compare, typename _Alloc::template rebind< _Key> ::other> ::const_reverse_iterator reverse_iterator; 
# 129
typedef typename _Rb_tree< _Key, _Key, _Identity< _Key> , _Compare, typename _Alloc::template rebind< _Key> ::other> ::const_reverse_iterator const_reverse_iterator; 
# 130
typedef typename _Rb_tree< _Key, _Key, _Identity< _Key> , _Compare, typename _Alloc::template rebind< _Key> ::other> ::size_type size_type; 
# 131
typedef typename _Rb_tree< _Key, _Key, _Identity< _Key> , _Compare, typename _Alloc::template rebind< _Key> ::other> ::difference_type difference_type; 
# 137
multiset() : _M_t() 
# 138
{ } 
# 146
explicit multiset(const _Compare &__comp, const allocator_type &
# 147
__a = allocator_type()) : _M_t(__comp, (_Key_alloc_type)__a) 
# 148
{ } 
# 159
template< class _InputIterator> 
# 160
multiset(_InputIterator __first, _InputIterator __last) : _M_t() 
# 162
{ ((_M_t)._M_insert_equal(__first, __last)); } 
# 175
template< class _InputIterator> 
# 176
multiset(_InputIterator __first, _InputIterator __last, const _Compare &
# 177
__comp, const allocator_type &
# 178
__a = allocator_type()) : _M_t(__comp, (_Key_alloc_type)__a) 
# 180
{ ((_M_t)._M_insert_equal(__first, __last)); } 
# 189
multiset(const multiset &__x) : _M_t(__x._M_t) 
# 190
{ } 
# 229
multiset &operator=(const multiset &__x) 
# 230
{ 
# 231
(_M_t) = (__x._M_t); 
# 232
return *this; 
# 233
} 
# 278
key_compare key_comp() const 
# 279
{ return ((_M_t).key_comp()); } 
# 282
value_compare value_comp() const 
# 283
{ return ((_M_t).key_comp()); } 
# 286
allocator_type get_allocator() const 
# 287
{ return (allocator_type)((_M_t).get_allocator()); } 
# 295
iterator begin() const 
# 296
{ return ((_M_t).begin()); } 
# 304
iterator end() const 
# 305
{ return ((_M_t).end()); } 
# 313
reverse_iterator rbegin() const 
# 314
{ return ((_M_t).rbegin()); } 
# 322
reverse_iterator rend() const 
# 323
{ return ((_M_t).rend()); } 
# 365
bool empty() const 
# 366
{ return ((_M_t).empty()); } 
# 370
size_type size() const 
# 371
{ return ((_M_t).size()); } 
# 375
size_type max_size() const 
# 376
{ return ((_M_t).max_size()); } 
# 390
void swap(multiset &__x) 
# 391
{ ((_M_t).swap(__x._M_t)); } 
# 454
iterator insert(const value_type &__x) 
# 455
{ return ((_M_t)._M_insert_equal(__x)); } 
# 484
iterator insert(const_iterator __position, const value_type &__x) 
# 485
{ return ((_M_t)._M_insert_equal_(__position, __x)); } 
# 501
template< class _InputIterator> void 
# 503
insert(_InputIterator __first, _InputIterator __last) 
# 504
{ ((_M_t)._M_insert_equal(__first, __last)); } 
# 551
void erase(iterator __position) 
# 552
{ ((_M_t).erase(__position)); } 
# 567
size_type erase(const key_type &__x) 
# 568
{ return ((_M_t).erase(__x)); } 
# 605
void erase(iterator __first, iterator __last) 
# 606
{ ((_M_t).erase(__first, __last)); } 
# 616
void clear() 
# 617
{ ((_M_t).clear()); } 
# 627
size_type count(const key_type &__x) const 
# 628
{ return ((_M_t).count(__x)); } 
# 645
iterator find(const key_type &__x) 
# 646
{ return ((_M_t).find(__x)); } 
# 649
const_iterator find(const key_type &__x) const 
# 650
{ return ((_M_t).find(__x)); } 
# 666
iterator lower_bound(const key_type &__x) 
# 667
{ return ((_M_t).lower_bound(__x)); } 
# 670
const_iterator lower_bound(const key_type &__x) const 
# 671
{ return ((_M_t).lower_bound(__x)); } 
# 682
iterator upper_bound(const key_type &__x) 
# 683
{ return ((_M_t).upper_bound(__x)); } 
# 686
const_iterator upper_bound(const key_type &__x) const 
# 687
{ return ((_M_t).upper_bound(__x)); } 
# 707
pair< typename _Rb_tree< _Key, _Key, _Identity< _Key> , _Compare, typename _Alloc::template rebind< _Key> ::other> ::const_iterator, typename _Rb_tree< _Key, _Key, _Identity< _Key> , _Compare, typename _Alloc::template rebind< _Key> ::other> ::const_iterator>  equal_range(const key_type &__x) 
# 708
{ return ((_M_t).equal_range(__x)); } 
# 711
pair< typename _Rb_tree< _Key, _Key, _Identity< _Key> , _Compare, typename _Alloc::template rebind< _Key> ::other> ::const_iterator, typename _Rb_tree< _Key, _Key, _Identity< _Key> , _Compare, typename _Alloc::template rebind< _Key> ::other> ::const_iterator>  equal_range(const key_type &__x) const 
# 712
{ return ((_M_t).equal_range(__x)); } 
# 715
template< class _K1, class _C1, class _A1> friend bool operator==(const std::multiset< _K1, _C1, _A1>  &, const std::multiset< _K1, _C1, _A1>  &); 
# 720
template< class _K1, class _C1, class _A1> friend bool operator<(const std::multiset< _K1, _C1, _A1>  &, const std::multiset< _K1, _C1, _A1>  &); 
# 724
}; 
# 737
template< class _Key, class _Compare, class _Alloc> inline bool 
# 739
operator==(const multiset< _Key, _Compare, _Alloc>  &__x, const multiset< _Key, _Compare, _Alloc>  &
# 740
__y) 
# 741
{ return (__x._M_t) == (__y._M_t); } 
# 754
template< class _Key, class _Compare, class _Alloc> inline bool 
# 756
operator<(const multiset< _Key, _Compare, _Alloc>  &__x, const multiset< _Key, _Compare, _Alloc>  &
# 757
__y) 
# 758
{ return (__x._M_t) < (__y._M_t); } 
# 761
template< class _Key, class _Compare, class _Alloc> inline bool 
# 763
operator!=(const multiset< _Key, _Compare, _Alloc>  &__x, const multiset< _Key, _Compare, _Alloc>  &
# 764
__y) 
# 765
{ return !(__x == __y); } 
# 768
template< class _Key, class _Compare, class _Alloc> inline bool 
# 770
operator>(const multiset< _Key, _Compare, _Alloc>  &__x, const multiset< _Key, _Compare, _Alloc>  &
# 771
__y) 
# 772
{ return __y < __x; } 
# 775
template< class _Key, class _Compare, class _Alloc> inline bool 
# 777
operator<=(const multiset< _Key, _Compare, _Alloc>  &__x, const multiset< _Key, _Compare, _Alloc>  &
# 778
__y) 
# 779
{ return !(__y < __x); } 
# 782
template< class _Key, class _Compare, class _Alloc> inline bool 
# 784
operator>=(const multiset< _Key, _Compare, _Alloc>  &__x, const multiset< _Key, _Compare, _Alloc>  &
# 785
__y) 
# 786
{ return !(__x < __y); } 
# 789
template< class _Key, class _Compare, class _Alloc> inline void 
# 791
swap(multiset< _Key, _Compare, _Alloc>  &__x, multiset< _Key, _Compare, _Alloc>  &
# 792
__y) 
# 793
{ (__x.swap(__y)); } 
# 796
}
# 66 "/usr/include/c++/4.8.2/bits/stl_map.h" 3
namespace std __attribute((__visibility__("default"))) { 
# 94
template< class _Key, class _Tp, class _Compare = less< _Key> , class 
# 95
_Alloc = allocator< pair< const _Key, _Tp> > > 
# 96
class map { 
# 99
public: typedef _Key key_type; 
# 100
typedef _Tp mapped_type; 
# 101
typedef pair< const _Key, _Tp>  value_type; 
# 102
typedef _Compare key_compare; 
# 103
typedef _Alloc allocator_type; 
# 107
private: typedef typename _Alloc::value_type _Alloc_value_type; 
# 114
public: class value_compare : public binary_function< pair< const _Key, _Tp> , pair< const _Key, _Tp> , bool>  { 
# 117
friend class map; 
# 119
protected: _Compare comp; 
# 121
value_compare(_Compare __c) : comp(__c) 
# 122
{ } 
# 125
public: bool operator()(const typename ::std::map< _Key, _Tp, _Compare, _Alloc> ::value_type &__x, const typename ::std::map< _Key, _Tp, _Compare, _Alloc> ::value_type &__y) const 
# 126
{ return (comp)((__x.first), (__y.first)); } 
# 127
}; 
# 132
private: typedef typename _Alloc::template rebind< pair< const _Key, _Tp> > ::other _Pair_alloc_type; 
# 135
typedef _Rb_tree< _Key, pair< const _Key, _Tp> , _Select1st< pair< const _Key, _Tp> > , _Compare, typename _Alloc::template rebind< pair< const _Key, _Tp> > ::other>  _Rep_type; 
# 138
_Rep_type _M_t; 
# 143
public: typedef typename _Alloc::template rebind< pair< const _Key, _Tp> > ::other::pointer pointer; 
# 144
typedef typename _Alloc::template rebind< pair< const _Key, _Tp> > ::other::const_pointer const_pointer; 
# 145
typedef typename _Alloc::template rebind< pair< const _Key, _Tp> > ::other::reference reference; 
# 146
typedef typename _Alloc::template rebind< pair< const _Key, _Tp> > ::other::const_reference const_reference; 
# 147
typedef typename _Rb_tree< _Key, pair< const _Key, _Tp> , _Select1st< pair< const _Key, _Tp> > , _Compare, typename _Alloc::template rebind< pair< const _Key, _Tp> > ::other> ::iterator iterator; 
# 148
typedef typename _Rb_tree< _Key, pair< const _Key, _Tp> , _Select1st< pair< const _Key, _Tp> > , _Compare, typename _Alloc::template rebind< pair< const _Key, _Tp> > ::other> ::const_iterator const_iterator; 
# 149
typedef typename _Rb_tree< _Key, pair< const _Key, _Tp> , _Select1st< pair< const _Key, _Tp> > , _Compare, typename _Alloc::template rebind< pair< const _Key, _Tp> > ::other> ::size_type size_type; 
# 150
typedef typename _Rb_tree< _Key, pair< const _Key, _Tp> , _Select1st< pair< const _Key, _Tp> > , _Compare, typename _Alloc::template rebind< pair< const _Key, _Tp> > ::other> ::difference_type difference_type; 
# 151
typedef typename _Rb_tree< _Key, pair< const _Key, _Tp> , _Select1st< pair< const _Key, _Tp> > , _Compare, typename _Alloc::template rebind< pair< const _Key, _Tp> > ::other> ::reverse_iterator reverse_iterator; 
# 152
typedef typename _Rb_tree< _Key, pair< const _Key, _Tp> , _Select1st< pair< const _Key, _Tp> > , _Compare, typename _Alloc::template rebind< pair< const _Key, _Tp> > ::other> ::const_reverse_iterator const_reverse_iterator; 
# 160
map() : _M_t() 
# 161
{ } 
# 169
explicit map(const _Compare &__comp, const allocator_type &
# 170
__a = allocator_type()) : _M_t(__comp, (_Pair_alloc_type)__a) 
# 171
{ } 
# 180
map(const map &__x) : _M_t(__x._M_t) 
# 181
{ } 
# 223
template< class _InputIterator> 
# 224
map(_InputIterator __first, _InputIterator __last) : _M_t() 
# 226
{ ((_M_t)._M_insert_unique(__first, __last)); } 
# 240
template< class _InputIterator> 
# 241
map(_InputIterator __first, _InputIterator __last, const _Compare &
# 242
__comp, const allocator_type &
# 243
__a = allocator_type()) : _M_t(__comp, (_Pair_alloc_type)__a) 
# 245
{ ((_M_t)._M_insert_unique(__first, __last)); } 
# 264
map &operator=(const map &__x) 
# 265
{ 
# 266
(_M_t) = (__x._M_t); 
# 267
return *this; 
# 268
} 
# 310
allocator_type get_allocator() const 
# 311
{ return (allocator_type)((_M_t).get_allocator()); } 
# 320
iterator begin() 
# 321
{ return ((_M_t).begin()); } 
# 329
const_iterator begin() const 
# 330
{ return ((_M_t).begin()); } 
# 338
iterator end() 
# 339
{ return ((_M_t).end()); } 
# 347
const_iterator end() const 
# 348
{ return ((_M_t).end()); } 
# 356
reverse_iterator rbegin() 
# 357
{ return ((_M_t).rbegin()); } 
# 365
const_reverse_iterator rbegin() const 
# 366
{ return ((_M_t).rbegin()); } 
# 374
reverse_iterator rend() 
# 375
{ return ((_M_t).rend()); } 
# 383
const_reverse_iterator rend() const 
# 384
{ return ((_M_t).rend()); } 
# 429
bool empty() const 
# 430
{ return ((_M_t).empty()); } 
# 434
size_type size() const 
# 435
{ return ((_M_t).size()); } 
# 439
size_type max_size() const 
# 440
{ return ((_M_t).max_size()); } 
# 456
mapped_type &operator[](const key_type &__k) 
# 457
{ 
# 461
iterator __i = lower_bound(__k); 
# 463
if ((__i == this->end()) || key_comp()(__k, ((*__i).first))) { 
# 469
__i = insert(__i, value_type(__k, mapped_type())); }  
# 471
return (*__i).second; 
# 472
} 
# 501
mapped_type &at(const key_type &__k) 
# 502
{ 
# 503
iterator __i = lower_bound(__k); 
# 504
if ((__i == this->end()) || key_comp()(__k, ((*__i).first))) { 
# 505
__throw_out_of_range("map::at"); }  
# 506
return (*__i).second; 
# 507
} 
# 510
const mapped_type &at(const key_type &__k) const 
# 511
{ 
# 512
const_iterator __i = lower_bound(__k); 
# 513
if ((__i == this->end()) || key_comp()(__k, ((*__i).first))) { 
# 514
__throw_out_of_range("map::at"); }  
# 515
return (*__i).second; 
# 516
} 
# 594
pair< typename _Rb_tree< _Key, pair< const _Key, _Tp> , _Select1st< pair< const _Key, _Tp> > , _Compare, typename _Alloc::template rebind< pair< const _Key, _Tp> > ::other> ::iterator, bool>  insert(const value_type &__x) 
# 595
{ return ((_M_t)._M_insert_unique(__x)); } 
# 646
iterator insert(iterator __position, const value_type &__x) 
# 648
{ return ((_M_t)._M_insert_unique_(__position, __x)); } 
# 668
template< class _InputIterator> void 
# 670
insert(_InputIterator __first, _InputIterator __last) 
# 671
{ ((_M_t)._M_insert_unique(__first, __last)); } 
# 710
void erase(iterator __position) 
# 711
{ ((_M_t).erase(__position)); } 
# 726
size_type erase(const key_type &__x) 
# 727
{ return ((_M_t).erase(__x)); } 
# 762
void erase(iterator __first, iterator __last) 
# 763
{ ((_M_t).erase(__first, __last)); } 
# 778
void swap(map &__x) 
# 779
{ ((_M_t).swap(__x._M_t)); } 
# 788
void clear() 
# 789
{ ((_M_t).clear()); } 
# 797
key_compare key_comp() const 
# 798
{ return ((_M_t).key_comp()); } 
# 805
value_compare value_comp() const 
# 806
{ return (value_compare)((_M_t).key_comp()); } 
# 821
iterator find(const key_type &__x) 
# 822
{ return ((_M_t).find(__x)); } 
# 836
const_iterator find(const key_type &__x) const 
# 837
{ return ((_M_t).find(__x)); } 
# 848
size_type count(const key_type &__x) const 
# 849
{ return (((_M_t).find(__x)) == ((_M_t).end())) ? 0 : 1; } 
# 863
iterator lower_bound(const key_type &__x) 
# 864
{ return ((_M_t).lower_bound(__x)); } 
# 878
const_iterator lower_bound(const key_type &__x) const 
# 879
{ return ((_M_t).lower_bound(__x)); } 
# 888
iterator upper_bound(const key_type &__x) 
# 889
{ return ((_M_t).upper_bound(__x)); } 
# 898
const_iterator upper_bound(const key_type &__x) const 
# 899
{ return ((_M_t).upper_bound(__x)); } 
# 917
pair< typename _Rb_tree< _Key, pair< const _Key, _Tp> , _Select1st< pair< const _Key, _Tp> > , _Compare, typename _Alloc::template rebind< pair< const _Key, _Tp> > ::other> ::iterator, typename _Rb_tree< _Key, pair< const _Key, _Tp> , _Select1st< pair< const _Key, _Tp> > , _Compare, typename _Alloc::template rebind< pair< const _Key, _Tp> > ::other> ::iterator>  equal_range(const key_type &__x) 
# 918
{ return ((_M_t).equal_range(__x)); } 
# 936
pair< typename _Rb_tree< _Key, pair< const _Key, _Tp> , _Select1st< pair< const _Key, _Tp> > , _Compare, typename _Alloc::template rebind< pair< const _Key, _Tp> > ::other> ::const_iterator, typename _Rb_tree< _Key, pair< const _Key, _Tp> , _Select1st< pair< const _Key, _Tp> > , _Compare, typename _Alloc::template rebind< pair< const _Key, _Tp> > ::other> ::const_iterator>  equal_range(const key_type &__x) const 
# 937
{ return ((_M_t).equal_range(__x)); } 
# 939
template< class _K1, class _T1, class _C1, class _A1> friend bool operator==(const std::map< _K1, _T1, _C1, _A1>  &, const std::map< _K1, _T1, _C1, _A1>  &); 
# 944
template< class _K1, class _T1, class _C1, class _A1> friend bool operator<(const std::map< _K1, _T1, _C1, _A1>  &, const std::map< _K1, _T1, _C1, _A1>  &); 
# 948
}; 
# 960
template< class _Key, class _Tp, class _Compare, class _Alloc> inline bool 
# 962
operator==(const map< _Key, _Tp, _Compare, _Alloc>  &__x, const map< _Key, _Tp, _Compare, _Alloc>  &
# 963
__y) 
# 964
{ return (__x._M_t) == (__y._M_t); } 
# 977
template< class _Key, class _Tp, class _Compare, class _Alloc> inline bool 
# 979
operator<(const map< _Key, _Tp, _Compare, _Alloc>  &__x, const map< _Key, _Tp, _Compare, _Alloc>  &
# 980
__y) 
# 981
{ return (__x._M_t) < (__y._M_t); } 
# 984
template< class _Key, class _Tp, class _Compare, class _Alloc> inline bool 
# 986
operator!=(const map< _Key, _Tp, _Compare, _Alloc>  &__x, const map< _Key, _Tp, _Compare, _Alloc>  &
# 987
__y) 
# 988
{ return !(__x == __y); } 
# 991
template< class _Key, class _Tp, class _Compare, class _Alloc> inline bool 
# 993
operator>(const map< _Key, _Tp, _Compare, _Alloc>  &__x, const map< _Key, _Tp, _Compare, _Alloc>  &
# 994
__y) 
# 995
{ return __y < __x; } 
# 998
template< class _Key, class _Tp, class _Compare, class _Alloc> inline bool 
# 1000
operator<=(const map< _Key, _Tp, _Compare, _Alloc>  &__x, const map< _Key, _Tp, _Compare, _Alloc>  &
# 1001
__y) 
# 1002
{ return !(__y < __x); } 
# 1005
template< class _Key, class _Tp, class _Compare, class _Alloc> inline bool 
# 1007
operator>=(const map< _Key, _Tp, _Compare, _Alloc>  &__x, const map< _Key, _Tp, _Compare, _Alloc>  &
# 1008
__y) 
# 1009
{ return !(__x < __y); } 
# 1012
template< class _Key, class _Tp, class _Compare, class _Alloc> inline void 
# 1014
swap(map< _Key, _Tp, _Compare, _Alloc>  &__x, map< _Key, _Tp, _Compare, _Alloc>  &
# 1015
__y) 
# 1016
{ (__x.swap(__y)); } 
# 1019
}
# 64 "/usr/include/c++/4.8.2/bits/stl_multimap.h" 3
namespace std __attribute((__visibility__("default"))) { 
# 92
template< class _Key, class _Tp, class 
# 93
_Compare = less< _Key> , class 
# 94
_Alloc = allocator< pair< const _Key, _Tp> > > 
# 95
class multimap { 
# 98
public: typedef _Key key_type; 
# 99
typedef _Tp mapped_type; 
# 100
typedef pair< const _Key, _Tp>  value_type; 
# 101
typedef _Compare key_compare; 
# 102
typedef _Alloc allocator_type; 
# 106
private: typedef typename _Alloc::value_type _Alloc_value_type; 
# 113
public: class value_compare : public binary_function< pair< const _Key, _Tp> , pair< const _Key, _Tp> , bool>  { 
# 116
friend class multimap; 
# 118
protected: _Compare comp; 
# 120
value_compare(_Compare __c) : comp(__c) 
# 121
{ } 
# 124
public: bool operator()(const typename ::std::multimap< _Key, _Tp, _Compare, _Alloc> ::value_type &__x, const typename ::std::multimap< _Key, _Tp, _Compare, _Alloc> ::value_type &__y) const 
# 125
{ return (comp)((__x.first), (__y.first)); } 
# 126
}; 
# 131
private: typedef typename _Alloc::template rebind< pair< const _Key, _Tp> > ::other _Pair_alloc_type; 
# 134
typedef _Rb_tree< _Key, pair< const _Key, _Tp> , _Select1st< pair< const _Key, _Tp> > , _Compare, typename _Alloc::template rebind< pair< const _Key, _Tp> > ::other>  _Rep_type; 
# 136
_Rep_type _M_t; 
# 141
public: typedef typename _Alloc::template rebind< pair< const _Key, _Tp> > ::other::pointer pointer; 
# 142
typedef typename _Alloc::template rebind< pair< const _Key, _Tp> > ::other::const_pointer const_pointer; 
# 143
typedef typename _Alloc::template rebind< pair< const _Key, _Tp> > ::other::reference reference; 
# 144
typedef typename _Alloc::template rebind< pair< const _Key, _Tp> > ::other::const_reference const_reference; 
# 145
typedef typename _Rb_tree< _Key, pair< const _Key, _Tp> , _Select1st< pair< const _Key, _Tp> > , _Compare, typename _Alloc::template rebind< pair< const _Key, _Tp> > ::other> ::iterator iterator; 
# 146
typedef typename _Rb_tree< _Key, pair< const _Key, _Tp> , _Select1st< pair< const _Key, _Tp> > , _Compare, typename _Alloc::template rebind< pair< const _Key, _Tp> > ::other> ::const_iterator const_iterator; 
# 147
typedef typename _Rb_tree< _Key, pair< const _Key, _Tp> , _Select1st< pair< const _Key, _Tp> > , _Compare, typename _Alloc::template rebind< pair< const _Key, _Tp> > ::other> ::size_type size_type; 
# 148
typedef typename _Rb_tree< _Key, pair< const _Key, _Tp> , _Select1st< pair< const _Key, _Tp> > , _Compare, typename _Alloc::template rebind< pair< const _Key, _Tp> > ::other> ::difference_type difference_type; 
# 149
typedef typename _Rb_tree< _Key, pair< const _Key, _Tp> , _Select1st< pair< const _Key, _Tp> > , _Compare, typename _Alloc::template rebind< pair< const _Key, _Tp> > ::other> ::reverse_iterator reverse_iterator; 
# 150
typedef typename _Rb_tree< _Key, pair< const _Key, _Tp> , _Select1st< pair< const _Key, _Tp> > , _Compare, typename _Alloc::template rebind< pair< const _Key, _Tp> > ::other> ::const_reverse_iterator const_reverse_iterator; 
# 157
multimap() : _M_t() 
# 158
{ } 
# 166
explicit multimap(const _Compare &__comp, const allocator_type &
# 167
__a = allocator_type()) : _M_t(__comp, (_Pair_alloc_type)__a) 
# 168
{ } 
# 177
multimap(const multimap &__x) : _M_t(__x._M_t) 
# 178
{ } 
# 218
template< class _InputIterator> 
# 219
multimap(_InputIterator __first, _InputIterator __last) : _M_t() 
# 221
{ ((_M_t)._M_insert_equal(__first, __last)); } 
# 234
template< class _InputIterator> 
# 235
multimap(_InputIterator __first, _InputIterator __last, const _Compare &
# 236
__comp, const allocator_type &
# 237
__a = allocator_type()) : _M_t(__comp, (_Pair_alloc_type)__a) 
# 239
{ ((_M_t)._M_insert_equal(__first, __last)); } 
# 258
multimap &operator=(const multimap &__x) 
# 259
{ 
# 260
(_M_t) = (__x._M_t); 
# 261
return *this; 
# 262
} 
# 304
allocator_type get_allocator() const 
# 305
{ return (allocator_type)((_M_t).get_allocator()); } 
# 314
iterator begin() 
# 315
{ return ((_M_t).begin()); } 
# 323
const_iterator begin() const 
# 324
{ return ((_M_t).begin()); } 
# 332
iterator end() 
# 333
{ return ((_M_t).end()); } 
# 341
const_iterator end() const 
# 342
{ return ((_M_t).end()); } 
# 350
reverse_iterator rbegin() 
# 351
{ return ((_M_t).rbegin()); } 
# 359
const_reverse_iterator rbegin() const 
# 360
{ return ((_M_t).rbegin()); } 
# 368
reverse_iterator rend() 
# 369
{ return ((_M_t).rend()); } 
# 377
const_reverse_iterator rend() const 
# 378
{ return ((_M_t).rend()); } 
# 421
bool empty() const 
# 422
{ return ((_M_t).empty()); } 
# 426
size_type size() const 
# 427
{ return ((_M_t).size()); } 
# 431
size_type max_size() const 
# 432
{ return ((_M_t).max_size()); } 
# 501
iterator insert(const value_type &__x) 
# 502
{ return ((_M_t)._M_insert_equal(__x)); } 
# 537
iterator insert(iterator __position, const value_type &__x) 
# 539
{ return ((_M_t)._M_insert_equal_(__position, __x)); } 
# 560
template< class _InputIterator> void 
# 562
insert(_InputIterator __first, _InputIterator __last) 
# 563
{ ((_M_t)._M_insert_equal(__first, __last)); } 
# 615
void erase(iterator __position) 
# 616
{ ((_M_t).erase(__position)); } 
# 631
size_type erase(const key_type &__x) 
# 632
{ return ((_M_t).erase(__x)); } 
# 671
void erase(iterator __first, iterator __last) 
# 672
{ ((_M_t).erase(__first, __last)); } 
# 687
void swap(multimap &__x) 
# 688
{ ((_M_t).swap(__x._M_t)); } 
# 697
void clear() 
# 698
{ ((_M_t).clear()); } 
# 706
key_compare key_comp() const 
# 707
{ return ((_M_t).key_comp()); } 
# 714
value_compare value_comp() const 
# 715
{ return (value_compare)((_M_t).key_comp()); } 
# 730
iterator find(const key_type &__x) 
# 731
{ return ((_M_t).find(__x)); } 
# 745
const_iterator find(const key_type &__x) const 
# 746
{ return ((_M_t).find(__x)); } 
# 754
size_type count(const key_type &__x) const 
# 755
{ return ((_M_t).count(__x)); } 
# 769
iterator lower_bound(const key_type &__x) 
# 770
{ return ((_M_t).lower_bound(__x)); } 
# 784
const_iterator lower_bound(const key_type &__x) const 
# 785
{ return ((_M_t).lower_bound(__x)); } 
# 794
iterator upper_bound(const key_type &__x) 
# 795
{ return ((_M_t).upper_bound(__x)); } 
# 804
const_iterator upper_bound(const key_type &__x) const 
# 805
{ return ((_M_t).upper_bound(__x)); } 
# 821
pair< typename _Rb_tree< _Key, pair< const _Key, _Tp> , _Select1st< pair< const _Key, _Tp> > , _Compare, typename _Alloc::template rebind< pair< const _Key, _Tp> > ::other> ::iterator, typename _Rb_tree< _Key, pair< const _Key, _Tp> , _Select1st< pair< const _Key, _Tp> > , _Compare, typename _Alloc::template rebind< pair< const _Key, _Tp> > ::other> ::iterator>  equal_range(const key_type &__x) 
# 822
{ return ((_M_t).equal_range(__x)); } 
# 838
pair< typename _Rb_tree< _Key, pair< const _Key, _Tp> , _Select1st< pair< const _Key, _Tp> > , _Compare, typename _Alloc::template rebind< pair< const _Key, _Tp> > ::other> ::const_iterator, typename _Rb_tree< _Key, pair< const _Key, _Tp> , _Select1st< pair< const _Key, _Tp> > , _Compare, typename _Alloc::template rebind< pair< const _Key, _Tp> > ::other> ::const_iterator>  equal_range(const key_type &__x) const 
# 839
{ return ((_M_t).equal_range(__x)); } 
# 841
template< class _K1, class _T1, class _C1, class _A1> friend bool operator==(const std::multimap< _K1, _T1, _C1, _A1>  &, const std::multimap< _K1, _T1, _C1, _A1>  &); 
# 846
template< class _K1, class _T1, class _C1, class _A1> friend bool operator<(const std::multimap< _K1, _T1, _C1, _A1>  &, const std::multimap< _K1, _T1, _C1, _A1>  &); 
# 850
}; 
# 862
template< class _Key, class _Tp, class _Compare, class _Alloc> inline bool 
# 864
operator==(const multimap< _Key, _Tp, _Compare, _Alloc>  &__x, const multimap< _Key, _Tp, _Compare, _Alloc>  &
# 865
__y) 
# 866
{ return (__x._M_t) == (__y._M_t); } 
# 879
template< class _Key, class _Tp, class _Compare, class _Alloc> inline bool 
# 881
operator<(const multimap< _Key, _Tp, _Compare, _Alloc>  &__x, const multimap< _Key, _Tp, _Compare, _Alloc>  &
# 882
__y) 
# 883
{ return (__x._M_t) < (__y._M_t); } 
# 886
template< class _Key, class _Tp, class _Compare, class _Alloc> inline bool 
# 888
operator!=(const multimap< _Key, _Tp, _Compare, _Alloc>  &__x, const multimap< _Key, _Tp, _Compare, _Alloc>  &
# 889
__y) 
# 890
{ return !(__x == __y); } 
# 893
template< class _Key, class _Tp, class _Compare, class _Alloc> inline bool 
# 895
operator>(const multimap< _Key, _Tp, _Compare, _Alloc>  &__x, const multimap< _Key, _Tp, _Compare, _Alloc>  &
# 896
__y) 
# 897
{ return __y < __x; } 
# 900
template< class _Key, class _Tp, class _Compare, class _Alloc> inline bool 
# 902
operator<=(const multimap< _Key, _Tp, _Compare, _Alloc>  &__x, const multimap< _Key, _Tp, _Compare, _Alloc>  &
# 903
__y) 
# 904
{ return !(__y < __x); } 
# 907
template< class _Key, class _Tp, class _Compare, class _Alloc> inline bool 
# 909
operator>=(const multimap< _Key, _Tp, _Compare, _Alloc>  &__x, const multimap< _Key, _Tp, _Compare, _Alloc>  &
# 910
__y) 
# 911
{ return !(__x < __y); } 
# 914
template< class _Key, class _Tp, class _Compare, class _Alloc> inline void 
# 916
swap(multimap< _Key, _Tp, _Compare, _Alloc>  &__x, multimap< _Key, _Tp, _Compare, _Alloc>  &
# 917
__y) 
# 918
{ (__x.swap(__y)); } 
# 921
}
# 49 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/util_allocator.cuh"
namespace thrust { namespace system { namespace cuda { namespace detail { 
# 52
namespace cub_ { 
# 104
struct CachingDeviceAllocator { 
# 114
enum { 
# 116
INVALID_DEVICE_ORDINAL = (-1)
# 117
}; 
# 122
static unsigned IntPow(unsigned 
# 123
base, unsigned 
# 124
exp) 
# 125
{ 
# 126
unsigned retval = (1); 
# 127
while (exp > (0)) 
# 128
{ 
# 129
if (exp & (1)) { 
# 130
retval = (retval * base); 
# 131
}  
# 132
base = (base * base); 
# 133
exp = (exp >> 1); 
# 134
}  
# 135
return retval; 
# 136
} 
# 142
static void NearestPowerOf(unsigned &
# 143
power, size_t &
# 144
rounded_bytes, unsigned 
# 145
base, size_t 
# 146
value) 
# 147
{ 
# 148
power = (0); 
# 149
rounded_bytes = (1); 
# 151
while (rounded_bytes < value) 
# 152
{ 
# 153
rounded_bytes *= base; 
# 154
power++; 
# 155
}  
# 156
} 
# 161
struct BlockDescriptor { 
# 163
int device; 
# 164
void *d_ptr; 
# 165
cudaStream_t associated_stream; 
# 166
cudaEvent_t ready_event; 
# 167
size_t bytes; 
# 168
unsigned bin; 
# 171
BlockDescriptor(void *d_ptr, int device) : device(device), d_ptr(d_ptr), associated_stream((0)), ready_event((0)), bytes((0)), bin((0)) 
# 178
{ } 
# 181
BlockDescriptor(size_t bytes, unsigned bin, int device, cudaStream_t associated_stream) : device(device), d_ptr((__null)), associated_stream(associated_stream), ready_event((0)), bytes(bytes), bin(bin) 
# 188
{ } 
# 191
static bool PtrCompare(const BlockDescriptor &a, const BlockDescriptor &b) 
# 192
{ 
# 193
if ((a.device) == (b.device)) { 
# 194
return (a.d_ptr) < (b.d_ptr); } else { 
# 196
return (a.device) < (b.device); }  
# 197
} 
# 200
static bool SizeCompare(const BlockDescriptor &a, const BlockDescriptor &b) 
# 201
{ 
# 202
if ((a.device) == (b.device)) { 
# 203
return (a.bytes) < (b.bytes); } else { 
# 205
return (a.device) < (b.device); }  
# 206
} 
# 207
}; 
# 210
typedef bool (*Compare)(const BlockDescriptor &, const BlockDescriptor &); 
# 215
typedef std::multiset< BlockDescriptor, bool (*)(const BlockDescriptor &, const BlockDescriptor &)>  CachedBlocks; 
# 218
typedef std::multiset< BlockDescriptor, bool (*)(const BlockDescriptor &, const BlockDescriptor &)>  BusyBlocks; 
# 221
typedef std::map< int, unsigned long>  GpuCachedBytes; 
# 229
Spinlock spin_lock; 
# 231
unsigned bin_growth; 
# 232
unsigned min_bin; 
# 233
unsigned max_bin; 
# 235
size_t min_bin_bytes; 
# 236
size_t max_bin_bytes; 
# 237
size_t max_cached_bytes; 
# 239
bool debug; 
# 240
bool skip_cleanup; 
# 244
GpuCachedBytes cached_bytes; 
# 245
CachedBlocks cached_blocks; 
# 246
BusyBlocks live_blocks; 
# 259
CachingDeviceAllocator(unsigned 
# 260
bin_growth, unsigned 
# 261
min_bin, unsigned 
# 262
max_bin, size_t 
# 263
max_cached_bytes, bool 
# 264
skip_cleanup = false) : spin_lock(0), bin_growth(bin_growth), min_bin(min_bin), max_bin(max_bin), min_bin_bytes(IntPow(bin_growth, min_bin)), max_bin_bytes(IntPow(bin_growth, max_bin)), max_cached_bytes(max_cached_bytes), debug(false), cached_blocks(BlockDescriptor::SizeCompare), live_blocks(BlockDescriptor::PtrCompare) 
# 278
{ } 
# 294
CachingDeviceAllocator(bool 
# 295
skip_cleanup = false) : spin_lock(0), bin_growth((8)), min_bin((3)), max_bin((7)), min_bin_bytes(IntPow(bin_growth, min_bin)), max_bin_bytes(IntPow(bin_growth, max_bin)), max_cached_bytes(((max_bin_bytes) * (3)) - (1)), debug(false), skip_cleanup(skip_cleanup), cached_blocks(BlockDescriptor::SizeCompare), live_blocks(BlockDescriptor::PtrCompare) 
# 310
{ } 
# 316
cudaError_t SetMaxCachedBytes(size_t 
# 317
max_cached_bytes) 
# 318
{ 
# 325
Lock(&(spin_lock)); 
# 327
(this->max_cached_bytes) = max_cached_bytes; 
# 329
if (debug) { printf("New max_cached_bytes(%lld)\n", (long long)max_cached_bytes); }  ; 
# 332
Unlock(&(spin_lock)); 
# 334
return cudaSuccess; 
# 337
} 
# 347
cudaError_t DeviceAllocate(int 
# 348
device, void **
# 349
d_ptr, size_t 
# 350
bytes, cudaStream_t 
# 351
active_stream = 0) 
# 352
{ 
# 358
(*d_ptr) = (__null); 
# 359
bool locked = false; 
# 360
int entrypoint_device = (INVALID_DEVICE_ORDINAL); 
# 361
cudaError_t error = cudaSuccess; 
# 363
do { 
# 365
if (cub_::Debug(error = cudaGetDevice(&entrypoint_device), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/util_allocator.cuh", 365)) { break; }  
# 366
if (device == (INVALID_DEVICE_ORDINAL)) { 
# 367
device = entrypoint_device; }  
# 370
unsigned bin; 
# 371
size_t bin_bytes; 
# 372
NearestPowerOf(bin, bin_bytes, bin_growth, bytes); 
# 373
if (bin < (min_bin)) { 
# 374
bin = (min_bin); 
# 375
bin_bytes = (min_bin_bytes); 
# 376
}  
# 379
if (bin > (max_bin)) 
# 380
{ 
# 382
bin = ((unsigned)(-1)); 
# 383
bin_bytes = bytes; 
# 384
}  
# 386
BlockDescriptor search_key(bin_bytes, bin, device, active_stream); 
# 389
if (!locked) { 
# 390
Lock(&(spin_lock)); 
# 391
locked = true; 
# 392
}  
# 395
std::multiset< BlockDescriptor, bool (*)(const BlockDescriptor &, const BlockDescriptor &)> ::iterator block_itr = (cached_blocks).lower_bound(search_key); 
# 398
bool found = false; 
# 399
while ((block_itr != ((cached_blocks).end())) && ((block_itr->device) == device) && ((block_itr->bin) == (search_key.bin))) 
# 402
{ 
# 403
cudaStream_t prev_stream = block_itr->associated_stream; 
# 404
if ((active_stream == prev_stream) || ((cudaEventQuery(block_itr->ready_event)) != (cudaErrorNotReady))) 
# 405
{ 
# 407
found = true; 
# 408
search_key = (*block_itr); 
# 409
(search_key.associated_stream) = active_stream; 
# 410
(live_blocks).insert(search_key); 
# 413
(cached_blocks).erase(block_itr); 
# 414
(cached_bytes)[device] -= (search_key.bytes); 
# 416
if (debug) { printf("\tdevice %d reused cached block for stream %lld (%lld bytes, previously associated with stream %lld).\n\t\t %lld available block" "s cached (%lld bytes), %lld live blocks outstanding.\n", device, (long long)active_stream, (long long)(search_key.bytes), (long long)prev_stream, (long long)(cached_blocks).size(), (long long)(cached_bytes)[device], (long long)(live_blocks).size()); }  
# 417
; 
# 419
break; 
# 420
}  
# 422
block_itr++; 
# 423
}  
# 425
if (!found) 
# 426
{ 
# 428
if (locked) { 
# 429
Unlock(&(spin_lock)); 
# 430
locked = false; 
# 431
}  
# 434
if (device != entrypoint_device) { 
# 435
if (cub_::Debug(error = cudaSetDevice(device), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/util_allocator.cuh", 435)) { break; }  
# 436
}  
# 439
if (cub_::Debug(error = cudaMalloc(&(search_key.d_ptr), search_key.bytes), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/util_allocator.cuh", 439)) { break; }  
# 440
if (cub_::Debug(error = cudaEventCreateWithFlags(&(search_key.ready_event), 2), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/util_allocator.cuh", 440)) { break; }  
# 443
if (!locked) { 
# 444
Lock(&(spin_lock)); 
# 445
locked = true; 
# 446
}  
# 449
(live_blocks).insert(search_key); 
# 451
if (debug) { printf("\tdevice %d allocating new device block %lld bytes associated with stream %lld.\n\t\t %lld available blocks cached (%lld bytes)," " %lld live blocks outstanding.\n", device, (long long)(search_key.bytes), (long long)(search_key.associated_stream), (long long)(cached_blocks).size(), (long long)(cached_bytes)[device], (long long)(live_blocks).size()); }  
# 452
; 
# 453
}  
# 456
(*d_ptr) = (search_key.d_ptr); 
# 458
} while (0); 
# 461
if (locked) { 
# 462
Unlock(&(spin_lock)); 
# 463
locked = false; 
# 464
}  
# 467
if ((entrypoint_device != (INVALID_DEVICE_ORDINAL)) && (entrypoint_device != device)) 
# 468
{ 
# 469
if (cub_::Debug(error = cudaSetDevice(entrypoint_device), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/util_allocator.cuh", 469)) { return error; }  
# 470
}  
# 472
return error; 
# 475
} 
# 485
cudaError_t DeviceAllocate(void **
# 486
d_ptr, size_t 
# 487
bytes, cudaStream_t 
# 488
active_stream = 0) 
# 489
{ 
# 494
return this->DeviceAllocate(INVALID_DEVICE_ORDINAL, d_ptr, bytes, active_stream); 
# 496
} 
# 506
cudaError_t DeviceFree(int 
# 507
device, void *
# 508
d_ptr) 
# 509
{ 
# 515
bool locked = false; 
# 516
int entrypoint_device = (INVALID_DEVICE_ORDINAL); 
# 517
cudaError_t error = cudaSuccess; 
# 519
do { 
# 520
if (cub_::Debug(error = cudaGetDevice(&entrypoint_device), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/util_allocator.cuh", 520)) { break; }  
# 521
if (device == (INVALID_DEVICE_ORDINAL)) { 
# 522
device = entrypoint_device; }  
# 525
if (device != entrypoint_device) { 
# 526
if (cub_::Debug(error = cudaSetDevice(device), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/util_allocator.cuh", 526)) { break; }  
# 527
}  
# 530
if (!locked) { 
# 531
Lock(&(spin_lock)); 
# 532
locked = true; 
# 533
}  
# 536
BlockDescriptor search_key(d_ptr, device); 
# 537
std::multiset< BlockDescriptor, bool (*)(const BlockDescriptor &, const BlockDescriptor &)> ::iterator block_itr = (live_blocks).find(search_key); 
# 538
if ((block_itr == ((live_blocks).end()))) 
# 539
{ 
# 541
if (cub_::Debug(error = cudaErrorUnknown, "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/util_allocator.cuh", 541)) { break; }  
# 542
} else 
# 544
{ 
# 546
search_key = (*block_itr); 
# 547
(live_blocks).erase(block_itr); 
# 550
if (((cached_bytes)[device] + (search_key.bytes)) <= (max_cached_bytes)) 
# 551
{ 
# 553
if (cub_::Debug(error = cudaEventRecord(search_key.ready_event, search_key.associated_stream), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/util_allocator.cuh", 553)) { break; }  
# 556
(cached_blocks).insert(search_key); 
# 557
(cached_bytes)[device] += (search_key.bytes); 
# 559
if (debug) { printf("\tdevice %d returned %lld bytes from associated stream %lld.\n\t\t %lld available blocks cached (%lld bytes), %lld live blocks o" "utstanding.\n", device, (long long)(search_key.bytes), (long long)(search_key.associated_stream), (long long)(cached_blocks).size(), (long long)(cached_bytes)[device], (long long)(live_blocks).size()); }  
# 560
; 
# 561
} else 
# 563
{ 
# 565
if (locked) { 
# 566
Unlock(&(spin_lock)); 
# 567
locked = false; 
# 568
}  
# 571
if (cub_::Debug(error = cudaFree(d_ptr), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/util_allocator.cuh", 571)) { break; }  
# 572
if (cub_::Debug(error = cudaEventDestroy(search_key.ready_event), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/util_allocator.cuh", 572)) { break; }  
# 574
if (debug) { printf("\tdevice %d freed %lld bytes from associated stream %lld.\n\t\t  %lld available blocks cached (%lld bytes), %lld live blocks out" "standing.\n", device, (long long)(search_key.bytes), (long long)(search_key.associated_stream), (long long)(cached_blocks).size(), (long long)(cached_bytes)[device], (long long)(live_blocks).size()); }  
# 575
; 
# 576
}  
# 577
}  
# 578
} while (0); 
# 581
if (locked) { 
# 582
Unlock(&(spin_lock)); 
# 583
locked = false; 
# 584
}  
# 586
if ((entrypoint_device != (INVALID_DEVICE_ORDINAL)) && (entrypoint_device != device)) 
# 587
{ 
# 588
if (cub_::Debug(error = cudaSetDevice(entrypoint_device), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/util_allocator.cuh", 588)) { return error; }  
# 589
}  
# 591
return error; 
# 594
} 
# 604
cudaError_t DeviceFree(void *
# 605
d_ptr) 
# 606
{ 
# 611
return this->DeviceFree(INVALID_DEVICE_ORDINAL, d_ptr); 
# 613
} 
# 619
cudaError_t FreeAllCached() 
# 620
{ 
# 626
cudaError_t error = cudaSuccess; 
# 627
bool locked = false; 
# 628
int entrypoint_device = (INVALID_DEVICE_ORDINAL); 
# 629
int current_device = (INVALID_DEVICE_ORDINAL); 
# 632
if (!locked) { 
# 633
Lock(&(spin_lock)); 
# 634
locked = true; 
# 635
}  
# 637
while (!(cached_blocks).empty()) 
# 638
{ 
# 640
std::multiset< BlockDescriptor, bool (*)(const BlockDescriptor &, const BlockDescriptor &)> ::iterator begin = (cached_blocks).begin(); 
# 643
if (entrypoint_device == (INVALID_DEVICE_ORDINAL)) 
# 644
{ 
# 645
if (cub_::Debug(error = cudaGetDevice(&entrypoint_device), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/util_allocator.cuh", 645)) { break; }  
# 646
}  
# 649
if ((begin->device) != current_device) 
# 650
{ 
# 651
if (cub_::Debug(error = cudaSetDevice(begin->device), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/util_allocator.cuh", 651)) { break; }  
# 652
current_device = (begin->device); 
# 653
}  
# 656
if (cub_::Debug(error = cudaFree(begin->d_ptr), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/util_allocator.cuh", 656)) { break; }  
# 657
if (cub_::Debug(error = cudaEventDestroy(begin->ready_event), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/util_allocator.cuh", 657)) { break; }  
# 660
(cached_bytes)[current_device] -= (begin->bytes); 
# 661
(cached_blocks).erase(begin); 
# 663
if (debug) { printf("\tdevice %d freed %lld bytes.\n\t\t  %lld available blocks cached (%lld bytes), %lld live blocks outstanding.\n", current_device, (long long)(begin->bytes), (long long)(cached_blocks).size(), (long long)(cached_bytes)[current_device], (long long)(live_blocks).size()); }  
# 664
; 
# 665
}  
# 668
if (locked) { 
# 669
Unlock(&(spin_lock)); 
# 670
locked = false; 
# 671
}  
# 674
if (entrypoint_device != (INVALID_DEVICE_ORDINAL)) 
# 675
{ 
# 676
if (cub_::Debug(error = cudaSetDevice(entrypoint_device), "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/cub/util_allocator.cuh", 676)) { return error; }  
# 677
}  
# 679
return error; 
# 682
} 
# 688
virtual ~CachingDeviceAllocator() 
# 689
{ 
# 690
if (!(skip_cleanup)) { 
# 691
this->FreeAllCached(); }  
# 692
} 
# 694
}; 
# 701
}
# 702
}}}}
# 32 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/detail/stable_radix_sort.inl"
namespace thrust { 
# 34
namespace system { 
# 36
namespace cuda { 
# 38
namespace detail { 
# 40
namespace detail { 
# 42
namespace stable_radix_sort_detail { 
# 47
template< class Key> cudaError_t 
# 49
cub_sort_keys_wrapper(void *d_temp_storage, size_t &
# 50
temp_storage_bytes, cub_::DoubleBuffer< Key>  &
# 51
d_keys, int 
# 52
num_items, less< Key>  
# 53
comp, int 
# 54
begin_bit = 0, int 
# 55
end_bit = sizeof(Key) * (8), cudaStream_t 
# 56
stream = 0, bool 
# 57
debug_synchronous = false) 
# 58
{ 
# 59
struct workaround { 
# 62
static cudaError_t host_path(void *d_temp_storage, size_t &
# 63
temp_storage_bytes, cub_::DoubleBuffer< Key>  &
# 64
d_keys, int 
# 65
num_items, less< Key> , int 
# 67
begin_bit, int 
# 68
end_bit, cudaStream_t 
# 69
stream, bool 
# 70
debug_synchronous) 
# 71
{ 
# 72
return cub_::DeviceRadixSort::SortKeys(d_temp_storage, temp_storage_bytes, d_keys, num_items, begin_bit, end_bit, stream, debug_synchronous); 
# 73
} 
# 76
static cudaError_t device_path(void *d_temp_storage, size_t &
# 77
temp_storage_bytes, cub_::DoubleBuffer< Key>  &
# 78
d_keys, int 
# 79
num_items, less< Key> , int 
# 81
begin_bit, int 
# 82
end_bit, cudaStream_t 
# 83
stream, bool 
# 84
debug_synchronous) 
# 85
{int volatile ___ = 1;(void)d_temp_storage;(void)temp_storage_bytes;(void)d_keys;(void)num_items;(void)begin_bit;(void)end_bit;(void)stream;(void)debug_synchronous;
# 91
::exit(___);}
#if 0
# 85
{ 
# 87
return cub_::DeviceRadixSort::SortKeys(d_temp_storage, temp_storage_bytes, d_keys, num_items, begin_bit, end_bit, stream, debug_synchronous); 
# 91
} 
#endif
# 92 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/detail/stable_radix_sort.inl"
}; 
# 95
return (workaround::host_path)(d_temp_storage, temp_storage_bytes, d_keys, num_items, comp, begin_bit, end_bit, stream, debug_synchronous); 
# 99
} 
# 103
template< class Key> cudaError_t 
# 105
cub_sort_keys_wrapper(void *d_temp_storage, size_t &
# 106
temp_storage_bytes, cub_::DoubleBuffer< Key>  &
# 107
d_keys, int 
# 108
num_items, greater< Key>  
# 109
comp, int 
# 110
begin_bit = 0, int 
# 111
end_bit = sizeof(Key) * (8), cudaStream_t 
# 112
stream = 0, bool 
# 113
debug_synchronous = false) 
# 114
{ 
# 115
struct workaround { 
# 118
static cudaError_t host_path(void *d_temp_storage, size_t &
# 119
temp_storage_bytes, cub_::DoubleBuffer< Key>  &
# 120
d_keys, int 
# 121
num_items, greater< Key> , int 
# 123
begin_bit, int 
# 124
end_bit, cudaStream_t 
# 125
stream, bool 
# 126
debug_synchronous) 
# 127
{ 
# 128
return cub_::DeviceRadixSort::SortKeysDescending(d_temp_storage, temp_storage_bytes, d_keys, num_items, begin_bit, end_bit, stream, debug_synchronous); 
# 129
} 
# 132
static cudaError_t device_path(void *d_temp_storage, size_t &
# 133
temp_storage_bytes, cub_::DoubleBuffer< Key>  &
# 134
d_keys, int 
# 135
num_items, greater< Key> , int 
# 137
begin_bit, int 
# 138
end_bit, cudaStream_t 
# 139
stream, bool 
# 140
debug_synchronous) 
# 141
{int volatile ___ = 1;(void)d_temp_storage;(void)temp_storage_bytes;(void)d_keys;(void)num_items;(void)begin_bit;(void)end_bit;(void)stream;(void)debug_synchronous;
# 147
::exit(___);}
#if 0
# 141
{ 
# 143
return cub_::DeviceRadixSort::SortKeys(d_temp_storage, temp_storage_bytes, d_keys, num_items, begin_bit, end_bit, stream, debug_synchronous); 
# 147
} 
#endif
# 148 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/detail/stable_radix_sort.inl"
}; 
# 151
return (workaround::host_path)(d_temp_storage, temp_storage_bytes, d_keys, num_items, comp, begin_bit, end_bit, stream, debug_synchronous); 
# 155
} 
# 161
template< class T, class Compare> tuple< unsigned long, unsigned long, unsigned long, null_type, null_type, null_type, null_type, null_type, null_type, null_type>  
# 163
compute_temporary_storage_requirements_for_radix_sort_n(size_t n, Compare comp, cudaStream_t stream) 
# 164
{ 
# 165
cub_::DoubleBuffer< T>  dummy; 
# 168
size_t num_additional_temp_storage_bytes = (0); 
# 169
cuda::detail::throw_on_error(cub_sort_keys_wrapper(0, num_additional_temp_storage_bytes, dummy, static_cast< int>(n), comp, 0, sizeof(T) * (8), stream), "after cub_::DeviceRadixSort::SortKeys(0)"); 
# 174
typedef bulk_::detail::aligned_type< 16UL> ::type aligned_type; 
# 176
size_t num_double_buffer_bytes = n * sizeof(T); 
# 177
size_t num_aligned_double_buffer_bytes = thrust::detail::util::round_i(num_double_buffer_bytes, sizeof(aligned_type)); 
# 178
size_t num_aligned_total_temporary_storage_bytes = num_aligned_double_buffer_bytes + num_additional_temp_storage_bytes; 
# 180
return thrust::make_tuple(num_aligned_total_temporary_storage_bytes, num_aligned_double_buffer_bytes, num_additional_temp_storage_bytes); 
# 181
} 
# 184
template< class DerivedPolicy, class T, class Compare> void 
# 186
stable_radix_sort_n(execution_policy< DerivedPolicy>  &exec, T *first, size_t n, Compare comp) 
# 187
{ 
# 188
if (n > (1)) 
# 189
{ 
# 190
cudaStream_t s = stream(thrust::detail::derived_cast< DerivedPolicy> (exec)); 
# 193
size_t num_temporary_storage_bytes = (0); 
# 194
size_t offset_to_additional_temp_storage = (0); 
# 195
size_t num_additional_temp_storage_bytes = (0); 
# 196
thrust::tie(num_temporary_storage_bytes, offset_to_additional_temp_storage, num_additional_temp_storage_bytes) = compute_temporary_storage_requirements_for_radix_sort_n< T> (n, comp, s); 
# 200
thrust::detail::temporary_array< char, DerivedPolicy>  temporary_storage(exec, num_temporary_storage_bytes); 
# 203
cub_::DoubleBuffer< T>  double_buffer; 
# 204
((double_buffer.d_buffers)[0]) = thrust::raw_pointer_cast(&(*first)); 
# 205
((double_buffer.d_buffers)[1]) = (reinterpret_cast< T *>(reinterpret_cast< void *>(thrust::raw_pointer_cast(&(temporary_storage[0]))))); 
# 207
cuda::detail::throw_on_error(cub_sort_keys_wrapper(thrust::raw_pointer_cast(&(temporary_storage[offset_to_additional_temp_storage])), num_additional_temp_storage_bytes, double_buffer, static_cast< int>(n), comp, 0, sizeof(T) * (8), s), "after cub_::DeviceRadixSort::SortKeys(1)"); 
# 217
thrust::system::cuda::detail::synchronize_if_enabled("stable_radix_sort_n(): after cub_::DeviceRadixSort::SortKeys(1)"); 
# 219
if ((double_buffer.selector) != 0) 
# 220
{ 
# 221
T *temp_ptr = reinterpret_cast< T *>((double_buffer.d_buffers)[1]); 
# 222
thrust::copy(exec, temp_ptr, temp_ptr + n, first); 
# 223
}  
# 224
}  
# 225
} 
# 228
}
# 231
template< class DerivedPolicy, class 
# 232
RandomAccessIterator> void 
# 234
stable_radix_sort(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator 
# 235
first, RandomAccessIterator 
# 236
last, less< typename iterator_value< RandomAccessIterator> ::type>  
# 237
comp) 
# 238
{ 
# 239
stable_radix_sort_detail::stable_radix_sort_n(exec, thrust::raw_pointer_cast(&(*first)), last - first, comp); 
# 240
} 
# 243
template< class DerivedPolicy, class 
# 244
RandomAccessIterator> void 
# 246
stable_radix_sort(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator 
# 247
first, RandomAccessIterator 
# 248
last, greater< typename iterator_value< RandomAccessIterator> ::type>  
# 249
comp) 
# 250
{ 
# 251
stable_radix_sort_detail::stable_radix_sort_n(exec, thrust::raw_pointer_cast(&(*first)), last - first, comp); 
# 252
} 
# 260
namespace stable_radix_sort_detail { 
# 265
template< class Key, class Value> cudaError_t 
# 267
cub_sort_pairs_wrapper(void *d_temp_storage, size_t &
# 268
temp_storage_bytes, cub_::DoubleBuffer< Key>  &
# 269
d_keys, cub_::DoubleBuffer< Value>  &
# 270
d_values, int 
# 271
num_items, less< Key>  
# 272
comp, int 
# 273
begin_bit = 0, int 
# 274
end_bit = sizeof(Key) * (8), cudaStream_t 
# 275
stream = 0, bool 
# 276
debug_synchronous = false) 
# 277
{ 
# 278
struct workaround { 
# 281
static cudaError_t host_path(void *d_temp_storage, size_t &
# 282
temp_storage_bytes, cub_::DoubleBuffer< Key>  &
# 283
d_keys, cub_::DoubleBuffer< Value>  &
# 284
d_values, int 
# 285
num_items, less< Key> , int 
# 287
begin_bit, int 
# 288
end_bit, cudaStream_t 
# 289
stream, bool 
# 290
debug_synchronous) 
# 291
{ 
# 292
return cub_::DeviceRadixSort::SortPairs(d_temp_storage, temp_storage_bytes, d_keys, d_values, num_items, begin_bit, end_bit, stream, debug_synchronous); 
# 293
} 
# 296
static cudaError_t device_path(void *d_temp_storage, size_t &
# 297
temp_storage_bytes, cub_::DoubleBuffer< Key>  &
# 298
d_keys, cub_::DoubleBuffer< Value>  &
# 299
d_values, int 
# 300
num_items, less< Key> , int 
# 302
begin_bit, int 
# 303
end_bit, cudaStream_t 
# 304
stream, bool 
# 305
debug_synchronous) 
# 306
{int volatile ___ = 1;(void)d_temp_storage;(void)temp_storage_bytes;(void)d_keys;(void)d_values;(void)num_items;(void)begin_bit;(void)end_bit;(void)stream;(void)debug_synchronous;
# 312
::exit(___);}
#if 0
# 306
{ 
# 308
return cub_::DeviceRadixSort::SortPairs(d_temp_storage, temp_storage_bytes, d_keys, d_values, num_items, begin_bit, end_bit, stream, debug_synchronous); 
# 312
} 
#endif
# 313 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/detail/stable_radix_sort.inl"
}; 
# 316
return (workaround::host_path)(d_temp_storage, temp_storage_bytes, d_keys, d_values, num_items, comp, begin_bit, end_bit, stream, debug_synchronous); 
# 320
} 
# 324
template< class Key, class Value> cudaError_t 
# 326
cub_sort_pairs_wrapper(void *d_temp_storage, size_t &
# 327
temp_storage_bytes, cub_::DoubleBuffer< Key>  &
# 328
d_keys, cub_::DoubleBuffer< Value>  &
# 329
d_values, int 
# 330
num_items, greater< Key>  
# 331
comp, int 
# 332
begin_bit = 0, int 
# 333
end_bit = sizeof(Key) * (8), cudaStream_t 
# 334
stream = 0, bool 
# 335
debug_synchronous = false) 
# 336
{ 
# 337
struct workaround { 
# 340
static cudaError_t host_path(void *d_temp_storage, size_t &
# 341
temp_storage_bytes, cub_::DoubleBuffer< Key>  &
# 342
d_keys, cub_::DoubleBuffer< Value>  &
# 343
d_values, int 
# 344
num_items, greater< Key> , int 
# 346
begin_bit, int 
# 347
end_bit, cudaStream_t 
# 348
stream, bool 
# 349
debug_synchronous) 
# 350
{ 
# 351
return cub_::DeviceRadixSort::SortPairsDescending(d_temp_storage, temp_storage_bytes, d_keys, d_values, num_items, begin_bit, end_bit, stream, debug_synchronous); 
# 352
} 
# 355
static cudaError_t device_path(void *d_temp_storage, size_t &
# 356
temp_storage_bytes, cub_::DoubleBuffer< Key>  &
# 357
d_keys, cub_::DoubleBuffer< Value>  &
# 358
d_values, int 
# 359
num_items, greater< Key> , int 
# 361
begin_bit, int 
# 362
end_bit, cudaStream_t 
# 363
stream, bool 
# 364
debug_synchronous) 
# 365
{int volatile ___ = 1;(void)d_temp_storage;(void)temp_storage_bytes;(void)d_keys;(void)d_values;(void)num_items;(void)begin_bit;(void)end_bit;(void)stream;(void)debug_synchronous;
# 371
::exit(___);}
#if 0
# 365
{ 
# 367
return cub_::DeviceRadixSort::SortPairsDescending(d_temp_storage, temp_storage_bytes, d_keys, d_values, num_items, begin_bit, end_bit, stream, debug_synchronous); 
# 371
} 
#endif
# 372 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/detail/stable_radix_sort.inl"
}; 
# 375
return (workaround::host_path)(d_temp_storage, temp_storage_bytes, d_keys, d_values, num_items, comp, begin_bit, end_bit, stream, debug_synchronous); 
# 379
} 
# 386
template< class Key, class Value, class Compare> tuple< unsigned long, unsigned long, unsigned long, unsigned long, null_type, null_type, null_type, null_type, null_type, null_type>  
# 388
compute_temporary_storage_requirements_for_radix_sort_by_key_n(size_t n, Compare comp, cudaStream_t stream) 
# 389
{ 
# 390
cub_::DoubleBuffer< Key>  dummy_keys; 
# 391
cub_::DoubleBuffer< Value>  dummy_values; 
# 394
size_t num_additional_temp_storage_bytes = (0); 
# 395
cuda::detail::throw_on_error(cub_sort_pairs_wrapper(0, num_additional_temp_storage_bytes, dummy_keys, dummy_values, static_cast< int>(n), comp, 0, sizeof(Key) * (8), stream), "after cub_::DeviceRadixSort::SortPairs(0)"); 
# 400
typedef bulk_::detail::aligned_type< 16UL> ::type aligned_type; 
# 402
size_t num_keys_double_buffer_bytes = n * sizeof(Key); 
# 405
size_t num_aligned_keys_double_buffer_bytes = thrust::detail::util::round_i(num_keys_double_buffer_bytes, sizeof(aligned_type)); 
# 407
size_t num_values_double_buffer_bytes = n * sizeof(Value); 
# 410
size_t num_aligned_double_buffer_bytes = thrust::detail::util::round_i(num_aligned_keys_double_buffer_bytes + num_values_double_buffer_bytes, sizeof(aligned_type)); 
# 412
size_t num_aligned_total_temporary_storage_bytes = num_aligned_double_buffer_bytes + num_additional_temp_storage_bytes; 
# 414
return thrust::make_tuple(num_aligned_total_temporary_storage_bytes, num_aligned_keys_double_buffer_bytes, num_aligned_double_buffer_bytes, num_additional_temp_storage_bytes); 
# 415
} 
# 419
template< class DerivedPolicy, class 
# 420
Key, class 
# 421
Value, class 
# 422
Compare> void 
# 424
stable_radix_sort_by_key_n(execution_policy< DerivedPolicy>  &exec, Key *
# 425
first1, size_t 
# 426
n, Value *
# 427
first2, Compare 
# 428
comp) 
# 429
{ 
# 430
if (n > (1)) 
# 431
{ 
# 432
cudaStream_t s = stream(thrust::detail::derived_cast< DerivedPolicy> (exec)); 
# 435
size_t num_temporary_storage_bytes = (0); 
# 436
size_t offset_to_values_buffer = (0); 
# 437
size_t offset_to_additional_temp_storage = (0); 
# 438
size_t num_additional_temp_storage_bytes = (0); 
# 439
thrust::tie(num_temporary_storage_bytes, offset_to_values_buffer, offset_to_additional_temp_storage, num_additional_temp_storage_bytes) = compute_temporary_storage_requirements_for_radix_sort_by_key_n< Key, Value> (n, comp, s); 
# 443
thrust::detail::temporary_array< char, DerivedPolicy>  temporary_storage(exec, num_temporary_storage_bytes); 
# 446
cub_::DoubleBuffer< Key>  double_buffer_keys; 
# 447
((double_buffer_keys.d_buffers)[0]) = thrust::raw_pointer_cast(&(*first1)); 
# 448
((double_buffer_keys.d_buffers)[1]) = (reinterpret_cast< Key *>(reinterpret_cast< void *>(thrust::raw_pointer_cast(&(temporary_storage[0]))))); 
# 450
cub_::DoubleBuffer< Value>  double_buffer_values; 
# 451
((double_buffer_values.d_buffers)[0]) = thrust::raw_pointer_cast(&(*first2)); 
# 452
((double_buffer_values.d_buffers)[1]) = (reinterpret_cast< Value *>(reinterpret_cast< void *>(thrust::raw_pointer_cast(&(temporary_storage[offset_to_values_buffer]))))); 
# 454
cuda::detail::throw_on_error(cub_sort_pairs_wrapper(thrust::raw_pointer_cast(&(temporary_storage[offset_to_additional_temp_storage])), num_additional_temp_storage_bytes, double_buffer_keys, double_buffer_values, static_cast< int>(n), comp, 0, sizeof(Key) * (8), s), "after cub_::DeviceRadixSort::SortPairs(1)"); 
# 465
thrust::system::cuda::detail::synchronize_if_enabled("stable_radix_sort_by_key_n(): after cub_::DeviceRadixSort::SortPairs(1)"); 
# 467
if ((double_buffer_keys.selector) != 0) 
# 468
{ 
# 469
Key *temp_ptr = reinterpret_cast< Key *>((double_buffer_keys.d_buffers)[1]); 
# 470
thrust::copy(exec, temp_ptr, temp_ptr + n, first1); 
# 471
}  
# 473
if ((double_buffer_values.selector) != 0) 
# 474
{ 
# 475
Value *temp_ptr = reinterpret_cast< Value *>((double_buffer_values.d_buffers)[1]); 
# 476
thrust::copy(exec, temp_ptr, temp_ptr + n, first2); 
# 477
}  
# 478
}  
# 479
} 
# 482
}
# 485
template< class DerivedPolicy, class 
# 486
RandomAccessIterator1, class 
# 487
RandomAccessIterator2> void 
# 489
stable_radix_sort_by_key(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator1 
# 490
first1, RandomAccessIterator1 
# 491
last1, RandomAccessIterator2 
# 492
first2, less< typename iterator_value< RandomAccessIterator1> ::type>  
# 493
comp) 
# 494
{ 
# 495
stable_radix_sort_detail::stable_radix_sort_by_key_n(exec, thrust::raw_pointer_cast(&(*first1)), last1 - first1, thrust::raw_pointer_cast(&(*first2)), comp); 
# 500
} 
# 503
template< class DerivedPolicy, class 
# 504
RandomAccessIterator1, class 
# 505
RandomAccessIterator2> void 
# 507
stable_radix_sort_by_key(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator1 
# 508
first1, RandomAccessIterator1 
# 509
last1, RandomAccessIterator2 
# 510
first2, greater< typename iterator_value< RandomAccessIterator1> ::type>  
# 511
comp) 
# 512
{ 
# 513
stable_radix_sort_detail::stable_radix_sort_by_key_n(exec, thrust::raw_pointer_cast(&(*first1)), last1 - first1, thrust::raw_pointer_cast(&(*first2)), comp); 
# 518
} 
# 521
}
# 522
}
# 523
}
# 524
}
# 525
}
# 28 "/usr/local/cuda-8.0/include/thrust/partition.h"
namespace thrust { 
# 97
template< class DerivedPolicy, class 
# 98
ForwardIterator, class 
# 99
Predicate> ForwardIterator 
# 97
partition(const detail::execution_policy_base< DerivedPolicy>  & exec, ForwardIterator first, ForwardIterator last, Predicate pred); 
# 157
template< class ForwardIterator, class 
# 158
Predicate> ForwardIterator 
# 157
partition(ForwardIterator first, ForwardIterator last, Predicate pred); 
# 225
template< class DerivedPolicy, class 
# 226
ForwardIterator, class 
# 227
InputIterator, class 
# 228
Predicate> ForwardIterator 
# 225
partition(const detail::execution_policy_base< DerivedPolicy>  & exec, ForwardIterator first, ForwardIterator last, InputIterator stencil, Predicate pred); 
# 293
template< class ForwardIterator, class 
# 294
InputIterator, class 
# 295
Predicate> ForwardIterator 
# 293
partition(ForwardIterator first, ForwardIterator last, InputIterator stencil, Predicate pred); 
# 369
template< class DerivedPolicy, class 
# 370
InputIterator, class 
# 371
OutputIterator1, class 
# 372
OutputIterator2, class 
# 373
Predicate> pair< OutputIterator1, OutputIterator2>  
# 369
partition_copy(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator first, InputIterator last, OutputIterator1 out_true, OutputIterator2 out_false, Predicate pred); 
# 446
template< class InputIterator, class 
# 447
OutputIterator1, class 
# 448
OutputIterator2, class 
# 449
Predicate> pair< OutputIterator1, OutputIterator2>  
# 446
partition_copy(InputIterator first, InputIterator last, OutputIterator1 out_true, OutputIterator2 out_false, Predicate pred); 
# 523
template< class DerivedPolicy, class 
# 524
InputIterator1, class 
# 525
InputIterator2, class 
# 526
OutputIterator1, class 
# 527
OutputIterator2, class 
# 528
Predicate> pair< OutputIterator1, OutputIterator2>  
# 523
partition_copy(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator1 first, InputIterator1 last, InputIterator2 stencil, OutputIterator1 out_true, OutputIterator2 out_false, Predicate pred); 
# 599
template< class InputIterator1, class 
# 600
InputIterator2, class 
# 601
OutputIterator1, class 
# 602
OutputIterator2, class 
# 603
Predicate> pair< OutputIterator1, OutputIterator2>  
# 599
partition_copy(InputIterator1 first, InputIterator1 last, InputIterator2 stencil, OutputIterator1 out_true, OutputIterator2 out_false, Predicate pred); 
# 672
template< class DerivedPolicy, class 
# 673
ForwardIterator, class 
# 674
Predicate> ForwardIterator 
# 672
stable_partition(const detail::execution_policy_base< DerivedPolicy>  & exec, ForwardIterator first, ForwardIterator last, Predicate pred); 
# 735
template< class ForwardIterator, class 
# 736
Predicate> ForwardIterator 
# 735
stable_partition(ForwardIterator first, ForwardIterator last, Predicate pred); 
# 805
template< class DerivedPolicy, class 
# 806
ForwardIterator, class 
# 807
InputIterator, class 
# 808
Predicate> ForwardIterator 
# 805
stable_partition(const detail::execution_policy_base< DerivedPolicy>  & exec, ForwardIterator first, ForwardIterator last, InputIterator stencil, Predicate pred); 
# 875
template< class ForwardIterator, class 
# 876
InputIterator, class 
# 877
Predicate> ForwardIterator 
# 875
stable_partition(ForwardIterator first, ForwardIterator last, InputIterator stencil, Predicate pred); 
# 953
template< class DerivedPolicy, class 
# 954
InputIterator, class 
# 955
OutputIterator1, class 
# 956
OutputIterator2, class 
# 957
Predicate> pair< OutputIterator1, OutputIterator2>  
# 953
stable_partition_copy(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator first, InputIterator last, OutputIterator1 out_true, OutputIterator2 out_false, Predicate pred); 
# 1032
template< class InputIterator, class 
# 1033
OutputIterator1, class 
# 1034
OutputIterator2, class 
# 1035
Predicate> pair< OutputIterator1, OutputIterator2>  
# 1032
stable_partition_copy(InputIterator first, InputIterator last, OutputIterator1 out_true, OutputIterator2 out_false, Predicate pred); 
# 1110
template< class DerivedPolicy, class 
# 1111
InputIterator1, class 
# 1112
InputIterator2, class 
# 1113
OutputIterator1, class 
# 1114
OutputIterator2, class 
# 1115
Predicate> pair< OutputIterator1, OutputIterator2>  
# 1110
stable_partition_copy(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator1 first, InputIterator1 last, InputIterator2 stencil, OutputIterator1 out_true, OutputIterator2 out_false, Predicate pred); 
# 1188
template< class InputIterator1, class 
# 1189
InputIterator2, class 
# 1190
OutputIterator1, class 
# 1191
OutputIterator2, class 
# 1192
Predicate> pair< OutputIterator1, OutputIterator2>  
# 1188
stable_partition_copy(InputIterator1 first, InputIterator1 last, InputIterator2 stencil, OutputIterator1 out_true, OutputIterator2 out_false, Predicate pred); 
# 1263
template< class DerivedPolicy, class ForwardIterator, class Predicate> ForwardIterator partition_point(const detail::execution_policy_base< DerivedPolicy>  & exec, ForwardIterator first, ForwardIterator last, Predicate pred); 
# 1315
template< class ForwardIterator, class Predicate> ForwardIterator partition_point(ForwardIterator first, ForwardIterator last, Predicate pred); 
# 1376
template< class DerivedPolicy, class InputIterator, class Predicate> bool is_partitioned(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator first, InputIterator last, Predicate pred); 
# 1425
template< class InputIterator, class Predicate> bool is_partitioned(InputIterator first, InputIterator last, Predicate pred); 
# 1436
}
# 27 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/partition.h"
namespace thrust { 
# 29
namespace system { 
# 31
namespace detail { 
# 33
namespace generic { 
# 37
template< class ExecutionPolicy, class 
# 38
ForwardIterator, class 
# 39
Predicate> ForwardIterator 
# 37
stable_partition(execution_policy< ExecutionPolicy>  & exec, ForwardIterator first, ForwardIterator last, Predicate pred); 
# 46
template< class ExecutionPolicy, class 
# 47
ForwardIterator, class 
# 48
InputIterator, class 
# 49
Predicate> ForwardIterator 
# 46
stable_partition(execution_policy< ExecutionPolicy>  & exec, ForwardIterator first, ForwardIterator last, InputIterator stencil, Predicate pred); 
# 58
template< class ExecutionPolicy, class 
# 59
InputIterator, class 
# 60
OutputIterator1, class 
# 61
OutputIterator2, class 
# 62
Predicate> pair< OutputIterator1, OutputIterator2>  
# 58
stable_partition_copy(execution_policy< ExecutionPolicy>  & exec, InputIterator first, InputIterator last, OutputIterator1 out_true, OutputIterator2 out_false, Predicate pred); 
# 73
template< class ExecutionPolicy, class 
# 74
InputIterator1, class 
# 75
InputIterator2, class 
# 76
OutputIterator1, class 
# 77
OutputIterator2, class 
# 78
Predicate> pair< OutputIterator1, OutputIterator2>  
# 73
stable_partition_copy(execution_policy< ExecutionPolicy>  & exec, InputIterator1 first, InputIterator1 last, InputIterator2 stencil, OutputIterator1 out_true, OutputIterator2 out_false, Predicate pred); 
# 90
template< class ExecutionPolicy, class 
# 91
ForwardIterator, class 
# 92
Predicate> ForwardIterator 
# 90
partition(execution_policy< ExecutionPolicy>  & exec, ForwardIterator first, ForwardIterator last, Predicate pred); 
# 100
template< class ExecutionPolicy, class 
# 101
ForwardIterator, class 
# 102
InputIterator, class 
# 103
Predicate> ForwardIterator 
# 100
partition(execution_policy< ExecutionPolicy>  & exec, ForwardIterator first, ForwardIterator last, InputIterator stencil, Predicate pred); 
# 112
template< class ExecutionPolicy, class 
# 113
InputIterator, class 
# 114
OutputIterator1, class 
# 115
OutputIterator2, class 
# 116
Predicate> pair< OutputIterator1, OutputIterator2>  
# 112
partition_copy(execution_policy< ExecutionPolicy>  & exec, InputIterator first, InputIterator last, OutputIterator1 out_true, OutputIterator2 out_false, Predicate pred); 
# 127
template< class ExecutionPolicy, class 
# 128
InputIterator1, class 
# 129
InputIterator2, class 
# 130
OutputIterator1, class 
# 131
OutputIterator2, class 
# 132
Predicate> pair< OutputIterator1, OutputIterator2>  
# 127
partition_copy(execution_policy< ExecutionPolicy>  & exec, InputIterator1 first, InputIterator1 last, InputIterator2 stencil, OutputIterator1 out_true, OutputIterator2 out_false, Predicate pred); 
# 144
template< class ExecutionPolicy, class 
# 145
ForwardIterator, class 
# 146
Predicate> ForwardIterator 
# 144
partition_point(execution_policy< ExecutionPolicy>  & exec, ForwardIterator first, ForwardIterator last, Predicate pred); 
# 154
template< class ExecutionPolicy, class 
# 155
InputIterator, class 
# 156
Predicate> bool 
# 154
is_partitioned(execution_policy< ExecutionPolicy>  & exec, InputIterator first, InputIterator last, Predicate pred); 
# 164
}
# 165
}
# 166
}
# 167
}
# 27 "/usr/local/cuda-8.0/include/thrust/remove.h"
namespace thrust { 
# 95
template< class DerivedPolicy, class 
# 96
ForwardIterator, class 
# 97
T> ForwardIterator 
# 95
remove(const detail::execution_policy_base< DerivedPolicy>  & exec, ForwardIterator first, ForwardIterator last, const T & value); 
# 157
template< class ForwardIterator, class 
# 158
T> ForwardIterator 
# 157
remove(ForwardIterator first, ForwardIterator last, const T & value); 
# 211
template< class DerivedPolicy, class 
# 212
InputIterator, class 
# 213
OutputIterator, class 
# 214
T> OutputIterator 
# 211
remove_copy(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator first, InputIterator last, OutputIterator result, const T & value); 
# 264
template< class InputIterator, class 
# 265
OutputIterator, class 
# 266
T> OutputIterator 
# 264
remove_copy(InputIterator first, InputIterator last, OutputIterator result, const T & value); 
# 342
template< class DerivedPolicy, class 
# 343
ForwardIterator, class 
# 344
Predicate> ForwardIterator 
# 342
remove_if(const detail::execution_policy_base< DerivedPolicy>  & exec, ForwardIterator first, ForwardIterator last, Predicate pred); 
# 415
template< class ForwardIterator, class 
# 416
Predicate> ForwardIterator 
# 415
remove_if(ForwardIterator first, ForwardIterator last, Predicate pred); 
# 479
template< class DerivedPolicy, class 
# 480
InputIterator, class 
# 481
OutputIterator, class 
# 482
Predicate> OutputIterator 
# 479
remove_copy_if(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator first, InputIterator last, OutputIterator result, Predicate pred); 
# 542
template< class InputIterator, class 
# 543
OutputIterator, class 
# 544
Predicate> OutputIterator 
# 542
remove_copy_if(InputIterator first, InputIterator last, OutputIterator result, Predicate pred); 
# 605
template< class DerivedPolicy, class 
# 606
ForwardIterator, class 
# 607
InputIterator, class 
# 608
Predicate> ForwardIterator 
# 605
remove_if(const detail::execution_policy_base< DerivedPolicy>  & exec, ForwardIterator first, ForwardIterator last, InputIterator stencil, Predicate pred); 
# 665
template< class ForwardIterator, class 
# 666
InputIterator, class 
# 667
Predicate> ForwardIterator 
# 665
remove_if(ForwardIterator first, ForwardIterator last, InputIterator stencil, Predicate pred); 
# 727
template< class DerivedPolicy, class 
# 728
InputIterator1, class 
# 729
InputIterator2, class 
# 730
OutputIterator, class 
# 731
Predicate> OutputIterator 
# 727
remove_copy_if(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator1 first, InputIterator1 last, InputIterator2 stencil, OutputIterator result, Predicate pred); 
# 788
template< class InputIterator1, class 
# 789
InputIterator2, class 
# 790
OutputIterator, class 
# 791
Predicate> OutputIterator 
# 788
remove_copy_if(InputIterator1 first, InputIterator1 last, InputIterator2 stencil, OutputIterator result, Predicate pred); 
# 803
}
# 27 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/remove.h"
namespace thrust { 
# 29
namespace system { 
# 31
namespace detail { 
# 33
namespace generic { 
# 37
template< class DerivedPolicy, class 
# 38
ForwardIterator, class 
# 39
T> ForwardIterator 
# 37
remove(execution_policy< DerivedPolicy>  & exec, ForwardIterator first, ForwardIterator last, const T & value); 
# 47
template< class DerivedPolicy, class 
# 48
InputIterator, class 
# 49
OutputIterator, class 
# 50
T> OutputIterator 
# 47
remove_copy(execution_policy< DerivedPolicy>  & exec, InputIterator first, InputIterator last, OutputIterator result, const T & value); 
# 59
template< class DerivedPolicy, class 
# 60
ForwardIterator, class 
# 61
Predicate> ForwardIterator 
# 59
remove_if(execution_policy< DerivedPolicy>  & exec, ForwardIterator first, ForwardIterator last, Predicate pred); 
# 69
template< class DerivedPolicy, class 
# 70
ForwardIterator, class 
# 71
InputIterator, class 
# 72
Predicate> ForwardIterator 
# 69
remove_if(execution_policy< DerivedPolicy>  & exec, ForwardIterator first, ForwardIterator last, InputIterator stencil, Predicate pred); 
# 81
template< class DerivedPolicy, class 
# 82
InputIterator, class 
# 83
OutputIterator, class 
# 84
Predicate> OutputIterator 
# 81
remove_copy_if(execution_policy< DerivedPolicy>  & exec, InputIterator first, InputIterator last, OutputIterator result, Predicate pred); 
# 93
template< class DerivedPolicy, class 
# 94
InputIterator1, class 
# 95
InputIterator2, class 
# 96
OutputIterator, class 
# 97
Predicate> OutputIterator 
# 93
remove_copy_if(execution_policy< DerivedPolicy>  & exec, InputIterator1 first, InputIterator1 last, InputIterator2 stencil, OutputIterator result, Predicate pred); 
# 107
}
# 108
}
# 109
}
# 110
}
# 30 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/remove.inl"
namespace thrust { 
# 32
namespace system { 
# 34
namespace detail { 
# 36
namespace generic { 
# 40
template< class DerivedPolicy, class 
# 41
ForwardIterator, class 
# 42
T> ForwardIterator 
# 44
remove(execution_policy< DerivedPolicy>  &exec, ForwardIterator 
# 45
first, ForwardIterator 
# 46
last, const T &
# 47
value) 
# 48
{ 
# 49
thrust::detail::equal_to_value< T>  pred(value); 
# 52
return thrust::remove_if(exec, first, last, pred); 
# 53
} 
# 56
template< class DerivedPolicy, class 
# 57
InputIterator, class 
# 58
OutputIterator, class 
# 59
T> OutputIterator 
# 61
remove_copy(execution_policy< DerivedPolicy>  &exec, InputIterator 
# 62
first, InputIterator 
# 63
last, OutputIterator 
# 64
result, const T &
# 65
value) 
# 66
{ 
# 67
thrust::detail::equal_to_value< T>  pred(value); 
# 70
return thrust::remove_copy_if(exec, first, last, result, pred); 
# 71
} 
# 74
template< class DerivedPolicy, class 
# 75
ForwardIterator, class 
# 76
Predicate> ForwardIterator 
# 78
remove_if(execution_policy< DerivedPolicy>  &exec, ForwardIterator 
# 79
first, ForwardIterator 
# 80
last, Predicate 
# 81
pred) 
# 82
{ 
# 83
typedef typename iterator_traits< ForwardIterator> ::value_type InputType; 
# 86
thrust::detail::temporary_array< typename iterator_traits< ForwardIterator> ::value_type, DerivedPolicy>  temp(exec, first, last); 
# 89
return thrust::remove_copy_if(exec, (temp.begin()), (temp.end()), (temp.begin()), first, pred); 
# 90
} 
# 93
template< class DerivedPolicy, class 
# 94
ForwardIterator, class 
# 95
InputIterator, class 
# 96
Predicate> ForwardIterator 
# 98
remove_if(execution_policy< DerivedPolicy>  &exec, ForwardIterator 
# 99
first, ForwardIterator 
# 100
last, InputIterator 
# 101
stencil, Predicate 
# 102
pred) 
# 103
{ 
# 104
typedef typename iterator_traits< ForwardIterator> ::value_type InputType; 
# 107
thrust::detail::temporary_array< typename iterator_traits< ForwardIterator> ::value_type, DerivedPolicy>  temp(exec, first, last); 
# 110
return thrust::remove_copy_if(exec, (temp.begin()), (temp.end()), stencil, first, pred); 
# 111
} 
# 114
template< class DerivedPolicy, class 
# 115
InputIterator, class 
# 116
OutputIterator, class 
# 117
Predicate> OutputIterator 
# 119
remove_copy_if(execution_policy< DerivedPolicy>  &exec, InputIterator 
# 120
first, InputIterator 
# 121
last, OutputIterator 
# 122
result, Predicate 
# 123
pred) 
# 124
{ 
# 125
return thrust::remove_copy_if(exec, first, last, first, result, pred); 
# 126
} 
# 129
template< class DerivedPolicy, class 
# 130
InputIterator1, class 
# 131
InputIterator2, class 
# 132
OutputIterator, class 
# 133
Predicate> OutputIterator 
# 135
remove_copy_if(execution_policy< DerivedPolicy>  &exec, InputIterator1 
# 136
first, InputIterator1 
# 137
last, InputIterator2 
# 138
stencil, OutputIterator 
# 139
result, Predicate 
# 140
pred) 
# 141
{ 
# 142
return thrust::copy_if(exec, first, last, stencil, result, thrust::detail::not1(pred)); 
# 143
} 
# 146
}
# 147
}
# 148
}
# 149
}
# 28 "/usr/local/cuda-8.0/include/thrust/system/detail/sequential/remove.h"
namespace thrust { 
# 30
namespace system { 
# 32
namespace detail { 
# 34
namespace sequential { 
# 39
template< class DerivedPolicy, class 
# 40
ForwardIterator, class 
# 41
Predicate> ForwardIterator 
# 43
remove_if(execution_policy< DerivedPolicy>  &, ForwardIterator 
# 44
first, ForwardIterator 
# 45
last, Predicate 
# 46
pred) 
# 47
{ 
# 52
thrust::detail::wrapped_function< Predicate, bool>  wrapped_pred(pred); 
# 55
while ((first != last) && (!wrapped_pred(*first))) { 
# 56
++first; }  
# 58
if (first == last) { 
# 59
return first; }  
# 62
ForwardIterator result = first; 
# 64
++first; 
# 66
while (first != last) 
# 67
{ 
# 68
if (!wrapped_pred(*first)) 
# 69
{ 
# 70
(*result) = (*first); 
# 71
++result; 
# 72
}  
# 73
++first; 
# 74
}  
# 76
return result; 
# 77
} 
# 81
template< class DerivedPolicy, class 
# 82
ForwardIterator, class 
# 83
InputIterator, class 
# 84
Predicate> ForwardIterator 
# 86
remove_if(execution_policy< DerivedPolicy>  &, ForwardIterator 
# 87
first, ForwardIterator 
# 88
last, InputIterator 
# 89
stencil, Predicate 
# 90
pred) 
# 91
{ 
# 96
thrust::detail::wrapped_function< Predicate, bool>  wrapped_pred(pred); 
# 99
while ((first != last) && (!wrapped_pred(*stencil))) 
# 100
{ 
# 101
++first; 
# 102
++stencil; 
# 103
}  
# 105
if (first == last) { 
# 106
return first; }  
# 109
ForwardIterator result = first; 
# 111
++first; 
# 112
++stencil; 
# 114
while (first != last) 
# 115
{ 
# 116
if (!wrapped_pred(*stencil)) 
# 117
{ 
# 118
(*result) = (*first); 
# 119
++result; 
# 120
}  
# 121
++first; 
# 122
++stencil; 
# 123
}  
# 125
return result; 
# 126
} 
# 130
template< class DerivedPolicy, class 
# 131
InputIterator, class 
# 132
OutputIterator, class 
# 133
Predicate> OutputIterator 
# 135
remove_copy_if(execution_policy< DerivedPolicy>  &, InputIterator 
# 136
first, InputIterator 
# 137
last, OutputIterator 
# 138
result, Predicate 
# 139
pred) 
# 140
{ 
# 145
thrust::detail::wrapped_function< Predicate, bool>  wrapped_pred(pred); 
# 147
while (first != last) 
# 148
{ 
# 149
if (!wrapped_pred(*first)) 
# 150
{ 
# 151
(*result) = (*first); 
# 152
++result; 
# 153
}  
# 155
++first; 
# 156
}  
# 158
return result; 
# 159
} 
# 163
template< class DerivedPolicy, class 
# 164
InputIterator1, class 
# 165
InputIterator2, class 
# 166
OutputIterator, class 
# 167
Predicate> OutputIterator 
# 169
remove_copy_if(execution_policy< DerivedPolicy>  &, InputIterator1 
# 170
first, InputIterator1 
# 171
last, InputIterator2 
# 172
stencil, OutputIterator 
# 173
result, Predicate 
# 174
pred) 
# 175
{ 
# 180
thrust::detail::wrapped_function< Predicate, bool>  wrapped_pred(pred); 
# 182
while (first != last) 
# 183
{ 
# 184
if (!wrapped_pred(*stencil)) 
# 185
{ 
# 186
(*result) = (*first); 
# 187
++result; 
# 188
}  
# 190
++first; 
# 191
++stencil; 
# 192
}  
# 194
return result; 
# 195
} 
# 198
}
# 199
}
# 200
}
# 201
}
# 29 "/usr/local/cuda-8.0/include/thrust/detail/remove.inl"
namespace thrust { 
# 34
template< class DerivedPolicy, class 
# 35
ForwardIterator, class 
# 36
T> ForwardIterator 
# 38
remove(const detail::execution_policy_base< DerivedPolicy>  &exec, ForwardIterator 
# 39
first, ForwardIterator 
# 40
last, const T &
# 41
value) 
# 42
{ 
# 43
using system::detail::generic::remove;
# 44
return remove(detail::derived_cast(detail::strip_const(exec)), first, last, value); 
# 45
} 
# 49
template< class DerivedPolicy, class 
# 50
InputIterator, class 
# 51
OutputIterator, class 
# 52
T> OutputIterator 
# 54
remove_copy(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator 
# 55
first, InputIterator 
# 56
last, OutputIterator 
# 57
result, const T &
# 58
value) 
# 59
{ 
# 60
using system::detail::generic::remove_copy;
# 61
return remove_copy(detail::derived_cast(detail::strip_const(exec)), first, last, result, value); 
# 62
} 
# 66
template< class DerivedPolicy, class 
# 67
ForwardIterator, class 
# 68
Predicate> ForwardIterator 
# 70
remove_if(const detail::execution_policy_base< DerivedPolicy>  &exec, ForwardIterator 
# 71
first, ForwardIterator 
# 72
last, Predicate 
# 73
pred) 
# 74
{ 
# 75
using system::detail::generic::remove_if;
# 76
return remove_if(detail::derived_cast(detail::strip_const(exec)), first, last, pred); 
# 77
} 
# 81
template< class DerivedPolicy, class 
# 82
InputIterator, class 
# 83
OutputIterator, class 
# 84
Predicate> OutputIterator 
# 86
remove_copy_if(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator 
# 87
first, InputIterator 
# 88
last, OutputIterator 
# 89
result, Predicate 
# 90
pred) 
# 91
{ 
# 92
using system::detail::generic::remove_copy_if;
# 93
return remove_copy_if(detail::derived_cast(detail::strip_const(exec)), first, last, result, pred); 
# 94
} 
# 98
template< class DerivedPolicy, class 
# 99
ForwardIterator, class 
# 100
InputIterator, class 
# 101
Predicate> ForwardIterator 
# 103
remove_if(const detail::execution_policy_base< DerivedPolicy>  &exec, ForwardIterator 
# 104
first, ForwardIterator 
# 105
last, InputIterator 
# 106
stencil, Predicate 
# 107
pred) 
# 108
{ 
# 109
using system::detail::generic::remove_if;
# 110
return remove_if(detail::derived_cast(detail::strip_const(exec)), first, last, stencil, pred); 
# 111
} 
# 115
template< class DerivedPolicy, class 
# 116
InputIterator1, class 
# 117
InputIterator2, class 
# 118
OutputIterator, class 
# 119
Predicate> OutputIterator 
# 121
remove_copy_if(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator1 
# 122
first, InputIterator1 
# 123
last, InputIterator2 
# 124
stencil, OutputIterator 
# 125
result, Predicate 
# 126
pred) 
# 127
{ 
# 128
using system::detail::generic::remove_copy_if;
# 129
return remove_copy_if(detail::derived_cast(detail::strip_const(exec)), first, last, stencil, result, pred); 
# 130
} 
# 133
template< class ForwardIterator, class 
# 134
T> ForwardIterator 
# 135
remove(ForwardIterator first, ForwardIterator 
# 136
last, const T &
# 137
value) 
# 138
{ 
# 139
using thrust::system::detail::generic::select_system;
# 141
typedef typename iterator_system< ForwardIterator> ::type System; 
# 143
System system; 
# 145
return thrust::remove(select_system(system), first, last, value); 
# 146
} 
# 149
template< class InputIterator, class 
# 150
OutputIterator, class 
# 151
T> OutputIterator 
# 152
remove_copy(InputIterator first, InputIterator 
# 153
last, OutputIterator 
# 154
result, const T &
# 155
value) 
# 156
{ 
# 157
using system::detail::generic::select_system;
# 159
typedef typename iterator_system< InputIterator> ::type System1; 
# 160
typedef typename iterator_system< OutputIterator> ::type System2; 
# 162
System1 system1; 
# 163
System2 system2; 
# 165
return thrust::remove_copy(select_system(system1, system2), first, last, result, value); 
# 166
} 
# 169
template< class ForwardIterator, class 
# 170
Predicate> ForwardIterator 
# 171
remove_if(ForwardIterator first, ForwardIterator 
# 172
last, Predicate 
# 173
pred) 
# 174
{ 
# 175
using thrust::system::detail::generic::select_system;
# 177
typedef typename iterator_system< ForwardIterator> ::type System; 
# 179
System system; 
# 181
return thrust::remove_if(select_system(system), first, last, pred); 
# 182
} 
# 185
template< class ForwardIterator, class 
# 186
InputIterator, class 
# 187
Predicate> ForwardIterator 
# 188
remove_if(ForwardIterator first, ForwardIterator 
# 189
last, InputIterator 
# 190
stencil, Predicate 
# 191
pred) 
# 192
{ 
# 193
using system::detail::generic::select_system;
# 195
typedef typename iterator_system< ForwardIterator> ::type System1; 
# 196
typedef typename iterator_system< InputIterator> ::type System2; 
# 198
System1 system1; 
# 199
System2 system2; 
# 201
return thrust::remove_if(select_system(system1, system2), first, last, stencil, pred); 
# 202
} 
# 205
template< class InputIterator, class 
# 206
OutputIterator, class 
# 207
Predicate> OutputIterator 
# 208
remove_copy_if(InputIterator first, InputIterator 
# 209
last, OutputIterator 
# 210
result, Predicate 
# 211
pred) 
# 212
{ 
# 213
using system::detail::generic::select_system;
# 215
typedef typename iterator_system< InputIterator> ::type System1; 
# 216
typedef typename iterator_system< OutputIterator> ::type System2; 
# 218
System1 system1; 
# 219
System2 system2; 
# 221
return thrust::remove_copy_if(select_system(system1, system2), first, last, result, pred); 
# 222
} 
# 225
template< class InputIterator1, class 
# 226
InputIterator2, class 
# 227
OutputIterator, class 
# 228
Predicate> OutputIterator 
# 229
remove_copy_if(InputIterator1 first, InputIterator1 
# 230
last, InputIterator2 
# 231
stencil, OutputIterator 
# 232
result, Predicate 
# 233
pred) 
# 234
{ 
# 235
using system::detail::generic::select_system;
# 237
typedef typename iterator_system< InputIterator1> ::type System1; 
# 238
typedef typename iterator_system< InputIterator2> ::type System2; 
# 239
typedef typename iterator_system< OutputIterator> ::type System3; 
# 241
System1 system1; 
# 242
System2 system2; 
# 243
System3 system3; 
# 245
return thrust::remove_copy_if(select_system(system1, system2, system3), first, last, stencil, result, pred); 
# 246
} 
# 249
}
# 28 "/usr/local/cuda-8.0/include/thrust/count.h"
namespace thrust { 
# 83
template< class DerivedPolicy, class InputIterator, class EqualityComparable> typename iterator_traits< InputIterator> ::difference_type count(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator first, InputIterator last, const EqualityComparable & value); 
# 121
template< class InputIterator, class EqualityComparable> typename iterator_traits< InputIterator> ::difference_type count(InputIterator first, InputIterator last, const EqualityComparable & value); 
# 174
template< class DerivedPolicy, class InputIterator, class Predicate> typename iterator_traits< InputIterator> ::difference_type count_if(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator first, InputIterator last, Predicate pred); 
# 222
template< class InputIterator, class Predicate> typename iterator_traits< InputIterator> ::difference_type count_if(InputIterator first, InputIterator last, Predicate pred); 
# 232
}
# 23 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/count.h"
namespace thrust { 
# 25
namespace system { 
# 27
namespace detail { 
# 29
namespace generic { 
# 33
template< class DerivedPolicy, class InputIterator, class EqualityComparable> typename iterator_traits< InputIterator> ::difference_type count(execution_policy< DerivedPolicy>  & exec, InputIterator first, InputIterator last, const EqualityComparable & value); 
# 39
template< class DerivedPolicy, class InputIterator, class Predicate> typename iterator_traits< InputIterator> ::difference_type count_if(execution_policy< DerivedPolicy>  & exec, InputIterator first, InputIterator last, Predicate pred); 
# 45
}
# 46
}
# 47
}
# 48
}
# 27 "/usr/local/cuda-8.0/include/thrust/transform_reduce.h"
namespace thrust { 
# 105
template< class DerivedPolicy, class 
# 106
InputIterator, class 
# 107
UnaryFunction, class 
# 108
OutputType, class 
# 109
BinaryFunction> OutputType 
# 105
transform_reduce(const detail::execution_policy_base< DerivedPolicy>  & exec, InputIterator first, InputIterator last, UnaryFunction unary_op, OutputType init, BinaryFunction binary_op); 
# 179
template< class InputIterator, class 
# 180
UnaryFunction, class 
# 181
OutputType, class 
# 182
BinaryFunction> OutputType 
# 179
transform_reduce(InputIterator first, InputIterator last, UnaryFunction unary_op, OutputType init, BinaryFunction binary_op); 
# 195
}
# 23 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/transform_reduce.h"
namespace thrust { 
# 25
namespace system { 
# 27
namespace detail { 
# 29
namespace generic { 
# 33
template< class ExecutionPolicy, class 
# 34
InputIterator, class 
# 35
UnaryFunction, class 
# 36
OutputType, class 
# 37
BinaryFunction> OutputType 
# 33
transform_reduce(execution_policy< ExecutionPolicy>  & exec, InputIterator first, InputIterator last, UnaryFunction unary_op, OutputType init, BinaryFunction binary_op); 
# 47
}
# 48
}
# 49
}
# 50
}
# 22 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/transform_reduce.inl"
namespace thrust { 
# 24
namespace system { 
# 26
namespace detail { 
# 28
namespace generic { 
# 32
template< class DerivedPolicy, class 
# 33
InputIterator, class 
# 34
UnaryFunction, class 
# 35
OutputType, class 
# 36
BinaryFunction> OutputType 
# 38
transform_reduce(execution_policy< DerivedPolicy>  &exec, InputIterator 
# 39
first, InputIterator 
# 40
last, UnaryFunction 
# 41
unary_op, OutputType 
# 42
init, BinaryFunction 
# 43
binary_op) 
# 44
{ 
# 45
transform_iterator< UnaryFunction, InputIterator, OutputType>  xfrm_first(first, unary_op); 
# 46
transform_iterator< UnaryFunction, InputIterator, OutputType>  xfrm_last(last, unary_op); 
# 48
return thrust::reduce(exec, xfrm_first, xfrm_last, init, binary_op); 
# 49
} 
# 52
}
# 53
}
# 54
}
# 55
}
# 28 "/usr/local/cuda-8.0/include/thrust/detail/transform_reduce.inl"
namespace thrust { 
# 33
template< class DerivedPolicy, class 
# 34
InputIterator, class 
# 35
UnaryFunction, class 
# 36
OutputType, class 
# 37
BinaryFunction> OutputType 
# 39
transform_reduce(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator 
# 40
first, InputIterator 
# 41
last, UnaryFunction 
# 42
unary_op, OutputType 
# 43
init, BinaryFunction 
# 44
binary_op) 
# 45
{ 
# 46
using system::detail::generic::transform_reduce;
# 47
return transform_reduce(detail::derived_cast(detail::strip_const(exec)), first, last, unary_op, init, binary_op); 
# 48
} 
# 51
template< class InputIterator, class 
# 52
UnaryFunction, class 
# 53
OutputType, class 
# 54
BinaryFunction> OutputType 
# 55
transform_reduce(InputIterator first, InputIterator 
# 56
last, UnaryFunction 
# 57
unary_op, OutputType 
# 58
init, BinaryFunction 
# 59
binary_op) 
# 60
{ 
# 61
using thrust::system::detail::generic::select_system;
# 63
typedef typename iterator_system< InputIterator> ::type System; 
# 65
System system; 
# 67
return thrust::transform_reduce(select_system(system), first, last, unary_op, init, binary_op); 
# 68
} 
# 71
}
# 22 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/count.inl"
namespace thrust { 
# 24
namespace system { 
# 26
namespace detail { 
# 28
namespace generic { 
# 32
template< class InputType, class Predicate, class CountType> 
# 33
struct count_if_transform { 
# 36
count_if_transform(Predicate _pred) : pred(_pred) { } 
# 40
CountType operator()(const InputType &val) 
# 41
{ 
# 42
if ((pred)(val)) { 
# 43
return 1; } else { 
# 45
return 0; }  
# 46
} 
# 48
Predicate pred; 
# 49
}; 
# 52
template< class DerivedPolicy, class InputIterator, class EqualityComparable> typename iterator_traits< InputIterator> ::difference_type 
# 55
count(execution_policy< DerivedPolicy>  &exec, InputIterator first, InputIterator last, const EqualityComparable &value) 
# 56
{ 
# 58
return thrust::count_if(exec, first, last, ((thrust::detail::equal_to_value< EqualityComparable> )(value))); 
# 59
} 
# 62
template< class DerivedPolicy, class InputIterator, class Predicate> typename iterator_traits< InputIterator> ::difference_type 
# 65
count_if(execution_policy< DerivedPolicy>  &exec, InputIterator first, InputIterator last, Predicate pred) 
# 66
{ 
# 67
typedef typename iterator_traits< InputIterator> ::value_type InputType; 
# 68
typedef typename iterator_traits< InputIterator> ::difference_type CountType; 
# 70
count_if_transform< typename iterator_traits< InputIterator> ::value_type, Predicate, typename iterator_traits< InputIterator> ::difference_type>  unary_op(pred); 
# 71
plus< typename iterator_traits< InputIterator> ::difference_type>  binary_op; 
# 72
return thrust::transform_reduce(exec, first, last, unary_op, (CountType)0, binary_op); 
# 73
} 
# 76
}
# 77
}
# 78
}
# 79
}
# 29 "/usr/local/cuda-8.0/include/thrust/detail/count.inl"
namespace thrust { 
# 34
template< class DerivedPolicy, class InputIterator, class EqualityComparable> typename iterator_traits< InputIterator> ::difference_type 
# 37
count(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator first, InputIterator last, const EqualityComparable &value) 
# 38
{ 
# 39
using system::detail::generic::count;
# 40
return count(detail::derived_cast(detail::strip_const(exec)), first, last, value); 
# 41
} 
# 45
template< class DerivedPolicy, class InputIterator, class Predicate> typename iterator_traits< InputIterator> ::difference_type 
# 48
count_if(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator first, InputIterator last, Predicate pred) 
# 49
{ 
# 50
using system::detail::generic::count_if;
# 51
return count_if(detail::derived_cast(detail::strip_const(exec)), first, last, pred); 
# 52
} 
# 55
template< class InputIterator, class EqualityComparable> typename iterator_traits< InputIterator> ::difference_type 
# 57
count(InputIterator first, InputIterator last, const EqualityComparable &value) 
# 58
{ 
# 59
using thrust::system::detail::generic::select_system;
# 61
typedef typename iterator_system< InputIterator> ::type System; 
# 63
System system; 
# 65
return thrust::count(select_system(system), first, last, value); 
# 66
} 
# 69
template< class InputIterator, class Predicate> typename iterator_traits< InputIterator> ::difference_type 
# 71
count_if(InputIterator first, InputIterator last, Predicate pred) 
# 72
{ 
# 73
using thrust::system::detail::generic::select_system;
# 75
typedef typename iterator_system< InputIterator> ::type System; 
# 77
System system; 
# 79
return thrust::count_if(select_system(system), first, last, pred); 
# 80
} 
# 83
}
# 32 "/usr/local/cuda-8.0/include/thrust/system/detail/generic/partition.inl"
namespace thrust { 
# 34
namespace system { 
# 36
namespace detail { 
# 38
namespace generic { 
# 42
template< class DerivedPolicy, class 
# 43
ForwardIterator, class 
# 44
Predicate> ForwardIterator 
# 46
stable_partition(execution_policy< DerivedPolicy>  &exec, ForwardIterator 
# 47
first, ForwardIterator 
# 48
last, Predicate 
# 49
pred) 
# 50
{ 
# 51
typedef typename iterator_traits< ForwardIterator> ::value_type InputType; 
# 54
thrust::detail::temporary_array< typename iterator_traits< ForwardIterator> ::value_type, DerivedPolicy>  temp(exec, first, last); 
# 57
typename iterator_difference< ForwardIterator> ::type num_true = thrust::count_if(exec, first, last, pred); 
# 60
ForwardIterator out_false = first; 
# 61
thrust::advance(out_false, num_true); 
# 63
return thrust::stable_partition_copy(exec, (temp.begin()), (temp.end()), first, out_false, pred).first; 
# 64
} 
# 67
template< class DerivedPolicy, class 
# 68
ForwardIterator, class 
# 69
InputIterator, class 
# 70
Predicate> ForwardIterator 
# 72
stable_partition(execution_policy< DerivedPolicy>  &exec, ForwardIterator 
# 73
first, ForwardIterator 
# 74
last, InputIterator 
# 75
stencil, Predicate 
# 76
pred) 
# 77
{ 
# 78
typedef typename iterator_traits< ForwardIterator> ::value_type InputType; 
# 81
thrust::detail::temporary_array< typename iterator_traits< ForwardIterator> ::value_type, DerivedPolicy>  temp(exec, first, last); 
# 84
InputIterator stencil_last = stencil; 
# 85
thrust::advance(stencil_last, (temp.size())); 
# 86
typename iterator_difference< InputIterator> ::type num_true = thrust::count_if(exec, stencil, stencil_last, pred); 
# 89
ForwardIterator out_false = first; 
# 90
thrust::advance(out_false, num_true); 
# 92
return thrust::stable_partition_copy(exec, (temp.begin()), (temp.end()), stencil, first, out_false, pred).first; 
# 93
} 
# 96
template< class DerivedPolicy, class 
# 97
InputIterator, class 
# 98
OutputIterator1, class 
# 99
OutputIterator2, class 
# 100
Predicate> pair< OutputIterator1, OutputIterator2>  
# 103
stable_partition_copy(execution_policy< DerivedPolicy>  &exec, InputIterator 
# 104
first, InputIterator 
# 105
last, OutputIterator1 
# 106
out_true, OutputIterator2 
# 107
out_false, Predicate 
# 108
pred) 
# 109
{ 
# 110
thrust::detail::unary_negate< Predicate>  not_pred(pred); 
# 113
OutputIterator1 end_of_true_partition = thrust::remove_copy_if(exec, first, last, out_true, not_pred); 
# 116
OutputIterator2 end_of_false_partition = thrust::remove_copy_if(exec, first, last, out_false, pred); 
# 118
return thrust::make_pair(end_of_true_partition, end_of_false_partition); 
# 119
} 
# 122
template< class DerivedPolicy, class 
# 123
InputIterator1, class 
# 124
InputIterator2, class 
# 125
OutputIterator1, class 
# 126
OutputIterator2, class 
# 127
Predicate> pair< OutputIterator1, OutputIterator2>  
# 130
stable_partition_copy(execution_policy< DerivedPolicy>  &exec, InputIterator1 
# 131
first, InputIterator1 
# 132
last, InputIterator2 
# 133
stencil, OutputIterator1 
# 134
out_true, OutputIterator2 
# 135
out_false, Predicate 
# 136
pred) 
# 137
{ 
# 138
thrust::detail::unary_negate< Predicate>  not_pred(pred); 
# 141
OutputIterator1 end_of_true_partition = thrust::remove_copy_if(exec, first, last, stencil, out_true, not_pred); 
# 144
OutputIterator2 end_of_false_partition = thrust::remove_copy_if(exec, first, last, stencil, out_false, pred); 
# 146
return thrust::make_pair(end_of_true_partition, end_of_false_partition); 
# 147
} 
# 150
template< class DerivedPolicy, class 
# 151
ForwardIterator, class 
# 152
Predicate> ForwardIterator 
# 154
partition(execution_policy< DerivedPolicy>  &exec, ForwardIterator 
# 155
first, ForwardIterator 
# 156
last, Predicate 
# 157
pred) 
# 158
{ 
# 159
return thrust::stable_partition(exec, first, last, pred); 
# 160
} 
# 163
template< class DerivedPolicy, class 
# 164
ForwardIterator, class 
# 165
InputIterator, class 
# 166
Predicate> ForwardIterator 
# 168
partition(execution_policy< DerivedPolicy>  &exec, ForwardIterator 
# 169
first, ForwardIterator 
# 170
last, InputIterator 
# 171
stencil, Predicate 
# 172
pred) 
# 173
{ 
# 174
return thrust::stable_partition(exec, first, last, stencil, pred); 
# 175
} 
# 178
template< class DerivedPolicy, class 
# 179
InputIterator, class 
# 180
OutputIterator1, class 
# 181
OutputIterator2, class 
# 182
Predicate> pair< OutputIterator1, OutputIterator2>  
# 185
partition_copy(execution_policy< DerivedPolicy>  &exec, InputIterator 
# 186
first, InputIterator 
# 187
last, OutputIterator1 
# 188
out_true, OutputIterator2 
# 189
out_false, Predicate 
# 190
pred) 
# 191
{ 
# 192
return thrust::stable_partition_copy(exec, first, last, out_true, out_false, pred); 
# 193
} 
# 196
template< class DerivedPolicy, class 
# 197
InputIterator1, class 
# 198
InputIterator2, class 
# 199
OutputIterator1, class 
# 200
OutputIterator2, class 
# 201
Predicate> pair< OutputIterator1, OutputIterator2>  
# 204
partition_copy(execution_policy< DerivedPolicy>  &exec, InputIterator1 
# 205
first, InputIterator1 
# 206
last, InputIterator2 
# 207
stencil, OutputIterator1 
# 208
out_true, OutputIterator2 
# 209
out_false, Predicate 
# 210
pred) 
# 211
{ 
# 212
return thrust::stable_partition_copy(exec, first, last, stencil, out_true, out_false, pred); 
# 213
} 
# 216
template< class DerivedPolicy, class 
# 217
ForwardIterator, class 
# 218
Predicate> ForwardIterator 
# 220
partition_point(execution_policy< DerivedPolicy>  &exec, ForwardIterator 
# 221
first, ForwardIterator 
# 222
last, Predicate 
# 223
pred) 
# 224
{ 
# 225
return thrust::find_if_not(exec, first, last, pred); 
# 226
} 
# 229
template< class DerivedPolicy, class 
# 230
InputIterator, class 
# 231
Predicate> bool 
# 233
is_partitioned(execution_policy< DerivedPolicy>  &exec, InputIterator 
# 234
first, InputIterator 
# 235
last, Predicate 
# 236
pred) 
# 237
{ 
# 238
return thrust::is_sorted(exec, thrust::make_transform_iterator(first, thrust::detail::not1(pred)), thrust::make_transform_iterator(last, thrust::detail::not1(pred))); 
# 241
} 
# 244
}
# 245
}
# 246
}
# 247
}
# 29 "/usr/local/cuda-8.0/include/thrust/detail/partition.inl"
namespace thrust { 
# 34
template< class DerivedPolicy, class 
# 35
ForwardIterator, class 
# 36
Predicate> ForwardIterator 
# 38
partition(const detail::execution_policy_base< DerivedPolicy>  &exec, ForwardIterator 
# 39
first, ForwardIterator 
# 40
last, Predicate 
# 41
pred) 
# 42
{ 
# 43
using system::detail::generic::partition;
# 44
return partition(detail::derived_cast(detail::strip_const(exec)), first, last, pred); 
# 45
} 
# 49
template< class DerivedPolicy, class 
# 50
ForwardIterator, class 
# 51
InputIterator, class 
# 52
Predicate> ForwardIterator 
# 54
partition(const detail::execution_policy_base< DerivedPolicy>  &exec, ForwardIterator 
# 55
first, ForwardIterator 
# 56
last, InputIterator 
# 57
stencil, Predicate 
# 58
pred) 
# 59
{ 
# 60
using system::detail::generic::partition;
# 61
return partition(detail::derived_cast(detail::strip_const(exec)), first, last, stencil, pred); 
# 62
} 
# 66
template< class DerivedPolicy, class 
# 67
InputIterator, class 
# 68
OutputIterator1, class 
# 69
OutputIterator2, class 
# 70
Predicate> pair< OutputIterator1, OutputIterator2>  
# 73
partition_copy(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator 
# 74
first, InputIterator 
# 75
last, OutputIterator1 
# 76
out_true, OutputIterator2 
# 77
out_false, Predicate 
# 78
pred) 
# 79
{ 
# 80
using system::detail::generic::partition_copy;
# 81
return partition_copy(detail::derived_cast(detail::strip_const(exec)), first, last, out_true, out_false, pred); 
# 82
} 
# 86
template< class DerivedPolicy, class 
# 87
InputIterator1, class 
# 88
InputIterator2, class 
# 89
OutputIterator1, class 
# 90
OutputIterator2, class 
# 91
Predicate> pair< OutputIterator1, OutputIterator2>  
# 94
partition_copy(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator1 
# 95
first, InputIterator1 
# 96
last, InputIterator2 
# 97
stencil, OutputIterator1 
# 98
out_true, OutputIterator2 
# 99
out_false, Predicate 
# 100
pred) 
# 101
{ 
# 102
using system::detail::generic::partition_copy;
# 103
return partition_copy(detail::derived_cast(detail::strip_const(exec)), first, last, stencil, out_true, out_false, pred); 
# 104
} 
# 108
template< class DerivedPolicy, class 
# 109
ForwardIterator, class 
# 110
Predicate> ForwardIterator 
# 112
stable_partition(const detail::execution_policy_base< DerivedPolicy>  &exec, ForwardIterator 
# 113
first, ForwardIterator 
# 114
last, Predicate 
# 115
pred) 
# 116
{ 
# 117
using system::detail::generic::stable_partition;
# 118
return stable_partition(detail::derived_cast(detail::strip_const(exec)), first, last, pred); 
# 119
} 
# 123
template< class DerivedPolicy, class 
# 124
ForwardIterator, class 
# 125
InputIterator, class 
# 126
Predicate> ForwardIterator 
# 128
stable_partition(const detail::execution_policy_base< DerivedPolicy>  &exec, ForwardIterator 
# 129
first, ForwardIterator 
# 130
last, InputIterator 
# 131
stencil, Predicate 
# 132
pred) 
# 133
{ 
# 134
using system::detail::generic::stable_partition;
# 135
return stable_partition(detail::derived_cast(detail::strip_const(exec)), first, last, stencil, pred); 
# 136
} 
# 140
template< class DerivedPolicy, class 
# 141
InputIterator, class 
# 142
OutputIterator1, class 
# 143
OutputIterator2, class 
# 144
Predicate> pair< OutputIterator1, OutputIterator2>  
# 147
stable_partition_copy(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator 
# 148
first, InputIterator 
# 149
last, OutputIterator1 
# 150
out_true, OutputIterator2 
# 151
out_false, Predicate 
# 152
pred) 
# 153
{ 
# 154
using system::detail::generic::stable_partition_copy;
# 155
return stable_partition_copy(detail::derived_cast(detail::strip_const(exec)), first, last, out_true, out_false, pred); 
# 156
} 
# 160
template< class DerivedPolicy, class 
# 161
InputIterator1, class 
# 162
InputIterator2, class 
# 163
OutputIterator1, class 
# 164
OutputIterator2, class 
# 165
Predicate> pair< OutputIterator1, OutputIterator2>  
# 168
stable_partition_copy(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator1 
# 169
first, InputIterator1 
# 170
last, InputIterator2 
# 171
stencil, OutputIterator1 
# 172
out_true, OutputIterator2 
# 173
out_false, Predicate 
# 174
pred) 
# 175
{ 
# 176
using system::detail::generic::stable_partition_copy;
# 177
return stable_partition_copy(detail::derived_cast(detail::strip_const(exec)), first, last, stencil, out_true, out_false, pred); 
# 178
} 
# 182
template< class DerivedPolicy, class ForwardIterator, class Predicate> ForwardIterator 
# 184
partition_point(const detail::execution_policy_base< DerivedPolicy>  &exec, ForwardIterator 
# 185
first, ForwardIterator 
# 186
last, Predicate 
# 187
pred) 
# 188
{ 
# 189
using system::detail::generic::partition_point;
# 190
return partition_point(detail::derived_cast(detail::strip_const(exec)), first, last, pred); 
# 191
} 
# 195
template< class DerivedPolicy, class InputIterator, class Predicate> bool 
# 197
is_partitioned(const detail::execution_policy_base< DerivedPolicy>  &exec, InputIterator 
# 198
first, InputIterator 
# 199
last, Predicate 
# 200
pred) 
# 201
{ 
# 202
using system::detail::generic::is_partitioned;
# 203
return is_partitioned(detail::derived_cast(detail::strip_const(exec)), first, last, pred); 
# 204
} 
# 207
template< class ForwardIterator, class 
# 208
Predicate> ForwardIterator 
# 209
partition(ForwardIterator first, ForwardIterator 
# 210
last, Predicate 
# 211
pred) 
# 212
{ 
# 213
using thrust::system::detail::generic::select_system;
# 215
typedef typename iterator_system< ForwardIterator> ::type System; 
# 217
System system; 
# 219
return thrust::partition(select_system(system), first, last, pred); 
# 220
} 
# 223
template< class ForwardIterator, class 
# 224
InputIterator, class 
# 225
Predicate> ForwardIterator 
# 226
partition(ForwardIterator first, ForwardIterator 
# 227
last, InputIterator 
# 228
stencil, Predicate 
# 229
pred) 
# 230
{ 
# 231
using system::detail::generic::select_system;
# 233
typedef typename iterator_system< ForwardIterator> ::type System1; 
# 234
typedef typename iterator_system< InputIterator> ::type System2; 
# 236
System1 system1; 
# 237
System2 system2; 
# 239
return thrust::partition(select_system(system1, system2), first, last, stencil, pred); 
# 240
} 
# 243
template< class ForwardIterator, class 
# 244
Predicate> ForwardIterator 
# 245
stable_partition(ForwardIterator first, ForwardIterator 
# 246
last, Predicate 
# 247
pred) 
# 248
{ 
# 249
using thrust::system::detail::generic::select_system;
# 251
typedef typename iterator_system< ForwardIterator> ::type System; 
# 253
System system; 
# 255
return thrust::stable_partition(select_system(system), first, last, pred); 
# 256
} 
# 259
template< class ForwardIterator, class 
# 260
InputIterator, class 
# 261
Predicate> ForwardIterator 
# 262
stable_partition(ForwardIterator first, ForwardIterator 
# 263
last, InputIterator 
# 264
stencil, Predicate 
# 265
pred) 
# 266
{ 
# 267
using system::detail::generic::select_system;
# 269
typedef typename iterator_system< ForwardIterator> ::type System1; 
# 270
typedef typename iterator_system< InputIterator> ::type System2; 
# 272
System1 system1; 
# 273
System2 system2; 
# 275
return thrust::stable_partition(select_system(system1, system2), first, last, stencil, pred); 
# 276
} 
# 279
template< class InputIterator, class 
# 280
OutputIterator1, class 
# 281
OutputIterator2, class 
# 282
Predicate> pair< OutputIterator1, OutputIterator2>  
# 284
partition_copy(InputIterator first, InputIterator 
# 285
last, OutputIterator1 
# 286
out_true, OutputIterator2 
# 287
out_false, Predicate 
# 288
pred) 
# 289
{ 
# 290
using system::detail::generic::select_system;
# 292
typedef typename iterator_system< InputIterator> ::type System1; 
# 293
typedef typename iterator_system< OutputIterator1> ::type System2; 
# 294
typedef typename iterator_system< OutputIterator2> ::type System3; 
# 296
System1 system1; 
# 297
System2 system2; 
# 298
System3 system3; 
# 300
return thrust::partition_copy(select_system(system1, system2, system3), first, last, out_true, out_false, pred); 
# 301
} 
# 304
template< class InputIterator1, class 
# 305
InputIterator2, class 
# 306
OutputIterator1, class 
# 307
OutputIterator2, class 
# 308
Predicate> pair< OutputIterator1, OutputIterator2>  
# 310
partition_copy(InputIterator1 first, InputIterator1 
# 311
last, InputIterator2 
# 312
stencil, OutputIterator1 
# 313
out_true, OutputIterator2 
# 314
out_false, Predicate 
# 315
pred) 
# 316
{ 
# 317
using system::detail::generic::select_system;
# 319
typedef typename iterator_system< InputIterator1> ::type System1; 
# 320
typedef typename iterator_system< InputIterator1> ::type System2; 
# 321
typedef typename iterator_system< OutputIterator1> ::type System3; 
# 322
typedef typename iterator_system< OutputIterator2> ::type System4; 
# 324
System1 system1; 
# 325
System2 system2; 
# 326
System3 system3; 
# 327
System4 system4; 
# 329
return thrust::partition_copy(select_system(system1, system2, system3, system4), first, last, stencil, out_true, out_false, pred); 
# 330
} 
# 333
template< class InputIterator, class 
# 334
OutputIterator1, class 
# 335
OutputIterator2, class 
# 336
Predicate> pair< OutputIterator1, OutputIterator2>  
# 338
stable_partition_copy(InputIterator first, InputIterator 
# 339
last, OutputIterator1 
# 340
out_true, OutputIterator2 
# 341
out_false, Predicate 
# 342
pred) 
# 343
{ 
# 344
using system::detail::generic::select_system;
# 346
typedef typename iterator_system< InputIterator> ::type System1; 
# 347
typedef typename iterator_system< OutputIterator1> ::type System2; 
# 348
typedef typename iterator_system< OutputIterator2> ::type System3; 
# 350
System1 system1; 
# 351
System2 system2; 
# 352
System3 system3; 
# 354
return thrust::stable_partition_copy(select_system(system1, system2, system3), first, last, out_true, out_false, pred); 
# 355
} 
# 358
template< class InputIterator1, class 
# 359
InputIterator2, class 
# 360
OutputIterator1, class 
# 361
OutputIterator2, class 
# 362
Predicate> pair< OutputIterator1, OutputIterator2>  
# 364
stable_partition_copy(InputIterator1 first, InputIterator1 
# 365
last, InputIterator2 
# 366
stencil, OutputIterator1 
# 367
out_true, OutputIterator2 
# 368
out_false, Predicate 
# 369
pred) 
# 370
{ 
# 371
using system::detail::generic::select_system;
# 373
typedef typename iterator_system< InputIterator1> ::type System1; 
# 374
typedef typename iterator_system< InputIterator2> ::type System2; 
# 375
typedef typename iterator_system< OutputIterator1> ::type System3; 
# 376
typedef typename iterator_system< OutputIterator2> ::type System4; 
# 378
System1 system1; 
# 379
System2 system2; 
# 380
System3 system3; 
# 381
System4 system4; 
# 383
return thrust::stable_partition_copy(select_system(system1, system2, system3, system4), first, last, stencil, out_true, out_false, pred); 
# 384
} 
# 387
template< class ForwardIterator, class Predicate> ForwardIterator 
# 388
partition_point(ForwardIterator first, ForwardIterator 
# 389
last, Predicate 
# 390
pred) 
# 391
{ 
# 392
using thrust::system::detail::generic::select_system;
# 394
typedef typename iterator_system< ForwardIterator> ::type System; 
# 396
System system; 
# 398
return thrust::partition_point(select_system(system), first, last, pred); 
# 399
} 
# 402
template< class InputIterator, class Predicate> bool 
# 403
is_partitioned(InputIterator first, InputIterator 
# 404
last, Predicate 
# 405
pred) 
# 406
{ 
# 407
using thrust::system::detail::generic::select_system;
# 409
typedef typename iterator_system< InputIterator> ::type System; 
# 411
System system; 
# 413
return thrust::is_partitioned(select_system(system), first, last, pred); 
# 414
} 
# 417
}
# 27 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/detail/stable_primitive_sort.inl"
namespace thrust { 
# 29
namespace system { 
# 31
namespace cuda { 
# 33
namespace detail { 
# 35
namespace detail { 
# 37
namespace stable_primitive_sort_detail { 
# 41
template< class Iterator> 
# 42
struct enable_if_bool_sort : public thrust::detail::enable_if< thrust::detail::is_same< bool, typename iterator_value< Iterator> ::type> ::value>  { 
# 49
}; 
# 52
template< class Iterator> 
# 53
struct disable_if_bool_sort : public thrust::detail::disable_if< thrust::detail::is_same< bool, typename iterator_value< Iterator> ::type> ::value>  { 
# 60
}; 
# 63
template< class DerivedPolicy, class 
# 64
RandomAccessIterator> typename enable_if_bool_sort< RandomAccessIterator> ::type 
# 67
stable_primitive_sort(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator 
# 68
first, RandomAccessIterator 
# 69
last, less< typename iterator_value< RandomAccessIterator> ::type> ) 
# 71
{ 
# 74
thrust::stable_partition(exec, first, last, logical_not< bool> ()); 
# 75
} 
# 78
template< class DerivedPolicy, class 
# 79
RandomAccessIterator> typename enable_if_bool_sort< RandomAccessIterator> ::type 
# 82
stable_primitive_sort(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator 
# 83
first, RandomAccessIterator 
# 84
last, greater< typename iterator_value< RandomAccessIterator> ::type> ) 
# 86
{ 
# 89
thrust::stable_partition(exec, first, last, identity< bool> ()); 
# 90
} 
# 93
template< class DerivedPolicy, class 
# 94
RandomAccessIterator, class 
# 95
Compare> typename disable_if_bool_sort< RandomAccessIterator> ::type 
# 98
stable_primitive_sort(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator 
# 99
first, RandomAccessIterator 
# 100
last, Compare 
# 101
comp) 
# 102
{ 
# 104
detail::stable_radix_sort(exec, first, last, comp); 
# 105
} 
# 108
struct logical_not_first { 
# 110
template< class Tuple> bool 
# 112
operator()(Tuple t) 
# 113
{ 
# 114
return !thrust::get< 0> (t); 
# 115
} 
# 116
}; 
# 119
template< class DerivedPolicy, class 
# 120
RandomAccessIterator1, class 
# 121
RandomAccessIterator2> typename enable_if_bool_sort< RandomAccessIterator1> ::type 
# 124
stable_primitive_sort_by_key(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator1 
# 125
keys_first, RandomAccessIterator1 
# 126
keys_last, RandomAccessIterator2 
# 127
values_first, less< typename iterator_value< RandomAccessIterator1> ::type> ) 
# 129
{ 
# 132
thrust::stable_partition(exec, thrust::make_zip_iterator(thrust::make_tuple(keys_first, values_first)), thrust::make_zip_iterator(thrust::make_tuple(keys_last, values_first)), logical_not_first()); 
# 136
} 
# 139
struct first_tuple_element { 
# 141
template< class Tuple> bool 
# 143
operator()(Tuple t) 
# 144
{ 
# 145
return thrust::get< 0> (t); 
# 146
} 
# 147
}; 
# 150
template< class DerivedPolicy, class 
# 151
RandomAccessIterator1, class 
# 152
RandomAccessIterator2> typename enable_if_bool_sort< RandomAccessIterator1> ::type 
# 155
stable_primitive_sort_by_key(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator1 
# 156
keys_first, RandomAccessIterator1 
# 157
keys_last, RandomAccessIterator2 
# 158
values_first, greater< typename iterator_value< RandomAccessIterator1> ::type> ) 
# 160
{ 
# 164
thrust::stable_partition(exec, thrust::make_zip_iterator(thrust::make_tuple(keys_first, values_first)), thrust::make_zip_iterator(thrust::make_tuple(keys_last, values_first)), first_tuple_element()); 
# 168
} 
# 171
template< class DerivedPolicy, class 
# 172
RandomAccessIterator1, class 
# 173
RandomAccessIterator2, class 
# 174
Compare> typename disable_if_bool_sort< RandomAccessIterator1> ::type 
# 177
stable_primitive_sort_by_key(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator1 
# 178
keys_first, RandomAccessIterator1 
# 179
keys_last, RandomAccessIterator2 
# 180
values_first, Compare 
# 181
comp) 
# 182
{ 
# 184
detail::stable_radix_sort_by_key(exec, keys_first, keys_last, values_first, comp); 
# 185
} 
# 188
}
# 191
template< class DerivedPolicy, class 
# 192
RandomAccessIterator> void 
# 194
stable_primitive_sort(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator 
# 195
first, RandomAccessIterator 
# 196
last, less< typename iterator_value< RandomAccessIterator> ::type>  
# 197
comp) 
# 198
{ 
# 199
stable_primitive_sort_detail::stable_primitive_sort(exec, first, last, comp); 
# 200
} 
# 203
template< class DerivedPolicy, class 
# 204
RandomAccessIterator> void 
# 206
stable_primitive_sort(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator 
# 207
first, RandomAccessIterator 
# 208
last, greater< typename iterator_value< RandomAccessIterator> ::type>  
# 209
comp) 
# 210
{ 
# 211
stable_primitive_sort_detail::stable_primitive_sort(exec, first, last, comp); 
# 212
} 
# 215
template< class DerivedPolicy, class 
# 216
RandomAccessIterator1, class 
# 217
RandomAccessIterator2> void 
# 219
stable_primitive_sort_by_key(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator1 
# 220
keys_first, RandomAccessIterator1 
# 221
keys_last, RandomAccessIterator2 
# 222
values_first, less< typename iterator_value< RandomAccessIterator1> ::type>  
# 223
comp) 
# 224
{ 
# 225
stable_primitive_sort_detail::stable_primitive_sort_by_key(exec, keys_first, keys_last, values_first, comp); 
# 226
} 
# 229
template< class DerivedPolicy, class 
# 230
RandomAccessIterator1, class 
# 231
RandomAccessIterator2> void 
# 233
stable_primitive_sort_by_key(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator1 
# 234
keys_first, RandomAccessIterator1 
# 235
keys_last, RandomAccessIterator2 
# 236
values_first, greater< typename iterator_value< RandomAccessIterator1> ::type>  
# 237
comp) 
# 238
{ 
# 239
stable_primitive_sort_detail::stable_primitive_sort_by_key(exec, keys_first, keys_last, values_first, comp); 
# 240
} 
# 243
}
# 244
}
# 245
}
# 246
}
# 247
}
# 31 "/usr/local/cuda-8.0/include/thrust/detail/trivial_sequence.h"
namespace thrust { 
# 34
namespace detail { 
# 38
template< class Iterator, class DerivedPolicy, class is_trivial> struct _trivial_sequence { }; 
# 41
template< class Iterator, class DerivedPolicy> 
# 42
struct _trivial_sequence< Iterator, DerivedPolicy, integral_constant< bool, true> >  { 
# 44
typedef Iterator iterator_type; 
# 45
Iterator first, last; 
# 48
_trivial_sequence(execution_policy< DerivedPolicy>  &, Iterator _first, Iterator _last) : first(_first), last(_last) 
# 49
{ 
# 51
} 
# 54
iterator_type begin() { return first; } 
# 57
iterator_type end() { return last; } 
# 58
}; 
# 61
template< class Iterator, class DerivedPolicy> 
# 62
struct _trivial_sequence< Iterator, DerivedPolicy, integral_constant< bool, false> >  { 
# 64
typedef typename thrust::iterator_value< Iterator> ::type iterator_value; 
# 65
typedef typename temporary_array< typename thrust::iterator_value< Iterator> ::type, DerivedPolicy> ::iterator iterator_type; 
# 67
temporary_array< typename thrust::iterator_value< Iterator> ::type, DerivedPolicy>  buffer; 
# 70
_trivial_sequence(execution_policy< DerivedPolicy>  &exec, Iterator first, Iterator last) : buffer(exec, first, last) 
# 72
{ 
# 74
} 
# 77
iterator_type begin() { return ((buffer).begin()); } 
# 80
iterator_type end() { return ((buffer).end()); } 
# 81
}; 
# 83
template< class Iterator, class DerivedPolicy> 
# 84
struct trivial_sequence : public _trivial_sequence< Iterator, DerivedPolicy, typename is_trivial_iterator< Iterator> ::type>  { 
# 87
typedef ::thrust::detail::_trivial_sequence< Iterator, DerivedPolicy, typename is_trivial_iterator< Iterator> ::type>  super_t; 
# 90
trivial_sequence(execution_policy< DerivedPolicy>  &exec, Iterator first, Iterator last) : super_t(exec, first, last) { } 
# 91
}; 
# 93
}
# 95
}
# 56 "/usr/local/cuda-8.0/include/thrust/system/cuda/detail/sort.inl"
namespace thrust { 
# 58
namespace system { 
# 60
namespace cuda { 
# 62
namespace detail { 
# 64
namespace stable_sort_detail { 
# 68
template< class KeyType, class StrictWeakCompare> 
# 69
struct can_use_primitive_sort : public thrust::detail::and_< thrust::detail::is_arithmetic< KeyType> , thrust::detail::or_< thrust::detail::is_same< StrictWeakCompare, less< KeyType> > , thrust::detail::is_same< StrictWeakCompare, greater< KeyType> > > >  { 
# 77
}; 
# 80
template< class RandomAccessIterator, class StrictWeakCompare> 
# 81
struct enable_if_primitive_sort : public thrust::detail::enable_if< can_use_primitive_sort< typename iterator_value< RandomAccessIterator> ::type, StrictWeakCompare> ::value>  { 
# 88
}; 
# 91
template< class RandomAccessIterator, class StrictWeakCompare> 
# 92
struct enable_if_comparison_sort : public thrust::detail::disable_if< can_use_primitive_sort< typename iterator_value< RandomAccessIterator> ::type, StrictWeakCompare> ::value>  { 
# 99
}; 
# 102
template< class DerivedPolicy, class 
# 103
RandomAccessIterator, class 
# 104
StrictWeakOrdering> typename enable_if_primitive_sort< RandomAccessIterator, StrictWeakOrdering> ::type 
# 107
stable_sort(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator 
# 108
first, RandomAccessIterator 
# 109
last, StrictWeakOrdering 
# 110
comp) 
# 111
{ 
# 113
thrust::detail::trivial_sequence< RandomAccessIterator, DerivedPolicy>  keys(exec, first, last); 
# 115
detail::stable_primitive_sort(exec, (keys.begin()), (keys.end()), comp); 
# 118
if (!thrust::detail::is_trivial_iterator< RandomAccessIterator> ::value) 
# 119
{ 
# 120
thrust::copy(exec, (keys.begin()), (keys.end()), first); 
# 121
}  
# 122
} 
# 125
template< class DerivedPolicy, class 
# 126
RandomAccessIterator, class 
# 127
StrictWeakOrdering> typename enable_if_comparison_sort< RandomAccessIterator, StrictWeakOrdering> ::type 
# 130
stable_sort(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator 
# 131
first, RandomAccessIterator 
# 132
last, StrictWeakOrdering 
# 133
comp) 
# 134
{ 
# 135
detail::stable_merge_sort(exec, first, last, comp); 
# 136
} 
# 139
template< class DerivedPolicy, class 
# 140
RandomAccessIterator1, class 
# 141
RandomAccessIterator2, class 
# 142
StrictWeakOrdering> typename enable_if_primitive_sort< RandomAccessIterator1, StrictWeakOrdering> ::type 
# 145
stable_sort_by_key(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator1 
# 146
keys_first, RandomAccessIterator1 
# 147
keys_last, RandomAccessIterator2 
# 148
values_first, StrictWeakOrdering 
# 149
comp) 
# 150
{ 
# 152
thrust::detail::trivial_sequence< RandomAccessIterator1, DerivedPolicy>  keys(exec, keys_first, keys_last); 
# 153
thrust::detail::trivial_sequence< RandomAccessIterator2, DerivedPolicy>  values(exec, values_first, values_first + (keys_last - keys_first)); 
# 155
detail::stable_primitive_sort_by_key(exec, (keys.begin()), (keys.end()), (values.begin()), comp); 
# 158
if (!thrust::detail::is_trivial_iterator< RandomAccessIterator1> ::value) 
# 159
{ 
# 160
thrust::copy(exec, (keys.begin()), (keys.end()), keys_first); 
# 161
}  
# 163
if (!thrust::detail::is_trivial_iterator< RandomAccessIterator2> ::value) 
# 164
{ 
# 165
thrust::copy(exec, (values.begin()), (values.end()), values_first); 
# 166
}  
# 167
} 
# 170
template< class DerivedPolicy, class 
# 171
RandomAccessIterator1, class 
# 172
RandomAccessIterator2, class 
# 173
StrictWeakOrdering> typename enable_if_comparison_sort< RandomAccessIterator1, StrictWeakOrdering> ::type 
# 176
stable_sort_by_key(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator1 
# 177
keys_first, RandomAccessIterator1 
# 178
keys_last, RandomAccessIterator2 
# 179
values_first, StrictWeakOrdering 
# 180
comp) 
# 181
{ 
# 182
detail::stable_merge_sort_by_key(exec, keys_first, keys_last, values_first, comp); 
# 183
} 
# 186
}
# 189
template< class DerivedPolicy, class 
# 190
RandomAccessIterator, class 
# 191
StrictWeakOrdering> void 
# 193
stable_sort(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator 
# 194
first, RandomAccessIterator 
# 195
last, StrictWeakOrdering 
# 196
comp) 
# 197
{ 
# 203
typedef thrust::detail::static_assert_test< sizeof(thrust::detail::STATIC_ASSERTION_FAILURE< (bool)(thrust::detail::depend_on_instantiation< RandomAccessIterator, true> ::value)> )>  thrust_static_assert_typedef_203 __attribute((unused)); 
# 205
struct workaround { 
# 208
static void parallel_path(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator 
# 209
first, RandomAccessIterator 
# 210
last, StrictWeakOrdering 
# 211
comp) 
# 212
{ 
# 213
stable_sort_detail::stable_sort(exec, first, last, comp); 
# 214
} 
# 217
static void sequential_path(RandomAccessIterator first, RandomAccessIterator 
# 218
last, StrictWeakOrdering 
# 219
comp) 
# 220
{ 
# 221
thrust::sort(thrust::seq, first, last, comp); 
# 222
} 
# 223
}; 
# 226
(workaround::parallel_path)(exec, first, last, comp); 
# 230
} 
# 233
template< class DerivedPolicy, class 
# 234
RandomAccessIterator1, class 
# 235
RandomAccessIterator2, class 
# 236
StrictWeakOrdering> void 
# 238
stable_sort_by_key(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator1 
# 239
keys_first, RandomAccessIterator1 
# 240
keys_last, RandomAccessIterator2 
# 241
values_first, StrictWeakOrdering 
# 242
comp) 
# 243
{ 
# 249
typedef thrust::detail::static_assert_test< sizeof(thrust::detail::STATIC_ASSERTION_FAILURE< (bool)(thrust::detail::depend_on_instantiation< RandomAccessIterator1, true> ::value)> )>  thrust_static_assert_typedef_249 __attribute((unused)); 
# 251
struct workaround { 
# 254
static void parallel_path(execution_policy< DerivedPolicy>  &exec, RandomAccessIterator1 
# 255
keys_first, RandomAccessIterator1 
# 256
keys_last, RandomAccessIterator2 
# 257
values_first, StrictWeakOrdering 
# 258
comp) 
# 259
{ 
# 260
stable_sort_detail::stable_sort_by_key(exec, keys_first, keys_last, values_first, comp); 
# 261
} 
# 264
static void sequential_path(RandomAccessIterator1 keys_first, RandomAccessIterator1 
# 265
keys_last, RandomAccessIterator2 
# 266
values_first, StrictWeakOrdering 
# 267
comp) 
# 268
{ 
# 269
thrust::stable_sort_by_key(thrust::seq, keys_first, keys_last, values_first, comp); 
# 270
} 
# 271
}; 
# 274
(workaround::parallel_path)(exec, keys_first, keys_last, values_first, comp); 
# 278
} 
# 281
}
# 282
}
# 283
}
# 284
}
# 29 "/usr/local/cuda-8.0/include/thrust/detail/sort.inl"
namespace thrust { 
# 34
template< class DerivedPolicy, class RandomAccessIterator> void 
# 36
sort(const detail::execution_policy_base< DerivedPolicy>  &exec, RandomAccessIterator 
# 37
first, RandomAccessIterator 
# 38
last) 
# 39
{ 
# 40
using system::detail::generic::sort;
# 41
return sort(detail::derived_cast(detail::strip_const(exec)), first, last); 
# 42
} 
# 46
template< class DerivedPolicy, class 
# 47
RandomAccessIterator, class 
# 48
StrictWeakOrdering> void 
# 50
sort(const detail::execution_policy_base< DerivedPolicy>  &exec, RandomAccessIterator 
# 51
first, RandomAccessIterator 
# 52
last, StrictWeakOrdering 
# 53
comp) 
# 54
{ 
# 55
using system::detail::generic::sort;
# 56
return sort(detail::derived_cast(detail::strip_const(exec)), first, last, comp); 
# 57
} 
# 61
template< class DerivedPolicy, class RandomAccessIterator> void 
# 63
stable_sort(const detail::execution_policy_base< DerivedPolicy>  &exec, RandomAccessIterator 
# 64
first, RandomAccessIterator 
# 65
last) 
# 66
{ 
# 67
using system::detail::generic::stable_sort;
# 68
return stable_sort(detail::derived_cast(detail::strip_const(exec)), first, last); 
# 69
} 
# 73
template< class DerivedPolicy, class 
# 74
RandomAccessIterator, class 
# 75
StrictWeakOrdering> void 
# 77
stable_sort(const detail::execution_policy_base< DerivedPolicy>  &exec, RandomAccessIterator 
# 78
first, RandomAccessIterator 
# 79
last, StrictWeakOrdering 
# 80
comp) 
# 81
{ 
# 82
using system::detail::generic::stable_sort;
# 83
return stable_sort(detail::derived_cast(detail::strip_const(exec)), first, last, comp); 
# 84
} 
# 88
template< class DerivedPolicy, class 
# 89
RandomAccessIterator1, class 
# 90
RandomAccessIterator2> void 
# 92
sort_by_key(const detail::execution_policy_base< DerivedPolicy>  &exec, RandomAccessIterator1 
# 93
keys_first, RandomAccessIterator1 
# 94
keys_last, RandomAccessIterator2 
# 95
values_first) 
# 96
{ 
# 97
using system::detail::generic::sort_by_key;
# 98
return sort_by_key(detail::derived_cast(detail::strip_const(exec)), keys_first, keys_last, values_first); 
# 99
} 
# 103
template< class DerivedPolicy, class 
# 104
RandomAccessIterator1, class 
# 105
RandomAccessIterator2, class 
# 106
StrictWeakOrdering> void 
# 108
sort_by_key(const detail::execution_policy_base< DerivedPolicy>  &exec, RandomAccessIterator1 
# 109
keys_first, RandomAccessIterator1 
# 110
keys_last, RandomAccessIterator2 
# 111
values_first, StrictWeakOrdering 
# 112
comp) 
# 113
{ 
# 114
using system::detail::generic::sort_by_key;
# 115
return sort_by_key(detail::derived_cast(detail::strip_const(exec)), keys_first, keys_last, values_first, comp); 
# 116
} 
# 120
template< class DerivedPolicy, class 
# 121
RandomAccessIterator1, class 
# 122
RandomAccessIterator2> void 
# 124
stable_sort_by_key(const detail::execution_policy_base< DerivedPolicy>  &exec, RandomAccessIterator1 
# 125
keys_first, RandomAccessIterator1 
# 126
keys_last, RandomAccessIterator2 
# 127
values_first) 
# 128
{ 
# 129
using system::detail::generic::stable_sort_by_key;
# 130
return stable_sort_by_key(detail::derived_cast(detail::strip_const(exec)), keys_first, keys_last, values_first); 
# 131
} 
# 135
template< class DerivedPolicy, class 
# 136
RandomAccessIterator1, class 
# 137
RandomAccessIterator2, class 
# 138
StrictWeakOrdering> void 
# 140
stable_sort_by_key(const detail::execution_policy_base< DerivedPolicy>  &exec, RandomAccessIterator1 
# 141
keys_first, RandomAccessIterator1 
# 142
keys_last, RandomAccessIterator2 
# 143
values_first, StrictWeakOrdering 
# 144
comp) 
# 145
{ 
# 146
using system::detail::generic::stable_sort_by_key;
# 147
return stable_sort_by_key(detail::derived_cast(detail::strip_const(exec)), keys_first, keys_last, values_first, comp); 
# 148
} 
# 152
template< class DerivedPolicy, class ForwardIterator> bool 
# 154
is_sorted(const detail::execution_policy_base< DerivedPolicy>  &exec, ForwardIterator 
# 155
first, ForwardIterator 
# 156
last) 
# 157
{ 
# 158
using system::detail::generic::is_sorted;
# 159
return is_sorted(detail::derived_cast(detail::strip_const(exec)), first, last); 
# 160
} 
# 164
template< class DerivedPolicy, class ForwardIterator, class Compare> bool 
# 166
is_sorted(const detail::execution_policy_base< DerivedPolicy>  &exec, ForwardIterator 
# 167
first, ForwardIterator 
# 168
last, Compare 
# 169
comp) 
# 170
{ 
# 171
using system::detail::generic::is_sorted;
# 172
return is_sorted(detail::derived_cast(detail::strip_const(exec)), first, last, comp); 
# 173
} 
# 177
template< class DerivedPolicy, class ForwardIterator> ForwardIterator 
# 179
is_sorted_until(const detail::execution_policy_base< DerivedPolicy>  &exec, ForwardIterator 
# 180
first, ForwardIterator 
# 181
last) 
# 182
{ 
# 183
using system::detail::generic::is_sorted_until;
# 184
return is_sorted_until(detail::derived_cast(detail::strip_const(exec)), first, last); 
# 185
} 
# 189
template< class DerivedPolicy, class ForwardIterator, class Compare> ForwardIterator 
# 191
is_sorted_until(const detail::execution_policy_base< DerivedPolicy>  &exec, ForwardIterator 
# 192
first, ForwardIterator 
# 193
last, Compare 
# 194
comp) 
# 195
{ 
# 196
using system::detail::generic::is_sorted_until;
# 197
return is_sorted_until(detail::derived_cast(detail::strip_const(exec)), first, last, comp); 
# 198
} 
# 205
template< class RandomAccessIterator> void 
# 206
sort(RandomAccessIterator first, RandomAccessIterator 
# 207
last) 
# 208
{ 
# 209
using thrust::system::detail::generic::select_system;
# 211
typedef typename iterator_system< RandomAccessIterator> ::type System; 
# 213
System system; 
# 215
return thrust::sort(select_system(system), first, last); 
# 216
} 
# 219
template< class RandomAccessIterator, class 
# 220
StrictWeakOrdering> void 
# 221
sort(RandomAccessIterator first, RandomAccessIterator 
# 222
last, StrictWeakOrdering 
# 223
comp) 
# 224
{ 
# 225
using thrust::system::detail::generic::select_system;
# 227
typedef typename iterator_system< RandomAccessIterator> ::type System; 
# 229
System system; 
# 231
return thrust::sort(select_system(system), first, last, comp); 
# 232
} 
# 235
template< class RandomAccessIterator> void 
# 236
stable_sort(RandomAccessIterator first, RandomAccessIterator 
# 237
last) 
# 238
{ 
# 239
using thrust::system::detail::generic::select_system;
# 241
typedef typename iterator_system< RandomAccessIterator> ::type System; 
# 243
System system; 
# 245
return thrust::stable_sort(select_system(system), first, last); 
# 246
} 
# 249
template< class RandomAccessIterator, class 
# 250
StrictWeakOrdering> void 
# 251
stable_sort(RandomAccessIterator first, RandomAccessIterator 
# 252
last, StrictWeakOrdering 
# 253
comp) 
# 254
{ 
# 255
using thrust::system::detail::generic::select_system;
# 257
typedef typename iterator_system< RandomAccessIterator> ::type System; 
# 259
System system; 
# 261
return thrust::stable_sort(select_system(system), first, last, comp); 
# 262
} 
# 270
template< class RandomAccessIterator1, class 
# 271
RandomAccessIterator2> void 
# 272
sort_by_key(RandomAccessIterator1 keys_first, RandomAccessIterator1 
# 273
keys_last, RandomAccessIterator2 
# 274
values_first) 
# 275
{ 
# 276
using system::detail::generic::select_system;
# 278
typedef typename iterator_system< RandomAccessIterator1> ::type System1; 
# 279
typedef typename iterator_system< RandomAccessIterator2> ::type System2; 
# 281
System1 system1; 
# 282
System2 system2; 
# 284
return thrust::sort_by_key(select_system(system1, system2), keys_first, keys_last, values_first); 
# 285
} 
# 288
template< class RandomAccessIterator1, class 
# 289
RandomAccessIterator2, class 
# 290
StrictWeakOrdering> void 
# 291
sort_by_key(RandomAccessIterator1 keys_first, RandomAccessIterator1 
# 292
keys_last, RandomAccessIterator2 
# 293
values_first, StrictWeakOrdering 
# 294
comp) 
# 295
{ 
# 296
using system::detail::generic::select_system;
# 298
typedef typename iterator_system< RandomAccessIterator1> ::type System1; 
# 299
typedef typename iterator_system< RandomAccessIterator2> ::type System2; 
# 301
System1 system1; 
# 302
System2 system2; 
# 304
return thrust::sort_by_key(select_system(system1, system2), keys_first, keys_last, values_first, comp); 
# 305
} 
# 308
template< class RandomAccessIterator1, class 
# 309
RandomAccessIterator2> void 
# 310
stable_sort_by_key(RandomAccessIterator1 keys_first, RandomAccessIterator1 
# 311
keys_last, RandomAccessIterator2 
# 312
values_first) 
# 313
{ 
# 314
using system::detail::generic::select_system;
# 316
typedef typename iterator_system< RandomAccessIterator1> ::type System1; 
# 317
typedef typename iterator_system< RandomAccessIterator2> ::type System2; 
# 319
System1 system1; 
# 320
System2 system2; 
# 322
return thrust::stable_sort_by_key(select_system(system1, system2), keys_first, keys_last, values_first); 
# 323
} 
# 326
template< class RandomAccessIterator1, class 
# 327
RandomAccessIterator2, class 
# 328
StrictWeakOrdering> void 
# 329
stable_sort_by_key(RandomAccessIterator1 keys_first, RandomAccessIterator1 
# 330
keys_last, RandomAccessIterator2 
# 331
values_first, StrictWeakOrdering 
# 332
comp) 
# 333
{ 
# 334
using system::detail::generic::select_system;
# 336
typedef typename iterator_system< RandomAccessIterator1> ::type System1; 
# 337
typedef typename iterator_system< RandomAccessIterator2> ::type System2; 
# 339
System1 system1; 
# 340
System2 system2; 
# 342
return thrust::stable_sort_by_key(select_system(system1, system2), keys_first, keys_last, values_first, comp); 
# 343
} 
# 346
template< class ForwardIterator> bool 
# 347
is_sorted(ForwardIterator first, ForwardIterator 
# 348
last) 
# 349
{ 
# 350
using thrust::system::detail::generic::select_system;
# 352
typedef typename iterator_system< ForwardIterator> ::type System; 
# 354
System system; 
# 356
return thrust::is_sorted(select_system(system), first, last); 
# 357
} 
# 360
template< class ForwardIterator, class 
# 361
Compare> bool 
# 362
is_sorted(ForwardIterator first, ForwardIterator 
# 363
last, Compare 
# 364
comp) 
# 365
{ 
# 366
using thrust::system::detail::generic::select_system;
# 368
typedef typename iterator_system< ForwardIterator> ::type System; 
# 370
System system; 
# 372
return thrust::is_sorted(select_system(system), first, last, comp); 
# 373
} 
# 376
template< class ForwardIterator> ForwardIterator 
# 377
is_sorted_until(ForwardIterator first, ForwardIterator 
# 378
last) 
# 379
{ 
# 380
using thrust::system::detail::generic::select_system;
# 382
typedef typename iterator_system< ForwardIterator> ::type System; 
# 384
System system; 
# 386
return thrust::is_sorted_until(select_system(system), first, last); 
# 387
} 
# 390
template< class ForwardIterator, class 
# 391
Compare> ForwardIterator 
# 392
is_sorted_until(ForwardIterator first, ForwardIterator 
# 393
last, Compare 
# 394
comp) 
# 395
{ 
# 396
using thrust::system::detail::generic::select_system;
# 398
typedef typename iterator_system< ForwardIterator> ::type System; 
# 400
System system; 
# 402
return thrust::is_sorted_until(select_system(system), first, last, comp); 
# 403
} 
# 406
}
# 65 "/usr/include/assert.h" 3
extern "C" {
# 68
extern void __assert_fail(const char * __assertion, const char * __file, unsigned __line, const char * __function) throw()
# 70
 __attribute((__noreturn__)); 
# 73
extern void __assert_perror_fail(int __errnum, const char * __file, unsigned __line, const char * __function) throw()
# 75
 __attribute((__noreturn__)); 
# 80
extern void __assert(const char * __assertion, const char * __file, int __line) throw()
# 81
 __attribute((__noreturn__)); 
# 84
}
# 13 "./gpu_bin_shift.cu"
static int d_start_shift[3]; 
# 15
__attribute__((unused)) static inline void init_shift_bounds(int mi) 
# 16
{int volatile ___ = 1;(void)mi;
# 20
::exit(___);}
#if 0
# 16
{ 
# 17
((d_start_shift)[0]) = mi; 
# 18
((d_start_shift)[1]) = mi; 
# 19
((d_start_shift)[2]) = mi; 
# 20
} 
#endif
# 24 "./gpu_bin_shift.cu"
static void calculate_sort_keypair(gtc_particle_data_t *zion, int *seq, int *psi_theta) ;
#if 0
# 25
{ 
# 26
const int tid = __device_builtin_variable_threadIdx.x; 
# 27
const int bid = __device_builtin_variable_blockIdx.x; 
# 28
const int nthreads = __device_builtin_variable_blockDim.x; 
# 29
const int m = tid + (bid * nthreads); 
# 31
real *z0 = zion->z0; 
# 32
real *z1 = zion->z1; 
# 34
int mi = params.mi; 
# 35
real a0 = params.a0; 
# 36
real delr = params.delr; 
# 37
int mpsi = params.mpsi; 
# 38
real r; 
# 40
if (m < mi) { 
# 41
if (m == 0) { 
# 42
init_shift_bounds(mi); }  
# 44
(seq[m]) = m; 
# 45
real pi2_inv = params.pi2_inv; 
# 46
real psi = z0[m]; 
# 47
real theta = z1[m]; 
# 48
real zetamin = params.zetamin; 
# 49
real zetamax = params.zetamax; 
# 51
real pi2 = (2) * (params.pi); 
# 52
real *zion2 = zion->z2; 
# 53
real zetatmp = zion2[m]; 
# 54
real zetaright = min(pi2, zetatmp) - zetamax; 
# 55
real zetaleft = zetatmp - zetamin; 
# 56
int shift = (zetaright * zetaleft) > (0); 
# 57
zetaright = (zetaright * pi2_inv); 
# 58
zetaright = (zetaright - floor(zetaright)); 
# 59
int right = zetaright < (0.5); 
# 62
r = psi; 
# 67
int iptmp = (int)(((r - a0) * delr) + (0.5)); 
# 68
int ip = d_abs_min_int(mpsi, iptmp); 
# 72
(psi_theta[m]) = (ip + ((shift * (1 + right)) * 268435456)); 
# 76
}  
# 77
} 
#endif
# 79 "./gpu_bin_shift.cu"
static void calculate_sort_keypair_radial(gtc_particle_data_t *zion, int *seq, int *psi_theta) ;
#if 0
# 80
{ 
# 81
const int tid = __device_builtin_variable_threadIdx.x; 
# 82
const int bid = __device_builtin_variable_blockIdx.x; 
# 83
const int nthreads = __device_builtin_variable_blockDim.x; 
# 84
const int m = tid + (bid * nthreads); 
# 85
real *z0 = zion->z0; 
# 86
real *z1 = zion->z1; 
# 88
const real a_nover_in = radial_decomp.a_nover_in; 
# 89
const real a_nover_out = radial_decomp.a_nover_out; 
# 90
const int myrank_radiald = radial_decomp.myrank_radiald; 
# 91
const int nradial_dom = radial_decomp.nradial_dom; 
# 93
int mi = params.mi; 
# 94
real a0 = params.a0; 
# 95
real delr = params.delr; 
# 96
int mpsi = params.mpsi; 
# 97
real r; 
# 99
if (m < mi) { 
# 100
if (m == 0) { 
# 101
init_shift_bounds(mi); }  
# 103
(seq[m]) = m; 
# 104
real pi2_inv = params.pi2_inv; 
# 105
real psi = z0[m]; 
# 106
real theta = z1[m]; 
# 110
real pi2 = (2) * (params.pi); 
# 115
r = psi; 
# 127
int shift = ((r < a_nover_in) && (myrank_radiald > 0)) || ((r > a_nover_out) && (myrank_radiald < (nradial_dom - 1))); 
# 128
int right = (r > a_nover_out) && (myrank_radiald < (nradial_dom - 1)); 
# 130
int iptmp = (int)(((r - a0) * delr) + (0.5)); 
# 131
int ip = d_abs_min_int(mpsi, iptmp); 
# 135
(psi_theta[m]) = (ip + ((shift * (1 + right)) * 268435456)); 
# 139
}  
# 140
} 
#endif
# 142 "./gpu_bin_shift.cu"
static void calculate_sort_keypair_shift(gtc_particle_data_t *zion, int *seq, int *psi_theta) ;
#if 0
# 143
{ 
# 144
const int tid = __device_builtin_variable_threadIdx.x; 
# 145
const int bid = __device_builtin_variable_blockIdx.x; 
# 146
const int nthreads = __device_builtin_variable_blockDim.x; 
# 147
const int m = tid + (bid * nthreads); 
# 148
int mi = params.mi; 
# 150
if (m < mi) { 
# 151
if (m == 0) { 
# 152
init_shift_bounds(mi); }  
# 153
(seq[m]) = m; 
# 154
real pi2_inv = params.pi2_inv; 
# 155
real zetamin = params.zetamin; 
# 156
real zetamax = params.zetamax; 
# 157
real pi2 = (2.0) * (params.pi); 
# 158
real *zion2 = zion->z2; 
# 159
real zetatmp = zion2[m]; 
# 160
real zetaright = min(pi2, zetatmp) - zetamax; 
# 161
real zetaleft = zetatmp - zetamin; 
# 162
int shift = (zetaright * zetaleft) > (0.0); 
# 163
zetaright = (zetaright * pi2_inv); 
# 164
zetaright = (zetaright - floor(zetaright)); 
# 165
int right = zetaright < (0.5); 
# 167
(psi_theta[m]) = ((shift) ? (right) ? 2 : 1 : 0); 
# 169
}  
# 170
} 
#endif
# 172 "./gpu_bin_shift.cu"
static void calculate_sort_keypair_radial_shift(gtc_particle_data_t *zion, int *seq, int *psi_theta) ;
#if 0
# 173
{ 
# 174
const int tid = __device_builtin_variable_threadIdx.x; 
# 175
const int bid = __device_builtin_variable_blockIdx.x; 
# 176
const int nthreads = __device_builtin_variable_blockDim.x; 
# 177
const int m = tid + (bid * nthreads); 
# 179
const real a_nover_in = radial_decomp.a_nover_in; 
# 180
const real a_nover_out = radial_decomp.a_nover_out; 
# 181
const int myrank_radiald = radial_decomp.myrank_radiald; 
# 182
const int nradial_dom = radial_decomp.nradial_dom; 
# 184
int mi = params.mi; 
# 186
if (m < mi) { 
# 187
if (m == 0) { 
# 188
init_shift_bounds(mi); }  
# 189
(seq[m]) = m; 
# 190
real pi2_inv = params.pi2_inv; 
# 191
real zetamin = params.zetamin; 
# 192
real zetamax = params.zetamax; 
# 193
real pi2 = (2) * (params.pi); 
# 195
real *zion0 = zion->z0; 
# 196
real z0 = zion0[m]; 
# 199
real r = z0; 
# 209
int shift = ((r < a_nover_in) && (myrank_radiald > 0)) || ((r > a_nover_out) && (myrank_radiald < (nradial_dom - 1))); 
# 210
int right = (r > a_nover_out) && (myrank_radiald < (nradial_dom - 1)); 
# 212
(psi_theta[m]) = ((shift) ? (right) ? 2 : 1 : 0); 
# 214
}  
# 215
} 
#endif
# 217 "./gpu_bin_shift.cu"
static void permute_particles_zion_ph1(gtc_particle_data_t *d_zion, gtc_particle_data_t *d_auxs_zion, int *permutation, int irk) ;
#if 0
# 217
{ 
# 218
const int tid = __device_builtin_variable_threadIdx.x; 
# 219
const int bid = __device_builtin_variable_blockIdx.x; 
# 220
const int nthreads = __device_builtin_variable_blockDim.x; 
# 221
const int gid = tid + (bid * nthreads); 
# 222
int mi = params.mi; 
# 224
if (gid < mi) { 
# 225
int pos = permutation[gid]; 
# 228
real z0, z1, z2, z3, z4, z00, z01, z02, z03, z04; 
# 229
z0 = TunedTexLoad< double, CA> ::Ld((d_zion->z0) + pos); 
# 230
z1 = TunedTexLoad< double, CA> ::Ld((d_zion->z1) + pos); 
# 231
z2 = TunedTexLoad< double, CA> ::Ld((d_zion->z2) + pos); 
# 232
z3 = TunedTexLoad< double, CA> ::Ld((d_zion->z3) + pos); 
# 233
z4 = TunedTexLoad< double, CA> ::Ld((d_zion->z4) + pos); 
# 235
TunedStore< double, CS> ::St(z0, (d_auxs_zion->z0) + gid); 
# 236
TunedStore< double, CS> ::St(z1, (d_auxs_zion->z1) + gid); 
# 237
TunedStore< double, CS> ::St(z2, (d_auxs_zion->z2) + gid); 
# 238
TunedStore< double, CS> ::St(z3, (d_auxs_zion->z3) + gid); 
# 239
TunedStore< double, CS> ::St(z4, (d_auxs_zion->z4) + gid); 
# 241
if (irk == 1) { 
# 242
z00 = TunedTexLoad< double, CA> ::Ld((d_zion->z00) + pos); 
# 243
z01 = TunedTexLoad< double, CA> ::Ld((d_zion->z01) + pos); 
# 244
z02 = TunedTexLoad< double, CA> ::Ld((d_zion->z02) + pos); 
# 245
z03 = TunedTexLoad< double, CA> ::Ld((d_zion->z03) + pos); 
# 246
z04 = TunedTexLoad< double, CA> ::Ld((d_zion->z04) + pos); 
# 248
TunedStore< double, CS> ::St(z00, (d_auxs_zion->z00) + gid); 
# 249
TunedStore< double, CS> ::St(z01, (d_auxs_zion->z01) + gid); 
# 250
TunedStore< double, CS> ::St(z02, (d_auxs_zion->z02) + gid); 
# 251
TunedStore< double, CS> ::St(z03, (d_auxs_zion->z03) + gid); 
# 252
TunedStore< double, CS> ::St(z04, (d_auxs_zion->z04) + gid); 
# 253
}  
# 269
}  
# 270
} 
#endif
# 272 "./gpu_bin_shift.cu"
static void permute_particles_zion_ph2(gtc_particle_data_t *d_zion, gtc_particle_data_t *d_auxs_zion, int *permutation, int *keys) ;
#if 0
# 272
{ 
# 273
const int tid = __device_builtin_variable_threadIdx.x; 
# 274
const int bid = __device_builtin_variable_blockIdx.x; 
# 275
const int nthreads = __device_builtin_variable_blockDim.x; 
# 276
const int gid = tid + (bid * nthreads); 
# 277
int mi = params.mi; 
# 279
if (gid < mi) { 
# 280
int pos = permutation[gid]; 
# 281
int key_val = keys[gid]; 
# 282
int prev_key_val = (gid > 0) ? keys[gid - 1] : (keys[0]); 
# 284
if ((key_val >= (1 * 268435456)) && (key_val < (2 * 268435456)) && (prev_key_val < (1 * 268435456))) { 
# 285
((d_start_shift)[1]) = gid; }  
# 286
if ((key_val >= (2 * 268435456)) && (prev_key_val < (2 * 268435456))) { 
# 287
((d_start_shift)[2]) = gid; }  
# 290
real z5, z05; 
# 291
z5 = TunedTexLoad< double, CA> ::Ld((d_zion->z5) + pos); 
# 292
z05 = TunedTexLoad< double, CA> ::Ld((d_zion->z05) + pos); 
# 293
TunedStore< double, CS> ::St(z5, (d_auxs_zion->z5) + gid); 
# 294
TunedStore< double, CS> ::St(z05, (d_auxs_zion->z05) + gid); 
# 299
}  
# 300
} 
#endif
# 302 "./gpu_bin_shift.cu"
static void permute_particles_zion_shift_ph2(gtc_particle_data_t *d_zion, gtc_particle_data_t *d_auxs_zion, int *permutation, int *keys) ;
#if 0
# 302
{ 
# 303
const int tid = __device_builtin_variable_threadIdx.x; 
# 304
const int bid = __device_builtin_variable_blockIdx.x; 
# 305
const int nthreads = __device_builtin_variable_blockDim.x; 
# 306
const int gid = tid + (bid * nthreads); 
# 307
int mi = params.mi; 
# 309
if (gid < mi) { 
# 310
int pos = permutation[gid]; 
# 311
int key_val = keys[gid]; 
# 312
int prev_key_val = (gid > 0) ? keys[gid - 1] : (keys[0]); 
# 313
if ((key_val == 1) && (prev_key_val == 0)) { 
# 314
((d_start_shift)[1]) = gid; }  
# 316
if (((key_val == 2) && (prev_key_val == 1)) || ((key_val == 2) && (prev_key_val == 0))) { 
# 318
((d_start_shift)[2]) = gid; }  
# 321
real z5, z05; 
# 322
z5 = TunedTexLoad< double, CA> ::Ld((d_zion->z5) + pos); 
# 323
z05 = TunedTexLoad< double, CA> ::Ld((d_zion->z05) + pos); 
# 324
TunedStore< double, CS> ::St(z5, (d_auxs_zion->z5) + gid); 
# 325
TunedStore< double, CS> ::St(z05, (d_auxs_zion->z05) + gid); 
# 330
}  
# 331
} 
#endif
# 333 "./gpu_bin_shift.cu"
static void update_particle_zion_ph1(gtc_particle_data_t *d_zion, gtc_particle_data_t *d_auxs_zion, int irk) ;
#if 0
# 333
{ 
# 334
const int tid = __device_builtin_variable_threadIdx.x; 
# 335
const int bid = __device_builtin_variable_blockIdx.x; 
# 336
const int nthreads = __device_builtin_variable_blockDim.x; 
# 337
const int gid = tid + (bid * nthreads); 
# 338
int mi = params.mi; 
# 340
if (gid < mi) { 
# 341
((d_zion->z0)[gid]) = ((d_auxs_zion->z0)[gid]); 
# 342
((d_zion->z1)[gid]) = ((d_auxs_zion->z1)[gid]); 
# 343
((d_zion->z2)[gid]) = ((d_auxs_zion->z2)[gid]); 
# 344
((d_zion->z3)[gid]) = ((d_auxs_zion->z3)[gid]); 
# 345
((d_zion->z4)[gid]) = ((d_auxs_zion->z4)[gid]); 
# 347
if (irk == 1) { 
# 348
((d_zion->z00)[gid]) = ((d_auxs_zion->z00)[gid]); 
# 349
((d_zion->z01)[gid]) = ((d_auxs_zion->z01)[gid]); 
# 350
((d_zion->z02)[gid]) = ((d_auxs_zion->z02)[gid]); 
# 351
((d_zion->z03)[gid]) = ((d_auxs_zion->z03)[gid]); 
# 352
((d_zion->z04)[gid]) = ((d_auxs_zion->z04)[gid]); 
# 353
}  
# 354
}  
# 355
} 
#endif
# 357 "./gpu_bin_shift.cu"
static void update_particle_zion_ph2(gtc_particle_data_t *d_zion, gtc_particle_data_t *d_auxs_zion) ;
#if 0
# 357
{ 
# 358
const int tid = __device_builtin_variable_threadIdx.x; 
# 359
const int bid = __device_builtin_variable_blockIdx.x; 
# 360
const int nthreads = __device_builtin_variable_blockDim.x; 
# 361
const int gid = tid + (bid * nthreads); 
# 362
int mi = params.mi; 
# 364
if (gid < mi) { 
# 365
((d_zion->z5)[gid]) = ((d_auxs_zion->z5)[gid]); 
# 366
((d_zion->z05)[gid]) = ((d_auxs_zion->z05)[gid]); 
# 367
}  
# 368
} 
#endif
# 371 "./gpu_bin_shift.cu"
extern "C" void call_gpu_bin_particles_kernel(gtc_bench_data_t *gtc_input, gpu_kernel_args_t *gpu_kernel_input, int shift_direction) 
# 372
{ 
# 373
gpu_timer_start(gpu_kernel_input); 
# 374
int mi = (gtc_input->global_params).mi; 
# 375
int nt = 512; 
# 376
int nb = ((mi + nt) - 1) / nt; 
# 377
int irk = gpu_kernel_input->irk; 
# 378
int istep = gpu_kernel_input->istep; 
# 380
gtc_sort_particle_t *d_sort = &(gpu_kernel_input->d_sort); 
# 384
int shift_only = ((irk != 2) || ((istep % 10) != 0)) || (shift_direction == 1); 
# 388
if (shift_only) { 
# 389
if (shift_direction == 0) { 
# 390
(cudaConfigureCall(nb, nt)) ? (void)0 : (calculate_sort_keypair_shift)(gpu_kernel_input->ptr_d_zion, d_sort->d_value, d_sort->d_sort_key); } else { 
# 391
if (shift_direction == 1) { 
# 392
(cudaConfigureCall(nb, nt)) ? (void)0 : (calculate_sort_keypair_radial_shift)(gpu_kernel_input->ptr_d_zion, d_sort->d_value, d_sort->d_sort_key); } else { 
# 394
printf("other shift_direction options are not available\n"); }  }  } else 
# 395
{ 
# 397
if (shift_direction == 0) { 
# 398
(cudaConfigureCall(nb, nt)) ? (void)0 : (calculate_sort_keypair)(gpu_kernel_input->ptr_d_zion, d_sort->d_value, d_sort->d_sort_key); } else { 
# 399
if (shift_direction == 1) { 
# 400
(cudaConfigureCall(nb, nt)) ? (void)0 : (calculate_sort_keypair_radial)(gpu_kernel_input->ptr_d_zion, d_sort->d_value, d_sort->d_sort_key); } else { 
# 402
printf("other shift_direction options are not available\n"); }  }  
# 404
}  
# 406
thrust::device_ptr< int>  d_key(d_sort->d_sort_key); 
# 407
thrust::device_ptr< int>  d_value(d_sort->d_value); 
# 408
thrust::stable_sort_by_key(d_key, (d_key + mi), d_value); 
# 409
((gpu_kernel_input->gpu_timing).device_particle_sort_time) += (gpu_timer_measure(gpu_kernel_input)); 
# 412
if (shift_only) { 
# 413
(cudaConfigureCall(nb, nt)) ? (void)0 : (permute_particles_zion_shift_ph2)(gpu_kernel_input->ptr_d_zion, gpu_kernel_input->ptr_d_auxs_zion, d_sort->d_value, d_sort->d_sort_key); } else { 
# 416
(cudaConfigureCall(nb, nt)) ? (void)0 : (permute_particles_zion_ph2)(gpu_kernel_input->ptr_d_zion, gpu_kernel_input->ptr_d_auxs_zion, d_sort->d_value, d_sort->d_sort_key); }  
# 417
(cudaConfigureCall(nb, nt)) ? (void)0 : (update_particle_zion_ph2)(gpu_kernel_input->ptr_d_zion, gpu_kernel_input->ptr_d_auxs_zion); 
# 419
(cudaConfigureCall(nb, nt)) ? (void)0 : (permute_particles_zion_ph1)(gpu_kernel_input->ptr_d_zion, gpu_kernel_input->ptr_d_auxs_zion, d_sort->d_value, irk); 
# 420
(cudaConfigureCall(nb, nt)) ? (void)0 : (update_particle_zion_ph1)(gpu_kernel_input->ptr_d_zion, gpu_kernel_input->ptr_d_auxs_zion, irk); 
# 422
((gpu_kernel_input->gpu_timing).device_particle_bin_time) += (gpu_timer_measure_end(gpu_kernel_input)); 
# 423
} 
# 425
static int h_start_shift[3]; 
# 429
extern "C" void call_gpu_shifti_extract_kernel(gtc_bench_data_t *gtc_input, gpu_kernel_args_t *gpu_kernel_input, unsigned tops[3], real *sends[3], int shift_direction) 
# 430
{ 
# 431
gpu_timer_start(gpu_kernel_input); 
# 433
{ cudaError err = cudaMemcpyFromSymbol(h_start_shift, d_start_shift, sizeof(int) * (3), 0, cudaMemcpyDeviceToHost); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "./gpu_bin_shift.cu", 433, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 434
int shift_left_size, shift_right_size, total_shift; 
# 435
int start_shift_left; 
# 436
int mi = (gtc_input->global_params).mi; 
# 438
(mi == ((h_start_shift)[0])) ? static_cast< void>(0) : __assert_fail("mi == h_start_shift[0]", "./gpu_bin_shift.cu", 438, __PRETTY_FUNCTION__); 
# 439
if (((h_start_shift)[1]) == mi) { 
# 440
((h_start_shift)[1]) = ((h_start_shift)[2]); }  
# 442
if (((h_start_shift)[1]) < mi) { 
# 443
shift_left_size = (((h_start_shift)[2]) - ((h_start_shift)[1])); 
# 444
start_shift_left = ((h_start_shift)[1]); 
# 445
} else { 
# 446
shift_left_size = 0; }  
# 448
if (((h_start_shift)[2]) < mi) { 
# 449
shift_right_size = (mi - ((h_start_shift)[2])); 
# 450
} else { 
# 451
shift_right_size = 0; }  
# 453
(tops[1]) = shift_left_size; 
# 454
(tops[2]) = shift_right_size; 
# 455
total_shift = (shift_left_size + shift_right_size); 
# 457
if (total_shift == 0) { 
# 458
((gpu_kernel_input->gpu_timing).memtransfer_shift_time) += (gpu_timer_measure_end(gpu_kernel_input)); 
# 459
return; 
# 460
}  
# 462
gtc_particle_decomp_t *parallel_decomp = &(gtc_input->parallel_decomp); 
# 464
if ((2 * total_shift) >= (parallel_decomp->sendbuf_size)) { 
# 465
fprintf(stderr, "Error! GPU PE %d, shift_left_size %d, shift_right_size %d, sendbuf_size %d\n", parallel_decomp->mype, shift_left_size, shift_right_size, parallel_decomp->sendbuf_size); 
# 469
exit(1); 
# 470
} else { 
# 471
(sends[1]) = (parallel_decomp->sendbuf); 
# 472
(sends[2]) = ((parallel_decomp->sendbuf) + (12 * shift_left_size)); 
# 473
(sends[0]) = ((parallel_decomp->sendbuf) + (12 * total_shift)); 
# 474
}  
# 476
cudaStream_t stream; 
# 477
{ cudaError err = cudaStreamCreate(&stream); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "./gpu_bin_shift.cu", 477, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 478
int d_mimax = gpu_kernel_input->d_mimax; 
# 479
int i, j, k; 
# 496
for (i = 0; i < 12; i++) { 
# 497
{ cudaError err = cudaMemcpyAsync((void *)((sends[1]) + (i * shift_left_size)), (((gpu_kernel_input->d_zion).z0) + (i * d_mimax)) + start_shift_left, shift_left_size * sizeof(real), cudaMemcpyDeviceToHost, stream); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "./gpu_bin_shift.cu", 497, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 498
{ cudaError err = cudaMemcpyAsync((void *)((sends[2]) + (i * shift_right_size)), ((((gpu_kernel_input->d_zion).z0) + (i * d_mimax)) + start_shift_left) + shift_left_size, shift_right_size * sizeof(real), cudaMemcpyDeviceToHost, stream); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "./gpu_bin_shift.cu", 498, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 499
}  
# 501
((gtc_input->global_params).mi) -= total_shift; 
# 502
{ cudaError err = cudaStreamSynchronize(stream); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "./gpu_bin_shift.cu", 502, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 503
{ cudaError err = cudaStreamDestroy(stream); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "./gpu_bin_shift.cu", 503, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 505
((gpu_kernel_input->gpu_timing).memtransfer_shift_time) += (gpu_timer_measure_end(gpu_kernel_input)); 
# 507
} 
# 510
extern "C" void call_gpu_shifti_append_kernel(gtc_bench_data_t *gtc_input, gpu_kernel_args_t *gpu_kernel_input, int mi_append, real *particle_data) 
# 511
{ 
# 512
if (mi_append == 0) { 
# 513
return; }  
# 514
gpu_timer_start(gpu_kernel_input); 
# 515
cudaStream_t stream; 
# 516
{ cudaError err = cudaStreamCreate(&stream); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "./gpu_bin_shift.cu", 516, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 517
int d_mimax = gpu_kernel_input->d_mimax; 
# 518
int mimax_shift = gpu_kernel_input->d_max_shift_mi; 
# 519
int i, j; 
# 533
for (i = 0; i < 12; i++) 
# 534
{ cudaError err = cudaMemcpyAsync((((gpu_kernel_input->d_zion).z0) + (i * d_mimax)) + ((h_start_shift)[1]), particle_data + (i * mimax_shift), mi_append * sizeof(real), cudaMemcpyHostToDevice, stream); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "./gpu_bin_shift.cu", 535, cudaGetErrorString(err)); exit(1); }  }  ; 
# 535
; 
# 537
{ cudaError err = cudaStreamSynchronize(stream); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "./gpu_bin_shift.cu", 537, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 538
{ cudaError err = cudaStreamDestroy(stream); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "./gpu_bin_shift.cu", 538, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 540
((gpu_kernel_input->gpu_timing).memtransfer_shift_time) += (gpu_timer_measure(gpu_kernel_input)); 
# 542
((gtc_input->global_params).mi) += mi_append; 
# 546
{ cudaError err = cudaMemcpyToSymbol(params, &((gtc_input->global_params).mi), sizeof(int), __builtin_offsetof(gtc_global_params_t, mi), cudaMemcpyHostToDevice); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "./gpu_bin_shift.cu", 546, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 548
((gpu_kernel_input->gpu_timing).device_shift_time) += (gpu_timer_measure_end(gpu_kernel_input)); 
# 550
} 
# 30 "./gpu_push_kernel.cu"
__attribute__((unused)) static inline real fetch_evector(int i) 
# 31
{int volatile ___ = 1;(void)i;
# 34
::exit(___);}
#if 0
# 31
{ 
# 32
int2 e = tex1Dfetch(evectorTexRef, i); 
# 33
return __hiloint2double(e.y, e.x); 
# 34
} 
#endif
# 47 "./gpu_push_kernel.cu"
static void gpu_pushi_kernel(gtc_particle_data_t *zion, gtc_aux_particle_data_t *aux_zion, gtc_field_data_t *grid, gtc_diagnosis_data_t *diagnosis, int irk, int istep, int idiag) ;
#if 0
# 48
{ 
# 49
const int tid = __device_builtin_variable_threadIdx.x; 
# 50
const int bid = __device_builtin_variable_blockIdx.x; 
# 51
const int nblocks = __device_builtin_variable_gridDim.x; 
# 52
const int nthreads = __device_builtin_variable_blockDim.x; 
# 53
const int gid = tid + (bid * nthreads); 
# 54
const int np = nblocks * nthreads; 
# 56
const int mflux = 5; 
# 57
__attribute__((unused)) extern real shared_buffer_gyro[]; 
# 58
real *vdrtmp = shared_buffer_gyro; 
# 60
real *scalar_data_s = &(vdrtmp[mflux]); 
# 61
real *flux_s = &(scalar_data_s[7 * nthreads]); 
# 63
if (idiag == 0) { 
# 64
for (int i = tid; i < (7 * nthreads); i += nthreads) { 
# 65
(scalar_data_s[i]) = (0.0); 
# 66
}  
# 67
for (int i = tid; i < ((4 * mflux) * nthreads); i += nthreads) { 
# 68
(flux_s[i]) = (0.0); 
# 69
}  
# 70
__syncthreads(); 
# 71
}  
# 73
int mi = params.mi; 
# 77
int mpsi = params.mpsi; 
# 79
const real a = params.a; 
# 80
const real a0 = params.a0; 
# 81
const real a1 = params.a1; 
# 82
const real delr = params.delr; 
# 83
const real pi2 = (2.0) * (params.pi); 
# 84
const real pi2_inv = params.pi2_inv; 
# 85
const int nbound = params.nbound; 
# 86
const real gyroradius = params.gyroradius; 
# 87
const real qion = params.qion; 
# 88
const real aion = params.aion; 
# 89
const real tstep = params.tstep; 
# 90
const real nonlinear = params.nonlinear; 
# 91
const real paranl = params.paranl; 
# 93
real *__restrict__ scalar_data = diagnosis->scalar_data; 
# 94
real *__restrict__ flux_data = diagnosis->flux_data; 
# 113
real delz, a_diff, zetamin; 
# 120
const real *pgyro; const real *tgyro; 
# 121
int ipjt; 
# 124
int mpsi_max; 
# 125
real wzt, r_diff, rdum, rhotmp, tflr, tdumtmp, tdumtmp2, tdum, tdum2; 
# 126
real wtion0tmp, wtion1tmp; 
# 127
int iptmp, im, im2, idxpg, jt, jttmp; 
# 128
int jtion0tmp, jtion1tmp, j00, j01; 
# 129
real r, wz1, wz0; 
# 131
int ip; 
# 136
const real *__restrict__ pfluxpsi = grid->pfluxpsi; 
# 138
const int igrid_in = radial_decomp.igrid_in; 
# 139
const int ipsi_valid_in = radial_decomp.ipsi_valid_in; 
# 140
const int ipsi_valid_out = radial_decomp.ipsi_valid_out; 
# 141
const int nloc_over = radial_decomp.nloc_over; 
# 142
const real rho_max = radial_decomp.rho_max; 
# 144
real *__restrict__ zion1 = zion->z0; 
# 145
real *__restrict__ zion2 = zion->z1; 
# 146
real *__restrict__ zion3 = zion->z2; 
# 147
real *__restrict__ zion4 = zion->z3; 
# 148
real *__restrict__ zion5 = zion->z4; 
# 149
real *__restrict__ zion6 = zion->z5; 
# 151
real *__restrict__ zion01 = zion->z00; 
# 152
real *__restrict__ zion02 = zion->z01; 
# 153
real *__restrict__ zion03 = zion->z02; 
# 154
real *__restrict__ zion04 = zion->z03; 
# 155
real *__restrict__ zion05 = zion->z04; 
# 156
real *__restrict__ zion06 = zion->z05; 
# 165
real zion1m, zion2m, zion3m, zion4m, zion5m, zion6m; 
# 167
real dtime; 
# 168
real sbound = (1.0); 
# 169
if (nbound == 0) { sbound = (0.0); }  
# 170
real psimax = ((0.5) * a1) * a1; 
# 171
real psimin = ((0.5) * a0) * a0; 
# 172
real cmratio = qion / aion; 
# 173
real cinv = (1.0) / qion; 
# 174
real vthi = (gyroradius * fabs(qion)) / aion; 
# 175
real d_inv = ((real)mflux) / (a1 - a0); 
# 177
for (int m = gid; m < mi; m += np) { 
# 179
if (irk == 1) { 
# 180
dtime = ((0.5) * tstep); 
# 181
if (tid < mflux) { 
# 182
(vdrtmp[tid]) = (0.0); }  
# 185
TunedLoad< double, CS> ::Ld(zion1m, zion1 + m); 
# 186
TunedLoad< double, CS> ::Ld(zion2m, zion2 + m); 
# 187
TunedLoad< double, CS> ::Ld(zion3m, zion3 + m); 
# 188
TunedLoad< double, CS> ::Ld(zion4m, zion4 + m); 
# 189
TunedLoad< double, CS> ::Ld(zion5m, zion5 + m); 
# 191
TunedStore< double, CS> ::St(zion1m, zion01 + m); 
# 192
TunedStore< double, CS> ::St(zion2m, zion02 + m); 
# 193
TunedStore< double, CS> ::St(zion3m, zion03 + m); 
# 194
TunedStore< double, CS> ::St(zion4m, zion04 + m); 
# 195
TunedStore< double, CS> ::St(zion5m, zion05 + m); 
# 204
} else { 
# 205
dtime = tstep; 
# 206
if (nonlinear < (0.5)) { 
# 207
printf("Error! decoupling modes for nonlinear = 0.0 not implemented\n"); 
# 209
if (tid < mflux) { 
# 210
(vdrtmp[tid]) = (0.0); }  
# 211
} else { 
# 212
if (tid < mflux) { 
# 213
(vdrtmp[tid]) = (pfluxpsi[tid]); }  
# 214
}  
# 215
}  
# 216
__syncthreads(); 
# 217
real wp0, wp1, wt00, wt01, wt10, wt11; 
# 218
int kk, larmor; 
# 220
int ii, ij1, ij2, ij3, ij4, idx1, idx2, idx3, idx4; 
# 224
if (irk != 1) { 
# 225
TunedLoad< double, CS> ::Ld(zion1m, zion1 + m); 
# 226
TunedLoad< double, CS> ::Ld(zion2m, zion2 + m); 
# 227
TunedLoad< double, CS> ::Ld(zion3m, zion3 + m); 
# 228
TunedLoad< double, CS> ::Ld(zion4m, zion4 + m); 
# 229
TunedLoad< double, CS> ::Ld(zion5m, zion5 + m); 
# 230
}  
# 231
TunedLoad< double, CS> ::Ld(zion6m, zion6 + m); 
# 240
real e1 = (0.0); 
# 241
real e2 = (0.0); 
# 242
real e3 = (0.0); 
# 246
kk = 0; 
# 259
a_diff = (a1 - a0); 
# 260
zetamin = (params.zetamin); 
# 261
real smu_inv = params.smu_inv; 
# 271
pgyro = (grid->pgyro); tgyro = (grid->tgyro); 
# 274
real psitmp = zion1m; 
# 275
real thetatmp = zion2m; 
# 276
real zetatmp = zion3m; 
# 277
real rhoi = zion6m * smu_inv; 
# 279
delz = (params.delz); 
# 280
mpsi_max = (mpsi - 1); 
# 283
r = psitmp; 
# 287
iptmp = ((int)(((r - a0) * delr) + (0.5))); 
# 288
ip = d_abs_min_int(mpsi, iptmp); 
# 298
jttmp = ((int)(((thetatmp * pi2_inv) * ((delt)[ip])) + (0.5))); 
# 299
jt = d_abs_min_int((mtheta)[ip], jttmp); 
# 301
wzt = ((zetatmp - zetamin) * delz); 
# 302
wz1 = (wzt - ((real)kk)); 
# 303
wz0 = ((1.0) - wz1); 
# 304
r_diff = (r - a0); 
# 326
ipjt = (((igrid)[ip]) + jt); 
# 334
int ind = m; 
# 335
for (larmor = 0; larmor < 4; larmor++) { 
# 351
idxpg = (larmor + (4 * (ipjt - igrid_in))); 
# 352
rhotmp = (rhoi * (pgyro[idxpg])); 
# 353
if (fabs(rhotmp) > rho_max) { 
# 354
printf("rhotmp=%e rhoi=%e rho_max=%e pgyro=%e\n", rhotmp, rhoi, rho_max, pgyro[idxpg]); 
# 355
printf("warning: push sub reducing rhoi to %e from %e\n", ((rhotmp / fabs(rhotmp)) * rho_max) / (pgyro[idxpg]), rhoi); 
# 356
rhotmp = ((rhotmp / fabs(rhotmp)) * rho_max); 
# 357
rhoi = (rhotmp / (pgyro[idxpg])); 
# 358
}  
# 359
rdum = (delr * d_abs_min_real(a_diff, r_diff + rhotmp)); 
# 361
tflr = (thetatmp + (rhoi * (tgyro[idxpg]))); 
# 364
ii = d_abs_min_int(mpsi_max, (int)rdum); 
# 366
wp1 = (rdum - ((real)ii)); 
# 367
wp0 = ((1.0) - wp1); 
# 371
im = ii; 
# 372
im2 = (ii + 1); 
# 374
tdumtmp = ((pi2_inv * (tflr - (zetatmp * ((qtinv)[im])))) + (10.0)); 
# 375
tdumtmp2 = ((pi2_inv * (tflr - (zetatmp * ((qtinv)[im2])))) + (10.0)); 
# 377
tdum = ((tdumtmp - ((int)tdumtmp)) * ((delt)[im])); 
# 378
tdum2 = ((tdumtmp2 - ((int)tdumtmp2)) * ((delt)[im2])); 
# 380
j00 = d_abs_min_int(((mtheta)[im]) - 1, (int)tdum); 
# 381
j01 = d_abs_min_int(((mtheta)[im2]) - 1, (int)tdum2); 
# 383
jtion0tmp = (((igrid)[im]) + j00); 
# 384
jtion1tmp = (((igrid)[im2]) + j01); 
# 386
wtion0tmp = (tdum - ((real)j00)); 
# 387
wtion1tmp = (tdum2 - ((real)j01)); 
# 389
ij1 = (jtion0tmp - igrid_in); 
# 390
ij3 = (jtion1tmp - igrid_in); 
# 392
wp0 = ((1.0) - wp1); 
# 393
wt10 = wtion0tmp; 
# 394
wt11 = wtion1tmp; 
# 395
wt01 = ((1.0) - wt11); 
# 396
wt00 = ((1.0) - wt10); 
# 397
ij2 = (ij1 + 1); 
# 398
ij4 = (ij3 + 1); 
# 423
idx1 = (6 * ij1); 
# 425
idx3 = (6 * ij3); 
# 465
e1 = (e1 + ((wp0 * wt00) * ((wz0 * fetch_evector(idx1 + 0)) + (wz1 * fetch_evector(idx1 + 3))))); 
# 466
e2 = (e2 + ((wp0 * wt00) * ((wz0 * fetch_evector(idx1 + 1)) + (wz1 * fetch_evector(idx1 + 4))))); 
# 467
e3 = (e3 + ((wp0 * wt00) * ((wz0 * fetch_evector(idx1 + 2)) + (wz1 * fetch_evector(idx1 + 5))))); 
# 468
e1 = (e1 + ((wp0 * wt10) * ((wz0 * fetch_evector((idx1 + 6) + 0)) + (wz1 * fetch_evector((idx1 + 6) + 3))))); 
# 469
e2 = (e2 + ((wp0 * wt10) * ((wz0 * fetch_evector((idx1 + 6) + 1)) + (wz1 * fetch_evector((idx1 + 6) + 4))))); 
# 470
e3 = (e3 + ((wp0 * wt10) * ((wz0 * fetch_evector((idx1 + 6) + 2)) + (wz1 * fetch_evector((idx1 + 6) + 5))))); 
# 472
e1 = (e1 + ((wp1 * wt01) * ((wz0 * fetch_evector(idx3 + 0)) + (wz1 * fetch_evector(idx3 + 3))))); 
# 473
e2 = (e2 + ((wp1 * wt01) * ((wz0 * fetch_evector(idx3 + 1)) + (wz1 * fetch_evector(idx3 + 4))))); 
# 474
e3 = (e3 + ((wp1 * wt01) * ((wz0 * fetch_evector(idx3 + 2)) + (wz1 * fetch_evector(idx3 + 5))))); 
# 475
e1 = (e1 + ((wp1 * wt11) * ((wz0 * fetch_evector((idx3 + 6) + 0)) + (wz1 * fetch_evector((idx3 + 6) + 3))))); 
# 476
e2 = (e2 + ((wp1 * wt11) * ((wz0 * fetch_evector((idx3 + 6) + 1)) + (wz1 * fetch_evector((idx3 + 6) + 4))))); 
# 477
e3 = (e3 + ((wp1 * wt11) * ((wz0 * fetch_evector((idx3 + 6) + 2)) + (wz1 * fetch_evector((idx3 + 6) + 5))))); 
# 513
ind += mi; 
# 514
}  
# 516
real wpi1 = (0.25) * e1; 
# 517
real wpi2 = (0.25) * e2; 
# 518
real wpi3 = (0.25) * e3; 
# 520
real zion01m, zion02m, zion03m, zion04m, zion05m; 
# 522
if (irk == 1) { 
# 523
zion01m = zion1m; 
# 524
zion02m = zion2m; 
# 525
zion03m = zion3m; 
# 526
zion04m = zion4m; 
# 527
zion05m = zion5m; 
# 528
} else { 
# 530
TunedLoad< double, CS> ::Ld(zion01m, zion01 + m); 
# 531
TunedLoad< double, CS> ::Ld(zion02m, zion02 + m); 
# 532
TunedLoad< double, CS> ::Ld(zion03m, zion03 + m); 
# 533
TunedLoad< double, CS> ::Ld(zion04m, zion04 + m); 
# 534
TunedLoad< double, CS> ::Ld(zion05m, zion05 + m); 
# 542
}  
# 545
real ainv = (1.0) / a; 
# 557
real rinv = (1.0) / r; 
# 559
const real q0 = params.q0; 
# 560
const real q1 = params.q1; 
# 561
const real q2 = params.q2; 
# 562
const real rw = params.rw; 
# 563
const real rc = params.rc; 
# 564
ii = d_abs_min_int(mpsi - 1, (int)((r - a0) * delr)); 
# 565
ip = d_abs_min_int(mflux - 1, 1 + ((int)((r - a0) * d_inv))); 
# 566
wp0 = (((real)(ii + 1)) - ((r - a0) * delr)); 
# 567
wp1 = ((1.0) - wp0); 
# 568
real tem = (wp0 * ((temp)[ii])) + (wp1 * ((temp)[ii + 1])); 
# 569
real q = (q0 + ((q1 * r) * ainv)) + ((((q2 * r) * r) * ainv) * ainv); 
# 570
real qinv = (1.0) / q; 
# 571
real cost = cos(zion2m); 
# 572
real sint = sin(zion2m); 
# 573
real b = (1.0) / ((1.0) + (r * cost)); 
# 574
real g = (1.0); 
# 575
real gp = (0.0); 
# 576
real ri = (0.0); 
# 577
real rip = (0.0); 
# 578
real dbdp = ((((-(1.0)) * b) * b) * cost) * rinv; 
# 579
real dbdt = ((b * b) * r) * sint; 
# 580
real dedb = cinv * (((((zion4m * zion4m) * qion) * b) * cmratio) + (zion6m * zion6m)); 
# 581
real deni = (1.0) / (((g * q) + ri) + (zion4m * ((g * rip) - (ri * gp)))); 
# 582
real upara = (zion4m * b) * cmratio; 
# 583
real energy = ((((0.5) * aion) * upara) * upara) + ((zion6m * zion6m) * b); 
# 584
real rfac = rw * (r - rc); 
# 586
rfac = (rfac * rfac); 
# 587
rfac = ((rfac * rfac) * rfac); 
# 588
rfac = exp((-1) * rfac); 
# 594
real kappa = ((1.0) - sbound) + (sbound * rfac); 
# 595
const real kappati = params.kappati; 
# 596
const real kappan = params.kappan; 
# 597
kappa = ((((((energy * tem) - (1.5)) * kappati) + kappan) * kappa) * rinv); 
# 600
real dptdp = wpi1; 
# 601
real dptdt = wpi2; 
# 602
real dptdz = wpi3 - (wpi2 * qinv); 
# 603
real epara = ((((-(1.0)) * wpi3) * b) * q) * deni; 
# 605
dptdt = (dptdt + (vdrtmp[ip])); 
# 608
real vdr = (q * ((ri * dptdz) - (g * dptdt))) * deni; 
# 609
real wdrive = vdr * kappa; 
# 610
real wpara = ((epara * (upara - ((dtemp)[ii]))) * qion) * tem; 
# 612
real wdrift = ((((q * ((((g * dbdt) * dptdp) - ((g * dbdp) * dptdt)) + ((ri * dbdp) * dptdz))) * deni) * dedb) * qion) * tem; 
# 614
real wdot = ((zion06[m]) - zion5m) * ((wdrive + wpara) + wdrift); 
# 616
const real flow0 = params.flow0; 
# 617
const real flow1 = params.flow1; 
# 618
const real flow2 = params.flow2; 
# 619
dptdp = ((dptdp * nonlinear) + (gyroradius * ((flow0 + ((flow1 * r) * ainv)) + ((((flow2 * r) * r) * ainv) * ainv)))); 
# 620
dptdt = (dptdt * nonlinear); 
# 621
dptdz = (dptdz * nonlinear); 
# 624
real pdot = (q * (((((-g) * dedb) * dbdt) - (g * dptdt)) + (ri * dptdz))) * deni; 
# 625
real tdot = (((upara * b) * ((1.0) - ((q * gp) * zion4m))) + ((q * g) * ((dedb * dbdp) + dptdp))) * deni; 
# 626
real zdot = ((((upara * b) * q) * ((1.0) + (rip * zion4m))) - ((q * ri) * ((dedb * dbdp) + dptdp))) * deni; 
# 627
real rdot = ((((gp * zion4m) - (1.0)) * ((dedb * dbdt) + (paranl * dptdt))) - (((paranl * q) * ((1.0) + (rip * zion4m))) * dptdz)) * deni; 
# 631
zion1m = max((1.000000000000000021e-08) * psimax, (((0.5) * zion01m) * zion01m) + (dtime * pdot)); 
# 632
zion1m = sqrt((2.0) * zion1m); 
# 636
TunedStore< double, CS> ::St(zion1m, zion1 + m); 
# 637
zion2m = (zion02m + (dtime * tdot)); 
# 638
zion3m = (zion03m + (dtime * zdot)); 
# 639
zion4m = (zion04m + (dtime * rdot)); 
# 640
TunedStore< double, CS> ::St(zion4m, zion4 + m); 
# 641
zion5m = (zion05m + (dtime * wdot)); 
# 642
TunedStore< double, CS> ::St(zion5m, zion5 + m); 
# 643
real z1t = (zion2m * pi2_inv) + (10); 
# 644
zion2m = (pi2 * (z1t - ((int)z1t))); 
# 645
TunedStore< double, CS> ::St(zion2m, zion2 + m); 
# 646
z1t = ((zion3m * pi2_inv) + (10)); 
# 647
zion3m = (pi2 * (z1t - ((int)z1t))); 
# 648
TunedStore< double, CS> ::St(zion3m, zion3 + m); 
# 650
if (irk == 2) { 
# 652
if ((zion1m > a1) || (zion1m < a0)) { 
# 656
TunedStore< double, CS> ::St(zion01m, zion1 + m); 
# 657
TunedStore< double, CS> ::St(pi2 - zion02m, zion2 + m); 
# 658
TunedStore< double, CS> ::St(zion03m, zion3 + m); 
# 659
TunedStore< double, CS> ::St(zion04m, zion4 + m); 
# 660
TunedStore< double, CS> ::St(zion05m, zion5 + m); 
# 662
TunedStore< double, CS> ::St(pi2 - zion02m, zion02 + m); 
# 663
}  
# 670
}  
# 723
if (idiag == 0) { 
# 724
ip = d_abs_min_int(mflux - 1, (int)((r - a0) * d_inv)); 
# 727
real vdrenergy = ((vdr * rinv) * (energy - (((((1.5) * aion) * vthi) * vthi) * ((rtemi)[ii])))) * zion05m; 
# 731
(flux_s[(ip * nthreads) + tid]) += vdrenergy; 
# 732
(flux_s[((mflux * nthreads) + (ip * nthreads)) + tid]) += (1.0); 
# 733
(flux_s[(((2 * mflux) * nthreads) + (ip * nthreads)) + tid]) += ((vdr * rinv) * r); 
# 734
(flux_s[(((3 * mflux) * nthreads) + (ip * nthreads)) + tid]) += (1.0); 
# 736
(scalar_data_s[(0 * nthreads) + tid]) += vdrenergy; 
# 737
(scalar_data_s[(1 * nthreads) + tid]) += ((vdr * rinv) * zion05m); 
# 738
(scalar_data_s[(2 * nthreads) + tid]) += ((b * zion04m) * zion05m); 
# 739
(scalar_data_s[(3 * nthreads) + tid]) += (zion05m * zion05m); 
# 740
(scalar_data_s[(4 * nthreads) + tid]) += (energy * zion05m); 
# 741
(scalar_data_s[(5 * nthreads) + tid]) += energy; 
# 742
(scalar_data_s[(6 * nthreads) + tid]) += zion05m; 
# 743
}  
# 745
}  
# 746
__syncthreads(); 
# 748
if (idiag == 0) { 
# 750
int nTotalThreads = nthreads; 
# 751
while (nTotalThreads > 1) { 
# 752
int half = nTotalThreads >> 1; 
# 753
if (tid < half) { 
# 754
for (int i = 0; i < 7; i++) { 
# 755
(scalar_data_s[(i * nthreads) + tid]) += (scalar_data_s[((i * nthreads) + tid) + half]); 
# 756
}  
# 758
for (int i = 0; i < mflux; i++) 
# 759
{ 
# 762
(flux_s[(i * nthreads) + tid]) += (flux_s[((i * nthreads) + tid) + half]); 
# 763
(flux_s[((mflux * nthreads) + (i * nthreads)) + tid]) += (flux_s[(((mflux * nthreads) + (i * nthreads)) + tid) + half]); 
# 764
(flux_s[(((2 * mflux) * nthreads) + (i * nthreads)) + tid]) += (flux_s[((((2 * mflux) * nthreads) + (i * nthreads)) + tid) + half]); 
# 765
(flux_s[(((3 * mflux) * nthreads) + (i * nthreads)) + tid]) += (flux_s[((((3 * mflux) * nthreads) + (i * nthreads)) + tid) + half]); 
# 766
}  
# 767
}  
# 768
__syncthreads(); 
# 769
nTotalThreads = (nTotalThreads >> 1); 
# 770
}  
# 771
if (tid == 0) { 
# 772
atomicDPupdate(scalar_data, scalar_data_s[0]); 
# 773
atomicDPupdate(scalar_data + 2, scalar_data_s[nthreads]); 
# 774
atomicDPupdate(scalar_data + 6, scalar_data_s[2 * nthreads]); 
# 775
atomicDPupdate(scalar_data + 8, scalar_data_s[3 * nthreads]); 
# 776
atomicDPupdate(scalar_data + 12, scalar_data_s[4 * nthreads]); 
# 777
atomicDPupdate(scalar_data + 13, scalar_data_s[5 * nthreads]); 
# 778
atomicDPupdate(scalar_data + 15, scalar_data_s[6 * nthreads]); 
# 779
}  
# 797
if (tid < 5) { 
# 799
atomicDPupdate(flux_data + tid, flux_s[tid * nthreads]); }  
# 801
if ((tid >= 5) && (tid < 10)) { 
# 803
atomicDPupdate(flux_data + tid, flux_s[(mflux * nthreads) + ((tid - 5) * nthreads)]); }  
# 805
if ((tid >= 10) && (tid < 15)) { 
# 806
atomicDPupdate(flux_data + tid, flux_s[((2 * mflux) * nthreads) + ((tid - 10) * nthreads)]); }  
# 808
if ((tid >= 15) && (tid < 20)) { 
# 809
atomicDPupdate(flux_data + tid, flux_s[((3 * mflux) * nthreads) + ((tid - 15) * nthreads)]); }  
# 811
}  
# 812
} 
#endif
# 814 "./gpu_push_kernel.cu"
bool findGridDims(dim3 &Dg, int nblocks, int max_dim) 
# 815
{ 
# 816
if ((nblocks > max_dim) && ((nblocks % max_dim) == 0)) { 
# 817
(Dg.x) = max_dim; 
# 818
(Dg.y) = (nblocks / max_dim); 
# 819
return true; 
# 820
}  
# 821
int guess_a = (int)sqrt(nblocks); 
# 822
int guess_b = (int)sqrt(nblocks); 
# 823
int best_error = abs((guess_a * guess_b) - nblocks); 
# 824
int best_guess_a = guess_a; 
# 825
int best_guess_b = guess_b; 
# 826
guess_a++; 
# 827
while (guess_a < max_dim) { 
# 828
while ((guess_b * guess_a) > nblocks) { 
# 829
guess_b--; }  
# 830
int error = abs((guess_a * guess_b) - nblocks); 
# 831
if (error < best_error) { 
# 832
best_error = error; 
# 833
best_guess_a = guess_a; 
# 834
best_guess_b = guess_b; 
# 835
}  
# 836
guess_a++; 
# 837
}  
# 838
(Dg.x) = best_guess_a; 
# 839
(Dg.y) = best_guess_b; 
# 840
if (best_error == 0) { 
# 841
return true; } else 
# 842
{ 
# 843
if (((guess_a * guess_b) - nblocks) < 0) { 
# 844
(Dg.x) += (1); }  
# 845
return false; 
# 846
}  
# 847
} 
# 850
extern "C" void call_gpu_push_kernel(gtc_bench_data_t *gtc_input, gpu_kernel_args_t *gpu_kernel_input, int idiag) 
# 851
{ 
# 852
int mi = (gtc_input->global_params).mi; 
# 853
int nthreads = (gpu_kernel_input->nthreads) * 4; 
# 854
gtc_global_params_t *h_params = &(gtc_input->global_params); 
# 855
gtc_diagnosis_data_t *h_diagnosis = &(gtc_input->diagnosis_data); 
# 856
gtc_diagnosis_data_t *d_diagnosis = &(gpu_kernel_input->d_diagnosis); 
# 857
gtc_radial_decomp_t *h_radial_decomp = &(gtc_input->radial_decomp); 
# 859
int mzeta = h_params->mzeta; int nloc_over = h_radial_decomp->nloc_over; 
# 860
int mype = (gtc_input->parallel_decomp).mype; 
# 862
dim3 Db = dim3(nthreads, 1); 
# 863
dim3 Dg; 
# 864
int nblocks = ((mi + nthreads) - 1) / nthreads; 
# 868
gtc_field_data_t *h_grid = &(gtc_input->field_data); 
# 869
gtc_field_data_t *d_grid = &(gpu_kernel_input->d_grid); 
# 870
gpu_timer_start(gpu_kernel_input); 
# 872
{ cudaError err = cudaMemcpy((void *)(d_grid->evector), h_grid->evector, ((3 * (mzeta + 1)) * nloc_over) * sizeof(real), cudaMemcpyHostToDevice); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "./gpu_push_kernel.cu", 872, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 873
{ cudaError err = cudaMemcpy((void *)(d_grid->pfluxpsi), h_grid->pfluxpsi, (5) * sizeof(real), cudaMemcpyHostToDevice); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "./gpu_push_kernel.cu", 873, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 876
if (idiag == 0) { 
# 878
{ cudaError err = cudaMemcpy((void *)(d_diagnosis->scalar_data), h_diagnosis->scalar_data, (16) * sizeof(real), cudaMemcpyHostToDevice); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "./gpu_push_kernel.cu", 878, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 880
{ cudaError err = cudaMemset(d_diagnosis->flux_data, 0, (4 * 5) * sizeof(real)); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "./gpu_push_kernel.cu", 880, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 881
}  
# 882
((gpu_kernel_input->gpu_timing).memtransfer_push_time) += (gpu_timer_measure(gpu_kernel_input)); 
# 884
if (nblocks < (((gpu_kernel_input->deviceProp).maxGridSize)[0])) { 
# 885
(Dg.x) = nblocks; } else 
# 886
{ 
# 887
if (!findGridDims(Dg, nblocks, ((gpu_kernel_input->deviceProp).maxGridSize)[0])) { ; }  
# 889
}  
# 891
int mi_per_thread = gpu_kernel_input->charge_mi_per_thread; 
# 892
nthreads = ((gpu_kernel_input->nthreads) / 2); 
# 893
int mp = (gpu_kernel_input->deviceProp).multiProcessorCount; 
# 894
int m = ((mi + (nthreads * mp)) - 1) / (nthreads * mp); 
# 895
m = (((m + mi_per_thread) - 1) / mi_per_thread); 
# 896
nblocks = (mp * m); 
# 897
mi_per_thread = (((mi + (nblocks * nthreads)) - 1) / mi_per_thread); 
# 900
int shared_buffer = ((5) * sizeof(real)) + (((7 * nthreads) + ((4 * 5) * nthreads)) * sizeof(real)); 
# 901
(cudaConfigureCall(nblocks, nthreads, shared_buffer)) ? (void)0 : (gpu_pushi_kernel)(gpu_kernel_input->ptr_d_zion, gpu_kernel_input->ptr_d_aux_zion, gpu_kernel_input->ptr_d_grid, gpu_kernel_input->ptr_d_diagnosis, gpu_kernel_input->irk, gpu_kernel_input->istep, idiag); 
# 902
cudaError_t lasterror = cudaGetLastError(); 
# 903
if (lasterror != (cudaSuccess)) { 
# 904
printf("Error in launching gpu_pushi_kernel routine: %s\n", cudaGetErrorString(lasterror)); 
# 905
}  
# 907
((gpu_kernel_input->gpu_timing).device_push_time) += (gpu_timer_measure(gpu_kernel_input)); 
# 910
if (idiag == 0) { 
# 912
{ cudaError err = cudaMemcpy((void *)(h_diagnosis->scalar_data), d_diagnosis->scalar_data, (16) * sizeof(real), cudaMemcpyDeviceToHost); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "./gpu_push_kernel.cu", 912, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 923
{ cudaError err = cudaMemcpy((void *)(h_diagnosis->flux_data), d_diagnosis->flux_data, (4 * 5) * sizeof(real), cudaMemcpyDeviceToHost); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "./gpu_push_kernel.cu", 923, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 924
}  
# 925
((gpu_kernel_input->gpu_timing).memtransfer_push_time) += (gpu_timer_measure_end(gpu_kernel_input)); 
# 927
} 
# 294 "gpu_setup.cu"
extern "C" void cpy_gtc_data_to_device(gtc_bench_data_t *gtc_input, gpu_kernel_args_t *gpu_kernel_args) 
# 295
{ 
# 296
gtc_global_params_t *h_params = &(gtc_input->global_params); 
# 297
gtc_field_data_t *h_grid = &(gtc_input->field_data); 
# 298
gtc_field_data_t *d_grid = &(gpu_kernel_args->d_grid); 
# 299
gtc_particle_data_t *d_zion = &(gpu_kernel_args->d_zion); 
# 300
gtc_particle_data_t *h_zion = &(gtc_input->particle_data); 
# 301
gtc_radial_decomp_t *h_radial_decomp = &(gtc_input->radial_decomp); 
# 304
int mpsi = h_params->mpsi; 
# 305
int mi = h_params->mi; 
# 306
int nloc_over = h_radial_decomp->nloc_over; 
# 307
int d_mimax = mi; 
# 310
{ cudaError err = cudaMemcpy((void *)(gpu_kernel_args->ptr_d_zion), (void *)d_zion, sizeof(gtc_particle_data_t), cudaMemcpyHostToDevice); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 310, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 311
{ cudaError err = cudaMemcpy((void *)(d_zion->z0), h_zion->z0, d_mimax * sizeof(real), cudaMemcpyHostToDevice); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 311, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 312
{ cudaError err = cudaMemcpy((void *)(d_zion->z1), h_zion->z1, d_mimax * sizeof(real), cudaMemcpyHostToDevice); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 312, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 313
{ cudaError err = cudaMemcpy((void *)(d_zion->z2), h_zion->z2, d_mimax * sizeof(real), cudaMemcpyHostToDevice); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 313, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 314
{ cudaError err = cudaMemcpy((void *)(d_zion->z3), h_zion->z3, d_mimax * sizeof(real), cudaMemcpyHostToDevice); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 314, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 315
{ cudaError err = cudaMemcpy((void *)(d_zion->z4), h_zion->z4, d_mimax * sizeof(real), cudaMemcpyHostToDevice); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 315, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 316
{ cudaError err = cudaMemcpy((void *)(d_zion->z5), h_zion->z5, d_mimax * sizeof(real), cudaMemcpyHostToDevice); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 316, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 317
{ cudaError err = cudaMemcpy((void *)(d_zion->z00), h_zion->z0, d_mimax * sizeof(real), cudaMemcpyHostToDevice); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 317, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 318
{ cudaError err = cudaMemcpy((void *)(d_zion->z01), h_zion->z1, d_mimax * sizeof(real), cudaMemcpyHostToDevice); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 318, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 319
{ cudaError err = cudaMemcpy((void *)(d_zion->z02), h_zion->z2, d_mimax * sizeof(real), cudaMemcpyHostToDevice); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 319, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 320
{ cudaError err = cudaMemcpy((void *)(d_zion->z03), h_zion->z3, d_mimax * sizeof(real), cudaMemcpyHostToDevice); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 320, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 321
{ cudaError err = cudaMemcpy((void *)(d_zion->z04), h_zion->z4, d_mimax * sizeof(real), cudaMemcpyHostToDevice); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 321, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 322
{ cudaError err = cudaMemcpy((void *)(d_zion->z05), h_zion->z05, d_mimax * sizeof(real), cudaMemcpyHostToDevice); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 322, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 325
gtc_particle_data_t *d_auxs_zion = &(gpu_kernel_args->d_auxs_zion); 
# 326
{ cudaError err = cudaMemcpy((void *)(gpu_kernel_args->ptr_d_auxs_zion), (void *)d_auxs_zion, sizeof(gtc_particle_data_t), cudaMemcpyHostToDevice); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 326, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 349
gtc_diagnosis_data_t *d_diagnosis = &(gpu_kernel_args->d_diagnosis); 
# 350
{ cudaError err = cudaMemcpy((void *)(gpu_kernel_args->ptr_d_diagnosis), (void *)d_diagnosis, sizeof(gtc_diagnosis_data_t), cudaMemcpyHostToDevice); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 350, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 353
int tmp = h_params->mimax; 
# 354
(h_params->mimax) = (gpu_kernel_args->d_mimax); 
# 355
{ cudaError err = cudaMemcpyToSymbol(params, h_params, sizeof(gtc_global_params_t), 0, cudaMemcpyHostToDevice); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 355, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 356
(h_params->mimax) = tmp; 
# 357
{ cudaError err = cudaMemcpyToSymbol(radial_decomp, h_radial_decomp, sizeof(gtc_radial_decomp_t), 0, cudaMemcpyHostToDevice); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 357, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 359
real vthi = ((h_params->gyroradius) * fabs(h_params->qion)) / (h_params->aion); 
# 361
int i; 
# 362
for (i = 0; i < (mpsi + 1); i++) { 
# 363
((h_grid->temp)[i]) = (1.0); 
# 364
((h_grid->dtemp)[i]) = (0.0); 
# 365
((h_grid->temp)[i]) = ((1.0) / ((((((h_grid->temp)[i]) * ((h_grid->rtemi)[i])) * (h_params->aion)) * vthi) * vthi)); 
# 367
}  
# 371
{ cudaError err = cudaMemcpyToSymbol(temp, h_grid->temp, (mpsi + 1) * sizeof(real), 0, cudaMemcpyHostToDevice); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 371, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 372
{ cudaError err = cudaMemcpyToSymbol(rtemi, h_grid->rtemi, (mpsi + 1) * sizeof(real), 0, cudaMemcpyHostToDevice); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 372, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 373
{ cudaError err = cudaMemcpyToSymbol(igrid, h_grid->igrid, (mpsi + 1) * sizeof(int), 0, cudaMemcpyHostToDevice); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 373, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 374
{ cudaError err = cudaMemcpyToSymbol(delt, h_grid->delt, (mpsi + 1) * sizeof(real), 0, cudaMemcpyHostToDevice); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 374, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 375
{ cudaError err = cudaMemcpyToSymbol(qtinv, h_grid->qtinv, (mpsi + 1) * sizeof(real), 0, cudaMemcpyHostToDevice); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 375, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 376
{ cudaError err = cudaMemcpyToSymbol(mtheta, h_grid->mtheta, (mpsi + 1) * sizeof(int), 0, cudaMemcpyHostToDevice); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 376, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 377
{ cudaError err = cudaMemcpyToSymbol(max_shift_mi, &(gpu_kernel_args->d_max_shift_mi), sizeof(int), 0, cudaMemcpyHostToDevice); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 377, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 379
{ cudaError err = cudaMemcpy((void *)(gpu_kernel_args->ptr_d_grid), d_grid, sizeof(gtc_field_data_t), cudaMemcpyHostToDevice); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 379, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 381
{ cudaError err = cudaMemcpy((void *)(d_grid->pgyro), h_grid->pgyro, (4 * nloc_over) * sizeof(real), cudaMemcpyHostToDevice); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 381, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 382
{ cudaError err = cudaMemcpy((void *)(d_grid->tgyro), h_grid->tgyro, (4 * nloc_over) * sizeof(real), cudaMemcpyHostToDevice); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 382, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 387
int mzeta = h_params->mzeta; 
# 388
{ cudaError err = cudaBindTexture(0, evectorTexRef, (void *)(d_grid->evector), ((nloc_over * 3) * (mzeta + 1)) * sizeof(real)); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 388, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 391
{ cudaError err = cudaMemcpy((void *)(d_grid->pfluxpsi), h_grid->pfluxpsi, (5) * sizeof(real), cudaMemcpyHostToDevice); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 391, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 393
} 
# 396
extern "C" void gpu_atexit() 
# 397
{ 
# 401
} 
# 404
extern "C" void gpu_setup(gtc_bench_data_t *gtc_input, gpu_kernel_args_t *gpu_kernel_args) 
# 405
{ 
# 406
gtc_global_params_t *h_params = &(gtc_input->global_params); 
# 407
(gpu_kernel_args->d_mimax) = ((h_params->mi) + (100 * ((int)ceil(sqrt(h_params->mi))))); 
# 408
(gpu_kernel_args->d_mimax) = ((((gpu_kernel_args->d_mimax) / 64) + 1) * 64); 
# 410
(gpu_kernel_args->d_max_shift_mi) = ((gpu_kernel_args->d_mimax) / (100 / 10)); 
# 411
(gpu_kernel_args->d_nloc_over_cluster) = (((((gtc_input->radial_decomp).nloc_over) + 4) - 1) / 4); 
# 412
(gpu_kernel_args->d_nloc_over_cluster) = ((((gpu_kernel_args->d_nloc_over_cluster) / 64) + 1) * 64); 
# 413
(gpu_kernel_args->d_extra_mimax) = ((int)(((3.0) * ((gtc_input->radial_decomp).nloc_over)) * ((gtc_input->global_params).micell))); 
# 414
(gpu_kernel_args->d_extra_mimax) = ((((gpu_kernel_args->d_extra_mimax) / 64) + 1) * 64); 
# 416
int device_count = 0; 
# 417
int pe = (gtc_input->parallel_decomp).mype; 
# 419
{ cudaError err = cudaGetDeviceCount(&device_count); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 419, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 420
int gpu_device = pe % device_count; 
# 421
{ cudaError err = cudaSetDevice(gpu_device); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 421, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 422
{ cudaError err = cudaGetDevice(&gpu_device); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 422, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 423
cudaGetDeviceProperties(&(gpu_kernel_args->deviceProp), gpu_device); 
# 424
int nblocks = 1; 
# 425
if (pe == 0) { printf("multiProcessorCount=%d\n", (gpu_kernel_args->deviceProp).multiProcessorCount); }  
# 426
while (nblocks < ((gpu_kernel_args->deviceProp).multiProcessorCount)) { 
# 427
nblocks *= 2; }  
# 429
(gpu_kernel_args->nblocks) = (2 * nblocks); 
# 431
if (pe == 0) { 
# 432
char *name[] = {(char *)("no"), (char *)("yes")}; 
# 433
fprintf(stderr, "PE %d: Running on cuda device %d, total devices %d, Warpsize: %d, Min block count: %d\n", pe, gpu_device, device_count, (gpu_kernel_args->deviceProp).warpSize, gpu_kernel_args->nblocks); 
# 434
fprintf(stderr, "GPU Run Configuration\n========================\nPrefer L1: %s\nUse of PTX intrinsics: %s\nParticle binning: %s (period %d)\nOn " "the fly aux computation: %s\nGyro local compute: %s\nUse cooperative threading for charge deposition: %s\nUse four-point algorit" "hm: %s\nUse synergestic_sort_shift: %s\n=======================\n", (name)[0], (name)[1], (name)[1], 10, (name)[1], (name)[0], (name)[1], (name)[0], (name)[1]); 
# 444
}  
# 446
(gpu_kernel_args->nthreads) = 64; 
# 447
(gpu_kernel_args->charge_mi_per_thread) = 64; 
# 448
allocate_device_data(gtc_input, gpu_kernel_args); 
# 449
memset(&(gpu_kernel_args->gpu_timing), 0, sizeof(gpu_timing_t)); 
# 458
{ cudaError err = cudaDeviceSetSharedMemConfig(cudaSharedMemBankSizeEightByte); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 458, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 479
{ cudaError err = cudaFuncSetCacheConfig(gpu_pushi_kernel, cudaFuncCachePreferShared); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 479, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 480
{ cudaError err = cudaFuncSetCacheConfig(gpu_charge_cooperative, cudaFuncCachePreferShared); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 480, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 481
{ cudaError err = cudaFuncSetCacheConfig(gpu_charge_multi, cudaFuncCachePreferShared); if ((cudaSuccess) != err) { fprintf(stderr, "Cuda error in file \'%s\' in line %i : %s.\n", "gpu_setup.cu", 481, cudaGetErrorString(err)); exit(1); }  } ; ; 
# 490
atexit(gpu_atexit); 
# 491
} 
# 493
extern "C" void print_gpu_timing(gpu_kernel_args_t *gpu_kernel_args) 
# 494
{ 
# 495
fprintf(stderr, "\nGPU PCIe time summary:\nCharge\t\t\t%9.6f s\nPush\t\t\t%9.6f s\nShift\t\t\t%9.6f s\n\nExecution time summary on GPU device:\nC" "harge\t\t\t%9.6f s\nPush\t\t\t%9.6f s\nShift\t\t\t%9.6f s\nParticle sort\t%9.6f s\nParticle bin\t%9.6f s\ncharge reset   %9.6f s" "\ncharge initialization %9.6f s\ncharge interpolation  %9.6f s\npush point interpolation %9.6f s\npush gyro interpolation  %9.6f" " s\n", (gpu_kernel_args->gpu_timing).memtransfer_charge_time, (gpu_kernel_args->gpu_timing).memtransfer_push_time, (gpu_kernel_args->gpu_timing).memtransfer_shift_time, (gpu_kernel_args->gpu_timing).device_charge_time, (gpu_kernel_args->gpu_timing).device_push_time, (gpu_kernel_args->gpu_timing).device_shift_time, (gpu_kernel_args->gpu_timing).device_particle_sort_time, (gpu_kernel_args->gpu_timing).device_particle_bin_time, (gpu_kernel_args->gpu_timing).memreset_charge_time, (gpu_kernel_args->gpu_timing).initialization_charge_time, (gpu_kernel_args->gpu_timing).interpolation_charge_time, (gpu_kernel_args->gpu_timing).interpolation_push_point_time, (gpu_kernel_args->gpu_timing).interpolation_push_gyro_time); 
# 523
} 

# 1 "gpu_setup.cudafe1.stub.c"
#define _NV_ANON_NAMESPACE _GLOBAL__N__17_gpu_setup_cpp1_ii_524b47c1
# 1 "gpu_setup.cudafe1.stub.c"
#include "gpu_setup.cudafe1.stub.c"
# 1 "gpu_setup.cudafe1.stub.c"
#undef _NV_ANON_NAMESPACE
